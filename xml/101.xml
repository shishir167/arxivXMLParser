<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T04:08:55Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|100001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610004</id><created>2006-10-01</created><authors><author><keyname>B&#xe9;cher</keyname><forenames>G&#xe9;rard</forenames><affiliation>GREYC</affiliation></author><author><keyname>Enjalbert</keyname><forenames>Patrice</forenames><affiliation>GREYC</affiliation></author><author><keyname>Fiev&#xe9;</keyname><forenames>Estelle</forenames><affiliation>LIMSI</affiliation></author><author><keyname>Gosselin</keyname><forenames>Laurent</forenames><affiliation>DS</affiliation></author><author><keyname>L&#xe9;vy</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIPN</affiliation></author><author><keyname>Ligozat</keyname><forenames>G&#xe9;rard</forenames><affiliation>LIMSI</affiliation></author></authors><title>Rapport technique du projet OGRE</title><categories>cs.CL cs.AI</categories><comments>92 pages</comments><proxy>ccsd ccsd-00102406</proxy><abstract>  This repport concerns automatic understanding of (french) iterative
sentences, i.e. sentences where one single verb has to be interpreted by a more
or less regular plurality of events. A linguistic analysis is proposed along an
extension of Reichenbach's theory, several formal representations are
considered and a corpus of 18000 newspaper extracts is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610005</id><created>2006-10-02</created><authors><author><keyname>Ren</keyname><forenames>Ran</forenames></author></authors><title>Domain Wall Displacement Detection Technology Research Report</title><categories>cs.OH</categories><comments>4 pages, 0 figures</comments><abstract>  This article introduce a new data storage method called DWDD(Domain Wall
Displacement Detection) and tell you why it succeed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610006</id><created>2006-10-02</created><updated>2007-04-03</updated><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>A Typed Hybrid Description Logic Programming Language with Polymorphic
  Order-Sorted DL-Typed Unification for Semantic Web Type Systems</title><categories>cs.AI</categories><comments>Full technical report 12/05. Published inn: Proc. of 2nd Int.
  Workshop on OWL: Experiences and Directions 2006 (OWLED'06) at ISWC'06,
  Athens, Georgia, USA, 2006</comments><acm-class>F.3; H.2; I.2; D.2</acm-class><journal-ref>In: Proc. of 2nd Int. Workshop on OWL: Experiences and Directions
  2006 (OWLED'06) at ISWC'06, Athens, Georgia, USA, 2006</journal-ref><abstract>  In this paper we elaborate on a specific application in the context of hybrid
description logic programs (hybrid DLPs), namely description logic Semantic Web
type systems (DL-types) which are used for term typing of LP rules based on a
polymorphic, order-sorted, hybrid DL-typed unification as procedural semantics
of hybrid DLPs. Using Semantic Web ontologies as type systems facilitates
interchange of domain-independent rules over domain boundaries via dynamically
typing and mapping of explicitly defined type ontologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610007</id><created>2006-10-02</created><updated>2006-10-05</updated><authors><author><keyname>Eichhorn</keyname><forenames>G&#xfc;nther</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Henneken</keyname><forenames>Edwin A.</forenames></author><author><keyname>Thompson</keyname><forenames>Donna M.</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Full Text Searching in the Astrophysics Data System</title><categories>cs.DL astro-ph cs.DB</categories><comments>To appear in Library and Information Systems in Astronomy V</comments><abstract>  The Smithsonian/NASA Astrophysics Data System (ADS) provides a search system
for the astronomy and physics scholarly literature. All major and many smaller
astronomy journals that were published on paper have been scanned back to
volume 1 and are available through the ADS free of charge. All scanned pages
have been converted to text and can be searched through the ADS Full Text
Search System. In addition, searches can be fanned out to several external
search systems to include the literature published in electronic form. Results
from the different search systems are combined into one results list.
  The ADS Full Text Search System is available at:
http://adsabs.harvard.edu/fulltext_service.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610008</id><created>2006-10-02</created><authors><author><keyname>Eichhorn</keyname><forenames>G&#xfc;nther</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Henneken</keyname><forenames>Edwin A.</forenames></author><author><keyname>Thompson</keyname><forenames>Donna M.</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Connectivity in the Astronomy Digital Library</title><categories>cs.DL astro-ph cs.DB</categories><comments>To appear in Library and Information Systems in Astronomy V</comments><abstract>  The Astrophysics Data System (ADS) provides an extensive system of links
between the literature and other on-line information. Recently, the journals of
the American Astronomical Society (AAS) and a group of NASA data centers have
collaborated to provide more links between on-line data obtained by space
missions and the on-line journals. Authors can now specify which data sets they
have used in their article. This information is used by the participants to
provide the links between the literature and the data.
  The ADS is available at: http://ads.harvard.edu
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610009</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610009</id><created>2006-10-03</created><updated>2007-02-01</updated><authors><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author><author><keyname>Perifel</keyname><forenames>Sylvain</forenames><affiliation>LIP</affiliation></author></authors><title>VPSPACE and a Transfer Theorem over the Reals</title><categories>cs.CC</categories><comments>Full version of the paper (appendices of the first version are now
  included in the text)</comments><proxy>ccsd ensl-00103018</proxy><abstract>  We introduce a new class VPSPACE of families of polynomials. Roughly
speaking, a family of polynomials is in VPSPACE if its coefficients can be
computed in polynomial space. Our main theorem is that if (uniform,
constant-free) VPSPACE families can be evaluated efficiently then the class PAR
of decision problems that can be solved in parallel polynomial time over the
real numbers collapses to P. As a result, one must first be able to show that
there are VPSPACE families which are hard to evaluate in order to separate over
the reals P from NP, or even from PAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610010</identifier>
 <datestamp>2014-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610010</id><created>2006-10-03</created><updated>2014-02-04</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Kaser</keyname><forenames>Owen</forenames></author></authors><title>One-Pass, One-Hash n-Gram Statistics Estimation</title><categories>cs.DB cs.CL</categories><comments>Fixed a typo</comments><report-no>TR-06-001</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In multimedia, text or bioinformatics databases, applications query sequences
of n consecutive symbols called n-grams. Estimating the number of distinct
n-grams is a view-size estimation problem. While view sizes can be estimated by
sampling under statistical assumptions, we desire an unassuming algorithm with
universally valid accuracy bounds. Most related work has focused on repeatedly
hashing the data, which is prohibitive for large data sources. We prove that a
one-pass one-hash algorithm is sufficient for accurate estimates if the hashing
is sufficiently independent. To reduce costs further, we investigate recursive
random hashing algorithms and show that they are sufficiently independent in
practice. We compare our running times with exact counts using suffix arrays
and show that, while we use hardly any storage, we are an order of magnitude
faster. The approach further is extended to a one-pass/one-hash computation of
n-gram entropy and iceberg counts. The experiments use a large collection of
English text from the Gutenberg Project as well as synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610011</id><created>2006-10-03</created><authors><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Eichhorn</keyname><forenames>Gunther</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Henneken</keyname><forenames>Edwin</forenames></author><author><keyname>Demleitner</keyname><forenames>Markus</forenames></author><author><keyname>Thompson</keyname><forenames>Donna</forenames></author><author><keyname>Bohlen</keyname><forenames>Elizabeth</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Creation and use of Citations in the ADS</title><categories>cs.DL astro-ph cs.DB cs.IR</categories><comments>9 pages; to be published in the proceedings of the conference
  &quot;Library and Information Services V,&quot; June 2006, Cambridge, MA, USA</comments><abstract>  With over 20 million records, the ADS citation database is regularly used by
researchers and librarians to measure the scientific impact of individuals,
groups, and institutions. In addition to the traditional sources of citations,
the ADS has recently added references extracted from the arXiv e-prints on a
nightly basis. We review the procedures used to harvest and identify the
reference data used in the creation of citations, the policies and procedures
that we follow to avoid double-counting and to eliminate contributions which
may not be scholarly in nature. Finally, we describe how users and institutions
can easily obtain quantitative citation data from the ADS, both interactively
and via web-based programming tools.
  The ADS is available at http://ads.harvard.edu.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610012</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610012</id><created>2006-10-04</created><updated>2007-06-21</updated><authors><author><keyname>Pillai</keyname><forenames>N Rajesh</forenames></author><author><keyname>Kumar</keyname><forenames>Yogesh</forenames></author></authors><title>On Shift Sequences for Interleaved Construction of Sequence Sets with
  Low Correlation</title><categories>cs.IT math.IT</categories><comments>Corrected typos. Added special case for v=2 for second problem</comments><abstract>  Construction of signal sets with low correlation property is of interest to
designers of CDMA systems. One of the preferred ways of constructing such sets
is the interleaved construction which uses two sequences a and b with 2-level
autocorrelation and a shift sequence e. The shift sequence has to satisfy
certain conditions for the resulting signal set to have low correlation
properties. This article shows that the conditions reported in literature are
too strong and gives a version which results in more number of shift sequences.
An open problem on the existence of shift sequences for attaining an
interleaved set with maximum correlation value bounded by v+2 is also taken up
and solved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610013</id><created>2006-10-04</created><authors><author><keyname>Gaaloul</keyname><forenames>Khaled</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Charoy</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Godart</keyname><forenames>Claude</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Cooperative Processes for Scientific Workflows</title><categories>cs.NI</categories><proxy>ccsd inria-00102537</proxy><journal-ref>Dans 6th International Conference on Computational Science 3, 3993
  (2006) 976-979</journal-ref><abstract>  The work described in this paper is a contribution to the problems of
managing in data-intensive scientific applications. First, we discuss
scientific workflows and motivate there use in scientific applications. Then,
we introduce the concept of cooperative processes and describe their
interactions and uses in a flexible cooperative workflow system called
\textit{Bonita}. Finally, we propose an approach to integrate and synthesize
the data exchanged by the mapping of data-intensive science into Bonita, using
a binary approach, and illustrate the endeavors done to enhance the performance
computations within a dynamic environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610014</id><created>2006-10-04</created><authors><author><keyname>Tuengerthal</keyname><forenames>Max</forenames><affiliation>CHRISTIAN-Albrechts-Universit&#xe4;T Zu Kiel</affiliation></author><author><keyname>Kuesters</keyname><forenames>Ralf</forenames><affiliation>CHRISTIAN-Albrechts-Universit&#xe4;T Zu Kiel</affiliation></author><author><keyname>Turuani</keyname><forenames>Mathieu</forenames><affiliation>INRIA Lorraine - Loria / Lifc</affiliation></author></authors><title>Implementing a Unification Algorithm for Protocol Analysis with XOR</title><categories>cs.CR</categories><proxy>ccsd inria-00103602</proxy><journal-ref>Dans UNIF'06 - 20th International Workshop on Unification (2006)
  1-5</journal-ref><abstract>  In this paper, we propose a unification algorithm for the theory $E$ which
combines unification algorithms for $E\_{\std}$ and $E\_{\ACUN}$ (ACUN
properties, like XOR) but compared to the more general combination methods uses
specific properties of the equational theories for further optimizations. Our
optimizations drastically reduce the number of non-deterministic choices, in
particular those for variable identification and linear orderings. This is
important for reducing both the runtime of the unification algorithm and the
number of unifiers in the complete set of unifiers. We emphasize that obtaining
a ``small'' set of unifiers is essential for the efficiency of the constraint
solving procedure within which the unification algorithm is used. The method is
implemented in the CL-Atse tool for security protocol analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610015</id><created>2006-10-04</created><authors><author><keyname>Nouioua</keyname><forenames>Farid</forenames><affiliation>LIPN</affiliation></author></authors><title>Why did the accident happen? A norm-based reasoning approach</title><categories>cs.AI</categories><proxy>ccsd ccsd-00085160</proxy><journal-ref>Logical Aspects of Computational Linguistics, student
  sessionUniversit\'{e} de bordeaux (Ed.) (2005) 31-34</journal-ref><abstract>  In this paper we describe an architecture of a system that answer the
question : Why did the accident happen? from the textual description of an
accident. We present briefly the different parts of the architecture and then
we describe with more detail the semantic part of the system i.e. the part in
which the norm-based reasoning is performed on the explicit knowlege extracted
from the text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610016</id><created>2006-10-04</created><authors><author><keyname>Nouioua</keyname><forenames>Farid</forenames><affiliation>LIPN</affiliation></author></authors><title>Norm Based Causal Reasoning in Textual Corpus</title><categories>cs.AI cs.CL</categories><proxy>ccsd ccsd-00085161</proxy><journal-ref>Proceedings of the Sixth International Workshop on Computational
  Semantics IWCS-6, France (2005) 396-400</journal-ref><abstract>  Truth based entailments are not sufficient for a good comprehension of NL. In
fact, it can not deduce implicit information necessary to understand a text. On
the other hand, norm based entailments are able to reach this goal. This idea
was behind the development of Frames (Minsky 75) and Scripts (Schank 77, Schank
79) in the 70's. But these theories are not formalized enough and their
adaptation to new situations is far from being obvious. In this paper, we
present a reasoning system which uses norms in a causal reasoning process in
order to find the cause of an accident from a text describing it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610017</id><created>2006-10-04</created><authors><author><keyname>Satti</keyname><forenames>Maruti</forenames></author></authors><title>A Quasigroup Based Cryptographic System</title><categories>cs.CR</categories><comments>22 pages, 11 figures</comments><abstract>  This paper presents a quasigroup encryptor that has very good scrambling
properties. We show that the output of the encryptor maximizes the output
entropy and the encrypted output for constant and random inputs is very
similar. The system architecture of the quasigroup encryptor and the
autocorrelation properties of the output sequences are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610018</id><created>2006-10-04</created><authors><author><keyname>Nouioua</keyname><forenames>Farid</forenames><affiliation>LIPN</affiliation></author></authors><title>Raisonnement stratifi\'{e} \`{a} base de normes pour inf\'{e}rer les
  causes dans un corpus textuel</title><categories>cs.AI cs.CL</categories><proxy>ccsd ccsd-00085163</proxy><journal-ref>The Seventh International Symposium On Programming and
  SystemsUSTHB d'Alger (Ed.) (2005) 81-92</journal-ref><abstract>  To understand texts written in natural language (LN), we use our knowledge
about the norms of the domain. Norms allow to infer more implicit information
from the text. This kind of information can, in general, be defeasible, but it
remains useful and acceptable while the text do not contradict it explicitly.
In this paper we describe a non-monotonic reasoning system based on the norms
of the car crash domain. The system infers the cause of an accident from its
textual description. The cause of an accident is seen as the most specific norm
which has been violated. The predicates and the rules of the system are
stratified: organized on layers in order to obtain an efficient reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610019</id><created>2006-10-04</created><authors><author><keyname>Samper</keyname><forenames>Juan J.</forenames></author><author><keyname>Castillo</keyname><forenames>Pedro A.</forenames></author><author><keyname>Araujo</keyname><forenames>Lourdes</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author></authors><title>NectaRSS, an RSS feed ranking system that implicitly learns user
  preferences</title><categories>cs.IR cs.HC</categories><comments>Submitted to First Monday. 16 pages</comments><abstract>  In this paper a new RSS feed ranking method called NectaRSS is introduced.
The system recommends information to a user based on his/her past choices. User
preferences are automatically acquired, avoiding explicit feedback, and ranking
is based on those preferences distilled to a user profile. NectaRSS uses the
well-known vector space model for user profiles and new documents, and compares
them using information-retrieval techniques, but introduces a novel method for
user profile creation and adaptation from users' past choices. The efficiency
of the proposed method has been tested by embedding it into an intelligent
aggregator (RSS feed reader), which has been used by different and
heterogeneous users. Besides, this paper proves that the ranking of newsitems
yielded by NectaRSS improves its quality with user's choices, and its
superiority over other algorithms that use a different information
representation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610020</id><created>2006-10-04</created><updated>2006-10-06</updated><authors><author><keyname>Gilreath</keyname><forenames>William F.</forenames></author></authors><title>XString: XML as a String</title><categories>cs.DB</categories><comments>27-pages, 2-tables</comments><abstract>  Extensible markup language (XML) is a technology that has been much hyped, so
that XML has become an industry buzzword. Behind the hype is a powerful
technology for data representation in a platform independent manner. As a text
document, however, XML suffers from being too bloated, and requires an XML
parser to access and manipulate it. XString is an encoding method for XML, in
essence, a markup language's markup language. XString gives the benefit of
compressing XML, and allows for easy manipulation and processing of XML source
as a very long string.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610021</identifier>
 <datestamp>2007-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610021</id><created>2006-10-04</created><updated>2007-10-13</updated><authors><author><keyname>Bennatan</keyname><forenames>Amir</forenames></author><author><keyname>Burshtein</keyname><forenames>David</forenames></author></authors><title>On the Fading Paper Achievable Region of the Fading MIMO Broadcast
  Channel</title><categories>cs.IT math.IT</categories><comments>Manuscript submitted to IEEE Transactions on Information Theory: June
  2006, revised: July 2007, accepted: October 2007. The material in this paper
  was presented at the 44th Annual Allerton Conference on Communications,
  Control and Computing, Monticello, IL, September 2006</comments><abstract>  We consider transmission over the ergodic fading multi-antenna broadcast
(MIMO-BC) channel with partial channel state information at the transmitter and
full information at the receiver. Over the equivalent {\it non}-fading channel,
capacity has recently been shown to be achievable using transmission schemes
that were designed for the ``dirty paper'' channel. We focus on a similar
``fading paper'' model. The evaluation of the fading paper capacity is
difficult to obtain. We confine ourselves to the {\it linear-assignment}
capacity, which we define, and use convex analysis methods to prove that its
maximizing distribution is Gaussian. We compare our fading-paper transmission
to an application of dirty paper coding that ignores the partial state
information and assumes the channel is fixed at the average fade. We show that
a gain is easily achieved by appropriately exploiting the information. We also
consider a cooperative upper bound on the sum-rate capacity as suggested by
Sato. We present a numeric example that indicates that our scheme is capable of
realizing much of this upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610022</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610022</id><created>2006-10-05</created><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author></authors><title>Iterative Decoding of Low-Density Parity Check Codes (A Survey)</title><categories>cs.IT cs.CC math.IT</categories><comments>29 pages</comments><acm-class>E.4</acm-class><journal-ref>Bulletin of the EATCS, Issue 90, October 2006</journal-ref><abstract>  Much progress has been made on decoding algorithms for error-correcting codes
in the last decade. In this article, we give an introduction to some
fundamental results on iterative, message-passing algorithms for low-density
parity check codes. For certain important stochastic channels, this line of
work has enabled getting very close to Shannon capacity with algorithms that
are extremely efficient (both in theory and practice).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610023</id><created>2006-10-05</created><authors><author><keyname>Nouioua</keyname><forenames>Farid</forenames><affiliation>LIPN</affiliation></author><author><keyname>Kayser</keyname><forenames>Daniel</forenames><affiliation>LIPN</affiliation></author></authors><title>Une exp\'{e}rience de s\'{e}mantique inf\'{e}rentielle</title><categories>cs.AI</categories><proxy>ccsd ccsd-00085151</proxy><journal-ref>Actes de TALN'06UCL Presses Universitaires de Louvain (Ed.) (2006)
  246-255</journal-ref><abstract>  We develop a system which must be able to perform the same inferences that a
human reader of an accident report can do and more particularly to determine
the apparent causes of the accident. We describe the general framework in which
we are situated, linguistic and semantic levels of the analysis and the
inference rules used by the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610024</id><created>2006-10-05</created><authors><author><keyname>Brahimi</keyname><forenames>Belynda</forenames><affiliation>CRAN</affiliation></author><author><keyname>Aubrun</keyname><forenames>Christophe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Rondeau</keyname><forenames>Eric</forenames><affiliation>CRAN</affiliation></author></authors><title>Network calculus based FDI approach for switched Ethernet architecture</title><categories>cs.NI</categories><proxy>ccsd ccsd-00103675</proxy><journal-ref>6th IFAC Symposium on Fault Detection, Supervision and Safety of
  Technical Processes, Chine (29/08/2006) 6 pages</journal-ref><abstract>  The Networked Control Systems (NCS) are complex systems which integrate
information provided by several domians such as automatic control, computer
science, communication network. The work presented in this paper concerns fault
detection, isolation and compensation of communication network. The proposed
method is based on the classical approach of Fault Detection and Isolation and
Fault Tolerant Control (FDI/FTC) currently used in diagnosis. The modelling of
the network to be supervised is based on both couloured petri nets and network
calculus theory often used to represent and analyse the network behaviour. The
goal is to implement inside network devices algorithms enabling to detect,
isolate and compensate communication faults in an autonomous way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610025</identifier>
 <datestamp>2007-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610025</id><created>2006-10-05</created><updated>2007-11-28</updated><authors><author><keyname>Anand</keyname><forenames>M.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Low Correlation Sequences over the QAM Constellation</title><categories>cs.IT math.IT</categories><comments>21 pages, 3 figures. To appear in IEEE Transactions on Information
  Theory in February 2008</comments><abstract>  This paper presents the first concerted look at low correlation sequence
families over QAM constellations of size M^2=4^m and their potential
applicability as spreading sequences in a CDMA setting.
  Five constructions are presented, and it is shown how such sequence families
have the ability to transport a larger amount of data as well as enable
variable-rate signalling on the reverse link.
  Canonical family CQ has period N, normalized maximum-correlation parameter
theta_max bounded above by A sqrt(N), where 'A' ranges from 1.8 in the 16-QAM
case to 3.0 for large M. In a CDMA setting, each user is enabled to transfer 2m
bits of data per period of the spreading sequence which can be increased to 3m
bits of data by halving the size of the sequence family. The technique used to
construct CQ is easily extended to produce larger sequence families and an
example is provided.
  Selected family SQ has a lower value of theta_max but permits only (m+1)-bit
data modulation. The interleaved 16-QAM sequence family IQ has theta_max &lt;=
sqrt(2) sqrt(N) and supports 3-bit data modulation.
  The remaining two families are over a quadrature-PAM (Q-PAM) subset of size
2M of the M^2-QAM constellation. Family P has a lower value of theta_max in
comparison with Family SQ, while still permitting (m+1)-bit data modulation.
Interleaved family IP, over the 8-ary Q-PAM constellation, permits 3-bit data
modulation and interestingly, achieves the Welch lower bound on theta_max.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610026</id><created>2006-10-05</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>van Stee</keyname><forenames>Rob</forenames></author></authors><title>Covering selfish machines</title><categories>cs.GT</categories><abstract>  We consider the machine covering problem for selfish related machines. For a
constant number of machines, m, we show a monotone polynomial time
approximation scheme (PTAS) with running time that is linear in the number of
jobs. It uses a new technique for reducing the number of jobs while remaining
close to the optimal solution. We also present an FPTAS for the classical
machine covering problem (the previous best result was a PTAS) and use this to
give a monotone FPTAS.
  Additionally, we give a monotone approximation algorithm with approximation
ratio \min(m,(2+\eps)s_1/s_m) where \eps&gt;0 can be chosen arbitrarily small and
s_i is the (real) speed of machine i. Finally we give improved results for two
machines.
  Our paper presents the first results for this problem in the context of
selfish machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610027</identifier>
 <datestamp>2008-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610027</id><created>2006-10-05</created><updated>2008-04-03</updated><authors><author><keyname>Demri</keyname><forenames>Stephane</forenames></author><author><keyname>Lazic</keyname><forenames>Ranko</forenames></author></authors><title>LTL with the Freeze Quantifier and Register Automata</title><categories>cs.LO cs.CC</categories><comments>29 pages</comments><acm-class>F.1.1; F.4.1</acm-class><abstract>  A data word is a sequence of pairs of a letter from a finite alphabet and an
element from an infinite set, where the latter can only be compared for
equality. To reason about data words, linear temporal logic is extended by the
freeze quantifier, which stores the element at the current word position into a
register, for equality comparisons deeper in the formula. By translations from
the logic to alternating automata with registers and then to faulty counter
automata whose counters may erroneously increase at any time, and from faulty
and error-free counter automata to the logic, we obtain a complete complexity
table for logical fragments defined by varying the set of temporal operators
and the number of registers. In particular, the logic with future-time
operators and 1 register is decidable but not primitive recursive over finite
data words. Adding past-time operators or 1 more register, or switching to
infinite data words, cause undecidability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610028</id><created>2006-10-05</created><authors><author><keyname>Zendra</keyname><forenames>Olivier</forenames><affiliation>INRIA Lorraine - LORIA, LORIA</affiliation></author></authors><title>Memory and compiler optimizations for low-power and -energy</title><categories>cs.PL cs.PF</categories><comments>ICOOOLPS'2006 was co-located with the 20th European Conference on
  Object-Oriented Programming (ECOOP'2006)</comments><proxy>ccsd inria-00104146</proxy><journal-ref>Dans 1st ECOOP Workshop on Implementation, Compilation,
  Optimization of Object-Oriented Languages, Programs and Systems
  (ICOOOLPS'2006). (2006)</journal-ref><abstract>  Embedded systems become more and more widespread, especially autonomous ones,
and clearly tend to be ubiquitous. In such systems, low-power and low-energy
usage get ever more crucial. Furthermore, these issues also become paramount in
(massively) multi-processors systems, either in one machine or more widely in a
grid. The various problems faced pertain to autonomy, power supply
possibilities, thermal dissipation, or even sheer energy cost. Although it has
since long been studied in harware, energy optimization is more recent in
software. In this paper, we thus aim at raising awareness to low-power and
low-energy issues in the language and compilation community. We thus broadly
but briefly survey techniques and solutions to this energy issue, focusing on a
few specific aspects in the context of compiler optimizations and memory
management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610029</id><created>2006-10-05</created><authors><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Thompson</keyname><forenames>Donna</forenames></author><author><keyname>Henneken</keyname><forenames>Edwin</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Data in the ADS -- Understanding How to Use it Better</title><categories>cs.DL cs.DB</categories><comments>4 pages; submitted to the proceedings of the Library and Information
  Services in Astronomy V; to be published by ASP Conference Proceedings</comments><abstract>  The Smithsonian/NASA ADS Abstract Service contains a wealth of data for
astronomers and librarians alike, yet the vast majority of usage consists of
rudimentary searches. Hints on how to obtain more focused search results by
using more of the various capabilities of the ADS are presented, including
searching by affiliation. We also discuss the classification of articles by
content and by referee status.
  The ADS is funded by NASA Grant NNG06GG68G-16613687.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610030</id><created>2006-10-05</created><authors><author><keyname>Thompson</keyname><forenames>Donna M.</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn</forenames></author><author><keyname>Henneken</keyname><forenames>Edwin</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Bohlen</keyname><forenames>Elizabeth</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Paper to Screen: Processing Historical Scans in the ADS</title><categories>cs.DL cs.HC</categories><comments>4 pages; submitted to the proceedings of Library and Information
  Services in Astronomy; to be published in the ASP Conference Series</comments><abstract>  The NASA Astrophysics Data System in conjunction with the Wolbach Library at
the Harvard-Smithsonian Center for Astrophysics is working on a project to
microfilm historical observatory publications. The microfilm is then scanned
for inclusion in the ADS. The ADS currently contains over 700,000 scanned pages
of volumes of historical literature. Many of these volumes lack clear
pagination or other bibliographic data that are necessary to take advantage of
the searching capabilities of the ADS. This paper will address some of the
interesting challenges that needed to be resolved during the processing of the
Observatory Reports included in the ADS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610031</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610031</id><created>2006-10-05</created><authors><author><keyname>Warner</keyname><forenames>Simeon</forenames></author><author><keyname>Bekaert</keyname><forenames>Jeroen</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoming</forenames></author><author><keyname>Payette</keyname><forenames>Sandy</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Pathways: Augmenting interoperability across scholarly repositories</title><categories>cs.DL</categories><comments>18 pages. Accepted for International Journal on Digital Libraries
  special issue on Digital Libraries and eScience</comments><acm-class>H.3.7</acm-class><doi>10.1007/s00799-007-0016-7</doi><abstract>  In the emerging eScience environment, repositories of papers, datasets,
software, etc., should be the foundation of a global and natively-digital
scholarly communications system. The current infrastructure falls far short of
this goal. Cross-repository interoperability must be augmented to support the
many workflows and value-chains involved in scholarly communication. This will
not be achieved through the promotion of single repository architecture or
content representation, but instead requires an interoperability framework to
connect the many heterogeneous systems that will exist.
  We present a simple data model and service architecture that augments
repository interoperability to enable scholarly value-chains to be implemented.
We describe an experiment that demonstrates how the proposed infrastructure can
be deployed to implement the workflow involved in the creation of an overlay
journal over several different repository systems (Fedora, aDORe, DSpace and
arXiv).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610032</id><created>2006-10-05</created><authors><author><keyname>Walma</keyname><forenames>Mathys</forenames></author></authors><title>Pipelined Feed-Forward Cyclic Redundancy Check (CRC) Calculation</title><categories>cs.NI</categories><comments>admin note: Paper removed for copyright reasons</comments><abstract>  This paper discusses a method for pipelining the calculation of CRC's, such
as ITU/CCITT CRC32, into a mostly feed-forward architecture. This method allows
several benefits such as independent scaling of circuit frequency and data
throughput. Additionally it allows calculation over packet tails (packet length
not a multiple of CRC input width). Finally it offers the ability to update a
CRC where a subset of data in the packet has changed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610033</identifier>
 <datestamp>2009-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610033</id><created>2006-10-06</created><authors><author><keyname>Cuturi</keyname><forenames>Marco</forenames></author><author><keyname>Vert</keyname><forenames>Jean-Philippe</forenames></author><author><keyname>Birkenes</keyname><forenames>Oystein</forenames></author><author><keyname>Matsui</keyname><forenames>Tomoko</forenames></author></authors><title>A kernel for time series based on global alignments</title><categories>cs.CV cs.LG</categories><doi>10.1109/ICASSP.2007.366260</doi><abstract>  We propose in this paper a new family of kernels to handle times series,
notably speech data, within the framework of kernel methods which includes
popular algorithms such as the Support Vector Machine. These kernels elaborate
on the well known Dynamic Time Warping (DTW) family of distances by considering
the same set of elementary operations, namely substitutions and repetitions of
tokens, to map a sequence onto another. Associating to each of these operations
a given score, DTW algorithms use dynamic programming techniques to compute an
optimal sequence of operations with high overall score. In this paper we
consider instead the score spanned by all possible alignments, take a smoothed
version of their maximum and derive a kernel out of this formulation. We prove
that this kernel is positive definite under favorable conditions and show how
it can be tuned effectively for practical applications as we report encouraging
results on a speech recognition task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610034</identifier>
 <datestamp>2012-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610034</id><created>2006-10-06</created><updated>2012-08-28</updated><authors><author><keyname>Graedel</keyname><forenames>Erich</forenames></author><author><keyname>Walukiewicz</keyname><forenames>Igor</forenames></author></authors><title>Postinal Determinacy of Games with Infinitely Many Priorities</title><categories>cs.LO cs.GT</categories><comments>This paper has been replaced due to a typo in the title</comments><abstract>  We study two-player games of infinite duration that are played on finite or
infinite game graphs. A winning strategy for such a game is positional if it
only depends on the current position, and not on the history of the play. A
game is positionally determined if, from each position, one of the two players
has a positional winning strategy.
  The theory of such games is well studied for winning conditions that are
defined in terms of a mapping that assigns to each position a priority from a
finite set. Specifically, in Muller games the winner of a play is determined by
the set of those priorities that have been seen infinitely often; an important
special case are parity games where the least (or greatest) priority occurring
infinitely often determines the winner. It is well-known that parity games are
positionally determined whereas Muller games are determined via finite-memory
strategies.
  In this paper, we extend this theory to the case of games with infinitely
many priorities. Such games arise in several application areas, for instance in
pushdown games with winning conditions depending on stack contents.
  For parity games there are several generalisations to the case of infinitely
many priorities. While max-parity games over omega or min-parity games over
larger ordinals than omega require strategies with infinite memory, we can
prove that min-parity games with priorities in omega are positionally
determined. Indeed, it turns out that the min-parity condition over omega is
the only infinitary Muller condition that guarantees positional determinacy on
all game graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610035</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610035</id><created>2006-10-06</created><updated>2006-11-03</updated><authors><author><keyname>Graedel</keyname><forenames>Erich</forenames></author><author><keyname>Walukiewicz</keyname><forenames>Igor</forenames></author></authors><title>Positional Determinacy of Games with Infinitely Many Priorities</title><categories>cs.LO cs.GT</categories><acm-class>F.4.1; G.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 4 (November
  3, 2006) lmcs:912</journal-ref><doi>10.2168/LMCS-2(4:6)2006</doi><abstract>  We study two-player games of infinite duration that are played on finite or
infinite game graphs. A winning strategy for such a game is positional if it
only depends on the current position, and not on the history of the play. A
game is positionally determined if, from each position, one of the two players
has a positional winning strategy.
  The theory of such games is well studied for winning conditions that are
defined in terms of a mapping that assigns to each position a priority from a
finite set. Specifically, in Muller games the winner of a play is determined by
the set of those priorities that have been seen infinitely often; an important
special case are parity games where the least (or greatest) priority occurring
infinitely often determines the winner. It is well-known that parity games are
positionally determined whereas Muller games are determined via finite-memory
strategies.
  In this paper, we extend this theory to the case of games with infinitely
many priorities. Such games arise in several application areas, for instance in
pushdown games with winning conditions depending on stack contents.
  For parity games there are several generalisations to the case of infinitely
many priorities. While max-parity games over omega or min-parity games over
larger ordinals than omega require strategies with infinite memory, we can
prove that min-parity games with priorities in omega are positionally
determined. Indeed, it turns out that the min-parity condition over omega is
the only infinitary Muller condition that guarantees positional determinacy on
all game graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610036</identifier>
 <datestamp>2008-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610036</id><created>2006-10-06</created><updated>2008-01-15</updated><authors><author><keyname>Nuida</keyname><forenames>Koji</forenames></author><author><keyname>Hagiwara</keyname><forenames>Manabu</forenames></author><author><keyname>Watanabe</keyname><forenames>Hajime</forenames></author><author><keyname>Imai</keyname><forenames>Hideki</forenames></author></authors><title>Optimization of Memory Usage in Tardos's Fingerprinting Codes</title><categories>cs.CR cs.NA</categories><comments>12 pages, 1 figure; (v2) tables revised, typos corrected, comments on
  some recent works added; (v3) submitted version, title changed from &quot;Optimal
  probabilistic fingerprinting codes using optimal finite random variables
  related to numerical quadrature&quot;</comments><acm-class>K.4.4; G.1.4</acm-class><abstract>  It is known that Tardos's collusion-secure probabilistic fingerprinting code
(Tardos code; STOC'03) has length of theoretically minimal order with respect
to the number of colluding users. However, Tardos code uses certain continuous
probability distribution in codeword generation, which creates some problems
for practical use, in particular, it requires large extra memory. A solution
proposed so far is to use some finite probability distributions instead. In
this paper, we determine the optimal finite distribution in order to decrease
extra memory amount. By our result, the extra memory is reduced to 1/32 of the
original, or even becomes needless, in some practical setting. Moreover, the
code length is also reduced, e.g. to about 20.6% of Tardos code asymptotically.
Finally, we address some other practical issues such as approximation errors
which are inevitable in any real implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610037</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610037</id><created>2006-10-06</created><authors><author><keyname>Liu</keyname><forenames>Nan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>The Capacity Region of a Class of Discrete Degraded Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure; presented at the 44th annual Allerton Conference
  on Communication, Control and Computing, September 27-29, 2006</comments><abstract>  We provide a single-letter characterization for the capacity region of a
class of discrete degraded interference channels (DDICs). The class of DDICs
considered includes the discrete additive degraded interference channel (DADIC)
studied by Benzel. We show that for the class of DDICs studied, encoder
cooperation does not increase the capacity region, and therefore, the capacity
region of the class of DDICs is the same as the capacity region of the
corresponding degraded broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610038</id><created>2006-10-07</created><authors><author><keyname>Hutzelmeyer</keyname><forenames>Hannes</forenames></author></authors><title>Church's thesis is questioned by new calculation paradigm</title><categories>cs.LO</categories><comments>32 pages</comments><acm-class>F.4.1</acm-class><abstract>  Church's thesis claims that all effecticely calculable functions are
recursive. A shortcoming of the various definitions of recursive functions lies
in the fact that it is not a matter of a syntactical check to find out if an
entity gives rise to a function. Eight new ideas for a precise setup of
arithmetical logic and its metalanguage give the proper environment for the
construction of a special computer, the ARBACUS computer. Computers do not come
to a necessary halt; it is requested that calculators are constructed on the
basis of computers in a way that they always come to a halt, then all
calculations are effective. The ARBATOR is defined as a calculator with
two-layer-computation. It allows for the calculation of all primitive recursive
functions, but multi-level-arbation also allows for the calculation of other
arbative functions that are not primitive recursive. The new paradigm of
calculation does not have the above mentioned shortcoming. The defenders of
Church's thesis are challenged to show that exotic arbative functions are
recursive and to put forward a recursive function that is not arbative. A
construction with three-tier-multi-level-arbation that includes a
diagonalisation leads to the extravagant yet calculable Snark-function that is
not arbative. As long as it is not shown that all exotic arbative functions and
particularily the Snark-function are arithmetically representable Goedel's
first incompleteness sentence is in limbo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610039</id><created>2006-10-08</created><authors><author><keyname>Rubens</keyname><forenames>Neil</forenames></author></authors><title>The Application of Fuzzy Logic to the Construction of the Ranking
  Function of Information Retrieval Systems</title><categories>cs.IR cs.AI</categories><journal-ref>N. Rubens. The application of fuzzy logic to the construction of
  the ranking function of information retrieval systems. Computer Modelling and
  New Technologies, 10(1):20-27, 2006</journal-ref><abstract>  The quality of the ranking function is an important factor that determines
the quality of the Information Retrieval system. Each document is assigned a
score by the ranking function; the score indicates the likelihood of relevance
of the document given a query. In the vector space model, the ranking function
is defined by a mathematic expression. We propose a fuzzy logic (FL) approach
to defining the ranking function. FL provides a convenient way of converting
knowledge expressed in a natural language into fuzzy logic rules. The resulting
ranking function could be easily viewed, extended, and verified: * if (tf is
high) and (idf is high) &gt; (relevance is high); * if (overlap is high) &gt;
(relevance is high). By using above FL rules, we are able to achieve
performance approximately equal to the state of the art search engine Apache
Lucene (deltaP10 +0.92%; deltaMAP -0.1%). The fuzzy logic approach allows
combining the logic-based model with the vector model. The resulting model
possesses simplicity and formalism of the logic based model, and the
flexibility and performance of the vector model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610040</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610040</id><created>2006-10-09</created><authors><author><keyname>Deng</keyname><forenames>Yun</forenames></author><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author></authors><title>Crosstalk-free Conjugate Networks for Optical Multicast Switching</title><categories>cs.NI</categories><comments>10 pages</comments><doi>10.1109/JLT.2006.882249</doi><abstract>  High-speed photonic switching networks can switch optical signals at the rate
of several terabits per second. However, they suffer from an intrinsic
crosstalk problem when two optical signals cross at the same switch element. To
avoid crosstalk, active connections must be node-disjoint in the switching
network. In this paper, we propose a sequence of decomposition and merge
operations, called conjugate transformation, performed on each switch element
to tackle this problem. The network resulting from this transformation is
called conjugate network. By using the numbering-schemes of networks, we prove
that if the route assignments in the original network are link-disjoint, their
corresponding ones in the conjugate network would be node-disjoint. Thus,
traditional nonblocking switching networks can be transformed into
crosstalk-free optical switches in a routine manner. Furthermore, we show that
crosstalk-free multicast switches can also be obtained from existing
nonblocking multicast switches via the same conjugate transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610041</id><created>2006-10-09</created><authors><author><keyname>Fix</keyname><forenames>J&#xe9;r&#xe9;my</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Vitay</keyname><forenames>Julien</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Rougier</keyname><forenames>Nicolas</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A Computational Model of Spatial Memory Anticipation during Visual
  Search</title><categories>cs.NE</categories><proxy>ccsd inria-00104673</proxy><journal-ref>Dans Anticipatory Behavior in Adaptive Learning Systems 2006
  (2006)</journal-ref><abstract>  Some visual search tasks require to memorize the location of stimuli that
have been previously scanned. Considerations about the eye movements raise the
question of how we are able to maintain a coherent memory, despite the frequent
drastically changes in the perception. In this article, we present a
computational model that is able to anticipate the consequences of the eye
movements on the visual perception in order to update a spatial memory
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610042</identifier>
 <datestamp>2008-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610042</id><created>2006-10-09</created><updated>2008-09-25</updated><authors><author><keyname>Gubin</keyname><forenames>Sergey</forenames></author></authors><title>A Polynomial Time Algorithm for The Traveling Salesman Problem</title><categories>cs.DM cs.CC cs.DS</categories><comments>8 pages. Simplified</comments><acm-class>F.2.0; G.2.1; G.2.2</acm-class><journal-ref>Complementary to Yannakakis' Theorem, 22nd MCCCC, University of
  Nevada, Las Vegas, 2008, p.8</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ATSP polytope can be expressed by asymmetric polynomial size linear
program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610043</id><created>2006-10-09</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author></authors><title>Farthest-Point Heuristic based Initialization Methods for K-Modes
  Clustering</title><categories>cs.AI</categories><comments>7 pages</comments><abstract>  The k-modes algorithm has become a popular technique in solving categorical
data clustering problems in different application domains. However, the
algorithm requires random selection of initial points for the clusters.
Different initial points often lead to considerable distinct clustering
results. In this paper we present an experimental study on applying a
farthest-point heuristic based initialization method to k-modes clustering to
improve its performance. Experiments show that new initialization method leads
to better clustering accuracy than random selection initialization method for
k-modes clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610044</id><created>2006-10-09</created><authors><author><keyname>Turletti</keyname><forenames>Thierry</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Seok</keyname><forenames>Yongho</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>M\'{e}canismes de Transmission Multipoint pour R\'{e}seaux Locaux Sans
  Fil IEEE 802.11</title><categories>cs.NI</categories><proxy>ccsd inria-00104699</proxy><abstract>  Le standard IEEE 802.11 est inefficace pour la transmission multim\'{e}dia en
multipoint. En particulier, les paquets multipoints sont envoy\'{e}s en boucle
ouverte de la m\^{e}me mani\`{e}re que les paquets broadcast. L'absence
d'acquittements rend impossible la mise en oeuvre de m\'{e}canismes de
contr\^{o}le de congestion, de m\'{e}canisme de fiabilisation de la
transmission ainsi que d'algorithmes d'adaptation du d\'{e}bit de transmission
physique. Dans ce rapport, nous proposons de nouveaux m\'{e}canismes de
ransmission multipoint qui se basent sur une approche leader pour renvoyer des
acquittements. Nous nous interessons \`{a} des solutions pratiques qui sont
suceptibles d'\^{e}tre implant\'{e}s dans les cartes r\'{e}seaux sans fil
actuelles et futures et qui restent compatibles avec les stations IEEE 802.11
standards. Nous proposons deux m\'{e}canismes pour adapter le d\'{e}bit de
transmission physique des flots multipoints: un m\'{e}canisme simplifi\'{e}
appel\'{e} LB-ARF et un m\'{e}canisme plus robuste appel\'{e} RRAM. Nos
simulations montrent que pour des environnements statiques, un m\'{e}canisme
aussi simple que LB-ARF suffit pour obtenir de bonnes performances. Le
m\'{e}canisme RRAM est quant \`{a} lui aussi efficace dans des environnements
statiques que lorsque les stations sont mobiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610045</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610045</id><created>2006-10-09</created><authors><author><keyname>Far</keyname><forenames>Reza Rashidi</forenames></author><author><keyname>Oraby</keyname><forenames>Tamer</forenames></author><author><keyname>Bryc</keyname><forenames>Wlodzimierz</forenames></author><author><keyname>Speicher</keyname><forenames>Roland</forenames></author></authors><title>Spectra of large block matrices</title><categories>cs.IT math.IT math.OA</categories><comments>40 pages, 6 figures</comments><acm-class>H.1.1</acm-class><abstract>  In a frequency selective slow-fading channel in a MIMO system, the channel
matrix is of the form of a block matrix. This paper proposes a method to
calculate the limit of the eigenvalue distribution of block matrices if the
size of the blocks tends to infinity. While it considers random matrices, it
takes an operator-valued free probability approach to achieve this goal. Using
this method, one derives a system of equations, which can be solved numerically
to compute the desired eigenvalue distribution. The paper initially tackles the
problem for square block matrices, then extends the solution to rectangular
block matrices. Finally, it deals with Wishart type block matrices. For two
special cases, the results of our approach are compared with results from
simulations. The first scenario investigates the limit eigenvalue distribution
of block Toeplitz matrices. The second scenario deals with the distribution of
Wishart type block matrices for a frequency selective slow-fading channel in a
MIMO system for two different cases of $n_R=n_T$ and $n_R=2n_T$. Using this
method, one may calculate the capacity and the Signal-to-Interference-and-Noise
Ratio in large MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610046</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610046</id><created>2006-10-09</created><updated>2007-03-21</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Streaming Maximum-Minimum Filter Using No More than Three Comparisons
  per Element</title><categories>cs.DS</categories><comments>to appear in Nordic Journal of Computing</comments><acm-class>F.2.1</acm-class><journal-ref>Daniel Lemire, Streaming Maximum-Minimum Filter Using No More than
  Three Comparisons per Element, Nordic Journal of Computing, Volume 13, Number
  4, pages 328-339, 2006</journal-ref><abstract>  The running maximum-minimum (max-min) filter computes the maxima and minima
over running windows of size w. This filter has numerous applications in signal
processing and time series analysis. We present an easy-to-implement online
algorithm requiring no more than 3 comparisons per element, in the worst case.
Comparatively, no algorithm is known to compute the running maximum (or
minimum) filter in 1.5 comparisons per element, in the worst case. Our
algorithm has reduced latency and memory usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610047</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610047</id><created>2006-10-09</created><authors><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Cuff</keyname><forenames>Paul</forenames></author><author><keyname>Van Roy</keyname><forenames>Benjamin</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Capacity of the Trapdoor Channel with Feedback</title><categories>cs.IT math.IT</categories><abstract>  We establish that the feedback capacity of the trapdoor channel is the
logarithm of the golden ratio and provide a simple communication scheme that
achieves capacity. As part of the analysis, we formulate a class of dynamic
programs that characterize capacities of unifilar finite-state channels. The
trapdoor channel is an instance that admits a simple analytic solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610048</id><created>2006-10-09</created><authors><author><keyname>Keller</keyname><forenames>Nathan</forenames></author><author><keyname>Miller</keyname><forenames>Stephen D.</forenames></author><author><keyname>Mironov</keyname><forenames>Ilya</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramarathnam</forenames></author></authors><title>MV3: A new word based stream cipher using rapid mixing and revolving
  buffers</title><categories>cs.CR cs.DM math.CO</categories><comments>27 pages, shortened version will appear in &quot;Topics in Cryptology -
  CT-RSA 2007&quot;</comments><abstract>  MV3 is a new word based stream cipher for encrypting long streams of data. A
direct adaptation of a byte based cipher such as RC4 into a 32- or 64-bit word
version will obviously need vast amounts of memory. This scaling issue
necessitates a look for new components and principles, as well as mathematical
analysis to justify their use. Our approach, like RC4's, is based on rapidly
mixing random walks on directed graphs (that is, walks which reach a random
state quickly, from any starting point). We begin with some well understood
walks, and then introduce nonlinearity in their steps in order to improve
security and show long term statistical correlations are negligible. To
minimize the short term correlations, as well as to deter attacks using
equations involving successive outputs, we provide a method for sequencing the
outputs derived from the walk using three revolving buffers. The cipher is fast
-- it runs at a speed of less than 5 cycles per byte on a Pentium IV processor.
A word based cipher needs to output more bits per step, which exposes more
correlations for attacks. Moreover we seek simplicity of construction and
transparent analysis. To meet these requirements, we use a larger state and
claim security corresponding to only a fraction of it. Our design is for an
adequately secure word-based cipher; our very preliminary estimate puts the
security close to exhaustive search for keys of size &lt; 256 bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610049</id><created>2006-10-10</created><authors><author><keyname>Morin</keyname><forenames>Edgar</forenames></author></authors><title>Restricted Complexity, General Complexity</title><categories>cs.CC nlin.AO</categories><comments>25 pages. Presented at the Colloquium &quot;Intelligence de la complexit'e
  : 'epist'emologie et pragmatique&quot;, Cerisy-La-Salle, France, June 26th, 2005.
  Translated from French by Carlos Gershenson</comments><abstract>  Why has the problematic of complexity appeared so late? And why would it be
justified?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610050</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610050</id><created>2006-10-10</created><updated>2006-11-21</updated><authors><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author></authors><title>The Mathematical Parallels Between Packet Switching and Information
  Transmission</title><categories>cs.IT cs.NI math.IT</categories><comments>21 pages, 25 figures, Submitted to IEEE Transactions on Information
  Theory</comments><abstract>  All communication networks comprise of transmission systems and switching
systems, even though they are usually treated as two separate issues.
Communication channels are generally disturbed by noise from various sources.
In circuit switched networks, reliable communication requires the
error-tolerant transmission of bits over noisy channels. In packet switched
networks, however, not only can bits be corrupted with noise, but resources
along connection paths are also subject to contention. Thus, quality of service
(QoS) is determined by buffer delays and packet losses. The theme of this paper
is to show that transmission noise and packet contention actually have similar
characteristics and can be tamed by comparable means to achieve reliable
communication, and a number of analogies between switching and transmission are
identified. The sampling theorem of bandlimited signals provides the
cornerstone of digital communication and signal processing. Recently, the
Birkhoff-von Neumann decomposition of traffic matrices has been widely applied
to packet switches. With respect to the complexity reduction of packet
switching, we show that the decomposition of a doubly stochastic traffic matrix
plays a similar role to that of the sampling theorem in digital transmission.
We conclude that packet switching systems are governed by mathematical laws
that are similar to those of digital transmission systems as envisioned by
Shannon in his seminal 1948 paper, A Mathematical Theory of Communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610051</id><created>2006-10-10</created><updated>2006-10-20</updated><authors><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Trebuchet</keyname><forenames>Philippe</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Strong bi-homogeneous B\'{e}zout theorem and its use in effective real
  algebraic geometry</title><categories>cs.SC</categories><proxy>ccsd inria-00105204</proxy><abstract>  Let f1, ..., fs be a polynomial family in Q[X1,..., Xn] (with s less than n)
of degree bounded by D. Suppose that f1, ..., fs generates a radical ideal, and
defines a smooth algebraic variety V. Consider a projection P. We prove that
the degree of the critical locus of P restricted to V is bounded by
D^s(D-1)^(n-s) times binomial of n and n-s. This result is obtained in two
steps. First the critical points of P restricted to V are characterized as
projections of the solutions of Lagrange's system for which a bi-homogeneous
structure is exhibited. Secondly we prove a bi-homogeneous B\'ezout Theorem,
which bounds the sum of the degrees of the equidimensional components of the
radical of an ideal generated by a bi-homogeneous polynomial family. This
result is improved when f1,..., fs is a regular sequence. Moreover, we use
Lagrange's system to design an algorithm computing at least one point in each
connected component of a smooth real algebraic set. This algorithm generalizes,
to the non equidimensional case, the one of Safey El Din and Schost. The
evaluation of the output size of this algorithm gives new upper bounds on the
first Betti number of a smooth real algebraic set. Finally, we estimate its
arithmetic complexity and prove that in the worst cases it is polynomial in n,
s, D^s(D-1)^(n-s) and the binomial of n and n-s, and the complexity of
evaluation of f1,..., fs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610052</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610052</id><created>2006-10-10</created><authors><author><keyname>Wang</keyname><forenames>Chih-Chun</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Princeton University</affiliation></author></authors><title>Finite-Dimensional Bounds on Zm and Binary LDPC Codes with Belief
  Propagation Decoders</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Theory</comments><abstract>  This paper focuses on finite-dimensional upper and lower bounds on decodable
thresholds of Zm and binary low-density parity-check (LDPC) codes, assuming
belief propagation decoding on memoryless channels. A concrete framework is
presented, admitting systematic searches for new bounds. Two noise measures are
considered: the Bhattacharyya noise parameter and the soft bit value for a
maximum a posteriori probability (MAP) decoder on the uncoded channel. For Zm
LDPC codes, an iterative m-dimensional bound is derived for
m-ary-input/symmetric-output channels, which gives a sufficient stability
condition for Zm LDPC codes and is complemented by a matched necessary
stability condition introduced herein. Applications to coded modulation and to
codes with non-equiprobable distributed codewords are also discussed.
  For binary codes, two new lower bounds are provided for symmetric channels,
including a two-dimensional iterative bound and a one-dimensional non-iterative
bound, the latter of which is the best known bound that is tight for binary
symmetric channels (BSCs), and is a strict improvement over the bound derived
by the channel degradation argument. By adopting the reverse channel
perspective, upper and lower bounds on the decodable Bhattacharyya noise
parameter are derived for non-symmetric channels, which coincides with the
existing bound for symmetric channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610053</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610053</id><created>2006-10-10</created><authors><author><keyname>Gzyl</keyname><forenames>Henryk</forenames></author><author><keyname>ter Horst</keyname><forenames>Enrique</forenames></author><author><keyname>Malone</keyname><forenames>Samuel</forenames></author></authors><title>Towards a Bayesian framework for option pricing</title><categories>cs.CE q-fin.PR</categories><abstract>  In this paper, we describe a general method for constructing the posterior
distribution of an option price. Our framework takes as inputs the prior
distributions of the parameters of the stochastic process followed by the
underlying, as well as the likelihood function implied by the observed price
history for the underlying. Our work extends that of Karolyi (1993) and
Darsinos and Satchell (2001), but with the crucial difference that the
likelihood function we use for inference is that which is directly implied by
the underlying, rather than imposed in an ad hoc manner via the introduction of
a function representing &quot;measurement error.&quot; As such, an important problem
still relevant for our method is that of model risk, and we address this issue
by describing how to perform a Bayesian averaging of parameter inferences based
on the different models considered using our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610054</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610054</id><created>2006-10-10</created><updated>2008-02-04</updated><authors><author><keyname>Dershowitz</keyname><forenames>Nachum</forenames></author><author><keyname>Harris</keyname><forenames>Mitchell A.</forenames></author><author><keyname>Huang</keyname><forenames>Guan-Shieng</forenames></author></authors><title>Enumeration Problems Related to Ground Horn Theories</title><categories>cs.LO cs.DM</categories><comments>4 pages, before journal submission</comments><acm-class>F.4.1</acm-class><abstract>  We investigate the enumeration of varieties of boolean theories related to
Horn clauses. We describe a number of combinatorial equivalences among
different characterizations and calculate the number of different theories in
$n$ variables for slightly different characterizations. The method of counting
is via counting models using a satisfiability checker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610055</id><created>2006-10-11</created><authors><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Extending the Calculus of Constructions with Tarski's fix-point theorem</title><categories>cs.LO</categories><proxy>ccsd inria-00105529</proxy><abstract>  We propose to use Tarski's least fixpoint theorem as a basis to define
recursive functions in the calculus of inductive constructions. This widens the
class of functions that can be modeled in type-theory based theorem proving
tool to potentially non-terminating functions. This is only possible if we
extend the logical framework by adding the axioms that correspond to classical
logic. We claim that the extended framework makes it possible to reason about
terminating and non-terminating computations and we show that common facilities
of the calculus of inductive construction, like program extraction can be
extended to also handle the new functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610056</id><created>2006-10-11</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Constructing experimental indicators for Open Access documents</title><categories>cs.DL</categories><comments>9 pages, 3 figures</comments><abstract>  The ongoing paradigm change in the scholarly publication system ('science is
turning to e-science') makes it necessary to construct alternative evaluation
criteria/metrics which appropriately take into account the unique
characteristics of electronic publications and other research output in digital
formats. Today, major parts of scholarly Open Access (OA) publications and the
self-archiving area are not well covered in the traditional citation and
indexing databases. The growing share and importance of freely accessible
research output demands new approaches/metrics for measuring and for evaluating
of these new types of scientific publications. In this paper we propose a
simple quantitative method which establishes indicators by measuring the
access/download pattern of OA documents and other web entities of a single web
server. The experimental indicators (search engine, backlink and direct access
indicator) are constructed based on standard local web usage data. This new
type of web-based indicator is developed to model the specific demand for
better study/evaluation of the accessibility, visibility and interlinking of
open accessible documents. We conclude that e-science will need new stable
e-indicators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610057</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610057</id><created>2006-10-11</created><authors><author><keyname>Loidreau</keyname><forenames>P.</forenames></author></authors><title>Properties of codes in rank metric</title><categories>cs.DM cs.IT math.IT</categories><comments>18 pages, 1 figure</comments><abstract>  We study properties of rank metric and codes in rank metric over finite
fields. We show that in rank metric perfect codes do not exist. We derive an
existence bound that is the equivalent of the Gilbert--Varshamov bound in
Hamming metric. We study the asymptotic behavior of the minimum rank distance
of codes satisfying GV. We derive the probability distribution of minimum rank
distance for random and random $\F{q}$-linear codes. We give an asymptotic
equivalent of their average minimum rank distance and show that random
$\F{q}$-linear codes are on GV bound for rank metric.
  We show that the covering density of optimum codes whose codewords can be
seen as square matrices is lower bounded by a function depending only on the
error-correcting capability of the codes. We show that there are quasi-perfect
codes in rank metric over fields of characteristic 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610058</id><created>2006-10-11</created><authors><author><keyname>Smirnov</keyname><forenames>A. V.</forenames></author><author><keyname>Levashova</keyname><forenames>T. V.</forenames></author><author><keyname>Pashkin</keyname><forenames>M. P.</forenames></author><author><keyname>Shilov</keyname><forenames>N. G.</forenames></author><author><keyname>Krizhanovsky</keyname><forenames>A. A.</forenames></author><author><keyname>Kashevnik</keyname><forenames>A. M.</forenames></author><author><keyname>Komarova</keyname><forenames>A. S.</forenames></author></authors><title>Context-sensitive access to e-document corpus</title><categories>cs.IR</categories><comments>9 pages, 1 figure, short version of this paper was presented at the
  International Conference Corpus Linguistics 2006. October 10-14, St.
  Petersburg, Russia</comments><acm-class>H.3.1; H.3.3; H.4.3; G.2.2</acm-class><abstract>  The methodology of context-sensitive access to e-documents considers context
as a problem model based on the knowledge extracted from the application
domain, and presented in the form of application ontology. Efficient access to
an information in the text form is needed. Wiki resources as a modern text
format provides huge number of text in a semi formalized structure. At the
first stage of the methodology, documents are indexed against the ontology
representing macro-situation. The indexing method uses a topic tree as a middle
layer between documents and the application ontology. At the second stage
documents relevant to the current situation (the abstract and operational
contexts) are identified and sorted by degree of relevance. Abstract context is
a problem-oriented ontology-based model. Operational context is an
instantiation of the abstract context with data provided by the information
sources. The following parts of the methodology are described: (i) metrics for
measuring similarity of e-documents to ontology, (ii) a document index storing
results of indexing of e-documents against the ontology; (iii) a method for
identification of relevant e-documents based on semantic similarity measures.
Wikipedia (wiki resource) is used as a corpus of e-documents for approach
evaluation in a case study. Text categorization, the presence of metadata, and
an existence of a lot of articles related to different topics characterize the
corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610059</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610059</id><created>2006-10-11</created><updated>2008-03-27</updated><authors><author><keyname>Jonchery</keyname><forenames>Claire</forenames><affiliation>MAP5</affiliation></author><author><keyname>Dibos</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LAGA, IG</affiliation></author><author><keyname>Koepfler</keyname><forenames>Georges</forenames><affiliation>MAP5</affiliation></author></authors><title>Camera motion estimation through planar deformation determination</title><categories>cs.CV</categories><comments>21 pages, version modifi\'ee accept\'e le 20 mars 2008</comments><proxy>ccsd ccsd-00104903</proxy><journal-ref>Journal of Mathematical Imaging and Vision 32, 1 (2008) 73-87</journal-ref><doi>10.1007/s10851-008-0086-1</doi><abstract>  In this paper, we propose a global method for estimating the motion of a
camera which films a static scene. Our approach is direct, fast and robust, and
deals with adjacent frames of a sequence. It is based on a quadratic
approximation of the deformation between two images, in the case of a scene
with constant depth in the camera coordinate system. This condition is very
restrictive but we show that provided translation and depth inverse variations
are small enough, the error on optical flow involved by the approximation of
depths by a constant is small. In this context, we propose a new model of
camera motion, that allows to separate the image deformation in a similarity
and a ``purely'' projective application, due to change of optical axis
direction. This model leads to a quadratic approximation of image deformation
that we estimate with an M-estimator; we can immediatly deduce camera motion
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610060</id><created>2006-10-11</created><authors><author><keyname>Levene</keyname><forenames>Mark</forenames></author><author><keyname>Bar-Ilan</keyname><forenames>Judit</forenames></author></authors><title>Comparing Typical Opening Move Choices Made by Humans and Chess Engines</title><categories>cs.AI</categories><comments>12 pages, 1 figure, 6 tables</comments><acm-class>I.2.0</acm-class><abstract>  The opening book is an important component of a chess engine, and thus
computer chess programmers have been developing automated methods to improve
the quality of their books. For chess, which has a very rich opening theory,
large databases of high-quality games can be used as the basis of an opening
book, from which statistics relating to move choices from given positions can
be collected. In order to find out whether the opening books used by modern
chess engines in machine versus machine competitions are ``comparable'' to
those used by chess players in human versus human competitions, we carried out
analysis on 26 test positions using statistics from two opening books one
compiled from humans' games and the other from machines' games. Our analysis
using several nonparametric measures, shows that, overall, there is a strong
association between humans' and machines' choices of opening moves when using a
book to guide their choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610061</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610061</id><created>2006-10-11</created><authors><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author><author><keyname>Michel</keyname><forenames>Thomas</forenames></author></authors><title>The Delay-Limited Capacity Region of OFDM Broadcast Channels</title><categories>cs.IT math.IT</categories><abstract>  In this work, the delay limited capacity (DLC) of orthogonal frequency
division multiplexing (OFDM) systems is investigated. The analysis is organized
into two parts. In the first part, the impact of system parameters on the OFDM
DLC is analyzed in a general setting. The main results are that under weak
assumptions the maximum achievable single user DLC is almost independent of the
distribution of the path attenuations in the low signal-to-noise (SNR) region
but depends strongly on the delay spread. In the high SNR region the roles are
exchanged. Here, the impact of delay spread is negligible while the impact of
the distribution becomes dominant. The relevant asymptotic quantities are
derived without employing simplifying assumptions on the OFDM correlation
structure. Moreover, for both cases it is shown that the DLC is maximized if
the total channel energy is uniformly spread, i.e. the power delay profile is
uniform. It is worth pointing out that since universal bounds are obtained the
results can also be used for other classes of parallel channels with block
fading characteristic. The second part extends the setting to the broadcast
channel and studies the corresponding OFDM DLC BC region. An algorithm for
computing the OFDM BC DLC region is presented. To derive simple but smart
resource allocation strategies, the principle of rate water-filling employing
order statistics is introduced. This yields analytical lower bounds on the OFDM
DLC region based on orthogonal frequency division multiple access (OFDMA) and
ordinal channel state information (CSI). Finally, the schemes are compared to
an algorithm using full CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610062</id><created>2006-10-11</created><authors><author><keyname>Blanqui</keyname><forenames>Frederic</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A type-based termination criterion for dependently-typed higher-order
  rewrite systems</title><categories>cs.LO cs.PL</categories><comments>Colloque avec actes et comit\'{e} de lecture. internationale</comments><proxy>ccsd inria-00100254</proxy><journal-ref>Dans 15th International Conference on Rewriting Techniques and
  Applications - RTA'04 (2004) 15 p</journal-ref><abstract>  Several authors devised type-based termination criteria for ML-like languages
allowing non-structural recursive calls. We extend these works to general
rewriting and dependent types, hence providing a powerful termination criterion
for the combination of rewriting and beta-reduction in the Calculus of
Constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610063</identifier>
 <datestamp>2008-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610063</id><created>2006-10-11</created><updated>2008-05-27</updated><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LRI</affiliation></author><author><keyname>Jouannaud</keyname><forenames>Jean-Pierre</forenames><affiliation>LRI</affiliation></author><author><keyname>Okada</keyname><forenames>Mitsuhiro</forenames></author></authors><title>The Calculus of Algebraic Constructions</title><categories>cs.LO</categories><proxy>ccsd inria-00105545</proxy><journal-ref>Dans Rewriting Techniques and Applications, 10th International
  Conference, RTA-99 1631 (1999)</journal-ref><abstract>  This paper is concerned with the foundations of the Calculus of Algebraic
Constructions (CAC), an extension of the Calculus of Constructions by inductive
data types. CAC generalizes inductive types equipped with higher-order
primitive recursion, by providing definitions of functions by pattern-matching
which capture recursor definitions for arbitrary non-dependent and
non-polymorphic inductive types satisfying a strictly positivity condition. CAC
also generalizes the first-order framework of abstract data types by providing
dependent types and higher-order rewrite rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610064</id><created>2006-10-11</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LRI</affiliation></author></authors><title>Termination and Confluence of Higher-Order Rewrite Systems</title><categories>cs.LO</categories><proxy>ccsd inria-00105556</proxy><journal-ref>Dans Rewriting Techniques and Applications, 11th International
  Conference, RTA 2000 1833 (2000)</journal-ref><abstract>  In the last twenty years, several approaches to higher-order rewriting have
been proposed, among which Klop's Combinatory Rewrite Systems (CRSs), Nipkow's
Higher-order Rewrite Systems (HRSs) and Jouannaud and Okada's higher-order
algebraic specification languages, of which only the last one considers typed
terms. The later approach has been extended by Jouannaud, Okada and the present
author into Inductive Data Type Systems (IDTSs). In this paper, we extend IDTSs
with the CRS higher-order pattern-matching mechanism, resulting in simply-typed
CRSs. Then, we show how the termination criterion developed for IDTSs with
first-order pattern-matching, called the General Schema, can be extended so as
to prove the strong normalization of IDTSs with higher-order pattern-matching.
Next, we compare the unified approach with HRSs. We first prove that the
extended General Schema can also be applied to HRSs. Second, we show how
Nipkow's higher-order critical pair analysis technique for proving local
confluence can be applied to IDTSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610065</id><created>2006-10-11</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LRI</affiliation></author></authors><title>Definitions by Rewriting in the Calculus of Constructions</title><categories>cs.LO</categories><comments>Best student paper (Kleene Award)</comments><proxy>ccsd inria-00105568</proxy><journal-ref>Dans 16th Annual IEEE Symposium on Logic in Computer Science
  (2001)</journal-ref><abstract>  The main novelty of this paper is to consider an extension of the Calculus of
Constructions where predicates can be defined with a general form of rewrite
rules. We prove the strong normalization of the reduction relation generated by
the beta-rule and the user-defined rules under some general syntactic
conditions including confluence. As examples, we show that two important
systems satisfy these conditions: a sub-system of the Calculus of Inductive
Constructions which is the basis of the proof assistant Coq, and the Natural
Deduction Modulo a large class of equational theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610066</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610066</id><created>2006-10-11</created><updated>2013-09-16</updated><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LRI</affiliation></author><author><keyname>Jouannaud</keyname><forenames>Jean-Pierre</forenames><affiliation>LRI</affiliation></author><author><keyname>Okada</keyname><forenames>Mitsuhiro</forenames></author></authors><title>Inductive-data-type Systems</title><categories>cs.LO</categories><comments>Theoretical Computer Science (2002)</comments><proxy>ccsd</proxy><doi>10.1016/S0304-3975(00)00347-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous work (&quot;Abstract Data Type Systems&quot;, TCS 173(2), 1997), the last
two authors presented a combined language made of a (strongly normalizing)
algebraic rewrite system and a typed lambda-calculus enriched by
pattern-matching definitions following a certain format, called the &quot;General
Schema&quot;, which generalizes the usual recursor definitions for natural numbers
and similar &quot;basic inductive types&quot;. This combined language was shown to be
strongly normalizing. The purpose of this paper is to reformulate and extend
the General Schema in order to make it easily extensible, to capture a more
general class of inductive types, called &quot;strictly positive&quot;, and to ease the
strong normalization proof of the resulting system. This result provides a
computation model for the combination of an algebraic specification language
based on abstract data types and of a strongly typed functional language with
strictly positive inductive types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610067</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610067</id><created>2006-10-11</created><updated>2006-10-17</updated><authors><author><keyname>Saba</keyname><forenames>Walid S.</forenames></author></authors><title>Language, logic and ontology: uncovering the structure of commonsense
  knowledge</title><categories>cs.AI math.LO</categories><comments>30 pages, 7 figures, 3 tables under revision for a journal submission</comments><abstract>  The purpose of this paper is twofold: (i) we argue that the structure of
commonsense knowledge must be discovered, rather than invented; and (ii) we
argue that natural language, which is the best known theory of our (shared)
commonsense knowledge, should itself be used as a guide to discovering the
structure of commonsense knowledge. In addition to suggesting a systematic
method to the discovery of the structure of commonsense knowledge, the method
we propose seems to also provide an explanation for a number of phenomena in
natural language, such as metaphor, intensionality, and the semantics of
nominal compounds. Admittedly, our ultimate goal is quite ambitious, and it is
no less than the systematic 'discovery' of a well-typed ontology of commonsense
knowledge, and the subsequent formulation of the long-awaited goal of a meaning
algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610068</id><created>2006-10-11</created><updated>2007-02-22</updated><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LRI</affiliation></author></authors><title>Type theory and rewriting</title><categories>cs.LO</categories><comments>English version of my PhD thesis</comments><proxy>ccsd inria-00105525</proxy><abstract>  We study the properties, in particular termination, of dependent types
systems for lambda calculus and rewriting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610069</id><created>2006-10-11</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>An Isabelle formalization of protocol-independent secrecy with an
  application to e-commerce</title><categories>cs.LO</categories><proxy>ccsd inria-00105606</proxy><abstract>  A protocol-independent secrecy theorem is established and applied to several
non-trivial protocols. In particular, it is applied to protocols proposed for
protecting the computation results of free-roaming mobile agents doing
comparison shopping. All the results presented here have been formally proved
in Isabelle by building on Larry Paulson's inductive approach. This therefore
provides a library of general theorems that can be applied to other protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610070</id><created>2006-10-11</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LIX</affiliation></author></authors><title>Inductive types in the Calculus of Algebraic Constructions</title><categories>cs.LO</categories><proxy>ccsd inria-00105617</proxy><journal-ref>Dans Typed Lambda Calculi and Applications, 6th International
  Conference, TLCA 2003 2701 (2003)</journal-ref><abstract>  In a previous work, we proved that almost all of the Calculus of Inductive
Constructions (CIC), which is the basis of the proof assistant Coq, can be seen
as a Calculus of Algebraic Constructions (CAC), an extension of the Calculus of
Constructions with functions and predicates defined by higher-order rewrite
rules. In this paper, we not only prove that CIC as a whole can be seen as a
CAC, but also that it can be extended with non-free constructors,
pattern-matching on defined symbols, non-strictly positive types and
inductive-recursive types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610071</id><created>2006-10-11</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LIX</affiliation></author></authors><title>Rewriting modulo in Deduction modulo</title><categories>cs.LO</categories><proxy>ccsd inria-00105625</proxy><journal-ref>Dans Rewriting Techniques and Applications, 14th International
  Conference, RTA 2003 2706 (2003)</journal-ref><abstract>  We study the termination of rewriting modulo a set of equations in the
Calculus of Algebraic Constructions, an extension of the Calculus of
Constructions with functions and predicates defined by higher-order rewrite
rules. In a previous work, we defined general syntactic conditions based on the
notion of computable closure for ensuring the termination of the combination of
rewriting and beta-reduction. Here, we show that this result is preserved when
considering rewriting modulo a set of equations if the equivalence classes
generated by these equations are finite, the equations are linear and satisfy
general syntactic conditions also based on the notion of computable closure.
This includes equations like associativity and commutativity, and provides an
original treatment of termination modulo equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610072</id><created>2006-10-12</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA, LIX</affiliation></author></authors><title>Definitions by rewriting in the Calculus of Constructions</title><categories>cs.LO</categories><comments>Journal version of LICS'01</comments><proxy>ccsd inria-00105648</proxy><report-no>Journal version of LICS'01</report-no><journal-ref>Mathematical Structures in Computer Science 15, 1 (2005) 37-92</journal-ref><doi>10.1017/S0960129504004426</doi><abstract>  This paper presents general syntactic conditions ensuring the strong
normalization and the logical consistency of the Calculus of Algebraic
Constructions, an extension of the Calculus of Constructions with functions and
predicates defined by higher-order rewrite rules. On the one hand, the Calculus
of Constructions is a powerful type system in which one can formalize the
propositions and natural deduction proofs of higher-order logic. On the other
hand, rewriting is a simple and powerful computation paradigm. The combination
of both allows, among other things, to develop formal proofs with a reduced
size and more automation compared with more traditional proof assistants. The
main novelty is to consider a general form of rewriting at the predicate-level
which generalizes the strong elimination of the Calculus of Inductive
Constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610073</id><created>2006-10-12</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Inductive types in the Calculus of Algebraic Constructions</title><categories>cs.LO</categories><comments>Journal version of TLCA'03</comments><proxy>ccsd inria-00105655</proxy><report-no>Journal version of TLCA'03</report-no><journal-ref>Fundamenta Informaticae 65, 1-2 (2005) 61-86</journal-ref><abstract>  In a previous work, we proved that an important part of the Calculus of
Inductive Constructions (CIC), the basis of the Coq proof assistant, can be
seen as a Calculus of Algebraic Constructions (CAC), an extension of the
Calculus of Constructions with functions and predicates defined by higher-order
rewrite rules. In this paper, we prove that almost all CIC can be seen as a
CAC, and that it can be further extended with non-strictly positive types and
inductive-recursive types together with non-free constructors and
pattern-matching on defined symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610074</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610074</id><created>2006-10-12</created><updated>2006-10-12</updated><authors><author><keyname>Schmidt</keyname><forenames>Georg</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir R.</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author></authors><title>Collaborative Decoding of Interleaved Reed-Solomon Codes and
  Concatenated Code Designs</title><categories>cs.IT math.IT</categories><comments>20 pages, 7 figures</comments><abstract>  Interleaved Reed-Solomon codes are applied in numerous data processing, data
transmission, and data storage systems. They are generated by interleaving
several codewords of ordinary Reed-Solomon codes. Usually, these codewords are
decoded independently by classical algebraic decoding methods. However, by
collaborative algebraic decoding approaches, such interleaved schemes allow the
correction of error patterns beyond half the minimum distance, provided that
the errors in the received signal occur in bursts. In this work, collaborative
decoding of interleaved Reed-Solomon codes by multi-sequence shift-register
synthesis is considered and analyzed. Based on the framework of interleaved
Reed-Solomon codes, concatenated code designs are investigated, which are
obtained by interleaving several Reed-Solomon codes, and concatenating them
with an inner block code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610075</id><created>2006-10-12</created><updated>2006-10-23</updated><authors><author><keyname>Aerts</keyname><forenames>Diederik</forenames></author><author><keyname>Czachor</keyname><forenames>Marek</forenames></author><author><keyname>De Moor</keyname><forenames>Bart</forenames></author></authors><title>On Geometric Algebra representation of Binary Spatter Codes</title><categories>cs.AI quant-ph</categories><comments>preliminary version</comments><abstract>  Kanerva's Binary Spatter Codes are reformulated in terms of geometric
algebra. The key ingredient of the construction is the representation of XOR
binding in terms of geometric product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610076</id><created>2006-10-12</created><updated>2006-10-13</updated><authors><author><keyname>Valdivia-Granda</keyname><forenames>Willy</forenames></author><author><keyname>Perrizo</keyname><forenames>William</forenames></author><author><keyname>Deckard</keyname><forenames>Edward</forenames></author><author><keyname>Larson</keyname><forenames>Francis</forenames></author></authors><title>Peano Count Trees (P-Trees) and Rule Association Mining for Gene
  Expression Profiling of Microarray Data</title><categories>cs.DS cs.IR q-bio.MN</categories><journal-ref>2002 International Conference in Bioinformatics. Bangkok, Thailand</journal-ref><abstract>  The greatest challenge in maximizing the use of gene expression data is to
develop new computational tools capable of interconnecting and interpreting the
results from different organisms and experimental settings. We propose an
integrative and comprehensive approach including a super-chip containing data
from microarray experiments collected on different species subjected to hypoxic
and anoxic stress. A data mining technology called Peano count tree (P-trees)
is used to represent genomic data in multidimensions. Each microarray spot is
presented as a pixel with its corresponding red/green intensity feature bands.
Each bad is stored separately in a reorganized 8-separate (bSQ) file format.
Each bSQ is converted to a quadrant base tree structure (P-tree) from which a
superchip is represented as expression P-trees (EP-trees) and repression
P-trees (RP-trees). The use of association rule mining is proposed to derived
to meanigingfully organize signal transduction pathways taking in consideration
evolutionary considerations. We argue that the genetic constitution of an
organism (K) can be represented by the total number of genes belonging to two
groups. The group X constitutes genes (X1,Xn) and they can be represented as 1
or 0 depending on whether the gene was expressed or not. The second group of Y
genes (Y1,Yn) is expressed at different levels. These genes have a very high
repression, high expression, very repressed or highly repressed. However, many
genes of the group Y are specie specific and modulated by the products and
combinations of genes of the group X. In this paper, we introduce the dSQ and
P-tree technology; the biological implications of association rule mining using
X and Y gene groups and some advances in the integration of this information
using the BRAIN architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610077</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610077</id><created>2006-10-12</created><authors><author><keyname>Ravindran</keyname><forenames>Niranjay</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>MIMO Broadcast Channels with Block Diagonalization and Finite Rate
  Feedback</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures, submitted to International Conference on
  Acoustics, Speech, and Signal Processing (ICASSP) 2007</comments><acm-class>H.1.1</acm-class><abstract>  Block diagonalization is a linear precoding technique for the multiple
antenna broadcast (downlink) channel that involves transmission of multiple
data streams to each receiver such that no multi-user interference is
experienced at any of the receivers. This low-complexity scheme operates only a
few dB away from capacity but does require very accurate channel knowledge at
the transmitter, which can be very difficult to obtain in fading scenarios. We
consider a limited feedback system where each receiver knows its channel
perfectly, but the transmitter is only provided with a finite number of channel
feedback bits from each receiver. Using a random vector quantization argument,
we quantify the throughput loss due to imperfect channel knowledge as a
function of the feedback level. The quality of channel knowledge must improve
proportional to the SNR in order to prevent interference-limitations, and we
show that scaling the number of feedback bits linearly with the system SNR is
sufficient to maintain a bounded rate loss. Finally, we investigate a simple
scalar quantization scheme that is seen to achieve the same scaling behavior as
vector quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610078</id><created>2006-10-13</created><updated>2007-05-22</updated><authors><author><keyname>Abdesslem</keyname><forenames>Fehmi Ben</forenames></author><author><keyname>Iannone</keyname><forenames>Luigi</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author><author><keyname>Obraczka</keyname><forenames>Katia</forenames></author><author><keyname>Solis</keyname><forenames>Ignacio</forenames></author><author><keyname>Fdida</keyname><forenames>Serge</forenames></author></authors><title>Rapid Prototyping over IEEE 802.11</title><categories>cs.NI</categories><comments>Changed content. 12 pages</comments><abstract>  This paper introduces Prawn, a tool for prototyping communication protocols
over IEEE 802.11 networks. Prawn allows researchers to conduct both functional
assessment and performance evaluation as an inherent part of the protocol
design process. Since Prawn runs on real IEEE 802.11 nodes, prototypes can be
evaluated and adjusted under realistic conditions. Once the prototype has been
extensively tested and thoroughly validated, and its functional design tuned
accordingly, it is then ready for implementation. Prawn facilitates prototype
development by providing: (i) a set of building blocks that implement common
functions needed by a wide range of wireless protocols (e.g., neighbor
discovery, link quality assessment, message transmission and reception), and
(ii) an API that allows protocol designers to access Prawn primitives. We show
through a number of case studies how Prawn supports prototyping as part of
protocol design and, as a result of enabling deployment and testing under
real-world scenarios, how Prawn provides useful feedback on protocol operation
and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610079</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610079</id><created>2006-10-12</created><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>An Enhanced Covering Lemma for Multiterminal Source Coding</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. 2006 IEEE Information Theory Workshop, October
  22-26, 2006, Chengdu, China. (5 pages)</comments><abstract>  An enhanced covering lemma for a Markov chain is proved in this paper, and
then the distributed source coding problem of correlated general sources with
one average distortion criterion under fixed-length coding is investigated.
Based on the enhanced lemma, a sufficient and necessary condition for
determining the achievability of rate-distortion triples is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610080</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610080</id><created>2006-10-13</created><updated>2007-06-22</updated><authors><author><keyname>Roux</keyname><forenames>St&#xe9;phane Le</forenames></author><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Computable Closed Euclidean Subsets with and without Computable Points</title><categories>cs.LO math.LO</categories><comments>Included helpful remarks of J.Miller and of X.Zheng</comments><acm-class>F.4.1</acm-class><abstract>  The empty set of course contains no computable point. On the other hand,
surprising results due to Zaslavskii, Tseitin, Kreisel, and Lacombe assert the
existence of NON-empty co-r.e. closed sets devoid of computable points: sets
which are `large' in the sense of positive Lebesgue measure. We observe that a
certain size is in fact necessary: every non-empty co-r.e. closed real set
without computable points has continuum cardinality.
  This leads us to investigate for various classes of computable real subsets
whether they necessarily contain a (not necessarily effectively findable)
computable point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610081</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610081</id><created>2006-10-13</created><updated>2006-11-03</updated><authors><author><keyname>Birkedal</keyname><forenames>Lars</forenames></author><author><keyname>Torp-Smith</keyname><forenames>Noah</forenames></author><author><keyname>Yang</keyname><forenames>Hongseok</forenames></author></authors><title>Semantics of Separation-Logic Typing and Higher-order Frame Rules
  for&lt;br&gt; Algol-like Languages</title><categories>cs.LO</categories><acm-class>F.3; D.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 5 (November
  3, 2006) lmcs:1079</journal-ref><doi>10.2168/LMCS-2(5:1)2006</doi><abstract>  We show how to give a coherent semantics to programs that are well-specified
in a version of separation logic for a language with higher types: idealized
algol extended with heaps (but with immutable stack variables). In particular,
we provide simple sound rules for deriving higher-order frame rules, allowing
for local reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610082</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610082</id><created>2006-10-13</created><authors><author><keyname>Stepanov</keyname><forenames>Sander</forenames></author><author><keyname>Hadar</keyname><forenames>Ofer</forenames></author></authors><title>Theoretical analysis of network cranback protocols performance</title><categories>cs.IT math.IT</categories><abstract>  Suggested the decision of the network cranback protocols performance
analyzing problem from Eyal Felstine, Reuven Cohen and Ofer Hadar, &quot; Crankback
Prediction in Hierarchical ATM networks&quot;, Journal of Network and Systems
Management, Vol. 10, No. 3, September 2002. It show that the false alarm
probability and probability of successful way crossing can be calculated. The
main optimization equations are developed for cranback protocol parameters by
using analytical expressions for statistical protocol characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610083</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610083</id><created>2006-10-13</created><authors><author><keyname>Stepanov</keyname><forenames>Sander</forenames></author></authors><title>Estimation of the traffic in the binary channel for data networks</title><categories>cs.IT math.IT</categories><abstract>  It is impossible to provide an effective utilization of communication
networks without the analysis of the quantitative characteristics of the
traffic in real time. The constant supervision of all channels of the data
practically is impracticable because requires transfer of the significant
additional information on a network and large resources expenses for devices of
the control. Thus, the task on traffic estimation with small expenses in real
time is the urgent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610084</id><created>2006-10-13</created><authors><author><keyname>Claveirole</keyname><forenames>Thomas</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author><author><keyname>Abdalla</keyname><forenames>Michel</forenames></author><author><keyname>Viniotis</keyname><forenames>Yannis</forenames></author></authors><title>Share and Disperse: How to Resist Against Aggregator Compromises in
  Sensor Networks</title><categories>cs.NI cs.CR</categories><comments>9 pages, 3 figures, 2 tables</comments><abstract>  A common approach to overcome the limited nature of sensor networks is to
aggregate data at intermediate nodes. A challenging issue in this context is to
guarantee end-to-end security mainly because sensor networks are extremely
vulnerable to node compromises. In order to secure data aggregation, in this
paper we propose three schemes that rely on multipath routing. The first one
guarantees data confidentiality through secret sharing, while the second and
third ones provide data availability through information dispersal. Based on
qualitative analysis and implementation, we show that, by applying these
schemes, a sensor network can achieve data confidentiality, authenticity, and
protection against denial of service attacks even in the presence of multiple
compromised nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610085</id><created>2006-10-13</created><authors><author><keyname>Wang</keyname><forenames>Farn</forenames></author></authors><title>Symbolic Simulation-Checking of Dense-Time Systems</title><categories>cs.LO cs.SE</categories><comments>16 pages, 1 figure</comments><acm-class>D.3.1; F.1.1; F.4.3</acm-class><abstract>  Intuitively, an (implementation) automata is simulated by a (specification)
automata if every externally observable transition by the implementation
automata can also be made by the specification automata. In this work, we
present a symbolic algorithm for the simulation-checking of timed automatas. We
first present a simulation-checking procedure that operates on state spaces,
representable with convex polyhedra, of timed automatas. We then present
techniques to represent those intermediate result convex polyhedra with zones
and make the procedure an algorithm. We then discuss how to handle Zeno states
in the implementation automata. Finally, we have endeavored to realize the
algorithm and report the performance of our algorithm in the experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610086</id><created>2006-10-13</created><updated>2006-11-17</updated><authors><author><keyname>Fenner</keyname><forenames>S. A.</forenames></author><author><keyname>Zhang</keyname><forenames>Y.</forenames></author></authors><title>The central nature of the Hidden Subgroup problem</title><categories>cs.CC quant-ph</categories><comments>12 pages, no figures. Corrected Proposition 3.3 and added discussion
  relating it to results of Childs and van Dam (quant-ph/0507190). Adjusted
  Definition 2.2 and the proof of Proposition 3.3 to fix a minor bug. Other
  minor corrections/clarifications. Updated references</comments><abstract>  We show that several problems that figure prominently in quantum computing,
including Hidden Coset, Hidden Shift, and Orbit Coset, are equivalent or
reducible to Hidden Subgroup for a large variety of groups. We also show that,
over permutation groups, the decision version and search version of Hidden
Subgroup are polynomial-time equivalent. For Hidden Subgroup over dihedral
groups, such an equivalence can be obtained if the order of the group is
smooth. Finally, we give nonadaptive program checkers for Hidden Subgroup and
its decision version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610087</id><created>2006-10-13</created><authors><author><keyname>Khoury</keyname><forenames>Joud</forenames></author><author><keyname>Jerez</keyname><forenames>Henry N</forenames></author><author><keyname>Nehme-Antoun</keyname><forenames>Nicolas</forenames></author><author><keyname>Abdallah</keyname><forenames>Chaouki</forenames></author></authors><title>An Application of the Mobile Transient Internet Architecture to IP
  Mobility and Inter-Operability</title><categories>cs.NI</categories><acm-class>C.2.6</acm-class><abstract>  We introduce an application of a mobile transient network architecture on top
of the current Internet. This paper is an application extension to a conceptual
mobile network architecture. It attempts to specifically reinforce some of the
powerful notions exposed by the architecture from an application perspective.
Of these notions, we explore the network expansion layer, an overlay of
components and services, that enables a persistent identification network and
other required services. The overlay abstraction introduces several benefits of
which mobility and communication across heterogenous network structures are of
interest to this paper. We present implementations of several components and
protocols including gateways, Agents and the Open Device Access Protocol. Our
present identification network implementation exploits the current
implementation of the Handle System through the use of distributed, global and
persistent identifiers called handles. Handles are used to identify and locate
devices and services abstracting any physical location or network association
from the communicating ends. A communication framework is finally demonstrated
that would allow for mobile devices on the public Internet to have persistent
identifiers and thus be persistently accessible either directly or indirectly.
This application expands IP inter-operability beyond its current boundaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610088</id><created>2006-10-14</created><authors><author><keyname>Sparavigna</keyname><forenames>A.</forenames></author><author><keyname>Montrucchio</keyname><forenames>B.</forenames></author></authors><title>Vector field visualization with streamlines</title><categories>cs.GR</categories><comments>9 pges, 7 figures</comments><abstract>  We have recently developed an algorithm for vector field visualization with
oriented streamlines, able to depict the flow directions everywhere in a dense
vector field and the sense of the local orientations. The algorithm has useful
applications in the visualization of the director field in nematic liquid
crystals. Here we propose an improvement of the algorithm able to enhance the
visualization of the local magnitude of the field. This new approach of the
algorithm is compared with the same procedure applied to the Line Integral
Convolution (LIC) visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610089</id><created>2006-10-14</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Zwolinski</keyname><forenames>Mark</forenames></author></authors><title>Reversible Logic to Cryptographic Hardware: A New Paradigm</title><categories>cs.CR</categories><comments>Published in the proceedings of the The 49th IEEE International
  Midwest Symposium on Circuits and Systems (MWSCAS 2006), Puerto Rico, August
  2006. Nominated for the Student Paper Award</comments><abstract>  Differential Power Analysis (DPA) presents a major challenge to
mathematically-secure cryptographic protocols. Attackers can break the
encryption by measuring the energy consumed in the working digital circuit. To
prevent this type of attack, this paper proposes the use of reversible logic
for designing the ALU of a cryptosystem. Ideally, reversible circuits dissipate
zero energy. Thus, it would be of great significance to apply reversible logic
to designing secure cryptosystems. As far as is known, this is the first
attempt to apply reversible logic to developing secure cryptosystems. In a
prototype of a reversible ALU for a crypto-processor, reversible designs of
adders and Montgomery multipliers are presented. The reversible designs of a
carry propagate adder, four-to-two and five-to-two carry save adders are
presented using a reversible TSG gate. One of the important properties of the
TSG gate is that it can work singly as a reversible full adder. In order to
design the reversible Montgomery multiplier, novel reversible sequential
circuits are also proposed which are integrated with the proposed adders to
design a reversible modulo multiplier. It is intended that this paper will
provide a starting point for developing cryptosystems secure against DPA
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610090</id><created>2006-10-14</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Arabnia</keyname><forenames>Hamid R.</forenames></author><author><keyname>Vinod</keyname><forenames>A. P</forenames></author></authors><title>Combined Integer and Floating Point Multiplication Architecture(CIFM)
  for FPGAs and Its Reversible Logic Implementation</title><categories>cs.AR</categories><comments>Published in the proceedings of the The 49th IEEE International
  Midwest Symposium on Circuits and Systems (MWSCAS 2006), Puerto Rico, August
  2006. Nominated for the Student Paper Award(12 papers are nominated for
  Student paper Award among all submissions)</comments><abstract>  In this paper, the authors propose the idea of a combined integer and
floating point multiplier(CIFM) for FPGAs. The authors propose the replacement
of existing 18x18 dedicated multipliers in FPGAs with dedicated 24x24
multipliers designed with small 4x4 bit multipliers. It is also proposed that
for every dedicated 24x24 bit multiplier block designed with 4x4 bit
multipliers, four redundant 4x4 multiplier should be provided to enforce the
feature of self repairability (to recover from the faults). In the proposed
CIFM reconfigurability at run time is also provided resulting in low power. The
major source of motivation for providing the dedicated 24x24 bit multiplier
stems from the fact that single precision floating point multiplier requires
24x24 bit integer multiplier for mantissa multiplication. A reconfigurable,
self-repairable 24x24 bit multiplier (implemented with 4x4 bit multiply
modules) will ideally suit this purpose, making FPGAs more suitable for integer
as well floating point operations. A dedicated 4x4 bit multiplier is also
proposed in this paper. Moreover, in the recent years, reversible logic has
emerged as a promising technology having its applications in low power CMOS,
quantum computing, nanotechnology, and optical computing. It is not possible to
realize quantum computing without reversible logic. Thus, this paper also paper
provides the reversible logic implementation of the proposed CIFM. The
reversible CIFM designed and proposed here will form the basis of the
completely reversible FPGAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610091</id><created>2006-10-14</created><updated>2006-12-24</updated><authors><author><keyname>Mansilla</keyname><forenames>R.</forenames></author><author><keyname>K&#xf6;ppen</keyname><forenames>E.</forenames></author><author><keyname>Cocho</keyname><forenames>G.</forenames></author><author><keyname>Miramontes</keyname><forenames>P.</forenames></author></authors><title>On the Behavior of Journal Impact Factor Rank-Order Distribution</title><categories>cs.IR physics.soc-ph</categories><comments>Submitted to the Journal of Informetrics, redundat text cropped,
  bibliography corrected, new section added, typos corrected</comments><abstract>  An empirical law for the rank-order behavior of journal impact factors is
found. Using an extensive data base on impact factors including journals on
Education, Agrosciences, Geosciences, Biosciences and Environ- mental,
Chemical, Computer, Engineering, Material, Mathematical, Medical and Physical
Sciences we have found extremely good fits out- performing other rank-order
models. Some extensions to other areas of knowledge are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610092</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610092</id><created>2006-10-14</created><updated>2010-02-04</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Happy endings for flip graphs</title><categories>cs.CG math.CO math.MG</categories><comments>26 pages, 15 figures. Revised and expanded for journal publication</comments><acm-class>F.2.2</acm-class><journal-ref>Journal of Computational Geometry 1(1):3-28, 2010.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the triangulations of a finite point set form a flip graph that
can be embedded isometrically into a hypercube, if and only if the point set
has no empty convex pentagon. Point sets of this type include convex subsets of
lattices, points on two lines, and several other infinite families. As a
consequence, flip distance in such point sets can be computed efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610093</identifier>
 <datestamp>2011-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610093</id><created>2006-10-15</created><updated>2007-11-06</updated><authors><author><keyname>van Ditmarsch</keyname><forenames>H. P.</forenames></author><author><keyname>Kooi</keyname><forenames>B. P.</forenames></author></authors><title>Semantic results for ontic and epistemic change</title><categories>cs.LO cs.AI cs.MA</categories><journal-ref>G. Bonanno, W. van der Hoek, and M. Wooldridge (editors), Logic
  and the Foundations of Game and Decision Theory (LOFT 7), pages 87-117. Texts
  in Logic and Games, Amsterdam University Press, 2008</journal-ref><abstract>  We give some semantic results for an epistemic logic incorporating dynamic
operators to describe information changing events. Such events include
epistemic changes, where agents become more informed about the non-changing
state of the world, and ontic changes, wherein the world changes. The events
are executed in information states that are modeled as pointed Kripke models.
Our contribution consists of three semantic results. (i) Given two information
states, there is an event transforming one into the other. The linguistic
correspondent to this is that every consistent formula can be made true in
every information state by the execution of an event. (ii) A more technical
result is that: every event corresponds to an event in which the postconditions
formalizing ontic change are assignments to `true' and `false' only (instead of
assignments to arbitrary formulas in the logical language). `Corresponds' means
that execution of either event in a given information state results in
bisimilar information states. (iii) The third, also technical, result is that
every event corresponds to a sequence of events wherein all postconditions are
assignments of a single atom only (instead of simultaneous assignments of more
than one atom).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610094</id><created>2006-10-15</created><updated>2007-01-03</updated><authors><author><keyname>Mesbah</keyname><forenames>Ali</forenames></author><author><keyname>van Deursen</keyname><forenames>Arie</forenames></author></authors><title>Migrating Multi-page Web Applications to Single-page AJAX Interfaces</title><categories>cs.SE</categories><report-no>TUD-SERG-2006-018</report-no><journal-ref>Proceedings of the 11th European Conference on Software
  Maintenance and Reengineering (CSMR'07), IEEE Computer Society, 2007</journal-ref><abstract>  Recently, a new web development technique for creating interactive web
applications, dubbed AJAX, has emerged. In this new model, the single-page web
interface is composed of individual components which can be updated/replaced
independently. With the rise of AJAX web applications classical multi-page web
applications are becoming legacy systems. If until a year ago, the concern
revolved around migrating legacy systems to web-based settings, today we have a
new challenge of migrating web applications to single-page AJAX applications.
Gaining an understanding of the navigational model and user interface structure
of the source application is the first step in the migration process. In this
paper, we explore how reverse engineering techniques can help analyze classic
web applications for this purpose. Our approach, using a schema-based
clustering technique, extracts a navigational model of web applications, and
identifies candidate user interface components to be migrated to a single-page
AJAX interface. Additionally, results of a case study, conducted to evaluate
our tool, are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610095</id><created>2006-10-16</created><authors><author><keyname>Gim&#xe9;nez</keyname><forenames>Omer</forenames></author></authors><title>Solving planning domains with polytree causal graphs is NP-complete</title><categories>cs.AI cs.CC</categories><acm-class>I.2.8</acm-class><abstract>  We show that solving planning domains on binary variables with polytree
causal graph is \NP-complete. This is in contrast to a polynomial-time
algorithm of Domshlak and Brafman that solves these planning domains for
polytree causal graphs of bounded indegree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610096</id><created>2006-10-16</created><authors><author><keyname>Blazy</keyname><forenames>Sandrine</forenames><affiliation>CEDRIC</affiliation></author></authors><title>Partial Evaluation for Program Comprehension</title><categories>cs.SE</categories><proxy>ccsd inria-00106403</proxy><journal-ref>Dans ACM Computing Surveys, Symposium on partial evaluation 30, 3
  es (1998)</journal-ref><abstract>  Program comprehension is the most tedious and time consuming task of software
maintenance, an important phase of the software life cycle. This is
particularly true while maintaining scientific application programs that have
been written in Fortran for decades and that are still vital in various domains
even though more modern languages are used to implement their user interfaces.
Very often, programs have evolved as their application domains increase
continually and have become very complex due to extensive modifications. This
generality in programs is implemented by input variables whose value does not
vary in the context of a given application. Thus, it is very interesting for
the maintainer to propagate such information, that is to obtain a simplified
program, which behaves like the initial one when used according to the
restriction. We have adapted partial evaluation for program comprehension. Our
partial evaluator performs mainly two tasks: constant propagation and
statements simplification. It includes an interprocedural alias analysis. As
our aim is program comprehension rather than optimization, there are two main
differences with classical partial evaluation. We do not change the original
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610097</id><created>2006-10-16</created><authors><author><keyname>Blazy</keyname><forenames>Sandrine</forenames><affiliation>CEDRIC</affiliation></author><author><keyname>Gervais</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>CEDRIC</affiliation></author><author><keyname>Laleau</keyname><forenames>R&#xe9;gine</forenames><affiliation>CEDRIC</affiliation></author></authors><title>Reuse of Specification Patterns with the B Method</title><categories>cs.SE</categories><proxy>ccsd inria-00078953</proxy><journal-ref>Dans ZB 2003: Formal Specification and Development in Z and B,
  2651 (2003) 40-57</journal-ref><abstract>  This paper describes an approach for reusing specification patterns.
Specification patterns are design patterns that are expressed in a formal
specification language. Reusing a specification pattern means instantiating it
or composing it with other specification patterns. Three levels of composition
are defined: juxtaposition, composition with inter-patterns links and
unification. This paper shows through examples how to define specification
patterns in B, how to reuse them directly in B, and also how to reuse the
proofs associated with specification patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610098</id><created>2006-10-16</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Moses</keyname><forenames>Yoram</forenames></author></authors><title>Characterizing Solution Concepts in Games Using Knowledge-Based Programs</title><categories>cs.GT cs.DC cs.MA</categories><comments>To appear, IJCAI 2007</comments><abstract>  We show how solution concepts in games such as Nash equilibrium, correlated
equilibrium, rationalizability, and sequential equilibrium can be given a
uniform definition in terms of \emph{knowledge-based programs}. Intuitively,
all solution concepts are implementations of two knowledge-based programs, one
appropriate for games represented in normal form, the other for games
represented in extensive form. These knowledge-based programs can be viewed as
embodying rationality. The representation works even if (a) information sets do
not capture an agent's knowledge, (b) uncertainty is not represented by
probability, or (c) the underlying game is not common knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610099</id><created>2006-10-16</created><updated>2006-10-24</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Properties of Codes with the Rank Metric</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, accepted to Globecom 2006</comments><abstract>  In this paper, we study properties of rank metric codes in general and
maximum rank distance (MRD) codes in particular. For codes with the rank
metric, we first establish Gilbert and sphere-packing bounds, and then obtain
the asymptotic forms of these two bounds and the Singleton bound. Based on the
asymptotic bounds, we observe that asymptotically Gilbert-Varsharmov bound is
exceeded by MRD codes and sphere-packing bound cannot be attained. We also
establish bounds on the rank covering radius of maximal codes, and show that
all MRD codes are maximal codes and all the MRD codes known so far achieve the
maximum rank covering radius.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610100</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610100</id><created>2006-10-17</created><authors><author><keyname>Jerez</keyname><forenames>Henry N</forenames></author><author><keyname>Khoury</keyname><forenames>Joud</forenames></author><author><keyname>Abdallah</keyname><forenames>Chaouki</forenames></author></authors><title>A Mobile Transient Internet Architecture</title><categories>cs.NI cs.IT math.IT</categories><acm-class>C.2.1</acm-class><abstract>  This paper describes a new architecture for transient mobile networks
destined to merge existing and future network architectures, communication
implementations and protocol operations by introducing a new paradigm to data
delivery and identification. The main goal of our research is to enable
seamless end-to-end communication between mobile and stationary devices across
multiple networks and through multiple communication environments. The
architecture establishes a set of infrastructure components and protocols that
set the ground for a Persistent Identification Network (PIN). The basis for the
operation of PIN is an identification space consisting of unique location
independent identifiers similar to the ones implemented in the Handle system.
Persistent Identifiers are used to identify and locate Digital Entities which
can include devices, services, users and even traffic. The architecture
establishes a primary connection independent logical structure that can operate
over conventional networks or more advanced peer-to-peer aggregation networks.
Communication is based on routing pools and novel protocols for routing data
across several abstraction levels of the network, regardless of the end-points'
current association and state...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610101</id><created>2006-10-17</created><authors><author><keyname>de Falco</keyname><forenames>Diego</forenames></author><author><keyname>Tamascelli</keyname><forenames>Dario</forenames></author></authors><title>Entropy generation in a model of reversible computation</title><categories>cs.CC quant-ph</categories><comments>13 pages, 6 figures</comments><journal-ref>RAIRO-Inf.Theor.Appl. 40, (2006) 93-105</journal-ref><doi>10.1051/ita:2006013</doi><abstract>  We present a model in which, due to the quantum nature of the signals
controlling the implementation time of successive unitary computational steps,
\emph{physical} irreversibility appears in the execution of a \emph{logically}
reversible computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610102</identifier>
 <datestamp>2008-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610102</id><created>2006-10-17</created><updated>2008-03-06</updated><authors><author><keyname>Mitra</keyname><forenames>Arindam</forenames></author></authors><title>Quantum communication is possible with pure state</title><categories>cs.IT math.IT</categories><abstract>  It is believed that quantum communication is not possible with a pure
ensemble of states because quantum entropy of pure state is zero. This is
indeed possible due to geometric consequence of entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610103</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610103</id><created>2006-10-17</created><authors><author><keyname>Gopala</keyname><forenames>Praveen Kumar</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On the Secrecy Capacity of Fading Channels</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figures, Submitted to the IEEE Trans. on Information
  Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  We consider the secure transmission of information over an ergodic fading
channel in the presence of an eavesdropper. Our eavesdropper can be viewed as
the wireless counterpart of Wyner's wiretapper. The secrecy capacity of such a
system is characterized under the assumption of asymptotically long coherence
intervals. We first consider the full Channel State Information (CSI) case,
where the transmitter has access to the channel gains of the legitimate
receiver and the eavesdropper. The secrecy capacity under this full CSI
assumption serves as an upper bound for the secrecy capacity when only the CSI
of the legitimate receiver is known at the transmitter, which is characterized
next. In each scenario, the perfect secrecy capacity is obtained along with the
optimal power and rate allocation strategies. We then propose a low-complexity
on/off power allocation strategy that achieves near-optimal performance with
only the main channel CSI. More specifically, this scheme is shown to be
asymptotically optimal as the average SNR goes to infinity, and interestingly,
is shown to attain the secrecy capacity under the full CSI assumption.
Remarkably, our results reveal the positive impact of fading on the secrecy
capacity and establish the critical role of rate adaptation, based on the main
channel CSI, in facilitating secure communications over slow fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610104</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610104</id><created>2006-10-17</created><authors><author><keyname>Nam</keyname><forenames>Young-Han</forenames></author><author><keyname>Gopala</keyname><forenames>Praveen Kumar</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>ARQ Diversity in Fading Random Access Channels</title><categories>cs.IT math.IT</categories><comments>24 pages, 6 figures, submitted to IEEE Transactions on Wireless
  Communications</comments><acm-class>E.4; H.1.1</acm-class><abstract>  A cross-layer optimization approach is adopted for the design of symmetric
random access wireless systems. Instead of the traditional collision model, a
more realistic physical layer model is considered. Based on this model, an
Incremental Redundancy Automatic Repeat reQuest (IR-ARQ) scheme, tailored to
jointly combat the effects of collisions, multi-path fading, and additive
noise, is developed. The Diversity-Multiplexing-Delay tradeoff (DMDT) of the
proposed scheme is analyzed for fully-loaded queues, and compared with that of
Gallager tree algorithm for collision resolution and the network-assisted
diversity multiple access (NDMA) protocol of Tsatsanis et al.. The fully-loaded
queue model is then replaced by one with random arrivals, under which these
protocols are compared in terms of the stability region, average delay and
diversity gain. Overall, our analytical and numerical results establish the
superiority of the proposed IR-ARQ scheme and reveal some important insights.
For example, it turns out that the performance is optimized, for a given total
throughput, by maximizing the probability that a certain user sends a new
packet and minimizing the transmission rate employed by each user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610105</identifier>
 <datestamp>2007-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610105</id><created>2006-10-18</created><updated>2007-11-22</updated><authors><author><keyname>Narayanan</keyname><forenames>Arvind</forenames></author><author><keyname>Shmatikov</keyname><forenames>Vitaly</forenames></author></authors><title>How To Break Anonymity of the Netflix Prize Dataset</title><categories>cs.CR cs.DB</categories><abstract>  We present a new class of statistical de-anonymization attacks against
high-dimensional micro-data, such as individual preferences, recommendations,
transaction records and so on. Our techniques are robust to perturbation in the
data and tolerate some mistakes in the adversary's background knowledge.
  We apply our de-anonymization methodology to the Netflix Prize dataset, which
contains anonymous movie ratings of 500,000 subscribers of Netflix, the world's
largest online movie rental service. We demonstrate that an adversary who knows
only a little bit about an individual subscriber can easily identify this
subscriber's record in the dataset. Using the Internet Movie Database as the
source of background knowledge, we successfully identified the Netflix records
of known users, uncovering their apparent political preferences and other
potentially sensitive information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610106</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610106</id><created>2006-10-18</created><authors><author><keyname>Gopala</keyname><forenames>Praveen Kumar</forenames></author><author><keyname>Nam</keyname><forenames>Young-Han</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On the Error Exponents of ARQ Channels with Deadlines</title><categories>cs.IT math.IT</categories><comments>16 pages, 6 figures, Submitted to the IEEE Trans. on Information
  Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  We consider communication over Automatic Repeat reQuest (ARQ) memoryless
channels with deadlines. In particular, an upper bound L is imposed on the
maximum number of ARQ transmission rounds. In this setup, it is shown that
incremental redundancy ARQ outperforms Forney's memoryless decoding in terms of
the achievable error exponents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610107</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610107</id><created>2006-10-18</created><authors><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Xin</keyname><forenames>Yan</forenames></author><author><keyname>Garg</keyname><forenames>Hari Krishna</forenames></author></authors><title>Interference Channels with Common Information</title><categories>cs.IT math.IT</categories><comments>23 pages, 5 figures, submitted to Trans. Inform. Theory</comments><abstract>  In this paper, we consider the discrete memoryless interference channel with
common information, in which two senders need deliver not only private messages
but also certain common messages to their corresponding receivers. We derive an
achievable rate region for such a channel by exploiting a random coding
strategy, namely cascaded superposition coding. We reveal that the derived
achievable rate region generalizes some important existing results for the
interference channels with or without common information. Furthermore, we
specialize to a class of deterministic interference channels with common
information, and show that the derived achievable rate region is indeed the
capacity region for this class of channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610108</identifier>
 <datestamp>2009-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610108</id><created>2006-10-18</created><updated>2009-02-01</updated><authors><author><keyname>Lagha</keyname><forenames>Mohand</forenames><affiliation>AERONAUTIC Department of Blida University, Femto-ST</affiliation></author><author><keyname>Bensebti</keyname><forenames>Messaoud</forenames><affiliation>AERONAUTIC Department of Blida University</affiliation></author></authors><title>Doppler Spectrum Estimation by Ramanujan Fourier Transforms</title><categories>cs.NA cs.CE</categories><proxy>ccsd ccsd-00107169</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Doppler spectrum estimation of a weather radar signal in a classic way
can be made by two methods, temporal one based in the autocorrelation of the
successful signals, whereas the other one uses the estimation of the power
spectral density PSD by using Fourier transforms. We introduces a new tool of
signal processing based on Ramanujan sums cq(n), adapted to the analysis of
arithmetical sequences with several resonances p/q. These sums are almost
periodic according to time n of resonances and aperiodic according to the order
q of resonances. New results will be supplied by the use of Ramanujan Fourier
Transform (RFT) for the estimation of the Doppler spectrum for the weather
radar signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610109</id><created>2006-10-18</created><authors><author><keyname>Nassar</keyname><forenames>Mohamed El Baker</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>State</keyname><forenames>Radu</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Festor</keyname><forenames>Olivier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Intrusion detection mechanisms for VoIP applications</title><categories>cs.NI</categories><proxy>ccsd inria-00107054</proxy><journal-ref>Dans Third annual VoIP security workshop (VSW'06) (2006)</journal-ref><abstract>  VoIP applications are emerging today as an important component in business
and communication industry. In this paper, we address the intrusion detection
and prevention in VoIP networks and describe how a conceptual solution based on
the Bayes inference approach can be used to reinforce the existent security
mechanisms. Our approach is based on network monitoring and analyzing of the
VoIP-specific traffic. We give a detailed example on attack detection using the
SIP signaling protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610110</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610110</id><created>2006-10-18</created><updated>2009-02-24</updated><authors><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>ELIAUS</affiliation></author><author><keyname>Lester</keyname><forenames>David</forenames><affiliation>University of Manchester</affiliation></author><author><keyname>Martin-Dorel</keyname><forenames>Erik</forenames><affiliation>ELIAUS, Lamps</affiliation></author><author><keyname>Truffert</keyname><forenames>Annick</forenames><affiliation>LAMPS</affiliation></author></authors><title>Stochastic Formal Methods for Hybrid Systems</title><categories>cs.MS</categories><proxy>ccsd ccsd-00107495</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a framework to bound the probability that accumulated errors were
never above a given threshold on hybrid systems. Such systems are used for
example to model an aircraft or a nuclear power plant on one side and its
software on the other side. This report contains simple formulas based on
L\'evy's and Markov's inequalities and it presents a formal theory of random
variables with a special focus on producing concrete results. We selected four
very common applications that fit in our framework and cover the common
practices of hybrid systems that evolve for a long time. We compute the number
of bits that remain continuously significant in the first two applications with
a probability of failure around one against a billion, where worst case
analysis considers that no significant bit remains. We are using PVS as such
formal tools force explicit statement of all hypotheses and prevent incorrect
uses of theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610111</identifier>
 <datestamp>2007-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610111</id><created>2006-10-18</created><updated>2007-10-02</updated><authors><author><keyname>Jung</keyname><forenames>Kyomin</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>Local approximate inference algorithms</title><categories>cs.AI</categories><comments>21 pages, 10 figures</comments><abstract>  We present a new local approximation algorithm for computing Maximum a
Posteriori (MAP) and log-partition function for arbitrary exponential family
distribution represented by a finite-valued pair-wise Markov random field
(MRF), say $G$. Our algorithm is based on decomposition of $G$ into {\em
appropriately} chosen small components; then computing estimates locally in
each of these components and then producing a {\em good} global solution. We
show that if the underlying graph $G$ either excludes some finite-sized graph
as its minor (e.g. Planar graph) or has low doubling dimension (e.g. any graph
with {\em geometry}), then our algorithm will produce solution for both
questions within {\em arbitrary accuracy}. We present a message-passing
implementation of our algorithm for MAP computation using self-avoiding walk of
graph. In order to evaluate the computational cost of this implementation, we
derive novel tight bounds on the size of self-avoiding walk tree for arbitrary
graph.
  As a consequence of our algorithmic result, we show that the normalized
log-partition function (also known as free-energy) for a class of {\em regular}
MRFs will converge to a limit, that is computable to an arbitrary accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610112</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610112</id><created>2006-10-18</created><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>On the Performance of Lossless Joint Source-Channel Coding Based on
  Linear Codes</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. 2006 IEEE Information Theory Workshop, October
  22-26, 2006, Chengdu, China. (5 pages, 2 figures)</comments><abstract>  A general lossless joint source-channel coding scheme based on linear codes
is proposed and then analyzed in this paper. It is shown that a linear code
with good joint spectrum can be used to establish limit-approaching joint
source-channel coding schemes for arbitrary sources and channels, where the
joint spectrum of the code is a generalization of the input-output weight
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610113</id><created>2006-10-19</created><authors><author><keyname>Mora</keyname><forenames>A. M.</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author><author><keyname>Millan</keyname><forenames>C.</forenames></author><author><keyname>Torrecillas</keyname><forenames>J.</forenames></author><author><keyname>Laredo</keyname><forenames>J. L. J.</forenames></author></authors><title>CHAC. A MOACO Algorithm for Computation of Bi-Criteria Military Unit
  Path in the Battlefield</title><categories>cs.MA cs.CC</categories><journal-ref>Published in Proceedings of the Workshop on Nature Inspired
  Cooperative Strategies for Optimization. NICSO'2006, Pelta &amp; Krasnogor, (eds)
  pp 85-98, Jun. 2006</journal-ref><abstract>  In this paper we propose a Multi-Objective Ant Colony Optimization (MOACO)
algorithm called CHAC, which has been designed to solve the problem of finding
the path on a map (corresponding to a simulated battlefield) that minimizes
resources while maximizing safety. CHAC has been tested with two different
state transition rules: an aggregative function that combines the heuristic and
pheromone information of both objectives and a second one that is based on the
dominance concept of multiobjective optimization problems. These rules have
been evaluated in several different situations (maps with different degree of
difficulty), and we have found that they yield better results than a greedy
algorithm (taken as baseline) in addition to a military behaviour that is also
better in the tactical sense. The aggregative function, in general, yields
better results than the one based on dominance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610114</identifier>
 <datestamp>2008-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610114</id><created>2006-10-19</created><updated>2008-01-12</updated><authors><author><keyname>Thomann</keyname><forenames>Hans-Rudolf</forenames></author></authors><title>Instant Computing - A New Computation Paradigm</title><categories>cs.CC cs.CR quant-ph</categories><comments>Final version, 34 pages. Theorem 3 generalized and strengthened.
  Review results implemented. Typos corrected</comments><acm-class>F.1.1; F.1.2; F.1.3; F.1.4</acm-class><abstract>  Voltage peaks on a conventional computer's power lines allow for the
well-known dangerous DPA attacks. We show that measurement of a quantum
computer's transient state during a computational step reveals information
about a complete computation of arbitrary length, which can be extracted by
repeated probing, if the computer is suitably programmed. Instant computing, as
we name this mode of operation, recognizes for any total or partial recursive
function arguments lying in the domain of definition and yields their function
value with arbitrary small error probability in probabilistic linear time. This
implies recognition of (not necessarily recursively enumerable) complements of
recursively enumerable sets and the solution of the halting problem. Future
quantum computers are shown to be likely to allow for instant computing, and
some consequences are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610115</identifier>
 <datestamp>2007-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610115</id><created>2006-10-19</created><updated>2007-09-28</updated><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>An Achievable Rate Region for the Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>15 pages, 6 figures, submitted to IEEE Trans. Inform. Theory; This
  paper has been withdrawn by the authors because the content will be
  completely covered by another paper that the authors will submit soon</comments><abstract>  An achievable rate region for the Gaussian interference channel is derived
using Sato's modified frequency division multiplexing idea and a special case
of Han and Kobayashi's rate region (denoted by $\Gmat^\prime$). We show that
the new inner bound includes $\Gmat^\prime$, Sason's rate region $\Dmat$, as
well as the achievable region via TDM/FDM, as its subsets. The advantage of
this improved inner bound over $\Gmat^\prime$ arises due to its inherent
ability to utilize the whole transmit power range on the real line without
violating the power constraint. We also provide analysis to examine the
conditions for the new achievable region to strictly extend $\Gmat^\prime$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610116</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610116</id><created>2006-10-19</created><authors><author><keyname>Kakkonen</keyname><forenames>Tuomo</forenames></author></authors><title>DepAnn - An Annotation Tool for Dependency Treebanks</title><categories>cs.CL</categories><journal-ref>Proceedings of the 11th ESSLLI Student Session at the 18th
  European Summer School in Logic, Language and Information (ESSLLI 2006), pp.
  214-225. Malaga, Spain, 2006</journal-ref><abstract>  DepAnn is an interactive annotation tool for dependency treebanks, providing
both graphical and text-based annotation interfaces. The tool is aimed for
semi-automatic creation of treebanks. It aids the manual inspection and
correction of automatically created parses, making the annotation process
faster and less error-prone. A novel feature of the tool is that it enables the
user to view outputs from several parsers as the basis for creating the final
tree to be saved to the treebank. DepAnn uses TIGER-XML, an XML-based general
encoding format for both, representing the parser outputs and saving the
annotated treebank. The tool includes an automatic consistency checker for
sentence structures. In addition, the tool enables users to build structures
manually, add comments on the annotations, modify the tagsets, and mark
sentences for further revision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610117</id><created>2006-10-19</created><authors><author><keyname>Avigad</keyname><forenames>Jeremy</forenames></author><author><keyname>Yin</keyname><forenames>Yimu</forenames></author></authors><title>Quantifier elimination for the reals with a predicate for the powers of
  two</title><categories>cs.LO</categories><acm-class>F.4.1; I.2.3</acm-class><abstract>  In 1985, van den Dries showed that the theory of the reals with a predicate
for the integer powers of two admits quantifier elimination in an expanded
language, and is hence decidable. He gave a model-theoretic argument, which
provides no apparent bounds on the complexity of a decision procedure. We
provide a syntactic argument that yields a procedure that is primitive
recursive, although not elementary. In particular, we show that it is possible
to eliminate a single block of existential quantifiers in time $2^0_{O(n)}$,
where $n$ is the length of the input formula and $2_k^x$ denotes $k$-fold
iterated exponentiation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610118</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610118</id><created>2006-10-19</created><authors><author><keyname>Kakkonen</keyname><forenames>Tuomo</forenames></author><author><keyname>Myller</keyname><forenames>Niko</forenames></author><author><keyname>Sutinen</keyname><forenames>Erkki</forenames></author></authors><title>Applying Part-of-Seech Enhanced LSA to Automatic Essay Grading</title><categories>cs.IR cs.CL</categories><journal-ref>Proceedings of the 4th IEEE International Conference on
  Information Technology: Research and Education (ITRE 2006). Tel Aviv, Israel,
  2006</journal-ref><abstract>  Latent Semantic Analysis (LSA) is a widely used Information Retrieval method
based on &quot;bag-of-words&quot; assumption. However, according to general conception,
syntax plays a role in representing meaning of sentences. Thus, enhancing LSA
with part-of-speech (POS) information to capture the context of word
occurrences appears to be theoretically feasible extension. The approach is
tested empirically on a automatic essay grading system using LSA for document
similarity comparisons. A comparison on several POS-enhanced LSA models is
reported. Our findings show that the addition of contextual information in the
form of POS tags can raise the accuracy of the LSA-based scoring models up to
10.77 per cent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610119</id><created>2006-10-19</created><authors><author><keyname>Hazan</keyname><forenames>Elad</forenames></author></authors><title>Approximate Convex Optimization by Online Game Playing</title><categories>cs.DS</categories><abstract>  Lagrangian relaxation and approximate optimization algorithms have received
much attention in the last two decades. Typically, the running time of these
methods to obtain a $\epsilon$ approximate solution is proportional to
$\frac{1}{\epsilon^2}$. Recently, Bienstock and Iyengar, following Nesterov,
gave an algorithm for fractional packing linear programs which runs in
$\frac{1}{\epsilon}$ iterations. The latter algorithm requires to solve a
convex quadratic program every iteration - an optimization subroutine which
dominates the theoretical running time.
  We give an algorithm for convex programs with strictly convex constraints
which runs in time proportional to $\frac{1}{\epsilon}$. The algorithm does NOT
require to solve any quadratic program, but uses gradient steps and elementary
operations only. Problems which have strictly convex constraints include
maximum entropy frequency estimation, portfolio optimization with loss risk
constraints, and various computational problems in signal processing.
  As a side product, we also obtain a simpler version of Bienstock and
Iyengar's result for general linear programming, with similar running time.
  We derive these algorithms using a new framework for deriving convex
optimization algorithms from online game playing algorithms, which may be of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610120</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610120</id><created>2006-10-20</created><updated>2008-10-22</updated><authors><author><keyname>Standish</keyname><forenames>Russell K.</forenames></author><author><keyname>Madina</keyname><forenames>Duraid</forenames></author></authors><title>Classdesc and Graphcode: support for scientific programming in C++</title><categories>cs.MS cs.CE cs.DC</categories><acm-class>D.1.3; D.1.5; D.2.12; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented programming languages such as Java and Objective C have
become popular for implementing agent-based and other object-based simulations
since objects in those languages can {\em reflect} (i.e. make runtime queries
of an object's structure). This allows, for example, a fairly trivial {\em
serialisation} routine (conversion of an object into a binary representation
that can be stored or passed over a network) to be written. However C++ does
not offer this ability, as type information is thrown away at compile time. Yet
C++ is often a preferred development environment, whether for performance
reasons or for its expressive features such as operator overloading.
  In scientific coding, changes to a model's codes takes place constantly, as
the model is refined, and different phenomena are studied. Yet traditionally,
facilities such as checkpointing, routines for initialising model parameters
and analysis of model output depend on the underlying model remaining static,
otherwise each time a model is modified, a whole slew of supporting routines
needs to be changed to reflect the new data structures. Reflection offers the
advantage of the simulation framework adapting to the underlying model without
programmer intervention, reducing the effort of modifying the model.
  In this paper, we present the {\em Classdesc} system which brings many of the
benefits of object reflection to C++, {\em ClassdescMP} which dramatically
simplifies coding of MPI based parallel programs and {\em
  Graphcode} a general purpose data parallel programming environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610121</identifier>
 <datestamp>2007-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610121</id><created>2006-10-20</created><updated>2007-05-09</updated><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author></authors><title>Construction algorithm for network error-correcting codes attaining the
  Singleton bound</title><categories>cs.IT cs.DM cs.NI math.IT</categories><comments>To appear in IEICE Trans. Fundamentals
  (http://ietfec.oxfordjournals.org/), vol. E90-A, no. 9, Sept. 2007. LaTeX2e,
  7 pages, using ieice.cls and pstricks.sty. Version 4 adds randomized
  construction of network error-correcting codes, comparisons of the proposed
  methods to the existing methods, additional explanations in the proof</comments><acm-class>C.2.1; E.1; E.4; G.2.2</acm-class><journal-ref>IEICE Trans. Fundamentals, vol. E90-A, no. 9, pp. 1729-1735,
  September 2007</journal-ref><doi>10.1093/ietfec/e90-a.9.1729</doi><abstract>  We give a centralized deterministic algorithm for constructing linear network
error-correcting codes that attain the Singleton bound of network
error-correcting codes. The proposed algorithm is based on the algorithm by
Jaggi et al. We give estimates on the time complexity and the required symbol
size of the proposed algorithm. We also estimate the probability of a random
choice of local encoding vectors by all intermediate nodes giving a network
error-correcting codes attaining the Singleton bound. We also clarify the
relationship between the robust network coding and the network error-correcting
codes with known locations of errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610122</id><created>2006-10-20</created><authors><author><keyname>Langlois</keyname><forenames>Philippe</forenames><affiliation>LP2A-DALI</affiliation></author><author><keyname>Louvet</keyname><forenames>Nicolas</forenames><affiliation>LP2A-DALI</affiliation></author></authors><title>Faithful Polynomial Evaluation with Compensated Horner Algorithm</title><categories>cs.NA cs.MS</categories><proxy>ccsd ccsd-00107222</proxy><acm-class>G.4</acm-class><abstract>  This paper presents two sufficient conditions to ensure a faithful evaluation
of polynomial in IEEE-754 floating point arithmetic. Faithfulness means that
the computed value is one of the two floating point neighbours of the exact
result; it can be satisfied using a more accurate algorithm than the classic
Horner scheme. One condition here provided is an apriori bound of the
polynomial condition number derived from the error analysis of the compensated
Horner algorithm. The second condition is both dynamic and validated to check
at the running time the faithfulness of a given evaluation. Numerical
experiments illustrate the behavior of these two conditions and that associated
running time over-cost is really interesting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610123</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610123</id><created>2006-10-20</created><updated>2006-11-20</updated><authors><author><keyname>Strassburger</keyname><forenames>Lutz</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Proof Nets and the Identity of Proofs</title><categories>cs.LO</categories><proxy>ccsd inria-00107260</proxy><abstract>  These are the notes for a 5-lecture-course given at ESSLLI 2006 in Malaga,
Spain. The URL of the school is http://esslli2006.lcc.uma.es/ . This version
slightly differs from the one which has been distributed at the school because
typos have been removed and comments and suggestions by students have been
worked in. The course is intended to be introductory. That means no prior
knowledge of proof nets is required. However, the student should be familiar
with the basics of propositional logic, and should have seen formal proofs in
some formal deductive system (e.g., sequent calculus, natural deduction,
resolution, tableaux, calculus of structures, Frege-Hilbert-systems, ...). It
is probably helpful if the student knows already what cut elimination is, but
this is not strictly necessary. In these notes, I will introduce the concept of
``proof nets'' from the viewpoint of the problem of the identity of proofs. I
will proceed in a rather informal way. The focus will be more on presenting
ideas than on presenting technical details. The goal of the course is to give
the student an overview of the theory of proof nets and make the vast amount of
literature on the topic easier accessible to the beginner. For introducing the
basic concepts of the theory, I will in the first part of the course stick to
the unit-free multiplicative fragment of linear logic because of its rather
simple notion of proof nets. In the second part of the course we will see proof
nets for more sophisticated logics. This is a basic introduction into proof
nets from the perspective of the identity of proofs. We discuss how deductive
proofs can be translated into proof nets and what a correctness criterion is.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610124</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610124</id><created>2006-10-20</created><authors><author><keyname>Kakkonen</keyname><forenames>Tuomo</forenames></author></authors><title>Dependency Treebanks: Methods, Annotation Schemes and Tools</title><categories>cs.CL</categories><journal-ref>Proceedings of the 15th Nordic Conference of Computational
  Linguistics (NODALIDA 2005), pp. 94-104. Joensuu, Finland, 2005</journal-ref><abstract>  In this paper, current dependencybased treebanks are introduced and analyzed.
The methods used for building the resources, the annotation schemes applied,
and the tools used (such as POS taggers, parsers and annotation software) are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610125</id><created>2006-10-20</created><updated>2006-11-02</updated><authors><author><keyname>Hofman</keyname><forenames>Radoslaw</forenames></author></authors><title>Report on article: P=NP Linear programming formulation of the Traveling
  Salesman Problem</title><categories>cs.CC cs.DM cs.DS</categories><comments>This version contain more figures, and clearer way to explain counter
  example idea for k dimensions</comments><acm-class>F.2</acm-class><abstract>  This article presents counter examples for three articles claiming that P=NP.
Articles for which it applies are: Moustapha Diaby &quot;P = NP: Linear programming
formulation of the traveling salesman problem&quot; and &quot;Equality of complexity
classes P and NP: Linear programming formulation of the quadratic assignment
problem&quot;, and also Sergey Gubin &quot;A Polynomial Time Algorithm for The Traveling
Salesman Problem&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610126</id><created>2006-10-20</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Legg</keyname><forenames>Shane</forenames></author></authors><title>Fitness Uniform Optimization</title><categories>cs.NE cs.LG</categories><comments>25 double-column pages, 12 figures</comments><report-no>IDSIA-16-06</report-no><journal-ref>IEEE Transactions on Evolutionary Computation, 10:5 (2006) 568-589</journal-ref><doi>10.1109/TEVC.2005.863127</doi><abstract>  In evolutionary algorithms, the fitness of a population increases with time
by mutating and recombining individuals and by a biased selection of more fit
individuals. The right selection pressure is critical in ensuring sufficient
optimization progress on the one hand and in preserving genetic diversity to be
able to escape from local optima on the other hand. Motivated by a universal
similarity relation on the individuals, we propose a new selection scheme,
which is uniform in the fitness values. It generates selection pressure toward
sparsely populated fitness regions, not necessarily toward higher fitness, as
is the case for all other selection schemes. We show analytically on a simple
example that the new selection scheme can be much more effective than standard
selection schemes. We also propose a new deletion scheme which achieves a
similar result via deletion and show how such a scheme preserves genetic
diversity more effectively than standard approaches. We compare the performance
of the new schemes to tournament selection and random deletion on an artificial
deceptive problem and a range of NP-hard problems: traveling salesman, set
covering and satisfiability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610127</id><created>2006-10-20</created><authors><author><keyname>Vlad</keyname><forenames>Serban E.</forenames></author></authors><title>The intersection and the union of the asynchronous systems</title><categories>cs.GL</categories><comments>The 14-th Conference on Applied and Industrial Mathematics CAIM 2006,
  Satellite Conference of ICM2006, Chisinau, Moldova, August 17-19, 2006</comments><abstract>  The asynchronous systems $f$ are the models of the asynchronous circuits from
digital electrical engineering. They are multi-valued functions that associate
to each input $u:\mathbf{R}\to \{0,1\}^{m}$ a set of states $x\in f(u),$ where
$x:\mathbf{R}\to \{0,1\}^{n}.$ The intersection of the systems allows adding
supplementary conditions in modeling and the union of the systems allows
considering the validity of one of two systems in modeling, for example when
testing the asynchronous circuits and the circuit is supposed to be 'good' or
'bad'. The purpose of the paper is that of analyzing the intersection and the
union against the initial/final states, initial/final time, initial/final state
functions, subsystems, dual systems, inverse systems, Cartesian product of
systems, parallel connection and serial connection of systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610128</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610128</id><created>2006-10-20</created><updated>2007-08-24</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Kaser</keyname><forenames>Owen</forenames></author></authors><title>Hierarchical Bin Buffering: Online Local Moments for Dynamic External
  Memory Arrays</title><categories>cs.DS cs.DB</categories><acm-class>H.3.5; G.1.1</acm-class><journal-ref>Daniel Lemire and Owen Kaser, Hierarchical Bin Buffering: Online
  Local Moments for Dynamic External Memory Arrays, ACM Transactions on
  Algorithms 4(1): 14 (2008)</journal-ref><doi>10.1145/1328911.1328925</doi><abstract>  Local moments are used for local regression, to compute statistical measures
such as sums, averages, and standard deviations, and to approximate probability
distributions. We consider the case where the data source is a very large I/O
array of size n and we want to compute the first N local moments, for some
constant N. Without precomputation, this requires O(n) time. We develop a
sequence of algorithms of increasing sophistication that use precomputation and
additional buffer space to speed up queries. The simpler algorithms partition
the I/O array into consecutive ranges called bins, and they are applicable not
only to local-moment queries, but also to algebraic queries (MAX, AVERAGE, SUM,
etc.). With N buffers of size sqrt{n}, time complexity drops to O(sqrt n). A
more sophisticated approach uses hierarchical buffering and has a logarithmic
time complexity (O(b log_b n)), when using N hierarchical buffers of size n/b.
Using Overlapped Bin Buffering, we show that only a single buffer is needed, as
with wavelet-based algorithms, but using much less storage. Applications exist
in multidimensional and statistical databases over massive data sets,
interactive image processing, and visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610129</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610129</id><created>2006-10-23</created><authors><author><keyname>Gunes</keyname><forenames>Ismail</forenames></author><author><keyname>Bingol</keyname><forenames>Haluk</forenames></author></authors><title>Community Detection in Complex Networks Using Agents</title><categories>cs.MA cs.CY</categories><comments>5 pages</comments><acm-class>I.2.11</acm-class><abstract>  Community structure identification has been one of the most popular research
areas in recent years due to its applicability to the wide scale of
disciplines. To detect communities in varied topics, there have been many
algorithms proposed so far. However, most of them still have some drawbacks to
be addressed. In this paper, we present an agent-based based community
detection algorithm. The algorithm that is a stochastic one makes use of agents
by forcing them to perform biased moves in a smart way. Using the information
collected by the traverses of these agents in the network, the network
structure is revealed. Also, the network modularity is used for determining the
number of communities. Our algorithm removes the need for prior knowledge about
the network such as number of the communities or any threshold values.
Furthermore, the definite community structure is provided as a result instead
of giving some structures requiring further processes. Besides, the
computational and time costs are optimized because of using thread like working
agents. The algorithm is tested on three network data of different types and
sizes named Zachary karate club, college football and political books. For all
three networks, the real network structures are identified in almost every run.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610130</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610130</id><created>2006-10-23</created><authors><author><keyname>Haroutunian</keyname><forenames>Evgueni A.</forenames><affiliation>Associate Member, IEEE</affiliation></author></authors><title>On Bounds for $E$-capacity of DMC</title><categories>cs.IT math.IT</categories><abstract>  Random coding, expurgated and sphere packing bounds are derived by method of
types and method of graph decomposition for $E$-capacity of discrete memoryless
channel (DMC). Three decoding rules are considered, the random coding bound is
attainable by each of the three rules, but the expurgated bound is achievable
only by maximum-likelihood decoding. Sphere packing bound is obtained by very
simple combinatorial reasonings of the method of types. The paper joins and
reviews the results of previous hard achievable publications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610131</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610131</id><created>2006-10-23</created><authors><author><keyname>Marchal</keyname><forenames>Loris</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Rehn</keyname><forenames>Veronika</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Robert</keyname><forenames>Yves</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Vivien</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author></authors><title>Scheduling and data redistribution strategies on star platforms</title><categories>cs.DC</categories><proxy>ccsd inria-00108518</proxy><abstract>  In this work we are interested in the problem of scheduling and
redistributing data on master-slave platforms. We consider the case were the
workers possess initial loads, some of which having to be redistributed in
order to balance their completion times. We examine two different scenarios.
The first model assumes that the data consists of independent and identical
tasks. We prove the NP-completeness in the strong sense for the general case,
and we present two optimal algorithms for special platform types. Furthermore
we propose three heuristics for the general case. Simulations consolidate the
theoretical results. The second data model is based on Divisible Load Theory.
This problem can be solved in polynomial time by a combination of linear
programming and simple analytical manipulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610132</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610132</id><created>2006-10-23</created><authors><author><keyname>Lee</keyname><forenames>Kwankyu</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael E.</forenames></author></authors><title>List Decoding of Hermitian Codes using Groebner Bases</title><categories>cs.IT cs.SC math.IT</categories><comments>19 pages, 2 figures</comments><abstract>  List decoding of Hermitian codes is reformulated to allow an efficient and
simple algorithm for the interpolation step. The algorithm is developed using
the theory of Groebner bases of modules. The computational complexity of the
algorithm seems comparable to previously known algorithms achieving the same
task, and the algorithm is better suited for hardware implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610133</id><created>2006-10-23</created><updated>2007-04-19</updated><authors><author><keyname>Silverston</keyname><forenames>Thomas</forenames></author><author><keyname>Fourmaux</keyname><forenames>Olivier</forenames></author></authors><title>P2P IPTV Measurement: A Comparison Study</title><categories>cs.NI cs.MM</categories><comments>10 pages</comments><abstract>  With the success of P2P file sharing, new emerging P2P applications arise on
the Internet for streaming content like voice (VoIP) or live video (IPTV).
Nowadays, there are lots of works measuring P2P file sharing or P2P telephony
systems, but there is still no comprehensive study about P2P IPTV, whereas it
should be massively used in the future. During the last FIFA world cup, we
measured network traffic generated by P2P IPTV applications like PPlive,
PPstream, TVants and Sopcast. In this paper we analyze some of our results
during the same games for the applications. We focus on traffic statistics and
churn of peers within these P2P networks. Our objectives are threefold: we
point out the traffic generated to understand the impact they will have on the
network, we try to infer the mechanisms of such applications and highlight
differences, and we give some insights about the users' behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610134</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610134</id><created>2006-10-23</created><authors><author><keyname>Clegg</keyname><forenames>Richard G.</forenames></author><author><keyname>Dodson</keyname><forenames>Maurice</forenames></author></authors><title>A Markov Chain based method for generating long-range dependence</title><categories>cs.NI cs.PF math.ST stat.TH</categories><comments>8 pages, 2 figures</comments><journal-ref>Phys. Rev. E 72, 026118 2005</journal-ref><doi>10.1103/PhysRevE.72.026118</doi><abstract>  This paper describes a model for generating time series which exhibit the
statistical phenomenon known as long-range dependence (LRD). A Markov Modulated
Process based upon an infinite Markov chain is described. The work described is
motivated by applications in telecommunications where LRD is a known property
of time-series measured on the internet. The process can generate a time series
exhibiting LRD with known parameters and is particularly suitable for modelling
internet traffic since the time series is in terms of ones and zeros which can
be interpreted as data packets and inter-packet gaps. The method is extremely
simple computationally and analytically and could prove more tractable than
other methods described in the literature
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610135</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610135</id><created>2006-10-23</created><updated>2006-12-18</updated><authors><author><keyname>Clegg</keyname><forenames>Richard G.</forenames></author></authors><title>Markov-modulated on/off processes for long-range dependent internet
  traffic</title><categories>cs.NI cs.DM cs.PF math.ST stat.TH</categories><comments>33 pages, 13 figures. Revised after comments and changed format.
  Added diagrams about queue overflow probabilities</comments><abstract>  The aim of this paper is to use a very simple queuing model to compare a
number of models from the literature which have been used to replicate the
statistical nature of internet traffic and, in particular, the long-range
dependence of this traffic. The four models all have the form of discrete time
Markov-modulated processes (two other models are introduced for comparison
purposes).
  While it is often stated that long-range dependence has a critical effect on
queuing performance, it appears that the models used here do not well
replicated the queuing performance of real internet traffic. In particular,
they fail to replicate the mean queue length (and hence the mean delay) and the
probability of the queue length exceeding a given level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610136</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610136</id><created>2006-10-24</created><updated>2007-09-21</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author></authors><title>Bounds on the coefficients of the characteristic and minimal polynomials</title><categories>cs.SC</categories><proxy>ccsd hal-00086820</proxy><journal-ref>Journal of Inequalities in Pure and Applied Mathematics 8, 2
  (2007) art. 31, 6pp</journal-ref><abstract>  This note presents absolute bounds on the size of the coefficients of the
characteristic and minimal polynomials depending on the size of the
coefficients of the associated matrix. Moreover, we present algorithms to
compute more precise input-dependant bounds on these coefficients. Such bounds
are e.g. useful to perform deterministic chinese remaindering of the
characteristic or minimal polynomial of an integer matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610137</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610137</id><created>2006-10-24</created><authors><author><keyname>Acciai</keyname><forenames>Lucia</forenames><affiliation>LIF</affiliation></author><author><keyname>Boreale</keyname><forenames>Michele</forenames><affiliation>LIF</affiliation></author><author><keyname>Zilio</keyname><forenames>Silvano Dal</forenames><affiliation>LIF</affiliation></author></authors><title>A Concurrent Calculus with Atomic Transactions</title><categories>cs.LO cs.DC</categories><comments>29 pages</comments><proxy>ccsd hal-00109264</proxy><abstract>  The Software Transactional Memory (STM) model is an original approach for
controlling concurrent accesses to ressources without the need for explicit
lock-based synchronization mechanisms. A key feature of STM is to provide a way
to group sequences of read and write actions inside atomic blocks, similar to
database transactions, whose whole effect should occur atomically. In this
paper, we investigate STM from a process algebra perspective and define an
extension of asynchronous CCS with atomic blocks of actions. Our goal is not
only to set a formal ground for reasoning on STM implementations but also to
understand how this model fits with other concurrency control mechanisms. We
also view this calculus as a test bed for extending process calculi with atomic
transactions. This is an interesting direction for investigation since, for the
most part, actual works that mix transactions with process calculi consider
compensating transactions, a model that lacks all the well-known ACID
properties. We show that the addition of atomic transactions results in a very
expressive calculus, enough to easily encode other concurrent primitives such
as guarded choice and multiset-synchronization (\`{a} la join-calculus). The
correctness of our encodings is proved using a suitable notion of bisimulation
equivalence. The equivalence is then applied to prove interesting ``laws of
transactions'' and to obtain a simple normal form for transactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610138</identifier>
 <datestamp>2007-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610138</id><created>2006-10-24</created><updated>2007-12-05</updated><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Why block length and delay behave differently if feedback is present</title><categories>cs.IT math.IT</categories><comments>42 pages, 22 figures</comments><abstract>  For output-symmetric DMCs at even moderately high rates, fixed-block-length
communication systems show no improvements in their error exponents with
feedback. In this paper, we study systems with fixed end-to-end delay and show
that feedback generally provides dramatic gains in the error exponents.
  A new upper bound (the uncertainty-focusing bound) is given on the
probability of symbol error in a fixed-delay communication system with
feedback. This bound turns out to have a similar form to Viterbi's bound used
for the block error probability of convolutional codes as a function of the
fixed constraint length. The uncertainty-focusing bound is shown to be
asymptotically achievable with noiseless feedback for erasure channels as well
as any output-symmetric DMC that has strictly positive zero-error capacity.
Furthermore, it can be achieved in a delay-universal (anytime) fashion even if
the feedback itself is delayed by a small amount. Finally, it is shown that for
end-to-end delay, it is generally possible at high rates to beat the
sphere-packing bound for general DMCs -- thereby providing a counterexample to
a conjecture of Pinsker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610139</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610139</id><created>2006-10-24</created><updated>2006-10-26</updated><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>How to beat the sphere-packing bound with feedback</title><categories>cs.IT math.IT</categories><comments>9 pages, 3 figures, corrected typos and increased font size.
  Submitted to IT Transactions</comments><abstract>  The sphere-packing bound $E_{sp}(R)$ bounds the reliability function for
fixed-length block-codes. For symmetric channels, it remains a valid bound even
when strictly causal noiseless feedback is allowed from the decoder to the
encoder. To beat the bound, the problem must be changed. While it has long been
known that variable-length block codes can do better when trading-off error
probability with expected block-length, this correspondence shows that the {\em
fixed-delay} setting also presents such an opportunity for generic channels.
  While $E_{sp}(R)$ continues to bound the tradeoff between bit error and fixed
end-to-end latency for symmetric channels used {\em without} feedback, a new
bound called the ``focusing bound'' gives the limits on what can be done with
feedback. If low-rate reliable flow-control is free (ie. the noisy channel has
strictly positive zero-error capacity), then the focusing bound can be
asymptotically achieved. Even when the channel has no zero-error capacity, it
is possible to substantially beat the sphere-packing bound by synthesizing an
appropriately reliable channel to carry the flow-control information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610140</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610140</id><created>2006-10-24</created><authors><author><keyname>Makarov</keyname><forenames>Leonid</forenames></author><author><keyname>Komarov</keyname><forenames>Peter</forenames></author></authors><title>Constant for associative patterns ensemble</title><categories>cs.AI</categories><comments>6 pages</comments><acm-class>I.2.6</acm-class><abstract>  Creation procedure of associative patterns ensemble in terms of formal logic
with using neural net-work (NN) model is formulated. It is shown that the
associative patterns set is created by means of unique procedure of NN work
which having individual parameters of entrance stimulus transformation. It is
ascer-tained that the quantity of the selected associative patterns possesses
is a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610141</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610141</id><created>2006-10-24</created><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Stabilization using both noisy and noiseless feedback</title><categories>cs.IT math.IT</categories><comments>9 pages, 5 figures, originally presented at MTNS 06</comments><abstract>  When designing a distributed control system, the system designer has a choice
in how to connect the different units through communication channels. In
practice, noiseless and noisy channels may coexist. Using the standard toy
example of scalar stabilization, this paper shows how a small amount of
noiseless feedback can perform a ``supervisory'' role and thereby boost the
effectiveness of noisy feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610142</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610142</id><created>2006-10-24</created><authors><author><keyname>Agarwal</keyname><forenames>Mukul</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author><author><keyname>Mitter</keyname><forenames>Sanjoy</forenames></author></authors><title>Coding into a source: a direct inverse Rate-Distortion theorem</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figure, orginally presented at Allerton 06</comments><abstract>  Shannon proved that if we can transmit bits reliably at rates larger than the
rate distortion function $R(D)$, then we can transmit this source to within a
distortion $D$. We answer the converse question ``If we can transmit a source
to within a distortion $D$, can we transmit bits reliably at rates less than
the rate distortion function?'' in the affirmative. This can be viewed as a
direct converse of the rate distortion theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610143</identifier>
 <datestamp>2007-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610143</id><created>2006-10-24</created><updated>2007-12-05</updated><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author><author><keyname>Mitter</keyname><forenames>Sanjoy</forenames></author></authors><title>Source coding and channel requirements for unstable processes</title><categories>cs.IT math.IT</categories><comments>37 pages, 9 figures. Cleaned up typos and reformatted paper for
  increased clarity</comments><abstract>  Our understanding of information in systems has been based on the foundation
of memoryless processes. Extensions to stable Markov and auto-regressive
processes are classical. Berger proved a source coding theorem for the
marginally unstable Wiener process, but the infinite-horizon exponentially
unstable case has been open since Gray's 1970 paper. There were also no
theorems showing what is needed to communicate such processes across noisy
channels.
  In this work, we give a fixed-rate source-coding theorem for the
infinite-horizon problem of coding an exponentially unstable Markov process.
The encoding naturally results in two distinct bitstreams that have
qualitatively different QoS requirements for communicating over a noisy medium.
The first stream captures the information that is accumulating within the
nonstationary process and requires sufficient anytime reliability from the
channel used to communicate the process. The second stream captures the
historical information that dissipates within the process and is essentially
classical. This historical information can also be identified with a natural
stable counterpart to the unstable process. A converse demonstrating the
fundamentally layered nature of unstable sources is given by means of
information-embedding ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610144</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610144</id><created>2006-10-24</created><authors><author><keyname>Chang</keyname><forenames>Cheng</forenames></author><author><keyname>Draper</keyname><forenames>Stark</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Lossless coding for distributed streaming sources</title><categories>cs.IT math.IT</categories><comments>40 pages, 11 figures, submitted to IT Transactions</comments><abstract>  Distributed source coding is traditionally viewed in the block coding context
-- all the source symbols are known in advance at the encoders. This paper
instead considers a streaming setting in which iid source symbol pairs are
revealed to the separate encoders in real time and need to be reconstructed at
the decoder with some tolerable end-to-end delay using finite rate noiseless
channels. A sequential random binning argument is used to derive a lower bound
on the error exponent with delay and show that both ML decoding and universal
decoding achieve the same positive error exponents inside the traditional
Slepian-Wolf rate region. The error events are different from the block-coding
error events and give rise to slightly different exponents. Because the
sequential random binning scheme is also universal over delays, the resulting
code eventually reconstructs every source symbol correctly with probability 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610145</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610145</id><created>2006-10-25</created><updated>2008-09-23</updated><authors><author><keyname>Berlin</keyname><forenames>Peter</forenames></author><author><keyname>Nakiboglu</keyname><forenames>Baris</forenames></author><author><keyname>Rimoldi</keyname><forenames>Bixio</forenames></author><author><keyname>Telatar</keyname><forenames>Emre</forenames></author></authors><title>A Simple Converse of Burnashev's Reliability</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure, updated missing reference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a remarkable paper published in 1976, Burnashev determined the reliability
function of variable-length block codes over discrete memoryless channels with
feedback. Subsequently, an alternative achievability proof was obtained by
Yamamoto and Itoh via a particularly simple and instructive scheme. Their idea
is to alternate between a communication and a confirmation phase until the
receiver detects the codeword used by the sender to acknowledge that the
message is correct. We provide a converse that parallels the Yamamoto-Itoh
achievability construction. Besides being simpler than the original, the
proposed converse suggests that a communication and a confirmation phase are
implicit in any scheme for which the probability of error decreases with the
largest possible exponent. The proposed converse also makes it intuitively
clear why the terms that appear in Burnashev's exponent are necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610146</identifier>
 <datestamp>2007-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610146</id><created>2006-10-25</created><updated>2007-12-05</updated><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author><author><keyname>Mitter</keyname><forenames>Sanjoy</forenames></author></authors><title>The necessity and sufficiency of anytime capacity for stabilization of a
  linear system over a noisy communication link, Part II: vector systems</title><categories>cs.IT math.IT</categories><comments>20 pages, 6 figures: significantly shortened and streamlined,
  improved example with a better bound</comments><abstract>  In part I, we reviewed how Shannon's classical notion of capacity is not
sufficient to characterize a noisy communication channel if the channel is
intended to be used as part of a feedback loop to stabilize an unstable scalar
linear system. While classical capacity is not enough, a sense of capacity
(parametrized by reliability) called &quot;anytime capacity&quot; is both necessary and
sufficient for channel evaluation in this context. The rate required is the log
of the open-loop system gain and the required reliability comes from the
desired sense of stability. Sufficiency is maintained even in cases with noisy
observations and without any explicit feedback between the observer and the
controller. This established the asymptotic equivalence between scalar
stabilization problems and delay-universal communication problems with
feedback.
  Here in part II, the vector-state generalizations are established and it is
the magnitudes of the unstable eigenvalues that play an essential role. To deal
with such systems, the concept of the anytime rate-region is introduced. This
is the region of rates that the channel can support while still meeting
potentially different anytime reliability targets for parallel message streams.
All the scalar results generalize on an eigenvalue by eigenvalue basis. When
there is no explicit feedback of the noisy channel outputs, the intrinsic delay
of the unstable system tells us what the feedback delay needs to be while
evaluating the anytime-rate-region for the channel. An example involving a
binary erasure channel is used to illustrate how differentiated service is
required in any separation-based control architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610147</identifier>
 <datestamp>2008-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610147</id><created>2006-10-25</created><authors><author><keyname>Liu</keyname><forenames>Kun-hong</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Huang</keyname><forenames>De-shuang</forenames></author><author><keyname>Cheng</keyname><forenames>Min</forenames></author></authors><title>Grooming of Dynamic Traffic in WDM Star and Tree Networks Using Genetic
  Algorithm</title><categories>cs.NI</categories><comments>15 pages</comments><journal-ref>Photonic Network Communications,Volume 15, Number 2, 2008</journal-ref><doi>10.1007/s11107-007-0103-0</doi><abstract>  The advances in WDM technology lead to the great interest in traffic grooming
problems. As traffic often changes from time to time, the problem of grooming
dynamic traffic is of great practical value. In this paper, we discuss dynamic
grooming of traffic in star and tree networks. A genetic algorithm (GA) based
approach is proposed to support arbitrary dynamic traffic patterns, which
minimizes the number of ADM's and wavelengths. To evaluate the algorithm,
tighter bounds are derived. Computer simulation results show that our algorithm
is efficient in reducing both the numbers of ADM's and wavelengths in tree and
star networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610148</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610148</id><created>2006-10-25</created><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Decoder Error Probability of MRD Codes</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures. Presented at ITW 2006, Chengdu, China</comments><abstract>  In this paper, we first introduce the concept of elementary linear subspace,
which has similar properties to those of a set of coordinates. Using this new
concept, we derive properties of maximum rank distance (MRD) codes that
parallel those of maximum distance separable (MDS) codes. Using these
properties, we show that the decoder error probability of MRD codes with error
correction capability t decreases exponentially with t^2 based on the
assumption that all errors with the same rank are equally likely. We argue that
the channel based on this assumption is an approximation of a channel corrupted
by crisscross errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610149</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610149</id><created>2006-10-26</created><updated>2007-01-31</updated><authors><author><keyname>Frid</keyname><forenames>A.</forenames></author></authors><title>Canonical decomposition of catenation of factorial languages</title><categories>cs.LO</categories><comments>Submitted</comments><abstract>  According to a previous result by S. V. Avgustinovich and the author, each
factorial language admits a unique canonical decomposition to a catenation of
factorial languages. In this paper, we analyze the appearance of the canonical
decomposition of a catenation of two factorial languages whose canonical
decompositions are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610150</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610150</id><created>2006-10-26</created><authors><author><keyname>Haroutunian</keyname><forenames>Evgueni A.</forenames><affiliation>Associate Member, IEEE</affiliation></author><author><keyname>Hakobyan</keyname><forenames>Parandzem M.</forenames></author></authors><title>On LAO Testing of Multiple Hypotheses for Many Independent Objects</title><categories>cs.IT math.IT</categories><abstract>  The problem of many hypotheses logarithmically asymptotically optimal (LAO)
testing for a model consisting of three or more independent objects is solved.
It is supposed that $M$ probability distributions are known and each object
independently of others follows to one of them. The matrix of asymptotic
interdependencies (reliability--reliability functions) of all possible pairs of
the error probability exponents (reliabilities) in optimal testing for this
model is studied.
  This problem was introduced (and solved for the case of two objects and two
given probability distributions) by Ahlswede and Haroutunian. The model with
two independent objects with $M$ hypotheses was explored by Haroutunian and
Hakobyan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610151</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610151</id><created>2006-10-26</created><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Anytime coding on the infinite bandwidth AWGN channel: A sequential
  semi-orthogonal optimal code</title><categories>cs.IT math.IT</categories><comments>12 pages, 6 figures, submitted to IT Transactions</comments><abstract>  It is well known that orthogonal coding can be used to approach the Shannon
capacity of the power-constrained AWGN channel without a bandwidth constraint.
This correspondence describes a semi-orthogonal variation of pulse position
modulation that is sequential in nature -- bits can be ``streamed across''
without having to buffer up blocks of bits at the transmitter. ML decoding
results in an exponentially small probability of error as a function of
tolerated receiver delay and thus eventually a zero probability of error on
every transmitted bit. In the high-rate regime, a matching upper bound is given
on the delay error exponent. We close with some comments on the case with
feedback and the connections to the capacity per unit cost problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610152</identifier>
 <datestamp>2007-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610152</id><created>2006-10-26</created><updated>2007-08-23</updated><authors><author><keyname>Mitra</keyname><forenames>Arindam</forenames></author></authors><title>An unbreakable cryptosystem for common people</title><categories>cs.CR</categories><comments>Pdf</comments><abstract>  It has been found that an algorithm can generate true random numbers on
classical computer. The algorithm can be used to generate unbreakable message
PIN (personal identification number) and password.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610153</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610153</id><created>2006-10-26</created><updated>2007-01-26</updated><authors><author><keyname>Calude</keyname><forenames>Cristian S.</forenames></author><author><keyname>Stay</keyname><forenames>Michael A.</forenames></author></authors><title>Most Programs Stop Quickly or Never Halt</title><categories>cs.IT math.IT</categories><comments>Shortened abstract and changed format of references to match Adv.
  Appl. Math guidelines</comments><report-no>CDMTCS-284</report-no><abstract>  Since many real-world problems arising in the fields of compiler
optimisation, automated software engineering, formal proof systems, and so
forth are equivalent to the Halting Problem--the most notorious undecidable
problem--there is a growing interest, not only academically, in understanding
the problem better and in providing alternative solutions. Halting computations
can be recognised by simply running them; the main difficulty is to detect
non-halting programs. Our approach is to have the probability space extend over
both space and time and to consider the probability that a random $N$-bit
program has halted by a random time. We postulate an a priori computable
probability distribution on all possible runtimes and we prove that given an
integer k&gt;0, we can effectively compute a time bound T such that the
probability that an N-bit program will eventually halt given that it has not
halted by T is smaller than 2^{-k}. We also show that the set of halting
programs (which is computably enumerable, but not computable) can be written as
a disjoint union of a computable set and a set of effectively vanishing
probability. Finally, we show that ``long'' runtimes are effectively rare. More
formally, the set of times at which an N-bit program can stop after the time
2^{N+constant} has effectively zero density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610154</identifier>
 <datestamp>2007-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610154</id><created>2006-10-26</created><updated>2006-10-26</updated><authors><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Usage Impact Factor: the effects of sample characteristics on
  usage-based impact metrics</title><categories>cs.DL</categories><comments>13 pages, 7 figures</comments><acm-class>H.3.7</acm-class><journal-ref>Journal of the American Society for Information Science and
  Technology, 59(1), 2008</journal-ref><abstract>  There exist ample demonstrations that indicators of scholarly impact
analogous to the citation-based ISI Impact Factor can be derived from usage
data. However, contrary to the ISI IF which is based on citation data generated
by the global community of scholarly authors, so far usage can only be
practically recorded at a local level leading to community-specific assessments
of scholarly impact that are difficult to generalize to the global scholarly
community. We define a journal Usage Impact Factor which mimics the definition
of the Thomson Scientific's ISI Impact Factor. Usage Impact Factor rankings are
calculated on the basis of a large-scale usage data set recorded for the
California State University system from 2003 to 2005. The resulting journal
rankings are then compared to Thomson Scientific's ISI Impact Factor which is
used as a baseline indicator of general impact. Our results indicate that
impact as derived from California State University usage reflects the
particular scientific and demographic characteristics of its communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610155</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610155</id><created>2006-10-27</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Hastie</keyname><forenames>Trevor J.</forenames></author><author><keyname>Church</keyname><forenames>Kenneth W.</forenames></author></authors><title>Nonlinear Estimators and Tail Bounds for Dimension Reduction in $l_1$
  Using Cauchy Random Projections</title><categories>cs.DS cs.IR cs.LG</categories><abstract>  For dimension reduction in $l_1$, the method of {\em Cauchy random
projections} multiplies the original data matrix $\mathbf{A}
\in\mathbb{R}^{n\times D}$ with a random matrix $\mathbf{R} \in
\mathbb{R}^{D\times k}$ ($k\ll\min(n,D)$) whose entries are i.i.d. samples of
the standard Cauchy C(0,1). Because of the impossibility results, one can not
hope to recover the pairwise $l_1$ distances in $\mathbf{A}$ from $\mathbf{B} =
\mathbf{AR} \in \mathbb{R}^{n\times k}$, using linear estimators without
incurring large errors. However, nonlinear estimators are still useful for
certain applications in data stream computation, information retrieval,
learning, and data mining.
  We propose three types of nonlinear estimators: the bias-corrected sample
median estimator, the bias-corrected geometric mean estimator, and the
bias-corrected maximum likelihood estimator. The sample median estimator and
the geometric mean estimator are asymptotically (as $k\to \infty$) equivalent
but the latter is more accurate at small $k$. We derive explicit tail bounds
for the geometric mean estimator and establish an analog of the
Johnson-Lindenstrauss (JL) lemma for dimension reduction in $l_1$, which is
weaker than the classical JL lemma for dimension reduction in $l_2$.
  Asymptotically, both the sample median estimator and the geometric mean
estimators are about 80% efficient compared to the maximum likelihood estimator
(MLE). We analyze the moments of the MLE and propose approximating the
distribution of the MLE by an inverse Gaussian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610156</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610156</id><created>2006-10-27</created><authors><author><keyname>D'Aquin</keyname><forenames>Mathieu</forenames><affiliation>INRIA Lorraine - LORIA, KMI</affiliation></author><author><keyname>Badra</keyname><forenames>Fadi</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lafrogne</keyname><forenames>Sandrine</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lieber</keyname><forenames>Jean</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Napoli</keyname><forenames>Amedeo</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Szathmary</keyname><forenames>Laszlo</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Adaptation Knowledge Discovery from a Case Base</title><categories>cs.AI</categories><proxy>ccsd hal-00110287</proxy><journal-ref>Proceedings of the 17th European Conference on Artificial
  Intelligence (ECAI-06), Trento G. Brewka (Ed.) (2006) 795--796</journal-ref><abstract>  In case-based reasoning, the adaptation step depends in general on
domain-dependent knowledge, which motivates studies on adaptation knowledge
acquisition (AKA). CABAMAKA is an AKA system based on principles of knowledge
discovery from databases. This system explores the variations within the case
base to elicit adaptation knowledge. It has been successfully tested in an
application of case-based decision support to breast cancer treatment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610157</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610157</id><created>2006-10-27</created><authors><author><keyname>Liu</keyname><forenames>Kun-hong</forenames></author><author><keyname>Xu</keyname><forenames>Yong</forenames></author><author><keyname>Huang</keyname><forenames>De-Shuang</forenames></author></authors><title>A Genetic Algorithm Approach to the Grooming of Dynamic Traffic in Tree
  and Star Networks with Bifurcation</title><categories>cs.NI</categories><comments>16 pages; Guangxi, Guilin, Proceeding of the 10th International
  Conference on Intelligent Technologies, pp. 524-533</comments><abstract>  Traffic grooming is widely employed to reduce the number of ADM's and
wavelengths. We consider the problem of grooming of dynamic traffic in WDM tree
and star networks in this paper. To achieve better results, we used the
bifurcation techniques to the grooming of arbitrary dynamic traffic in a
strictly non-blocking manner in networks. Three splitting methods, including
Traffic-Cutting, Traffic-Dividing and Synthesized-Splitting were proposed. A
genetic algorithm (GA) approach based on these methods was proposed to tackle
such grooming problems in tree and star networks. The performance of these
algorithms was tested under different conditions in star and tree networks.
Computer simulation results showed that our algorithm is efficient in reducing
both the numbers of ADM's and wavelengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610158</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610158</id><created>2006-10-27</created><authors><author><keyname>Afolabi</keyname><forenames>Babajide</forenames><affiliation>LORIA</affiliation></author><author><keyname>Thiery</keyname><forenames>Odile</forenames><affiliation>LORIA</affiliation></author></authors><title>Considering users' behaviours in improving the responses of an
  information base</title><categories>cs.LG cs.IR</categories><proxy>ccsd inria-00110334</proxy><journal-ref>Dans I International Conference on Multidisciplinary Information
  Sciences and Technologies (2006)</journal-ref><abstract>  In this paper, our aim is to propose a model that helps in the efficient use
of an information system by users, within the organization represented by the
IS, in order to resolve their decisional problems. In other words we want to
aid the user within an organization in obtaining the information that
corresponds to his needs (informational needs that result from his decisional
problems). This type of information system is what we refer to as economic
intelligence system because of its support for economic intelligence processes
of the organisation. Our assumption is that every EI process begins with the
identification of the decisional problem which is translated into an
informational need. This need is then translated into one or many information
search problems (ISP). We also assumed that an ISP is expressed in terms of the
user's expectations and that these expectations determine the activities or the
behaviors of the user, when he/she uses an IS. The model we are proposing is
used for the conception of the IS so that the process of retrieving of
solution(s) or the responses given by the system to an ISP is based on these
behaviours and correspond to the needs of the user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610159</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610159</id><created>2006-10-27</created><updated>2007-09-24</updated><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Calderbank</keyname><forenames>A. Robert</forenames></author></authors><title>Boolean Functions, Projection Operators and Quantum Error Correcting
  Codes</title><categories>cs.IT math.IT quant-ph</categories><comments>Submitted to IEEE Transactions on Information Theory, October 2006,
  to appear in IEEE Transactions on Information Theory, 2008</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 54, no. 4, pp.1700-1707, Apr. 2008.</journal-ref><doi>10.1109/TIT.2008.917720</doi><abstract>  This paper describes a fundamental correspondence between Boolean functions
and projection operators in Hilbert space. The correspondence is widely
applicable, and it is used in this paper to provide a common mathematical
framework for the design of both additive and non-additive quantum error
correcting codes. The new framework leads to the construction of a variety of
codes including an infinite class of codes that extend the original ((5,6,2))
code found by Rains [21]. It also extends to operator quantum error correcting
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610160</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610160</id><created>2006-10-29</created><authors><author><keyname>Rajan</keyname><forenames>G. Susinder</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Non-Orthogonal Distributed Space-Time Coded Protocol Part II-Code
  Construction and DM-G Tradeoff</title><categories>cs.IT math.IT</categories><comments>Proceedings 2006 IEEE Information Theory Workshop, Chengdu, China (5
  pages, No figures)</comments><journal-ref>Proceedings of IEEE ITW'06, Chengdu, China, October 22-26, 2006,
  pp. 488-492</journal-ref><abstract>  This is the second part of a two-part series of papers. In this paper, for
the generalized non-orthogonal amplify and forward (GNAF) protocol presented in
Part-I, a construction of a new family of distributed space-time codes based on
Co-ordinate Interleaved Orthogonal Designs (CIOD) which result in reduced
Maximum Likelihood (ML) decoding complexity at the destination is proposed.
Further, it is established that the recently proposed Toeplitz space-time codes
as well as space-time block codes (STBCs) from cyclic division algebras can be
used in GNAF protocol. Finally, a lower bound on the optimal
Diversity-Multiplexing Gain (DM-G) tradeoff for the GNAF protocol is
established and it is shown that this bound approaches the transmit diversity
bound asymptotically as the number of relays and the number of channels uses
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610161</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610161</id><created>2006-10-29</created><authors><author><keyname>Rajan</keyname><forenames>G. Susinder</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Non-Orthogonal Distributed Space-Time Coded Protocol Part I: Signal
  Model and Design Criteria</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, Proceedings of 2006 IEEE Information Theory
  Workshop (ITW'06), (A typo in equation (1) in the proceedings has been
  corrected.)</comments><journal-ref>Proceedings of 2006 IEEE Information Theory Workshop (ITW'06),
  Oct. 22-26, 2006, Chengdu, China, pp.385-389</journal-ref><abstract>  In this two-part series of papers, a generalized non-orthogonal amplify and
forward (GNAF) protocol which generalizes several known cooperative diversity
protocols is proposed. Transmission in the GNAF protocol comprises of two
phases - the broadcast phase and the cooperation phase. In the broadcast phase,
the source broadcasts its information to the relays as well as the destination.
In the cooperation phase, the source and the relays together transmit a
space-time code in a distributed fashion. The GNAF protocol relaxes the
constraints imposed by the protocol of Jing and Hassibi on the code structure.
In Part-I of this paper, a code design criteria is obtained and it is shown
that the GNAF protocol is delay efficient and coding gain efficient as well.
Moreover GNAF protocol enables the use of sphere decoders at the destination
with a non-exponential Maximum likelihood (ML) decoding complexity. In Part-II,
several low decoding complexity code constructions are studied and a lower
bound on the Diversity-Multiplexing Gain tradeoff of the GNAF protocol is
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610162</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610162</id><created>2006-10-29</created><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Multigroup-Decodable STBCs from Clifford Algebras</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, Proceedings of 2006 IEEE Information Theory
  Workshop (ITW 2006)</comments><journal-ref>Proceedings of 2006 IEEE Information Theory Workshop (ITW 2006),
  October 22-26, 2006, Chengdu, China, pp.448-452</journal-ref><abstract>  A Space-Time Block Code (STBC) in $K$ symbols (variables) is called $g$-group
decodable STBC if its maximum-likelihood decoding metric can be written as a
sum of $g$ terms such that each term is a function of a subset of the $K$
variables and each variable appears in only one term. In this paper we provide
a general structure of the weight matrices of multi-group decodable codes using
Clifford algebras. Without assuming that the number of variables in each group
to be the same, a method of explicitly constructing the weight matrices of
full-diversity, delay-optimal $g$-group decodable codes is presented for
arbitrary number of antennas. For the special case of $N_t=2^a$ we construct
two subclass of codes: (i) A class of $2a$-group decodable codes with rate
$\frac{a}{2^{(a-1)}}$, which is, equivalently, a class of Single-Symbol
Decodable codes, (ii) A class of $(2a-2)$-group decodable with rate
$\frac{(a-1)}{2^{(a-2)}}$, i.e., a class of Double-Symbol Decodable codes.
Simulation results show that the DSD codes of this paper perform better than
previously known Quasi-Orthogonal Designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610163</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610163</id><created>2006-10-30</created><authors><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Harwood</keyname><forenames>Aaron</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>A Taxonomy of Peer-to-Peer Based Complex Queries: a Grid perspective</title><categories>cs.NI cs.DC cs.DS</categories><abstract>  Grid superscheduling requires support for efficient and scalable discovery of
resources. Resource discovery activities involve searching for the appropriate
resource types that match the user's job requirements. To accomplish this goal,
a resource discovery system that supports the desired look-up operation is
mandatory. Various kinds of solutions to this problem have been suggested,
including the centralised and hierarchical information server approach.
However, both of these approaches have serious limitations in regards to
scalability, fault-tolerance and network congestion. To overcome these
limitations, organising resource information using Peer-to-Peer (P2P) network
model has been proposed. Existing approaches advocate an extension to
structured P2P protocols, to support the Grid resource information system
(GRIS). In this paper, we identify issues related to the design of such an
efficient, scalable, fault-tolerant, consistent and practical GRIS system using
a P2P network model. We compile these issues into various taxonomies in
sections III and IV. Further, we look into existing works that apply P2P based
network protocols to GRIS. We think that this taxonomy and its mapping to
relevant systems would be useful for academic and industry based researchers
who are engaged in the design of scalable Grid systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610164</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610164</id><created>2006-10-30</created><updated>2006-10-31</updated><authors><author><keyname>Karkare</keyname><forenames>Bageshri</forenames><affiliation>Sathe</affiliation></author><author><keyname>Khedker</keyname><forenames>Uday</forenames></author></authors><title>Complexity of Data Flow Analysis for Non-Separable Frameworks</title><categories>cs.PL</categories><comments>Published in the International Conference on Programming Languages
  and Compilers (PLC) 2006, Las Vegas, U.S.A</comments><abstract>  The complexity of round robin method of intraprocedural data flow analysis is
measured in number of iterations over the control flow graph. Existing
complexity bounds realistically explain the complexity of only Bit-vector
frameworks which are separable. In this paper we define the complexity bounds
for non-separable frameworks by quantifying the interdependences among the data
flow information of program entities using an Entity Dependence Graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610165</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610165</id><created>2006-10-30</created><authors><author><keyname>Liu</keyname><forenames>Fuchun</forenames></author><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Xing</keyname><forenames>Hongyan</forenames></author><author><keyname>Fan</keyname><forenames>Zhujun</forenames></author></authors><title>Decentralized Failure Diagnosis of Stochastic Discrete Event Systems</title><categories>cs.AI</categories><comments>25 pages. Comments and criticisms are welcome</comments><acm-class>F.1.2; I.2.8; G.3; I.6.8</acm-class><journal-ref>IEEE Transactions on Automatic Control, 53 (2) (2008) 535-546.</journal-ref><abstract>  Recently, the diagnosability of {\it stochastic discrete event systems}
(SDESs) was investigated in the literature, and, the failure diagnosis
considered was {\it centralized}. In this paper, we propose an approach to {\it
decentralized} failure diagnosis of SDESs, where the stochastic system uses
multiple local diagnosers to detect failures and each local diagnoser possesses
its own information. In a way, the centralized failure diagnosis of SDESs can
be viewed as a special case of the decentralized failure diagnosis presented in
this paper with only one projection. The main contributions are as follows: (1)
We formalize the notion of codiagnosability for stochastic automata, which
means that a failure can be detected by at least one local stochastic diagnoser
within a finite delay. (2) We construct a codiagnoser from a given stochastic
automaton with multiple projections, and the codiagnoser associated with the
local diagnosers is used to test codiagnosability condition of SDESs. (3) We
deal with a number of basic properties of the codiagnoser. In particular, a
necessary and sufficient condition for the codiagnosability of SDESs is
presented. (4) We give a computing method in detail to check whether
codiagnosability is violated. And (5) some examples are described to illustrate
the applications of the codiagnosability and its computing method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610166</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610166</id><created>2006-10-30</created><authors><author><keyname>Cachat</keyname><forenames>Thierry</forenames><affiliation>LIAFA</affiliation></author></authors><title>Tree Automata Make Ordinal Theory Easy</title><categories>cs.GT</categories><proxy>ccsd hal-00110485</proxy><journal-ref>Foundations of Software Technology and Theoretical Computer
  Science, 26th International Conference, 2006, Proceedings. FSTTCS 2006 (2006)
  286-297</journal-ref><abstract>  We give a new simple proof of the decidability of the First Order Theory of
(omega^omega^i,+) and the Monadic Second Order Theory of (omega^i,&lt;), improving
the complexity in both cases. Our algorithm is based on tree automata and a new
representation of (sets of) ordinals by (infinite) trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610167</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610167</id><created>2006-10-30</created><updated>2006-11-10</updated><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>ECA-RuleML: An Approach combining ECA Rules with temporal interval-based
  KR Event/Action Logics and Transactional Update Logics</title><categories>cs.AI cs.LO cs.MA cs.SE</categories><comments>Republished in Paschke, A.: ECA-RuleML/ECA-LP: A Homogeneous
  Event-Condition-Action Logic Programming Language, Int. Conf. of Rule Markup
  Languages (RuleML'06), Athens, Georgia, USA, 2006</comments><report-no>IBIS, TUM, Technical Report 11/05</report-no><acm-class>I.2; H.2.4; I.2.5; I.2.4; K.6.3</acm-class><abstract>  An important problem to be addressed within Event-Driven Architecture (EDA)
is how to correctly and efficiently capture and process the event/action-based
logic. This paper endeavors to bridge the gap between the Knowledge
Representation (KR) approaches based on durable events/actions and such
formalisms as event calculus, on one hand, and event-condition-action (ECA)
reaction rules extending the approach of active databases that view events as
instantaneous occurrences and/or sequences of events, on the other. We propose
formalism based on reaction rules (ECA rules) and a novel interval-based event
logic and present concrete RuleML-based syntax, semantics and implementation.
We further evaluate this approach theoretically, experimentally and on an
example derived from common industry use cases and illustrate its benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610168</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610168</id><created>2006-10-30</created><authors><author><keyname>Oluwade</keyname><forenames>Dele</forenames></author></authors><title>Presentation Theorems for Coded Character Sets</title><categories>cs.DM</categories><comments>14 pages, including a page of symbols and a page containing a table</comments><acm-class>G.2.0; E.4; I.1.1</acm-class><abstract>  The notion of 'presentation', as used in combinatorial group theory, is
applied to coded character sets(CCSs) - sets which facilitate the interchange
of messages in a digital computer network(DCN) . By grouping each element of
the set into two portions and using the idea of group presentation(whereby a
group is specified by its set of generators and its set of relators), the
presentation of a CCS is described. This is illustrated using the Extended
Binary Coded Decimal Interchange Code(EBCDIC) which is one of the most popular
CCSs in DCNs.
  Key words: Group presentation, coded character set, digital computer network
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610169</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610169</id><created>2006-10-30</created><authors><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir Keyvan</forenames></author></authors><title>On the User Selection for MIMO Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>57 pages 5 figures</comments><report-no>Technical Report #2005-16</report-no><abstract>  In this paper, a downlink communication system, in which a Base Station (BS)
equipped with $M$ antennas communicates with $N$ users each equipped with $K$
receive antennas, is considered. An efficient suboptimum algorithm is proposed
for selecting a set of users in order to maximize the sum-rate throughput of
the system. For the asymptotic case when $N$ tends to infinity, the necessary
and sufficient conditions in order to achieve the maximum sum-rate throughput,
such that the difference between the achievable sum-rate and the maximum value
approaches zero, is derived. The complexity of our algorithm is investigated in
terms of the required amount of feedback from the users to the base station, as
well as the number of searches required for selecting the users. It is shown
that the proposed method is capable of achieving a large portion of the
sum-rate capacity, with a very low complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610170</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610170</id><created>2006-10-30</created><authors><author><keyname>Szita</keyname><forenames>Istvan</forenames></author><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author></authors><title>Low-complexity modular policies: learning to play Pac-Man and a new
  framework beyond MDPs</title><categories>cs.LG cs.AI</categories><comments>23 pages</comments><abstract>  In this paper we propose a method that learns to play Pac-Man. We define a
set of high-level observation and action modules. Actions are temporally
extended, and multiple action modules may be in effect concurrently. A decision
of the agent is represented as a rule-based policy. For learning, we apply the
cross-entropy method, a recent global optimization algorithm. The learned
policies reached better score than the hand-crafted policy, and neared the
score of average human players. We argue that learning is successful mainly
because (i) the policy space includes the combination of individual actions and
thus it is sufficiently rich, (ii) the search is biased towards low-complexity
policies and low complexity solutions can be found quickly if they exist. Based
on these principles, we formulate a new theoretical framework, which can be
found in the Appendix as supporting material.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610171</identifier>
 <datestamp>2007-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610171</id><created>2006-10-31</created><authors><author><keyname>Marzuoli</keyname><forenames>Annalisa</forenames></author><author><keyname>Rasetti</keyname><forenames>Mario</forenames></author></authors><title>Coupling of quantum angular momenta: an insight into analogic/discrete
  and local/global models of computation</title><categories>cs.CC quant-ph</categories><comments>17 pages, 1 figure; Workshop `Natural processes and models of
  computation' Bologna (Italy) June 16-18 2005; to appear in Natural Computing</comments><journal-ref>Natural Computing Vol 6, No.2 (2007) 151-168</journal-ref><doi>10.1007/s11047-006-9018-4</doi><abstract>  In the past few years there has been a tumultuous activity aimed at
introducing novel conceptual schemes for quantum computing. The approach
proposed in (Marzuoli A and Rasetti M 2002, 2005a) relies on the (re)coupling
theory of SU(2) angular momenta and can be viewed as a generalization to
arbitrary values of the spin variables of the usual quantum-circuit model based
on `qubits' and Boolean gates. Computational states belong to
finite-dimensional Hilbert spaces labelled by both discrete and continuous
parameters, and unitary gates may depend on quantum numbers ranging over finite
sets of values as well as continuous (angular) variables. Such a framework is
an ideal playground to discuss discrete (digital) and analogic computational
processes, together with their relationships occuring when a consistent
semiclassical limit takes place on discrete quantum gates. When working with
purely discrete unitary gates, the simulator is naturally modelled as families
of quantum finite states--machines which in turn represent discrete versions of
topological quantum computation models. We argue that our model embodies a sort
of unifying paradigm for computing inspired by Nature and, even more
ambitiously, a universal setting in which suitably encoded quantum symbolic
manipulations of combinatorial, topological and algebraic problems might find
their `natural' computational reference model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610172</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610172</id><created>2006-10-30</created><authors><author><keyname>Wang</keyname><forenames>DaoShun</forenames></author><author><keyname>Yi</keyname><forenames>Feng</forenames></author><author><keyname>Li</keyname><forenames>Xiaobo</forenames></author><author><keyname>Luo</keyname><forenames>Ping</forenames></author><author><keyname>Dai</keyname><forenames>Yiqi</forenames></author></authors><title>On the Analysis and Generalization of Extended Visual Cryptography
  Schemes</title><categories>cs.CR</categories><abstract>  An Extended Visual Cryptography Scheme (EVCS) was proposed by Ateniese et al.
[3] to protect a binary secret image with meaningful (innocent-looking) shares.
This is implemented by concatenating an extended matrix to each basis matrix.
The minimum size of the extended matrix was obtained from a hypergraph coloring
model and the scheme was designed for binary images only [3]. In this paper, we
give a more concise derivation for this matrix extension for color images.
Furthermore, we present a (k, n) scheme to protect multiple color images with
meaningful shares. This scheme is an extension of the (n, n) VCS for multiple
binary images proposed in Droste scheme [2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610173</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610173</id><created>2006-10-31</created><authors><author><keyname>Xiao</keyname><forenames>Shi</forenames></author><author><keyname>Xiao</keyname><forenames>Gaoxi</forenames></author></authors><title>On Degree-Based Decentralized Search in Complex Networks</title><categories>cs.PF</categories><comments>6 pages, 3 figs, shortly published by ECCS'06</comments><abstract>  Decentralized search aims to find the target node in a large network by using
only local information. The applications of it include peer-to-peer file
sharing, web search and anything else that requires locating a specific target
in a complex system. In this paper, we examine the degree-based decentralized
search method. Specifically, we evaluate the efficiency of the method in
different cases with different amounts of available local information. In
addition, we propose a simple refinement algorithm for significantly shortening
the length of the route that has been found. Some insights useful for the
future developments of efficient decentralized search schemes have been
achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610174</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610174</id><created>2006-10-31</created><updated>2007-02-21</updated><authors><author><keyname>Samer</keyname><forenames>Marko</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>A Fixed-Parameter Algorithm for #SAT with Parameter Incidence Treewidth</title><categories>cs.DS cs.CC cs.LO</categories><comments>9 pages, 1 figure</comments><acm-class>F.2.2; F.4.1</acm-class><abstract>  We present an efficient fixed-parameter algorithm for #SAT parameterized by
the incidence treewidth, i.e., the treewidth of the bipartite graph whose
vertices are the variables and clauses of the given CNF formula; a variable and
a clause are joined by an edge if and only if the variable occurs in the
clause. Our algorithm runs in time O(4^k k l N), where k denotes the incidence
treewidth, l denotes the size of a largest clause, and N denotes the number of
nodes of the tree-decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610175</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610175</id><created>2006-10-31</created><authors><author><keyname>Dezert</keyname><forenames>Jean</forenames></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>DSmT: A new paradigm shift for information fusion</title><categories>cs.AI</categories><comments>11 pages. Presented to Cogis06 International Conference, Paris,
  France, 2006</comments><acm-class>I.4.8</acm-class><abstract>  The management and combination of uncertain, imprecise, fuzzy and even
paradoxical or high conflicting sources of information has always been and
still remains of primal importance for the development of reliable information
fusion systems. In this short survey paper, we present the theory of plausible
and paradoxical reasoning, known as DSmT (Dezert-Smarandache Theory) in
literature, developed for dealing with imprecise, uncertain and potentially
highly conflicting sources of information. DSmT is a new paradigm shift for
information fusion and recent publications have shown the interest and the
potential ability of DSmT to solve fusion problems where Dempster's rule used
in Dempster-Shafer Theory (DST) provides counter-intuitive results or fails to
provide useful result at all. This paper is focused on the foundations of DSmT
and on its main rules of combination (classic, hybrid and Proportional Conflict
Redistribution rules). Shafer's model on which is based DST appears as a
particular and specific case of DSm hybrid model which can be easily handled by
DSmT as well. Several simple but illustrative examples are given throughout
this paper to show the interest and the generality of this new theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611001</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611001</id><created>2006-11-01</created><authors><author><keyname>Elkin</keyname><forenames>Michael</forenames></author></authors><title>A near-optimal fully dynamic distributed algorithm for maintaining
  sparse spanners</title><categories>cs.DS</categories><abstract>  In this paper we devise an extremely efficient fully dynamic distributed
algorithm for maintaining sparse spanners. Our resuls also include the first
fully dynamic centralized algorithm for the problem with non-trivial bounds for
both incremental and decremental update. Finally, we devise a very efficient
streaming algorithm for the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611002</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611002</id><created>2006-11-01</created><authors><author><keyname>Servetto</keyname><forenames>Sergio D.</forenames><affiliation>Cornell University</affiliation></author></authors><title>Lattice Quantization with Side Information: Codes, Asymptotics, and
  Applications in Sensor Networks</title><categories>cs.IT math.IT</categories><comments>Final version, to appear in the IEEE Transactions on Information
  Theory, in February 2007 (first submission: March 2002)</comments><journal-ref>IEEE Transactions on Information Theory; 53(2):714-731, 2007.</journal-ref><abstract>  We consider the problem of rate/distortion with side information available
only at the decoder. For the case of jointly-Gaussian source X and side
information Y, and mean-squared error distortion, Wyner proved in 1976 that the
rate/distortion function for this problem is identical to the conditional
rate/distortion function R_{X|Y}, assuming the side information Y is available
at the encoder. In this paper we construct a structured class of asymptotically
optimal quantizers for this problem: under the assumption of high correlation
between source X and side information Y, we show there exist quantizers within
our class whose performance comes arbitrarily close to Wyner's bound. As an
application illustrating the relevance of the high-correlation asymptotics, we
also explore the use of these quantizers in the context of a problem of data
compression for sensor networks, in a setup involving a large number of devices
collecting highly correlated measurements within a confined area. An important
feature of our formulation is that, although the per-node throughput of the
network tends to zero as network size increases, so does the amount of
information generated by each transmitter. This is a situation likely to be
encountered often in practice, which allows us to cast under new--and more
``optimistic''--light some negative results on the transport capacity of
large-scale wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611003</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611003</id><created>2006-11-01</created><authors><author><keyname>Hu</keyname><forenames>An-swol</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Servetto</keyname><forenames>Sergio D.</forenames><affiliation>Cornell University</affiliation></author></authors><title>A Scalable Protocol for Cooperative Time Synchronization Using Spatial
  Averaging</title><categories>cs.NI cs.IT math.IT</categories><comments>Submitted to the IEEE/ACM Transactions on Networking, October 2006.
  See also cs.IT/0503031</comments><abstract>  Time synchronization is an important aspect of sensor network operation.
However, it is well known that synchronization error accumulates over multiple
hops. This presents a challenge for large-scale, multi-hop sensor networks with
a large number of nodes distributed over wide areas. In this work, we present a
protocol that uses spatial averaging to reduce error accumulation in
large-scale networks. We provide an analysis to quantify the synchronization
improvement achieved using spatial averaging and find that in a basic
cooperative network, the skew and offset variance decrease approximately as
$1/\bar{N}$ where $\bar{N}$ is the number of cooperating nodes. For general
networks, simulation results and a comparison to basic cooperative network
results are used to illustrate the improvement in synchronization performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611004</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611004</id><created>2006-11-01</created><updated>2006-11-04</updated><authors><author><keyname>Birkedal</keyname><forenames>Lars</forenames></author><author><keyname>M&#xf8;gelberg</keyname><forenames>Rasmus E.</forenames></author><author><keyname>lo</keyname><forenames>Rasmus Lerchedahl Petersen &#x142; he&#x142;</forenames></author></authors><title>Linear Abadi and Plotkin Logic</title><categories>cs.LO</categories><acm-class>F.4.1; D.3.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 5 (November
  3, 2006) lmcs:866</journal-ref><doi>10.2168/LMCS-2(5:2)2006</doi><abstract>  We present a formalization of a version of Abadi and
  Plotkin's logic for parametricity for a polymorphic dual
intuitionistic/linear type theory with fixed points, and show, following
Plotkin's suggestions, that it can be used to define a wide collection of
types, including existential types, inductive types, coinductive types and
general recursive types. We show that the recursive types satisfy a universal
property called dinaturality, and we develop reasoning principles for the
constructed types. In the case of recursive types, the reasoning principle is a
mixed induction/coinduction principle, with the curious property that
coinduction holds for general relations, but induction only for a limited
collection of ``admissible'' relations. A similar property was observed in
Pitts' 1995 analysis of recursive types in domain theory. In a future paper we
will develop a category theoretic notion of models of the logic presented here,
and show how the results developed in the logic can be transferred to the
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611005</id><created>2006-11-01</created><authors><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author><author><keyname>Yeomans</keyname><forenames>Joanne</forenames></author></authors><title>Protocols for Scholarly Communication</title><categories>cs.DL</categories><comments>8 pages, to appear in Library and Information Systems in Astronomy V</comments><report-no>CERN-OPEN-2006-053</report-no><abstract>  CERN, the European Organization for Nuclear Research, has operated an
institutional preprint repository for more than 10 years. The repository
contains over 850,000 records of which more than 450,000 are full-text OA
preprints, mostly in the field of particle physics, and it is integrated with
the library's holdings of books, conference proceedings, journals and other
grey literature. In order to encourage effective propagation and open access to
scholarly material, CERN is implementing a range of innovative library services
into its document repository: automatic keywording, reference extraction,
collaborative management tools and bibliometric tools. Some of these services,
such as user reviewing and automatic metadata extraction, could make up an
interesting testbed for future publishing solutions and certainly provide an
exciting environment for e-science possibilities. The future protocol for
scientific communication should naturally guide authors towards OA publication
and CERN wants to help reach a full open access publishing environment for the
particle physics community and the related sciences in the next few years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611006</id><created>2006-11-01</created><authors><author><keyname>Togelius</keyname><forenames>Julian</forenames></author><author><keyname>Lucas</keyname><forenames>Simon M.</forenames></author></authors><title>Evolving controllers for simulated car racing</title><categories>cs.NE cs.LG cs.RO</categories><comments>Won the CEC 2005 Best Student Paper Award</comments><journal-ref>Proceedings of the 2005 Congress on Evolutionary Computation,
  pages 1906-1913</journal-ref><abstract>  This paper describes the evolution of controllers for racing a simulated
radio-controlled car around a track, modelled on a real physical track. Five
different controller architectures were compared, based on neural networks,
force fields and action sequences. The controllers use either egocentric (first
person), Newtonian (third person) or no information about the state of the car
(open-loop controller). The only controller that was able to evolve good racing
behaviour was based on a neural network acting on egocentric inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611007</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611007</id><created>2006-11-01</created><updated>2006-11-03</updated><authors><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Gao</keyname><forenames>Xiqi</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>MIMO Multichannel Beamforming: SER and Outage Using New Eigenvalue
  Distributions of Complex Noncentral Wishart Matrices</title><categories>cs.IT math.IT</categories><comments>26 pages, 5 figures, to appear in IEEE Transactions on Communications</comments><abstract>  This paper analyzes MIMO systems with multichannel beamforming in Ricean
fading. Our results apply to a wide class of multichannel systems which
transmit on the eigenmodes of the MIMO channel. We first present new
closed-form expressions for the marginal ordered eigenvalue distributions of
complex noncentral Wishart matrices. These are used to characterize the
statistics of the signal to noise ratio (SNR) on each eigenmode. Based on this,
we present exact symbol error rate (SER) expressions. We also derive
closed-form expressions for the diversity order, array gain, and outage
probability. We show that the global SER performance is dominated by the
subchannel corresponding to the minimum channel singular value. We also show
that, at low outage levels, the outage probability varies inversely with the
Ricean K-factor for cases where transmission is only on the most dominant
subchannel (i.e. a singlechannel beamforming system). Numerical results are
presented to validate the theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611008</id><created>2006-11-02</created><authors><author><keyname>Hofman</keyname><forenames>Radoslaw</forenames></author></authors><title>Why Linear Programming cannot solve large instances of NP-complete
  problems in polynomial time</title><categories>cs.CC cs.DM cs.DS cs.NA</categories><acm-class>F.1; F.2</acm-class><abstract>  This article discusses ability of Linear Programming models to be used as
solvers of NP-complete problems. Integer Linear Programming is known as
NP-complete problem, but non-integer Linear Programming problems can be solved
in polynomial time, what places them in P class. During past three years there
appeared some articles using LP to solve NP-complete problems. This methods use
large number of variables (O(n^9)) solving correctly almost all instances that
can be solved in reasonable time. Can they solve infinitively large instances?
This article gives answer to this question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611009</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611009</id><created>2006-11-02</created><authors><author><keyname>Schulte</keyname><forenames>Christian</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author></authors><title>Efficient constraint propagation engines</title><categories>cs.AI cs.PL</categories><comments>45 pages, 1 figure, 14 tables</comments><acm-class>D.3.2; D.3.3</acm-class><journal-ref>ACM TOPLAS, 31(1) article 2, 2008</journal-ref><abstract>  This paper presents a model and implementation techniques for speeding up
constraint propagation. Three fundamental approaches to improving constraint
propagation based on propagators as implementations of constraints are
explored: keeping track of which propagators are at fixpoint, choosing which
propagator to apply next, and how to combine several propagators for the same
constraint. We show how idempotence reasoning and events help track fixpoints
more accurately. We improve these methods by using them dynamically (taking
into account current domains to improve accuracy). We define priority-based
approaches to choosing a next propagator and show that dynamic priorities can
improve propagation. We illustrate that the use of multiple propagators for the
same constraint can be advantageous with priorities, and introduce staged
propagators that combine the effects of multiple propagators with priorities
for greater efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611010</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611010</id><created>2006-11-02</created><authors><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>On the structure of generalized toric codes</title><categories>cs.IT math.IT</categories><journal-ref>The final version can be found in: Journal of Symbolic
  Computation. Volume 44, Issue 5, May 2009, Pages 499-506</journal-ref><abstract>  Toric codes are obtained by evaluating rational functions of a nonsingular
toric variety at the algebraic torus. One can extend toric codes to the so
called generalized toric codes. This extension consists on evaluating elements
of an arbitrary polynomial algebra at the algebraic torus instead of a linear
combination of monomials whose exponents are rational points of a convex
polytope. We study their multicyclic and metric structure, and we use them to
express their dual and to estimate their minimum distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611011</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611011</id><created>2006-11-02</created><authors><author><keyname>Gammerman</keyname><forenames>Alexander</forenames></author><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Hedging predictions in machine learning</title><categories>cs.LG</categories><comments>24 pages; 9 figures; 2 tables; a version of this paper (with
  discussion and rejoinder) is to appear in &quot;The Computer Journal&quot;</comments><report-no>On-line Compression Modelling Project (New Series), Working Paper 02</report-no><journal-ref>Computer Journal, 50:151-177, 2007</journal-ref><doi>10.1093/comjnl/bxl065</doi><abstract>  Recent advances in machine learning make it possible to design efficient
prediction algorithms for data sets with huge numbers of parameters. This paper
describes a new technique for &quot;hedging&quot; the predictions output by many such
algorithms, including support vector machines, kernel ridge regression, kernel
nearest neighbours, and by many other state-of-the-art methods. The hedged
predictions for the labels of new objects include quantitative measures of
their own accuracy and reliability. These measures are provably valid under the
assumption of randomness, traditional in machine learning: the objects and
their labels are assumed to be generated independently from the same
probability distribution. In particular, it becomes possible to control (up to
statistical fluctuations) the number of erroneous predictions by selecting a
suitable confidence level. Validity being achieved automatically, the remaining
goal of hedged prediction is efficiency: taking full account of the new
objects' features and other available information to produce as accurate
predictions as possible. This can be done successfully using the powerful
machinery of modern machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611012</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611012</id><created>2006-11-03</created><authors><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Gao</keyname><forenames>Xiqi</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Asymptotic SER and Outage Probability of MIMO MRC in Correlated Fading</title><categories>cs.IT math.IT</categories><comments>10 pages, 2 figures, to appear in IEEE Signal Processing Letters</comments><doi>10.1109/LSP.2006.881512</doi><abstract>  This letter derives the asymptotic symbol error rate (SER) and outage
probability of multiple-input multiple-output (MIMO) maximum ratio combining
(MRC) systems. We consider Rayleigh fading channels with both transmit and
receive spatial correlation. Our results are based on new asymptotic
expressions which we derive for the p.d.f. and c.d.f. of the maximum eigenvalue
of positive-definite quadratic forms in complex Gaussian matrices. We prove
that spatial correlation does not affect the diversity order, but that it
reduces the array gain and hence increases the SER in the high SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611013</id><created>2006-11-03</created><authors><author><keyname>Oliveira</keyname><forenames>Osvaldo N.</forenames><suffix>Jr.</suffix></author><author><keyname>Zucolotto</keyname><forenames>Valtencir</forenames></author><author><keyname>Aluisio</keyname><forenames>Sandra M.</forenames></author></authors><title>Developing strategies to produce better scientific papers: a Recipe for
  non-native users of English</title><categories>cs.OH</categories><comments>10 pages, 1 figure</comments><abstract>  In this paper we introduce the AMADEUS strategy, which has been used to
produce scientific writing tools for non-native users of English for 15 years,
and emphasize a learn-by-doing approach through which students and novice
writers can improve their scientific writing. More specifically, we provide a
9-step recipe for the students to compile writing material according to a
procedure that has proven efficient in scientific writing courses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611014</id><created>2006-11-03</created><authors><author><keyname>Braun</keyname><forenames>Erik</forenames></author><author><keyname>Luetticke</keyname><forenames>Rainer</forenames></author><author><keyname>Gloeckner</keyname><forenames>Ingo</forenames></author><author><keyname>Helbig</keyname><forenames>Hermann</forenames></author></authors><title>Interactive Problem Solving in Prolog</title><categories>cs.HC cs.CY cs.PL</categories><comments>4 pages, 1 figure, accepted for publication: Interactive computer
  aided learning (ICL) 2006, International Conference in Villach (Austria).
  Paper was not published because the authors were not able to participate on
  the conference</comments><acm-class>K.3.1; K.3.2; D.1.6; I.2.6; H.5.2</acm-class><abstract>  This paper presents an environment for solving Prolog problems which has been
implemented as a module for the virtual laboratory VILAB. During the problem
solving processes the learners get fast adaptive feedback. As a result
analysing the learner's actions the system suggests the use of suitable
auxiliary predicates which will also be checked for proper implementation. The
focus of the environment has been set on robustness and the integration in
VILAB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611015</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611015</id><created>2006-11-03</created><authors><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Sung</keyname><forenames>Chi Wan</forenames></author></authors><title>On the Fairness of Rate Allocation in Gaussian Multiple Access Channel
  and Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>26 pages</comments><abstract>  The capacity region of a channel consists of all achievable rate vectors.
Picking a particular point in the capacity region is synonymous with rate
allocation. The issue of fairness in rate allocation is addressed in this
paper. We review several notions of fairness, including max-min fairness,
proportional fairness and Nash bargaining solution. Their efficiencies for
general multiuser channels are discussed. We apply these ideas to the Gaussian
multiple access channel (MAC) and the Gaussian broadcast channel (BC). We show
that in the Gaussian MAC, max-min fairness and proportional fairness coincide.
For both Gaussian MAC and BC, we devise efficient algorithms that locate the
fair point in the capacity region. Some elementary properties of fair rate
allocations are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611016</id><created>2006-11-03</created><authors><author><keyname>Martin-Guillerez</keyname><forenames>Damien</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author><author><keyname>Ban&#xe2;tre</keyname><forenames>Michel</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author><author><keyname>Couderc</keyname><forenames>Paul</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author></authors><title>Increasing Data Resilience of Mobile Devices with a Collaborative Backup
  Service</title><categories>cs.NI</categories><proxy>ccsd inria-00111139</proxy><abstract>  Whoever has had his cell phone stolen knows how frustrating it is to be
unable to get his contact list back. To avoid data loss when losing or
destroying a mobile device like a PDA or a cell phone, data is usually
backed-up to a fixed station. However, in the time between the last backup and
the failure, important data can have been produced and then lost. To handle
this issue, we propose a transparent collaborative backup system. Indeed, by
saving data on other mobile devices between two connections to a global
infrastructure, we can resist to such scenarios. In this paper, after a general
description of such a system, we present a way to replicate data on mobile
devices to attain a prerequired resilience for the backup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611017</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611017</id><created>2006-11-03</created><authors><author><keyname>Kang</keyname><forenames>W.</forenames></author><author><keyname>Ulukus</keyname><forenames>S.</forenames></author></authors><title>A New Data Processing Inequality and Its Applications in Distributed
  Source and Channel Coding</title><categories>cs.IT math.IT</categories><comments>45 pages, 3 figures, submitted to IEEE Trans. Information Theory</comments><acm-class>H.1.1</acm-class><abstract>  In the distributed coding of correlated sources, the problem of
characterizing the joint probability distribution of a pair of random variables
satisfying an n-letter Markov chain arises. The exact solution of this problem
is intractable. In this paper, we seek a single-letter necessary condition for
this n-letter Markov chain. To this end, we propose a new data processing
inequality on a new measure of correlation by means of spectrum analysis. Based
on this new data processing inequality, we provide a single-letter necessary
condition for the required joint probability distribution. We apply our results
to two specific examples involving the distributed coding of correlated
sources: multi-terminal rate-distortion region and multiple access channel with
correlated sources, and propose new necessary conditions for these two
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611018</id><created>2006-11-03</created><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author></authors><title>Logic Column 17: A Rendezvous of Logic, Complexity, and Algebra</title><categories>cs.LO</categories><comments>30 pages</comments><abstract>  This article surveys recent advances in applying algebraic techniques to
constraint satisfaction problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611019</identifier>
 <datestamp>2007-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611019</id><created>2006-11-04</created><updated>2007-11-20</updated><authors><author><keyname>Bui-Xuan</keyname><forenames>Binh-Minh</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Habib</keyname><forenames>Michel</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Limouzy</keyname><forenames>Vincent</forenames><affiliation>LIAFA</affiliation></author><author><keyname>De Montgolfier</keyname><forenames>Fabien</forenames><affiliation>LIAFA</affiliation></author></authors><title>Algorithmic Aspects of a General Modular Decomposition Theory</title><categories>cs.DS</categories><proxy>ccsd hal-00111235</proxy><acm-class>E.1; G.2; G.2.2</acm-class><abstract>  A new general decomposition theory inspired from modular graph decomposition
is presented. This helps unifying modular decomposition on different
structures, including (but not restricted to) graphs. Moreover, even in the
case of graphs, the terminology ``module'' not only captures the classical
graph modules but also allows to handle 2-connected components, star-cutsets,
and other vertex subsets. The main result is that most of the nice algorithmic
tools developed for modular decomposition of graphs still apply efficiently on
our generalisation of modules. Besides, when an essential axiom is satisfied,
almost all the important properties can be retrieved. For this case, an
algorithm given by Ehrenfeucht, Gabow, McConnell and Sullivan 1994 is
generalised and yields a very efficient solution to the associated
decomposition problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611020</id><created>2006-11-04</created><authors><author><keyname>Bose</keyname><forenames>J.</forenames></author><author><keyname>Furber</keyname><forenames>S. B.</forenames></author><author><keyname>Shapiro</keyname><forenames>J. L.</forenames></author></authors><title>An associative memory for the on-line recognition and prediction of
  temporal sequences</title><categories>cs.NE cs.AI</categories><comments>Published in IJCNN 2005, Montreal, Canada</comments><doi>10.1109/IJCNN.2005.1556028</doi><abstract>  This paper presents the design of an associative memory with feedback that is
capable of on-line temporal sequence learning. A framework for on-line sequence
learning has been proposed, and different sequence learning models have been
analysed according to this framework. The network model is an associative
memory with a separate store for the sequence context of a symbol. A sparse
distributed memory is used to gain scalability. The context store combines the
functionality of a neural layer with a shift register. The sensitivity of the
machine to the sequence context is controllable, resulting in different
characteristic behaviours. The model can store and predict on-line sequences of
various types and length. Numerical simulations on the model have been carried
out to determine its properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611021</id><created>2006-11-05</created><authors><author><keyname>Vlad</keyname><forenames>Serban E.</forenames></author></authors><title>Relatively inertial delays</title><categories>cs.OH</categories><comments>the Eleventh Symposium of Mathematics and its Applications, November
  2-5, 2006, Timisoara, Romania</comments><abstract>  The paper studies the relatively inertial delays that represent one of the
most important concepts in the modeling of the asynchronous circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611022</id><created>2006-11-05</created><authors><author><keyname>Ganguli</keyname><forenames>Anurag</forenames></author><author><keyname>Cortes</keyname><forenames>Jorge</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Multirobot rendezvous with visibility sensors in nonconvex environments</title><categories>cs.RO</categories><comments>21 pages</comments><abstract>  This paper presents a coordination algorithm for mobile autonomous robots.
Relying upon distributed sensing the robots achieve rendezvous, that is, they
move to a common location. Each robot is a point mass moving in a nonconvex
environment according to an omnidirectional kinematic model. Each robot is
equipped with line-of-sight limited-range sensors, i.e., a robot can measure
the relative position of any object (robots or environment boundary) if and
only if the object is within a given distance and there are no obstacles
in-between. The algorithm is designed using the notions of robust visibility,
connectivity-preserving constraint sets, and proximity graphs. Simulations
illustrate the theoretical results on the correctness of the proposed
algorithm, and its performance in asynchronous setups and with sensor
measurement and control errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611023</id><created>2006-11-05</created><authors><author><keyname>Baswana</keyname><forenames>Surender</forenames></author></authors><title>Faster Streaming algorithms for graph spanners</title><categories>cs.DS</categories><comments>16 pages</comments><abstract>  Given an undirected graph $G=(V,E)$ on $n$ vertices, $m$ edges, and an
integer $t\ge 1$, a subgraph $(V,E_S)$, $E_S\subseteq E$ is called a
$t$-spanner if for any pair of vertices $u,v \in V$, the distance between them
in the subgraph is at most $t$ times the actual distance. We present streaming
algorithms for computing a $t$-spanner of essentially optimal size-stretch
trade offs for any undirected graph.
  Our first algorithm is for the classical streaming model and works for
unweighted graphs only. The algorithm performs a single pass on the stream of
edges and requires $O(m)$ time to process the entire stream of edges. This
drastically improves the previous best single pass streaming algorithm for
computing a $t$-spanner which requires $\theta(mn^{\frac{2}{t}})$ time to
process the stream and computes spanner with size slightly larger than the
optimal.
  Our second algorithm is for {\em StreamSort} model introduced by Aggarwal et
al. [FOCS 2004], which is the streaming model augmented with a sorting
primitive. The {\em StreamSort} model has been shown to be a more powerful and
still very realistic model than the streaming model for massive data sets
applications. Our algorithm, which works of weighted graphs as well, performs
$O(t)$ passes using $O(\log n)$ bits of working memory only.
  Our both the algorithms require elementary data structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611024</id><created>2006-11-06</created><authors><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author><author><keyname>Ye</keyname><forenames>Tong</forenames></author></authors><title>A Relational Approach to Functional Decomposition of Logic Circuits</title><categories>cs.DM cs.LG</categories><comments>29 pages, 12 figures, submitted to Discrete Applied Mathematics</comments><abstract>  Functional decomposition of logic circuits has profound influence on all
quality aspects of the cost-effective implementation of modern digital systems.
In this paper, a relational approach to the decomposition of logic circuits is
proposed. This approach is parallel to the normalization of relational
databases, they are governed by the same concepts of functional dependency (FD)
and multi-valued dependency (MVD). It is manifest that the functional
decomposition of switching function actually exploits the same idea and serves
a similar purpose as database normalization. Partitions play an important role
in the decomposition. The interdependency of two partitions can be represented
by a bipartite graph. We demonstrate that both FD and MVD can be represented by
bipartite graphs with specific topological properties, which are delineated by
partitions of minterms. It follows that our algorithms are procedures of
constructing those specific bipartite graphs of interest to meet the
information-lossless criteria of functional decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611025</id><created>2006-11-06</created><authors><author><keyname>Larrosa</keyname><forenames>Javier</forenames></author><author><keyname>Heras</keyname><forenames>Federico</forenames></author><author><keyname>de Givry</keyname><forenames>Simon</forenames></author></authors><title>A Logical Approach to Efficient Max-SAT solving</title><categories>cs.AI cs.LO</categories><abstract>  Weighted Max-SAT is the optimization version of SAT and many important
problems can be naturally encoded as such. Solving weighted Max-SAT is an
important problem from both a theoretical and a practical point of view. In
recent years, there has been considerable interest in finding efficient solving
techniques. Most of this work focus on the computation of good quality lower
bounds to be used within a branch and bound DPLL-like algorithm. Most often,
these lower bounds are described in a procedural way. Because of that, it is
difficult to realize the {\em logic} that is behind.
  In this paper we introduce an original framework for Max-SAT that stresses
the parallelism with classical SAT. Then, we extend the two basic SAT solving
techniques: {\em search} and {\em inference}. We show that many algorithmic
{\em tricks} used in state-of-the-art Max-SAT solvers are easily expressable in
{\em logic} terms with our framework in a unified manner.
  Besides, we introduce an original search algorithm that performs a restricted
amount of {\em weighted resolution} at each visited node. We empirically
compare our algorithm with a variety of solving alternatives on several
benchmarks. Our experiments, which constitute to the best of our knowledge the
most comprehensive Max-sat evaluation ever reported, show that our algorithm is
generally orders of magnitude faster than any competitor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611026</id><created>2006-11-06</created><authors><author><keyname>Salmon-Alt</keyname><forenames>Susanne</forenames><affiliation>ATILF</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Pierrel</keyname><forenames>Jean-Marie</forenames><affiliation>ATILF</affiliation></author></authors><title>Un mod\`ele g\'en\'erique d'organisation de corpus en ligne: application
  \`a la FReeBank</title><categories>cs.CL</categories><proxy>ccsd hal-00110970</proxy><journal-ref>Traitement Automatique des Langues (TAL) 45 (2006) 145-169</journal-ref><abstract>  The few available French resources for evaluating linguistic models or
algorithms on other linguistic levels than morpho-syntax are either
insufficient from quantitative as well as qualitative point of view or not
freely accessible. Based on this fact, the FREEBANK project intends to create
French corpora constructed using manually revised output from a hybrid
Constraint Grammar parser and annotated on several linguistic levels
(structure, morpho-syntax, syntax, coreference), with the objective to make
them available on-line for research purposes. Therefore, we will focus on using
standard annotation schemes, integration of existing resources and maintenance
allowing for continuous enrichment of the annotations. Prior to the actual
presentation of the prototype that has been implemented, this paper describes a
generic model for the organization and deployment of a linguistic resource
archive, in compliance with the various works currently conducted within
international standardization initiatives (TEI and ISO/TC 37/SC 4).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611027</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611027</id><created>2006-11-06</created><authors><author><keyname>Bhaskar</keyname><forenames>Raghav</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>M&#xfc;hlethaler</keyname><forenames>Paul</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Augot</keyname><forenames>Daniel</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Adjih</keyname><forenames>Cdric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Boudjit</keyname><forenames>Saadi</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Laouiti</keyname><forenames>Anis</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Efficient and Dynamic Group Key Agreement in Ad hoc Networks</title><categories>cs.CR</categories><proxy>ccsd inria-00071348</proxy><abstract>  Confidentiality, integrity and authentication are more relevant issues in Ad
hoc networks than in wired fixed networks. One way to address these issues is
the use of symmetric key cryptography, relying on a secret key shared by all
members of the network. But establishing and maintaining such a key (also
called the session key) is a non-trivial problem. We show that Group Key
Agreement (GKA) protocols are suitable for establishing and maintaining such a
session key in these dynamic networks. We take an existing GKA protocol, which
is robust to connectivity losses and discuss all the issues for good
functioning of this protocol in Ad hoc networks. We give implementation details
and network parameters, which significantly reduce the computational burden of
using public key cryptography in such networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611028</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611028</id><created>2006-11-06</created><updated>2007-06-18</updated><authors><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author></authors><title>A Decomposition Theory for Binary Linear Codes</title><categories>cs.DM cs.IT math.IT</categories><comments>37 pages, 4 figures; submitted to IEEE Transactions on Information
  Theory, Nov 2006; revised June 2007</comments><abstract>  The decomposition theory of matroids initiated by Paul Seymour in the 1980's
has had an enormous impact on research in matroid theory. This theory, when
applied to matrices over the binary field, yields a powerful decomposition
theory for binary linear codes. In this paper, we give an overview of this code
decomposition theory, and discuss some of its implications in the context of
the recently discovered formulation of maximum-likelihood (ML) decoding of a
binary linear code over a discrete memoryless channel as a linear programming
problem. We translate matroid-theoretic results of Gr\&quot;otschel and Truemper
from the combinatorial optimization literature to give examples of non-trivial
families of codes for which the ML decoding problem can be solved in time
polynomial in the length of the code. One such family is that consisting of
codes $C$ for which the codeword polytope is identical to the Koetter-Vontobel
fundamental polytope derived from the entire dual code $C^\perp$. However, we
also show that such families of codes are not good in a coding-theoretic sense
-- either their dimension or their minimum distance must grow sub-linearly with
codelength. As a consequence, we have that decoding by linear programming, when
applied to good codes, cannot avoid failing occasionally due to the presence of
pseudocodewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611029</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611029</id><created>2006-11-06</created><updated>2006-11-16</updated><authors><author><keyname>Biere</keyname><forenames>Armin</forenames></author><author><keyname>Heljanko</keyname><forenames>Keijo</forenames></author><author><keyname>Junttila</keyname><forenames>Tommi</forenames></author><author><keyname>Latvala</keyname><forenames>Timo</forenames></author><author><keyname>Schuppan</keyname><forenames>Viktor</forenames></author></authors><title>Linear Encodings of Bounded LTL Model Checking</title><categories>cs.LO</categories><comments>Final version for Logical Methods in Computer Science CAV 2005
  special issue</comments><acm-class>F.3.1; B.6.3; D.2.4; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 5 (November
  15, 2006) lmcs:892</journal-ref><doi>10.2168/LMCS-2(5:5)2006</doi><abstract>  We consider the problem of bounded model checking (BMC) for linear temporal
logic (LTL). We present several efficient encodings that have size linear in
the bound. Furthermore, we show how the encodings can be extended to LTL with
past operators (PLTL). The generalised encoding is still of linear size, but
cannot detect minimal length counterexamples. By using the virtual unrolling
technique minimal length counterexamples can be captured, however, the size of
the encoding is quadratic in the specification. We also extend virtual
unrolling to Buchi automata, enabling them to accept minimal length
counterexamples.
  Our BMC encodings can be made incremental in order to benefit from
incremental SAT technology. With fairly small modifications the incremental
encoding can be further enhanced with a termination check, allowing us to prove
properties with BMC. Experiments clearly show that our new encodings improve
performance of BMC considerably, particularly in the case of the incremental
encoding, and that they are very competitive for finding bugs. An analysis of
the liveness-to-safety transformation reveals many similarities to the BMC
encodings in this paper. Using the liveness-to-safety translation with
BDD-based invariant checking results in an efficient method to find shortest
counterexamples that complements the BMC-based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611030</identifier>
 <datestamp>2007-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611030</id><created>2006-11-07</created><updated>2007-09-12</updated><authors><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author></authors><title>Nonextensive Pythagoras' Theorem</title><categories>cs.IT math.IT</categories><comments>19 pages</comments><abstract>  Kullback-Leibler relative-entropy, in cases involving distributions resulting
from relative-entropy minimization, has a celebrated property reminiscent of
squared Euclidean distance: it satisfies an analogue of the Pythagoras'
theorem. And hence, this property is referred to as Pythagoras' theorem of
relative-entropy minimization or triangle equality and plays a fundamental role
in geometrical approaches of statistical estimation theory like information
geometry. Equvalent of Pythagoras' theorem in the generalized nonextensive
formalism is established in (Dukkipati at el., Physica A, 361 (2006) 124-138).
In this paper we give a detailed account of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611031</id><created>2006-11-07</created><updated>2007-05-01</updated><authors><author><keyname>Anderson</keyname><forenames>Scot</forenames></author><author><keyname>Revesz</keyname><forenames>Peter</forenames></author></authors><title>Efficient Threshold Aggregation of Moving Objects</title><categories>cs.DB</categories><comments>Technical report on spatiotemporal aggregation prior to journal
  submission</comments><abstract>  Calculating aggregation operators of moving point objects, using time as a
continuous variable, presents unique problems when querying for congestion in a
moving and changing (or dynamic) query space. We present a set of congestion
query operators, based on a threshold value, that estimate the following 5
aggregation operations in d-dimensions. 1) We call the count of point objects
that intersect the dynamic query space during the query time interval, the
CountRange. 2) We call the Maximum (or Minimum) congestion in the dynamic query
space at any time during the query time interval, the MaxCount (or MinCount).
3) We call the sum of time that the dynamic query space is congested, the
ThresholdSum. 4) We call the number of times that the dynamic query space is
congested, the ThresholdCount. And 5) we call the average length of time of all
the time intervals when the dynamic query space is congested, the
ThresholdAverage. These operators rely on a novel approach to transforming the
problem of selection based on position to a problem of selection based on a
threshold. These operators can be used to predict concentrations of migrating
birds that may carry disease such as Bird Flu and hence the information may be
used to predict high risk areas. On a smaller scale, those operators are also
applicable to maintaining safety in airplane operations. We present the theory
of our estimation operators and provide algorithms for exact operators. The
implementations of those operators, and experiments, which include data from
more than 7500 queries, indicate that our estimation operators produce fast,
efficient results with error under 5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611032</identifier>
 <datestamp>2008-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611032</id><created>2006-11-07</created><updated>2007-04-08</updated><authors><author><keyname>Nathan</keyname><forenames>Andre</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>V-like formations in flocks of artificial birds</title><categories>cs.NE</categories><journal-ref>Artificial Life 14 (2008), 179-188</journal-ref><doi>10.1162/artl.2008.14.2.179</doi><abstract>  We consider flocks of artificial birds and study the emergence of V-like
formations during flight. We introduce a small set of fully distributed
positioning rules to guide the birds' movements and demonstrate, by means of
simulations, that they tend to lead to stabilization into several of the
well-known V-like formations that have been observed in nature. We also provide
quantitative indicators that we believe are closely related to achieving V-like
formations, and study their behavior over a large set of independent
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611033</id><created>2006-11-08</created><authors><author><keyname>Plasencia</keyname><forenames>Maria Naya</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Cryptanalyse de Achterbahn-128/80</title><categories>cs.CR</categories><proxy>ccsd inria-00111964</proxy><abstract>  This paper presents two attacks against Achterbahn-128/80, the last version
of one of the stream cipher proposals in the eSTREAM project. The attack
against the 80-bit variant, Achterbahn-80, has complexity 2^{56.32}. The attack
against Achterbahn-128 requires 2^{75.4} operations and 2^{61} keystream bits.
These attacks are based on an improvement of the attack due to Hell and
Johansson against Achterbahn version 2 and also on an algorithm that makes
profit of the short lengths of the constituent registers.
  *****
  Ce papier pr\'{e}sente deux attaques sur Achterbahn-128/80, la derni\`{e}re
version d'un des algorithmes propos\'{e}s dans le cadre de eSTREAM. L'attaque
sur la version de 80 bits, Achterbahn-80, est en 2^{56.32}. L'attaque sur
Achterbahn-128 a besoin de 2^{75.4} calculs et 2^{61} bits de suite chiffrante.
Ces attaques sont bas\'{e}es sur une am\'{e}lioration de l'attaque propos\'{e}e
par Hell et Johansson sur la version 2 d'Achterbahn et aussi sur un algorithme
qui tire profit des petites longueurs des registres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611034</id><created>2006-11-08</created><authors><author><keyname>Robert</keyname><forenames>Yves</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Benoit</keyname><forenames>Anne</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Rehn</keyname><forenames>Veronika</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author></authors><title>Strategies for Replica Placement in Tree Networks</title><categories>cs.DC</categories><proxy>ccsd inria-00111963</proxy><abstract>  In this paper, we discuss and compare several policies to place replicas in
tree networks, subject to server capacity and QoS constraints. The client
requests are known beforehand, while the number and location of the servers are
to be determined. The standard approach in the literature is to enforce that
all requests of a client be served by the closest server in the tree. We
introduce and study two new policies. In the first policy, all requests from a
given client are still processed by the same server, but this server can be
located anywhere in the path from the client to the root. In the second policy,
the requests of a given client can be processed by multiple servers. One major
contribution of this paper is to assess the impact of these new policies on the
total replication cost. Another important goal is to assess the impact of
server heterogeneity, both from a theoretical and a practical perspective. In
this paper, we establish several new complexity results, and provide several
efficient polynomial heuristics for NP-complete instances of the problem. These
heuristics are compared to an absolute lower bound provided by the formulation
of the problem in terms of the solution of an integer linear program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611035</id><created>2006-11-08</created><authors><author><keyname>Bettini</keyname><forenames>Claudio</forenames></author><author><keyname>Wang</keyname><forenames>X. Sean</forenames></author><author><keyname>Jajodia</keyname><forenames>Sushil</forenames></author></authors><title>The Role of Quasi-identifiers in k-Anonymity Revisited</title><categories>cs.DB cs.CR</categories><comments>17 pages. Submitted for publication</comments><report-no>RT-11-06</report-no><abstract>  The concept of k-anonymity, used in the recent literature to formally
evaluate the privacy preservation of published tables, was introduced based on
the notion of quasi-identifiers (or QI for short). The process of obtaining
k-anonymity for a given private table is first to recognize the QIs in the
table, and then to anonymize the QI values, the latter being called
k-anonymization. While k-anonymization is usually rigorously validated by the
authors, the definition of QI remains mostly informal, and different authors
seem to have different interpretations of the concept of QI. The purpose of
this paper is to provide a formal underpinning of QI and examine the
correctness and incorrectness of various interpretations of QI in our formal
framework. We observe that in cases where the concept has been used correctly,
its application has been conservative; this note provides a formal
understanding of the conservative nature in such cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611036</id><created>2006-11-08</created><authors><author><keyname>Durand</keyname><forenames>Anne</forenames><affiliation>CRAI</affiliation></author><author><keyname>Drap</keyname><forenames>Pierre</forenames><affiliation>CRAI</affiliation></author><author><keyname>Meyer</keyname><forenames>Elise</forenames><affiliation>CRAI</affiliation></author><author><keyname>Grussenmeyer</keyname><forenames>Pierre</forenames><affiliation>CRAI</affiliation></author><author><keyname>Perrin</keyname><forenames>Jean-Pierre</forenames><affiliation>CRAI</affiliation></author></authors><title>Intra-site Level Cultural Heritage Documentation: Combination of Survey,
  Modeling and Imagery Data in a Web Information System</title><categories>cs.DL</categories><proxy>ccsd hal-00112406</proxy><abstract>  Cultural heritage documentation induces the use of computerized techniques to
manage and preserve the information produced. Geographical information systems
have proved their potentialities in this scope, but they are not always adapted
for the management of features at the scale of a particular archaeological
site. Moreover, computer applications in archaeology are often technology
driven and software constrained. Thus, we propose a tool that tries to avoid
these difficulties. We are developing an information system that works over the
Internet and that is joined with a web site. Aims are to assist the work of
archaeological sites managers and to be a documentation tool about these sites,
dedicated to everyone. We devote therefore our system both to the professionals
who are in charge of the site, and to the general public who visits it or who
wants to have information on it. The system permits to do exploratory analyses
of the data, especially at spatial and temporal levels. We propose to record
metadata about the archaeological features in XML and to access these features
through interactive 2D and 3D representations, and through queries systems
(keywords and images). The 2D images, photos, or vectors are generated in SVG,
while 3D models are generated in X3D. Archaeological features are also
automatically integrated in a MySQL database. The web site is an exchange
platform with the information system and is written in PHP. Our first
application case is the medieval castle of Vianden, Luxembourg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611037</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611037</id><created>2006-11-08</created><updated>2007-04-17</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>On Conditional Branches in Optimal Decision Trees</title><categories>cs.PF cs.IT math.IT</categories><comments>5 pages, 2 illustrations; conference version of cs.PF/0604016,
  accepted to ISIT 2007</comments><acm-class>B.1.4; C.0; C.1.1; D.3.4; E.1; F.2.2; G.3; H.3.3; I.2.8</acm-class><abstract>  The decision tree is one of the most fundamental programming abstractions. A
commonly used type of decision tree is the alphabetic binary tree, which uses
(without loss of generality) ``less than'' versus ''greater than or equal to''
tests in order to determine one of $n$ outcome events. The process of finding
an optimal alphabetic binary tree for a known probability distribution on
outcome events usually has the underlying assumption that the cost (time) per
decision is uniform and thus independent of the outcome of the decision. This
assumption, however, is incorrect in the case of software to be optimized for a
given microprocessor, e.g., in compiling switch statements or in fine-tuning
program bottlenecks. The operation of the microprocessor generally means that
the cost for the more likely decision outcome can or will be less -- often far
less -- than the less likely decision outcome. Here we formulate a variety of
$O(n^3)$-time $O(n^2)$-space dynamic programming algorithms to solve such
optimal binary decision tree problems, optimizing for the behavior of
processors with predictive branch capabilities, both static and dynamic. In the
static case, we use existing results to arrive at entropy-based performance
bounds. Solutions to this formulation are often faster in practice than
``optimal'' decision trees as formulated in the literature, and, for small
problems, are easily worth the extra complexity in finding the better solution.
This can be applied in fast implementation of decoding Huffman codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611038</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611038</id><created>2006-11-09</created><authors><author><keyname>Liu</keyname><forenames>Chengshi</forenames></author></authors><title>Nonsymmetric entropy I: basic concepts and results</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><abstract>  A new concept named nonsymmetric entropy which generalizes the concepts of
Boltzman's entropy and shannon's entropy, was introduced. Maximal nonsymmetric
entropy principle was proven. Some important distribution laws were derived
naturally from maximal nonsymmetric entropy principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611039</id><created>2006-11-09</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author><author><keyname>Skordev</keyname><forenames>Guentcho</forenames></author></authors><title>Substitutions for tilings $\{p,q\}$</title><categories>cs.CG cs.DM</categories><report-no>2005-102 (Publications du LITA, local research reports)</report-no><acm-class>F.2.2; G.2</acm-class><abstract>  In this paper we consider tiling $\{p, q \}$ of the Euclidean space and of
the hyperbolic space, and its dual graph $\Gamma_{q, p}$ from a combinatorial
point of view. A substitution $\sigma_{q, p}$ on an appropriate finite alphabet
is constructed. The homogeneity of graph $\Gamma_{q, p}$ and its generation
function are the basic tools for the construction. The tree associated with
substitution $\sigma_{q, p}$ is a spanning tree of graph $\Gamma_{q, p}$. Let
$u_n$ be the number of tiles of tiling $\{p, q \}$ of generation $n$. The
characteristic polynomial of the transition matrix of substitution $\sigma_{q,
p}$ is a characteristic polynomial of a linear recurrence. The sequence
$(u_n)_{n \geq 0}$ is a solution of this recurrence. The growth of sequence
$(u_n)_{n \geq 0}$ is given by the dominant root of the characteristic
polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611040</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611040</id><created>2006-11-09</created><updated>2008-09-25</updated><authors><author><keyname>Guidi</keyname><forenames>F.</forenames></author></authors><title>The Formal System lambda-delta</title><categories>cs.LO</categories><comments>44 pages, final version for ToCL (with minor changes wrt previous)</comments><report-no>UBLCS-2006-25</report-no><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The formal system lambda-delta is a typed lambda calculus that pursues the
unification of terms, types, environments and contexts as the main goal.
lambda-delta takes some features from the Automath-related lambda calculi and
some from the pure type systems, but differs from both in that it does not
include the Pi construction while it provides for an abbreviation mechanism at
the level of terms. lambda-delta enjoys some important desirable properties
such as the confluence of reduction, the correctness of types, the uniqueness
of types up to conversion, the subject reduction of the type assignment, the
strong normalization of the typed terms and, as a corollary, the decidability
of type inference problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611041</id><created>2006-11-09</created><authors><author><keyname>Gerdt</keyname><forenames>V. P.</forenames></author></authors><title>Groebner Bases Applied to Systems of Linear Difference Equations</title><categories>cs.SC</categories><comments>10 pages, Particles and Nuclei, Letters, to appear</comments><acm-class>I.1.2; I.1.4</acm-class><abstract>  In this paper we consider systems of partial (multidimensional) linear
difference equations. Specifically, such systems arise in scientific computing
under discretization of linear partial differential equations and in
computational high energy physics as recurrence relations for multiloop Feynman
integrals. The most universal algorithmic tool for investigation of linear
difference systems is based on their transformation into an equivalent Groebner
basis form. We present an algorithm for this transformation implemented in
Maple. The algorithm and its implementation can be applied to automatic
generation of difference schemes for linear partial differential equations and
to reduction of Feynman integrals. Some illustrative examples are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611042</id><created>2006-11-09</created><authors><author><keyname>Hinze-Hoare</keyname><forenames>Vita</forenames></author></authors><title>CSCR:Computer Supported Collaborative Research</title><categories>cs.HC cs.LG</categories><comments>3 Pages, 2 figures</comments><abstract>  It is suggested that a new area of CSCR (Computer Supported Collaborative
Research) is distinguished from CSCW and CSCL and that the demarcation between
the three areas could do with greater clarification and prescription.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611043</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611043</id><created>2006-11-10</created><authors><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Kim</keyname><forenames>Seung-Jean</forenames></author></authors><title>On the Convexity of log det (I + K X^{-1})</title><categories>cs.IT math.IT</categories><comments>2 pages</comments><abstract>  A simple proof is given for the convexity of log det (I+K X^{-1}) in the
positive definite matrix variable X with a given positive semidefinite K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611044</id><created>2006-11-10</created><authors><author><keyname>Migunov</keyname><forenames>Vladimir V.</forenames></author><author><keyname>Kafiyatullov</keyname><forenames>Rustem R.</forenames></author></authors><title>Protection of the information in a complex CAD system of renovation of
  industrial firms</title><categories>cs.CE</categories><comments>6 pages, 2 figures, in Russian</comments><acm-class>E.2; I.2.1; J.6</acm-class><abstract>  The threats to security of the information originating owing to involuntary
operations of the users of a CAD, and methods of its protection implemented in
a complex CAD system of renovation of firms are considered: rollback, autosave,
automatic backup copying and electronic subscript. The specificity of a complex
CAD is reflected in necessity of rollback and autosave both of the draw and the
parametric representations of its parts, which are the information models of
the problem-oriented extensions of the CAD
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611045</id><created>2006-11-10</created><authors><author><keyname>Migunov</keyname><forenames>Vladimir V.</forenames></author></authors><title>The evolution of the parametric models of drawings (modules) in the
  enterprises reconstruction CAD system</title><categories>cs.CE</categories><comments>8 pages, no figures, in Russian</comments><acm-class>E.2; I.2.1; J.6</acm-class><abstract>  Progressing methods of drawings creating automation is discussed on the basis
of so-called modules containing parametric representation of a part of the
drawing and the geometrical elements. The stages of evolution of modular
technology of automation of engineering are describing alternatives of applying
of moduluss for simple association of elements of the drawing without
parametric representation with an opportunity of its commenting, for graphic
symbols creating in the schemas of automation and drawings of pipelines, for
storage of the specific properties of elements, for development of the
specialized parts of the project: the axonometric schemas, profiles of outboard
pipe networks etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611046</id><created>2006-11-10</created><authors><author><keyname>Giordano</keyname><forenames>Laura</forenames></author><author><keyname>Gliozzi</keyname><forenames>Valentina</forenames></author><author><keyname>Olivetti</keyname><forenames>Nicola</forenames></author><author><keyname>Pozzato</keyname><forenames>Gian Luca</forenames></author></authors><title>Analytic Tableaux Calculi for KLM Logics of Nonmonotonic Reasoning</title><categories>cs.LO cs.AI</categories><comments>54 pages + appendix with proofs</comments><acm-class>F.4.1; I.2.3</acm-class><abstract>  We present tableau calculi for some logics of nonmonotonic reasoning, as
defined by Kraus, Lehmann and Magidor. We give a tableau proof procedure for
all KLM logics, namely preferential, loop-cumulative, cumulative and rational
logics. Our calculi are obtained by introducing suitable modalities to
interpret conditional assertions. We provide a decision procedure for the
logics considered, and we study their complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611047</id><created>2006-11-10</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>The Reaction RuleML Classification of the Event / Action / State
  Processing and Reasoning Space</title><categories>cs.AI</categories><comments>The Reaction RuleML Classification of the Event / Action / State
  Processing and Reasoning Space extracted from Paschke, A.: ECA-RuleML: An
  Approach combining ECA Rules with temporal interval-based KR Event/Action
  Logics and Transactional Update Logics, Internet-based Information Systems,
  Technical University Munich, Technical Report 11 / 2005</comments><report-no>Paschke, A.: The Reaction RuleML Classification of the Event /
  Action / State Processing and Reasoning Space, White Paper, October, 2006</report-no><acm-class>I.2; I.2.11; F.3; H.2.4</acm-class><abstract>  Reaction RuleML is a general, practical, compact and user-friendly
XML-serialized language for the family of reaction rules. In this white paper
we give a review of the history of event / action /state processing and
reaction rule approaches and systems in different domains, define basic
concepts and give a classification of the event, action, state processing and
reasoning space as well as a discussion of relevant / related work
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611048</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611048</id><created>2006-11-10</created><updated>2007-01-23</updated><authors><author><keyname>Abdulla</keyname><forenames>Parosh</forenames></author><author><keyname>Mahata</keyname><forenames>Pritha</forenames></author><author><keyname>Mayr</keyname><forenames>Richard</forenames></author></authors><title>Dense-Timed Petri Nets: Checking Zenoness, Token liveness and
  Boundedness</title><categories>cs.LO</categories><comments>61 pages, 18 figures</comments><acm-class>F.1.1; F.3.1; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (February
  7, 2007) lmcs:753</journal-ref><doi>10.2168/LMCS-3(1:1)2007</doi><abstract>  We consider Dense-Timed Petri Nets (TPN), an extension of Petri nets in which
each token is equipped with a real-valued clock and where the semantics is lazy
(i.e., enabled transitions need not fire; time can pass and disable
transitions). We consider the following verification problems for TPNs. (i)
Zenoness: whether there exists a zeno-computation from a given marking, i.e.,
an infinite computation which takes only a finite amount of time. We show
decidability of zenoness for TPNs, thus solving an open problem from [Escrig et
al.]. Furthermore, the related question if there exist arbitrarily fast
computations from a given marking is also decidable. On the other hand,
universal zenoness, i.e., the question if all infinite computations from a
given marking are zeno, is undecidable. (ii) Token liveness: whether a token is
alive in a marking, i.e., whether there is a computation from the marking which
eventually consumes the token. We show decidability of the problem by reducing
it to the coverability problem, which is decidable for TPNs. (iii) Boundedness:
whether the size of the reachable markings is bounded. We consider two versions
of the problem; namely semantic boundedness where only live tokens are taken
into consideration in the markings, and syntactic boundedness where also dead
tokens are considered. We show undecidability of semantic boundedness, while we
prove that syntactic boundedness is decidable through an extension of the
Karp-Miller algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611049</id><created>2006-11-13</created><updated>2007-02-27</updated><authors><author><keyname>Kuketayev</keyname><forenames>Argyn</forenames></author></authors><title>On numerical stability of recursive present value computation method</title><categories>cs.CE cs.NA</categories><comments>6 pages, 2 tables</comments><acm-class>G.1.0; J.1</acm-class><abstract>  We analyze numerical stability of a recursive computation scheme of present
value (PV) amd show that the absolute error increases exponentially for
positive discount rates. We show that reversing the direction of calculations
in the recurrence equation yields a robust PV computation routine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611050</id><created>2006-11-13</created><authors><author><keyname>Thomann</keyname><forenames>Hans-Rudolf</forenames></author></authors><title>HowTo Authenticate and Encrypt</title><categories>cs.CR</categories><abstract>  Recently, various side-channel attacks on widely used encryption methods have
been discovered. Extensive research is currently undertaken to develop new
types of combined encryption and authentication mechanisms. Developers of
security systems ask whether to implement methods recommended by international
standards or to choose one of the new proposals. We explain the nature of the
attacks and how they can be avoided, and recommend a sound, provably secure
solution: the CCM standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611051</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611051</id><created>2006-11-13</created><authors><author><keyname>Jha</keyname><forenames>Sumit Kumar</forenames></author></authors><title>Numerical Simulation guided Lazy Abstraction Refinement for Nonlinear
  Hybrid Automata</title><categories>cs.LO</categories><comments>11 pages, 2 figures</comments><acm-class>B.5.2</acm-class><abstract>  This draft suggests a new counterexample guided abstraction refinement
(CEGAR) framework that uses the combination of numerical simulation for
nonlinear differential equations with linear programming for linear hybrid
automata (LHA) to perform reachability analysis on nonlinear hybrid automata. A
notion of $\epsilon-$ structural robustness is also introduced which allows the
algorithm to validate counterexamples using numerical simulations.
  Keywords: verification, model checking, hybrid systems, hybrid automata,
robustness, robust hybrid systems, numerical simulation, cegar, abstraction
refinement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611052</id><created>2006-11-13</created><updated>2006-12-15</updated><authors><author><keyname>Achlioptas</keyname><forenames>Dimitris</forenames></author><author><keyname>Ricci-Tersenghi</keyname><forenames>Federico</forenames></author></authors><title>On the Solution-Space Geometry of Random Constraint Satisfaction
  Problems</title><categories>cs.CC cond-mat.dis-nn</categories><comments>25 pages, work presented at STOC'06</comments><abstract>  For a large number of random constraint satisfaction problems, such as random
k-SAT and random graph and hypergraph coloring, there are very good estimates
of the largest constraint density for which solutions exist. Yet, all known
polynomial-time algorithms for these problems fail to find solutions even at
much lower densities. To understand the origin of this gap we study how the
structure of the space of solutions evolves in such problems as constraints are
added. In particular, we prove that much before solutions disappear, they
organize into an exponential number of clusters, each of which is relatively
small and far apart from all other clusters. Moreover, inside each cluster most
variables are frozen, i.e., take only one value. The existence of such frozen
variables gives a satisfying intuitive explanation for the failure of the
polynomial-time algorithms analyzed so far. At the same time, our results
establish rigorously one of the two main hypotheses underlying Survey
Propagation, a heuristic introduced by physicists in recent years that appears
to perform extraordinarily well on random constraint satisfaction problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611053</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611053</id><created>2006-11-13</created><authors><author><keyname>Cover</keyname><forenames>Thomas M.</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>Capacity of a Class of Deterministic Relay Channels</title><categories>cs.IT math.IT</categories><comments>17 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  The capacity of a class of deterministic relay channels with the transmitter
input X, the receiver output Y, the relay output Y_1 = f(X, Y), and a separate
communication link from the relay to the receiver with capacity R_0, is shown
to be
  C(R_0) = \max_{p(x)} \min \{I(X;Y)+R_0, I(X;Y, Y_1) \}.
  Thus every bit from the relay is worth exactly one bit to the receiver. Two
alternative coding schemes are presented that achieve this capacity. The first
scheme, ``hash-and-forward'', is based on a simple yet novel use of random
binning on the space of relay outputs, while the second scheme uses the usual
``compress-and-forward''. In fact, these two schemes can be combined together
to give a class of optimal coding schemes. As a corollary, this relay capacity
result confirms a conjecture by Ahlswede and Han on the capacity of a channel
with rate-limited state information at the decoder in the special case when the
channel state is recoverable from the channel input and the output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611054</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611054</id><created>2006-11-13</created><authors><author><keyname>Strelioff</keyname><forenames>Christopher C.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>How Random is a Coin Toss? Bayesian Inference and the Symbolic Dynamics
  of Deterministic Chaos</title><categories>cs.LG cs.IT math.IT nlin.CD</categories><comments>8 pages, 1 figure; http://cse.ucdavis.edu/~cmg/compmech/pubs/hrct.htm</comments><abstract>  Symbolic dynamics has proven to be an invaluable tool in analyzing the
mechanisms that lead to unpredictability and random behavior in nonlinear
dynamical systems. Surprisingly, a discrete partition of continuous state space
can produce a coarse-grained description of the behavior that accurately
describes the invariant properties of an underlying chaotic attractor. In
particular, measures of the rate of information production--the topological and
metric entropy rates--can be estimated from the outputs of Markov or generating
partitions. Here we develop Bayesian inference for k-th order Markov chains as
a method to finding generating partitions and estimating entropy rates from
finite samples of discretized data produced by coarse-grained dynamical
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611055</id><created>2006-11-14</created><authors><author><keyname>Rippert</keyname><forenames>Christophe</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Courbot</keyname><forenames>Alexandre</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Grimaud</keyname><forenames>Gilles</forenames><affiliation>INRIA Futurs, LIFL</affiliation></author></authors><title>A Low-Footprint Class Loading Mechanism for Embedded Java Virtual
  Machines</title><categories>cs.OS</categories><proxy>ccsd inria-00113684</proxy><journal-ref>Dans 3rd ACM International Conference on the Principles and
  Practice of Programming in Java (2004)</journal-ref><abstract>  This paper shows that it is possible to dramatically reduce the memory
consumption of classes loaded in an embedded Java virtual machine without
reducing its functionalities. We describe how to pack the constant pool by
deleting entries which are only used during the class loading process. We
present some benchmarks which demonstrate the efficiency of this mechanism. We
finally suggest some additional optimizations which can be applied if some
restrictions to the functionalities of the virtual machine can be tolerated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611056</id><created>2006-11-14</created><authors><author><keyname>Watteyne</keyname><forenames>Thomas</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Using Existing Network Simulators for Power-Aware Self-Organizing
  Wireless Sensor Network Protocols</title><categories>cs.NI</categories><proxy>ccsd inria-00113679</proxy><abstract>  In this document, we compare three existing simulation platforms (OPNET
Modeler, Network Simulator 2, Georgia Tech Sensor Network Simulator). Our
comparative study focuses on ease of use, scalability, ease of implementing
power consumption model and physical layer modeling accuracy, mainly.
Conclusions of this study are presented, and will help us decide which
simulating environment to use for evaluating power-aware self-organizing sensor
networks protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611057</id><created>2006-11-14</created><authors><author><keyname>Thery</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Formalising Sylow's theorems in Coq</title><categories>cs.LO</categories><proxy>ccsd inria-00113750</proxy><abstract>  This report presents a formalisation of Sylow's theorems done in {\sc Coq}.
The formalisation has been done in a couple of weeks on top of Georges
Gonthier's {\sc ssreflect} \cite{ssreflect}. There were two ideas behind
formalising Sylow's theorems. The first one was to get familiar with Georges
way of doing proofs. The second one was to contribute to the collective effort
to formalise a large subset of group theory in {\sc Coq} with some non-trivial
proofs.}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611058</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611058</id><created>2006-11-14</created><authors><author><keyname>Cottrell</keyname><forenames>Marie</forenames><affiliation>CES, SAMOS</affiliation></author><author><keyname>Verleysen</keyname><forenames>Michel</forenames><affiliation>DICE</affiliation></author></authors><title>Advances in Self Organising Maps</title><categories>cs.NE math.ST nlin.AO stat.TH</categories><comments>Special Issue of the Neural Networks Journal after WSOM 05 in Paris</comments><proxy>ccsd hal-00113735</proxy><journal-ref>Neural Networks Volume 19, Issues 6-7 (2006) 721-722</journal-ref><doi>10.1016/j.neunet.2006.05.011</doi><abstract>  The Self-Organizing Map (SOM) with its related extensions is the most popular
artificial neural algorithm for use in unsupervised learning, clustering,
classification and data visualization. Over 5,000 publications have been
reported in the open literature, and many commercial projects employ the SOM as
a tool for solving hard real-world problems. Each two years, the &quot;Workshop on
Self-Organizing Maps&quot; (WSOM) covers the new developments in the field. The WSOM
series of conferences was initiated in 1997 by Prof. Teuvo Kohonen, and has
been successfully organized in 1997 and 1999 by the Helsinki University of
Technology, in 2001 by the University of Lincolnshire and Humberside, and in
2003 by the Kyushu Institute of Technology. The Universit\'{e} Paris I
Panth\'{e}on Sorbonne (SAMOS-MATISSE research centre) organized WSOM 2005 in
Paris on September 5-8, 2005.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611059</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611059</id><created>2006-11-14</created><authors><author><keyname>Sharma</keyname><forenames>Naresh</forenames></author><author><keyname>Tikku</keyname><forenames>Ashok Armen</forenames></author></authors><title>Is the cyclic prefix necessary?</title><categories>cs.IT math.IT</categories><comments>12 pages, 1 figure. Appeared in part in the Proceedings of
  International Symposium on Information Theory (ISIT), Seattle, WA, USA, July
  2006</comments><doi>10.1109/ISIT.2006.261688</doi><abstract>  We show that one can do away with the cyclic prefix (CP) for SC-FDE and OFDM
at the cost of a moderate increase in the complexity of a DFT-based receiver.
Such an approach effectively deals with the decrease in the number of channel
uses due to the introduction of the CP. It is shown that the SINR for SC-FDE
remains the same asymptotically with the proposed receiver without CP as that
of the conventional receiver with CP. The results are shown for $N_t$ transmit
antennas and $N_r$ receive antennas where $N_r \geq N_t$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611060</id><created>2006-11-14</created><authors><author><keyname>Moed</keyname><forenames>Henk F.</forenames></author></authors><title>The effect of 'Open Access' upon citation impact: An analysis of ArXiv's
  Condensed Matter Section</title><categories>cs.DL cs.IR physics.soc-ph</categories><comments>Version 13 November 2006. 16 pages, 6 figures, 2 tables</comments><abstract>  This article statistically analyses how the citation impact of articles
deposited in the Condensed Matter section of the preprint server ArXiv (hosted
by Cornell University), and subsequently published in a scientific journal,
compares to that of articles in the same journal that were not deposited in
that archive. Its principal aim is to further illustrate and roughly estimate
the effect of two factors, 'early view' and 'quality bias', upon differences in
citation impact between these two sets of papers, using citation data from
Thomson Scientific's Web of Science. It presents estimates for a number of
journals in the field of condensed matter physics. In order to discriminate
between an 'open access' effect and an early view effect, longitudinal citation
data was analysed covering a time period as long as 7 years. Quality bias was
measured by calculating ArXiv citation impact differentials at the level of
individual authors publishing in a journal, taking into account co-authorship.
The analysis provided evidence of a strong quality bias and early view effect.
Correcting for these effects, there is in a sample of 6 condensed matter
physics journals studied in detail, no sign of a general 'open access
advantage' of papers deposited in ArXiv. The study does provide evidence that
ArXiv accelerates citation, due to the fact that that ArXiv makes papers
earlier available rather than that it makes papers freely available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611061</id><created>2006-11-14</created><authors><author><keyname>Dash</keyname><forenames>Jan W.</forenames></author></authors><title>Multivariate Integral Perturbation Techniques - I (Theory)</title><categories>cs.CE cs.NA</categories><comments>25 pages, 2 figures</comments><acm-class>B.2.4; G.1.4; G.3; J.1; J.2; J.4</acm-class><abstract>  We present a quasi-analytic perturbation expansion for multivariate
N-dimensional Gaussian integrals. The perturbation expansion is an infinite
series of lower-dimensional integrals (one-dimensional in the simplest
approximation). This perturbative idea can also be applied to multivariate
Student-t integrals. We evaluate the perturbation expansion explicitly through
2nd order, and discuss the convergence, including enhancement using Pade
approximants. Brief comments on potential applications in finance are given,
including options, models for credit risk and derivatives, and correlation
sensitivities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611062</id><created>2006-11-14</created><updated>2007-05-01</updated><authors><author><keyname>Andova</keyname><forenames>Suzana</forenames></author><author><keyname>Cremers</keyname><forenames>Cas</forenames></author><author><keyname>Gjosteen</keyname><forenames>Kristian</forenames></author><author><keyname>Mauw</keyname><forenames>Sjouke</forenames></author><author><keyname>Mjolsnes</keyname><forenames>Stig F.</forenames></author><author><keyname>Radomirovic</keyname><forenames>Sasa</forenames></author></authors><title>A framework for compositional verification of security protocols</title><categories>cs.CR</categories><abstract>  Automatic security protocol analysis is currently feasible only for small
protocols. Since larger protocols quite often are composed of many small
protocols, compositional analysis is an attractive, but non-trivial approach.
  We have developed a framework for compositional analysis of a large class of
security protocols. The framework is intended to facilitate automatic as well
as manual verification of large structured security protocols. Our approach is
to verify properties of component protocols in a multi-protocol environment,
then deduce properties about the composed protocol. To reduce the complexity of
multi-protocol verification, we introduce a notion of protocol independence and
prove a number of theorems that enable analysis of independent component
protocols in isolation.
  To illustrate the applicability of our framework to real-world protocols, we
study a key establishment sequence in WiMax consisting of three subprotocols.
Except for a small amount of trivial reasoning, the analysis is done using
automatic tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611063</id><created>2006-11-15</created><authors><author><keyname>Iyengar</keyname><forenames>Garud</forenames></author><author><keyname>Kumar</keyname><forenames>Anuj</forenames></author></authors><title>Characterizing Optimal Adword Auctions</title><categories>cs.GT</categories><comments>29 pages, work was presented at a) Second Workshop on Sponsored
  Search Auctions, Ann Arbor, MI b) INFORMS Annual Meeting, Pittsburgh c)
  Decision Sciences Seminar, Fuqua School of Business, Duke University</comments><report-no>CORC Technical Report TR-2006-04 at Computational Optimization
  Research Center at Columbia University</report-no><abstract>  We present a number of models for the adword auctions used for pricing
advertising slots on search engines such as Google, Yahoo! etc. We begin with a
general problem formulation which allows the privately known valuation per
click to be a function of both the identity of the advertiser and the slot. We
present a compact characterization of the set of all deterministic incentive
compatible direct mechanisms for this model. This new characterization allows
us to conclude that there are incentive compatible mechanisms for this auction
with a multi-dimensional type-space that are {\em not} affine maximizers. Next,
we discuss two interesting special cases: slot independent valuation and slot
independent valuation up to a privately known slot and zero thereafter. For
both of these special cases, we characterize revenue maximizing and efficiency
maximizing mechanisms and show that these mechanisms can be computed with a
worst case computational complexity $O(n^2m^2)$ and $O(n^2m^3)$ respectively,
where $n$ is number of bidders and $m$ is number of slots. Next, we
characterize optimal rank based allocation rules and propose a new mechanism
that we call the customized rank based allocation. We report the results of a
numerical study that compare the revenue and efficiency of the proposed
mechanisms. The numerical results suggest that customized rank-based allocation
rule is significantly superior to the rank-based allocation rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611064</id><created>2006-11-14</created><authors><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Bui</keyname><forenames>Loc</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Distributed Link Scheduling with Constant Overhead</title><categories>cs.NI cs.PF</categories><abstract>  This paper proposes a new class of simple, distributed algorithms for
scheduling in wireless networks. The algorithms generate new schedules in a
distributed manner via simple local changes to existing schedules. The class is
parameterized by integers $k\geq 1$. We show that algorithm $k$ of our class
achieves $k/(k+2)$ of the capacity region, for every $k\geq 1$. The algorithms
have small and constant worst-case overheads: in particular, algorithm $k$
generates a new schedule using {\em (a)} time less than $4k+2$ round-trip times
between neighboring nodes in the network, and {\em (b)} at most three control
transmissions by any given node, for any $k$. The control signals are
explicitly specified, and face the same interference effects as normal data
transmissions. Our class of distributed wireless scheduling algorithms are the
first ones guaranteed to achieve any fixed fraction of the capacity region
while using small and constant overheads that do not scale with network size.
The parameter $k$ explicitly captures the tradeoff between control overhead and
scheduler throughput performance and provides a tuning knob protocol designers
can use to harness this trade-off in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611065</identifier>
 <datestamp>2007-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611065</id><created>2006-11-14</created><updated>2007-12-06</updated><authors><author><keyname>Chowdhury</keyname><forenames>M. M.</forenames></author></authors><title>On the security of new key exchange protocols based on the triple
  decomposition problem</title><categories>cs.CR</categories><comments>This figures are given in the other version</comments><acm-class>E.3</acm-class><abstract>  We show that two new key exchange protocols with security based on the triple
DP may have security based on the MSCSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611066</id><created>2006-11-15</created><updated>2006-12-22</updated><authors><author><keyname>Pasquinucci</keyname><forenames>Andrea</forenames></author></authors><title>A modular eballot system - V0.6</title><categories>cs.CR</categories><comments>15 pages</comments><abstract>  We consider a reasonably simple voting system which can be implemented for
web-based ballots. Simplicity, modularity and the requirement of compatibility
with current web browsers leads to a system which satisfies a set of security
requirements for a ballot system which is not complete but sufficient in many
cases. Due to weak-eligibility and vote-selling, this system cannot be used for
political or similar ballots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611067</id><created>2006-11-15</created><updated>2006-12-22</updated><authors><author><keyname>Pasquinucci</keyname><forenames>Andrea</forenames></author></authors><title>Implementing the modular eballot system V0.6</title><categories>cs.CR</categories><comments>9 pages</comments><abstract>  We describe a practical implementation of the modular eballot system proposed
in ref.[1]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611068</id><created>2006-11-15</created><updated>2006-12-11</updated><authors><author><keyname>Spek</keyname><forenames>Sander</forenames></author><author><keyname>Postma</keyname><forenames>Eric</forenames></author><author><keyname>Herik</keyname><forenames>H. Jaap van den</forenames></author></authors><title>Wikipedia: organisation from a bottom-up approach</title><categories>cs.DL cs.CY</categories><comments>Presented on the Research in Wikipedia workshop, of the WikiSym 2006</comments><acm-class>H.3.7; H.4.3</acm-class><abstract>  Wikipedia can be considered as an extreme form of a self-managing team, as a
means of labour division. One could expect that this bottom-up approach, with
the absense of top-down organisational control, would lead to a chaos, but our
analysis shows that this is not the case. In the Dutch Wikipedia, an integrated
and coherent data structure is created, while at the same time users succeed in
distributing roles by self-selection. Some users focus on an area of expertise,
while others edit over the whole encyclopedic range. This constitutes our
conclusion that Wikipedia, in general, is a successful example of a
self-managing team.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611069</id><created>2006-11-15</created><authors><author><keyname>Pitel</keyname><forenames>Guillaume</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Scaling Construction Grammar up to Production Systems: the SCIM</title><categories>cs.CL</categories><proxy>ccsd inria-00114040</proxy><journal-ref>Dans Scalable Natural Language Understanding 2006 (2006)</journal-ref><abstract>  While a great effort has concerned the development of fully integrated
modular understanding systems, few researches have focused on the problem of
unifying existing linguistic formalisms with cognitive processing models. The
Situated Constructional Interpretation Model is one of these attempts. In this
model, the notion of &quot;construction&quot; has been adapted in order to be able to
mimic the behavior of Production Systems. The Construction Grammar approach
establishes a model of the relations between linguistic forms and meaning, by
the mean of constructions. The latter can be considered as pairings from a
topologically structured space to an unstructured space, in some way a special
kind of production rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611070</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611070</id><created>2006-11-15</created><updated>2007-06-12</updated><authors><author><keyname>Ozgur</keyname><forenames>Ayfer</forenames></author><author><keyname>Leveque</keyname><forenames>Olivier</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Hierarchical Cooperation Achieves Optimal Capacity Scaling in Ad Hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>56 pages, 16 figures, submitted to IEEE Transactions on Information
  Theory</comments><abstract>  n source and destination pairs randomly located in an area want to
communicate with each other. Signals transmitted from one user to another at
distance r apart are subject to a power loss of r^{-alpha}, as well as a random
phase. We identify the scaling laws of the information theoretic capacity of
the network. In the case of dense networks, where the area is fixed and the
density of nodes increasing, we show that the total capacity of the network
scales linearly with n. This improves on the best known achievability result of
n^{2/3} of Aeron and Saligrama, 2006. In the case of extended networks, where
the density of nodes is fixed and the area increasing linearly with n, we show
that this capacity scales as n^{2-alpha/2} for 2&lt;alpha&lt;3 and sqrt{n} for
alpha&gt;3. The best known earlier result (Xie and Kumar 2006) identified the
scaling law for alpha &gt; 4. Thus, much better scaling than multihop can be
achieved in dense networks, as well as in extended networks with low
attenuation. The performance gain is achieved by intelligent node cooperation
and distributed MIMO communication. The key ingredient is a hierarchical and
digital architecture for nodal exchange of information for realizing the
cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611071</id><created>2006-11-15</created><authors><author><keyname>Ravichandar</keyname><forenames>Ramya</forenames></author><author><keyname>Arthur</keyname><forenames>James D.</forenames></author><author><keyname>Bohner</keyname><forenames>Shawn A.</forenames></author></authors><title>Capabilities Engineering: Constructing Change-Tolerant Systems</title><categories>cs.SE</categories><comments>10 pages, 4 Figures, To Appear in Hawaii International Conference on
  System Sciences 2007</comments><abstract>  We propose a Capabilities-based approach for building long-lived, complex
systems that have lengthy development cycles. User needs and technology evolve
during these extended development periods, and thereby, inhibit a fixed
requirements-oriented solution specification. In effect, for complex emergent
systems, the traditional approach of baselining requirements results in an
unsatisfactory system. Therefore, we present an alternative approach,
Capabilities Engineering, which mathematically exploits the structural
semantics of the Function Decomposition graph - a representation of user needs
- to formulate Capabilities. For any given software system, the set of derived
Capabilities embodies change-tolerant characteristics. More specifically, each
individual Capability is a functional abstraction constructed to be highly
cohesive and to be minimally coupled with its neighbors. Moreover, the
Capability set is chosen to accommodate an incremental development approach,
and to reflect the constraints of technology feasibility and implementation
schedules. We discuss our validation activities to empirically prove that the
Capabilities-based approach results in change-tolerant systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611072</id><created>2006-11-15</created><updated>2007-03-02</updated><authors><author><keyname>Ravichandar</keyname><forenames>Ramya</forenames></author><author><keyname>Arthur</keyname><forenames>James D.</forenames></author><author><keyname>Broadwater</keyname><forenames>Robert P.</forenames></author></authors><title>Reconciling Synthesis and Decomposition: A Composite Approach to
  Capability Identification</title><categories>cs.SE</categories><comments>This paper appears in the 14th Annual IEEE International Conference
  and Workshop on the Engineering of Computer Based Systems (ECBS); 10 pages, 9
  figures</comments><abstract>  Stakeholders' expectations and technology constantly evolve during the
lengthy development cycles of a large-scale computer based system.
Consequently, the traditional approach of baselining requirements results in an
unsatisfactory system because it is ill-equipped to accommodate such change. In
contrast, systems constructed on the basis of Capabilities are more
change-tolerant; Capabilities are functional abstractions that are neither as
amorphous as user needs nor as rigid as system requirements. Alternatively,
Capabilities are aggregates that capture desired functionality from the users'
needs, and are designed to exhibit desirable software engineering
characteristics of high cohesion, low coupling and optimum abstraction levels.
To formulate these functional abstractions we develop and investigate two
algorithms for Capability identification: Synthesis and Decomposition. The
synthesis algorithm aggregates detailed rudimentary elements of the system to
form Capabilities. In contrast, the decomposition algorithm determines
Capabilities by recursively partitioning the overall mission of the system into
more detailed entities. Empirical analysis on a small computer based library
system reveals that neither approach is sufficient by itself. However, a
composite algorithm based on a complementary approach reconciling the two polar
perspectives results in a more feasible set of Capabilities. In particular, the
composite algorithm formulates Capabilities using the cohesion and coupling
measures as defined by the decomposition algorithm and the abstraction level as
determined by the synthesis algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611073</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611073</id><created>2006-11-15</created><updated>2007-06-21</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Prefix Codes for Power Laws with Countable Support</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 tables, submitted to Transactions on Information Theory</comments><acm-class>E.4; H.1.1; I.2.8</acm-class><journal-ref>Information Theory, 2008. ISIT 2008. IEEE International Symposium
  on</journal-ref><doi>10.1109/ISIT.2008.4595434</doi><abstract>  In prefix coding over an infinite alphabet, methods that consider specific
distributions generally consider those that decline more quickly than a power
law (e.g., Golomb coding). Particular power-law distributions, however, model
many random variables encountered in practice. For such random variables,
compression performance is judged via estimates of expected bits per input
symbol. This correspondence introduces a family of prefix codes with an eye
towards near-optimal coding of known distributions. Compression performance is
precisely estimated for well-known probability distributions using these codes
and using previously known prefix codes. One application of these near-optimal
codes is an improved representation of rational numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611074</id><created>2006-11-15</created><updated>2006-11-16</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>On &quot;P = NP: Linear Programming Formulation of the Traveling Salesman
  Problem&quot;: A reply to Hofman's Claim of a &quot;Counter-Example&quot;</title><categories>cs.CC cs.DM</categories><comments>7 pages; 5 figures</comments><acm-class>F.2; F.2.2</acm-class><abstract>  We show that Hofman's claim of a &quot;counter-example&quot; to Diaby's LP formulation
of the TSP is invalid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611075</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611075</id><created>2006-11-15</created><updated>2008-02-22</updated><authors><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author></authors><title>Proportional Fairness in Multi-channel Multi-rate Wireless Networks-Part
  I: The Case of Deterministic Channels</title><categories>cs.NI cs.IT cs.PF math.IT</categories><abstract>  This is Part I of a two-part paper series that studies the use of the
proportional fairness (PF) utility function as the basis for capacity
allocation and scheduling in multi-channel multi-rate wireless networks. The
contributions of Part I are threefold. (i) First, we lay down the theoretical
foundation for PF. Specifically, we present the fundamental properties and
physical/economic interpretation of PF. We show by general mathematical
arguments that PF leads to equal airtime allocation to users for the
single-channel case; and equal equivalent airtime allocation to users for the
multi-channel case, where the equivalent airtime enjoyed by a user is a
weighted sum of the airtimes enjoyed by the user on all channels, with the
weight of a channel being the price or value of that channel. We also establish
the Pareto efficiency of PF solutions. (ii) Second, we derive characteristics
of PF solutions that are useful for the construction of PF-optimization
algorithms. We present several PF-optimization algorithms, including a fast
algorithm that is amenable to parallel implementation. (iii) Third, we study
the use of PF utility for capacity allocation in large-scale WiFi networks
consisting of many adjacent wireless LANs. We find that the PF solution
simultaneously achieves higher system throughput, better fairness, and lower
outage probability with respect to the default solution given by today's 802.11
commercial products. Part II of this paper series extends our investigation to
the time-varying-channel case in which the data rates enjoyed by users over the
channels vary dynamically over time
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611076</identifier>
 <datestamp>2008-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611076</id><created>2006-11-15</created><updated>2008-02-22</updated><authors><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author></authors><title>Proportional Fairness in Multi-channel Multi-rate Wireless Networks-Part
  II: The Case of Time-Varying Channels</title><categories>cs.PF cs.IT cs.NI math.IT</categories><abstract>  This is Part II of a two-part paper series that studies the use of the
proportional fairness (PF) utility function as the basis for capacity
allocation and scheduling in multi-channel multi-rate wireless networks. The
contributions of Part II are twofold. (i) First, we extend the problem
formulation, theoretical results, and algorithms to the case of time-varying
channels, where opportunistic capacity allocation and scheduling can be
exploited to improve system performance. We lay down the theoretical foundation
for optimization that &quot;couples&quot; the time-varying characteristic of channels
with the requirements of the underlying applications into one consideration. In
particular, the extent to which opportunistic optimization is possible is not
just a function of how fast the channel characteristics vary, but also a
function of the elasticity of the underlying applications for delayed capacity
allocation. (ii) Second, building upon our theoretical framework and results,
we study subcarrier allocation and scheduling in orthogonal frequency division
multiplexing (OFDM) cellular wireless networks. We introduce the concept of a
W-normalized Doppler frequency to capture the extent to which opportunistic
scheduling can be exploited to achieve throughput-fairness performance gain. We
show that a &quot;look-back PF&quot; scheduling can strike a good balance between system
throughput and fairness while taking the underlying application requirements
into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611077</id><created>2006-11-15</created><authors><author><keyname>Burgin</keyname><forenames>Mark</forenames></author><author><keyname>Eberbach</keyname><forenames>Eugene</forenames></author></authors><title>Evolutionary Optimization in an Algorithmic Setting</title><categories>cs.NE cs.AI</categories><abstract>  Evolutionary processes proved very useful for solving optimization problems.
In this work, we build a formalization of the notion of cooperation and
competition of multiple systems working toward a common optimization goal of
the population using evolutionary computation techniques. It is justified that
evolutionary algorithms are more expressive than conventional recursive
algorithms. Three subclasses of evolutionary algorithms are proposed here:
bounded finite, unbounded finite and infinite types. Some results on
completeness, optimality and search decidability for the above classes are
presented. A natural extension of Evolutionary Turing Machine model developed
in this paper allows one to mathematically represent and study properties of
cooperation and competition in a population of optimized species.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611078</id><created>2006-11-16</created><authors><author><keyname>Simonot-Lion</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Simonot</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>IECN</affiliation></author><author><keyname>Song</keyname><forenames>Ye-Qiong</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Safety Evaluation of Critical Applications Distributed on TDMA-Based
  Networks</title><categories>cs.OH</categories><proxy>ccsd inria-00114266</proxy><journal-ref>Dans Third Taiwanese-French Conference on Information Technology,
  TFIT'2006 (2006)</journal-ref><abstract>  Critical embedded systems have to provide a high level of dependability. In
automotive domain, for example, TDMA protocols are largely recommended because
of their deterministic behavior. Nevertheless, under the transient
environmental perturbations, the loss of communication cycles may occur with a
certain probability and, consequently, the system may fail. This paper analyzes
the impact of the transient perturbations (especially due to Electromagnetic
Interferences) on the dependability of systems distributed on TDMA-based
networks. The dependability of such system is modeled as that of
&quot;consecutive-k-out-of-n:F&quot; systems and we provide a efficient way for its
evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611079</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611079</id><created>2006-11-16</created><updated>2007-12-13</updated><authors><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author><author><keyname>Talavera</keyname><forenames>Bruno</forenames></author></authors><title>Managing network congestion with a Kohonen-based RED queue</title><categories>cs.NI cs.NE</categories><comments>8 pages, 9 figures</comments><doi>10.1016/j.engappai.2010.10.012</doi><abstract>  The behaviour of the TCP AIMD algorithm is known to cause queue length
oscillations when congestion occurs at a router output link. Indeed, due to
these queueing variations, end-to-end applications experience large delay
jitter. Many studies have proposed efficient Active Queue Management (AQM)
mechanisms in order to reduce queue oscillations and stabilize the queue
length. These AQM are mostly improvements of the Random Early Detection (RED)
model. Unfortunately, these enhancements do not react in a similar manner for
various network conditions and are strongly sensitive to their initial setting
parameters. Although this paper proposes a solution to overcome the
difficulties of setting these parameters by using a Kohonen neural network
model, another goal of this study is to investigate whether cognitive
intelligence could be placed in the core network to solve such stability
problem. In our context, we use results from the neural network area to
demonstrate that our proposal, named Kohonen-RED (KRED), enables a stable queue
length without complex parameters setting and passive measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611080</id><created>2006-11-16</created><authors><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author></authors><title>A Multi-server Scheduling Framework for Resource Allocation in Wireless
  Multi-carrier Networks</title><categories>cs.NA cs.CE cs.NI cs.PF</categories><abstract>  Multiuser resource allocation has recently been recognized as an effective
methodology for enhancing the power and spectrum efficiency in OFDM (orthogonal
frequency division multiplexing) systems. It is, however, not directly
applicable to current packet-switched networks, because (i) most existing
packet-scheduling schemes are based on a single-server model and do not serve
multiple users at the same time; and (ii) the conventional separate design of
MAC (medium access control) packet scheduling and PHY (physical) resource
allocation yields inefficient resource utilization. In this paper, we propose a
cross-layer resource allocation algorithm based on a novel multi-server
scheduling framework to achieve overall high system power efficiency in
packet-switched OFDM networks. Our contribution is four fold: (i) we propose
and analyze a MPGPS (multi-server packetized general processor sharing) service
discipline that serves multiple users at the same time and facilitates
multiuser resource allocation; (ii) we present a MPGPS-based joint MAC-PHY
resource allocation scheme that incorporates packet scheduling, subcarrier
allocation, and power allocation in an integrated framework; (iii) by
investigating the fundamental tradeoff between multiuser-diversity and queueing
performance, we present an A-MPGPS (adaptive MPGPS) service discipline that
strikes balance between power efficiency and queueing performance; and (iv) we
extend MPGPS to an O-MPGPS (opportunistic MPGPS) service discipline to further
enhance the resource utilization efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611081</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611081</id><created>2006-11-16</created><updated>2006-12-01</updated><authors><author><keyname>Ramos</keyname><forenames>Rubens Viana</forenames></author></authors><title>The Importance of the Algorithmic Information Theory to Construct a
  Possible Example Where NP # P - II: An Irreducible Sentence</title><categories>cs.CC cs.IT math.IT</categories><comments>2 pages</comments><abstract>  In this short communication it is discussed the relation between disentangled
states and algorithmic information theory aiming to construct an irreducible
sentence whose length increases in a non-polynomial way when the number of
qubits increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611082</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611082</id><created>2006-11-17</created><updated>2012-01-31</updated><authors><author><keyname>Feinstein</keyname><forenames>Craig Alan</forenames></author></authors><title>The Computational Complexity of the Traveling Salesman Problem</title><categories>cs.CC</categories><comments>1 page, made a minor correction</comments><journal-ref>Global Journal of Computer Science and Technology, Volume 11 Issue
  23, December 2011, pp 1-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we show that the Traveling Salesman Problem cannot be solved in
polynomial-time on a classical computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611083</id><created>2006-11-17</created><authors><author><keyname>Migunov</keyname><forenames>Vladimir V.</forenames></author></authors><title>Environment of development of the programs of parametric creating of the
  drawings in CAD-system of renovation of the enterprises</title><categories>cs.CE</categories><comments>5 pages, 3 figures, in Russian</comments><acm-class>I.2.1; J.6</acm-class><abstract>  The main ideas, data structures, structure and realization of operations with
them in environment of development of the programs of parametric creating of
the drawings are considered for the needs of the automated design engineering
system of renovation of the enterprises. The example of such program and
example of application of this environment for creating the drawing of the base
for equipment in CAD-system TechnoCAD GlassX are presented
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611084</id><created>2006-11-17</created><authors><author><keyname>Jacq</keyname><forenames>N.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Breton</keyname><forenames>V.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Chen</keyname><forenames>H. -Y.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Ho</keyname><forenames>L. -Y.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Hofmann</keyname><forenames>M.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Lee</keyname><forenames>H. -C.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Legr&#xe9;</keyname><forenames>Y.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Lin</keyname><forenames>S. -C.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Maass</keyname><forenames>A.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Medernach</keyname><forenames>E.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Merelli</keyname><forenames>I.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Milanesi</keyname><forenames>L.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Rastelli</keyname><forenames>G.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Reichstadt</keyname><forenames>M.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Salzemann</keyname><forenames>J.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Schwichtenberg</keyname><forenames>H.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Sridhar</keyname><forenames>M.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Kasam</keyname><forenames>V.</forenames><affiliation>LPC-Clermont</affiliation></author><author><keyname>Wu</keyname><forenames>Y. -T.</forenames></author><author><keyname>Zimmermann</keyname><forenames>M.</forenames></author></authors><title>Large Scale In Silico Screening on Grid Infrastructures</title><categories>cs.DC q-bio.QM</categories><comments>14 pages, 2 figures, 2 tables, The Third International Life Science
  Grid Workshop, LSGrid 2006, Yokohama, Japan, 13-14 october 2006, to appear in
  the proceedings</comments><proxy>ccsd in2p3-00114085</proxy><abstract>  Large-scale grid infrastructures for in silico drug discovery open
opportunities of particular interest to neglected and emerging diseases. In
2005 and 2006, we have been able to deploy large scale in silico docking within
the framework of the WISDOM initiative against Malaria and Avian Flu requiring
about 105 years of CPU on the EGEE, Auvergrid and TWGrid infrastructures. These
achievements demonstrated the relevance of large-scale grid infrastructures for
the virtual screening by molecular docking. This also allowed evaluating the
performances of the grid infrastructures and to identify specific issues raised
by large-scale deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611085</id><created>2006-11-17</created><authors><author><keyname>McJunkin</keyname><forenames>Timothy R.</forenames></author><author><keyname>Scott</keyname><forenames>Jill R.</forenames></author></authors><title>Fuzzy Logic Classification of Imaging Laser Desorption Fourier Transform
  Mass Spectrometry Data</title><categories>cs.AI</categories><abstract>  A fuzzy logic based classification engine has been developed for classifying
mass spectra obtained with an imaging internal source Fourier transform mass
spectrometer (I^2LD-FTMS). Traditionally, an operator uses the relative
abundance of ions with specific mass-to-charge (m/z) ratios to categorize
spectra. An operator does this by comparing the spectrum of m/z versus
abundance of an unknown sample against a library of spectra from known samples.
Automated positioning and acquisition allow I^2LD-FTMS to acquire data from
very large grids, this would require classification of up to 3600 spectrum per
hour to keep pace with the acquisition. The tedious job of classifying numerous
spectra generated in an I^2LD-FTMS imaging application can be replaced by a
fuzzy rule base if the cues an operator uses can be encapsulated. We present
the translation of linguistic rules to a fuzzy classifier for mineral phases in
basalt. This paper also describes a method for gathering statistics on ions,
which are not currently used in the rule base, but which may be candidates for
making the rule base more accurate and complete or to form new rule bases based
on data obtained from known samples. A spatial method for classifying spectra
with low membership values, based on neighboring sample classifications, is
also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611086</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611086</id><created>2006-11-17</created><authors><author><keyname>Gabrielyan</keyname><forenames>Emin</forenames></author><author><keyname>Hersch</keyname><forenames>Roger D.</forenames></author></authors><title>Reliable Multi-Path Routing Schemes for Real-Time Streaming</title><categories>cs.NI cs.IT math.IT</categories><comments>Emin Gabrielyan, &quot;Reliable Multi-Path Routing Schemes for Voice over
  Packet Networks&quot;, ICDT'06, International Conference on Digital
  Telecommunications, Cote d'Azur, France, 29-31 August 2006, pp. 65-72</comments><abstract>  In off-line streaming, packet level erasure resilient Forward Error
Correction (FEC) codes rely on the unrestricted buffering time at the receiver.
In real-time streaming, the extremely short playback buffering time makes FEC
inefficient for protecting a single path communication against long link
failures. It has been shown that one alternative path added to a single path
route makes packet level FEC applicable even when the buffering time is
limited. Further path diversity, however, increases the number of underlying
links increasing the total link failure rate, requiring from the sender
possibly more FEC packets. We introduce a scalar coefficient for rating a
multi-path routing topology of any complexity. It is called Redundancy Overall
Requirement (ROR) and is proportional to the total number of adaptive FEC
packets required for protection of the communication. With the capillary
routing algorithm, introduced in this paper we build thousands of multi-path
routing patterns. By computing their ROR coefficients, we show that contrary to
the expectations the overall requirement in FEC codes is reduced when the
further diversity of dual-path routing is achieved by the capillary routing
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611087</id><created>2006-11-17</created><authors><author><keyname>Singhmar</keyname><forenames>Naresh</forenames></author><author><keyname>Mathur</keyname><forenames>Vipul</forenames></author><author><keyname>Apte</keyname><forenames>Varsha</forenames></author><author><keyname>Manjunath</keyname><forenames>D.</forenames></author></authors><title>A Combined LIFO-Priority Scheme for Overload Control of E-commerce Web
  Servers</title><categories>cs.PF</categories><comments>10 pages, 8 figures, presented at the International Infrastructure
  Survivability Workshop (affiliated with the 25th IEEE International Real-Time
  Systems Symposium), Lisbon, Portugal, December 2004</comments><abstract>  E-commerce Web-servers often face overload conditions during which
revenue-generating requests may be dropped or abandoned due to an increase in
the browsing requests. In this paper we present a simple, yet effective,
mechanism for overload control of E-commerce Web-servers. We develop an
E-commerce workload model that separates the browsing requests from
revenue-generating transaction requests. During overload, we apply LIFO
discipline in the browsing queues and use a dynamic priority model to service
them. The transaction queues are given absolute priority over the browsing
queues. This is called the LIFO-Pri scheduling discipline. Experimental results
show that LIFO-Pri dramatically improves the overall Web-server throughput
while also increasing the completion rate of revenue-generating requests. The
Web-server was able to operate at nearly 60% of its maximum capacity even when
offered load was 1.5 times its capacity. Further, when compared to a single
queue FIFO system, there was a seven-fold increase in the number of completed
revenue-generating requests during overload.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611088</id><created>2006-11-18</created><authors><author><keyname>Larmore</keyname><forenames>Lawrence L.</forenames></author><author><keyname>Oravec</keyname><forenames>James A.</forenames></author></authors><title>T-Theory Applications to Online Algorithms for the Server Problem</title><categories>cs.DS cs.DM</categories><comments>19 figures 38 pages</comments><abstract>  Although largely unnoticed by the online algorithms community, T-theory, a
field of discrete mathematics, has contributed to the development of several
online algorithms for the k-server problem. A brief summary of the k-server
problem, and some important application concepts of T-theory, are given.
Additionally, a number of known k-server results are restated using the
established terminology of T-theory. Lastly, a previously unpublished
3-competitiveness proof, using T-theory, for the Harmonic algorithm for two
servers is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611089</id><created>2006-11-17</created><authors><author><keyname>Halford</keyname><forenames>Thomas R.</forenames></author><author><keyname>Chugg</keyname><forenames>Keith M.</forenames></author></authors><title>The Extraction and Complexity Limits of Graphical Models for Linear
  Codes</title><categories>cs.IT math.IT</categories><comments>18 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  Two broad classes of graphical modeling problems for codes can be identified
in the literature: constructive and extractive problems. The former class of
problems concern the construction of a graphical model in order to define a new
code. The latter class of problems concern the extraction of a graphical model
for a (fixed) given code. The design of a new low-density parity-check code for
some given criteria (e.g. target block length and code rate) is an example of a
constructive problem. The determination of a graphical model for a classical
linear block code which implies a decoding algorithm with desired performance
and complexity characteristics is an example of an extractive problem. This
work focuses on extractive graphical model problems and aims to lay out some of
the foundations of the theory of such problems for linear codes.
  The primary focus of this work is a study of the space of all graphical
models for a (fixed) given code. The tradeoff between cyclic topology and
complexity in this space is characterized via the introduction of a new bound:
the tree-inducing cut-set bound. The proposed bound provides a more precise
characterization of this tradeoff than that which can be obtained using
existing tools (e.g. the Cut-Set Bound) and can be viewed as a generalization
of the square-root bound for tail-biting trellises to graphical models with
arbitrary cyclic topologies. Searching the space of graphical models for a
given code is then enabled by introducing a set of basic graphical model
transformation operations which are shown to span this space. Finally,
heuristics for extracting novel graphical models for linear block codes using
these transformations are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611090</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611090</id><created>2006-11-17</created><updated>2008-08-04</updated><authors><author><keyname>Jiang</keyname><forenames>Jing</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Algebraic Soft-Decision Decoding of Reed-Solomon Codes Using Bit-level
  Soft Information</title><categories>cs.IT math.IT</categories><comments>32 pages, 12 figures, to appear in IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of algebraic soft-decision decoding of Reed-Solomon codes
using bit-level soft information is investigated. Optimal multiplicity
assignment strategies of algebraic soft-decision decoding with infinite cost
are first studied over erasure channels and the binary symmetric channel. The
corresponding decoding radii are calculated in closed forms and tight bounds on
the error probability are derived. The multiplicity assignment strategy and the
corresponding performance analysis are then generalized to characterize the
decoding region of algebraic softdecision decoding over a mixed error and
bit-level erasure channel. The bit-level decoding region of the proposed
multiplicity assignment strategy is shown to be significantly larger than that
of conventional Berlekamp-Massey decoding. As an application, a bit-level
generalized minimum distance decoding algorithm is proposed. The proposed
decoding compares favorably with many other Reed-Solomon soft-decision decoding
algorithms over various channels. Moreover, owing to the simplicity of the
proposed bit-level generalized minimum distance decoding, its performance can
be tightly bounded using order statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611091</id><created>2006-11-19</created><updated>2006-12-20</updated><authors><author><keyname>Sundararajan</keyname><forenames>Elankovan</forenames></author><author><keyname>Harwood</keyname><forenames>Aaron</forenames></author><author><keyname>Ramamohanarao</keyname><forenames>Kotagiri</forenames></author></authors><title>Lossy Bulk Synchronous Parallel Processing Model for Very Large Scale
  Grids</title><categories>cs.DC cs.CC cs.PF</categories><comments>14 pages,15 figures</comments><abstract>  The performance of a parallel algorithm in a very large scale grid is
significantly influenced by the underlying Internet protocols and
inter-connectivity. Many grid programming platforms use TCP due to its
reliability, usually with some optimizations to reduce its costs. However, TCP
does not perform well in a high bandwidth and high delay network environment.
On the other hand, UDP is the fastest protocol available because it omits
connection setup process, acknowledgments and retransmissions sacrificing
reliable transfer. Many new bulk data transfer schemes using UDP for data
transmission such as RBUDP, Tsunami, and SABUL have been introduced and shown
to have better performance compared to TCP. In this paper, we consider the use
of UDP and examine the relationship between packet loss and speedup with
respect to the number of grid nodes. Our measurement suggests that packet loss
rates between 5%-15% on average are not uncommon between PlanetLab nodes that
are widely distributed over the Internet. We show that transmitting multiple
copies of same packet produces higher speedup. We show the minimum number of
packet duplication required to maximize the possible speedup for a given number
of nodes using a BSP based model. Our work demonstrates that by using an
appropriate number of packet copies, we can increase performance of parallel
program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611092</id><created>2006-11-19</created><authors><author><keyname>Mor</keyname><forenames>Yishay</forenames></author><author><keyname>Winters</keyname><forenames>Niall</forenames></author></authors><title>Design approaches in technology enhanced learning</title><categories>cs.SE cs.CY</categories><abstract>  Design is a critical to the successful development of any interactive
learning environment (ILE). Moreover, in technology enhanced learning (TEL),
the design process requires input from many diverse areas of expertise. As
such, anyone undertaking tool development is required to directly address the
design challenge from multiple perspectives. We provide a motivation and
rationale for design approaches for learning technologies that draws upon
Simon's seminal proposition of Design Science (Simon, 1969). We then review the
application of Design Experiments (Brown, 1992) and Design Patterns (Alexander
et al., 1977) and argue that a patterns approach has the potential to address
many of the critical challenges faced by learning technologists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611093</identifier>
 <datestamp>2007-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611093</id><created>2006-11-20</created><updated>2007-09-01</updated><authors><author><keyname>Karkare</keyname><forenames>Amey</forenames></author><author><keyname>Sanyal</keyname><forenames>Amitabha</forenames></author><author><keyname>Khedker</keyname><forenames>Uday</forenames></author></authors><title>Effectiveness of Garbage Collection in MIT/GNU Scheme</title><categories>cs.PL cs.PF</categories><comments>7 figures, 3 tables</comments><acm-class>D.3.2; D.3.4; D.4.2</acm-class><abstract>  Scheme uses garbage collection for heap memory management. Ideally, garbage
collectors should be able to reclaim all dead objects, i.e. objects that will
not be used in future. However, garbage collectors collect only those dead
objects that are not reachable from any program variable. Dead objects that are
reachable from program variables are not reclaimed.
  In this paper we describe our experiments to measure the effectiveness of
garbage collection in MIT/GNU Scheme. We compute the drag time of objects, i.e.
the time for which an object remains in heap memory after its last use. The
number of dead objects and the drag time together indicate opportunities for
improving garbage collection. Our experiments reveal that up to 26% of dead
objects remain in memory. The average drag time is up to 37% of execution time.
Overall, we observe memory saving potential ranging from 9% to 65%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611094</id><created>2006-11-20</created><authors><author><keyname>Guravannavar</keyname><forenames>Ravindra</forenames></author><author><keyname>Sudarshan</keyname><forenames>S</forenames></author><author><keyname>Diwan</keyname><forenames>Ajit A</forenames></author><author><keyname>Babu</keyname><forenames>Ch. Sobhan</forenames></author></authors><title>Reducing Order Enforcement Cost in Complex Query Plans</title><categories>cs.DB</categories><comments>24 pages, 16 figures</comments><abstract>  Algorithms that exploit sort orders are widely used to implement joins,
grouping, duplicate elimination and other set operations. Query optimizers
traditionally deal with sort orders by using the notion of interesting orders.
The number of interesting orders is unfortunately factorial in the number of
participating attributes. Optimizer implementations use heuristics to prune the
number of interesting orders, but the quality of the heuristics is unclear.
Increasingly complex decision support queries and increasing use of covering
indices, which provide multiple alternative sort orders for relations, motivate
us to better address the problem of optimization with interesting orders.
  We show that even a simplified version of optimization with sort orders is
NP-hard and provide principled heuristics for choosing interesting orders. We
have implemented the proposed techniques in a Volcano-style cost-based
optimizer, and our performance study shows significant improvements in
estimated cost. We also executed our plans on a widely used commercial database
system, and on PostgreSQL, and found that actual execution times for our plans
were significantly better than for plans generated by those systems in several
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611095</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611095</id><created>2006-11-20</created><authors><author><keyname>Liu</keyname><forenames>Nan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Dense Gaussian Sensor Networks: Minimum Achievable Distortion and the
  Order Optimality of Separation</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><abstract>  We investigate the optimal performance of dense sensor networks by studying
the joint source-channel coding problem. The overall goal of the sensor network
is to take measurements from an underlying random process, code and transmit
those measurement samples to a collector node in a cooperative multiple access
channel with potential feedback, and reconstruct the entire random process at
the collector node. We provide lower and upper bounds for the minimum
achievable expected distortion when the underlying random process is Gaussian.
When the Gaussian random process satisfies some general conditions, we evaluate
the lower and upper bounds explicitly, and show that they are of the same order
for a wide range of power constraints. Thus, for these random processes, under
these power constraints, we express the minimum achievable expected distortion
as a function of the power constraint. Further, we show that the achievability
scheme that achieves the lower bound on the distortion is a separation-based
scheme that is composed of multi-terminal rate-distortion coding and
amplify-and-forward channel coding. Therefore, we conclude that separation is
order-optimal for the dense Gaussian sensor network scenario under
consideration, when the underlying random process satisfies some general
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611096</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611096</id><created>2006-11-20</created><authors><author><keyname>Binia</keyname><forenames>Jacob</forenames></author></authors><title>On the Rate Distortion Function of Certain Sources with a Proportional
  Mean-Square Error Distortion Measure</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><abstract>  New bounds on the rate distortion function of certain non-Gaussian sources,
with a proportional-weighted mean-square error (MSE) distortion measure, are
given. The growth, g, of the rate distortion function, as a result of changing
from a non-weighted MSE distortion measure to a proportional-weighted
distortion criterion is analyzed. It is shown that for a small distortion, d,
the growth, g, and the difference between the rate distortion functions of a
Gaussian memoryless source and a source with memory, both with the same
marginal statistics and MSE distortion measure, share the same lower bound.
Several examples and applications are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611097</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611097</id><created>2006-11-20</created><updated>2007-03-26</updated><authors><author><keyname>Halford</keyname><forenames>Thomas R.</forenames></author><author><keyname>Chugg</keyname><forenames>Keith M.</forenames></author></authors><title>Conditionally Cycle-Free Generalized Tanner Graphs: Theory and
  Application to High-Rate Serially Concatenated Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, minor revisions, to be presented at the 2007 IEEE Int'l
  Symposium on Information Theory</comments><abstract>  Generalized Tanner graphs have been implicitly studied by a number of authors
under the rubric of generalized parity-check matrices. This work considers the
conditioning of binary hidden variables in such models in order to break all
cycles and thus derive optimal soft-in soft-out (SISO) decoding algorithms.
Conditionally cycle-free generalized Tanner graphs are shown to imply optimal
SISO decoding algorithms for the first order Reed-Muller codes and their duals
- the extended Hamming codes - which are substantially less complex than
conventional bit-level trellis decoding. The study of low-complexity optimal
SISO decoding algorithms for the family of extended Hamming codes is
practically motivated. Specifically, it is shown that exended Hamming codes
offer an attractive alternative to high-rate convolutional codes in terms of
both performance and complexity for use in very high-rate, very low-floor,
serially concatenated coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611098</id><created>2006-11-20</created><authors><author><keyname>Lavault</keyname><forenames>Christian</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author></authors><title>Analysis of an Efficient Distributed Algorithm for Mutual Exclusion
  (Average-Case Analysis of Path Reversal)</title><categories>cs.DC cs.DS</categories><proxy>ccsd hal-00115119</proxy><journal-ref>LNCS 634 (1992) 133-144</journal-ref><abstract>  The algorithm analysed by Na\&quot;{i}mi, Trehe and Arnold was the very first
distributed algorithm to solve the mutual exclusion problem in complete
networks by using a dynamic logical tree structure as its basic distributed
data structure, viz. a path reversal transformation in rooted n-node trees;
besides, it was also the first one to achieve a logarithmic average-case
message complexity. The present paper proposes a direct and general approach to
compute the moments of the cost of path reversal. It basically uses one-one
correspondences between combinatorial structures and the associated probability
generating functions: the expected cost of path reversal is thus proved to be
exactly $H_{n-1}$. Moreover, time and message complexity of the algorithm as
well as randomized bounds on its worst-case message complexity in arbitrary
networks are also given. The average-case analysis of path reversal and the
analysis of this distributed algorithm for mutual exclusion are thus fully
completed in the paper. The general techniques used should also prove available
and fruitful when adapted to the most efficient recent tree-based distributed
algorithms for mutual exclusion which require powerful tools, particularly for
average-case analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611099</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611099</id><created>2006-11-20</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>On the space complexity of one-pass compression</title><categories>cs.IT math.IT</categories><acm-class>H.1.1</acm-class><abstract>  We study how much memory one-pass compression algorithms need to compete with
the best multi-pass algorithms. We call a one-pass algorithm an (f (n,
\ell))-footprint compressor if, given $n$, $\ell$ and an $n$-ary string $S$, it
stores $S$ in ((\rule{0ex}{2ex} O (H_\ell (S)) + o (\log n)) |S| + O (n^{\ell +
1} \log n)) bits -- where (H_\ell (S)) is the $\ell$th-order empirical entropy
of $S$ -- while using at most (f (n, \ell)) bits of memory. We prove that, for
any (\epsilon &gt; 0) and some (f (n, \ell) \in O (n^{\ell + \epsilon} \log n)),
there is an (f (n, \ell))-footprint compressor; on the other hand, there is no
(f (n, \ell))-footprint compressor for (f (n, \ell) \in o (n^\ell \log n)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611100</id><created>2006-11-20</created><authors><author><keyname>Mannucci</keyname><forenames>Mirco A.</forenames></author><author><keyname>Cherubin</keyname><forenames>Rose M.</forenames></author></authors><title>Model Theory of Ultrafinitism I: Fuzzy Initial Segments of Arithmetics</title><categories>cs.LO</categories><comments>31 pages, Tennenbaum Memorial invited talk</comments><abstract>  This article is the first of an intended series of works on the model theory
of Ultrafinitism. It is roughly divided into two parts. The first one addresses
some of the issues related to ultrafinitistic programs, as well as some of the
core ideas proposed thus far. The second part of the paper presents a model of
ultrafinitistic arithmetics based on the notion of fuzzy initial segments of
the standard natural numbers series. We also introduce a proof theory and a
semantics for ultrafinitism through which feasibly consistent theories can be
treated on the same footing as their classically consistent counterparts. We
conclude with a brief sketch of a foundational program, that aims at
reproducing the transfinite within the finite realm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611101</id><created>2006-11-21</created><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author><author><keyname>Husfeldt</keyname><forenames>Thore</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>Fourier meets M\&quot;{o}bius: fast subset convolution</title><categories>cs.DS cs.DM math.CO</categories><acm-class>F.2.1; F.2.2; G.2.1; G.2.2</acm-class><abstract>  We present a fast algorithm for the subset convolution problem: given
functions f and g defined on the lattice of subsets of an n-element set N,
compute their subset convolution f*g, defined for all S\subseteq N by (f *
g)(S) = \sum_{T \subseteq S}f(T) g(S\setminus T), where addition and
multiplication is carried out in an arbitrary ring. Via M\&quot;{o}bius transform
and inversion, our algorithm evaluates the subset convolution in O(n^2 2^n)
additions and multiplications, substantially improving upon the straightforward
O(3^n) algorithm. Specifically, if the input functions have an integer range
{-M,-M+1,...,M}, their subset convolution over the ordinary sum-product ring
can be computed in O^*(2^n log M) time; the notation O^* suppresses
polylogarithmic factors. Furthermore, using a standard embedding technique we
can compute the subset convolution over the max-sum or min-sum semiring in
O^*(2^n M) time. To demonstrate the applicability of fast subset convolution,
we present the first O^*(2^k n^2 + n m) algorithm for the minimum Steiner tree
problem in graphs with n vertices, k terminals, and m edges with bounded
integer weights, improving upon the O^*(3^k n + 2^k n^2 + n m) time bound of
the classical Dreyfus-Wagner algorithm. We also discuss extensions to recent
O^*(2^n)-time algorithms for covering and partitioning problems (Bj\&quot;{o}rklund
and Husfeldt, FOCS 2006; Koivisto, FOCS 2006).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611102</id><created>2006-11-21</created><authors><author><keyname>Langweg</keyname><forenames>Hanno</forenames></author><author><keyname>Kristiansen</keyname><forenames>Tommy</forenames></author></authors><title>Extending the Trusted Path in Client-Server Interaction</title><categories>cs.CR</categories><comments>8 pages, 3 figures</comments><acm-class>D.2.0; D.4.4; D.4.6</acm-class><abstract>  We present a method to secure the complete path between a server and the
local human user at a network node. This is useful for scenarios like internet
banking, electronic signatures, or online voting. Protection of input
authenticity and output integrity and authenticity is accomplished by a
combination of traditional and novel technologies, e.g., SSL, ActiveX, and
DirectX. Our approach does not require administrative privileges to deploy and
is hence suitable for consumer applications. Results are based on the
implementation of a proof-of-concept application for the Windows platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611103</id><created>2006-11-21</created><authors><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author></authors><title>Barriers and local minima in energy landscapes of stochastic local
  search</title><categories>cs.CC cond-mat.stat-mech</categories><acm-class>F.2.2; G.2.1; G.3; I.2.8</acm-class><abstract>  A local search algorithm operating on an instance of a Boolean constraint
satisfaction problem (in particular, k-SAT) can be viewed as a stochastic
process traversing successive adjacent states in an ``energy landscape''
defined by the problem instance on the n-dimensional Boolean hypercube. We
investigate analytically the worst-case topography of such landscapes in the
context of satisfiable k-SAT via a random ensemble of satisfiable ``k-regular''
linear equations modulo 2.
  We show that for each fixed k=3,4,..., the typical k-SAT energy landscape
induced by an instance drawn from the ensemble has a set of 2^{\Omega(n)} local
energy minima, each separated by an unconditional \Omega(n) energy barrier from
each of the O(1) ground states, that is, solution states with zero energy. The
main technical aspect of the analysis is that a random k-regular 0/1 matrix
constitutes a strong boundary expander with almost full GF(2)-linear rank, a
property which also enables us to prove a 2^{\Omega(n)} lower bound for the
expected number of steps required by the focused random walk heuristic to solve
typical instances drawn from the ensemble. These results paint a grim picture
of the worst-case topography of k-SAT for local search, and constitute
apparently the first rigorous analysis of the growth of energy barriers in a
random ensemble of k-SAT landscapes as the number of variables n is increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611104</id><created>2006-11-21</created><authors><author><keyname>Mouraud</keyname><forenames>Anthony</forenames><affiliation>ISC, GRIMAAG</affiliation></author><author><keyname>Paugam-Moisy</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>ISC</affiliation></author></authors><title>Learning and discrimination through STDP in a top-down modulated
  associative memory</title><categories>cs.NE cs.AI</categories><proxy>ccsd hal-00115420</proxy><journal-ref>Proceedings of 14 European Symposium on Artificial Neural Networks
  (ESANN 2006) (03/2006) 611-616</journal-ref><abstract>  This article underlines the learning and discrimination capabilities of a
model of associative memory based on artificial networks of spiking neurons.
Inspired from neuropsychology and neurobiology, the model implements top-down
modulations, as in neocortical layer V pyramidal neurons, with a learning rule
based on synaptic plasticity (STDP), for performing a multimodal association
learning task. A temporal correlation method of analysis proves the ability of
the model to associate specific activity patterns to different samples of
stimulation. Even in the absence of initial learning and with continuously
varying weights, the activity patterns become stable enough for discrimination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611105</id><created>2006-11-21</created><authors><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Liogkas</keyname><forenames>Nikitas</forenames></author><author><keyname>Kohler</keyname><forenames>Eddie</forenames></author><author><keyname>Zhang</keyname><forenames>Lixia</forenames></author></authors><title>Clustering and Sharing Incentives in BitTorrent Systems</title><categories>cs.NI</categories><proxy>ccsd inria-00112066</proxy><abstract>  Peer-to-peer protocols play an increasingly instrumental role in Internet
content distribution. Consequently, it is important to gain a full
understanding of how these protocols behave in practice and how their
parameters impact overall performance. We present the first experimental
investigation of the peer selection strategy of the popular BitTorrent protocol
in an instrumented private torrent. By observing the decisions of more than 40
nodes, we validate three BitTorrent properties that, though widely believed to
hold, have not been demonstrated experimentally. These include the clustering
of similar-bandwidth peers, the effectiveness of BitTorrent's sharing
incentives, and the peers' high average upload utilization. In addition, our
results show that BitTorrent's new choking algorithm in seed state provides
uniform service to all peers, and that an underprovisioned initial seed leads
to the absence of peer clustering and less effective sharing incentives. Based
on our observations, we provide guidelines for seed provisioning by content
providers, and discuss a tracker protocol extension that addresses an
identified limitation of the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611106</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611106</id><created>2006-11-21</created><authors><author><keyname>Vrins</keyname><forenames>F.</forenames></author><author><keyname>Pham</keyname><forenames>D. -T.</forenames></author><author><keyname>Verleysen</keyname><forenames>M.</forenames></author></authors><title>Mixing and non-mixing local minima of the entropy contrast for blind
  source separation</title><categories>cs.IT math.IT</categories><comments>11 pages, 6 figures, To appear in IEEE Transactions on Information
  Theory</comments><abstract>  In this paper, both non-mixing and mixing local minima of the entropy are
analyzed from the viewpoint of blind source separation (BSS); they correspond
respectively to acceptable and spurious solutions of the BSS problem. The
contribution of this work is twofold. First, a Taylor development is used to
show that the \textit{exact} output entropy cost function has a non-mixing
minimum when this output is proportional to \textit{any} of the non-Gaussian
sources, and not only when the output is proportional to the lowest entropic
source. Second, in order to prove that mixing entropy minima exist when the
source densities are strongly multimodal, an entropy approximator is proposed.
The latter has the major advantage that an error bound can be provided. Even if
this approximator (and the associated bound) is used here in the BSS context,
it can be applied for estimating the entropy of any random variable with
multimodal density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611107</id><created>2006-11-21</created><authors><author><keyname>Buchsbaum</keyname><forenames>Adam L.</forenames></author><author><keyname>Gansner</keyname><forenames>Emden R.</forenames></author><author><keyname>Procopiuc</keyname><forenames>Cecilia M.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Rectangular Layouts and Contact Graphs</title><categories>cs.DS cs.DM</categories><comments>28 pages, 13 figures, 55 references, 1 appendix</comments><acm-class>F.2.2; G.2.2</acm-class><abstract>  Contact graphs of isothetic rectangles unify many concepts from applications
including VLSI and architectural design, computational geometry, and GIS.
Minimizing the area of their corresponding {\em rectangular layouts} is a key
problem. We study the area-optimization problem and show that it is NP-hard to
find a minimum-area rectangular layout of a given contact graph. We present
O(n)-time algorithms that construct $O(n^2)$-area rectangular layouts for
general contact graphs and $O(n\log n)$-area rectangular layouts for trees.
(For trees, this is an $O(\log n)$-approximation algorithm.) We also present an
infinite family of graphs (rsp., trees) that require $\Omega(n^2)$ (rsp.,
$\Omega(n\log n)$) area.
  We derive these results by presenting a new characterization of graphs that
admit rectangular layouts using the related concept of {\em rectangular duals}.
A corollary to our results relates the class of graphs that admit rectangular
layouts to {\em rectangle of influence drawings}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611108</id><created>2006-11-21</created><updated>2007-05-22</updated><authors><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author><author><keyname>Stein</keyname><forenames>Cliff</forenames></author><author><keyname>Svitkina</keyname><forenames>Zoya</forenames></author></authors><title>On the Complexity of Processing Massive, Unordered, Distributed Data</title><categories>cs.CC cs.DC</categories><abstract>  An existing approach for dealing with massive data sets is to stream over the
input in few passes and perform computations with sublinear resources. This
method does not work for truly massive data where even making a single pass
over the data with a processor is prohibitive. Successful log processing
systems in practice such as Google's MapReduce and Apache's Hadoop use multiple
machines. They efficiently perform a certain class of highly distributable
computations defined by local computations that can be applied in any order to
the input.
  Motivated by the success of these systems, we introduce a simple algorithmic
model for massive, unordered, distributed (mud) computation. We initiate the
study of understanding its computational complexity. Our main result is a
positive one: any unordered function that can be computed by a streaming
algorithm can also be computed with a mud algorithm, with comparable space and
communication complexity. We extend this result to some useful classes of
approximate and randomized streaming algorithms. We also give negative results,
using communication complexity arguments to prove that extensions to private
randomness, promise problems and indeterminate functions are impossible.
  We believe that the line of research we introduce in this paper has the
potential for tremendous impact. The distributed systems that motivate our work
successfully process data at an unprecedented scale, distributed over hundreds
or even thousands of machines, and perform hundreds of such analyses each day.
The mud model (and its generalizations) inspire a set of complexity-theoretic
questions that lie at their heart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611109</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611109</id><created>2006-11-21</created><updated>2010-03-27</updated><authors><author><keyname>Jackson</keyname><forenames>R.</forenames></author><author><keyname>Rumynin</keyname><forenames>D.</forenames></author><author><keyname>Zaboronski</keyname><forenames>O.</forenames></author></authors><title>An approach to RAID-6 based on cyclic groups of a prime order</title><categories>cs.IT math.IT math.NT</categories><msc-class>94B60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the size of data storing arrays of disks grows, it becomes vital to
protect data against double disk failures. A popular method of protection is
via the Reed-Solomon (RS) code with two parity words. In the present paper we
construct alternative examples of linear block codes protecting against two
erasures. Our construction is based on an abstract notion of cone. Concrete
cones are constructed via matrix representations of cyclic groups of prime
order. In particular, this construction produces EVENODD code. Interesting
conditions on the prime number arise in our analysis of these codes. At the
end, we analyse an assembly implementation of the corresponding system on a
general purpose processor and compare its write and recovery speed with the
standard DP-RAID system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611110</id><created>2006-11-21</created><updated>2007-02-10</updated><authors><author><keyname>Chigani</keyname><forenames>Amine</forenames></author><author><keyname>Arthur</keyname><forenames>James D.</forenames></author></authors><title>The Implications of Network-Centric Software Systems on Software
  Architecture: A Critical Evaluation</title><categories>cs.SE</categories><comments>6 pages, 2 figures, ACMSE Conference 2007</comments><abstract>  The purpose of this paper is to evaluate the impact of emerging
network-centric software systems on the field of software architecture. We
first develop an insight concerning the term &quot;network-centric&quot; by presenting
its origin and its implications within the context of software architecture. On
the basis of this insight, we present our definition of a network-centric
framework and its distinguishing characteristics. We then enumerate the
challenges that face the field of software architecture as software development
shifts from a platform-centric to a network-centric model. In order to face
these challenges, we propose a formal approach embodied in a new architectural
style that supports overcoming these challenges at the architectural level.
Finally, we conclude by presenting an illustrative example to demonstrate the
usefulness of the concepts of network centricity, summarizing our
contributions, and linking our approach to future work that needs to be done in
this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611111</id><created>2006-11-21</created><authors><author><keyname>Hogg</keyname><forenames>Tad</forenames></author></authors><title>Distributed Control of Microscopic Robots in Biomedical Applications</title><categories>cs.RO cs.MA</categories><acm-class>I.2.9; I.2.11</acm-class><abstract>  Current developments in molecular electronics, motors and chemical sensors
could enable constructing large numbers of devices able to sense, compute and
act in micron-scale environments. Such microscopic machines, of sizes
comparable to bacteria, could simultaneously monitor entire populations of
cells individually in vivo. This paper reviews plausible capabilities for
microscopic robots and the physical constraints due to operation in fluids at
low Reynolds number, diffusion-limited sensing and thermal noise from Brownian
motion. Simple distributed controls are then presented in the context of
prototypical biomedical tasks, which require control decisions on millisecond
time scales. The resulting behaviors illustrate trade-offs among speed,
accuracy and resource use. A specific example is monitoring for patterns of
chemicals in a flowing fluid released at chemically distinctive sites.
Information collected from a large number of such devices allows estimating
properties of cell-sized chemical sources in a macroscopic volume. The
microscopic devices moving with the fluid flow in small blood vessels can
detect chemicals released by tissues in response to localized injury or
infection. We find the devices can readily discriminate a single cell-sized
chemical source from the background chemical concentration, providing
high-resolution sensing in both time and space. By contrast, such a source
would be difficult to distinguish from background when diluted throughout the
blood volume as obtained with a blood sample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611112</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611112</id><created>2006-11-21</created><authors><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr.</suffix></author><author><keyname>Forney</keyname><forenames>G. David</forenames><suffix>Jr</suffix></author></authors><title>Channel Coding: The Road to Channel Capacity</title><categories>cs.IT math.IT</categories><abstract>  Starting from Shannon's celebrated 1948 channel coding theorem, we trace the
evolution of channel coding from Hamming codes to capacity-approaching codes.
We focus on the contributions that have led to the most significant
improvements in performance vs. complexity for practical applications,
particularly on the additive white Gaussian noise (AWGN) channel. We discuss
algebraic block codes, and why they did not prove to be the way to get to the
Shannon limit. We trace the antecedents of today's capacity-approaching codes:
convolutional codes, concatenated codes, and other probabilistic coding
schemes. Finally, we sketch some of the practical applications of these codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611113</id><created>2006-11-21</created><authors><author><keyname>Ling</keyname><forenames>Maurice HT</forenames></author></authors><title>An Anthological Review of Research Utilizing MontyLingua, a Python-Based
  End-to-End Text Processor</title><categories>cs.CL</categories><comments>9 pages</comments><acm-class>H.5.2; I.2.7</acm-class><journal-ref>Ling, Maurice HT. 2006. An Anthological Review of Research
  Utilizing MontyLingua, a Python-Based End-to-End Text Processor. The Python
  Papers 1 (1): 5-13</journal-ref><abstract>  MontyLingua, an integral part of ConceptNet which is currently the largest
commonsense knowledge base, is an English text processor developed using Python
programming language in MIT Media Lab. The main feature of MontyLingua is the
coverage for all aspects of English text processing from raw input text to
semantic meanings and summary generation, yet each component in MontyLingua is
loosely-coupled to each other at the architectural and code level, which
enabled individual components to be used independently or substituted. However,
there has been no review exploring the role of MontyLingua in recent research
work utilizing it. This paper aims to review the use of and roles played by
MontyLingua and its components in research work published in 19 articles
between October 2004 and August 2006. We had observed a diversified use of
MontyLingua in many different areas, both generic and domain-specific. Although
the use of text summarizing component had not been observe, we are optimistic
that it will have a crucial role in managing the current trend of information
overload in future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611114</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611114</id><created>2006-11-22</created><updated>2006-12-01</updated><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>Very Sparse Stable Random Projections, Estimators and Tail Bounds for
  Stable Random Projections</title><categories>cs.DS cs.IT cs.LG math.IT</categories><abstract>  This paper will focus on three different aspects in improving the current
practice of stable random projections.
  Firstly, we propose {\em very sparse stable random projections} to
significantly reduce the processing and storage cost, by replacing the
$\alpha$-stable distribution with a mixture of a symmetric $\alpha$-Pareto
distribution (with probability $\beta$, $0&lt;\beta\leq1$) and a point mass at the
origin (with a probability $1-\beta$). This leads to a significant
$\frac{1}{\beta}$-fold speedup for small $\beta$.
  Secondly, we provide an improved estimator for recovering the original
$l_\alpha$ norms from the projected data. The standard estimator is based on
the (absolute) sample median, while we suggest using the geometric mean. The
geometric mean estimator we propose is strictly unbiased and is easier to
study. Moreover, the geometric mean estimator is more accurate, especially
non-asymptotically.
  Thirdly, we provide an adequate answer to the basic question of how many
projections (samples) are needed for achieving some pre-specified level of
accuracy. \cite{Proc:Indyk_FOCS00,Article:Indyk_TKDE03} did not provide a
criterion that can be used in practice. The geometric mean estimator we propose
allows us to derive sharp tail bounds which can be expressed in exponential
forms with constants explicitly given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611115</id><created>2006-11-22</created><authors><author><keyname>Horvath</keyname><forenames>Peter</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Jermyn</keyname><forenames>Ian</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Kato</keyname><forenames>Zoltan</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Zerubia</keyname><forenames>Josiane</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>A higher-order active contour model of a `gas of circles' and its
  application to tree crown extraction</title><categories>cs.CV</categories><proxy>ccsd inria-00115631</proxy><abstract>  Many image processing problems involve identifying the region in the image
domain occupied by a given entity in the scene. Automatic solution of these
problems requires models that incorporate significant prior knowledge about the
shape of the region. Many methods for including such knowledge run into
difficulties when the topology of the region is unknown a priori, for example
when the entity is composed of an unknown number of similar objects.
Higher-order active contours (HOACs) represent one method for the modelling of
non-trivial prior knowledge about shape without necessarily constraining region
topology, via the inclusion of non-local interactions between region boundary
points in the energy defining the model. The case of an unknown number of
circular objects arises in a number of domains, e.g. medical, biological,
nanotechnological, and remote sensing imagery. Regions composed of an a priori
unknown number of circles may be referred to as a `gas of circles'. In this
report, we present a HOAC model of a `gas of circles'. In order to guarantee
stable circles, we conduct a stability analysis via a functional Taylor
expansion of the HOAC energy around a circular shape. This analysis fixes one
of the model parameters in terms of the others and constrains the rest. In
conjunction with a suitable likelihood energy, we apply the model to the
extraction of tree crowns from aerial imagery, and show that the new model
outperforms other techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611116</identifier>
 <datestamp>2008-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611116</id><created>2006-11-22</created><authors><author><keyname>Nesterenko</keyname><forenames>Mikhail</forenames></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>Discovering Network Topology in the Presence of Byzantine Faults</title><categories>cs.DC cs.DS cs.OS</categories><journal-ref>13th Colloquium on Structural Information and Communication
  Complexity (SIROCCO), LNCS Volume 4056 pp. 212-226, Chester, UK, July 2006</journal-ref><doi>10.1007/11780823_17</doi><abstract>  We study the problem of Byzantine-robust topology discovery in an arbitrary
asynchronous network. We formally state the weak and strong versions of the
problem. The weak version requires that either each node discovers the topology
of the network or at least one node detects the presence of a faulty node. The
strong version requires that each node discovers the topology regardless of
faults. We focus on non-cryptographic solutions to these problems. We explore
their bounds. We prove that the weak topology discovery problem is solvable
only if the connectivity of the network exceeds the number of faults in the
system. Similarly, we show that the strong version of the problem is solvable
only if the network connectivity is more than twice the number of faults. We
present solutions to both versions of the problem. The presented algorithms
match the established graph connectivity bounds. The algorithms do not require
the individual nodes to know either the diameter or the size of the network.
The message complexity of both programs is low polynomial with respect to the
network size. We describe how our solutions can be extended to add the property
of termination, handle topology changes and perform neighborhood discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611117</id><created>2006-11-22</created><authors><author><keyname>Miyashita</keyname><forenames>Mark</forenames></author><author><keyname>Nesterenko</keyname><forenames>Mikhail</forenames></author></authors><title>2FACE: Bi-Directional Face Traversal for Efficient Geometric Routing</title><categories>cs.DC cs.DS cs.OS</categories><abstract>  We propose bi-directional face traversal algorithm $2FACE$ to shorten the
path the message takes to reach the destination in geometric routing. Our
algorithm combines the practicality of the best single-direction traversal
algorithms with the worst case message complexity of $O(|E|)$, where $E$ is the
number of network edges. We apply $2FACE$ to a variety of geometric routing
algorithms. Our simulation results indicate that bi-directional face traversal
decreases the latency of message delivery two to three times compared to single
direction face traversal. The thus selected path approaches the shortest
possible route. This gain in speed comes with a similar message overhead
increase. We describe an algorithm which compensates for this message overhead
by recording the preferable face traversal direction. Thus, if a source has
several messages to send to the destination, the subsequent messages follow the
shortest route. Our simulation results show that with most geometric routing
algorithms the message overhead of finding the short route by bi-directional
face traversal is compensated within two to four repeat messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611118</identifier>
 <datestamp>2008-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611118</id><created>2006-11-22</created><updated>2008-03-13</updated><authors><author><keyname>Wang</keyname><forenames>Haibin</forenames></author><author><keyname>Rogatko</keyname><forenames>Andre</forenames></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Sunderraman</keyname><forenames>Rajshekhar</forenames></author></authors><title>A Neutrosophic Description Logic</title><categories>cs.AI</categories><comments>18 pages. Presented at the IEEE International Conference on Granular
  Computing, Georgia State University, Atlanta, USA, May 2006</comments><acm-class>F.4.1</acm-class><journal-ref>Proceedings of 2006 IEEE International Conference on Granular
  Computing, edited by Yan-Qing Zhang and Tsau Young Lin, Georgia State
  University, Atlanta, pp. 305-308, 2006</journal-ref><abstract>  Description Logics (DLs) are appropriate, widely used, logics for managing
structured knowledge. They allow reasoning about individuals and concepts, i.e.
set of individuals with common properties. Typically, DLs are limited to
dealing with crisp, well defined concepts. That is, concepts for which the
problem whether an individual is an instance of it is yes/no question. More
often than not, the concepts encountered in the real world do not have a
precisely defined criteria of membership: we may say that an individual is an
instance of a concept only to a certain degree, depending on the individual's
properties. The DLs that deal with such fuzzy concepts are called fuzzy DLs. In
order to deal with fuzzy, incomplete, indeterminate and inconsistent concepts,
we need to extend the fuzzy DLs, combining the neutrosophic logic with a
classical DL. In particular, concepts become neutrosophic (here neutrosophic
means fuzzy, incomplete, indeterminate, and inconsistent), thus reasoning about
neutrosophic concepts is supported. We'll define its syntax, its semantics, and
describe its properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611119</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611119</id><created>2006-11-22</created><updated>2007-02-23</updated><authors><author><keyname>Hirshfeld</keyname><forenames>Yoram</forenames></author><author><keyname>Rabinovich</keyname><forenames>Alexander</forenames></author></authors><title>Expressiveness of Metric modalities for continuous time</title><categories>cs.LO</categories><acm-class>F.3.1; F.4; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (February
  23, 2007) lmcs:1096</journal-ref><doi>10.2168/LMCS-3(1:3)2007</doi><abstract>  We prove a conjecture by A. Pnueli and strengthen it showing a sequence of
&quot;counting modalities&quot; none of which is expressible in the temporal logic
generated by the previous modalities, over the real line, or over the positive
reals. Moreover, there is no finite temporal logic that can express all of them
over the real line, so that no finite metric temporal logic is expressively
complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611120</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611120</id><created>2006-11-22</created><authors><author><keyname>Bloch</keyname><forenames>Matthieu</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Rodrigues</keyname><forenames>Miguel R. D.</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steven W.</forenames></author></authors><title>Wireless Information-Theoretic Security - Part I: Theoretical Aspects</title><categories>cs.IT math.IT</categories><comments>27 pages, 14 figures, submitted to Special Issue of IEEE Trans. on
  Info. Theory on Information Theoretic Security</comments><abstract>  In this two-part paper, we consider the transmission of confidential data
over wireless wiretap channels. The first part presents an
information-theoretic problem formulation in which two legitimate partners
communicate over a quasi-static fading channel and an eavesdropper observes
their transmissions through another independent quasi-static fading channel. We
define the secrecy capacity in terms of outage probability and provide a
complete characterization of the maximum transmission rate at which the
eavesdropper is unable to decode any information. In sharp contrast with known
results for Gaussian wiretap channels (without feedback), our contribution
shows that in the presence of fading information-theoretic security is
achievable even when the eavesdropper has a better average signal-to-noise
ratio (SNR) than the legitimate receiver - fading thus turns out to be a friend
and not a foe. The issue of imperfect channel state information is also
addressed. Practical schemes for wireless information-theoretic security are
presented in Part II, which in some cases comes close to the secrecy capacity
limits given in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611121</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611121</id><created>2006-11-23</created><authors><author><keyname>Bloch</keyname><forenames>Matthieu</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Rodrigues</keyname><forenames>Miguel R. D.</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steven W.</forenames></author></authors><title>Wireless Information-Theoretic Security - Part II: Practical
  Implementation</title><categories>cs.IT math.IT</categories><comments>25 pages, 11 figures, submitted to Special Issue of IEEE Trans. on
  Info. Theory on Information Theoretic Security</comments><abstract>  In Part I of this two-part paper on confidential communication over wireless
channels, we studied the fundamental security limits of quasi-static fading
channels from the point of view of outage secrecy capacity with perfect and
imperfect channel state information. In Part II, we develop a practical secret
key agreement protocol for Gaussian and quasi-static fading wiretap channels.
The protocol uses a four-step procedure to secure communications: establish
common randomness via an opportunistic transmission, perform message
reconciliation, establish a common key via privacy amplification, and use of
the key. We introduce a new reconciliation procedure that uses multilevel
coding and optimized low density parity check codes which in some cases comes
close to achieving the secrecy capacity limits established in Part I. Finally,
we develop new metrics for assessing average secure key generation rates and
show that our protocol is effective in secure key renewal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611122</id><created>2006-11-23</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author><author><keyname>Bichler</keyname><forenames>Martin</forenames></author></authors><title>Knowledge Representation Concepts for Automated SLA Management</title><categories>cs.SE cs.AI cs.LO cs.PL</categories><comments>Paschke, A. and Bichler, M.: Knowledge Representation Concepts for
  Automated SLA Management, Int. Journal of Decision Support Systems (DSS),
  submitted 19th March 2006</comments><acm-class>I.2</acm-class><abstract>  Outsourcing of complex IT infrastructure to IT service providers has
increased substantially during the past years. IT service providers must be
able to fulfil their service-quality commitments based upon predefined Service
Level Agreements (SLAs) with the service customer. They need to manage, execute
and maintain thousands of SLAs for different customers and different types of
services, which needs new levels of flexibility and automation not available
with the current technology. The complexity of contractual logic in SLAs
requires new forms of knowledge representation to automatically draw inferences
and execute contractual agreements. A logic-based approach provides several
advantages including automated rule chaining allowing for compact knowledge
representation as well as flexibility to adapt to rapidly changing business
requirements. We suggest adequate logical formalisms for representation and
enforcement of SLA rules and describe a proof-of-concept implementation. The
article describes selected formalisms of the ContractLog KR and their adequacy
for automated SLA management and presents results of experiments to demonstrate
flexibility and scalability of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611123</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611123</id><created>2006-11-23</created><authors><author><keyname>Frigyik</keyname><forenames>B. A.</forenames></author><author><keyname>Srivastava</keyname><forenames>S.</forenames></author><author><keyname>Gupta</keyname><forenames>M. R.</forenames></author></authors><title>Functional Bregman Divergence and Bayesian Estimation of Distributions</title><categories>cs.IT cs.LG math.IT</categories><comments>26 pages, 1 figure</comments><abstract>  A class of distortions termed functional Bregman divergences is defined,
which includes squared error and relative entropy. A functional Bregman
divergence acts on functions or distributions, and generalizes the standard
Bregman divergence for vectors and a previous pointwise Bregman divergence that
was defined for functions. A recently published result showed that the mean
minimizes the expected Bregman divergence. The new functional definition
enables the extension of this result to the continuous case to show that the
mean minimizes the expected functional Bregman divergence over a set of
functions or distributions. It is shown how this theorem applies to the
Bayesian estimation of distributions. Estimation of the uniform distribution
from independent and identically drawn samples is used as a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611124</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611124</id><created>2006-11-24</created><authors><author><keyname>Abernethy</keyname><forenames>Jacob</forenames></author><author><keyname>Bach</keyname><forenames>Francis</forenames></author><author><keyname>Evgeniou</keyname><forenames>Theodoros</forenames></author><author><keyname>Vert</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Low-rank matrix factorization with attributes</title><categories>cs.LG cs.AI cs.IR</categories><comments>12 pages, 2 figures</comments><report-no>N-24/06/MM</report-no><abstract>  We develop a new collaborative filtering (CF) method that combines both
previously known users' preferences, i.e. standard CF, as well as product/user
attributes, i.e. classical function approximation, to predict a given user's
interest in a particular product. Our method is a generalized low rank matrix
completion problem, where we learn a function whose inputs are pairs of vectors
-- the standard low rank matrix completion problem being a special case where
the inputs to the function are the row and column indices of the matrix. We
solve this generalized matrix completion problem using tensor product kernels
for which we also formally generalize standard kernel properties. Benchmark
experiments on movie ratings show the advantages of our generalized matrix
completion method over the standard matrix completion one with no information
about movies or people, as well as over standard multi-task or single task
learning methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611125</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611125</id><created>2006-11-24</created><updated>2007-03-24</updated><authors><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Relay Channels with Confidential Messages</title><categories>cs.IT math.IT</categories><comments>20 pages, 6 figures, submitted to IEEE Transactions on Information
  Theory, Special issue on Information Theoretic Security</comments><abstract>  We consider a relay channel where a relay helps the transmission of messages
from one sender to one receiver. The relay is considered not only as a sender
that helps the message transmission but as a wire-tapper who can obtain some
knowledge about the transmitted messages. In this paper we study the coding
problem of the relay channel under the situation that some of transmitted
messages are confidential to the relay. A security of such confidential
messages is measured by the conditional entropy. The rate region is defined by
the set of transmission rates for which messages are reliably transmitted and
the security of confidential messages is larger than a prescribed level. In
this paper we give two definition of the rate region. We first define the rate
region in the case of deterministic encoder and call it the deterministic rate
region. Next, we define the rate region in the case of stochastic encoder and
call it the stochastic rate region. We derive explicit inner and outer bounds
for the above two rate regions and present a class of relay channels where two
bounds match. Furthermore, we show that stochastic encoder can enlarge the rate
region. We also evaluate the deterministic rate region of the Gaussian relay
channel with confidential messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611126</id><created>2006-11-24</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Fouz</keyname><forenames>Mahmoud</forenames></author></authors><title>Hereditary Discrepancies in Different Numbers of Colors II</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><abstract>  We bound the hereditary discrepancy of a hypergraph $\HH$ in two colors in
terms of its hereditary discrepancy in $c$ colors. We show that
$\herdisc(\HH,2) \le K c \herdisc(\HH,c)$, where $K$ is some absolute constant.
This bound is sharp.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611127</id><created>2006-11-24</created><authors><author><keyname>Montarnal</keyname><forenames>Philippe</forenames></author><author><keyname>Dimier</keyname><forenames>Alain</forenames></author><author><keyname>Deville</keyname><forenames>Estelle</forenames></author><author><keyname>Adam</keyname><forenames>Erwan</forenames></author><author><keyname>Gaombalet</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Bengaouer</keyname><forenames>Alain</forenames></author><author><keyname>Loth</keyname><forenames>Laurent</forenames></author><author><keyname>Chavant</keyname><forenames>Cl&#xe9;ment</forenames></author></authors><title>Coupling Methodology within the Software Platform Alliances</title><categories>cs.MS cs.CE</categories><comments>7 pages</comments><proxy>ccsd hal-00116195</proxy><journal-ref>Computational Methods for Coupled Problems in Science and
  Engineering (04/2005) CD-ROM</journal-ref><abstract>  CEA, ANDRA and EDF are jointly developing the software platform ALLIANCES
which aim is to produce a tool for the simulation of nuclear waste storage and
disposal repository. This type of simulations deals with highly coupled
thermo-hydro-mechanical and chemical (T-H-M-C) processes. A key objective of
Alliances is to give the capability for coupling algorithms development between
existing codes. The aim of this paper is to present coupling methodology use in
the context of this software platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611128</id><created>2006-11-25</created><updated>2006-12-06</updated><authors><author><keyname>Guclu</keyname><forenames>Hasan</forenames></author><author><keyname>Yuksel</keyname><forenames>Murat</forenames></author></authors><title>Scale-Free Overlay Topologies with Hard Cutoffs for Unstructured
  Peer-to-Peer Networks</title><categories>cs.NI cs.DC</categories><comments>19 pages, 12 figures, submitted to ICDCS 2007 (International
  Conference on Distributed Computing Systems 2007), one minor correction and
  formatting changes</comments><abstract>  In unstructured peer-to-peer (P2P) networks, the overlay topology (or
connectivity graph) among peers is a crucial component in addition to the
peer/data organization and search. Topological characteristics have profound
impact on the efficiency of search on such unstructured P2P networks as well as
other networks. It has been well-known that search on small-world topologies of
N nodes can be as efficient as O(ln N), while scale-free (power-law) topologies
offer even better search efficiencies like as good as O(lnln N) for a range of
degree distribution exponents. However, generation and maintenance of such
scale-free topologies are hard to realize in a distributed and potentially
uncooperative environments as in the P2P networks. A key limitation of
scale-free topologies is the high load (i.e. high degree) on very few number of
hub nodes. In a typical unstructured P2P network, peers are not willing to
maintain high degrees/loads as they may not want to store large number of
entries for construction of the overlay topology. So, to achieve fairness and
practicality among all peers, hard cutoffs on the number of entries are imposed
by the individual peers, which limits scale-freeness of the overall topology.
Thus, efficiency of the flooding search reduces as the size of the hard cutoff
does. We investigate construction of scale-free topologies with hard cutoffs
(i.e. there are not any major hubs) and effect of these hard cutoffs on the
search efficiency. Interestingly, we observe that the efficiency of normalized
flooding and random walk search algorithms increases as the hard cutoff
decreases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611129</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611129</id><created>2006-11-26</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Shannon's secrecy system with informed receivers and its application to
  systematic coding for wiretapped channels</title><categories>cs.IT math.IT</categories><abstract>  Shannon's secrecy system is studied in a setting, where both the legitimate
decoder and the wiretapper have access to side information sequences correlated
to the source, but the wiretapper receives both the coded information and the
side information via channels that are more noisy than the respective channels
of the legitmate decoder, which in turn, also shares a secret key with the
encoder. A single--letter characterization is provided for the achievable
region in the space of five figures of merit: the equivocation at the
wiretapper, the key rate, the distortion of the source reconstruction at the
legitimate receiver, the bandwidth expansion factor of the coded channels, and
the average transmission cost (generalized power). Beyond the fact that this is
an extension of earlier studies, it also provides a framework for studying
fundamental performance limits of systematic codes in the presence of a wiretap
channel. The best achievable performance of systematic codes is then compared
to that of a general code in several respects, and a few examples are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611130</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611130</id><created>2006-11-26</created><authors><author><keyname>Mele</keyname><forenames>Salvatore</forenames></author><author><keyname>Dallman</keyname><forenames>David</forenames></author><author><keyname>Vigen</keyname><forenames>Jens</forenames></author><author><keyname>Yeomans</keyname><forenames>Joanne</forenames></author></authors><title>Quantitative Analysis of the Publishing Landscape in High-Energy Physics</title><categories>cs.DL hep-ex hep-ph hep-th</categories><comments>For a better on-screen viewing experience this paper can also be
  obtained at:
  http://doc.cern.ch/archive/electronic/cern/preprints/open/open-2006-065.pdf</comments><report-no>CERN-OPEN-2006-065</report-no><journal-ref>JHEP0612:S01,2006</journal-ref><doi>10.1088/1126-6708/2006/12/S01</doi><abstract>  World-wide collaboration in high-energy physics (HEP) is a tradition which
dates back several decades, with scientific publications mostly coauthored by
scientists from different countries. This coauthorship phenomenon makes it
difficult to identify precisely the ``share'' of each country in HEP scientific
production. One year's worth of HEP scientific articles published in
peer-reviewed journals is analysed and their authors are uniquely assigned to
countries. This method allows the first correct estimation on a ``pro rata''
basis of the share of HEP scientific publishing among several countries and
institutions. The results provide an interesting insight into the geographical
collaborative patterns of the HEP community. The HEP publishing landscape is
further analysed to provide information on the journals favoured by the HEP
community and on the geographical variation of their author bases. These
results provide quantitative input to the ongoing debate on the possible
transition of HEP publishing to an Open Access model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611131</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611131</id><created>2006-11-26</created><updated>2007-05-30</updated><authors><author><keyname>Adamic</keyname><forenames>Lada A.</forenames></author><author><keyname>Bhavnani</keyname><forenames>Suresh K.</forenames></author><author><keyname>Shi</keyname><forenames>Xiaolin</forenames></author></authors><title>Scatter Networks: A New Approach for Analyzing Information Scatter on
  the Web</title><categories>cs.IR</categories><comments>minor revision: updated references and assortativity analysis, fixed
  typos</comments><abstract>  Information on any given topic is often scattered across the web. Previously
this scatter has been characterized through the distribution of a set of facts
(i.e. pieces of information) across web pages, showing that typically a few
pages contain many facts on the topic, while many pages contain just a few.
While such approaches have revealed important scatter phenomena, they are lossy
in that they conceal how specific facts (e.g. rare facts) occur in specific
types of pages (e.g. fact-rich pages). To reveal such regularities, we
construct bi-partite networks, consisting of two types of vertices: the facts
contained in webpages and the webpages themselves. Such a representation
enables the application of a series of network analysis techniques, revealing
structural features such as connectivity, robustness, and clustering. We
discuss the implications of each of these features to the users' ability to
find comprehensive information online. Finally, we compare the bipartite graph
structure of webpages and facts with the hyperlink structure between the
webpages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611132</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611132</id><created>2006-11-26</created><authors><author><keyname>Migunov</keyname><forenames>Vladimir V.</forenames></author></authors><title>The specifications making in complex CAD-system of renovation of the
  enterprises on the basis of modules in the drawing and electronic catalogues</title><categories>cs.CE</categories><comments>8 pages, 4 figures, in Russian</comments><acm-class>E.2; I.2.1; J.6</acm-class><abstract>  The experience of automation of the specifications making of the projects of
renovation of the industrial enterprises is described, being based on the
special modules in the drawing containing the visible image and additional
parameters, and electronic catalogues
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611133</id><created>2006-11-26</created><authors><author><keyname>Migunov</keyname><forenames>Vladimir V.</forenames></author></authors><title>The modelling of the automation schemes of technological processes in
  CAD-system of renovation of the enterprises</title><categories>cs.CE</categories><comments>4 pages, 3 figures, in Russian</comments><acm-class>I.2.1; J.6</acm-class><abstract>  According to the requirements of the Russian standards, the automation
schemes are necessary practically in each project of renovation of industrial
buildings and facilities, in which any technological processes are realized.
The model representations of the automation schemes in CAD-system TechnoCAD
GlassX are described. The models follow a principle &quot;to exclude a repeated
input operations&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611134</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611134</id><created>2006-11-27</created><authors><author><keyname>Safonov</keyname><forenames>Vladimir L.</forenames></author></authors><title>Hard Disk Drive as a Magnetomechanical Logic Device</title><categories>cs.OH cs.AR</categories><comments>3pages, 3 figures</comments><abstract>  We consider the conditions how two binary numbers can be superimposed on the
same track with the use of different recording magnetic fields. As a result the
average magnetization of longitudinal medium along the track can have three
states: -M, 0 and +M. Possibility to perform logic operations with these states
is considered. We demonstrate OR, AND, XOR and NOT operations and discuss a
modification of a recording device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611135</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611135</id><created>2006-11-27</created><authors><author><keyname>Gagn&#xe9;</keyname><forenames>Christian</forenames><affiliation>INRIA Futurs, ISI</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs, LRI</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LRI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author></authors><title>Genetic Programming for Kernel-based Learning with Co-evolving Subsets
  Selection</title><categories>cs.AI</categories><proxy>ccsd inria-00116344</proxy><journal-ref>Dans PPSN'06, 4193 (2006) 1008-1017</journal-ref><abstract>  Support Vector Machines (SVMs) are well-established Machine Learning (ML)
algorithms. They rely on the fact that i) linear learning can be formalized as
a well-posed optimization problem; ii) non-linear learning can be brought into
linear learning thanks to the kernel trick and the mapping of the initial
search space onto a high dimensional feature space. The kernel is designed by
the ML expert and it governs the efficiency of the SVM approach. In this paper,
a new approach for the automatic design of kernels by Genetic Programming,
called the Evolutionary Kernel Machine (EKM), is presented. EKM combines a
well-founded fitness function inspired from the margin criterion, and a
co-evolution framework ensuring the computational scalability of the approach.
Empirical validation on standard ML benchmark demonstrates that EKM is
competitive using state-of-the-art SVMs with tuned hyper-parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611136</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611136</id><created>2006-11-27</created><authors><author><keyname>Rietman</keyname><forenames>E. A.</forenames></author><author><keyname>Hillis</keyname><forenames>R. W.</forenames></author></authors><title>Neural Computation with Rings of Quasiperiodic Oscillators</title><categories>cs.RO</categories><comments>54 pages, 26 figures</comments><report-no>PSI SR-1278</report-no><abstract>  We describe the use of quasiperiodic oscillators for computation and control
of robots. We also describe their relationship to central pattern generators in
simple organisms and develop a group theory for describing the dynamics of
these systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611137</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611137</id><created>2006-11-27</created><authors><author><keyname>Golder</keyname><forenames>Scott</forenames></author><author><keyname>Wilkinson</keyname><forenames>Dennis M.</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Rhythms of social interaction: messaging within a massive online network</title><categories>cs.CY physics.soc-ph</categories><doi>10.1007/978-1-84628-905-7_3</doi><abstract>  We have analyzed the fully-anonymized headers of 362 million messages
exchanged by 4.2 million users of Facebook, an online social network of college
students, during a 26 month interval. The data reveal a number of strong daily
and weekly regularities which provide insights into the time use of college
students and their social lives, including seasonal variations. We also
examined how factors such as school affiliation and informal online friend
lists affect the observed behavior and temporal patterns. Finally, we show that
Facebook users appear to be clustered by school with respect to their temporal
messaging patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611138</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611138</id><created>2006-11-27</created><authors><author><keyname>Krmicek</keyname><forenames>Vojtech</forenames><affiliation>INRIA Futurs, LRI</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>INRIA Futurs, LRI</affiliation></author></authors><title>Functional Brain Imaging with Multi-Objective Multi-Modal Evolutionary
  Optimization</title><categories>cs.AI</categories><proxy>ccsd inria-00116342</proxy><journal-ref>Dans PPSN'06, 4193 (2006) 382-391</journal-ref><abstract>  Functional brain imaging is a source of spatio-temporal data mining problems.
A new framework hybridizing multi-objective and multi-modal optimization is
proposed to formalize these data mining problems, and addressed through
Evolutionary Computation (EC). The merits of EC for spatio-temporal data mining
are demonstrated as the approach facilitates the modelling of the experts'
requirements, and flexibly accommodates their changing goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611139</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611139</id><created>2006-11-28</created><authors><author><keyname>Garoche</keyname><forenames>Pierre-Lo&#xef;c</forenames><affiliation>IRIT</affiliation></author><author><keyname>Pantel</keyname><forenames>Marc</forenames><affiliation>IRIT</affiliation></author><author><keyname>Thirioux</keyname><forenames>Xavier</forenames><affiliation>IRIT</affiliation></author></authors><title>Static Safety for an Actor Dedicated Process Calculus by Abstract
  Interpretation</title><categories>cs.DC</categories><proxy>ccsd hal-00116251</proxy><journal-ref>Formal Methods for Open Object-Based Distributed Systems
  (26/05/2006) 78-92</journal-ref><doi>10.1007/11768869_8</doi><abstract>  The actor model eases the definition of concurrent programs with non uniform
behaviors. Static analysis of such a model was previously done in a data-flow
oriented way, with type systems. This approach was based on constraint set
resolution and was not able to deal with precise properties for communications
of behaviors. We present here a new approach, control-flow oriented, based on
the abstract interpretation framework, able to deal with communication of
behaviors. Within our new analyses, we are able to verify most of the previous
properties we observed as well as new ones, principally based on occurrence
counting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611140</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611140</id><created>2006-11-28</created><authors><author><keyname>Semet</keyname><forenames>Yann</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>On the Benefits of Inoculation, an Example in Train Scheduling</title><categories>cs.AI cs.NE</categories><proxy>ccsd inria-00116345</proxy><journal-ref>Dans GECCO-2006 (2006)</journal-ref><abstract>  The local reconstruction of a railway schedule following a small perturbation
of the traffic, seeking minimization of the total accumulated delay, is a very
difficult and tightly constrained combinatorial problem. Notoriously enough,
the railway company's public image degrades proportionally to the amount of
daily delays, and the same goes for its profit! This paper describes an
inoculation procedure which greatly enhances an evolutionary algorithm for
train re-scheduling. The procedure consists in building the initial population
around a pre-computed solution based on problem-related information available
beforehand. The optimization is performed by adapting times of departure and
arrival, as well as allocation of tracks, for each train at each station. This
is achieved by a permutation-based evolutionary algorithm that relies on a
semi-greedy heuristic scheduler to gradually reconstruct the schedule by
inserting trains one after another. Experimental results are presented on
various instances of a large real-world case involving around 500 trains and
more than 1 million constraints. In terms of competition with commercial math
ematical programming tool ILOG CPLEX, it appears that within a large class of
instances, excluding trivial instances as well as too difficult ones, and with
very few exceptions, a clever initialization turns an encouraging failure into
a clear-cut success auguring of substantial financial savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611141</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611141</id><created>2006-11-28</created><authors><author><keyname>Tiedemann</keyname><forenames>Peter</forenames></author><author><keyname>Andersen</keyname><forenames>Henrik Reif</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>A Generic Global Constraint based on MDDs</title><categories>cs.AI</categories><comments>Tech report, 31 pages, 3 figures</comments><abstract>  The paper suggests the use of Multi-Valued Decision Diagrams (MDDs) as the
supporting data structure for a generic global constraint. We give an algorithm
for maintaining generalized arc consistency (GAC) on this constraint that
amortizes the cost of the GAC computation over a root-to-terminal path in the
search tree. The technique used is an extension of the GAC algorithm for the
regular language constraint on finite length input. Our approach adds support
for skipped variables, maintains the reduced property of the MDD dynamically
and provides domain entailment detection. Finally we also show how to adapt the
approach to constraint types that are closely related to MDDs, such as AOMDDs
and Case DAGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611142</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611142</id><created>2006-11-28</created><authors><author><keyname>Chevalier</keyname><forenames>Yannick</forenames><affiliation>IRIT</affiliation></author><author><keyname>Kourjieh</keyname><forenames>Mounira</forenames><affiliation>IRIT</affiliation></author></authors><title>A Symbolic Intruder Model for Hash-Collision Attacks</title><categories>cs.CR</categories><proxy>ccsd hal-00116845</proxy><journal-ref>CSTVA'06, France (25/09/2006)</journal-ref><abstract>  In the recent years, several practical methods have been published to compute
collisions on some commonly used hash functions. In this paper we present a
method to take into account, at the symbolic level, that an intruder actively
attacking a protocol execution may use these collision algorithms in reasonable
time during the attack. Our decision procedure relies on the reduction of
constraint solving for an intruder exploiting the collision properties of hush
functions to constraint solving for an intruder operating on words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611143</identifier>
 <datestamp>2007-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611143</id><created>2006-11-28</created><updated>2007-07-18</updated><authors><author><keyname>Villemonteix</keyname><forenames>Julien</forenames></author><author><keyname>Vazquez</keyname><forenames>Emmanuel</forenames></author><author><keyname>Walter</keyname><forenames>Eric</forenames></author></authors><title>An informational approach to the global optimization of
  expensive-to-evaluate functions</title><categories>cs.NA</categories><comments>Accepted for publication in the Journal of Global Optimization (This
  is the revised version, with additional details on computational problems,
  and some grammatical changes)</comments><acm-class>G.1.1; G.1.6</acm-class><abstract>  In many global optimization problems motivated by engineering applications,
the number of function evaluations is severely limited by time or cost. To
ensure that each evaluation contributes to the localization of good candidates
for the role of global minimizer, a sequential choice of evaluation points is
usually carried out. In particular, when Kriging is used to interpolate past
evaluations, the uncertainty associated with the lack of information on the
function can be expressed and used to compute a number of criteria accounting
for the interest of an additional evaluation at any given point. This paper
introduces minimizer entropy as a new Kriging-based criterion for the
sequential choice of points at which the function should be evaluated. Based on
\emph{stepwise uncertainty reduction}, it accounts for the informational gain
on the minimizer expected from a new evaluation. The criterion is approximated
using conditional simulations of the Gaussian process model behind Kriging, and
then inserted into an algorithm similar in spirit to the \emph{Efficient Global
Optimization} (EGO) algorithm. An empirical comparison is carried out between
our criterion and \emph{expected improvement}, one of the reference criteria in
the literature. Experimental results indicate major evaluation savings over
EGO. Finally, the method, which we call IAGO (for Informational Approach to
Global Optimization) is extended to robust optimization problems, where both
the factors to be tuned and the function evaluations are corrupted by noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611144</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611144</id><created>2006-11-28</created><updated>2007-05-02</updated><authors><author><keyname>Ying</keyname><forenames>Lei</forenames></author><author><keyname>Yang</keyname><forenames>Sichao</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Coding Improves the Optimal Delay-Throughput Trade-offs in Mobile Ad-Hoc
  Networks: Two-Dimensional I.I.D. Mobility Models</title><categories>cs.NI cs.IT math.IT</categories><comments>Minor changes</comments><abstract>  In this paper, we investigate the delay-throughput trade-offs in mobile
ad-hoc networks under two-dimensional i.i.d. mobility models. We consider two
mobility time-scales: (i) Fast mobility where node mobility is at the same
time-scale as data transmissions; (ii) Slow mobility where node mobility is
assumed to occur at a much slower time-scale than data transmissions. Given a
delay constraint $D,$ the main results are as follows: (1) For the
two-dimensional i.i.d. mobility model with fast mobiles, the maximum throughput
per source-destination (S-D) pair is shown to be $O(\sqrt{D/n}),$ where $n$ is
the number of mobiles. (2) For the two-dimensional i.i.d. mobility model with
slow mobiles, the maximum throughput per S-D pair is shown to be
$O(\sqrt[3]{D/n}).$ (3) For each case, we propose a joint coding-scheduling
algorithm to achieve the optimal delay-throughput trade-offs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611145</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611145</id><created>2006-11-28</created><authors><author><keyname>Loth</keyname><forenames>Manuel</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Preux</keyname><forenames>Philippe</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>A Unified View of TD Algorithms; Introducing Full-Gradient TD and
  Equi-Gradient Descent TD</title><categories>cs.LG</categories><proxy>ccsd inria-00116936</proxy><journal-ref>Dans European Symposium on Artificial Neural Networks (2006)</journal-ref><abstract>  This paper addresses the issue of policy evaluation in Markov Decision
Processes, using linear function approximation. It provides a unified view of
algorithms such as TD(lambda), LSTD(lambda), iLSTD, residual-gradient TD. It is
asserted that they all consist in minimizing a gradient function and differ by
the form of this function and their means of minimizing it. Two new schemes are
introduced in that framework: Full-gradient TD which uses a generalization of
the principle introduced in iLSTD, and EGD TD, which reduces the gradient by
successive equi-gradient descents. These three algorithms form a new
intermediate family with the interesting property of making much better use of
the samples than TD while keeping a gradient descent scheme, which is useful
for complexity issues and optimistic policy iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611146</identifier>
 <datestamp>2009-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611146</id><created>2006-11-28</created><updated>2009-03-31</updated><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>Linear-Codes-Based Lossless Joint Source-Channel Coding for
  Multiple-Access Channels</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figures</comments><journal-ref>IEEE Trans. Inf. Theory 55 (2009) 1468-1486</journal-ref><doi>10.1109/TIT.2009.2013009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general lossless joint source-channel coding (JSCC) scheme based on linear
codes and random interleavers for multiple-access channels (MACs) is presented
and then analyzed in this paper. By the information-spectrum approach and the
code-spectrum approach, it is shown that a linear code with a good joint
spectrum can be used to establish limit-approaching lossless JSCC schemes for
correlated general sources and general MACs, where the joint spectrum is a
generalization of the input-output weight distribution. Some properties of
linear codes with good joint spectra are investigated. A formula on the
&quot;distance&quot; property of linear codes with good joint spectra is derived, based
on which, it is further proved that, the rate of any systematic codes with good
joint spectra cannot be larger than the reciprocal of the corresponding
alphabet cardinality, and any sparse generator matrices cannot yield linear
codes with good joint spectra. The problem of designing arbitrary rate coding
schemes is also discussed. A novel idea called &quot;generalized puncturing&quot; is
proposed, which makes it possible that one good low-rate linear code is enough
for the design of coding schemes with multiple rates. Finally, various coding
problems of MACs are reviewed in a unified framework established by the
code-spectrum approach, under which, criteria and candidates of good linear
codes in terms of spectrum requirements for such problems are clearly
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611147</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611147</id><created>2006-11-29</created><updated>2009-08-25</updated><authors><author><keyname>G</keyname><forenames>Raju Renjit.</forenames></author></authors><title>P is not equal to NP</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This submission has been withdrawn at the request of the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611148</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611148</id><created>2006-11-29</created><updated>2006-12-13</updated><authors><author><keyname>Calzolari</keyname><forenames>Federico</forenames></author><author><keyname>Sassolini</keyname><forenames>Eva</forenames></author><author><keyname>Sassi</keyname><forenames>Manuela</forenames></author><author><keyname>Cucurullo</keyname><forenames>Sebastiana</forenames></author><author><keyname>Picchi</keyname><forenames>Eugenio</forenames></author><author><keyname>Bertagna</keyname><forenames>Francesca</forenames></author><author><keyname>Enea</keyname><forenames>Alessandro</forenames></author><author><keyname>Monachini</keyname><forenames>Monica</forenames></author><author><keyname>Soria</keyname><forenames>Claudia</forenames></author><author><keyname>Calzolari</keyname><forenames>Nicoletta</forenames></author></authors><title>Next Generation Language Resources using GRID</title><categories>cs.DC cs.CL</categories><comments>4 pages</comments><journal-ref>Language Resources and Evaluation Conference LREC 2006 proceedings
  pp.1858-1861, Genoa [Italy]</journal-ref><abstract>  This paper presents a case study concerning the challenges and requirements
posed by next generation language resources, realized as an overall model of
open, distributed and collaborative language infrastructure. If a sort of &quot;new
paradigm&quot; is required, we think that the emerging and still evolving technology
connected to Grid computing is a very interesting and suitable one for a
concrete realization of this vision. Given the current limitations of Grid
computing, it is very important to test the new environment on basic language
analysis tools, in order to get the feeling of what are the potentialities and
possible limitations connected to its use in NLP. For this reason, we have done
some experiments on a module of Linguistic Miner, i.e. the extraction of
linguistic patterns from restricted domain corpora.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611149</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611149</id><created>2006-11-29</created><authors><author><keyname>Brahimi</keyname><forenames>Belynda</forenames><affiliation>CRAN</affiliation></author><author><keyname>Rondeau</keyname><forenames>Eric</forenames><affiliation>CRAN</affiliation></author><author><keyname>Aubrun</keyname><forenames>Christophe</forenames><affiliation>CRAN</affiliation></author></authors><title>Comparison between Networked Control System behaviour based on CAN and
  Switched Ethernet networks</title><categories>cs.NI</categories><comments>7 pages</comments><proxy>ccsd hal-00116970</proxy><journal-ref>2nd Workshop on Networked Control Systems : Tolerant to fault
  (23/11/2006) 7 pages</journal-ref><abstract>  The distributed control systems are more and more used in many industrial
applications. These systems are often referred as &quot;Networked control systems&quot;.
The goal of this paper is to show the network influence on feedback control
systems. Two networks are considered: Switched Ethernet network and CAN
fieldbus. The first one represents the non deterministic network and second one
represents the deterministic one. Several scenarii are studied to analyse the
stability of system according to different network parameters (packets losses,
congestion and frame priority). The Truetime simulator is used in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611150</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611150</id><created>2006-11-29</created><updated>2006-12-05</updated><authors><author><keyname>Sathe</keyname><forenames>Saket</forenames></author></authors><title>A Novel Bayesian Classifier using Copula Functions</title><categories>cs.LG cs.AI cs.IR</categories><abstract>  A useful method for representing Bayesian classifiers is through
\emph{discriminant functions}. Here, using copula functions, we propose a new
model for discriminants. This model provides a rich and generalized class of
decision boundaries. These decision boundaries significantly boost the
classification accuracy especially for high dimensional feature spaces. We
strengthen our analysis through simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611151</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611151</id><created>2006-11-29</created><updated>2007-02-01</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>Collaborative design : managing task interdependencies and multiple
  perspectives</title><categories>cs.HC</categories><proxy>ccsd inria-00117043</proxy><journal-ref>Interacting With Computers 18, 1 (2006) 1-20</journal-ref><abstract>  This paper focuses on two characteristics of collaborative design with
respect to cooperative work: the importance of work interdependencies linked to
the nature of design problems; and the fundamental function of design
cooperative work arrangement which is the confrontation and combination of
perspectives. These two intrinsic characteristics of the design work stress
specific cooperative processes: coordination processes in order to manage task
interdependencies, establishment of common ground and negotiation mechanisms in
order to manage the integration of multiple perspectives in design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611152</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611152</id><created>2006-11-29</created><updated>2007-02-01</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Martin</keyname><forenames>G&#xe9;raldine</forenames></author><author><keyname>Lavigne</keyname><forenames>Elisabeth</forenames></author></authors><title>Viewpoints in co-design: a field study in concurrent engineering</title><categories>cs.HC</categories><proxy>ccsd inria-00117051</proxy><journal-ref>Design Studies 26, 3 (2005) 215-241</journal-ref><abstract>  We present a field study aimed at analysing the use of viewpoints in
co-design meetings. A viewpoint is a representation characterised by a certain
combination of constraints. Three types of viewpoints are distinguished:
prescribed viewpoint, discipline-specific viewpoint and integrated viewpoint.
The contribution of our work consists in characterising the viewpoints of
various stakeholders involved in co-design (&quot;design office&quot; disciplines, and
production and maintenance disciplines), the dynamics of viewpoints
confrontation and the cooperative modes that enable these different viewpoints
to be integrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611153</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611153</id><created>2006-11-29</created><updated>2007-02-01</updated><authors><author><keyname>D'Astous</keyname><forenames>Patrick</forenames><affiliation>INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA</affiliation></author><author><keyname>Robillard</keyname><forenames>Pierre</forenames></author></authors><title>Changing our view on design evaluation meetings methodology: a study of
  software technical review meetings</title><categories>cs.HC</categories><proxy>ccsd inria-00117060</proxy><journal-ref>Design Studies (2004)</journal-ref><abstract>  By contrast to design meetings, design evaluation meetings (DEMs) have
generally been considered as situations in which, according to DEMs
methodologies, design activities are quite marginal. In a study of DEMs in
software development, i.e. in technical review meetings following a particular
review methodology, we showed: (i) the occurrence of design activities as part
of an argumentation process; (ii) the relative importance of cognitive
synchronisation as a prerequisite for evaluation; (iii) the important role
played in evaluation by argumentation that makes explicit the underlying design
rationale (DR). On the basis of our results, we discuss the potential for using
DR methodologies in this kind of meetings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611154</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611154</id><created>2006-11-29</created><updated>2007-03-02</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>Assessing the cognitive consequences of the object-oriented approach: a
  survey of empirical research on object-oriented design by individuals and
  teams</title><categories>cs.HC</categories><proxy>ccsd inria-00117062</proxy><journal-ref>Interacting with Computers 9 (1997) 47-72</journal-ref><abstract>  This paper presents a state-of-art review of empirical research on
object-oriented (OO) design. Many claims about the cognitive benefits of the OO
paradigm have been made by its advocates. These claims concern the ease of
designing and reusing software at the individual level as well as the benefits
of this paradigm at the team level. Since these claims are cognitive in nature,
its seems important to assess them empirically. After a brief presentation of
the main concepts of the OO paradigm, the claims about the superiority of OO
design are outlined. The core of this paper consists of a review of empirical
studies of OOD. We first discuss results concerning OOD by individuals. On the
basis of empirical work, we (1) analyse the design activity of novice OO
designers, (2) compare OO design with procedural design and, (3) discuss a
typology of problems relevant for the OO approach. Then we assess the claims
about naturalness and ease of OO design. The next part discusses results on OO
software reuse. On the basis of empirical work, we (1) compare reuse in the OO
versus procedural paradigm, (2) discuss the potential for OO software reuse and
(3) analyse reuse activity in the OO paradigm. Then we assess claims on
reusability. The final part reviews empirical work on OO design by teams. We
present results on communication, coordination, knowledge dissemination and
interactions with clients. Then we assess claims about OOD at the software
design team level. In a general conclusion, we discuss the limitations of these
studies and give some directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611155</identifier>
 <datestamp>2007-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611155</id><created>2006-11-29</created><updated>2007-08-20</updated><authors><author><keyname>Kelley</keyname><forenames>Christine A.</forenames></author><author><keyname>Sridhara</keyname><forenames>Deepak</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Zig-zag and Replacement Product Graphs and LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to Journal of Advances in Mathematics of Communications,
  Aug. 2007</comments><abstract>  The performance of codes defined from graphs depends on the expansion
property of the underlying graph in a crucial way. Graph products, such as the
zig-zag product and replacement product provide new infinite families of
constant degree expander graphs. The paper investigates the use of zig-zag and
replacement product graphs for the construction of codes on graphs. A
modification of the zig-zag product is also introduced, which can operate on
two unbalanced biregular bipartite graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611156</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611156</id><created>2006-11-30</created><authors><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Vinodh</keyname><forenames>K.</forenames></author><author><keyname>Anand</keyname><forenames>M.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>D-MG Tradeoff and Optimal Codes for a Class of AF and DF Cooperative
  Communication Protocols</title><categories>cs.IT math.IT</categories><comments>17 pages, 5 figures</comments><abstract>  We consider cooperative relay communication in a fading channel environment
under the Orthogonal Amplify and Forward (OAF) and Orthogonal and
Non-Orthogonal Selection Decode and Forward (OSDF and NSDF) protocols. For all
these protocols, we compute the Diversity-Multiplexing Gain Tradeoff (DMT). We
construct DMT optimal codes for the protocols which are sphere decodable and,
in certain cases, incur minimum possible delay. Our results establish that the
DMT of the OAF protocol is identical to the DMT of the Non-Orthogonal Amplify
and Forward (NAF) protocol. Two variants of the NSDF protocol are considered:
fixed-NSDF and variable-NSDF protocol. In the variable-NSDF protocol, the
fraction of time duration for which the source alone transmits is allowed to
vary with the rate of communication. Among the class of static
amplify-and-forward and decode-and-forward protocols, the variable-NSDF
protocol is shown to have the best known DMT for any number of relays apart
from the two-relay case. When there are two relays, the variable-NSDF protocol
is shown to improve on the DMT of the best previously-known protocol for higher
values of the multiplexing gain. Our results also establish that the fixed-NSDF
protocol has a better DMT than the NAF protocol for any number of relays.
Finally, we present a DMT optimal code construction for the NAF protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611157</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611157</id><created>2006-11-30</created><authors><author><keyname>Cohen</keyname><forenames>Reuven</forenames></author><author><keyname>Gonen</keyname><forenames>Mira</forenames></author><author><keyname>Wool</keyname><forenames>Avishai</forenames></author></authors><title>Bounding the Bias of Tree-Like Sampling in IP Topologies</title><categories>cs.NI</categories><comments>12 pages, 1 figure</comments><abstract>  It is widely believed that the Internet's AS-graph degree distribution obeys
a power-law form. Most of the evidence showing the power-law distribution is
based on BGP data. However, it was recently argued that since BGP collects data
in a tree-like fashion, it only produces a sample of the degree distribution,
and this sample may be biased. This argument was backed by simulation data and
mathematical analysis, which demonstrated that under certain conditions a tree
sampling procedure can produce an artificail power-law in the degree
distribution. Thus, although the observed degree distribution of the AS-graph
follows a power-law, this phenomenon may be an artifact of the sampling
process. In this work we provide some evidence to the contrary. We show, by
analysis and simulation, that when the underlying graph degree distribution
obeys a power-law with an exponent larger than 2, a tree-like sampling process
produces a negligible bias in the sampled degree distribution. Furthermore,
recent data collected from the DIMES project, which is not based on BGP
sampling, indicates that the underlying AS-graph indeed obeys a power-law
degree distribution with an exponent larger than 2. By combining this empirical
data with our analysis, we conclude that the bias in the degree distribution
calculated from BGP data is negligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611158</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611158</id><created>2006-11-30</created><updated>2007-02-02</updated><authors><author><keyname>Baker</keyname><forenames>Michael</forenames><affiliation>INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Lundt</keyname><forenames>Kristine</forenames></author><author><keyname>S&#xe9;journ&#xe9;</keyname><forenames>Arnauld</forenames></author></authors><title>Articulation entre \'{e}laboration de solutions et argumentation
  polyphonique</title><categories>cs.HC</categories><proxy>ccsd inria-00117081</proxy><journal-ref>Dans EPIQUE'2003 (2003)</journal-ref><abstract>  In this paper, we propose an analytical framework that aims to bring out the
nature of participants' contributions to co-design meetings, in a way that
synthesises content and function dimensions, together with the dimension of
dialogicality. We term the resulting global vision of contribution, the
&quot;interactive profile&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611159</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611159</id><created>2006-11-30</created><updated>2007-02-01</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>INRIA</affiliation></author><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA</affiliation></author></authors><title>Cognitive Effort in Collective Software Design: Methodological
  Perspectives in Cognitive Ergonomics</title><categories>cs.HC</categories><proxy>ccsd inria-00117083</proxy><journal-ref>Dans 2nd Workshop on Empirical Software Engineering (2003) 17-25</journal-ref><abstract>  Empirical software engineering is concerned with measuring, or estimating,
both the effort put into the software process and the quality of its product.
We defend the idea that measuring process effort and product quality and
establishing a relation between the two cannot be performed without a model of
cognitive and collective activities involved in software design, and without
measurement of these activities. This is the object of our field, i.e.
Cognitive Ergonomics of design. After a brief presentation of its theoretical
and methodological foundations, we will discuss a cognitive approach to design
activities and its potential to provide new directions in ESE. Then we will
present and discuss an illustration of the methodological directions we have
proposed for the analysis and measurement of cognitive activities in the
context of collective software design. The two situations analysed are
technical review meetings, and Request For Comments-like procedures in Open
Source Software design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611160</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611160</id><created>2006-11-30</created><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>Complementary Sets, Generalized Reed-Muller Codes, and Power Control for
  OFDM</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Trans. Inf. Theory, vol. 53, no. 2, pp. 808-814, 2007</journal-ref><abstract>  The use of error-correcting codes for tight control of the peak-to-mean
envelope power ratio (PMEPR) in orthogonal frequency-division multiplexing
(OFDM) transmission is considered in this correspondence. By generalizing a
result by Paterson, it is shown that each q-phase (q is even) sequence of
length 2^m lies in a complementary set of size 2^{k+1}, where k is a
nonnegative integer that can be easily determined from the generalized Boolean
function associated with the sequence. For small k this result provides a
reasonably tight bound for the PMEPR of q-phase sequences of length 2^m. A new
2^h-ary generalization of the classical Reed-Muller code is then used together
with the result on complementary sets to derive flexible OFDM coding schemes
with low PMEPR. These codes include the codes developed by Davis and Jedwab as
a special case. In certain situations the codes in the present correspondence
are similar to Paterson's code constructions and often outperform them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611161</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611161</id><created>2006-11-30</created><updated>2007-05-25</updated><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>On the Peak-to-Mean Envelope Power Ratio of Phase-Shifted Binary Codes</title><categories>cs.IT math.IT</categories><comments>minor revisions, accepted for IEEE Trans. Commun.</comments><journal-ref>IEEE Trans. Commun., vol. 56, no. 11, pp. 1816-1823, 2008</journal-ref><abstract>  The peak-to-mean envelope power ratio (PMEPR) of a code employed in
orthogonal frequency-division multiplexing (OFDM) systems can be reduced by
permuting its coordinates and by rotating each coordinate by a fixed phase
shift. Motivated by some previous designs of phase shifts using suboptimal
methods, the following question is considered in this paper. For a given binary
code, how much PMEPR reduction can be achieved when the phase shifts are taken
from a 2^h-ary phase-shift keying (2^h-PSK) constellation? A lower bound on the
achievable PMEPR is established, which is related to the covering radius of the
binary code. Generally speaking, the achievable region of the PMEPR shrinks as
the covering radius of the binary code decreases. The bound is then applied to
some well understood codes, including nonredundant BPSK signaling, BCH codes
and their duals, Reed-Muller codes, and convolutional codes. It is demonstrated
that most (presumably not optimal) phase-shift designs from the literature
attain or approach our bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611162</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611162</id><created>2006-11-30</created><updated>2009-09-24</updated><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>Quaternary Constant-Amplitude Codes for Multicode CDMA</title><categories>cs.IT math.IT</categories><comments>This is the revised journal version</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 55, no. 4, pp. 1824-1832, April 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A constant-amplitude code is a code that reduces the peak-to-average power
ratio (PAPR) in multicode code-division multiple access (MC-CDMA) systems to
the favorable value 1. In this paper quaternary constant-amplitude codes (codes
over Z_4) of length 2^m with error-correction capabilities are studied. These
codes exist for every positive integer m, while binary constant-amplitude codes
cannot exist if m is odd. Every word of such a code corresponds to a function
from the binary m-tuples to Z_4 having the bent property, i.e., its Fourier
transform has magnitudes 2^{m/2}. Several constructions of such functions are
presented, which are exploited in connection with algebraic codes over Z_4 (in
particular quaternary Reed-Muller, Kerdock, and Delsarte-Goethals codes) to
construct families of quaternary constant-amplitude codes. Mappings from binary
to quaternary constant-amplitude codes are presented as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611163</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611163</id><created>2006-11-30</created><authors><author><keyname>Kalles</keyname><forenames>Dimitris</forenames><affiliation>Hellenic Open University</affiliation></author></authors><title>On Measuring the Impact of Human Actions in the Machine Learning of a
  Board Game's Playing Policies</title><categories>cs.AI cs.GT cs.NE</categories><comments>Contains 19 pages, 10 figures, 8 tables. Submitted to a journal</comments><abstract>  We investigate systematically the impact of human intervention in the
training of computer players in a strategy board game. In that game, computer
players utilise reinforcement learning with neural networks for evolving their
playing strategies and demonstrate a slow learning speed. Human intervention
can significantly enhance learning performance, but carry-ing it out
systematically seems to be more of a problem of an integrated game development
environment as opposed to automatic evolutionary learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611164</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611164</id><created>2006-11-30</created><authors><author><keyname>Kalles</keyname><forenames>Dimitris</forenames><affiliation>Hellenic Open University</affiliation></author></authors><title>Player co-modelling in a strategy board game: discovering how to play
  fast</title><categories>cs.AI cs.LG</categories><comments>Contains 19 pages, 6 figures, 7 tables. Submitted to a journal</comments><abstract>  In this paper we experiment with a 2-player strategy board game where playing
models are evolved using reinforcement learning and neural networks. The models
are evolved to speed up automatic game development based on human involvement
at varying levels of sophistication and density when compared to fully
autonomous playing. The experimental results suggest a clear and measurable
association between the ability to win games and the ability to do that fast,
while at the same time demonstrating that there is a minimum level of human
involvement beyond which no learning really occurs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611165</identifier>
 <datestamp>2013-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611165</id><created>2006-11-30</created><authors><author><keyname>Correa</keyname><forenames>Ricardo C.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Partially ordered distributed computations on asynchronous
  point-to-point networks</title><categories>cs.DC</categories><journal-ref>Parallel Computing 35 (2009), 12-28</journal-ref><doi>10.1016/j.parco.2008.09.011</doi><abstract>  Asynchronous executions of a distributed algorithm differ from each other due
to the nondeterminism in the order in which the messages exchanged are handled.
In many situations of interest, the asynchronous executions induced by
restricting nondeterminism are more efficient, in an application-specific
sense, than the others. In this work, we define partially ordered executions of
a distributed algorithm as the executions satisfying some restricted orders of
their actions in two different frameworks, those of the so-called event- and
pulse-driven computations. The aim of these restrictions is to characterize
asynchronous executions that are likely to be more efficient for some important
classes of applications. Also, an asynchronous algorithm that ensures the
occurrence of partially ordered executions is given for each case. Two of the
applications that we believe may benefit from the restricted nondeterminism are
backtrack search, in the event-driven case, and iterative algorithms for
systems of linear equations, in the pulse-driven case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0611166</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0611166</id><created>2006-11-30</created><updated>2009-03-10</updated><authors><author><keyname>Kalles</keyname><forenames>Dimitris</forenames></author><author><keyname>Papagelis</keyname><forenames>Athanassios</forenames></author></authors><title>Lossless fitness inheritance in genetic algorithms for decision trees</title><categories>cs.AI cs.DS cs.NE</categories><comments>Contains 23 pages, 6 figures, 12 tables. Text last updated as of
  March 6, 2009. Submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When genetic algorithms are used to evolve decision trees, key tree quality
parameters can be recursively computed and re-used across generations of
partially similar decision trees. Simply storing instance indices at leaves is
enough for fitness to be piecewise computed in a lossless fashion. We show the
derivation of the (substantial) expected speed-up on two bounding case problems
and trace the attractive property of lossless fitness inheritance to the
divide-and-conquer nature of decision trees. The theoretical results are
supported by experimental evidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612001</id><created>2006-12-01</created><authors><author><keyname>Delacorte</keyname><forenames>Matthew</forenames></author></authors><title>Polynomial Time Symmetry and Isomorphism Testing for Connected Graphs</title><categories>cs.DM</categories><abstract>  We use the concept of a Kirchhoff resistor network (alternatively random walk
on a network) to probe connected graphs and produce symmetry revealing
canonical labelings of the graph(s) nodes and edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612002</id><created>2006-11-30</created><authors><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Trousse</keyname><forenames>Brigitte</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Reuse of designs: Desperately seeking an interdisciplinary cognitive
  approach</title><categories>cs.HC cs.AI</categories><proxy>ccsd inria-00117275</proxy><journal-ref>Dans IJCAI Thirteenth International Joint Conference on Artificial
  Intelligence Workshop &quot;Reuse of designs: An interdisciplinary cognitive
  approach&quot; (1993)</journal-ref><abstract>  This text analyses the papers accepted for the workshop &quot;Reuse of designs: an
interdisciplinary cognitive approach&quot;. Several dimensions and questions
considered as important (by the authors and/or by us) are addressed: What about
the &quot;interdisciplinary cognitive&quot; character of the approaches adopted by the
authors? Is design indeed a domain where the use of CBR is particularly
suitable? Are there important distinctions between CBR and other approaches?
Which types of knowledge -other than cases- is being, or might be, used in CBR
systems? With respect to cases: are there different &quot;types&quot; of case and
different types of case use? which formats are adopted for their
representation? do cases have &quot;components&quot;? how are cases organised in the case
memory? Concerning their retrieval: which types of index are used? on which
types of relation is retrieval based? how does one retrieve only a selected
number of cases, i.e., how does one retrieve only the &quot;best&quot; cases? which
processes and strategies are used, by the system and by its user? Finally, some
important aspects of CBR system development are shortly discussed: should CBR
systems be assistance or autonomous systems? how can case knowledge be
&quot;acquired&quot;? what about the empirical evaluation of CBR systems? The conclusion
points out some lacking points: not much attention is paid to the user, and few
papers have indeed adopted an interdisciplinary cognitive approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612003</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612003</id><created>2006-12-01</created><updated>2007-04-24</updated><authors><author><keyname>Lahiri</keyname><forenames>Shuvendu K.</forenames></author><author><keyname>Ball</keyname><forenames>Thomas</forenames></author><author><keyname>Cook</keyname><forenames>Byron</forenames></author></authors><title>Predicate Abstraction via Symbolic Decision Procedures</title><categories>cs.LO cs.PL cs.SC</categories><comments>The final accepted paper for Logical Methods in Computer Science,
  special issue on CAV 2005. Editor Sriram Rajamani (sriram@microsoft.com).
  Please perform make to build the paper. The pdf file is paper.pdf, and the
  comments for the referee's is present in referee_comments</comments><acm-class>F.3.1; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 2 (April 24,
  2007) lmcs:1151</journal-ref><doi>10.2168/LMCS-3(2:1)2007</doi><abstract>  We present a new approach for performing predicate abstraction based on
symbolic decision procedures. Intuitively, a symbolic decision procedure for a
theory takes a set of predicates in the theory and symbolically executes a
decision procedure on all the subsets over the set of predicates. The result of
the symbolic decision procedure is a shared expression (represented by a
directed acyclic graph) that implicitly represents the answer to a predicate
abstraction query.
  We present symbolic decision procedures for the logic of Equality and
Uninterpreted Functions (EUF) and Difference logic (DIFF) and show that these
procedures run in pseudo-polynomial (rather than exponential) time. We then
provide a method to construct symbolic decision procedures for simple mixed
theories (including the two theories mentioned above) using an extension of the
Nelson-Oppen combination method. We present preliminary evaluation of our
Procedure on predicate abstraction benchmarks from device driver verification
in SLAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612004</id><created>2006-11-30</created><updated>2007-03-02</updated><authors><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>LEI</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Wiedenbeck</keyname><forenames>Susan</forenames></author></authors><title>Object-Oriented Program Comprehension: Effect of Expertise, Task and
  Phase</title><categories>cs.HC</categories><proxy>ccsd inria-00117300</proxy><journal-ref>Empirical Software Engineering (2002)</journal-ref><abstract>  The goal of our study is to evaluate the effect on program comprehension of
three factors that have not previously been studied in a single experiment.
These factors are programmer expertise (expert vs. novice), programming task
(documentation vs. reuse), and the development of understanding over time
(phase 1 vs. phase 2). This study is carried out in the context of the mental
model approach to comprehension based on van Dijk and Kintsch's model (1983).
One key aspect of this model is the distinction between two kinds of
representation the reader might construct from a text: 1) the textbase, which
refers to what is said in the text and how it is said, and 2) the situation
model, which represents the situation referred to by the text. We have
evaluated the effect of the three factors mentioned above on the development of
both the textbase (or program model) and the situation model in object-oriented
program comprehension. We found a four-way interaction of expertise, phase,
task and type of model. For the documentation group we found that experts and
novices differ in the elaboration of their situation model but not their
program model. There was no interaction of expertise with phase and type of
model in the documentation group. For the reuse group, there was a three-way
interaction between phase, expertise and type of model. For the novice reuse
group, the effect of the phase was to increase the construction of the
situation model but not the program model. With respect to the task, our
results show that novices do not spontaneously construct a strong situation
model but are able to do so if the task demands it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612005</id><created>2006-11-30</created><updated>2007-03-02</updated><authors><author><keyname>D'Astous</keyname><forenames>Patrick</forenames><affiliation>INRIA</affiliation></author><author><keyname>Robillard</keyname><forenames>Pierre</forenames><affiliation>INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Quantitative Measurements of the Influence of Participant Roles during
  Peer Review Meetings</title><categories>cs.HC</categories><proxy>ccsd inria-00117298</proxy><journal-ref>Empirical Software Engineering 6 (2001) 143-159</journal-ref><abstract>  Peer review meetings (PRMs) are formal meetings during which peers
systematically analyze artifacts to improve their quality and report on
non-conformities. This paper presents an approach based on protocol analysis
for quantifying the influence of participant roles during PRMs. Three views are
used to characterize the seven defined participant roles. The project view
defines three roles supervisor, procedure expert and developer. The meeting
view defines two roles: author and reviewer, and the task view defines the
roles reflecting direct and indirect interest in the artifact under review. The
analysis, based on log-linear modeling, shows that review activities have
different patterns, depending on their focus: form or content. The influence of
each role is analyzed with respect to this focus. Interpretation of the
quantitative data leads to the suggestion that PRMs could be improved by
creating three different types of reviews, each of which collects together
specific roles: form review, cognitive synchronization review and content
review.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612006</id><created>2006-11-30</created><authors><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Evocation and elaboration of solutions: Different types of
  problem-solving actions. An empirical study on the design of an aerospace
  artifact</title><categories>cs.HC</categories><proxy>ccsd inria-00000165</proxy><journal-ref>Dans COGNITIVA 90. At the crossroads of Artificial Intelligence,
  Cognitive science, and Neuroscience (1991) 689-696</journal-ref><abstract>  An observational study was conducted on a professional designer working on a
design project in aerospace industry. The protocol data were analyzed in order
to gain insight into the actions the designer used for the development of a
solution to the corresponding problem. Different processes are described: from
the &quot;simple&quot; evocation of a solution existing in memory, to the elaboration of
a &quot;new&quot; solution out of mnesic entities without any clear link to the current
problem. Control is addressed in so far as it concerns the priority among the
different types of development processes: the progression from evocation of a
&quot;standard&quot; solution to elaboration of a &quot;new&quot; solution is supposed to
correspond to the resulting order, that is, the one in which the designer's
activity proceeds. Short discussions of * the double status of &quot;problem&quot; and
&quot;solution,&quot; * the problem/solution knowledge units in memory and their access,
and * the different abstraction levels on which problem and solution
representations are developed, are illustrated by the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612007</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612007</id><created>2006-11-30</created><updated>2006-12-18</updated><authors><author><keyname>Lee</keyname><forenames>Juyul</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>High SNR Analysis for MIMO Broadcast Channels: Dirty Paper Coding vs.
  Linear Precoding</title><categories>cs.IT math.IT</categories><comments>33 pages; Submitted to IEEE Transactions on Information Theory</comments><acm-class>H.1.1</acm-class><abstract>  We study the MIMO broadcast channel and compare the achievable throughput for
the optimal strategy of dirty paper coding to that achieved with sub-optimal
and lower complexity linear precoding (e.g., zero-forcing and block
diagonalization) transmission. Both strategies utilize all available spatial
dimensions and therefore have the same multiplexing gain, but an absolute
difference in terms of throughput does exist. The sum rate difference between
the two strategies is analytically computed at asymptotically high SNR, and it
is seen that this asymptotic statistic provides an accurate characterization at
even moderate SNR levels. Furthermore, the difference is not affected by
asymmetric channel behavior when each user a has different average SNR.
Weighted sum rate maximization is also considered, and a similar quantification
of the throughput difference between the two strategies is performed. In the
process, it is shown that allocating user powers in direct proportion to user
weights asymptotically maximizes weighted sum rate. For multiple antenna users,
uniform power allocation across the receive antennas is applied after
distributing power proportional to the user weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612008</id><created>2006-12-01</created><updated>2007-03-02</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>Design Strategies and Knowledge in Object-Oriented Programming: Effects
  of Experience</title><categories>cs.HC</categories><proxy>ccsd inria-00117299</proxy><journal-ref>Human-Computer Interaction 10, 2-3 (1995) 129-170</journal-ref><abstract>  An empirical study was conducted to analyse design strategies and knowledge
used in object-oriented software design. Eight professional programmers
experienced with procedural programming languages and either experienced or not
experienced in object-oriented design strategies related to two central aspects
of the object-oriented paradigm: (1) associating actions, i.e., execution
steps, of a complex plan to different objects and revising a complex plan, and
(2) defining simple plans at different levels in the class hierarchy. As
regards the development of complex plans elements attached to different
objects, our results show that, for beginners in OOP, the description of
objects and the description of actions are not always integrated in an early
design phase, particularly for the declarative problem whereas, for the
programmers experienced in OOP, the description of objects and the description
of actions tend to be integrated in their first drafts of solutions whichever
the problem type. The analysis of design strategies reveal the use of different
knowledge according to subjects' language experience: (1) schemas related to
procedural languages; actions are organized in an execution order, or (2)
schemas related to object-oriented languages; actions and objects are
integrated, and actions are organised around objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612009</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612009</id><created>2006-12-01</created><authors><author><keyname>Barcellini</keyname><forenames>Flore</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>LEI</affiliation></author></authors><title>Users' participation to the design process in an Open Source Software
  online community</title><categories>cs.HC</categories><proxy>ccsd inria-00117337</proxy><journal-ref>Dans 18th Annual Workshop on Psychology of Programming Interest
  Group PPIG'05 (2006) 99-114</journal-ref><abstract>  The objective of this research is to analyse the ways members of open-source
software communities participate in design. In particular we focus on how users
of an Open Source (OS) programming language (Python) participate in adding new
functionalities to the language. Indeed, in the OS communities, users are
highly skilled in computer sciences; they do not correspond to the common
representation of end-users and can potentially participate to the design
process. Our study characterizes the Python galaxy and analyses a formal
process to introduce new functionalities to the language called Python
Enhancement Proposal (PEP) from the idea of language evolution to the PEP
implementation. The analysis of a particular pushed-by-users PEP from one
application domain community (financial), shows: that the design process is
distributed and specialized between online and physical interactions spaces;
and there are some cross participants between users and developers communities
which may reveal boundary spanners roles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612010</id><created>2006-12-01</created><updated>2007-02-01</updated><authors><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA Rocquencourt, INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA Rocquencourt, INRIA</affiliation></author></authors><title>Articulation entre composantes verbale et graphico-gestuelle de
  l'interaction dans des r\'{e}unions de conception architecturale</title><categories>cs.HC</categories><proxy>ccsd inria-00117076</proxy><journal-ref>Dans SCAN'05 (2005)</journal-ref><abstract>  This study is focused on the role of external representations, e.g.,
skteches, in collaborative architectural design. In particular, we analyse (1)
the use of graphico-gestural modalities and, (2) the articulation modes between
graphico-gestural and verbal modalities in design interaction. We have
elaborated a first classification which distinguishes between two modes of
articulation, articulation in integrated activities versus articulation in
parallel activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612011</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612011</id><created>2006-12-02</created><updated>2007-01-31</updated><authors><author><keyname>Xiao</keyname><forenames>Hua</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Estimation of Bit and Frame Error Rates of Low-Density Parity-Check
  Codes on Binary Symmetric Channels</title><categories>cs.IT math.IT</categories><comments>15 pages, 5 figures, submitted to IEEE Transactions on Communications
  on Apr. 24, 2006, revised on Oct. 31, 2006 and Jan. 30, 2007</comments><abstract>  A method for estimating the performance of low-density parity-check (LDPC)
codes decoded by hard-decision iterative decoding algorithms on binary
symmetric channels (BSC) is proposed. Based on the enumeration of the smallest
weight error patterns that can not be all corrected by the decoder, this method
estimates both the frame error rate (FER) and the bit error rate (BER) of a
given LDPC code with very good precision for all crossover probabilities of
practical interest. Through a number of examples, we show that the proposed
method can be effectively applied to both regular and irregular LDPC codes and
to a variety of hard-decision iterative decoding algorithms. Compared with the
conventional Monte Carlo simulation, the proposed method has a much smaller
computational complexity, particularly for lower error rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612012</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612012</id><created>2006-12-03</created><authors><author><keyname>Narayanan</keyname><forenames>Hariharan</forenames></author></authors><title>Geographic Gossip on Geometric Random Graphs via Affine Combinations</title><categories>cs.MA cs.IT math.IT</categories><comments>15 pages, submitted</comments><acm-class>C.2.2</acm-class><abstract>  In recent times, a considerable amount of work has been devoted to the
development and analysis of gossip algorithms in Geometric Random Graphs. In a
recently introduced model termed &quot;Geographic Gossip,&quot; each node is aware of its
position but possesses no further information. Traditionally, gossip protocols
have always used convex linear combinations to achieve averaging. We develop a
new protocol for Geographic Gossip, in which counter-intuitively, we use {\it
non-convex affine combinations} as updates in addition to convex combinations
to accelerate the averaging process. The dependence of the number of
transmissions used by our algorithm on the number of sensors $n$ is $n
\exp(O(\log \log n)^2) = n^{1 + o(1)}$. For the previous algorithm, this
dependence was $\tilde{O}(n^{1.5})$. The exponent 1+ o(1) of our algorithm is
asymptotically optimal. Our algorithm involves a hierarchical structure of
$\log \log n$ depth and is not completely decentralized. However, the extent of
control exercised by a sensor on another is restricted to switching the other
on or off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612013</id><created>2006-12-04</created><updated>2006-12-04</updated><authors><author><keyname>Pathan</keyname><forenames>Al-Mukaddim Khan</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Broberg</keyname><forenames>James</forenames></author><author><keyname>Bubendorfer</keyname><forenames>Kris</forenames></author></authors><title>Economy-based Content Replication for Peering Content Delivery Networks</title><categories>cs.DC</categories><comments>Technical Report, GRIDS-TR-2006-20, Grid Computing and Distributed
  Systems Laboratory, University of Melbourne, Australia</comments><abstract>  Existing Content Delivery Networks (CDNs) exhibit the nature of closed
delivery networks which do not cooperate with other CDNs and in practice,
islands of CDNs are formed. The logical separation between contents and
services in this context results in two content networking domains. In addition
to that, meeting the Quality of Service requirements of users according to
negotiated Service Level Agreement is crucial for a CDN. Present trends in
content networks and content networking capabilities give rise to the interest
in interconnecting content networks. Hence, in this paper, we present an open,
scalable, and Service-Oriented Architecture (SOA)-based system that assist the
creation of open Content and Service Delivery Networks (CSDNs), which scale and
supports sharing of resources through peering with other CSDNs. To encourage
resource sharing and peering arrangements between different CDN providers at
global level, we propose using market-based models by introducing an
economy-based strategy for content replication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612014</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612014</id><created>2006-12-04</created><authors><author><keyname>Standish</keyname><forenames>Russell K.</forenames></author></authors><title>Going Stupid with EcoLab</title><categories>cs.MA</categories><acm-class>I.6.7</acm-class><journal-ref>Simulation, Vol 84, 611-618 (2008)</journal-ref><doi>10.1177/0037549708097</doi><abstract>  In 2005, Railsback et al. proposed a very simple model ({\em Stupid
  Model}) that could be implemented within a couple of hours, and later
extended to demonstrate the use of common ABM platform functionality. They
provided implementations of the model in several agent based modelling
platforms, and compared the platforms for ease of implementation of this simple
model, and performance. In this paper, I implement Railsback et al's Stupid
Model in the EcoLab simulation platform, a C++ based modelling platform,
demonstrating that it is a feasible platform for these sorts of models, and
compare the performance of the implementation with Repast, Mason and Swarm
versions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612015</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612015</id><created>2006-12-04</created><authors><author><keyname>Rif&#xe0;</keyname><forenames>Authors J.</forenames></author><author><keyname>Solov'eva</keyname><forenames>F.</forenames></author><author><keyname>Villanueva</keyname><forenames>M.</forenames></author></authors><title>On the intersection of additive perfect codes</title><categories>cs.IT math.IT</categories><comments>Submitted to Trans. Inform. Theory</comments><acm-class>E.4</acm-class><abstract>  The intersection problem for additive (extended and non-extended) perfect
codes, i.e. which are the possibilities for the number of codewords in the
intersection of two additive codes C1 and C2 of the same length, is
investigated. Lower and upper bounds for the intersection number are computed
and, for any value between these bounds, codes which have this given
intersection value are constructed.
  For all these codes the abelian group structure of the intersection is
characterized. The parameters of this abelian group structure corresponding to
the intersection codes are computed and lower and upper bounds for these
parameters are established. Finally, constructions of codes the intersection of
which fits any parameters between these bounds are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612016</id><created>2006-12-04</created><updated>2007-03-02</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>Memory of past designs: distinctive roles in individual and collective
  design</title><categories>cs.HC</categories><proxy>ccsd inria-00118150</proxy><journal-ref>Cognitive Technology Journal 1, 8 (2003) 16-24</journal-ref><abstract>  Empirical studies on design have emphasised the role of memory of past
solutions. Design involves the use of generic knowledge as well as episodic
knowledge about past designs for analogous problems : in this way, it involves
the reuse of past designs. We analyse this mechanism of reuse from a
socio-cognitive viewpoint. According to a purely cognitive approach, reuse
involves cognitive mechanisms linked to the problem solving activity itself.
Our socio-cognitive approach accounts for these phenomena as well as reuse
mechanisms linked to cooperation, in particular coordination, and
confrontation/integration of viewpoints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612017</id><created>2006-12-04</created><updated>2007-03-02</updated><authors><author><keyname>Martin</keyname><forenames>G&#xe9;raldine</forenames><affiliation>INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Lavigne</keyname><forenames>Elisabeth</forenames></author></authors><title>Confrontation of viewpoints in a concurrent engineering process</title><categories>cs.HC</categories><proxy>ccsd inria-00118159</proxy><journal-ref>Integrated design and manufacturing in mechanical
  engineeringKluwer Academic Publishers (Ed.) (2002)</journal-ref><abstract>  We present an empirical study aimed at analysing the use of viewpoints in an
industrial Concurrent Engineering context. Our focus is on the viewpoints
expressed in the argumentative process taking place in evaluation meetings. Our
results show that arguments enabling a viewpoint or proposal to be defended are
often characterized by the use of constraints. One result involved the way in
which the proposals for solutions are assessed during these meetings. We have
revealed the existence of specific assessment modes in these meetings as well
as their combination. Then, we show that, even if some constraints are
apparently identically used by the different specialists involved in meetings,
various meanings and weightings are associated with these constraints by these
different specialists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612018</id><created>2006-12-04</created><updated>2007-03-02</updated><authors><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>INRIA, LEI</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Wiedenbeck</keyname><forenames>Susan</forenames></author></authors><title>Mental Representations Constructed by Experts and Novices in
  Object-Oriented Program Comprehension</title><categories>cs.HC</categories><proxy>ccsd inria-00118167</proxy><journal-ref>Dans Human-Computer Interaction, INTERACT'97 (1997)</journal-ref><abstract>  Previous studies on program comprehension were carried out largely in the
context of procedural languages. Our purpose is to develop and evaluate a
cognitive model of object-oriented (OO) program understanding. Our model is
based on the van Dijk and Kintsch's model of text understanding (1983). One key
aspect of this theoretical approach is the distinction between two kinds of
representation the reader might construct from a text: the textbase and the
situation model. On the basis of results of an experiment we have conducted, we
evaluate the cognitive validity of this distinction in OO program
understanding. We examine how the construction of these two representations is
differentially affected by the programmer's expertise and how they evolve
differentially over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612019</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612019</id><created>2006-12-04</created><updated>2013-01-24</updated><authors><author><keyname>Ziv</keyname><forenames>Jacob</forenames></author></authors><title>On Finite Memory Universal Data Compression and Classification of
  Individual Sequences</title><categories>cs.IT math.IT</categories><comments>The manuscrip was errneously replaced by a different one on a
  differnt topic, thus erasing the oricinal manuscript</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Consider the case where consecutive blocks of N letters of a semi-infinite
individual sequence X over a finite-alphabet are being compressed into binary
sequences by some one-to-one mapping. No a-priori information about X is
available at the encoder, which must therefore adopt a universal
data-compression algorithm. It is known that if the universal LZ77 data
compression algorithm is successively applied to N-blocks then the best
error-free compression for the particular individual sequence X is achieved, as
$N$ tends to infinity. The best possible compression that may be achieved by
any universal data compression algorithm for finite N-blocks is discussed. It
is demonstrated that context tree coding essentially achieves it. Next,
consider a device called classifier (or discriminator) that observes an
individual training sequence X. The classifier's task is to examine individual
test sequences of length N and decide whether the test N-sequence has the same
features as those that are captured by the training sequence X, or is
sufficiently different, according to some appropriatecriterion. Here again, it
is demonstrated that a particular universal context classifier with a
storage-space complexity that is linear in N, is essentially optimal. This may
contribute a theoretical &quot;individual sequence&quot; justification for the
Probabilistic Suffix Tree (PST) approach in learning theory and in
computational biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612020</id><created>2006-12-04</created><authors><author><keyname>Martin</keyname><forenames>G&#xe9;raldine</forenames><affiliation>INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Lavigne</keyname><forenames>Elisabeth</forenames></author></authors><title>Analysing viewpoints in design through the argumentation process</title><categories>cs.OH</categories><proxy>ccsd inria-00118247</proxy><journal-ref>Dans INTERACT 2001 (2001) 521-529</journal-ref><abstract>  We present an empirical study aimed at analysing the use of viewpoints in an
industrial Concurrent Engineering context. Our focus is on the viewpoints
expressed in the argumentative process taking place in evaluation meetings. Our
results show that arguments enabling a viewpoint or proposal to be defended are
often characterized by the use of constraints. Firstly, we show that, even if
some constraints are apparently identically used by the different specialists
involved in meetings, various meanings and weightings are associated with these
constraints by these different specialists. Secondly, we show that the implicit
or explicit nature of constraints depends on several interlocutive factors.
Thirdly, we show that an argument often covers not only one constraint but a
network of constraints. The type of combination reflects viewpoints which have
specific status in the meeting. Then, we will propose a first model of the
dynamics of viewpoints confrontation/integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612021</id><created>2006-12-04</created><updated>2007-03-04</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames></author><author><keyname>Visser</keyname><forenames>Willemien</forenames></author></authors><title>Multimodality and parallelism in design interaction: co-designers'
  alignment and coalitions</title><categories>cs.HC</categories><proxy>ccsd inria-00118255</proxy><journal-ref>Dans COOP'2006 Volume 137 (2006) 118-131</journal-ref><abstract>  This paper presents an analysis of various forms of articulation between
graphico-gestural and verbal modalities in parallel interactions between
designers in a collaborative design situation. Based on our methodological
framework, we illustrate several forms of multimodal articulations, that is,
integrated and non-integrated, through extracts from a corpus on an
architectural design meeting. These modes reveal alignment or disalignment
between designers, with respect to the focus of their activities. They also
show different forms of coalition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612022</id><created>2006-12-04</created><authors><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Both Generic Design and Different Forms of Designing</title><categories>cs.HC</categories><proxy>ccsd inria-00118256</proxy><journal-ref>Dans Wonderground, the 2006 DRS (Design Research Society)
  International Conference (2006)</journal-ref><abstract>  This paper defends an augmented cognitively oriented &quot;generic-design
hypothesis&quot;: There are both significant similarities between the design
activities implemented in different situations and crucial differences between
these and other cognitive activities; yet, characteristics of a design
situation (i.e., related to the designers, the artefact, and other task
variables influencing these two) introduce specificities in the corresponding
design activities and cognitive structures that are used. We thus combine the
generic-design hypothesis with that of different &quot;forms&quot; of designing. In this
paper, outlining a number of directions that need further elaboration, we
propose a series of candidate dimensions underlying such forms of design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612023</id><created>2006-12-04</created><updated>2007-03-02</updated><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Rouet</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>INRIA, LEI</affiliation></author><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>INRIA, LEI</affiliation></author><author><keyname>Deleuze-Dordron</keyname><forenames>Catherine</forenames></author></authors><title>Reusing processes and documenting processes: toward an integrated
  framework</title><categories>cs.HC</categories><proxy>ccsd inria-00118274</proxy><journal-ref>Dans ECCE8 (1996) 139-144</journal-ref><abstract>  This paper presents a cognitive typology of reuse processes, and a cognitive
typology of documenting processes. Empirical studies on design with reuse and
on software documenting provide evidence for a generalized cognitive model.
First, these studies emphasize the cyclical nature of design: cycles of
planning, writing and revising occur. Second, natural language documentation
follows the hierarchy of cognitive entities manipulated during design.
Similarly software reuse involves exploiting various types of knowledge
depending on the phase of design in which reuse is involved. We suggest that
these observations can be explained based on cognitive models of text
processing: the van Dijk and Kintsch (1983) model of text comprehension, and
the Hayes and Flower (1980) model of text production. Based on our generalized
cognitive model, we suggest a framework for documenting reusable components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612024</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612024</id><created>2006-12-05</created><authors><author><keyname>Cheng</keyname><forenames>Peng</forenames></author><author><keyname>Yu</keyname><forenames>Guanding</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Chen</keyname><forenames>Hsiao-Hwa</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>On the Maximum Sum-rate Capacity of Cognitive Multiple Access Channel</title><categories>cs.IT math.IT</categories><comments>3 pages, 4 figures</comments><abstract>  We consider the communication scenario where multiple cognitive users wish to
communicate to the same receiver, in the presence of primary transmission. The
cognitive transmitters are assumed to have the side information about the
primary transmission. The capacity region of cognitive users is formulated
under the constraint that the capacity of primary transmission is not changed
as if no cognitive users exist. Moreover, the maximum sum-rate point of the
capacity region is characterized, by optimally allocating the power of each
cognitive user to transmit its own information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612025</id><created>2006-12-05</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Registers</title><categories>cs.DC</categories><comments>5 pages, LaTeX, Entry in: Encyclopedia of Algorithms, Ming-Yang Kao,
  Ed., Springer, To appear</comments><abstract>  Entry in: Encyclopedia of Algorithms, Ming-Yang Kao, Ed., Springer, To
appear.
  Synonyms: Wait-free registers, wait-free shared variables, asynchronous
communication hardware. Problem Definition: Consider a system of asynchronous
processes that communicate among themselves by only executing read and write
operations on a set of shared variables (also known as shared registers). The
system has no global clock or other synchronization primitives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612026</id><created>2006-12-05</created><authors><author><keyname>Nguyen</keyname><forenames>Trung</forenames></author><author><keyname>Boissonnat</keyname><forenames>Jean-Daniel</forenames></author><author><keyname>Falzon</keyname><forenames>Frederic</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author></authors><title>A disk-covering problem with application in optical interferometry</title><categories>cs.CG</categories><comments>10 pages, 8 figures</comments><acm-class>I.3.5</acm-class><abstract>  Given a disk O in the plane called the objective, we want to find n small
disks P_1,...,P_n called the pupils such that $\bigcup_{i,j=1}^n P_i \ominus
P_j \supseteq O$, where $\ominus$ denotes the Minkowski difference operator,
while minimizing the number of pupils, the sum of the radii or the total area
of the pupils. This problem is motivated by the construction of very large
telescopes from several smaller ones by so-called Optical Aperture Synthesis.
In this paper, we provide exact, approximate and heuristic solutions to several
variations of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612027</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612027</id><created>2006-12-05</created><authors><author><keyname>Grabec</keyname><forenames>Igor</forenames></author></authors><title>Experimental Information and Statistical Modeling of Physical Laws</title><categories>cs.IT cs.IR math.IT</categories><comments>an article submitted to &quot;IEEE Transactions on Information Theory&quot;</comments><abstract>  Statistical modeling of physical laws connects experiments with mathematical
descriptions of natural phenomena. The modeling is based on the probability
density of measured variables expressed by experimental data via a kernel
estimator. As an objective kernel the scattering function determined by
calibration of the instrument is introduced. This function provides for a new
definition of experimental information and redundancy of experimentation in
terms of information entropy. The redundancy increases with the number of
experiments, while the experimental information converges to a value that
describes the complexity of the data. The difference between the redundancy and
the experimental information is proposed as the model cost function. From its
minimum, a proper number of data in the model is estimated. As an optimal,
nonparametric estimator of the relation between measured variables the
conditional average extracted from the kernel estimator is proposed. The
modeling is demonstrated on noisy chaotic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612028</identifier>
 <datestamp>2008-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612028</id><created>2006-12-05</created><updated>2006-12-14</updated><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Stepanov</keyname><forenames>Alexey A.</forenames></author></authors><title>Using Combinatorics to Prune Search Trees: Independent and Dominating
  Set</title><categories>cs.DS cs.DM</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612029</id><created>2006-12-05</created><authors><author><keyname>Chen</keyname><forenames>Ming-Zhe</forenames></author></authors><title>A Classification of 6R Manipulators</title><categories>cs.RO</categories><comments>4 pages</comments><abstract>  This paper presents a classification of generic 6-revolute jointed (6R)
manipulators using homotopy class of their critical point manifold. A part of
classification is listed in this paper because of the complexity of homotopy
class of 4-torus. The results of this classification will serve future research
of the classification and topological properties of maniplators joint space and
workspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612030</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612030</id><created>2006-12-05</created><authors><author><keyname>Mooij</keyname><forenames>Joris</forenames></author><author><keyname>Kappen</keyname><forenames>Bert</forenames></author></authors><title>Loop corrections for approximate inference</title><categories>cs.AI cs.IT cs.LG math.IT</categories><comments>Technical report, 38 pages, 14 figures</comments><journal-ref>Journal of Machine Learning Research 8(May):1113-1143, 2007</journal-ref><abstract>  We propose a method for improving approximate inference methods that corrects
for the influence of loops in the graphical model. The method is applicable to
arbitrary factor graphs, provided that the size of the Markov blankets is not
too large. It is an alternative implementation of an idea introduced recently
by Montanari and Rizzo (2005). In its simplest form, which amounts to the
assumption that no loops are present, the method reduces to the minimal Cluster
Variation Method approximation (which uses maximal factors as outer clusters).
On the other hand, using estimates of the effect of loops (obtained by some
approximate inference algorithm) and applying the Loop Correcting (LC) method
usually gives significantly better results than applying the approximate
inference algorithm directly without loop corrections. Indeed, we often observe
that the loop corrected error is approximately the square of the error of the
approximate inference method used to estimate the effect of loops. We compare
different variants of the Loop Correcting method with other approximate
inference methods on a variety of graphical models, including &quot;real world&quot;
networks, and conclude that the LC approach generally obtains the most accurate
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612031</id><created>2006-12-05</created><authors><author><keyname>McGregor</keyname><forenames>Andrew</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Estimating Aggregate Properties on Probabilistic Streams</title><categories>cs.DS cs.DB</categories><comments>11 pages</comments><abstract>  The probabilistic-stream model was introduced by Jayram et al. \cite{JKV07}.
It is a generalization of the data stream model that is suited to handling
``probabilistic'' data where each item of the stream represents a probability
distribution over a set of possible events. Therefore, a probabilistic stream
determines a distribution over potentially a very large number of classical
&quot;deterministic&quot; streams where each item is deterministically one of the domain
values. The probabilistic model is applicable for not only analyzing streams
where the input has uncertainties (such as sensor data streams that measure
physical processes) but also where the streams are derived from the input data
by post-processing, such as tagging or reconciling inconsistent and poor
quality data.
  We present streaming algorithms for computing commonly used aggregates on a
probabilistic stream. We present the first known, one pass streaming algorithm
for estimating the \AVG, improving results in \cite{JKV07}. We present the
first known streaming algorithms for estimating the number of \DISTINCT items
on probabilistic streams. Further, we present extensions to other aggregates
such as the repeat rate, quantiles, etc. In all cases, our algorithms work with
provable accuracy guarantees and within the space constraints of the data
stream model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612032</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612032</id><created>2006-12-05</created><authors><author><keyname>Burnashev</keyname><forenames>Marat V.</forenames></author></authors><title>Code Spectrum and Reliability Function: Binary Symmetric Channel</title><categories>cs.IT math.IT</categories><comments>23 pages, to be published in Problems of Information Transmission</comments><journal-ref>Problems of Information Transmission, vol. 42, no. 4, pp. 3-22,
  2006</journal-ref><abstract>  A new approach for upper bounding the channel reliability function using the
code spectrum is described. It allows to treat in a unified way both a low and
a high rate cases. In particular, the earlier known upper bounds are improved,
and a new derivation of the sphere-packing bound is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612033</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612033</id><created>2006-12-06</created><authors><author><keyname>Kempe</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Acronym-Meaning Extraction from Corpora Using Multi-Tape Weighted
  Finite-State Machines</title><categories>cs.CL cs.DS cs.SC</categories><comments>6 pages, LaTeX</comments><report-no>2006/019 (at Xerox Research Centre Europe, France)</report-no><acm-class>F.1.1; I.2.7</acm-class><abstract>  The automatic extraction of acronyms and their meaning from corpora is an
important sub-task of text mining. It can be seen as a special case of string
alignment, where a text chunk is aligned with an acronym. Alternative
alignments have different cost, and ideally the least costly one should give
the correct meaning of the acronym. We show how this approach can be
implemented by means of a 3-tape weighted finite-state machine (3-WFSM) which
reads a text chunk on tape 1 and an acronym on tape 2, and generates all
alternative alignments on tape 3. The 3-WFSM can be automatically generated
from a simple regular expression. No additional algorithms are required at any
stage. Our 3-WFSM has a size of 27 states and 64 transitions, and finds the
best analysis of an acronym in a few milliseconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612034</id><created>2006-12-06</created><authors><author><keyname>Francois</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Leduc</keyname><forenames>Guy</forenames></author></authors><title>Predictable Disruption Tolerant Networks and Delivery Guarantees</title><categories>cs.NI</categories><comments>9 pages</comments><abstract>  This article studies disruption tolerant networks (DTNs) where each node
knows the probabilistic distribution of contacts with other nodes. It proposes
a framework that allows one to formalize the behaviour of such a network. It
generalizes extreme cases that have been studied before where (a) either nodes
only know their contact frequency with each other or (b) they have a perfect
knowledge of who meets who and when. This paper then gives an example of how
this framework can be used; it shows how one can find a packet forwarding
algorithm optimized to meet the 'delay/bandwidth consumption' trade-off:
packets are duplicated so as to (statistically) guarantee a given delay or
delivery probability, but not too much so as to reduce the bandwidth, energy,
and memory consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612035</id><created>2006-12-06</created><authors><author><keyname>Fernandez</keyname><forenames>Antonio</forenames><affiliation>LADYR</affiliation></author><author><keyname>Gramoli</keyname><forenames>Vincent</forenames><affiliation>IRISA</affiliation></author><author><keyname>Jimenez</keyname><forenames>Ernesto</forenames><affiliation>EUI</affiliation></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames><affiliation>IRISA</affiliation></author><author><keyname>Raynal</keyname><forenames>Michel</forenames><affiliation>IRISA</affiliation></author></authors><title>Distributed Slicing in Dynamic Systems</title><categories>cs.DC</categories><proxy>ccsd inria-00118675</proxy><abstract>  Peer to peer (P2P) systems are moving from application specific architectures
to a generic service oriented design philosophy. This raises interesting
problems in connection with providing useful P2P middleware services that are
capable of dealing with resource assignment and management in a large-scale,
heterogeneous and unreliable environment. One such service, the slicing
service, has been proposed to allow for an automatic partitioning of P2P
networks into groups (slices) that represent a controllable amount of some
resource and that are also relatively homogeneous with respect to that
resource, in the face of churn and other failures. In this report we propose
two algorithms to solve the distributed slicing problem. The first algorithm
improves upon an existing algorithm that is based on gossip-based sorting of a
set of uniform random numbers. We speed up convergence via a heuristic for
gossip peer selection. The second algorithm is based on a different approach:
statistical approximation of the rank of nodes in the ordering. The
scalability, efficiency and resilience to dynamics of both algorithms relies on
their gossip-based models. We present theoretical and experimental results to
prove the viability of these algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612036</id><created>2006-12-06</created><authors><author><keyname>Dongarra</keyname><forenames>Jack</forenames></author><author><keyname>Pineau</keyname><forenames>Jean-Francois</forenames></author><author><keyname>Robert</keyname><forenames>Yves</forenames></author><author><keyname>Shi</keyname><forenames>Zhiao</forenames></author><author><keyname>Vivien</keyname><forenames>Frederic</forenames></author></authors><title>Revisiting Matrix Product on Master-Worker Platforms</title><categories>cs.DC cs.MS</categories><acm-class>F.2.2</acm-class><abstract>  This paper is aimed at designing efficient parallel matrix-product algorithms
for heterogeneous master-worker platforms. While matrix-product is
well-understood for homogeneous 2D-arrays of processors (e.g., Cannon algorithm
and ScaLAPACK outer product algorithm), there are three key hypotheses that
render our work original and innovative:
  - Centralized data. We assume that all matrix files originate from, and must
be returned to, the master.
  - Heterogeneous star-shaped platforms. We target fully heterogeneous
platforms, where computational resources have different computing powers.
  - Limited memory. Because we investigate the parallelization of large
problems, we cannot assume that full matrix panels can be stored in the worker
memories and re-used for subsequent updates (as in ScaLAPACK).
  We have devised efficient algorithms for resource selection (deciding which
workers to enroll) and communication ordering (both for input and result
messages), and we report a set of numerical experiments on various platforms at
Ecole Normale Superieure de Lyon and the University of Tennessee. However, we
point out that in this first version of the report, experiments are limited to
homogeneous platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612037</id><created>2006-12-06</created><authors><author><keyname>Leroux</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LaBRI</affiliation></author></authors><title>Least Significant Digit First Presburger Automata</title><categories>cs.DS</categories><proxy>ccsd hal-00118748</proxy><abstract>  Since 1969 \cite{C-MST69,S-SMJ77}, we know that any Presburger-definable set
\cite{P-PCM29} (a set of integer vectors satisfying a formula in the
first-order additive theory of the integers) can be represented by a
state-based symmbolic representation, called in this paper Finite Digit Vector
Automata (FDVA). Efficient algorithms for manipulating these sets have been
recently developed. However, the problem of deciding if a FDVA represents such
a set, is a well-known hard problem first solved by Muchnik in 1991 with a
quadruply-exponential time algorithm. In this paper, we show how to determine
in polynomial time whether a FDVA represents a Presburger-definable set, and we
provide in this positive case a polynomial time algorithm that constructs a
Presburger-formula that defines the same set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612038</id><created>2006-12-06</created><authors><author><keyname>Anashin</keyname><forenames>Vladimir</forenames></author></authors><title>Non-Archimedean analysis, T-functions, and cryptography</title><categories>cs.CR math.DS</categories><comments>53 pages, 9 figures, LaTeX 2e. Lecture notes of a 20-hour course at
  the International Summer School `Mathematical Methods and Technologies in
  Computer Security' at Lomonosov Moscow State University, July 9--23, 2006</comments><acm-class>E.3</acm-class><abstract>  These are lecture notes of a 20-hour course at the International Summer
School \emph{Mathematical Methods and Technologies in Computer Security} at
Lomonosov Moscow State University, July 9--23, 2006.
  Loosely speaking, a $T$-function is a map of $n$-bit words into $n$-bit words
such that each $i$-th bit of image depends only on low-order bits $0,..., i$ of
the pre-image. For example, all arithmetic operations (addition,
multiplication) are $T$-functions, all bitwise logical operations ($\XOR$,
$\AND$, etc.) are $T$-functions. Any composition of $T$-functions is a
$T$-function as well. Thus $T$-functions are natural computer word-oriented
functions.
  It turns out that $T$-functions are continuous (and often differentiable!)
functions with respect to the so-called 2-adic distance. This observation gives
a powerful tool to apply 2-adic analysis to construct wide classes of
$T$-functions with provable cryptographic properties (long period, balance,
uniform distribution, high linear complexity, etc.); these functions currently
are being used in new generation of fast stream ciphers. We consider these
ciphers as specific automata that could be associated to dynamical systems on
the space of 2-adic integers. From this view the lectures could be considered
as a course in cryptographic applications of the non-Archimedean dynamics; the
latter has recently attracted significant attention in connection with
applications to physics, biology and cognitive sciences.
  During the course listeners study non-Archimedean machinery and its
applications to stream cipher design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612039</id><created>2006-12-06</created><authors><author><keyname>Aras</keyname><forenames>Raghav</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Dutech</keyname><forenames>Alain</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Charpillet</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Computing the Equilibria of Bimatrix Games using Dominance Heuristics</title><categories>cs.GT</categories><proxy>ccsd hal-00118840</proxy><abstract>  We propose a formulation of a general-sum bimatrix game as a bipartite
directed graph with the objective of establishing a correspondence between the
set of the relevant structures of the graph (in particular elementary cycles)
and the set of the Nash equilibria of the game. We show that finding the set of
elementary cycles of the graph permits the computation of the set of
equilibria. For games whose graphs have a sparse adjacency matrix, this serves
as a good heuristic for computing the set of equilibria. The heuristic also
allows the discarding of sections of the support space that do not yield any
equilibrium, thus serving as a useful pre-processing step for algorithms that
compute the equilibria through support enumeration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612040</identifier>
 <datestamp>2008-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612040</id><created>2006-12-07</created><authors><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Chung</keyname><forenames>Fan</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author><author><keyname>Fomenkov</keyname><forenames>Marina</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author><author><keyname>Willinger</keyname><forenames>Walter</forenames></author></authors><title>The Workshop on Internet Topology (WIT) Report</title><categories>cs.NI</categories><acm-class>C.2.5; C.2.1</acm-class><journal-ref>ACM SIGCOMM Computer Communication Review (CCR), v.37, n.1,
  p.69-73, 2007</journal-ref><doi>10.1145/1198255.1198267</doi><abstract>  Internet topology analysis has recently experienced a surge of interest in
computer science, physics, and the mathematical sciences. However, researchers
from these different disciplines tend to approach the same problem from
different angles. As a result, the field of Internet topology analysis and
modeling must untangle sets of inconsistent findings, conflicting claims, and
contradicting statements.
  On May 10-12, 2006, CAIDA hosted the Workshop on Internet topology (WIT). By
bringing together a group of researchers spanning the areas of computer
science, physics, and the mathematical sciences, the workshop aimed to improve
communication across these scientific disciplines, enable interdisciplinary
crossfertilization, identify commonalities in the different approaches, promote
synergy where it exists, and utilize the richness that results from exploring
similar problems from multiple perspectives.
  This report describes the findings of the workshop, outlines a set of
relevant open research problems identified by participants, and concludes with
recommendations that can benefit all scientific communities interested in
Internet topology research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612041</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612041</id><created>2006-12-07</created><authors><author><keyname>Kempe</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Viterbi Algorithm Generalized for n-Tape Best-Path Search</title><categories>cs.CL cs.DS cs.SC</categories><comments>12 pages, 3 figures, LaTeX (+ .eps)</comments><acm-class>F.1.1; I.2.7</acm-class><journal-ref>Proc. FSMNLP 2009, Pretoria, South Africa. July 21-24. (improved
  version).</journal-ref><abstract>  We present a generalization of the Viterbi algorithm for identifying the path
with minimal (resp. maximal) weight in a n-tape weighted finite-state machine
(n-WFSM), that accepts a given n-tuple of input strings (s_1,... s_n). It also
allows us to compile the best transduction of a given input n-tuple by a
weighted (n+m)-WFSM (transducer) with n input and m output tapes. Our algorithm
has a worst-case time complexity of O(|s|^n |E| log (|s|^n |Q|)), where n and
|s| are the number and average length of the strings in the n-tuple, and |Q|
and |E| the number of states and transitions in the n-WFSM, respectively. A
straight forward alternative, consisting in intersection followed by classical
shortest-distance search, operates in O(|s|^n (|E|+|Q|) log (|s|^n |Q|)) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612042</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612042</id><created>2006-12-07</created><authors><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author></authors><title>Decentralized Maximum Likelihood Estimation for Sensor Networks Composed
  of Nonlinearly Coupled Dynamical Systems</title><categories>cs.DC cs.IT math.IT</categories><comments>Journal paper accepted on IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2007.893921</doi><abstract>  In this paper we propose a decentralized sensor network scheme capable to
reach a globally optimum maximum likelihood (ML) estimate through
self-synchronization of nonlinearly coupled dynamical systems. Each node of the
network is composed of a sensor and a first-order dynamical system initialized
with the local measurements. Nearby nodes interact with each other exchanging
their state value and the final estimate is associated to the state derivative
of each dynamical system. We derive the conditions on the coupling mechanism
guaranteeing that, if the network observes one common phenomenon, each node
converges to the globally optimal ML estimate. We prove that the synchronized
state is globally asymptotically stable if the coupling strength exceeds a
given threshold. Acting on a single parameter, the coupling strength, we show
how, in the case of nonlinear coupling, the network behavior can switch from a
global consensus system to a spatial clustering system. Finally, we show the
effect of the network topology on the scalability properties of the network and
we validate our theoretical findings with simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612043</id><created>2006-12-07</created><authors><author><keyname>Cilibrasi</keyname><forenames>R.</forenames><affiliation>CWI</affiliation></author><author><keyname>Lotker</keyname><forenames>Z.</forenames><affiliation>CWI</affiliation></author><author><keyname>Navarra</keyname><forenames>A.</forenames><affiliation>LaBRI - Univ. Bordeaux 1</affiliation></author><author><keyname>Perennes</keyname><forenames>S.</forenames><affiliation>CNRS/INRIA/Univ. Nice</affiliation></author><author><keyname>Vitanyi</keyname><forenames>P.</forenames><affiliation>CWI/Univ. Amsterdam</affiliation></author></authors><title>About the Lifespan of Peer to Peer Networks</title><categories>cs.DC cs.IR</categories><comments>15 pages, LaTeX, 1 figure, Proc. 10th Int'nl Conf. Principles Of
  Distributed Systems (OPODIS), Lecture Notes in Computer Science, Vol. 4305,
  Springer Verlag, Berlin, 2006, 290--305</comments><abstract>  We analyze the ability of peer to peer networks to deliver a complete file
among the peers. Early on we motivate a broad generalization of network
behavior organizing it into one of two successive phases. According to this
view the network has two main states: first centralized - few sources (roots)
hold the complete file, and next distributed - peers hold some parts (chunks)
of the file such that the entire network has the whole file, but no individual
has it. In the distributed state we study two scenarios, first, when the peers
are ``patient'', i.e, do not leave the system until they obtain the complete
file; second, peers are ``impatient'' and almost always leave the network
before obtaining the complete file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612044</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612044</id><created>2006-12-07</created><authors><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>The Relay-Eavesdropper Channel: Cooperation for Secrecy</title><categories>cs.IT math.IT</categories><comments>33 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  This paper establishes the utility of user cooperation in facilitating secure
wireless communications. In particular, the four-terminal relay-eavesdropper
channel is introduced and an outer-bound on the optimal rate-equivocation
region is derived. Several cooperation strategies are then devised and the
corresponding achievable rate-equivocation region are characterized. Of
particular interest is the novel Noise-Forwarding (NF) strategy, where the
relay node sends codewords independent of the source message to confuse the
eavesdropper. This strategy is used to illustrate the deaf helper phenomenon,
where the relay is able to facilitate secure communications while being totally
ignorant of the transmitted messages. Furthermore, NF is shown to increase the
secrecy capacity in the reversely degraded scenario, where the relay node fails
to offer performance gains in the classical setting. The gain offered by the
proposed cooperation strategies is then proved theoretically and validated
numerically in the additive White Gaussian Noise (AWGN) channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612045</id><created>2006-12-07</created><authors><author><keyname>Borrel</keyname><forenames>Vincent</forenames></author><author><keyname>Legendre</keyname><forenames>Franck</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author><author><keyname>Fdida</keyname><forenames>Serge</forenames></author></authors><title>SIMPS: Using Sociology for Personal Mobility</title><categories>cs.NI</categories><abstract>  Assessing mobility in a thorough fashion is a crucial step toward more
efficient mobile network design. Recent research on mobility has focused on two
main points: analyzing models and studying their impact on data transport.
These works investigate the consequences of mobility. In this paper, instead,
we focus on the causes of mobility. Starting from established research in
sociology, we propose SIMPS, a mobility model of human crowd motion. This model
defines two complimentary behaviors, namely socialize and isolate, that
regulate an individual with regard to her/his own sociability level. SIMPS
leads to results that agree with scaling laws observed both in small-scale and
large-scale human motion. Although our model defines only two simple individual
behaviors, we observe many emerging collective behaviors (group
formation/splitting, path formation, and evolution). To our knowledge, SIMPS is
the first model in the networking community that tackles the roots governing
mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612046</id><created>2006-12-07</created><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Social Networks and Social Information Filtering on Digg</title><categories>cs.HC cs.AI cs.IR</categories><comments>8 pages, 5 figures Submitted to the International Conference on
  Weblogs and Social Media</comments><abstract>  The new social media sites -- blogs, wikis, Flickr and Digg, among others --
underscore the transformation of the Web to a participatory medium in which
users are actively creating, evaluating and distributing information. Digg is a
social news aggregator which allows users to submit links to, vote on and
discuss news stories. Each day Digg selects a handful of stories to feature on
its front page. Rather than rely on the opinion of a few editors, Digg
aggregates opinions of thousands of its users to decide which stories to
promote to the front page.
  Digg users can designate other users as ``friends'' and easily track friends'
activities: what new stories they submitted, commented on or read. The friends
interface acts as a \emph{social filtering} system, recommending to user
stories his or her friends liked or found interesting. By tracking the votes
received by newly submitted stories over time, we showed that social filtering
is an effective information filtering approach. Specifically, we showed that
(a) users tend to like stories submitted by friends and (b) users tend to like
stories their friends read and liked. As a byproduct of social filtering,
social networks also play a role in promoting stories to Digg's front page,
potentially leading to ``tyranny of the minority'' situation where a
disproportionate number of front page stories comes from the same small group
of interconnected users. Despite this, social filtering is a promising new
technology that can be used to personalize and tailor information to individual
users: for example, through personal front pages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612047</id><created>2006-12-07</created><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Jones</keyname><forenames>Laurie</forenames></author></authors><title>Social Browsing on Flickr</title><categories>cs.HC cs.AI</categories><comments>8 pages; submitted to the International Conference on Weblogs and
  Social Media</comments><abstract>  The new social media sites - blogs, wikis, del.icio.us and Flickr, among
others - underscore the transformation of the Web to a participatory medium in
which users are actively creating, evaluating and distributing information. The
photo-sharing site Flickr, for example, allows users to upload photographs,
view photos created by others, comment on those photos, etc. As is common to
other social media sites, Flickr allows users to designate others as
``contacts'' and to track their activities in real time. The contacts (or
friends) lists form the social network backbone of social media sites. We claim
that these social networks facilitate new ways of interacting with information,
e.g., through what we call social browsing. The contacts interface on Flickr
enables users to see latest images submitted by their friends. Through an
extensive analysis of Flickr data, we show that social browsing through the
contacts' photo streams is one of the primary methods by which users find new
images on Flickr. This finding has implications for creating personalized
recommendation systems based on the user's declared contacts lists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612048</id><created>2006-12-07</created><authors><author><keyname>li</keyname><forenames>chunxi</forenames></author><author><keyname>chen</keyname><forenames>changjia</forenames></author></authors><title>Queue Model of Leaf Degree Keeping Process in Gnutella Network</title><categories>cs.NI cs.PF</categories><comments>3 pages, 6 figures</comments><abstract>  Leaf degree keeping process of Gnutella is discussed in this paper. Queue
system based on rules of Gnutella protocol are introduced to modeling this
process. The leaf degree distributions resulted from the queue system and from
our real measurement are compared. The well match of those distributions reveal
that the leaf degree distribution in Gnutella network should not be power law
or power law like as reported before. It is more likely a distribution driven
by certain queue process specified by the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612049</identifier>
 <datestamp>2007-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612049</id><created>2006-12-08</created><updated>2007-09-19</updated><authors><author><keyname>Pischella</keyname><forenames>Mylene</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Power Control in Distributed Cooperative OFDMA Cellular Networks</title><categories>cs.IT math.IT</categories><comments>Withdrawn</comments><abstract>  This paper has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612050</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612050</id><created>2006-12-08</created><updated>2007-10-15</updated><authors><author><keyname>Bus&#xe9;</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Explicit factors of some iterated resultants and discriminants</title><categories>cs.SC math.AC math.AG</categories><comments>Selected for presentation at the conference MEGA 2007 (Strobl,
  Austria, June 25th - 29th)</comments><proxy>ccsd inria-00119287</proxy><journal-ref>Mathematics of Computation / Mathematics of Computation of the
  American Mathematical Society 78 (2009) 345--386</journal-ref><abstract>  In this paper, the result of applying iterative univariate resultant
constructions to multivariate polynomials is analyzed. We consider the input
polynomials as generic polynomials of a given degree and exhibit explicit
decompositions into irreducible factors of several constructions involving two
times iterated univariate resultants and discriminants over the integer
universal ring of coefficients of the entry polynomials. Cases involving from
two to four generic polynomials and resultants or discriminants in one of their
variables are treated. The decompositions into irreducible factors we get are
obtained by exploiting fundamental properties of the univariate resultants and
discriminants and induction on the degree of the polynomials. As a consequence,
each irreducible factor can be separately and explicitly computed in terms of a
certain multivariate resultant. With this approach, we also obtain as direct
corollaries some results conjectured by Collins and McCallum which correspond
to the case of polynomials whose coefficients are themselves generic
polynomials in other variables. Finally, a geometric interpretation of the
algebraic factorization of the iterated discriminant of a single polynomial is
detailled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612051</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612051</id><created>2006-12-08</created><updated>2008-03-03</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>On the Decoder Error Probability of Bounded Rank-Distance Decoders for
  Maximum Rank Distance Codes</title><categories>cs.IT math.IT</categories><comments>5 pages. To appear in IEEE Transactions on Information Theory</comments><abstract>  In this paper, we first introduce the concept of elementary linear subspace,
which has similar properties to those of a set of coordinates. We then use
elementary linear subspaces to derive properties of maximum rank distance (MRD)
codes that parallel those of maximum distance separable codes. Using these
properties, we show that, for MRD codes with error correction capability t, the
decoder error probability of bounded rank distance decoders decreases
exponentially with t^2 based on the assumption that all errors with the same
rank are equally likely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612052</id><created>2006-12-08</created><authors><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Pal</keyname><forenames>Martin</forenames></author><author><keyname>Stein</keyname><forenames>Cliff</forenames></author></authors><title>Budget Optimization in Search-Based Advertising Auctions</title><categories>cs.DS cs.CE cs.GT</categories><abstract>  Internet search companies sell advertisement slots based on users' search
queries via an auction. While there has been a lot of attention on the auction
process and its game-theoretic aspects, our focus is on the advertisers. In
particular, the advertisers have to solve a complex optimization problem of how
to place bids on the keywords of their interest so that they can maximize their
return (the number of user clicks on their ads) for a given budget. We model
the entire process and study this budget optimization problem. While most
variants are NP hard, we show, perhaps surprisingly, that simply randomizing
between two uniform strategies that bid equally on all the keywords works well.
More precisely, this strategy gets at least 1-1/e fraction of the maximum
clicks possible. Such uniform strategies are likely to be practical. We also
present inapproximability results, and optimal algorithms for variants of the
budget optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612053</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612053</id><created>2006-12-08</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Huang</keyname><forenames>Xiaowu</forenames></author></authors><title>Deriving Schrodinger Equation From A Soft-Decision Iterative Decoding
  Algorithm</title><categories>cs.IT math.IT</categories><comments>An extended abstract version of this paper has been presented at
  International Conference on Quantum Foundation and Technology, August, 2006,
  HangZhou, China (ICQFT'06)</comments><abstract>  The belief propagation algorithm has been recognized in the information
theory community as a soft-decision iterative decoding algorithm. It is the
most powerful algorithm found so far for attacking hard optimization problems
in channel decoding. Quantum mechanics is the foundation of modern physics with
the time-independent Schrodinger equation being one of the most important
equations. This paper shows that the equation can be derived from a generalized
belief propagation algorithm. Such a connection on a mathematical basis might
shed new insights into the foundations of quantum mechanics and quantum
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612054</id><created>2006-12-08</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>Lightweight security mechanism for PSTN-VoIP cooperation</title><categories>cs.CR cs.MM</categories><comments>6 pages, 5 figures</comments><acm-class>K.6.5; D.4.6; K.4.2</acm-class><abstract>  In this paper we describe a new, lightweight security mechanism for PSTN-VoIP
cooperation that is based on two information hiding techniques: digital
watermarking and steganography. Proposed scheme is especially suitable for
PSTN-IP-PSTN (toll-by-passing) scenario which nowadays is very popular
application of IP Telephony systems. With the use of this mechanism we
authenticate end-to-end transmitted voice between PSTN users. Additionally we
improve IP part traffic security (both media stream and VoIP signalling
messages). Exemplary scenario is presented for SIP signalling protocol along
with SIP-T extension and H.248/Megaco protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612055</id><created>2006-12-08</created><authors><author><keyname>Pagh</keyname><forenames>Anna</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author><author><keyname>Ruzic</keyname><forenames>Milan</forenames></author></authors><title>Linear Probing with Constant Independence</title><categories>cs.DS cs.DB</categories><comments>13 pages</comments><abstract>  Hashing with linear probing dates back to the 1950s, and is among the most
studied algorithms. In recent years it has become one of the most important
hash table organizations since it uses the cache of modern computers very well.
Unfortunately, previous analysis rely either on complicated and space consuming
hash functions, or on the unrealistic assumption of free access to a truly
random hash function. Already Carter and Wegman, in their seminal paper on
universal hashing, raised the question of extending their analysis to linear
probing. However, we show in this paper that linear probing using a pairwise
independent family may have expected {\em logarithmic} cost per operation. On
the positive side, we show that 5-wise independence is enough to ensure
constant expected time per operation. This resolves the question of finding a
space and time efficient hash function that provably ensures good performance
for linear probing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612056</id><created>2006-12-09</created><authors><author><keyname>Gayathree</keyname><forenames>U.</forenames></author></authors><title>Conscious Intelligent Systems - Part 1 : I X I</title><categories>cs.AI</categories><abstract>  Did natural consciousness and intelligent systems arise out of a path that
was co-evolutionary to evolution? Can we explain human self-consciousness as
having risen out of such an evolutionary path? If so how could it have been?
  In this first part of a two-part paper (titled IXI), we take a learning
system perspective to the problem of consciousness and intelligent systems, an
approach that may look unseasonable in this age of fMRI's and high tech
neuroscience.
  We posit conscious intelligent systems in natural environments and wonder how
natural factors influence their design paths. Such a perspective allows us to
explain seamlessly a variety of natural factors, factors ranging from the rise
and presence of the human mind, man's sense of I, his self-consciousness and
his looping thought processes to factors like reproduction, incubation,
extinction, sleep, the richness of natural behavior, etc. It even allows us to
speculate on a possible human evolution scenario and other natural phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612057</id><created>2006-12-09</created><authors><author><keyname>Gayathree</keyname><forenames>U.</forenames></author></authors><title>Conscious Intelligent Systems - Part II - Mind, Thought, Language and
  Understanding</title><categories>cs.AI</categories><abstract>  This is the second part of a paper on Conscious Intelligent Systems. We use
the understanding gained in the first part (Conscious Intelligent Systems Part
1: IXI (arxiv id cs.AI/0612056)) to look at understanding. We see how the
presence of mind affects understanding and intelligent systems; we see that the
presence of mind necessitates language. The rise of language in turn has
important effects on understanding. We discuss the humanoid question and how
the question of self-consciousness (and by association mind/thought/language)
would affect humanoids too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612058</id><created>2006-12-10</created><authors><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author></authors><title>Adaptive Simulated Annealing: A Near-optimal Connection between Sampling
  and Counting</title><categories>cs.DS cs.DM</categories><acm-class>G.3</acm-class><abstract>  We present a near-optimal reduction from approximately counting the
cardinality of a discrete set to approximately sampling elements of the set. An
important application of our work is to approximating the partition function
$Z$ of a discrete system, such as the Ising model, matchings or colorings of a
graph. The typical approach to estimating the partition function $Z(\beta^*)$
at some desired inverse temperature $\beta^*$ is to define a sequence, which we
call a {\em cooling schedule}, $\beta_0=0&lt;\beta_1&lt;...&lt;\beta_\ell=\beta^*$ where
Z(0) is trivial to compute and the ratios $Z(\beta_{i+1})/Z(\beta_i)$ are easy
to estimate by sampling from the distribution corresponding to $Z(\beta_i)$.
Previous approaches required a cooling schedule of length $O^*(\ln{A})$ where
$A=Z(0)$, thereby ensuring that each ratio $Z(\beta_{i+1})/Z(\beta_i)$ is
bounded. We present a cooling schedule of length $\ell=O^*(\sqrt{\ln{A}})$.
  For well-studied problems such as estimating the partition function of the
Ising model, or approximating the number of colorings or matchings of a graph,
our cooling schedule is of length $O^*(\sqrt{n})$, which implies an overall
savings of $O^*(n)$ in the running time of the approximate counting algorithm
(since roughly $\ell$ samples are needed to estimate each ratio).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612059</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612059</id><created>2006-12-11</created><authors><author><keyname>Malinowski</keyname><forenames>Simon</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author><author><keyname>J&#xe9;gou</keyname><forenames>Herv&#xe9;</forenames><affiliation>IRISA / INRIA Rennes, INRIA Rh&#xf4;ne-Alpes / GRAVIR-IMAG</affiliation></author><author><keyname>Guillemot</keyname><forenames>Christine</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author></authors><title>Synchronization recovery and state model reduction for soft decoding of
  variable length codes</title><categories>cs.NI cs.IT math.IT</categories><proxy>ccsd inria-00119600</proxy><journal-ref>IEEE transactions on information theory (2006)</journal-ref><abstract>  Variable length codes exhibit de-synchronization problems when transmitted
over noisy channels. Trellis decoding techniques based on Maximum A Posteriori
(MAP) estimators are often used to minimize the error rate on the estimated
sequence. If the number of symbols and/or bits transmitted are known by the
decoder, termination constraints can be incorporated in the decoding process.
All the paths in the trellis which do not lead to a valid sequence length are
suppressed. This paper presents an analytic method to assess the expected error
resilience of a VLC when trellis decoding with a sequence length constraint is
used. The approach is based on the computation, for a given code, of the amount
of information brought by the constraint. It is then shown that this quantity
as well as the probability that the VLC decoder does not re-synchronize in a
strict sense, are not significantly altered by appropriate trellis states
aggregation. This proves that the performance obtained by running a
length-constrained Viterbi decoder on aggregated state models approaches the
one obtained with the bit/symbol trellis, with a significantly reduced
complexity. It is then shown that the complexity can be further decreased by
projecting the state model on two state models of reduced size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612060</id><created>2006-12-11</created><authors><author><keyname>Kenkre</keyname><forenames>Sreyash</forenames></author><author><keyname>Vishwanathan</keyname><forenames>Sundar</forenames></author></authors><title>The Common Prefix Problem On Trees</title><categories>cs.DS cs.CC</categories><comments>8 pages</comments><abstract>  We present a theoretical study of a problem arising in database query
optimization, which we call as The Common Prefix Problem. We present a
$(1-o(1))$ factor approximation algorithm for this problem, when the underlying
graph is a binary tree. We then use a result of Feige and Kogan to show that
even on stars, the problem is hard to approximate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612061</identifier>
 <datestamp>2007-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612061</id><created>2006-12-11</created><updated>2007-10-17</updated><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Trustworthy content push</title><categories>cs.CR</categories><comments>4 pages, 4 eps figures</comments><journal-ref>Wireless Communications and Networking Conference, 2007.WCNC 2007.
  IEEE, March 2007 Page(s):2909 - 2912</journal-ref><doi>10.1109/WCNC.2007.539</doi><abstract>  Delivery of content to mobile devices gains increasing importance in
industrial environments to support employees in the field. An important
application are e-mail push services like the fashionable Blackberry. These
systems are facing security challenges regarding data transport to, and storage
of the data on the end user equipment. The emerging Trusted Computing
technology offers new answers to these open questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612062</id><created>2006-12-11</created><authors><author><keyname>Calzolari</keyname><forenames>Federico</forenames></author><author><keyname>Mammini</keyname><forenames>Michele</forenames></author><author><keyname>Monachini</keyname><forenames>Monica</forenames></author></authors><title>Unifying Lexicons in view of a Phonological and Morphological Lexical DB</title><categories>cs.IR</categories><comments>4 pages</comments><abstract>  The present work falls in the line of activities promoted by the European
Languguage Resource Association (ELRA) Production Committee (PCom) and raises
issues in methods, procedures and tools for the reusability, creation, and
management of Language Resources. A two-fold purpose lies behind this
experiment. The first aim is to investigate the feasibility, define methods and
procedures for combining two Italian lexical resources that have incompatible
formats and complementary information into a Unified Lexicon (UL). The adopted
strategy and the procedures appointed are described together with the driving
criterion of the merging task, where a balance between human and computational
efforts is pursued. The coverage of the UL has been maximized, by making use of
simple and fast matching procedures. The second aim is to exploit this newly
obtained resource for implementing the phonological and morphological layers of
the CLIPS lexical database. Implementing these new layers and linking them with
the already exisitng syntactic and semantic layers is not a trivial task. The
constraints imposed by the model, the impact at the architectural level and the
solution adopted in order to make the whole database `speak' efficiently are
presented. Advantages vs. disadvantages are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612063</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612063</id><created>2006-12-11</created><authors><author><keyname>Lu</keyname><forenames>Lunjin</forenames></author></authors><title>Improving Precision of Type Analysis Using Non-Discriminative Union</title><categories>cs.PL</categories><comments>47 pages, 5 tables, to appear in Theory and Practice of Logic
  Programming</comments><journal-ref>Theory and Practice of Logic Programming, 8 (1): 33-80, 2008</journal-ref><abstract>  This paper presents a new type analysis for logic programs. The analysis is
performed with a priori type definitions; and type expressions are formed from
a fixed alphabet of type constructors. Non-discriminative union is used to join
type information from different sources without loss of precision. An operation
that is performed repeatedly during an analysis is to detect if a fixpoint has
been reached. This is reduced to checking the emptiness of types. Due to the
use of non-discriminative union, the fundamental problem of checking the
emptiness of types is more complex in the proposed type analysis than in other
type analyses with a priori type definitions. The experimental results,
however, show that use of tabling reduces the effect to a small fraction of
analysis time on a set of benchmarks.
  Keywords: Type analysis, Non-discriminative union, Abstract interpretation,
Tabling
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612064</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612064</id><created>2006-12-11</created><updated>2007-01-19</updated><authors><author><keyname>Borissov</keyname><forenames>Yuri</forenames></author><author><keyname>Lee</keyname><forenames>Moon Ho</forenames></author></authors><title>Bounds on Key Appearance Equivocation for Substitution Ciphers</title><categories>cs.IT cs.CR math.IT</categories><comments>3 pages, typos corrected, submitted to IEEE Transactions on
  Information Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  The average conditional entropy of the key given the message and its
corresponding cryptogram, H(K|M,C), which is reffer as a key appearance
equivocation, was proposed as a theoretical measure of the strength of the
cipher system under a known-plaintext attack by Dunham in 1980. In the same
work (among other things), lower and upper bounds for H(S}_{M}|M^L,C^L) are
found and its asymptotic behaviour as a function of cryptogram length L is
described for simple substitution ciphers i.e. when the key space S_{M} is the
symmetric group acting on a discrete alphabet M. In the present paper we
consider the same problem when the key space is an arbitrary subgroup K of
S_{M} and generalize Dunham's result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612065</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612065</id><created>2006-12-12</created><updated>2007-03-28</updated><authors><author><keyname>Iyengar</keyname><forenames>Garud</forenames></author><author><keyname>Kumar</keyname><forenames>Anuj</forenames></author></authors><title>An equilibrium model for matching impatient demand and patient supply
  over time</title><categories>cs.GT q-fin.TR</categories><comments>15 pages, 4 figures</comments><acm-class>J.4; G.3</acm-class><abstract>  We present a simple dynamic equilibrium model for an online exchange where
both buyers and sellers arrive according to a exogenously defined stochastic
process. The structure of this exchange is motivated by the limit order book
mechanism used in stock markets. Both buyers and sellers are elastic in the
price-quantity space; however, only the sellers are assumed to be patient, i.e.
only the sellers have a price - time elasticity, whereas the buyers are assumed
to be impatient. Sellers select their selling price as a best response to all
the other sellers' strategies. We define and establish the existence of the
equilibrium in this model and show how to numerically compute this equilibrium.
We also show how to compute other relevant quantities such as the equilibrium
expected time to sale and equilibrium expected order density, as well as the
expected order density conditioned on current selling price. We derive a closed
form for the equilibrium distribution when the demand is price independent. At
this equilibrium the selling (limit order) price distribution is power tailed
as is empirically observed in order driven financial markets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612066</id><created>2006-12-11</created><authors><author><keyname>Defrawy</keyname><forenames>Karim El</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Argyraki</keyname><forenames>Katerina</forenames></author></authors><title>Optimal Filtering for DDoS Attacks</title><categories>cs.NI</categories><comments>13 pages, 14 figures</comments><abstract>  Distributed Denial-of-Service (DDoS) attacks are a major problem in the
Internet today. In one form of a DDoS attack, a large number of compromised
hosts send unwanted traffic to the victim, thus exhausting the resources of the
victim and preventing it from serving its legitimate clients. One of the main
mechanisms that have been proposed to deal with DDoS is filtering, which allows
routers to selectively block unwanted traffic. Given the magnitude of DDoS
attacks and the high cost of filters in the routers today, the successful
mitigation of a DDoS attack using filtering crucially depends on the efficient
allocation of filtering resources. In this paper, we consider a single router,
typically the gateway of the victim, with a limited number of available
filters. We study how to optimally allocate filters to attack sources, or
entire domains of attack sources, so as to maximize the amount of good traffic
preserved, under a constraint on the number of filters. We formulate the
problem as an optimization problem and solve it optimally using dynamic
programming, study the properties of the optimal allocation, experiment with a
simple heuristic and evaluate our solutions for a range of realistic
attack-scenarios. First, we look at a single-tier where the collateral damage
is high due to the filtering at the granularity of domains. Second, we look at
the two-tier problem where we have an additional constraint on the number of
filters and the filtering is performed on the granularity of attackers and
domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612067</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612067</id><created>2006-12-12</created><authors><author><keyname>Zhang</keyname><forenames>Jianwen</forenames></author><author><keyname>Armand</keyname><forenames>Marc A.</forenames></author></authors><title>Retrieving Reed-Solomon coded data under interpolation-based list
  decoding</title><categories>cs.IT math.IT</categories><comments>10 pages. Submitted to IEEE information theory for possible
  publication</comments><abstract>  A transform that enables generator-matrix-based Reed-Solomon (RS) coded data
to be recovered under interpolation-based list decoding is presented. The
transform matrix needs to be computed only once and the transformation of an
element from the output list to the desired RS coded data block incurs $k^{2}$
field multiplications, given a code of dimension $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612068</id><created>2006-12-12</created><authors><author><keyname>Hansen</keyname><forenames>Esben Rune</forenames></author><author><keyname>Andersen</keyname><forenames>Henrik Reif</forenames></author></authors><title>Interactive Configuration by Regular String Constraints</title><categories>cs.AI</categories><comments>Tech Report</comments><abstract>  A product configurator which is complete, backtrack free and able to compute
the valid domains at any state of the configuration can be constructed by
building a Binary Decision Diagram (BDD). Despite the fact that the size of the
BDD is exponential in the number of variables in the worst case, BDDs have
proved to work very well in practice. Current BDD-based techniques can only
handle interactive configuration with small finite domains. In this paper we
extend the approach to handle string variables constrained by regular
expressions. The user is allowed to change the strings by adding letters at the
end of the string. We show how to make a data structure that can perform fast
valid domain computations given some assignment on the set of string variables.
  We first show how to do this by using one large DFA. Since this approach is
too space consuming to be of practical use, we construct a data structure that
simulates the large DFA and in most practical cases are much more space
efficient. As an example a configuration problem on $n$ string variables with
only one solution in which each string variable is assigned to a value of
length of $k$ the former structure will use $\Omega(k^n)$ space whereas the
latter only need $O(kn)$. We also show how this framework easily can be
combined with the recent BDD techniques to allow both boolean, integer and
string variables in the configuration problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612069</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612069</id><created>2006-12-13</created><updated>2007-01-25</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author></authors><title>Cores of Countably Categorical Structures</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (January
  25, 2007) lmcs:780</journal-ref><doi>10.2168/LMCS-3(1:2)2007</doi><abstract>  A relational structure is a core, if all its endomorphisms are embeddings.
This notion is important for computational complexity classification of
constraint satisfaction problems. It is a fundamental fact that every finite
structure has a core, i.e., has an endomorphism such that the structure induced
by its image is a core; moreover, the core is unique up to isomorphism. Weprove
that every \omega -categorical structure has a core. Moreover, every
\omega-categorical structure is homomorphically equivalent to a model-complete
core, which is unique up to isomorphism, and which is finite or \omega
-categorical. We discuss consequences for constraint satisfaction with \omega
-categorical templates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612070</id><created>2006-12-13</created><authors><author><keyname>Benditkis</keyname><forenames>Sergey</forenames></author><author><keyname>Safro</keyname><forenames>Illya</forenames></author></authors><title>Generalizations of the Hanoi Towers Problem</title><categories>cs.DM</categories><abstract>  Our theme bases on the classical Hanoi Towers Problem. In this paper we will
define a new problem, permitting some positions, that were not legal in the
classical problem. Our goal is to find an optimal (shortest possible) sequence
of discs' moves. Besides that, we will research all versions of 3-pegs
classical problem with some special constraints, when some types of moves are
disallowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612071</id><created>2006-12-14</created><authors><author><keyname>Heylighen</keyname><forenames>Francis</forenames></author></authors><title>Why is Open Access Development so Successful? Stigmergic organization
  and the economics of information</title><categories>cs.CY cs.DL physics.soc-ph</categories><report-no>ECCO Working Paper 2006-06</report-no><journal-ref>in: B. Lutterbeck, M. Baerwolff &amp; R. A. Gehring (eds.), Open
  Source Jahrbuch 2007, Lehmanns Media, 2007</journal-ref><abstract>  The explosive development of &quot;free&quot; or &quot;open source&quot; information goods
contravenes the conventional wisdom that markets and commercial organizations
are necessary to efficiently supply products. This paper proposes a theoretical
explanation for this phenomenon, using concepts from economics and theories of
self-organization. Once available on the Internet, information is intrinsically
not a scarce good, as it can be replicated virtually without cost. Moreover,
freely distributing information is profitable to its creator, since it improves
the quality of the information, and enhances the creator's reputation. This
provides a sufficient incentive for people to contribute to open access
projects. Unlike traditional organizations, open access communities are open,
distributed and self-organizing. Coordination is achieved through stigmergy:
listings of &quot;work-in-progress&quot; direct potential contributors to the tasks where
their contribution is most likely to be fruitful. This obviates the need both
for centralized planning and for the &quot;invisible hand&quot; of the market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612072</identifier>
 <datestamp>2007-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612072</id><created>2006-12-14</created><updated>2007-09-24</updated><authors><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Pal</keyname><forenames>Martin</forenames></author><author><keyname>Svitkina</keyname><forenames>Zoya</forenames></author></authors><title>Stochastic Models for Budget Optimization in Search-Based Advertising</title><categories>cs.DS cs.GT</categories><abstract>  Internet search companies sell advertisement slots based on users' search
queries via an auction. Advertisers have to determine how to place bids on the
keywords of their interest in order to maximize their return for a given
budget: this is the budget optimization problem. The solution depends on the
distribution of future queries.
  In this paper, we formulate stochastic versions of the budget optimization
problem based on natural probabilistic models of distribution over future
queries, and address two questions that arise.
  [Evaluation] Given a solution, can we evaluate the expected value of the
objective function?
  [Optimization] Can we find a solution that maximizes the objective function
in expectation?
  Our main results are approximation and complexity results for these two
problems in our three stochastic models. In particular, our algorithmic results
show that simple prefix strategies that bid on all cheap keywords up to some
level are either optimal or good approximations for many cases; we show other
cases to be NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612073</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612073</id><created>2006-12-14</created><updated>2008-02-20</updated><authors><author><keyname>Anthapadmanabhan</keyname><forenames>N. Prasanth</forenames></author><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Dumer</keyname><forenames>Ilya</forenames></author></authors><title>On the Fingerprinting Capacity Under the Marking Assumption</title><categories>cs.IT cs.CR math.IT</categories><comments>final version, 12 pages, 2 figures, to appear in IEEE Trans. on
  Inform. Theory - Special Issue on Information-theoretic Security, Jun 2008,
  simplified proofs in Sections II and III, changes in Theorem 4.1</comments><abstract>  We address the maximum attainable rate of fingerprinting codes under the
marking assumption, studying lower and upper bounds on the value of the rate
for various sizes of the attacker coalition. Lower bounds are obtained by
considering typical coalitions, which represents a new idea in the area of
fingerprinting and enables us to improve the previously known lower bounds for
coalitions of size two and three. For upper bounds, the fingerprinting problem
is modelled as a communications problem. It is shown that the maximum code rate
is bounded above by the capacity of a certain class of channels, which are
similar to the multiple-access channel. Converse coding theorems proved in the
paper provide new upper bounds on fingerprinting capacity.
  It is proved that capacity for fingerprinting against coalitions of size two
and three over the binary alphabet satisfies $0.25 \leq C_{2,2} \leq 0.322$ and
$0.083 \leq C_{3,2} \leq 0.199$ respectively. For coalitions of an arbitrary
fixed size $t,$ we derive an upper bound $(t\ln2)^{-1}$ on fingerprinting
capacity in the binary case. Finally, for general alphabets, we establish upper
bounds on the fingerprinting capacity involving only single-letter mutual
information quantities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612074</id><created>2006-12-14</created><authors><author><keyname>Berenbrink</keyname><forenames>Petra</forenames></author><author><keyname>Cooper</keyname><forenames>Colin</forenames></author><author><keyname>Hu</keyname><forenames>Zengjian</forenames></author></authors><title>Energy Efficient Randomized Communication in Unknown AdHoc Networks</title><categories>cs.DC cs.DS</categories><comments>15 pages. 1 figure</comments><abstract>  This paper studies broadcasting and gossiping algorithms in random and
general AdHoc networks. Our goal is not only to minimise the broadcasting and
gossiping time, but also to minimise the energy consumption, which is measured
in terms of the total number of messages (or transmissions) sent. We assume
that the nodes of the network do not know the network, and that they can only
send with a fixed power, meaning they can not adjust the areas sizes that their
messages cover. We believe that under these circumstances the number of
transmissions is a very good measure for the overall energy consumption.
  For random networks, we present a broadcasting algorithm where every node
transmits at most once. We show that our algorithm broadcasts in $O(\log n)$
steps, w.h.p, where $n$ is the number of nodes. We then present a $O(d \log n)$
($d$ is the expected degree) gossiping algorithm using $O(\log n)$ messages per
node.
  For general networks with known diameter $D$, we present a randomised
broadcasting algorithm with optimal broadcasting time $O(D \log (n/D) + \log^2
n)$ that uses an expected number of $O(\log^2 n / \log (n/D))$ transmissions
per node. We also show a tradeoff result between the broadcasting time and the
number of transmissions: we construct a network such that any oblivious
algorithmusing a time-invariant distribution requires $\Omega(\log^2 n / \log
(n/D))$ messages per node in order to finish broadcasting in optimal time. This
demonstrates the tightness of our upper bound. We also show that no oblivious
algorithm can complete broadcasting w.h.p. using $o(\log n)$ messages per node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612075</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612075</id><created>2006-12-14</created><authors><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Intermediate Performance of Rateless Codes</title><categories>cs.IT math.IT</categories><abstract>  Rateless/fountain codes are designed so that all input symbols can be
recovered from a slightly larger number of coded symbols, with high probability
using an iterative decoder. In this paper we investigate the number of input
symbols that can be recovered by the same decoder, but when the number of coded
symbols available is less than the total number of input symbols. Of course
recovery of all inputs is not possible, and the fraction that can be recovered
will depend on the output degree distribution of the code.
  In this paper we (a) outer bound the fraction of inputs that can be recovered
for any output degree distribution of the code, and (b) design degree
distributions which meet/perform close to this bound. Our results are of
interest for real-time systems using rateless codes, and for Raptor-type
two-stage designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612076</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612076</id><created>2006-12-15</created><authors><author><keyname>Hachem</keyname><forenames>Walid</forenames><affiliation>LTCI</affiliation></author><author><keyname>Khorunzhiy</keyname><forenames>Oleksiy</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Najim</keyname><forenames>Jamal</forenames><affiliation>LTCI</affiliation></author><author><keyname>Pastur</keyname><forenames>Leonid</forenames></author></authors><title>A New Approach for Capacity Analysis of Large Dimensional Multi-Antenna
  Channels</title><categories>cs.IT math.IT math.PR</categories><proxy>ccsd hal-00120482</proxy><abstract>  This paper adresses the behaviour of the mutual information of correlated
MIMO Rayleigh channels when the numbers of transmit and receive antennas
converge to infinity at the same rate. Using a new and simple approach based on
Poincar\'{e}-Nash inequality and on an integration by parts formula, it is
rigorously established that the mutual information converges to a Gaussian
random variable whose mean and variance are evaluated. These results confirm
previous evaluations based on the powerful but non rigorous replica method. It
is believed that the tools that are used in this paper are simple, robust, and
of interest for the communications engineering community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612077</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612077</id><created>2006-12-15</created><authors><author><keyname>Pueschel</keyname><forenames>Markus</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Algebraic Signal Processing Theory</title><categories>cs.IT math.IT</categories><comments>67 pages. Parts of this document are submitted for publication under
  the titles &quot;Algebraic Signal Processing Theory: Foundation and 1-D Time&quot; and
  &quot;Algebraic Signal Processing Theory: 1-D Space&quot;</comments><acm-class>E.4</acm-class><abstract>  This paper presents an algebraic theory of linear signal processing. At the
core of algebraic signal processing is the concept of a linear signal model
defined as a triple (A, M, phi), where familiar concepts like the filter space
and the signal space are cast as an algebra A and a module M, respectively, and
phi generalizes the concept of the z-transform to bijective linear mappings
from a vector space of, e.g., signal samples, into the module M. A signal model
provides the structure for a particular linear signal processing application,
such as infinite and finite discrete time, or infinite or finite discrete
space, or the various forms of multidimensional linear signal processing. As
soon as a signal model is chosen, basic ingredients follow, including the
associated notions of filtering, spectrum, and Fourier transform. The shift
operator is a key concept in the algebraic theory: it is the generator of the
algebra of filters A. Once the shift is chosen, a well-defined methodology
leads to the associated signal model. Different shifts correspond to infinite
and finite time models with associated infinite and finite z-transforms, and to
infinite and finite space models with associated infinite and finite
C-transforms (that we introduce). In particular, we show that the 16 discrete
cosine and sine transforms are Fourier transforms for the finite space models.
Other definitions of the shift naturally lead to new signal models and to new
transforms as associated Fourier transforms in one and higher dimensions,
separable and non-separable. We explain in algebraic terms shift-invariance
(the algebra of filters A is commutative), the role of boundary conditions and
signal extensions, the connections between linear transforms and linear finite
Gauss-Markov fields, and several other concepts and connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612078</id><created>2006-12-16</created><updated>2007-03-02</updated><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Youjian</forenames></author><author><keyname>Rider</keyname><forenames>Brian</forenames></author></authors><title>Effect of Finite Rate Feedback on CDMA Signature Optimization and MIMO
  Beamforming Vector Selection</title><categories>cs.IT math.IT</categories><comments>24 pages, submitted to IEEE Trans. on Information Theory</comments><abstract>  We analyze the effect of finite rate feedback on CDMA (code-division multiple
access) signature optimization and MIMO (multi-input-multi-output) beamforming
vector selection. In CDMA signature optimization, for a particular user, the
receiver selects a signature vector from a codebook to best avoid interference
from other users, and then feeds the corresponding index back to the specified
user. For MIMO beamforming vector selection, the receiver chooses a beamforming
vector from a given codebook to maximize throughput, and feeds back the
corresponding index to the transmitter. These two problems are dual: both can
be modeled as selecting a unit norm vector from a finite size codebook to
&quot;match&quot; a randomly generated Gaussian matrix. In signature optimization, the
least match is required while the maximum match is preferred for beamforming
selection.
  Assuming that the feedback link is rate limited, our main result is an exact
asymptotic performance formulae where the length of the signature/beamforming
vector, the dimensions of interference/channel matrix, and the feedback rate
approach infinity with constant ratios. The proof rests on a large deviation
principle over a random matrix ensemble. Further, we show that random codebooks
generated from the isotropic distritution are asymptotically optimal not only
on average, but also with probability one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612079</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612079</id><created>2006-12-16</created><updated>2015-04-12</updated><authors><author><keyname>Gr&#xf8;nneberg</keyname><forenames>Steffen</forenames></author></authors><title>Executing the same binary on several operating systems</title><categories>cs.OS</categories><comments>The technique is outdated</comments><abstract>  We notice a way to execute a binary file on Windows and ELF-based systems. It
can be used to create software installers and other applications not exceeding
64 kilo bytes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612080</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612080</id><created>2006-12-17</created><authors><author><keyname>Binia</keyname><forenames>Jacob</forenames></author></authors><title>On the Decrease Rate of the Non-Gaussianness of the Sum of Independent
  Random Variables</title><categories>cs.IT math.IT</categories><comments>Submitted to the Trasactions of the IEEE on Information Theory</comments><abstract>  Several proofs of the monotonicity of the non-Gaussianness (divergence with
respect to a Gaussian random variable with identical second order statistics)
of the sum of n independent and identically distributed (i.i.d.) random
variables were published. We give an upper bound on the decrease rate of the
non-Gaussianness which is proportional to the inverse of n, for large n. The
proof is based on the relationship between non-Gaussianness and minimum
mean-square error (MMSE) and causal minimum mean-square error (CMMSE) in the
time-continuous Gaussian channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612081</id><created>2006-12-18</created><authors><author><keyname>Tungare</keyname><forenames>Manas</forenames></author><author><keyname>Pyla</keyname><forenames>Pardha S.</forenames></author><author><keyname>P&#xe9;rez-Qui&#xf1;ones</keyname><forenames>Manuel</forenames></author><author><keyname>Harrison</keyname><forenames>Steve</forenames></author></authors><title>Personal Information Ecosystems and Implications for Design</title><categories>cs.HC</categories><abstract>  Today, people use multiple devices to fulfill their information needs.
However, designers design each device individually, without accounting for the
other devices that users may also use. In many cases, the applications on all
these devices are designed to be functional replicates of each other. We argue
that this results in an over-reliance on data synchronization across devices,
version control nightmares, and increased burden of file management. In this
paper, we present the idea of a \textit{personal information ecosystem}, an
analogy to biological ecosystems, which allows us to discuss the
inter-relationships among these devices to fulfill the information needs of the
user. There is a need for designers to design devices as part of a complete
ecosystem, not as independent devices that simply share data replicated across
them. To help us understand this domain and to facilitate the dialogue and
study of such systems, we present the terminology, classifications of the
interdependencies among different devices, and resulting implications for
design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612082</id><created>2006-12-18</created><authors><author><keyname>Despeyroux</keyname><forenames>Thierry</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>Developing efficient parsers in Prolog: the CLF manual (v1.0)</title><categories>cs.SE</categories><proxy>ccsd inria-00120518</proxy><abstract>  This document describes a couple of tools that help to quickly design and
develop computer (formalized) languages. The first one use Flex to perform
lexical analysis and the second is an extention of Prolog DCGs to perfom
syntactical analysis. Initially designed as a new component for the Centaur
system, these tools are now available independently and can be used to
construct efficient Prolog parsers that can be integrated in Prolog or
heterogeneous systems. This is the initial version of the CLF documentation.
Updated version will be available online when necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612083</identifier>
 <datestamp>2007-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612083</id><created>2006-12-18</created><updated>2007-08-01</updated><authors><author><keyname>Zhao</keyname><forenames>Wenbing</forenames></author></authors><title>A Byzantine Fault Tolerant Distributed Commit Protocol</title><categories>cs.DC cs.DB</categories><comments>To appear in the proceedings of the 3rd IEEE International Symposium
  on Dependable, Autonomic and Secure Computing, 2007</comments><abstract>  In this paper, we present a Byzantine fault tolerant distributed commit
protocol for transactions running over untrusted networks. The traditional
two-phase commit protocol is enhanced by replicating the coordinator and by
running a Byzantine agreement algorithm among the coordinator replicas. Our
protocol can tolerate Byzantine faults at the coordinator replicas and a subset
of malicious faults at the participants. A decision certificate, which includes
a set of registration records and a set of votes from participants, is used to
facilitate the coordinator replicas to reach a Byzantine agreement on the
outcome of each transaction. The certificate also limits the ways a faulty
replica can use towards non-atomic termination of transactions, or semantically
incorrect transaction outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612084</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612084</id><created>2006-12-18</created><authors><author><keyname>Tekin</keyname><forenames>Ender</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Achievable Rates for the General Gaussian Multiple Access Wire-Tap
  Channel with Collective Secrecy</title><categories>cs.IT cs.CR math.IT</categories><comments>Presented at the 44th Annual Allerton Conference on Communication,
  Control, and Computing, September 27-29, 2006</comments><abstract>  We consider the General Gaussian Multiple Access Wire-Tap Channel (GGMAC-WT).
In this scenario, multiple users communicate with an intended receiver in the
presence of an intelligent and informed eavesdropper who is as capable as the
intended receiver, but has different channel parameters. We aim to provide
perfect secrecy for the transmitters in this multi-access environment. Using
Gaussian codebooks, an achievable secrecy region is determined and the power
allocation that maximizes the achievable sum-rate is found. Numerical results
showing the new rate region are presented. It is shown that the multiple-access
nature of the channel may be utilized to allow users with zero single-user
secrecy capacity to be able to transmit in perfect secrecy. In addition, a new
collaborative scheme is shown that may increase the achievable sum-rate. In
this scheme, a user who would not transmit to maximize the sum rate can help
another user who (i) has positive secrecy capacity to increase its rate, or
(ii) has zero secrecy capacity to achieve a positive secrecy capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612085</id><created>2006-12-18</created><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames></author><author><keyname>Hill</keyname><forenames>Patricia M.</forenames></author><author><keyname>Zaffanella</keyname><forenames>Enea</forenames></author></authors><title>The Parma Polyhedra Library: Toward a Complete Set of Numerical
  Abstractions for the Analysis and Verification of Hardware and Software
  Systems</title><categories>cs.MS cs.PL</categories><comments>38 pages, 2 figures, 3 listings, 3 tables</comments><report-no>Quaderno 457</report-no><acm-class>G.4; D.2.4</acm-class><abstract>  Since its inception as a student project in 2001, initially just for the
handling (as the name implies) of convex polyhedra, the Parma Polyhedra Library
has been continuously improved and extended by joining scrupulous research on
the theoretical foundations of (possibly non-convex) numerical abstractions to
a total adherence to the best available practices in software development. Even
though it is still not fully mature and functionally complete, the Parma
Polyhedra Library already offers a combination of functionality, reliability,
usability and performance that is not matched by similar, freely available
libraries. In this paper, we present the main features of the current version
of the library, emphasizing those that distinguish it from other similar
libraries and those that are important for applications in the field of
analysis and verification of hardware and software systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612086</identifier>
 <datestamp>2007-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612086</id><created>2006-12-18</created><updated>2007-10-08</updated><authors><author><keyname>Sutra</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Shapiro</keyname><forenames>Marc</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Barreto</keyname><forenames>Jo&#xe3;o Pedro</forenames><affiliation>INESC-ID</affiliation></author></authors><title>An asynchronous, decentralised commitment protocol for semantic
  optimistic replication</title><categories>cs.DB cs.NI</categories><proxy>ccsd inria-00120734</proxy><abstract>  We study large-scale distributed cooperative systems that use optimistic
replication. We represent a system as a graph of actions (operations) connected
by edges that reify semantic constraints between actions. Constraint types
include conflict, execution order, dependence, and atomicity. The local state
is some schedule that conforms to the constraints; because of conflicts, client
state is only tentative. For consistency, site schedules should converge; we
designed a decentralised, asynchronous commitment protocol. Each client makes a
proposal, reflecting its tentative and{\slash}or preferred schedules. Our
protocol distributes the proposals, which it decomposes into
semantically-meaningful units called candidates, and runs an election between
comparable candidates. A candidate wins when it receives a majority or a
plurality. The protocol is fully asynchronous: each site executes its tentative
schedule independently, and determines locally when a candidate has won an
election. The committed schedule is as close as possible to the preferences
expressed by clients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612087</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612087</id><created>2006-12-18</created><authors><author><keyname>Ingber</keyname><forenames>Lester</forenames></author></authors><title>Statistical mechanics of neocortical interactions: Portfolio of
  Physiological Indicators</title><categories>cs.CE cs.IT cs.NE math.IT q-bio.QM</categories><abstract>  There are several kinds of non-invasive imaging methods that are used to
collect data from the brain, e.g., EEG, MEG, PET, SPECT, fMRI, etc. It is
difficult to get resolution of information processing using any one of these
methods. Approaches to integrate data sources may help to get better resolution
of data and better correlations to behavioral phenomena ranging from attention
to diagnoses of disease. The approach taken here is to use algorithms developed
for the author's Trading in Risk Dimensions (TRD) code using modern methods of
copula portfolio risk management, with joint probability distributions derived
from the author's model of statistical mechanics of neocortical interactions
(SMNI). The author's Adaptive Simulated Annealing (ASA) code is for
optimizations of training sets, as well as for importance-sampling. Marginal
distributions will be evolved to determine their expected duration and
stability using algorithms developed by the author, i.e., PATHTREE and PATHINT
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612088</id><created>2006-12-19</created><updated>2006-12-19</updated><authors><author><keyname>Robert</keyname><forenames>Julien</forenames></author><author><keyname>Schabanel</keyname><forenames>Nicolas</forenames></author></authors><title>Non-Clairvoyant Batch Sets Scheduling: Fairness is Fair enough</title><categories>cs.DC cs.DS</categories><comments>12 pages, 1 figure</comments><abstract>  Scheduling questions arise naturally in many different areas among which
operating system design, compiling,... In real life systems, the
characteristics of the jobs (such as release time and processing time) are
usually unknown and unpredictable beforehand. The system is typically unaware
of the remaining work in each job or of the ability of the job to take
advantage of more resources. Following these observations, we adopt the job
model by Edmonds et al (2000, 2003) in which the jobs go through a sequence of
different phases. Each phase consists of a certain quantity of work and a
speed-up function that models how it takes advantage of the number of
processors it receives. We consider the non-clairvoyant online setting where a
collection of jobs arrives at time 0. We consider the metrics setflowtime
introduced by Robert et al (2007). The goal is to minimize the sum of the
completion time of the sets, where a set is completed when all of its jobs are
done. If the input consists of a single set of jobs, this is simply the
makespan of the jobs; and if the input consists of a collection of singleton
sets, it is simply the flowtime of the jobs. We show that the non-clairvoyant
strategy EQUIoEQUI that evenly splits the available processors among the still
unserved sets and then evenly splits these processors among the still
uncompleted jobs of each unserved set, achieves a competitive ratio
(2+\sqrt3+o(1))\frac{ln n}{lnln n} for the setflowtime minimization and that
this is asymptotically optimal (up to a constant factor), where n is the size
of the largest set. For makespan minimization, we show that the non-clairvoyant
strategy EQUI achieves a competitive ratio of (1+o(1))\frac{ln n}{lnln n},
which is again asymptotically optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612089</id><created>2006-12-19</created><authors><author><keyname>Woods</keyname><forenames>Damien</forenames></author><author><keyname>Neary</keyname><forenames>Turlough</forenames></author></authors><title>On the time complexity of 2-tag systems and small universal Turing
  machines</title><categories>cs.CC cs.DS</categories><comments>Slightly expanded and updated from conference version</comments><acm-class>F.1.1; F.1.3; F.2.3</acm-class><journal-ref>FOCS 2006: 47th Annual IEEE Symposium on Foundations of Computer
  Science, IEEE, pages 439-446, Berkeley, CA</journal-ref><abstract>  We show that 2-tag systems efficiently simulate Turing machines. As a
corollary we find that the small universal Turing machines of Rogozhin, Minsky
and others simulate Turing machines in polynomial time. This is an exponential
improvement on the previously known simulation time overhead and improves a
forty year old result in the area of small universal Turing machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612090</id><created>2006-12-18</created><authors><author><keyname>Hinze-Hoare</keyname><forenames>Vita</forenames></author></authors><title>A Review of Papers that have a bearing on an Analysis of User
  Interactions in A Collaborative On-line Laboratory</title><categories>cs.HC</categories><abstract>  A number of papers have been reviewed in the areas of HCI, CSCW, CSCL. These
have been analyzed with a view to extract the ideas relevant to a consideration
of user interactions in a collaborative on line laboratory which is being under
development for use in the ITO BSc course at Southampton University. The
construction of new theoretical models is to be based upon principles of
collaborative HCI design and constructivist and situational educational theory.
An investigation of the review papers it is hoped will lead towards a
methodology/framework that can be used as guidance for collaborative learning
systems and these will need to be developed alongside the requirements as they
change during the development cycles. The primary outcome will be the analysis
and re-design of the online e-learning laboratory together with a measure of
its efficacy in the learning process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612091</identifier>
 <datestamp>2008-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612091</id><created>2006-12-18</created><updated>2007-01-08</updated><authors><author><keyname>Vanclay</keyname><forenames>Jerome K</forenames></author></authors><title>Bias in the journal impact factor</title><categories>cs.DL q-bio.OT</categories><comments>9 pages, 8 figures; one reference corrected</comments><journal-ref>Scientometrics 78(1):3-12 (2009)</journal-ref><doi>10.1007/s11192-008-1778-4</doi><abstract>  The ISI journal impact factor (JIF) is based on a sample that may represent
half the whole-of-life citations to some journals, but a small fraction (&lt;10%)
of the citations accruing to other journals. This disproportionate sampling
means that the JIF provides a misleading indication of the true impact of
journals, biased in favour of journals that have a rapid rather than a
prolonged impact. Many journals exhibit a consistent pattern of citation
accrual from year to year, so it may be possible to adjust the JIF to provide a
more reliable indication of a journal's impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612092</id><created>2006-12-19</created><authors><author><keyname>Sidky</keyname><forenames>Ahmed</forenames></author><author><keyname>Arthur</keyname><forenames>James</forenames></author></authors><title>Agile Adoption Process Framework</title><categories>cs.SE</categories><comments>This is a reference document containing an overview of the adoption
  framework along with all the indicators used for the assessment of the agile
  practices</comments><abstract>  Today many organizations aspire to adopt agile processes in hope of
overcoming some of the difficulties they are facing with their current software
development process. There is no structured framework for the agile adoption
process. This paper presents a 3-Stage process framework that assists
organization and guides organizations through their agile adoption efforts. The
Process Framework has been received significantly positive feedback from
experts and leaders in agile adoption industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612093</id><created>2006-12-19</created><authors><author><keyname>Silva</keyname><forenames>Miguel S.</forenames></author><author><keyname>Martins</keyname><forenames>Francisco</forenames></author><author><keyname>Lopes</keyname><forenames>Luis</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>A Calculus for Sensor Networks</title><categories>cs.DC cs.PL</categories><comments>24 pages, 1 figure, submitted for publication</comments><abstract>  We consider the problem of providing a rigorous model for programming
wireless sensor networks. Assuming that collisions, packet losses, and errors
are dealt with at the lower layers of the protocol stack, we propose a Calculus
for Sensor Networks (CSN) that captures the main abstractions for programming
applications for this class of devices. Besides providing the syntax and
semantics for the calculus, we show its expressiveness by providing
implementations for several examples of typical operations on sensor networks.
Also included is a detailed discussion of possible extensions to CSN that
enable the modeling of other important features of these networks such as
sensor state, sampling strategies, and network security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612094</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612094</id><created>2006-12-19</created><authors><author><keyname>Sedoglavic</keyname><forenames>Alexandre</forenames><affiliation>INRIA Futurs, LIFL</affiliation></author></authors><title>Reduction of Algebraic Parametric Systems by Rectification of their
  Affine Expanded Lie Symmetries</title><categories>cs.SC</categories><comments>Before analysing an algebraic system (differential or not), one can
  generally reduce the number of parameters defining the system behavior by
  studying the system's Lie symmetries</comments><proxy>ccsd inria-00120991</proxy><journal-ref>Dans Algebraic Biology 2007 4545 (2007) 277--291</journal-ref><abstract>  Lie group theory states that knowledge of a $m$-parameters solvable group of
symmetries of a system of ordinary differential equations allows to reduce by
$m$ the number of equations. We apply this principle by finding some
\emph{affine derivations} that induces \emph{expanded} Lie point symmetries of
considered system. By rewriting original problem in an invariant coordinates
set for these symmetries, we \emph{reduce} the number of involved parameters.
We present an algorithm based on this standpoint whose arithmetic complexity is
\emph{quasi-polynomial} in input's size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612095</identifier>
 <datestamp>2008-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612095</id><created>2006-12-19</created><updated>2008-09-15</updated><authors><author><keyname>Adriaans</keyname><forenames>Pieter</forenames><affiliation>University of Amsterdam</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Approximation of the Two-Part MDL Code</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>14 pages, LaTeX, no figures, IEEE Trans Inform. Th., to appear</comments><acm-class>E.4; I.2.6; I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximation of the optimal two-part MDL code for given data, through
successive monotonically length-decreasing two-part MDL codes, has the
following properties: (i) computation of each step may take arbitrarily long;
(ii) we may not know when we reach the optimum, or whether we will reach the
optimum at all; (iii) the sequence of models generated may not monotonically
improve the goodness of fit; but (iv) the model associated with the optimum has
(almost) the best goodness of fit. To express the practically interesting
goodness of fit of individual models for individual data sets we have to rely
on Kolmogorov complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612096</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612096</id><created>2006-12-19</created><authors><author><keyname>Levin</keyname><forenames>David N.</forenames></author></authors><title>Using state space differential geometry for nonlinear blind source
  separation</title><categories>cs.LG cs.SD</categories><comments>Contains 14 pages and 3 figures. For related papers, see
  http://www.geocities.com/dlevin2001/ . New version is identical to original
  version except for URL in the byline</comments><acm-class>I.2.6; J.2; I.2.7; I.5</acm-class><journal-ref>Journal of Applied Physics 103, 044906 (2008)</journal-ref><doi>10.1063/1.2826943</doi><abstract>  Given a time series of multicomponent measurements of an evolving stimulus,
nonlinear blind source separation (BSS) seeks to find a &quot;source&quot; time series,
comprised of statistically independent combinations of the measured components.
In this paper, we seek a source time series with local velocity cross
correlations that vanish everywhere in stimulus state space. However, in an
earlier paper the local velocity correlation matrix was shown to constitute a
metric on state space. Therefore, nonlinear BSS maps onto a problem of
differential geometry: given the metric observed in the measurement coordinate
system, find another coordinate system in which the metric is diagonal
everywhere. We show how to determine if the observed data are separable in this
way, and, if they are, we show how to construct the required transformation to
the source coordinate system, which is essentially unique except for an unknown
rotation that can be found by applying the methods of linear BSS. Thus, the
proposed technique solves nonlinear BSS in many situations or, at least,
reduces it to linear BSS, without the use of probabilistic, parametric, or
iterative procedures. This paper also describes a generalization of this
methodology that performs nonlinear independent subspace separation. In every
case, the resulting decomposition of the observed data is an intrinsic property
of the stimulus' evolution in the sense that it does not depend on the way the
observer chooses to view it (e.g., the choice of the observing machine's
sensors). In other words, the decomposition is a property of the evolution of
the &quot;real&quot; stimulus that is &quot;out there&quot; broadcasting energy to the observer.
The technique is illustrated with analytic and numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612097</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612097</id><created>2006-12-19</created><authors><author><keyname>Nakiboglu</keyname><forenames>B.</forenames></author><author><keyname>Gallager</keyname><forenames>R. G.</forenames></author></authors><title>Error Exponents for Variable-length Block Codes with Feedback and Cost
  Constraints</title><categories>cs.IT math.IT</categories><acm-class>E.4; H.1.1</acm-class><abstract>  Variable-length block-coding schemes are investigated for discrete memoryless
channels with ideal feedback under cost constraints. Upper and lower bounds are
found for the minimum achievable probability of decoding error $P_{e,\min}$ as
a function of constraints $R, \AV$, and $\bar \tau$ on the transmission rate,
average cost, and average block length respectively. For given $R$ and $\AV$,
the lower and upper bounds to the exponent $-(\ln P_{e,\min})/\bar \tau$ are
asymptotically equal as $\bar \tau \to \infty$. The resulting reliability
function, $\lim_{\bar \tau\to \infty} (-\ln P_{e,\min})/\bar \tau$, as a
function of $R$ and $\AV$, is concave in the pair $(R, \AV)$ and generalizes
the linear reliability function of Burnashev to include cost constraints. The
results are generalized to a class of discrete-time memoryless channels with
arbitrary alphabets, including additive Gaussian noise channels with amplitude
and power constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612098</id><created>2006-12-20</created><authors><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author><author><keyname>Phatak</keyname><forenames>Deepak B.</forenames></author></authors><title>Algorithms and Approaches of Proxy Signature: A Survey</title><categories>cs.CR</categories><comments>29 pages</comments><abstract>  Numerous research studies have been investigated on proxy signatures over the
last decade. This survey reviews the research progress on proxy signatures,
analyzes a few notable proposals, and provides an overall remark of these
proposals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612099</id><created>2006-12-20</created><authors><author><keyname>Costa</keyname><forenames>Rui A.</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Network Information Flow in Small World Networks</title><categories>cs.IT cs.DM math.IT</categories><comments>23 pages, 8 fitures, submitted to the IEEE Transactions on
  Information Theory, November 2006</comments><abstract>  Recent results from statistical physics show that large classes of complex
networks, both man-made and of natural origin, are characterized by high
clustering properties yet strikingly short path lengths between pairs of nodes.
This class of networks are said to have a small-world topology. In the context
of communication networks, navigable small-world topologies, i.e. those which
admit efficient distributed routing algorithms, are deemed particularly
effective, for example in resource discovery tasks and peer-to-peer
applications. Breaking with the traditional approach to small-world topologies
that privileges graph parameters pertaining to connectivity, and intrigued by
the fundamental limits of communication in networks that exploit this type of
topology, we investigate the capacity of these networks from the perspective of
network information flow. Our contribution includes upper and lower bounds for
the capacity of standard and navigable small-world models, and the somewhat
surprising result that, with high probability, random rewiring does not alter
the capacity of a small-world network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612100</id><created>2006-12-20</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>van Stee</keyname><forenames>Rob</forenames></author></authors><title>Improved results for a memory allocation problem</title><categories>cs.DS</categories><acm-class>F.2.2</acm-class><abstract>  We consider a memory allocation problem that can be modeled as a version of
bin packing where items may be split, but each bin may contain at most two
(parts of) items. A 3/2-approximation algorithm and an NP-hardness proof for
this problem was given by Chung et al. We give a simpler 3/2-approximation
algorithm for it which is in fact an online algorithm. This algorithm also has
good performance for the more general case where each bin may contain at most k
parts of items. We show that this general case is also strongly NP-hard.
Additionally, we give an efficient 7/5-approximation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612101</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612101</id><created>2006-12-20</created><authors><author><keyname>Guillaud</keyname><forenames>M.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author><author><keyname>Moustakas</keyname><forenames>A. L.</forenames></author></authors><title>Maximum Entropy MIMO Wireless Channel Models</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Information Theory Dec. 2006; 16 pages, 4
  figures</comments><abstract>  In this contribution, models of wireless channels are derived from the
maximum entropy principle, for several cases where only limited information
about the propagation environment is available. First, analytical models are
derived for the cases where certain parameters (channel energy, average energy,
spatial correlation matrix) are known deterministically. Frequently, these
parameters are unknown (typically because the received energy or the spatial
correlation varies with the user position), but still known to represent
meaningful system characteristics. In these cases, analytical channel models
are derived by assigning entropy-maximizing distributions to these parameters,
and marginalizing them out. For the MIMO case with spatial correlation, we show
that the distribution of the covariance matrices is conveniently handled
through its eigenvalues. The entropy-maximizing distribution of the covariance
matrix is shown to be a Wishart distribution. Furthermore, the corresponding
probability density function of the channel matrix is shown to be described
analytically by a function of the channel Frobenius norm. This technique can
provide channel models incorporating the effect of shadow fading and spatial
correlation between antennas without the need to assume explicit values for
these parameters. The results are compared in terms of mutual information to
the classical i.i.d. Gaussian model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612102</id><created>2006-12-20</created><updated>2007-01-13</updated><authors><author><keyname>Dalvi</keyname><forenames>Nilesh</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>The Dichotomy of Conjunctive Queries on Probabilistic Structures</title><categories>cs.DB</categories><abstract>  We show that for every conjunctive query, the complexity of evaluating it on
a probabilistic database is either \PTIME or #\P-complete, and we give an
algorithm for deciding whether a given conjunctive query is \PTIME or
#\P-complete. The dichotomy property is a fundamental result on query
evaluation on probabilistic databases and it gives a complete classification of
the complexity of conjunctive queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612103</id><created>2006-12-20</created><authors><author><keyname>Rastogi</keyname><forenames>Vibhor</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author><author><keyname>Hong</keyname><forenames>Sungho</forenames></author></authors><title>The Boundary Between Privacy and Utility in Data Anonymization</title><categories>cs.DB</categories><abstract>  We consider the privacy problem in data publishing: given a relation I
containing sensitive information 'anonymize' it to obtain a view V such that,
on one hand attackers cannot learn any sensitive information from V, and on the
other hand legitimate users can use V to compute useful statistics on I. These
are conflicting goals. We use a definition of privacy that is derived from
existing ones in the literature, which relates the a priori probability of a
given tuple t, Pr(t), with the a posteriori probability, Pr(t | V), and propose
a novel and quite practical definition for utility. Our main result is the
following. Denoting n the size of I and m the size of the domain from which I
was drawn (i.e. n &lt; m) then: when the a priori probability is Pr(t) =
Omega(n/sqrt(m)) for some t, there exists no useful anonymization algorithm,
while when Pr(t) = O(n/m) for all tuples t, then we give a concrete
anonymization algorithm that is both private and useful. Our algorithm is quite
different from the k-anonymization algorithm studied intensively in the
literature, and is based on random deletions and insertions to I.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612104</id><created>2006-12-20</created><updated>2007-05-04</updated><authors><author><keyname>Burjorjee</keyname><forenames>Keki</forenames></author></authors><title>Sufficient Conditions for Coarse-Graining Evolutionary Dynamics</title><categories>cs.NE cs.AI</categories><comments>19 pages, 1 figure. Accepted to the Foundations of Genetic Algorithms
  Conference 2007 (FOGA IX)</comments><acm-class>I.2.8; F.2</acm-class><abstract>  It is commonly assumed that the ability to track the frequencies of a set of
schemata in the evolving population of an infinite population genetic algorithm
(IPGA) under different fitness functions will advance efforts to obtain a
theory of adaptation for the simple GA. Unfortunately, for IPGAs with long
genomes and non-trivial fitness functions there do not currently exist
theoretical results that allow such a study. We develop a simple framework for
analyzing the dynamics of an infinite population evolutionary algorithm (IPEA).
This framework derives its simplicity from its abstract nature. In particular
we make no commitment to the data-structure of the genomes, the kind of
variation performed, or the number of parents involved in a variation
operation. We use this framework to derive abstract conditions under which the
dynamics of an IPEA can be coarse-grained. We then use this result to derive
concrete conditions under which it becomes computationally feasible to closely
approximate the frequencies of a family of schemata of relatively low order
over multiple generations, even when the bitstsrings in the evolving population
of the IPGA are long.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612105</id><created>2006-12-21</created><updated>2006-12-24</updated><authors><author><keyname>Sundararajan</keyname><forenames>Elankovan</forenames></author><author><keyname>Harwood</keyname><forenames>Aaron</forenames></author></authors><title>Towards Parallel Computing on the Internet: Applications, Architectures,
  Models and Programming Tools</title><categories>cs.DC cs.PF</categories><comments>39 pages, 9 figures</comments><abstract>  The development of Internet wide resources for general purpose parallel
computing poses the challenging task of matching computation and communication
complexity. A number of parallel computing models exist that address this for
traditional parallel architectures, and there are a number of emerging models
that attempt to do this for large scale Internet-based systems like
computational grids. In this survey we cover the three fundamental aspects --
application, architecture and model, and we show how they have been developed
over the last decade. We also cover programming tools that are currently being
used for parallel programming in computational grids. The trend in conventional
computational models are to put emphasis on efficient communication between
participating nodes by adapting different types of communication to network
conditions. Effects of dynamism and uncertainties that arise in large scale
systems are evidently important to understand and yet there is currently little
work that addresses this from a parallel computing perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612106</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612106</id><created>2006-12-21</created><authors><author><keyname>Lasota</keyname><forenames>Slawomir</forenames></author><author><keyname>Nowak</keyname><forenames>David</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author></authors><title>On Completeness of Logical Relations for Monadic Types</title><categories>cs.LO cs.PL</categories><comments>20 pages, full version of the paper published at ASIAN'2006, with the
  same title</comments><acm-class>D.3.1; F.3.1</acm-class><journal-ref>Advances in Computer Science - ASIAN 2006, Secure Software, 11th
  Asian Computing Science Conference, Tokyo, Japan, December 6-8, 2006,
  Proceedings, volume 4435 of Lecture Notes in Computer Science, pages 223-230,
  Springer</journal-ref><doi>10.1007/978-3-540-77505-8_17</doi><abstract>  Software security can be ensured by specifying and verifying security
properties of software using formal methods with strong theoretical bases. In
particular, programs can be modeled in the framework of lambda-calculi, and
interesting properties can be expressed formally by contextual equivalence
(a.k.a. observational equivalence). Furthermore, imperative features, which
exist in most real-life software, can be nicely expressed in the so-called
computational lambda-calculus. Contextual equivalence is difficult to prove
directly, but we can often use logical relations as a tool to establish it in
lambda-calculi. We have already defined logical relations for the computational
lambda-calculus in previous work. We devote this paper to the study of their
completeness w.r.t. contextual equivalence in the computational
lambda-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612107</id><created>2006-12-21</created><authors><author><keyname>Drepper</keyname><forenames>Friedhelm R.</forenames></author></authors><title>Voiced speech as secondary response of a self-consistent fundamental
  drive</title><categories>cs.SD nlin.AO</categories><comments>13 pages with 3 figures</comments><acm-class>H.5.5; H.5.2</acm-class><abstract>  Voiced segments of speech are assumed to be composed of non-stationary
acoustic objects which can be described as stationary response of a
non-stationary fundamental drive (FD) process and which are furthermore suited
to reconstruct the hidden FD by using a voice adapted (self-consistent)
part-tone decomposition of the speech signal. The universality and robustness
of human pitch perception encourages the reconstruction of a band-limited FD in
the frequency range of the pitch. The self-consistent decomposition of voiced
continuants generates several part-tones which can be confirmed to be
topologically equivalent to corresponding acoustic modes of the excitation on
the transmitter side. As topologically equivalent image of a glottal master
oscillator, the self-consistent FD is suited to serve as low frequency part of
the basic time-scale separation of auditive perception and to describe the
broadband voiced excitation as entrained (synchronized) and/or modulated
primary response. Being guided by the acoustic correlates of pitch and loudness
perception, the time-scale separation avoids the conventional assumption of
stationary excitation and represents the basic decoding step of an advanced
precision transmission protocol of self-consistent (voiced) acoustic objects.
The present study is focussed on the adaptation of the trajectories (contours)
of the centre filter frequency of the part-tones to the chirp of the glottal
master oscillator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612108</id><created>2006-12-21</created><authors><author><keyname>Lebedev</keyname><forenames>Dmitry</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Mathieu</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Viennot</keyname><forenames>Laurent</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Gai</keyname><forenames>Anh-Tuan</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Reynier</keyname><forenames>Julien</forenames><affiliation>INRIA Rocquencourt, INRIA Rocquencourt</affiliation></author><author><keyname>De Montgolfier</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>On Using Matching Theory to Understand P2P Network Design</title><categories>cs.NI cs.GT</categories><proxy>ccsd inria-00121604</proxy><abstract>  This paper aims to provide insight into stability of collaboration choices in
P2P networks. We study networks where exchanges between nodes are driven by the
desire to receive the best service available. This is the case for most
existing P2P networks. We explore an evolution model derived from stable
roommates theory that accounts for heterogeneity between nodes. We show that
most P2P applications can be modeled using stable matching theory. This is the
case whenever preference lists can be deduced from the exchange policy. In many
cases, the preferences lists are characterized by an interesting acyclic
property. We show that P2P networks with acyclic preferences possess a unique
stable state with good convergence properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612109</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612109</id><created>2006-12-21</created><updated>2007-07-25</updated><authors><author><keyname>Gomez</keyname><forenames>Vicenc</forenames></author><author><keyname>Mooij</keyname><forenames>J. M.</forenames></author><author><keyname>Kappen</keyname><forenames>H. J.</forenames></author></authors><title>Truncating the loop series expansion for Belief Propagation</title><categories>cs.AI</categories><comments>31 pages, 12 figures, submitted to Journal of Machine Learning
  Research</comments><journal-ref>The Journal of Machine Learning Research, 8(Sep):1987--2016, 2007</journal-ref><abstract>  Recently, M. Chertkov and V.Y. Chernyak derived an exact expression for the
partition sum (normalization constant) corresponding to a graphical model,
which is an expansion around the Belief Propagation solution. By adding
correction terms to the BP free energy, one for each &quot;generalized loop&quot; in the
factor graph, the exact partition sum is obtained. However, the usually
enormous number of generalized loops generally prohibits summation over all
correction terms. In this article we introduce Truncated Loop Series BP
(TLSBP), a particular way of truncating the loop series of M. Chertkov and V.Y.
Chernyak by considering generalized loops as compositions of simple loops. We
analyze the performance of TLSBP in different scenarios, including the Ising
model, regular random graphs and on Promedas, a large probabilistic medical
diagnostic system. We show that TLSBP often improves upon the accuracy of the
BP solution, at the expense of increased computation time. We also show that
the performance of TLSBP strongly depends on the degree of interaction between
the variables. For weak interactions, truncating the series leads to
significant improvements, whereas for strong interactions it can be
ineffective, even if a high number of terms is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612110</id><created>2006-12-21</created><authors><author><keyname>Hamilton</keyname><forenames>James</forenames></author></authors><title>Architecture for Modular Data Centers</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  Several factors are driving high-scale deployments of large data centers
built upon commodity components. These commodity clusters are far cheaper than
mainframe systems of the past but they bring serious heat and power density
issues. Also the high failure rate of the individual components drives
significant administrative costs. This proposal outlines an architecture for
data center design based upon 20'x8'x8' modules that substantially changes how
these systems are acquired, administered, and then later recycled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612111</identifier>
 <datestamp>2009-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612111</id><created>2006-12-21</created><authors><author><keyname>Sears</keyname><forenames>Russell</forenames></author><author><keyname>van Ingen</keyname><forenames>Catharine</forenames></author></authors><title>Fragmentation in Large Object Repositories</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  Fragmentation leads to unpredictable and degraded application performance.
While these problems have been studied in detail for desktop filesystem
workloads, this study examines newer systems such as scalable object stores and
multimedia repositories. Such systems use a get/put interface to store objects.
In principle, databases and filesystems can support such applications
efficiently, allowing system designers to focus on complexity, deployment cost
and manageability. Although theoretical work proves that certain storage
policies behave optimally for some workloads, these policies often behave
poorly in practice. Most storage benchmarks focus on short-term behavior or do
not measure fragmentation. We compare SQL Server to NTFS and find that
fragmentation dominates performance when object sizes exceed 256KB-1MB. NTFS
handles fragmentation better than SQL Server. Although the performance curves
will vary with other systems and workloads, we expect the same interactions
between fragmentation and free space to apply. It is well-known that
fragmentation is related to the percentage free space. We found that the ratio
of free space to object size also impacts performance. Surprisingly, in both
systems, storing objects of a single size causes fragmentation, and changing
the size of write requests affects fragmentation. These problems could be
addressed with simple changes to the filesystem and database interfaces. It is
our hope that an improved understanding of fragmentation will lead to
predictable storage systems that require less maintenance after deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612112</id><created>2006-12-21</created><authors><author><keyname>Baryshnikov</keyname><forenames>Boris</forenames></author><author><keyname>Clinciu</keyname><forenames>Cipri</forenames></author><author><keyname>Cunningham</keyname><forenames>Conor</forenames></author><author><keyname>Giakoumakis</keyname><forenames>Leo</forenames></author><author><keyname>Oks</keyname><forenames>Slava</forenames></author><author><keyname>Stefani</keyname><forenames>Stefano</forenames></author></authors><title>Managing Query Compilation Memory Consumption to Improve DBMS Throughput</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  While there are known performance trade-offs between database page buffer
pool and query execution memory allocation policies, little has been written on
the impact of query compilation memory use on overall throughput of the
database management system (DBMS). We present a new aspect of the query
optimization problem and offer a solution implemented in Microsoft SQL Server
2005. The solution provides stable throughput for a range of workloads even
when memory requests outstrip the ability of the hardware to service those
requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612113</id><created>2006-12-21</created><authors><author><keyname>Greenfield</keyname><forenames>Paul</forenames></author><author><keyname>Fekete</keyname><forenames>Alan</forenames></author><author><keyname>Jang</keyname><forenames>Julian</forenames></author><author><keyname>Kuo</keyname><forenames>Dean</forenames></author><author><keyname>Nepal</keyname><forenames>Surya</forenames></author></authors><title>Isolation Support for Service-based Applications: A Position Paper</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  In this paper, we propose an approach to providing the benefits of isolation
in service-oriented applications where it is not feasible to hold traditional
locks for ACID transactions. Our technique, called &quot;Promises&quot;, provides an
uniform view for clients which covers a wide range of implementation techniques
on the service side, all allowing the client to check a condition and then
later rely on that condition still holding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612114</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612114</id><created>2006-12-21</created><authors><author><keyname>B&#xf6;hm</keyname><forenames>Alexander</forenames></author><author><keyname>Kanne</keyname><forenames>Carl-Christian</forenames></author><author><keyname>Moerkotte</keyname><forenames>Guido</forenames></author></authors><title>Demaq: A Foundation for Declarative XML Message Processing</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  This paper gives an overview of Demaq, an XML message processing system
operating on the foundation of transactional XML message queues. We focus on
the syntax and semantics of its fully declarative, rule-based application
language and demonstrate our message-based programming paradigm in the context
of a case study. Further, we discuss optimization opportunities for executing
Demaq programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612115</id><created>2006-12-21</created><authors><author><keyname>Barga</keyname><forenames>Roger S.</forenames></author><author><keyname>Goldstein</keyname><forenames>Jonathan</forenames></author><author><keyname>Ali</keyname><forenames>Mohamed</forenames></author><author><keyname>Hong</keyname><forenames>Mingsheng</forenames></author></authors><title>Consistent Streaming Through Time: A Vision for Event Stream Processing</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  Event processing will play an increasingly important role in constructing
enterprise applications that can immediately react to business critical events.
Various technologies have been proposed in recent years, such as event
processing, data streams and asynchronous messaging (e.g. pub/sub). We believe
these technologies share a common processing model and differ only in target
workload, including query language features and consistency requirements. We
argue that integrating these technologies is the next step in a natural
progression. In this paper, we present an overview and discuss the foundations
of CEDR, an event streaming system that embraces a temporal stream model to
unify and further enrich query language features, handle imperfections in event
delivery and define correctness guarantees. We describe specific contributions
made so far and outline next steps in developing the CEDR system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612116</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612116</id><created>2006-12-21</created><updated>2007-03-12</updated><authors><author><keyname>Danner</keyname><forenames>Norman</forenames></author><author><keyname>Royer</keyname><forenames>James S.</forenames></author></authors><title>Adventures in time and space</title><categories>cs.LO cs.PL</categories><comments>Corrected version to appear in Logical Methods in Computer Science</comments><acm-class>F.3.3; F.1.3; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (March 12,
  2007) lmcs:999</journal-ref><doi>10.2168/LMCS-3(1:9)2007</doi><abstract>  This paper investigates what is essentially a call-by-value version of PCF
under a complexity-theoretically motivated type system. The programming
formalism, ATR, has its first-order programs characterize the polynomial-time
computable functions, and its second-order programs characterize the type-2
basic feasible functionals of Mehlhorn and of Cook and Urquhart. (The ATR-types
are confined to levels 0, 1, and 2.) The type system comes in two parts, one
that primarily restricts the sizes of values of expressions and a second that
primarily restricts the time required to evaluate expressions. The
size-restricted part is motivated by Bellantoni and Cook's and Leivant's
implicit characterizations of polynomial-time. The time-restricting part is an
affine version of Barber and Plotkin's DILL. Two semantics are constructed for
ATR. The first is a pruning of the naive denotational semantics for ATR. This
pruning removes certain functions that cause otherwise feasible forms of
recursion to go wrong. The second semantics is a model for ATR's time
complexity relative to a certain abstract machine. This model provides a
setting for complexity recurrences arising from ATR recursions, the solutions
of which yield second-order polynomial time bounds. The time-complexity
semantics is also shown to be sound relative to the costs of interpretation on
the abstract machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612117</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612117</id><created>2006-12-21</created><authors><author><keyname>Urakami</keyname><forenames>Masahiro</forenames></author><author><keyname>Miyoshi</keyname><forenames>Seiji</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Statistical Mechanics of On-line Learning when a Moving Teacher Goes
  around an Unlearnable True Teacher</title><categories>cs.LG cond-mat.dis-nn</categories><comments>12 pages, 5 pages</comments><doi>10.1143/JPSJ.76.044003</doi><abstract>  In the framework of on-line learning, a learning machine might move around a
teacher due to the differences in structures or output functions between the
teacher and the learning machine. In this paper we analyze the generalization
performance of a new student supervised by a moving machine. A model composed
of a fixed true teacher, a moving teacher, and a student is treated
theoretically using statistical mechanics, where the true teacher is a
nonmonotonic perceptron and the others are simple perceptrons. Calculating the
generalization errors numerically, we show that the generalization errors of a
student can temporarily become smaller than that of a moving teacher, even if
the student only uses examples from the moving teacher. However, the
generalization error of the student eventually becomes the same value with that
of the moving teacher. This behavior is qualitatively different from that of a
linear model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612118</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612118</id><created>2006-12-22</created><authors><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author><author><keyname>Massoulie</keyname><forenames>Laurent</forenames></author></authors><title>Gossiping with Multiple Messages</title><categories>cs.NI cs.IT math.IT</categories><comments>Accepted to IEEE INFOCOM 2007</comments><abstract>  This paper investigates the dissemination of multiple pieces of information
in large networks where users contact each other in a random uncoordinated
manner, and users upload one piece per unit time. The underlying motivation is
the design and analysis of piece selection protocols for peer-to-peer networks
which disseminate files by dividing them into pieces. We first investigate
one-sided protocols, where piece selection is based on the states of either the
transmitter or the receiver. We show that any such protocol relying only on
pushes, or alternatively only on pulls, is inefficient in disseminating all
pieces to all users. We propose a hybrid one-sided piece selection protocol --
INTERLEAVE -- and show that by using both pushes and pulls it disseminates $k$
pieces from a single source to $n$ users in $10(k+\log n)$ time, while obeying
the constraint that each user can upload at most one piece in one unit of time,
with high probability for large $n$. An optimal, unrealistic centralized
protocol would take $k+\log_2 n$ time in this setting. Moreover, efficient
dissemination is also possible if the source implements forward erasure coding,
and users push the latest-released coded pieces (but do not pull). We also
investigate two-sided protocols where piece selection is based on the states of
both the transmitter and the receiver. We show that it is possible to
disseminate $n$ pieces to $n$ users in $n+O(\log n)$ time, starting from an
initial state where each user has a unique piece.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612119</id><created>2006-12-22</created><updated>2007-03-29</updated><authors><author><keyname>Brunie</keyname><forenames>Cyril</forenames><affiliation>LACO</affiliation></author><author><keyname>Picart</keyname><forenames>Philippe Saux</forenames><affiliation>LM</affiliation></author></authors><title>Symmetric Subresultants and Applications</title><categories>cs.SC</categories><proxy>ccsd hal-00121773</proxy><abstract>  Schur's transforms of a polynomial are used to count its roots in the unit
disk. These are generalized them by introducing the sequence of symmetric
sub-resultants of two polynomials. Although they do have a determinantal
definition, we show that they satisfy a structure theorem which allows us to
compute them with a type of Euclidean division. As a consequence, a fast
algorithm based on a dichotomic process and FFT is designed. We prove also that
these symmetric sub-resultants have a deep link with Toeplitz matrices.
Finally, we propose a new algorithm of inversion for such matrices. It has the
same cost as those already known, however it is fraction-free and consequently
well adapted to computer algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612120</id><created>2006-12-22</created><updated>2006-12-27</updated><authors><author><keyname>Ranzato</keyname><forenames>Francesco</forenames></author><author><keyname>Tapparo</keyname><forenames>Francesco</forenames></author></authors><title>Generalizing the Paige-Tarjan Algorithm by Abstract Interpretation</title><categories>cs.LO</categories><comments>Keywords: Abstract interpretation, abstract model checking, strong
  preservation, Paige-Tarjan algorithm, refinement algorithm</comments><acm-class>D.2.4; F.3.2</acm-class><abstract>  The Paige and Tarjan algorithm (PT) for computing the coarsest refinement of
a state partition which is a bisimulation on some Kripke structure is well
known. It is also well known in model checking that bisimulation is equivalent
to strong preservation of CTL, or, equivalently, of Hennessy-Milner logic.
Drawing on these observations, we analyze the basic steps of the PT algorithm
from an abstract interpretation perspective, which allows us to reason on
strong preservation in the context of generic inductively defined (temporal)
languages and of possibly non-partitioning abstract models specified by
abstract interpretation. This leads us to design a generalized Paige-Tarjan
algorithm, called GPT, for computing the minimal refinement of an abstract
interpretation-based model that strongly preserves some given language. It
turns out that PT is a straight instance of GPT on the domain of state
partitions for the case of strong preservation of Hennessy-Milner logic. We
provide a number of examples showing that GPT is of general use. We first show
how a well-known efficient algorithm for computing stuttering equivalence can
be viewed as a simple instance of GPT. We then instantiate GPT in order to
design a new efficient algorithm for computing simulation equivalence that is
competitive with the best available algorithms. Finally, we show how GPT allows
to compute new strongly preserving abstract models by providing an efficient
algorithm that computes the coarsest refinement of a given partition that
strongly preserves the language generated by the reachability operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612121</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612121</id><created>2006-12-22</created><authors><author><keyname>Funke</keyname><forenames>Stefan</forenames></author><author><keyname>Laue</keyname><forenames>Soeren</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author><author><keyname>Naujoks</keyname><forenames>Rouven</forenames></author></authors><title>Power Assignment Problems in Wireless Communication</title><categories>cs.CG cs.AR cs.NI</categories><comments>13 pages</comments><abstract>  A fundamental class of problems in wireless communication is concerned with
the assignment of suitable transmission powers to wireless devices/stations
such that the resulting communication graph satisfies certain desired
properties and the overall energy consumed is minimized. Many concrete
communication tasks in a wireless network like broadcast, multicast,
point-to-point routing, creation of a communication backbone, etc. can be
regarded as such a power assignment problem.
  This paper considers several problems of that kind; for example one problem
studied before in \cite{Carrots, Bilo} aims to select and assign powers to $k$
of the stations such that all other stations are within reach of at least one
of the selected stations. We improve the running time for obtaining a
$(1+\epsilon)$-approximate solution for this problem from
$n^{((\alpha/\epsilon)^{O(d)})}$ as reported by Bilo et al. (\cite{Bilo}) to
$O(n+ {(\frac{k^{2d+1}}{\epsilon^d})}^{\min{\{2k, (\alpha/\epsilon)^{O(d)}
\}}})$ that is, we obtain a running time that is \emph{linear} in the network
size. Further results include a constant approximation algorithm for the TSP
problem under squared (non-metric!) edge costs, which can be employed to
implement a novel data aggregation protocol, as well as efficient schemes to
perform $k$-hop multicasts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612122</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612122</id><created>2006-12-22</created><authors><author><keyname>Wagner</keyname><forenames>Joerg</forenames></author><author><keyname>Rankov</keyname><forenames>Boris</forenames></author><author><keyname>Wittneben</keyname><forenames>Armin</forenames></author></authors><title>Large N Analysis of Amplify-and-Forward MIMO Relay Channels with
  Correlated Rayleigh Fading</title><categories>cs.IT math.IT</categories><comments>submitted for publication to IEEE Transactions on Information Theory</comments><abstract>  In this correspondence the cumulants of the mutual information of the flat
Rayleigh fading amplify-and-forward MIMO relay channel without direct link
between source and destination are derived in the large array limit. The
analysis is based on the replica trick and covers both spatially independent
and correlated fading in the first and the second hop, while beamforming at all
terminals is restricted to deterministic weight matrices. Expressions for mean
and variance of the mutual information are obtained. Their parameters are
determined by a nonlinear equation system. All higher cumulants are shown to
vanish as the number of antennas n goes to infinity. In conclusion the
distribution of the mutual information I becomes Gaussian in the large n limit
and is completely characterized by the expressions obtained for mean and
variance of I. Comparisons with simulation results show that the asymptotic
results serve as excellent approximations for systems with only few antennas at
each node. The derivation of the results follows the technique formalized by
Moustakas et al. in [1]. Although the evaluations are more involved for the
MIMO relay channel compared to point-to-point MIMO channels, the structure of
the results is surprisingly simple again. In particular an elegant formula for
the mean of the mutual information is obtained, i.e., the ergodic capacity of
the two-hop amplify-and-forward MIMO relay channel without direct link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612123</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612123</id><created>2006-12-22</created><authors><author><keyname>Belenkaia</keyname><forenames>Lioudmila</forenames></author><author><keyname>Bohnert</keyname><forenames>Michael</forenames></author><author><keyname>Liehr</keyname><forenames>Andreas W.</forenames></author></authors><title>Electronic Laboratory Notebook Assisting Reflectance Spectrometry in
  Legal Medicine</title><categories>cs.DB cs.DL cs.IR</categories><comments>5 pages, 2 figures</comments><acm-class>H.2.8</acm-class><abstract>  Reflectance spectrometry is a fast and reliable method for the
characterisation of human skin if the spectra are analysed with respect to a
physical model describing the optical properties of human skin. For a field
study performed at the Institute of Legal Medicine and the Freiburg Materials
Research Center of the University of Freiburg an electronic laboratory notebook
has been developed, which assists in the recording, management, and analysis of
reflectance spectra. The core of the electronic laboratory notebook is a MySQL
database. It is filled with primary data via a web interface programmed in
Java, which also enables the user to browse the database and access the results
of data analysis. These are carried out by Matlab, Tcl and
  Python scripts, which retrieve the primary data from the electronic
laboratory notebook, perform the analysis, and store the results in the
database for further usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612124</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612124</id><created>2006-12-22</created><authors><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Randall</keyname><forenames>Paige A.</forenames></author></authors><title>Highly robust error correction by convex programming</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>23 pages, 2 figures</comments><abstract>  This paper discusses a stylized communications problem where one wishes to
transmit a real-valued signal x in R^n (a block of n pieces of information) to
a remote receiver. We ask whether it is possible to transmit this information
reliably when a fraction of the transmitted codeword is corrupted by arbitrary
gross errors, and when in addition, all the entries of the codeword are
contaminated by smaller errors (e.g. quantization errors).
  We show that if one encodes the information as Ax where A is a suitable m by
n coding matrix (m &gt;= n), there are two decoding schemes that allow the
recovery of the block of n pieces of information x with nearly the same
accuracy as if no gross errors occur upon transmission (or equivalently as if
one has an oracle supplying perfect information about the sites and amplitudes
of the gross errors). Moreover, both decoding strategies are very concrete and
only involve solving simple convex optimization programs, either a linear
program or a second-order cone program. We complement our study with numerical
simulations showing that the encoder/decoder pair performs remarkably well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612125</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612125</id><created>2006-12-22</created><updated>2010-10-02</updated><authors><author><keyname>Milan&#xe9;s</keyname><forenames>Anolan</forenames></author><author><keyname>Rodriguez</keyname><forenames>Noemi</forenames></author><author><keyname>Schulze</keyname><forenames>Bruno</forenames></author></authors><title>Heterogeneous Strong Computation Migration</title><categories>cs.DC</categories><comments>This is the pre-peer reviewed version of the following article:
  Milan\'es, A., Rodriguez, N. and Schulze, B. (2008), State of the art in
  heterogeneous strong migration of computations. Concurrency and Computation:
  Practice and Experience, 20: 1485-1508, which has been published in final
  form at http://onlinelibrary.wiley.com/doi/10.1002/cpe.1287/abstract</comments><journal-ref>Concurrency and Computation: Practice and Experience, 20:
  1485-1508</journal-ref><doi>10.1002/cpe.1287</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The continuous increase in performance requirements, for both scientific
computation and industry, motivates the need of a powerful computing
infrastructure. The Grid appeared as a solution for inexpensive execution of
heavy applications in a parallel and distributed manner. It allows combining
resources independently of their physical location and architecture to form a
global resource pool available to all grid users. However, grid environments
are highly unstable and unpredictable. Adaptability is a crucial issue in this
context, in order to guarantee an appropriate quality of service to users.
Migration is a technique frequently used for achieving adaptation. The
objective of this report is to survey the problem of strong migration in
heterogeneous environments like the grids', the related implementation issues
and the current solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612126</id><created>2006-12-22</created><authors><author><keyname>Ivankov</keyname><forenames>Petr R.</forenames></author><author><keyname>Ivankov</keyname><forenames>Nikolay P.</forenames></author></authors><title>The virtual reality framework for engineering objects</title><categories>cs.CE cs.MS</categories><acm-class>J.9</acm-class><abstract>  A framework for virtual reality of engineering objects has been developed.
This framework may simulate different equipment related to virtual reality.
Framework supports 6D dynamics, ordinary differential equations, finite
formulas, vector and matrix operations. The framework also supports embedding
of external software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612127</id><created>2006-12-22</created><authors><author><keyname>Eltabakh</keyname><forenames>Mohamed Y.</forenames></author><author><keyname>Ouzzani</keyname><forenames>Mourad</forenames></author><author><keyname>Aref</keyname><forenames>Walid G.</forenames></author></authors><title>bdbms -- A Database Management System for Biological Data</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  Biologists are increasingly using databases for storing and managing their
data. Biological databases typically consist of a mixture of raw data,
metadata, sequences, annotations, and related data obtained from various
sources. Current database technology lacks several functionalities that are
needed by biological databases. In this paper, we introduce bdbms, an
extensible prototype database management system for supporting biological data.
bdbms extends the functionalities of current DBMSs to include: (1) Annotation
and provenance management including storage, indexing, manipulation, and
querying of annotation and provenance as first class objects in bdbms, (2)
Local dependency tracking to track the dependencies and derivations among data
items, (3) Update authorization to support data curation via content-based
authorization, in contrast to identity-based authorization, and (4) New access
methods and their supporting operators that support pattern matching on various
types of compressed biological data types. This paper presents the design of
bdbms along with the techniques proposed to support these functionalities
including an extension to SQL. We also outline some open issues in building
bdbms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612128</id><created>2006-12-22</created><authors><author><keyname>Gyllstrom</keyname><forenames>Daniel</forenames></author><author><keyname>Wu</keyname><forenames>Eugene</forenames></author><author><keyname>Chae</keyname><forenames>Hee-Jin</forenames></author><author><keyname>Diao</keyname><forenames>Yanlei</forenames></author><author><keyname>Stahlberg</keyname><forenames>Patrick</forenames></author><author><keyname>Anderson</keyname><forenames>Gordon</forenames></author></authors><title>SASE: Complex Event Processing over Streams</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  RFID technology is gaining adoption on an increasing scale for tracking and
monitoring purposes. Wide deployments of RFID devices will soon generate an
unprecedented volume of data. Emerging applications require the RFID data to be
filtered and correlated for complex pattern detection and transformed to events
that provide meaningful, actionable information to end applications. In this
work, we design and develop SASE, a com-plex event processing system that
performs such data-information transformation over real-time streams. We design
a complex event language for specifying application logic for such
transformation, devise new query processing techniques to effi-ciently
implement the language, and develop a comprehensive system that collects,
cleans, and processes RFID data for deliv-ery of relevant, timely information
as well as storing necessary data for future querying. We demonstrate an
initial prototype of SASE through a real-world retail management scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612129</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612129</id><created>2006-12-22</created><authors><author><keyname>Bhattacharjee</keyname><forenames>Bishwaranjan</forenames></author><author><keyname>Ercegovac</keyname><forenames>Vuk</forenames></author><author><keyname>Glider</keyname><forenames>Joseph</forenames></author><author><keyname>Golding</keyname><forenames>Richard</forenames></author><author><keyname>Lohman</keyname><forenames>Guy</forenames></author><author><keyname>Markl</keyname><forenames>Volke</forenames></author><author><keyname>Pirahesh</keyname><forenames>Hamid</forenames></author><author><keyname>Rao</keyname><forenames>Jun</forenames></author><author><keyname>Rees</keyname><forenames>Robert</forenames></author><author><keyname>Reiss</keyname><forenames>Frederick</forenames></author><author><keyname>Shekita</keyname><forenames>Eugene</forenames></author><author><keyname>Swart</keyname><forenames>Garret</forenames></author></authors><title>Impliance: A Next Generation Information Management Appliance</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  ably successful in building a large market and adapting to the changes of the
last three decades, its impact on the broader market of information management
is surprisingly limited. If we were to design an information management system
from scratch, based upon today's requirements and hardware capabilities, would
it look anything like today's database systems?&quot; In this paper, we introduce
Impliance, a next-generation information management system consisting of
hardware and software components integrated to form an easy-to-administer
appliance that can store, retrieve, and analyze all types of structured,
semi-structured, and unstructured information. We first summarize the trends
that will shape information management for the foreseeable future. Those trends
imply three major requirements for Impliance: (1) to be able to store, manage,
and uniformly query all data, not just structured records; (2) to be able to
scale out as the volume of this data grows; and (3) to be simple and robust in
operation. We then describe four key ideas that are uniquely combined in
Impliance to address these requirements, namely the ideas of: (a) integrating
software and off-the-shelf hardware into a generic information appliance; (b)
automatically discovering, organizing, and managing all data - unstructured as
well as structured - in a uniform way; (c) achieving scale-out by exploiting
simple, massive parallel processing, and (d) virtualizing compute and storage
resources to unify, simplify, and streamline the management of Impliance.
Impliance is an ambitious, long-term effort to define simpler, more robust, and
more scalable information systems for tomorrow's enterprises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612130</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612130</id><created>2006-12-22</created><authors><author><keyname>Gai</keyname><forenames>Anh-Tuan</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Mathieu</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Reynier</keyname><forenames>Julien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>De Montgolfier</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Stratification in P2P Networks - Application to BitTorrent</title><categories>cs.NI</categories><proxy>ccsd inria-00121974</proxy><abstract>  We introduce a model for decentralized networks with collaborating peers. The
model is based on the stable matching theory which is applied to systems with a
global ranking utility function. We consider the dynamics of peers searching
for efficient collaborators and we prove that a unique stable solution exists.
We prove that the system converges towards the stable solution and analyze its
speed of convergence. We also study the stratification properties of the model,
both when all collaborations are possible and for random possible
collaborations. We present the corresponding fluid limit on the choice of
collaborators in the random case. As a practical example, we study the
BitTorrent Tit-for-Tat policy. For this system, our model provides an
interesting insight on peer download rates and a possible way to optimize peer
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612131</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612131</id><created>2006-12-22</created><updated>2006-12-29</updated><authors><author><keyname>Bohner</keyname><forenames>Amine Chigani James D. Arthur Shawn</forenames></author></authors><title>Architecting Network-Centric Software Systems: A Style-Based Beginning</title><categories>cs.SE</categories><comments>10 pages, 3 figures, 2 table, Submitted to Software Engineering
  Workshop 2007</comments><abstract>  With the advent of potent network technology, software development has
evolved from traditional platform-centric construction to network-centric
evolution. This change involves largely the way we reason about systems as
evidenced in the introduction of Network- Centric Operations (NCO).
Unfortunately, it has resulted in conflicting interpretations of how to map NCO
concepts to the field of software architecture. In this paper, we capture the
core concepts and goals of NCO, investigate the implications of these concepts
and goals on software architecture, and identify the operational
characteristics that distinguish network-centric software systems from other
systems. More importantly, we use architectural design principles to propose an
outline for a network-centric architectural style that helps in characterizing
network-centric software systems and that provides a means by which their
distinguishing operational characteristics can be realized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612132</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612132</id><created>2006-12-23</created><authors><author><keyname>Meho</keyname><forenames>Lokman I.</forenames></author><author><keyname>Yang</keyname><forenames>Kiduk</forenames></author></authors><title>A New Era in Citation and Bibliometric Analyses: Web of Science, Scopus,
  and Google Scholar</title><categories>cs.DL cs.IR</categories><comments>49 pages, accepted for publication in the Journal of the American
  Society for Information Science and Technology</comments><abstract>  Academic institutions, federal agencies, publishers, editors, authors, and
librarians increasingly rely on citation analysis for making hiring, promotion,
tenure, funding, and/or reviewer and journal evaluation and selection
decisions. The Institute for Scientific Information's (ISI) citation databases
have been used for decades as a starting point and often as the only tools for
locating citations and/or conducting citation analyses. ISI databases (or Web
of Science), however, may no longer be adequate as the only or even the main
sources of citations because new databases and tools that allow citation
searching are now available. Whether these new databases and tools complement
or represent alternatives to Web of Science (WoS) is important to explore.
Using a group of 15 library and information science faculty members as a case
study, this paper examines the effects of using Scopus and Google Scholar (GS)
on the citation counts and rankings of scholars as measured by WoS. The paper
discusses the strengths and weaknesses of WoS, Scopus, and GS, their overlap
and uniqueness, quality and language of the citations, and the implications of
the findings for citation analysis. The project involved citation searching for
approximately 1,100 scholarly works published by the study group and over 200
works by a test group (an additional 10 faculty members). Overall, more than
10,000 citing and purportedly citing documents were examined. WoS data took
about 100 hours of collecting and processing time, Scopus consumed 200 hours,
and GS a grueling 3,000 hours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612133</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612133</id><created>2006-12-25</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI and University of Amsterdam</affiliation></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames><affiliation>Ben Gurion University, Beer Sheva</affiliation></author></authors><title>Tales of Huffman</title><categories>cs.IT cs.CC math.IT</categories><comments>LaTex 8 pages</comments><abstract>  We study the new problem of Huffman-like codes subject to individual
restrictions on the code-word lengths of a subset of the source words. These
are prefix codes with minimal expected code-word length for a random source
where additionally the code-word lengths of a subset of the source words is
prescribed, possibly differently for every such source word. Based on a
structural analysis of properties of optimal solutions, we construct an
efficient dynamic programming algorithm for this problem, and for an integer
programming problem that may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612134</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612134</id><created>2006-12-25</created><authors><author><keyname>Mulmuley</keyname><forenames>Ketan D</forenames></author><author><keyname>Sohoni</keyname><forenames>Milind</forenames></author></authors><title>Geometric Complexity Theory II: Towards explicit obstructions for
  embeddings among class varieties</title><categories>cs.CC math.AG math.RT</categories><comments>46 pages</comments><acm-class>F.1.3</acm-class><abstract>  In part I we reduced the arithmetic (characteristic zero) version of the P
\not \subseteq NP conjecture to the problem of showing that a variety
associated with the complexity class NP cannot be embedded in the variety
associated the complexity class P. We call these class varieties.
  In this paper, this approach is developed further, reducing the nonexistence
problems, such as the P vs. NP and related lower bound problems, to existence
problems: specifically to proving existence of obstructions to such embeddings
among class varieties. It gives two results towards explicit construction of
such obstructions.
  The first result is a generalization of the Borel-Weil theorem to a class of
orbit closures, which include class varieties. The recond result is a weaker
form of a conjectured analogue of the second fundamental theorem of invariant
theory for the class variety associated with the complexity class NC. These
results indicate that the fundamental lower bound problems in complexity theory
are intimately linked with explicit construction problems in algebraic geometry
and representation theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612135</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612135</id><created>2006-12-26</created><authors><author><keyname>Diouri</keyname><forenames>Idriss</forenames><affiliation>CRAN</affiliation></author><author><keyname>Georges</keyname><forenames>Jean-Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Rondeau</keyname><forenames>Eric</forenames><affiliation>CRAN</affiliation></author></authors><title>Accommodation of the Service Offered by the Network for Networked
  Control Systems</title><categories>cs.NI</categories><comments>8 pages</comments><proxy>ccsd hal-00116967</proxy><journal-ref>2nd workshop on Networked Control Systems : Tolerant to faults
  (23/11/2006) 8 pages</journal-ref><abstract>  Networked Controlled Systems (NCSs) are more and more used in industrial
applications. They are strongly connected to real-time constraints because
important delays induced by the network can lead to an unstable process
control. Usually, the network used in NCSs is shared with many others
applications requiring different Quality of Service. The objective of this
paper is to optimize the tuning of the network scheduling mechanisms in taking
into account the level of Quality of Control. The goal is to maximize the
bandwidth allocation for unconstrained frames in guarantying that the control
constraints are respected. In this paper, we focus on switched Ethernet network
implementing the Classification of Service (IEEE 802.1p) based on a Weighted
Round Robin policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612136</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612136</id><created>2006-12-27</created><authors><author><keyname>Manin</keyname><forenames>Dmitrii</forenames></author></authors><title>Experiments on predictability of word in context and information rate in
  natural language</title><categories>cs.IT math.IT</categories><comments>14 pages, 3 figures</comments><journal-ref>Manin, D.Yu. 2006. Experiments on predictability of word in
  context and information rate in natural language. J. Information Processes
  (electronic publication, http://www.jip.ru), 6 (3), 229-236</journal-ref><abstract>  Based on data from a large-scale experiment with human subjects, we conclude
that the logarithm of probability to guess a word in context (unpredictability)
depends linearly on the word length. This result holds both for poetry and
prose, even though with prose, the subjects don't know the length of the
omitted word. We hypothesize that this effect reflects a tendency of natural
language to have an even information rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612137</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612137</id><created>2006-12-27</created><authors><author><keyname>Robinson</keyname><forenames>Eric</forenames></author><author><keyname>DeWitt</keyname><forenames>David</forenames></author></authors><title>Turning Cluster Management into Data Management: A System Overview</title><categories>cs.DB</categories><comments>This article is published under a Creative Commons License Agreement
  (http://creativecommons.org/licenses/by/2.5/.) You may copy, distribute,
  display, and perform the work, make derivative works and make commercial use
  of the work, but, you must attribute the work to the author and CIDR 2007.
  3rd Biennial Conference on Innovative Data Systems Research (CIDR) January
  710, 2007, Asilomar, California, USA</comments><proxy>mscmt</proxy><abstract>  This paper introduces the CondorJ2 cluster management system. Traditionally,
cluster management systems such as Condor employ a process-oriented approach
with little or no use of modern database system technology. In contrast,
CondorJ2 employs a data-centric, 3-tier web-application architecture for all
system functions (e.g., job submission, monitoring and scheduling; node
configuration, monitoring and management, etc.) except for job execution.
Employing a data-oriented approach allows the core challenge (i.e., managing
and coordinating a large set of distributed computing resources) to be
transformed from a relatively low-level systems problem into a more abstract,
higher-level data management problem. Preliminary results suggest that
CondorJ2's use of standard 3-tier software represents a significant step
forward to the design and implementation of large clusters (1,000 to 10,000
nodes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612138</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612138</id><created>2006-12-28</created><authors><author><keyname>Haubold</keyname><forenames>Alexander</forenames></author><author><keyname>Kender</keyname><forenames>John R.</forenames></author></authors><title>Accommodating Sample Size Effect on Similarity Measures in Speaker
  Clustering</title><categories>cs.SD cs.MM</categories><acm-class>H.3.3; H.5.1; H.5.5</acm-class><abstract>  We investigate the symmetric Kullback-Leibler (KL2) distance in speaker
clustering and its unreported effects for differently-sized feature matrices.
Speaker data is represented as Mel Frequency Cepstral Coefficient (MFCC)
vectors, and features are compared using the KL2 metric to form clusters of
speech segments for each speaker. We make two observations with respect to
clustering based on KL2: 1.) The accuracy of clustering is strongly dependent
on the absolute lengths of the speech segments and their extracted feature
vectors. 2.) The accuracy of the similarity measure strongly degrades with the
length of the shorter of the two speech segments. These effects of length can
be attributed to the measure of covariance used in KL2. We demonstrate an
empirical correction of this sample-size effect that increases clustering
accuracy. We draw parallels to two Vector Quantization-based (VQ) similarity
measures, one which exhibits an equivalent effect of sample size, and the
second being less influenced by it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612139</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612139</id><created>2006-12-28</created><authors><author><keyname>Haubold</keyname><forenames>Alexander</forenames></author><author><keyname>Kender</keyname><forenames>John R.</forenames></author></authors><title>Alignment of Speech to Highly Imperfect Text Transcriptions</title><categories>cs.SD cs.MM</categories><acm-class>H.3.1; H.5.1; H.5.5</acm-class><abstract>  We introduce a novel and inexpensive approach for the temporal alignment of
speech to highly imperfect transcripts from automatic speech recognition (ASR).
Transcripts are generated for extended lecture and presentation videos, which
in some cases feature more than 30 speakers with different accents, resulting
in highly varying transcription qualities. In our approach we detect a subset
of phonemes in the speech track, and align them to the sequence of phonemes
extracted from the transcript. We report on the results for 4 speech-transcript
sets ranging from 22 to 108 minutes. The alignment performance is promising,
showing a correct matching of phonemes within 10, 20, 30 second error margins
for more than 60%, 75%, 90% of text, respectively, on average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612140</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612140</id><created>2006-12-28</created><updated>2007-03-28</updated><authors><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author><author><keyname>Ferreira</keyname><forenames>Fernando M. L.</forenames></author><author><keyname>Kling</keyname><forenames>Daniel V.</forenames></author><author><keyname>Lopes</keyname><forenames>Eduardo</forenames></author><author><keyname>Protti</keyname><forenames>Fabio</forenames></author><author><keyname>Schmitz</keyname><forenames>Eber A.</forenames></author></authors><title>On simulating nondeterministic stochastic activity networks</title><categories>cs.DM</categories><journal-ref>European Journal of Operational Research 198 (2009), 266-274</journal-ref><doi>10.1016/j.ejor.2008.06.010</doi><abstract>  In this work we deal with a mechanism for process simulation called a
NonDeterministic Stochastic Activity Network (NDSAN). An NDSAN consists
basically of a set of activities along with precedence relations involving
these activities, which determine their order of execution. Activity durations
are stochastic, given by continuous, nonnegative random variables. The
nondeterministic behavior of an NDSAN is based on two additional possibilities:
(i) by associating choice probabilities with groups of activities, some
branches of execution may not be taken; (ii) by allowing iterated executions of
groups of activities according to predetermined probabilities, the number of
times an activity must be executed is not determined a priori. These properties
lead to a rich variety of activity networks, capable of modeling many real
situations in process engineering, project design, and troubleshooting. We
describe a recursive simulation algorithm for NDSANs, whose repeated execution
produces a close approximation to the probability distribution of the
completion time of the entire network. We also report on real-world case
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612141</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612141</id><created>2006-12-28</created><authors><author><keyname>Druault-Vicard</keyname><forenames>Annie</forenames></author><author><keyname>Tanguy</keyname><forenames>Christian</forenames></author></authors><title>Exact Failure Frequency Calculations for Extended Systems</title><categories>cs.PF</categories><proxy>ccsd hal-00122272</proxy><abstract>  This paper shows how the steady-state availability and failure frequency can
be calculated in a single pass for very large systems, when the availability is
expressed as a product of matrices. We apply the general procedure to
$k$-out-of-$n$:G and linear consecutive $k$-out-of-$n$:F systems, and to a
simple ladder network in which each edge and node may fail. We also give the
associated generating functions when the components have identical
availabilities and failure rates. For large systems, the failure rate of the
whole system is asymptotically proportional to its size. This paves the way to
ready-to-use formulae for various architectures, as well as proof that the
differential operator approach to failure frequency calculations is very useful
and straightforward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612142</identifier>
 <datestamp>2008-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612142</id><created>2006-12-28</created><updated>2008-07-03</updated><authors><author><keyname>Tanguy</keyname><forenames>Christian</forenames></author></authors><title>What is the probability of connecting two points ?</title><categories>cs.DM cs.NI</categories><comments>a few critical polynomials are at the end of the .tex source file</comments><proxy>ccsd hal-00122268</proxy><journal-ref>J. Phys. A: Math. Theor. 40 (2007) 14099-14116</journal-ref><doi>10.1088/1751-8113/40/47/005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-terminal reliability, known as the pair connectedness or connectivity
function in percolation theory, may actually be expressed as a product of
transfer matrices in which the probability of operation of each link and site
is exactly taken into account. When link and site probabilities are $p$ and
$\rho$, it obeys an asymptotic power-law behavior, for which the scaling factor
is the transfer matrix's eigenvalue of largest modulus. The location of the
complex zeros of the two-terminal reliability polynomial exhibits structural
transitions as $0 \leq \rho \leq 1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0612143</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0612143</id><created>2006-12-28</created><authors><author><keyname>Tanguy</keyname><forenames>Christian</forenames></author></authors><title>Exact solutions for the two- and all-terminal reliabilities of a simple
  ladder network</title><categories>cs.PF</categories><proxy>ccsd hal-00121520</proxy><abstract>  The exact calculation of network reliability in a probabilistic context has
been a long-standing issue of practical importance, but a difficult one, even
for planar graphs, with perfect nodes and with edges of identical reliability
p. Many approaches (determination of bounds, sums of disjoint products
algorithms, Monte Carlo evaluations, studies of the reliability polynomials,
etc.) can only provide approximations when the network's size increases. We
consider here a ladder graph of arbitrary size corresponding to real-life
network configurations, and give the exact, analytical solutions for the all-
and two-terminal reliabilities. These solutions use transfer matrices, in which
individual reliabilities of edges and nodes are taken into account. The special
case of identical edge and node reliabilities -- p and rho, respectively -- is
solved. We show that the zeros of the two-terminal reliability polynomial
exhibit structures which differ substantially for seemingly similar networks,
and we compare the sensitivity of various edges. We discuss how the present
work may be further extended to lead to a catalog of exactly solvable networks
in terms of reliability, which could be useful as elementary bricks for a new
and improved set of bounds or benchmarks in the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701001</id><created>2007-01-02</created><authors><author><keyname>Gore</keyname><forenames>Ashutosh Deepak</forenames></author><author><keyname>Jagabathula</keyname><forenames>Srikanth</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>On High Spatial Reuse Link Scheduling in STDMA Wireless Ad Hoc Networks</title><categories>cs.PF cs.NI</categories><comments>10 pages (double column), 10 figures</comments><acm-class>C.2.1; C.2.5; F.2</acm-class><abstract>  Graph-based algorithms for point-to-point link scheduling in Spatial reuse
Time Division Multiple Access (STDMA) wireless ad hoc networks often result in
a significant number of transmissions having low Signal to Interference and
Noise density Ratio (SINR) at intended receivers, leading to low throughput. To
overcome this problem, we propose a new algorithm for STDMA link scheduling
based on a graph model of the network as well as SINR computations. The
performance of our algorithm is evaluated in terms of spatial reuse and
computational complexity. Simulation results demonstrate that our algorithm
achieves better performance than existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701002</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701002</id><created>2007-01-02</created><authors><author><keyname>Serbetli</keyname><forenames>Semih</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Relay Assisted F/TDMA Ad Hoc Networks: Node Classification, Power
  Allocation and Relaying Strategies</title><categories>cs.IT math.IT</categories><comments>26 pages, 1 table, 9 figures</comments><abstract>  This paper considers the design of relay assisted F/TDMA ad hoc networks with
multiple relay nodes each of which assists the transmission of a predefined
subset of source nodes to their respective destinations. Considering the sum
capacity as the performance metric, we solve the problem of optimally
allocating the total power of each relay node between the transmissions it is
assisting. We consider four different relay transmission strategies, namely
regenerative decode-and-forward (RDF), nonregenerative decode-and-forward
(NDF), amplify-and-forward (AF) and compress-and-forward (CF). We first obtain
the optimum power allocation policies for the relay nodes that employ a uniform
relaying strategy for all nodes. We show that the optimum power allocation for
the RDF and NDF cases are modified water-filling solutions. We observe that for
a given relay transmit power, NDF always outperforms RDF whereas CF always
provides higher sum capacity than AF. When CF and NDF are compared, it is
observed that either of CF or NDF may outperform the other in different
scenarios. This observation suggests that the sum capacity can be further
improved by having each relay adopt its relaying strategy in helping different
source nodes. We investigate this problem next and determine the optimum power
allocation and relaying strategy for each source node that relay nodes assist.
We observe that optimum power allocation for relay nodes with hybrid relaying
strategies provides higher sum capacity than pure RDF, NDF, AF or CF relaying
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701003</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701003</id><created>2006-12-30</created><authors><author><keyname>Claussen</keyname><forenames>Jens Christian</forenames><affiliation>University Kiel</affiliation></author></authors><title>Magnification Laws of Winner-Relaxing and Winner-Enhancing Kohonen
  Feature Maps</title><categories>cs.NE cs.IT math.IT</categories><comments>6 pages, 3 figures. ESMTB 2002 Milano. For the extended journal
  version see cond-mat/0208414</comments><journal-ref>pp. 17-22 in : V. Capasso (Ed.): Mathematical Modeling &amp; Computing
  in Biology and Medicine, Miriam Series, Progetto Leonardo, Bologna (2003)</journal-ref><abstract>  Self-Organizing Maps are models for unsupervised representation formation of
cortical receptor fields by stimuli-driven self-organization in laterally
coupled winner-take-all feedforward structures. This paper discusses
modifications of the original Kohonen model that were motivated by a potential
function, in their ability to set up a neural mapping of maximal mutual
information. Enhancing the winner update, instead of relaxing it, results in an
algorithm that generates an infomax map corresponding to magnification exponent
of one. Despite there may be more than one algorithm showing the same
magnification exponent, the magnification law is an experimentally accessible
quantity and therefore suitable for quantitative description of neural
optimization principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701004</identifier>
 <datestamp>2008-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701004</id><created>2007-01-02</created><updated>2008-04-06</updated><authors><author><keyname>Ganguly</keyname><forenames>Sumit</forenames></author></authors><title>An algebraic approach to complexity of data stream computations</title><categories>cs.CC</categories><comments>Revised version</comments><abstract>  We consider a basic problem in the general data streaming model, namely, to
estimate a vector $f \in \Z^n$ that is arbitrarily updated (i.e., incremented
or decremented) coordinate-wise. The estimate $\hat{f} \in \Z^n$ must satisfy
$\norm{\hat{f}-f}_{\infty}\le \epsilon\norm{f}_1 $, that is, $\forall i
~(\abs{\hat{f}_i - f_i} \le \epsilon \norm{f}_1)$. It is known to have
$\tilde{O}(\epsilon^{-1})$ randomized space upper bound \cite{cm:jalgo},
$\Omega(\epsilon^{-1} \log (\epsilon n))$ space lower bound
\cite{bkmt:sirocco03} and deterministic space upper bound of
$\tilde{\Omega}(\epsilon^{-2})$ bits.\footnote{The $\tilde{O}$ and
$\tilde{\Omega}$ notations suppress poly-logarithmic factors in $n, \log
\epsilon^{-1}, \norm{f}_{\infty}$ and $\log \delta^{-1}$, where, $\delta$ is
the error probability (for randomized algorithm).} We show that any
deterministic algorithm for this problem requires space $\Omega(\epsilon^{-2}
(\log \norm{f}_1))$ bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701005</id><created>2006-12-30</created><authors><author><keyname>Tanguy</keyname><forenames>Christian</forenames></author></authors><title>Exact solutions for the two- and all-terminal reliabilities of the
  Brecht-Colbourn ladder and the generalized fan</title><categories>cs.PF</categories><proxy>ccsd hal-00122264</proxy><abstract>  The two- and all-terminal reliabilities of the Brecht-Colbourn ladder and the
generalized fan have been calculated exactly for arbitrary size as well as
arbitrary individual edge and node reliabilities, using transfer matrices of
dimension four at most. While the all-terminal reliabilities of these graphs
are identical, the special case of identical edge ($p$) and node ($\rho$)
reliabilities shows that their two-terminal reliabilities are quite distinct,
as demonstrated by their generating functions and the locations of the zeros of
the reliability polynomials, which undergo structural transitions at $\rho =
\displaystyle {1/2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701006</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701006</id><created>2006-12-30</created><updated>2008-09-17</updated><authors><author><keyname>Laendner</keyname><forenames>Stefan</forenames></author><author><keyname>Hehn</keyname><forenames>Thorsten</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author></authors><title>The Trapping Redundancy of Linear Block Codes</title><categories>cs.IT math.IT</categories><comments>12 pages, 4 tables, 1 figure, accepted for publication in IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize the notion of the stopping redundancy in order to study the
smallest size of a trapping set in Tanner graphs of linear block codes. In this
context, we introduce the notion of the trapping redundancy of a code, which
quantifies the relationship between the number of redundant rows in any
parity-check matrix of a given code and the size of its smallest trapping set.
Trapping sets with certain parameter sizes are known to cause error-floors in
the performance curves of iterative belief propagation decoders, and it is
therefore important to identify decoding matrices that avoid such sets. Bounds
on the trapping redundancy are obtained using probabilistic and constructive
methods, and the analysis covers both general and elementary trapping sets.
Numerical values for these bounds are computed for the [2640,1320] Margulis
code and the class of projective geometry codes, and compared with some new
code-specific trapping set size estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701007</id><created>2006-12-30</created><authors><author><keyname>Hatami</keyname><forenames>Hamed</forenames></author><author><keyname>Tusserkani</keyname><forenames>Ruzbeh</forenames></author></authors><title>On the Complexity of the Circular Chromatic Number</title><categories>cs.CG</categories><journal-ref>Journal of Graph Theory. 47(3) (2004) pp. 226-230</journal-ref><abstract>  Circular chromatic number, $\chi_c$ is a natural generalization of chromatic
number. It is known that it is \NP-hard to determine whether or not an
arbitrary graph $G$ satisfies $\chi(G) = \chi_c(G)$. In this paper we prove
that this problem is \NP-hard even if the chromatic number of the graph is
known. This answers a question of Xuding Zhu. Also we prove that for all
positive integers $k \ge 2$ and $n \ge 3$, for a given graph $G$ with
$\chi(G)=n$, it is \NP-complete to verify if $\chi_c(G) \le n- \frac{1}{k}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701008</id><created>2006-12-31</created><authors><author><keyname>Hatami</keyname><forenames>Hamed</forenames></author><author><keyname>Maserrat</keyname><forenames>Hossein</forenames></author></authors><title>On the Computational Complexity of Defining Sets</title><categories>cs.CC</categories><journal-ref>Journal of Discrete Applied Mathematics .149(1-3) (2005) pp.
  101-110</journal-ref><abstract>  Suppose we have a family ${\cal F}$ of sets. For every $S \in {\cal F}$, a
set $D \subseteq S$ is a {\sf defining set} for $({\cal F},S)$ if $S$ is the
only element of $\cal{F}$ that contains $D$ as a subset. This concept has been
studied in numerous cases, such as vertex colorings, perfect matchings,
dominating sets, block designs, geodetics, orientations, and Latin squares.
  In this paper, first, we propose the concept of a defining set of a logical
formula, and we prove that the computational complexity of such a problem is
$\Sigma_2$-complete.
  We also show that the computational complexity of the following problem about
the defining set of vertex colorings of graphs is $\Sigma_2$-complete:
  {\sc Instance:} A graph $G$ with a vertex coloring $c$ and an integer $k$.
  {\sc Question:} If ${\cal C}(G)$ be the set of all $\chi(G)$-colorings of
$G$, then does $({\cal C}(G),c)$ have a defining set of size at most $k$?
  Moreover, we study the computational complexity of some other variants of
this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701009</identifier>
 <datestamp>2009-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701009</id><created>2006-12-31</created><updated>2009-03-14</updated><authors><author><keyname>Afshani</keyname><forenames>Peyman</forenames></author><author><keyname>Hatami</keyname><forenames>Hamed</forenames></author></authors><title>Approximation and Inapproximability Results for Maximum Clique of Disc
  Graphs in High Dimensions</title><categories>cs.CG math.MG</categories><comments>Final version</comments><journal-ref>Information Processing Letters. 105(3) (2008) pp. 83-87</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove algorithmic and hardness results for the problem of finding the
largest set of a fixed diameter in the Euclidean space. In particular, we prove
that if $A^*$ is the largest subset of diameter $r$ of $n$ points in the
Euclidean space, then for every $\epsilon&gt;0$ there exists a polynomial time
algorithm that outputs a set $B$ of size at least $|A^*|$ and of diameter at
most $r(\sqrt{2}+\epsilon)$. On the hardness side, roughly speaking, we show
that unless $P=NP$ for every $\epsilon&gt;0$ it is not possible to guarantee the
diameter $r(\sqrt{4/3}-\epsilon)$ for $B$ even if the algorithm is allowed to
output a set of size $({95\over 94}-\epsilon)^{-1}|A^*|$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701010</id><created>2007-01-01</created><authors><author><keyname>Sidky</keyname><forenames>Ahmed</forenames></author><author><keyname>Arthur</keyname><forenames>James</forenames></author></authors><title>Determining the Applicability of Agile Practices to Mission and
  Life-critical Systems</title><categories>cs.SE</categories><abstract>  Adopting agile practices brings about many benefits and improvements to the
system being developed. However, in mission and life-critical systems, adopting
an inappropriate agile practice has detrimental impacts on the system in
various phases of its lifecycle as well as precludes desired qualities from
being actualized. This paper presents a three-stage process that provides
guidance to organizations on how to identify the agile practices they can
benefit from without causing any impact to the mission and life critical system
being developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701011</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701011</id><created>2007-01-02</created><updated>2007-04-17</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Infinite-Alphabet Prefix Codes Optimal for $\beta$-Exponential Penalties</title><categories>cs.IT cs.DS math.IT</categories><comments>5 pages, 2 figures (with 3 illustrations total), accepted to ISIT
  2007</comments><acm-class>E.4; H.1.1</acm-class><abstract>  Let $P = \{p(i)\}$ be a measure of strictly positive probabilities on the set
of nonnegative integers. Although the countable number of inputs prevents usage
of the Huffman algorithm, there are nontrivial $P$ for which known methods find
a source code that is optimal in the sense of minimizing expected codeword
length. For some applications, however, a source code should instead minimize
one of a family of nonlinear objective functions, $\beta$-exponential means,
those of the form $\log_a \sum_i p(i) a^{n(i)}$, where $n(i)$ is the length of
the $i$th codeword and $a$ is a positive constant. Applications of such
minimizations include a problem of maximizing the chance of message receipt in
single-shot communications ($a&lt;1$) and a problem of minimizing the chance of
buffer overflow in a queueing system ($a&gt;1$). This paper introduces methods for
finding codes optimal for such exponential means. One method applies to
geometric distributions, while another applies to distributions with lighter
tails. The latter algorithm is applied to Poisson distributions. Both are
extended to minimizing maximum pointwise redundancy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701012</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701012</id><created>2007-01-02</created><updated>2007-04-17</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>$D$-ary Bounded-Length Huffman Coding</title><categories>cs.IT cs.DS math.IT</categories><comments>5 pages, 2 figures, accepted to ISIT 2007</comments><acm-class>G.2.2; F.2; E.4; H.1.1</acm-class><abstract>  Efficient optimal prefix coding has long been accomplished via the Huffman
algorithm. However, there is still room for improvement and exploration
regarding variants of the Huffman problem. Length-limited Huffman coding,
useful for many practical applications, is one such variant, in which codes are
restricted to the set of codes in which none of the $n$ codewords is longer
than a given length, $l_{\max}$. Binary length-limited coding can be done in
$O(n l_{\max})$ time and O(n) space via the widely used Package-Merge
algorithm. In this paper the Package-Merge approach is generalized without
increasing complexity in order to introduce a minimum codeword length,
$l_{\min}$, to allow for objective functions other than the minimization of
expected codeword length, and to be applicable to both binary and nonbinary
codes; nonbinary codes were previously addressed using a slower dynamic
programming approach. These extensions have various applications -- including
faster decompression -- and can be used to solve the problem of finding an
optimal code with limited fringe, that is, finding the best code among codes
with a maximum difference between the longest and shortest codewords. The
previously proposed method for solving this problem was nonpolynomial time,
whereas solving this using the novel algorithm requires only $O(n (l_{\max}-
l_{\min})^2)$ time and O(n) space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701013</id><created>2007-01-03</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author><author><keyname>Xu</keyname><forenames>Xaiofei</forenames></author><author><keyname>Deng</keyname><forenames>Shengchun</forenames></author></authors><title>Attribute Value Weighting in K-Modes Clustering</title><categories>cs.AI</categories><comments>15 pages</comments><report-no>Tr-06-0615</report-no><abstract>  In this paper, the traditional k-modes clustering algorithm is extended by
weighting attribute value matches in dissimilarity computation. The use of
attribute value weighting technique makes it possible to generate clusters with
stronger intra-similarities, and therefore achieve better clustering
performance. Experimental results on real life datasets show that these value
weighting based k-modes algorithms are superior to the standard k-modes
algorithm with respect to clustering accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701014</id><created>2007-01-03</created><updated>2007-01-04</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>A Reply to Hofman On: &quot;Why LP cannot solve large instances of
  NP-complete problems in polynomial time&quot;</title><categories>cs.CC</categories><comments>2 page; 1 table; clarification of some unclear statements</comments><acm-class>F.2; F.2.2</acm-class><abstract>  Using an approach that seems to be patterned after that of Yannakakis, Hofman
argues that an NP-complete problem cannot be formulated as a polynomial
bounded-sized linear programming problem. He then goes on to propose a
&quot;construct&quot; that he claims to be a counter-example to recently published linear
programming formulations of the Traveling Salesman Problem (TSP) and the
Quadratic Assignment Problems (QAP), respectively. In this paper, we show that
Hofman's construct is flawed, and provide further proof that his
&quot;counter-example&quot; is invalid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701015</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701015</id><created>2007-01-03</created><updated>2007-12-21</updated><authors><author><keyname>Sens</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Arantes</keyname><forenames>Luciana</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Bouillaguet</keyname><forenames>Mathieu</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Martin</keyname><forenames>V&#xe9;ronique</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Greve</keyname><forenames>Fabiola</forenames><affiliation>DCC</affiliation></author></authors><title>Asynchronous Implementation of Failure Detectors with partial
  connectivity and unknown participants</title><categories>cs.DC</categories><proxy>ccsd inria-00122517</proxy><abstract>  We consider the problem of failure detection in dynamic networks such as
MANETs. Unreliable failure detectors are classical mechanisms which provide
information about process failures. However, most of current implementations
consider that the network is fully connected and that the initial number of
nodes of the system is known. This assumption is not applicable to dynamic
environments. Furthermore, such implementations are usually timer-based while
in dynamic networks there is no upper bound for communication delays since
nodes can move. This paper presents an asynchronous implementation of a failure
detector for unknown and mobile networks. Our approach does not rely on timers
and neither the composition nor the number of nodes in the system are known. We
prove that our algorithm can implement failure detectors of class &lt;&gt;S when
behavioral properties and connectivity conditions are satisfied by the
underlying system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701016</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701016</id><created>2007-01-03</created><updated>2007-04-18</updated><authors><author><keyname>Kafri</keyname><forenames>Oded</forenames></author></authors><title>The Second Law and Informatics</title><categories>cs.IT math.IT</categories><comments>20 pages 6 figures</comments><abstract>  A unification of thermodynamics and information theory is proposed. It is
argued that similarly to the randomness due to collisions in thermal systems,
the quenched randomness that exists in data files in informatics systems
contributes to entropy. Therefore, it is possible to define equilibrium and to
calculate temperature for informatics systems. The obtained temperature yields
correctly the Shannon information balance in informatics systems and is
consistent with the Clausius inequality and the Carnot cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701017</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701017</id><created>2007-01-03</created><updated>2007-05-09</updated><authors><author><keyname>Bacci</keyname><forenames>Giacomo</forenames></author><author><keyname>Luise</keyname><forenames>Marco</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Tulino</keyname><forenames>Antonia M.</forenames></author></authors><title>Energy-Efficient Power Control in Impulse Radio UWB Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Journal on Selected Topics in Signal Processing
  - Special issue on Performance Limits of Ultra-Wideband Systems</comments><doi>10.1109/JSTSP.2007.906588</doi><abstract>  In this paper, a game-theoretic model for studying power control for wireless
data networks in frequency-selective multipath environments is analyzed. The
uplink of an impulse-radio ultrawideband system is considered. The effects of
self-interference and multiple-access interference on the performance of
generic Rake receivers are investigated for synchronous systems. Focusing on
energy efficiency, a noncooperative game is proposed in which users in the
network are allowed to choose their transmit powers to maximize their own
utilities, and the Nash equilibrium for the proposed game is derived. It is
shown that, due to the frequency selective multipath, the noncooperative
solution is achieved at different signal-to-interference-plus-noise ratios,
depending on the channel realization and the type of Rake receiver employed. A
large-system analysis is performed to derive explicit expressions for the
achieved utilities. The Pareto-optimal (cooperative) solution is also discussed
and compared with the noncooperative approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701018</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701018</id><created>2007-01-03</created><authors><author><keyname>Duggan</keyname><forenames>Andrew</forenames></author><author><keyname>Barg</keyname><forenames>Alexander</forenames></author></authors><title>Performance Analysis of Algebraic Soft-Decision Decoding of Reed-Solomon
  Codes</title><categories>cs.IT math.IT</categories><comments>10 pages, 4 figures, submitted for publication</comments><abstract>  We investigate the decoding region for Algebraic Soft-Decision Decoding (ASD)
of Reed-Solomon codes in a discrete, memoryless, additive-noise channel. An
expression is derived for the error correction radius within which the
soft-decision decoder produces a list that contains the transmitted codeword.
The error radius for ASD is shown to be larger than that of Guruswami-Sudan
hard-decision decoding for a subset of low-rate codes. These results are also
extended to multivariable interpolation in the sense of Parvaresh and Vardy. An
upper bound is then presented for ASD's probability of error, where an error is
defined as the event that the decoder selects an erroneous codeword from its
list. This new definition gives a more accurate bound on the probability of
error of ASD than the results available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701019</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701019</id><created>2007-01-03</created><updated>2007-09-13</updated><authors><author><keyname>Wong</keyname><forenames>Tan F.</forenames></author><author><keyname>Lok</keyname><forenames>Tat M.</forenames></author><author><keyname>Shea</keyname><forenames>John M.</forenames></author></authors><title>Flow-optimized Cooperative Transmission for the Relay Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to Transactions on Information Theory, December 2006. 34
  pages, 4 figures. Correction, March 26, 2007. Revision, September 13, 2007:
  Revised text and provided additional proofs regarding diversity-multiplexing
  tradeoffs and delay-limited rates with optimal long-term power control</comments><abstract>  This paper describes an approach for half-duplex cooperative transmission in
a classical three-node relay channel. Assuming availability of channel state
information at nodes, the approach makes use of this information to optimize
distinct flows through the direct link from the source to the destination and
the path via the relay, respectively. It is shown that such a design can
effectively harness diversity advantage of the relay channel in both high-rate
and low-rate scenarios. When the rate requirement is low, the proposed design
gives a second-order outage diversity performance approaching that of
full-duplex relaying. When the rate requirement becomes asymptotically large,
the design still gives a close-to-second-order outage diversity performance.
The design also achieves the best diversity-multiplexing tradeoff possible for
the relay channel. With optimal long-term power control over the fading relay
channel, the proposed design achieves a delay-limited rate performance that is
only 3.0dB (5.4dB) worse than the capacity performance of the additive white
Gaussian channel in low- (high-) rate scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701020</id><created>2007-01-04</created><updated>2007-01-05</updated><authors><author><keyname>Ganguly</keyname><forenames>Sumit</forenames></author></authors><title>A nearly optimal and deterministic summary structure for update data
  streams</title><categories>cs.DS</categories><comments>Withdrawn</comments><abstract>  The paper has been withdrawn due to an error in Lemma 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701021</identifier>
 <datestamp>2013-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701021</id><created>2007-01-04</created><updated>2013-07-05</updated><authors><author><keyname>Milicchio</keyname><forenames>Franco</forenames></author></authors><title>The Unix KISS: A Case Study</title><categories>cs.OS cs.GL</categories><comments>Removed from arXiv and other sources</comments><abstract>  In this paper we show that the initial philosophy used in designing and
developing UNIX in early times has been forgotten due to &quot;fast practices&quot;. We
question the leitmotif that microkernels, though being by design adherent to
the KISS principle, have a number of context switches higher than their
monolithic counterparts, running a test suite and verify the results with
standard statistical validation tests. We advocate a wiser distribution of
shared libraries by statistically analyzing the weight of each shared object in
a typical UNIX system, showing that the majority of shared libraries exist in a
common space for no real evidence of need. Finally we examine the UNIX heritage
with an historical point of view, noticing how habits swiftly replaced the
intents of the original authors, moving the focus from the earliest purpose of
is avoiding complications, keeping a system simple to use and maintain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701022</id><created>2007-01-04</created><authors><author><keyname>Zakrzewski</keyname><forenames>Mateusz</forenames></author></authors><title>Definable functions in the simply typed lambda-calculus</title><categories>cs.LO</categories><comments>Submitted to TLCA 2007</comments><abstract>  It is a common knowledge that the integer functions definable in simply typed
lambda-calculus are exactly the extended polynomials. This is indeed the case
when one interprets integers over the type (p-&gt;p)-&gt;p-&gt;p where p is a base type
and/or equality is taken as beta-conversion. It is commonly believed that the
same holds for beta-eta equality and for integers represented over any fixed
type of the form (t-&gt;t)-&gt;t-&gt;t. In this paper we show that this opinion is not
quite true.
  We prove that the class of functions strictly definable in simply typed
lambda-calculus is considerably larger than the extended polynomials. Namely,
we define F as the class of strictly definable functions and G as a class that
contains extended polynomials and two additional functions, or more precisely,
two function schemas, and is closed under composition. We prove that G is a
subset of F.
  We conjecture that G exactly characterizes strictly definable functions, i.e.
G=F, and we gather some evidence for this conjecture proving, for example, that
every skewly representable finite range function is strictly representable over
(t-&gt;t)-&gt;t-&gt;t for some t.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701023</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701023</id><created>2007-01-04</created><updated>2008-07-15</updated><authors><author><keyname>Gubin</keyname><forenames>Sergey</forenames></author></authors><title>A Polynomial Time Algorithm for 3-SAT</title><categories>cs.CC cs.DM cs.DS cs.LO</categories><comments>9 pages. The version consolidates results and shares know-how</comments><acm-class>F.2.0; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Article describes a class of efficient algorithms for 3SAT and their
generalizations on SAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701024</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701024</id><created>2007-01-04</created><authors><author><keyname>Liang</keyname><forenames>Yingbin</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Secure Communication over Fading Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, Special Issue
  on Information Theoretic Security, November 2006</comments><abstract>  The fading broadcast channel with confidential messages (BCC) is
investigated, where a source node has common information for two receivers
(receivers 1 and 2), and has confidential information intended only for
receiver 1. The confidential information needs to be kept as secret as possible
from receiver 2. The broadcast channel from the source node to receivers 1 and
2 is corrupted by multiplicative fading gain coefficients in addition to
additive Gaussian noise terms. The channel state information (CSI) is assumed
to be known at both the transmitter and the receivers. The parallel BCC with
independent subchannels is first studied, which serves as an
information-theoretic model for the fading BCC. The secrecy capacity region of
the parallel BCC is established. This result is then specialized to give the
secrecy capacity region of the parallel BCC with degraded subchannels. The
secrecy capacity region is then established for the parallel Gaussian BCC, and
the optimal source power allocations that achieve the boundary of the secrecy
capacity region are derived. In particular, the secrecy capacity region is
established for the basic Gaussian BCC. The secrecy capacity results are then
applied to study the fading BCC. Both the ergodic and outage performances are
studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701025</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701025</id><created>2007-01-04</created><authors><author><keyname>Ryan</keyname><forenames>O.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author></authors><title>Free deconvolution for signal processing applications</title><categories>cs.IT math.IT</categories><comments>15 pages. submitted to IT Transactions on Information theoru</comments><abstract>  Situations in many fields of research, such as digital communications,
nuclear physics and mathematical finance, can be modelled with random matrices.
When the matrices get large, free probability theory is an invaluable tool for
describing the asymptotic behaviour of many systems. It will be shown how free
probability can be used to aid in source detection for certain systems. Sample
covariance matrices for systems with noise are the starting point in our source
detection problem. Multiplicative free deconvolution is shown to be a method
which can aid in expressing limit eigenvalue distributions for sample
covariance matrices, and to simplify estimators for eigenvalue distributions of
covariance matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701026</identifier>
 <datestamp>2007-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701026</id><created>2007-01-04</created><updated>2007-08-18</updated><authors><author><keyname>Chen</keyname><forenames>Po-Ning</forenames></author><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author><author><keyname>Hartmann</keyname><forenames>Carlos R. P.</forenames></author><author><keyname>Wu</keyname><forenames>Hong-Bin</forenames></author></authors><title>Analysis of Sequential Decoding Complexity Using the Berry-Esseen
  Inequality</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. on Information Theory, 30 pages, 9
  figures</comments><abstract>  his study presents a novel technique to estimate the computational complexity
of sequential decoding using the Berry-Esseen theorem. Unlike the theoretical
bounds determined by the conventional central limit theorem argument, which
often holds only for sufficiently large codeword length, the new bound obtained
from the Berry-Esseen theorem is valid for any blocklength. The accuracy of the
new bound is then examined for two sequential decoding algorithms, an
ordering-free variant of the generalized Dijkstra's algorithm (GDA)(or
simplified GDA) and the maximum-likelihood sequential decoding algorithm
(MLSDA). Empirically investigating codes of small blocklength reveals that the
theoretical upper bound for the simplified GDA almost matches the simulation
results as the signal-to-noise ratio (SNR) per information bit ($\gamma_b$) is
greater than or equal to 8 dB. However, the theoretical bound may become
markedly higher than the simulated average complexity when $\gamma_b$ is small.
For the MLSDA, the theoretical upper bound is quite close to the simulation
results for both high SNR ($\gamma_b\geq 6$ dB) and low SNR ($\gamma_b\leq 2$
dB). Even for moderate SNR, the simulation results and the theoretical bound
differ by at most \makeblue{0.8} on a $\log_{10}$ scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701027</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701027</id><created>2007-01-05</created><updated>2007-04-19</updated><authors><author><keyname>Palaiyanur</keyname><forenames>Hari</forenames></author><author><keyname>Chang</keyname><forenames>Cheng</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>The source coding game with a cheating switcher</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to International Symposium on
  Information Theory 2007; change in notation throughout paper for version 2</comments><abstract>  Berger's paper `The Source Coding Game', IEEE Trans. Inform. Theory, 1971,
considers the problem of finding the rate-distortion function for an
adversarial source comprised of multiple known IID sources. The adversary,
called the `switcher', was allowed only causal access to the source
realizations and the rate-distortion function was obtained through the use of a
type covering lemma. In this paper, the rate-distortion function of the
adversarial source is described, under the assumption that the switcher has
non-causal access to all source realizations. The proof utilizes the type
covering lemma and simple conditional, random `switching' rules. The
rate-distortion function is once again the maximization of the R(D) function
for a region of attainable IID distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701028</identifier>
 <datestamp>2008-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701028</id><created>2007-01-05</created><updated>2008-05-30</updated><authors><author><keyname>Herrera</keyname><forenames>Juan P.</forenames></author><author><keyname>Pury</keyname><forenames>Pedro A.</forenames></author></authors><title>Statistical keyword detection in literary corpora</title><categories>cs.CL cs.IR physics.soc-ph</categories><comments>Published version. 11 pages, 7 figures. SVJour for LaTeX2e</comments><journal-ref>Eur. Phys. J. B 63, 135-146 (2008)</journal-ref><doi>10.1140/epjb/e2008-00206-x</doi><abstract>  Understanding the complexity of human language requires an appropriate
analysis of the statistical distribution of words in texts. We consider the
information retrieval problem of detecting and ranking the relevant words of a
text by means of statistical information referring to the &quot;spatial&quot; use of the
words. Shannon's entropy of information is used as a tool for automatic keyword
extraction. By using The Origin of Species by Charles Darwin as a
representative text sample, we show the performance of our detector and compare
it with another proposals in the literature. The random shuffled text receives
special attention as a tool for calibrating the ranking indices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701029</id><created>2007-01-05</created><authors><author><keyname>Kusmierek</keyname><forenames>Dariusz</forenames></author></authors><title>The Inhabitation Problem for Rank Two Intersection Types</title><categories>cs.LO</categories><comments>15 pages</comments><abstract>  We prove that the inhabitation problem for rank two intersection types is
decidable, but (contrary to common belief) EXPTIME-hard. The exponential time
hardness is shown by reduction from the in-place acceptance problem for
alternating Turing machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701030</id><created>2007-01-05</created><authors><author><keyname>Chen</keyname><forenames>Eric Zhi</forenames></author></authors><title>New Constructions of a Family of 2-Generator Quasi-Cyclic Two-Weight
  Codes and Related Codes</title><categories>cs.IT math.IT</categories><comments>4 pages, conference</comments><abstract>  Based on cyclic simplex codes, a new construction of a family of 2-generator
quasi-cyclic two-weight codes is given. New optimal binary quasi-cyclic [195,
8, 96], [210, 8, 104] and [240, 8, 120] codes, good QC ternary [195, 6, 126],
[208, 6, 135], [221, 6, 144] codes are thus obtained. Furthermre, binary
quasi-cyclic self-complementary codes are also constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701031</id><created>2007-01-05</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Hardin</keyname><forenames>Th&#xe9;r&#xe8;se</forenames><affiliation>LIP6</affiliation></author><author><keyname>Weis</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>On the implementation of construction functions for non-free concrete
  data types</title><categories>cs.LO cs.PL</categories><proxy>ccsd inria-00095110</proxy><journal-ref>Dans 16th European Symposium on Programming (2006)</journal-ref><abstract>  Many algorithms use concrete data types with some additional invariants. The
set of values satisfying the invariants is often a set of representatives for
the equivalence classes of some equational theory. For instance, a sorted list
is a particular representative wrt commutativity. Theories like associativity,
neutral element, idempotence, etc. are also very common. Now, when one wants to
combine various invariants, it may be difficult to find the suitable
representatives and to efficiently implement the invariants. The preservation
of invariants throughout the whole program is even more difficult and error
prone. Classically, the programmer solves this problem using a combination of
two techniques: the definition of appropriate construction functions for the
representatives and the consistent usage of these functions ensured via
compiler verifications. The common way of ensuring consistency is to use an
abstract data type for the representatives; unfortunately, pattern matching on
representatives is lost. A more appealing alternative is to define a concrete
data type with private constructors so that both compiler verification and
pattern matching on representatives are granted. In this paper, we detail the
notion of private data type and study the existence of construction functions.
We also describe a prototype, called Moca, that addresses the entire problem
of...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701032</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701032</id><created>2007-01-05</created><updated>2009-06-03</updated><authors><author><keyname>Bonfante</keyname><forenames>Guillaume</forenames></author><author><keyname>Guiraud</keyname><forenames>Yves</forenames></author></authors><title>Polygraphic programs and polynomial-time functions</title><categories>cs.LO cs.CC math.CT</categories><comments>Logical Methods in Computer Science (to appear), 37 pages, 1 colour
  picture, corrected typos</comments><acm-class>F.1.1; F.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (June 3,
  2009) lmcs:764</journal-ref><doi>10.2168/LMCS-5(2:14)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational model of polygraphs. For that, we consider
polygraphic programs, a subclass of these objects, as a formal description of
first-order functional programs. We explain their semantics and prove that they
form a Turing-complete computational model. Their algebraic structure is used
by analysis tools, called polygraphic interpretations, for complexity analysis.
In particular, we delineate a subclass of polygraphic programs that compute
exactly the functions that are Turing-computable in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701033</id><created>2007-01-05</created><authors><author><keyname>Hegerle</keyname><forenames>Blake</forenames></author></authors><title>A Counterexample to a Proposed Proof of P=NP by S. Gubin</title><categories>cs.CC</categories><comments>2 pages</comments><abstract>  In a recent paper by S. Gubin [cs/0701023v1], a polynomial-time solution to
the 3SAT problem was presented as proof that P=NP. The proposed algorithm
cannot be made to work, which I shall demonstrate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701034</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701034</id><created>2007-01-05</created><updated>2007-05-09</updated><authors><author><keyname>Bacci</keyname><forenames>Giacomo</forenames></author><author><keyname>Luise</keyname><forenames>Marco</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Performance of Rake Receivers in IR-UWB Networks Using Energy-Efficient
  Power Control</title><categories>cs.IT math.IT</categories><comments>24 pages, 7 figures. Submitted to the IEEE Transactions on Wireless
  Communications</comments><abstract>  This paper studies the performance of partial-Rake (PRake) receivers in
impulse-radio ultrawideband wireless networks when an energy-efficient power
control scheme is adopted. Due to the large bandwidth of the system, the
multipath channel is assumed to be frequency-selective. By making use of
noncooperative game-theoretic models and large-system analysis tools, explicit
expressions are derived in terms of network parameters to measure the effects
of self-interference and multiple-access interference at a receiving access
point. Performance of the PRake receivers is thus compared in terms of achieved
utilities and loss to that of the all-Rake receiver. Simulation results are
provided to validate the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701035</id><created>2007-01-05</created><authors><author><keyname>Henneken</keyname><forenames>Edwin A.</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Thompson</keyname><forenames>Donna</forenames></author><author><keyname>Bohlen</keyname><forenames>Elizabeth</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Finding Astronomical Communities Through Co-readership Analysis</title><categories>cs.DL astro-ph</categories><comments>poster presented at the 209th AAS Meeting, 7 pages, 4 figures</comments><abstract>  Whenever a large group of people are engaged in an activity, communities will
form. The nature of these communities depends on the relationship considered.
In the group of people who regularly use scholarly literature, a relationship
like ``person i and person j have cited the same paper'' might reveal
communities of people working in a particular field. On this poster, we will
investigate the relationship ``person i and person j have read the same
paper''. Using the data logs of the NASA/Smithsonian Astrophysics Data System
(ADS), we first determine the population that will participate by requiring
that a user queries the ADS at a certain rate. Next, we apply the relationship
to this population. The result of this will be an abstract ``relationship
space'', which we will describe in terms of various ``representations''.
Examples of such ``representations'' are the projection of co-read vectors onto
Principal Components and the spectral density of the co-read network. We will
show that the co-read relationship results in structure, we will describe this
structure and we will provide a first attempt in the classification of this
structure in terms of astronomical communities.
  The ADS is funded by NASA Grant NNG06GG68G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701036</identifier>
 <datestamp>2007-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701036</id><created>2007-01-07</created><updated>2007-11-01</updated><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author></authors><title>Compression-based methods for nonparametric density estimation, on-line
  prediction, regression and classification for time series</title><categories>cs.IT math.IT</categories><abstract>  We address the problem of nonparametric estimation of characteristics for
stationary and ergodic time series. We consider finite-alphabet time series and
real-valued ones and the following four problems: i) estimation of the
(limiting) probability (or estimation of the density for real-valued time
series), ii) on-line prediction, iii) regression and iv) classification (or
so-called problems with side information). We show that so-called archivers (or
data compressors) can be used as a tool for solving these problems. In
particular, firstly, it is proven that any so-called universal code (or
universal data compressor) can be used as a basis for constructing
asymptotically optimal methods for the above problems. (By definition, a
universal code can &quot;compress&quot; any sequence generated by a stationary and
ergodic source asymptotically till the Shannon entropy of the source.) And,
secondly, we show experimentally that estimates, which are based on practically
used methods of data compression, have a reasonable precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701037</identifier>
 <datestamp>2009-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701037</id><created>2007-01-06</created><updated>2009-02-24</updated><authors><author><keyname>Ansel</keyname><forenames>Jason</forenames></author><author><keyname>Arya</keyname><forenames>Kapil</forenames></author><author><keyname>Cooperman</keyname><forenames>Gene</forenames></author></authors><title>DMTCP: Transparent Checkpointing for Cluster Computations and the
  Desktop</title><categories>cs.DC cs.OS</categories><comments>17 pages; 2 figures, 8 plots, and 2 tables; description of DMTCP;
  Version 3: describing checkpointing both for distributed multi-threaded
  applications (including MPI), and interactive shell-like languages on
  desktop; Revised to reflect version published in IPDPS-09; Software at:
  http://dmtcp.sourceforge.net/</comments><acm-class>D.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DMTCP (Distributed MultiThreaded CheckPointing) is a transparent user-level
checkpointing package for distributed applications. Checkpointing and restart
is demonstrated for a wide range of over 20 well known applications, including
MATLAB, Python, TightVNC, MPICH2, OpenMPI, and runCMS. RunCMS runs as a 680 MB
image in memory that includes 540 dynamic libraries, and is used for the CMS
experiment of the Large Hadron Collider at CERN. DMTCP transparently
checkpoints general cluster computations consisting of many nodes, processes,
and threads; as well as typical desktop applications. On 128 distributed cores
(32 nodes), checkpoint and restart times are typically 2 seconds, with
negligible run-time overhead. Typical checkpoint times are reduced to 0.2
seconds when using forked checkpointing. Experimental results show that
checkpoint time remains nearly constant as the number of nodes increases on a
medium-size cluster.
  DMTCP automatically accounts for fork, exec, ssh, mutexes/semaphores, TCP/IP
sockets, UNIX domain sockets, pipes, ptys (pseudo-terminals), terminal modes,
ownership of controlling terminals, signal handlers, open file descriptors,
shared open file descriptors, I/O (including the readline library), shared
memory (via mmap), parent-child process relationships, pid virtualization, and
other operating system artifacts. By emphasizing an unprivileged, user-space
approach, compatibility is maintained across Linux kernels from 2.6.9 through
the current 2.6.28. Since DMTCP is unprivileged and does not require special
kernel modules or kernel patches, DMTCP can be incorporated and distributed as
a checkpoint-restart module within some larger package.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701038</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701038</id><created>2007-01-06</created><updated>2007-02-27</updated><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author></authors><title>Approximate Eigenstructure of LTV Channels with Compactly Supported
  Spreading</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, submitted to the 2007 IEEE International Symposium
  on Information Theory; condition in Lemma 6 and constants in (26) corrected</comments><abstract>  In this article we obtain estimates on the approximate eigenstructure of
channels with a spreading function supported only on a set of finite measure
$|U|$.Because in typical application like wireless communication the spreading
function is a random process corresponding to a random Hilbert--Schmidt channel
operator $\BH$ we measure this approximation in terms of the ratio of the
$p$--norm of the deviation from variants of the Weyl symbol calculus to the
$a$--norm of the spreading function itself. This generalizes recent results
obtained for the case $p=2$ and $a=1$. We provide a general approach to this
topic and consider then operators with $|U|&lt;\infty$ in more detail. We show the
relation to pulse shaping and weighted norms of ambiguity functions. Finally we
derive several necessary conditions on $|U|$, such that the approximation error
is below certain levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701039</id><created>2007-01-06</created><authors><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames></author></authors><title>On the Complexity of the Numerically Definite Syllogistic and Related
  Fragments</title><categories>cs.LO cs.AI cs.CC</categories><comments>24 pages 1 figure</comments><acm-class>F.4.1</acm-class><abstract>  In this paper, we determine the complexity of the satisfiability problem for
various logics obtained by adding numerical quantifiers, and other
constructions, to the traditional syllogistic. In addition, we demonstrate the
incompleteness of some recently proposed proof-systems for these logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701040</id><created>2007-01-06</created><authors><author><keyname>Zhang</keyname><forenames>F.</forenames></author></authors><title>Curve Tracking Control for Legged Locomotion in Horizontal Plane</title><categories>cs.RO</categories><comments>10 pages, 11 figures, Submitted to IEEE Transactions on Automatic
  Control</comments><acm-class>I.2.9</acm-class><abstract>  We derive a hybrid feedback control law for the lateral leg spring (LLS)
model so that the center of mass of a legged runner follows a curved path in
horizontal plane. The control law enables the runner to change the placement
and the elasticity of its legs to move in a desired direction. Stable motion
along a curved path is achieved using curvature, bearing and relative distance
between the runner and the curve as feedback. Constraints on leg parameters
determine the class of curves that can be followed. We also derive an optimal
control law that stabilizes the orientation of the runner's body relative to
the velocity of the runner's center of mass.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701041</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701041</id><created>2007-01-07</created><authors><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>A Coding Theorem for a Class of Stationary Channels with Feedback</title><categories>cs.IT math.IT</categories><comments>23 pages, 5 figures, submitted for publication in IEEE Trans. Inform.
  Theory</comments><abstract>  A coding theorem is proved for a class of stationary channels with feedback
in which the output Y_n = f(X_{n-m}^n, Z_{n-m}^n) is the function of the
current and past m symbols from the channel input X_n and the stationary
ergodic channel noise Z_n. In particular, it is shown that the feedback
capacity is equal to $$ \limp_{n\to\infty} \sup_{p(x^n||y^{n-1})} \frac{1}{n}
I(X^n \to Y^n), $$ where I(X^n \to Y^n) = \sum_{i=1}^n I(X^i; Y_i|Y^{i-1})
denotes the Massey directed information from the channel input to the output,
and the supremum is taken over all causally conditioned distributions
p(x^n||y^{n-1}) = \prod_{i=1}^n p(x_i|x^{i-1},y^{i-1}). The main ideas of the
proof are the Shannon strategy for coding with side information and a new
elementary coding technique for the given channel model without feedback, which
is in a sense dual to Gallager's lossy coding of stationary ergodic sources. A
similar approach gives a simple alternative proof of coding theorems for finite
state channels by Yang-Kavcic-Tatikonda, Chen-Berger, and
Permuter-Weissman-Goldsmith.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701042</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701042</id><created>2007-01-08</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Tinguely</keyname><forenames>Stephan</forenames></author></authors><title>Sending a Bivariate Gaussian Source over a Gaussian MAC with Feedback</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to the IEEE International Symposium on Information
  Theory 2007</comments><acm-class>E.4</acm-class><abstract>  We consider the problem of transmitting a bivariate Gaussian source over a
two-user additive Gaussian multiple-access channel with feedback. Each of the
transmitters observes one of the source components and tries to describe it to
the common receiver. We are interested in the minimal mean squared error at
which the receiver can reconstruct each of the source components.
  In the ``symmetric case'' we show that, below a certain signal-to-noise ratio
threshold which is determined by the source correlation, feedback is useless
and the minimal distortion is achieved by uncoded transmission. For the general
case we give necessary conditions for the achievability of a distortion pair.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701043</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701043</id><created>2007-01-08</created><updated>2008-10-16</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Adaptive Alternating Minimization Algorithms</title><categories>cs.IT math.IT math.OC</categories><comments>12 pages, to appear in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 55, pp. 1423-1429,
  March 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical alternating minimization (or projection) algorithm has been
successful in the context of solving optimization problems over two variables.
The iterative nature and simplicity of the algorithm has led to its application
to many areas such as signal processing, information theory, control, and
finance. A general set of sufficient conditions for the convergence and
correctness of the algorithm is quite well-known when the underlying problem
parameters are fixed. In many practical situations, however, the underlying
problem parameters are changing over time, and the use of an adaptive algorithm
is more appropriate. In this paper, we study such an adaptive version of the
alternating minimization algorithm. As a main result of this paper, we provide
a general set of sufficient conditions for the convergence and correctness of
the adaptive algorithm. Perhaps surprisingly, these conditions seem to be the
minimal ones one would expect in such an adaptive setting. We present
applications of our results to adaptive decomposition of mixtures, adaptive
log-optimal portfolio selection, and adaptive filter design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701044</id><created>2007-01-08</created><authors><author><keyname>Lal</keyname><forenames>Sunder</forenames></author><author><keyname>Singh</keyname><forenames>Tej</forenames></author></authors><title>New ID Based Multi-Proxy Multi-Signcryption Scheme from Pairings</title><categories>cs.CR</categories><comments>9 pages</comments><abstract>  This paper presents an identity based multi-proxy multi-signcryption scheme
from pairings. In this scheme a proxy signcrypter group could authorized as a
proxy agent by the coopration of all members in the original signcryption
group. Then the proxy signcryption can be generated by the cooperation of all
the signcrypters in the authorized proxy signcrypter group on the behalf of the
original signcrypter group. As compared to the scheme of Liu and Xiao, the
proposed scheme provides public verifiability of the signature along with
simplified key management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701045</id><created>2007-01-08</created><updated>2007-01-16</updated><authors><author><keyname>Pinelis</keyname><forenames>Iosif</forenames></author></authors><title>Polygon Convexity: Another O(n) Test</title><categories>cs.CG cs.DS</categories><comments>14 pages; changes: (i) a test for non-strict convexity is added; (ii)
  the proofs are gathered in a separate section; (iii) a more detailed abstract
  is given</comments><acm-class>I.3.5; F.2.2; G.2.1; G.2.2</acm-class><abstract>  An n-gon is defined as a sequence \P=(V_0,...,V_{n-1}) of n points on the
plane. An n-gon \P is said to be convex if the boundary of the convex hull of
the set {V_0,...,V_{n-1}} of the vertices of \P coincides with the union of the
edges [V_0,V_1],...,[V_{n-1},V_0]; if at that no three vertices of \P are
collinear then \P is called strictly convex. We prove that an n-gon \P with
n\ge3 is strictly convex if and only if a cyclic shift of the sequence
(\al_0,...,\al_{n-1})\in[0,2\pi)^n of the angles between the x-axis and the
vectors V_1-V_0,...,V_0-V_{n-1} is strictly monotone. A ``non-strict'' version
of this result is also proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701046</id><created>2007-01-08</created><authors><author><keyname>Forte</keyname><forenames>Andrea G.</forenames></author><author><keyname>Schulzrinne</keyname><forenames>Henning</forenames></author></authors><title>Cooperation Between Stations in Wireless Networks</title><categories>cs.NI</categories><comments>16 pages, 49 references, 12 figures, 3 tables</comments><report-no>cucs-044-06</report-no><abstract>  In a wireless network, mobile nodes (MNs) repeatedly perform tasks such as
layer 2 (L2) handoff, layer 3 (L3) handoff and authentication. These tasks are
critical, particularly for real-time applications such as VoIP. We propose a
novel approach, namely Cooperative Roaming (CR), in which MNs can collaborate
with each other and share useful information about the network in which they
move. We show how we can achieve seamless L2 and L3 handoffs regardless of the
authentication mechanism used and without any changes to either the
infrastructure or the protocol. In particular, we provide a working
implementation of CR and show how, with CR, MNs can achieve a total L2+L3
handoff time of less than 16 ms in an open network and of about 21 ms in an
IEEE 802.11i network. We consider behaviors typical of IEEE 802.11 networks,
although many of the concepts and problems addressed here apply to any kind of
mobile network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701047</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701047</id><created>2007-01-08</created><updated>2007-04-12</updated><authors><author><keyname>Debowski</keyname><forenames>Lukasz</forenames></author></authors><title>On vocabulary size of grammar-based codes</title><categories>cs.IT cs.CL math.IT</categories><comments>5 pages, accepted to ISIT 2007 and corrected</comments><acm-class>E.4</acm-class><abstract>  We discuss inequalities holding between the vocabulary size, i.e., the number
of distinct nonterminal symbols in a grammar-based compression for a string,
and the excess length of the respective universal code, i.e., the code-based
analog of algorithmic mutual information. The aim is to strengthen inequalities
which were discussed in a weaker form in linguistics but shed some light on
redundancy of efficiently computable codes. The main contribution of the paper
is a construction of universal grammar-based codes for which the excess lengths
can be bounded easily.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701048</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701048</id><created>2007-01-08</created><updated>2007-01-12</updated><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author><author><keyname>Nuggehalli</keyname><forenames>Pavan</forenames></author></authors><title>Energy Conscious Interactive Communication for Sensor Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure. Minor revision: fixed a couple of typos</comments><acm-class>E.4</acm-class><abstract>  In this work, we are concerned with maximizing the lifetime of a cluster of
sensors engaged in single-hop communication with a base-station. In a
data-gathering network, the spatio-temporal correlation in sensor data induces
data-redundancy. Also, the interaction between two communicating parties is
well-known to reduce the communication complexity. This paper proposes a
formalism that exploits these two opportunities to reduce the number of bits
transmitted by a sensor node in a cluster, hence enhancing its lifetime. We
argue that our approach has several inherent advantages in scenarios where the
sensor nodes are acutely energy and computing-power constrained, but the
base-station is not so. This provides us an opportunity to develop
communication protocols, where most of the computing and communication is done
by the base-station.
  The proposed framework casts the sensor nodes and base-station communication
problem as the problem of multiple informants with correlated information
communicating with a recipient and attempts to extend extant work on
interactive communication between an informant-recipient pair to such
scenarios. Our work makes four major contributions. Firstly, we explicitly show
that in such scenarios interaction can help in reducing the communication
complexity. Secondly, we show that the order in which the informants
communicate with the recipient may determine the communication complexity.
Thirdly, we provide the framework to compute the $m$-message communication
complexity in such scenarios. Lastly, we prove that in a typical sensor network
scenario, the proposed formalism significantly reduces the communication and
computational complexities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701049</id><created>2007-01-08</created><updated>2007-03-26</updated><authors><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author></authors><title>On the Complexity of a Derivative Chess Problem</title><categories>cs.CC</categories><abstract>  We introduce QUEENS, a derivative chess problem based on the classical
n-queens problem. We prove that QUEENS is NP-complete, with respect to
polynomial-time reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701050</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701050</id><created>2007-01-08</created><updated>2007-04-13</updated><authors><author><keyname>Rioul</keyname><forenames>Olivier</forenames></author></authors><title>A Simple Proof of the Entropy-Power Inequality via Properties of Mutual
  Information</title><categories>cs.IT math.IT</categories><comments>5 pages, accepted for presentation at the IEEE International
  Symposium on Information Theory 2007</comments><abstract>  While most useful information theoretic inequalities can be deduced from the
basic properties of entropy or mutual information, Shannon's entropy power
inequality (EPI) seems to be an exception: available information theoretic
proofs of the EPI hinge on integral representations of differential entropy
using either Fisher's information (FI) or minimum mean-square error (MMSE). In
this paper, we first present a unified view of proofs via FI and MMSE, showing
that they are essentially dual versions of the same proof, and then fill the
gap by providing a new, simple proof of the EPI, which is solely based on the
properties of mutual information and sidesteps both FI or MMSE representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701051</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701051</id><created>2007-01-08</created><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author><author><keyname>Nuggehalli</keyname><forenames>Pavan</forenames></author></authors><title>Coding, Scheduling, and Cooperation in Wireless Sensor Networks</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure</comments><abstract>  We consider a single-hop data gathering sensor cluster consisting of a set of
sensors that need to transmit data periodically to a base-station. We are
interested in maximizing the lifetime of this network. Even though the setting
of our problem is very simple, it turns out that the solution is far from easy.
The complexity arises from several competing system-level opportunities
available to reduce the energy consumed in radio transmission. First, sensor
data is spatially and temporally correlated. Recent advances in distributed
source-coding allow us to take advantage of these correlations to reduce the
number of transmitted bits, with concomitant savings in energy. Second, it is
also well-known that channel-coding can be used to reduce transmission energy
by increasing transmission time. Finally, sensor nodes are cooperative, unlike
nodes in an ad hoc network that are often modeled as competitive, allowing us
to take full advantage of the first two opportunities for the purpose of
maximizing cluster lifetime. In this paper, we pose the problem of maximizing
lifetime as a max-min optimization problem subject to the constraint of
successful data collection and limited energy supply at each node. By
introducing the notion of instantaneous decoding, we are able to simplify this
optimization problem into a joint scheduling and time allocation problem. We
show that even with our ample simplification, the problem remains NP-hard. We
provide some algorithms, heuristics and insight for various scenarios. Our
chief contribution is to illustrate both the challenges and gains provided by
joint source-channel coding and scheduling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701052</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701052</id><created>2007-01-08</created><authors><author><keyname>Simon</keyname><forenames>Geoffroy</forenames><affiliation>DICE-MLG</affiliation></author><author><keyname>Lendasse</keyname><forenames>Amaury</forenames><affiliation>DICE-MLG</affiliation></author><author><keyname>Cottrell</keyname><forenames>Marie</forenames><affiliation>SAMOS, Matisse</affiliation></author><author><keyname>Fort</keyname><forenames>Jean-Claude</forenames><affiliation>SAMOS, Matisse</affiliation></author><author><keyname>Verleysen</keyname><forenames>Michel</forenames><affiliation>SAMOS, Matisse, Dice-MLG</affiliation></author></authors><title>Time Series Forecasting: Obtaining Long Term Trends with Self-Organizing
  Maps</title><categories>cs.LG math.ST stat.TH</categories><comments>\`{a} la suite de la conf\'{e}rence ANNPR, Florence 2003</comments><proxy>ccsd hal-00122749</proxy><journal-ref>Pattern Recognition Letter 26 n0; 12 (05/2005) 1795-1808</journal-ref><abstract>  Kohonen self-organisation maps are a well know classification tool, commonly
used in a wide variety of problems, but with limited applications in time
series forecasting context. In this paper, we propose a forecasting method
specifically designed for multi-dimensional long-term trends prediction, with a
double application of the Kohonen algorithm. Practical applications of the
method are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701053</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701053</id><created>2007-01-08</created><authors><author><keyname>Chen</keyname><forenames>Deqiang</forenames></author><author><keyname>Azarian</keyname><forenames>Kambiz</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author></authors><title>A Case For Amplify-Forward Relaying in the Block-Fading Multi-Access
  Channel</title><categories>cs.IT math.IT</categories><abstract>  This paper demonstrates the significant gains that multi-access users can
achieve from sharing a single amplify-forward relay in slow fading
environments. The proposed protocol, namely the multi-access relay
amplify-forward, allows for a low-complexity relay and achieves the optimal
diversity-multiplexing trade-off at high multiplexing gains. Analysis of the
protocol reveals that it uniformly dominates the compress-forward strategy and
further outperforms the dynamic decode-forward protocol at high multiplexing
gains. An interesting feature of the proposed protocol is that, at high
multiplexing gains, it resembles a multiple-input single-output system, and at
low multiplexing gains, it provides each user with the same
diversity-multiplexing trade-off as if there is no contention for the relay
from the other users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701054</id><created>2007-01-08</created><authors><author><keyname>Segerlind</keyname><forenames>Nathan</forenames></author></authors><title>Nearly-Exponential Size Lower Bounds for Symbolic Quantifier Elimination
  Algorithms and OBDD-Based Proofs of Unsatisfiability</title><categories>cs.CC cs.LO</categories><comments>40 pages, 3 figures. First public draft, comments welcome. Also
  submitted at ECCC</comments><acm-class>F.2.2</acm-class><abstract>  We demonstrate a family of propositional formulas in conjunctive normal form
so that a formula of size $N$ requires size $2^{\Omega(\sqrt[7]{N/logN})}$ to
refute using the tree-like OBDD refutation system of Atserias, Kolaitis and
Vardi with respect to all variable orderings. All known symbolic quantifier
elimination algorithms for satisfiability generate tree-like proofs when run on
unsatisfiable CNFs, so this lower bound applies to the run-times of these
algorithms. Furthermore, the lower bound generalizes earlier results on
OBDD-based proofs of unsatisfiability in that it applies for all variable
orderings, it applies when the clauses are processed according to an arbitrary
schedule, and it applies when variables are eliminated via quantification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701055</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701055</id><created>2007-01-08</created><authors><author><keyname>Hanlen</keyname><forenames>Leif</forenames></author><author><keyname>Abhayapala</keyname><forenames>Thushara</forenames></author></authors><title>Bounds on Space-Time-Frequency Dimensionality</title><categories>cs.IT math.IT</categories><comments>accepted Australian Communication Theory Workshop</comments><abstract>  We bound the number of electromagnetic signals which may be observed over a
frequency range $2W$ for a time $T$ within a region of space enclosed by a
radius $R$. Our result implies that broadband fields in space cannot be
arbitrarily complex: there is a finite amount of information which may be
extracted from a region of space via electromagnetic radiation.
  Three-dimensional space allows a trade-off between large carrier frequency
and bandwidth. We demonstrate applications in super-resolution and broadband
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701056</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701056</id><created>2007-01-08</created><authors><author><keyname>Abhayapala</keyname><forenames>Leif Hanlen Thushara</forenames></author></authors><title>Space-Time-Frequency Degrees of Freedom: Fundamental Limits for Spatial
  Information</title><categories>cs.IT math.IT</categories><abstract>  We bound the number of electromagnetic signals which may be observed over a
frequency range $[F-W,F+W]$ a time interval $[0,T]$ within a sphere of radius
$R$. We show that the such constrained signals may be represented by a series
expansion whose terms are bounded exponentially to zero beyond a threshold. Our
result implies there is a finite amount of information which may be extracted
from a region of space via electromagnetic radiation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701057</id><created>2007-01-08</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>Cooperative Optimization for Energy Minimization: A Case Study of Stereo
  Matching</title><categories>cs.CV cs.AI</categories><abstract>  Often times, individuals working together as a team can solve hard problems
beyond the capability of any individual in the team. Cooperative optimization
is a newly proposed general method for attacking hard optimization problems
inspired by cooperation principles in team playing. It has an established
theoretical foundation and has demonstrated outstanding performances in solving
real-world optimization problems. With some general settings, a cooperative
optimization algorithm has a unique equilibrium and converges to it with an
exponential rate regardless initial conditions and insensitive to
perturbations. It also possesses a number of global optimality conditions for
identifying global optima so that it can terminate its search process
efficiently. This paper offers a general description of cooperative
optimization, addresses a number of design issues, and presents a case study to
demonstrate its power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701058</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701058</id><created>2007-01-08</created><updated>2007-04-16</updated><authors><author><keyname>Mobasher</keyname><forenames>Amin</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Precoding in Multiple-Antenna Broadcast Systems with a Probabilistic
  Viewpoint</title><categories>cs.IT math.IT</categories><report-no>UW-E&amp;CE#2007-02</report-no><abstract>  In this paper, we investigate the minimum average transmit energy that can be
obtained in multiple antenna broadcast systems with channel inversion
technique. The achievable gain can be significantly higher than the
conventional gains that are mentioned in methods like perturbation technique of
Peel, et al. In order to obtain this gain, we introduce a Selective Mapping
(SLM) technique (based on random coding arguments). We propose to implement the
SLM method by using nested lattice codes in a trellis precoding framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701059</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701059</id><created>2007-01-08</created><updated>2007-04-25</updated><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author><author><keyname>Nuggehalli</keyname><forenames>Pavan</forenames></author></authors><title>Enhancing Sensor Network Lifetime Using Interactive Communication</title><categories>cs.IT math.IT</categories><comments>5 pages. To appear in ISIT-2007 (Final version). Major revision wrt
  version 2</comments><acm-class>C.2; E.4; H.1.1</acm-class><abstract>  We are concerned with maximizing the lifetime of a data-gathering wireless
sensor network consisting of set of nodes directly communicating with a
base-station. We model this scenario as the m-message interactive communication
between multiple correlated informants (sensor nodes) and a recipient
(base-station). With this framework, we show that m-message interactive
communication can indeed enhance network lifetime. Both worst-case and
average-case performances are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701060</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701060</id><created>2007-01-08</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Klappenecker</keyname><forenames>Andreas</forenames></author><author><keyname>Sarvepalli</keyname><forenames>Pradeep Kiran</forenames></author></authors><title>Duadic Group Algebra Codes</title><categories>cs.IT math.IT quant-ph</categories><comments>5 pages</comments><abstract>  Duadic group algebra codes are a generalization of quadratic residue codes.
This paper settles an open problem raised by Zhu concerning the existence of
duadic group algebra codes. These codes can be used to construct degenerate
quantum stabilizer codes that have the nice feature that many errors of small
weight do not need error correction; this fact is illustrated by an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701061</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701061</id><created>2007-01-09</created><authors><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Hou</keyname><forenames>Y. Thomas</forenames></author><author><keyname>Sherali</keyname><forenames>Hanif D.</forenames></author></authors><title>Conjugate Gradient Projection Approach for Multi-Antenna Gaussian
  Broadcast Channels</title><categories>cs.IT math.IT</categories><abstract>  It has been shown recently that the dirty-paper coding is the optimal
strategy for maximizing the sum rate of multiple-input multiple-output Gaussian
broadcast channels (MIMO BC). Moreover, by the channel duality, the nonconvex
MIMO BC sum rate problem can be transformed to the convex dual MIMO
multiple-access channel (MIMO MAC) problem with a sum power constraint. In this
paper, we design an efficient algorithm based on conjugate gradient projection
(CGP) to solve the MIMO BC maximum sum rate problem. Our proposed CGP algorithm
solves the dual sum power MAC problem by utilizing the powerful concept of
Hessian conjugacy. We also develop a rigorous algorithm to solve the projection
problem. We show that CGP enjoys provable convergence, nice scalability, and
great efficiency for large MIMO BC systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701062</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701062</id><created>2007-01-09</created><authors><author><keyname>Yang</keyname><forenames>Sichao</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author></authors><title>Network Coding over a Noisy Relay : a Belief Propagation Approach</title><categories>cs.IT math.IT</categories><abstract>  In recent years, network coding has been investigated as a method to obtain
improvements in wireless networks. A typical assumption of previous work is
that relay nodes performing network coding can decode the messages from sources
perfectly. On a simple relay network, we design a scheme to obtain network
coding gain even when the relay node cannot perfectly decode its received
messages. In our scheme, the operation at the relay node resembles message
passing in belief propagation, sending the logarithm likelihood ratio (LLR) of
the network coded message to the destination. Simulation results demonstrate
the gain obtained over different channel conditions. The goal of this paper is
not to give a theoretical result, but to point to possible interaction of
network coding with user cooperation in noisy scenario. The extrinsic
information transfer (EXIT) chart is shown to be a useful engineering tool to
analyze the performance of joint channel coding and network coding in the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701063</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701063</id><created>2007-01-09</created><authors><author><keyname>Takeuchi</keyname><forenames>Keigo</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Hierarchical Decoupling Principle of a MIMO-CDMA Channel in Asymptotic
  Limits</title><categories>cs.IT math.IT</categories><abstract>  We analyze an uplink of a fast flat fading MIMO-CDMA channel in the case
where the data symbol vector for each user follows an arbitrary distribution.
The spectral efficiency of the channel with CSI at the receiver is evaluated
analytically with the replica method. The main result is that the hierarchical
decoupling principle holds in the MIMO-CDMA channel, i.e., the MIMO-CDMA
channel is decoupled into a bank of single-user MIMO channels in the many-user
limit, and each single-user MIMO channel is further decoupled into a bank of
scalar Gaussian channels in the many-antenna limit for a fading model with a
limited number of scatterers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701064</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701064</id><created>2007-01-09</created><authors><author><keyname>Engelhardt</keyname><forenames>Kai</forenames></author><author><keyname>Moses</keyname><forenames>Yoram</forenames></author></authors><title>Causing Communication Closure: Safe Program Composition with Reliable
  Non-FIFO Channels</title><categories>cs.DC</categories><abstract>  A semantic framework for analyzing safe composition of distributed programs
is presented. Its applicability is illustrated by a study of program
composition when communication is reliable but not necessarily FIFO\@. In this
model, special care must be taken to ensure that messages do not accidentally
overtake one another in the composed program. We show that barriers do not
exist in this model. Indeed, no program that sends or receives messages can
automatically be composed with arbitrary programs without jeopardizing their
intended behavior. Safety of composition becomes context-sensitive and new
tools are needed for ensuring it. A notion of \emph{sealing} is defined, where
if a program $P$ is immediately followed by a program $Q$ that seals $P$ then
$P$ will be communication-closed--it will execute as if it runs in isolation.
The investigation of sealing in this model reveals a novel connection between
Lamport causality and safe composition. A characterization of sealable programs
is given, as well as efficient algorithms for testing if $Q$ seals $P$ and for
constructing a seal for a significant class of programs. It is shown that every
sealable program that is open to interference on $O(n^2)$ channels can be
sealed using O(n) messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701065</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701065</id><created>2007-01-09</created><authors><author><keyname>Chatzigeorgiou</keyname><forenames>I.</forenames></author><author><keyname>Rodrigues</keyname><forenames>M. R. D.</forenames></author><author><keyname>Wassell</keyname><forenames>I. J.</forenames></author><author><keyname>Carrasco</keyname><forenames>R.</forenames></author></authors><title>Can Punctured Rate-1/2 Turbo Codes Achieve a Lower Error Floor than
  their Rate-1/3 Parent Codes?</title><categories>cs.IT math.IT</categories><comments>5 pages, 7 figures, Proceedings of the 2006 IEEE Information Theory
  Workshop, Chengdu, China, October 22-26, 2006</comments><abstract>  In this paper we concentrate on rate-1/3 systematic parallel concatenated
convolutional codes and their rate-1/2 punctured child codes. Assuming
maximum-likelihood decoding over an additive white Gaussian channel, we
demonstrate that a rate-1/2 non-systematic child code can exhibit a lower error
floor than that of its rate-1/3 parent code, if a particular condition is met.
However, assuming iterative decoding, convergence of the non-systematic code
towards low bit-error rates is problematic. To alleviate this problem, we
propose rate-1/2 partially-systematic codes that can still achieve a lower
error floor than that of their rate-1/3 parent codes. Results obtained from
extrinsic information transfer charts and simulations support our conclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701066</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701066</id><created>2007-01-09</created><authors><author><keyname>Sassatelli</keyname><forenames>Lucile</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author></authors><title>Non-binary Hybrid LDPC Codes: Structure, Decoding and Optimization</title><categories>cs.IT math.IT</categories><journal-ref>IEEE 2006 Information Theory Workshop, Chengdu, China, Oct.2006,
  in proceedings</journal-ref><abstract>  In this paper, we propose to study and optimize a very general class of LDPC
codes whose variable nodes belong to finite sets with different orders. We
named this class of codes Hybrid LDPC codes. Although efficient optimization
techniques exist for binary LDPC codes and more recently for non-binary LDPC
codes, they both exhibit drawbacks due to different reasons. Our goal is to
capitalize on the advantages of both families by building codes with binary (or
small finite set order) and non-binary parts in their factor graph
representation. The class of Hybrid LDPC codes is obviously larger than
existing types of codes, which gives more degrees of freedom to find good codes
where the existing codes show their limits. We give two examples where hybrid
LDPC codes show their interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701067</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701067</id><created>2007-01-09</created><authors><author><keyname>Rajan</keyname><forenames>G. Susinder</forenames></author><author><keyname>Tandon</keyname><forenames>Anshoo</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>On Four-group ML Decodable Distributed Space Time Codes for Cooperative
  Communication</title><categories>cs.IT math.IT</categories><comments>To appear in Proceedings of WCNC 2007, Hong Kong, March 11-15, 2007.
  5 pages, 1 Figure</comments><abstract>  A construction of a new family of distributed space time codes (DSTCs) having
full diversity and low Maximum Likelihood (ML) decoding complexity is provided
for the two phase based cooperative diversity protocols of Jing-Hassibi and the
recently proposed Generalized Non-orthogonal Amplify and Forward (GNAF)
protocol of Rajan et al. The salient feature of the proposed DSTCs is that they
satisfy the extra constraints imposed by the protocols and are also four-group
ML decodable which leads to significant reduction in ML decoding complexity
compared to all existing DSTC constructions. Moreover these codes have uniform
distribution of power among the relays as well as in time. Also, simulations
results indicate that these codes perform better in comparison with the only
known DSTC with the same rate and decoding complexity, namely the Coordinate
Interleaved Orthogonal Design (CIOD). Furthermore, they perform very close to
DSTCs from field extensions which have same rate but higher decoding
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701068</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701068</id><created>2007-01-09</created><authors><author><keyname>Rajan</keyname><forenames>G. Susinder</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Distributed Space-Time Codes for Cooperative Networks with Partial CSI</title><categories>cs.IT math.IT</categories><comments>To appear in Proceedings of WCNC 2007, Hong Kong, March 11-15, 2007</comments><abstract>  Design criteria and full-diversity Distributed Space Time Codes (DSTCs) for
the two phase transmission based cooperative diversity protocol of Jing-Hassibi
and the Generalized Nonorthogonal Amplify and Forward (GNAF) protocol are
reported, when the relay nodes are assumed to have knowledge of the phase
component of the source to relay channel gains. It is shown that this under
this partial channel state information (CSI), several well known space time
codes for the colocated MIMO (Multiple Input Multiple Output) channel become
amenable for use as DSTCs. In particular, the well known complex orthogonal
designs, generalized coordinate interleaved orthogonal designs (GCIODs) and
unitary weight single symbol decodable (UW-SSD) codes are shown to satisfy the
required design constraints for DSTCs. Exploiting the relaxed code design
constraints, we propose DSTCs obtained from Clifford Algebras which have low ML
decoding complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701069</identifier>
 <datestamp>2007-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701069</id><created>2007-01-10</created><updated>2007-07-12</updated><authors><author><keyname>Didier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Laigle-Chapuy</keyname><forenames>Yann</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Finding low-weight polynomial multiples using discrete logarithm</title><categories>cs.CR</categories><journal-ref>Dans IEEE International Symposium on Information Theory - ISIT'07
  (2007)</journal-ref><abstract>  Finding low-weight multiples of a binary polynomial is a difficult problem
arising in the context of stream ciphers cryptanalysis. The classical algorithm
to solve this problem is based on a time memory trade-off. We will present an
improvement to this approach using discrete logarithm rather than a direct
representation of the involved polynomials. This gives an algorithm which
improves the theoretical complexity, and is also very flexible in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701070</identifier>
 <datestamp>2014-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701070</id><created>2007-01-10</created><authors><author><keyname>Augot</keyname><forenames>Daniel</forenames><affiliation>LITIS</affiliation></author><author><keyname>Bardet</keyname><forenames>Magali</forenames><affiliation>LITIS</affiliation></author><author><keyname>Faug&#xe8;re</keyname><forenames>Jean-Charles</forenames><affiliation>LIP6</affiliation></author></authors><title>On formulas for decoding binary cyclic codes</title><categories>cs.IT math.IT</categories><proxy>ccsd inria-00123312</proxy><journal-ref>IEEE International Symposium on Information Theory, 2007 (ISIT
  2007) (2007) 2646-2650</journal-ref><doi>10.1109/ISIT.2007.4557618</doi><abstract>  We adress the problem of the algebraic decoding of any cyclic code up to the
true minimum distance. For this, we use the classical formulation of the
problem, which is to find the error locator polynomial in terms of the syndroms
of the received word. This is usually done with the Berlekamp-Massey algorithm
in the case of BCH codes and related codes, but for the general case, there is
no generic algorithm to decode cyclic codes. Even in the case of the quadratic
residue codes, which are good codes with a very strong algebraic structure,
there is no available general decoding algorithm. For this particular case of
quadratic residue codes, several authors have worked out, by hand, formulas for
the coefficients of the locator polynomial in terms of the syndroms, using the
Newton identities. This work has to be done for each particular quadratic
residue code, and is more and more difficult as the length is growing.
Furthermore, it is error-prone. We propose to automate these computations,
using elimination theory and Grbner bases. We prove that, by computing
appropriate Grbner bases, one automatically recovers formulas for the
coefficients of the locator polynomial, in terms of the syndroms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701071</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701071</id><created>2007-01-10</created><updated>2007-08-23</updated><authors><author><keyname>Laoutaris</keyname><forenames>Nikolaos</forenames></author><author><keyname>Rajaraman</keyname><forenames>Rajmohan</forenames></author><author><keyname>Sundaram</keyname><forenames>Ravi</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>A bounded-degree network formation game</title><categories>cs.GT</categories><abstract>  Motivated by applications in peer-to-peer and overlay networks we define and
study the \emph{Bounded Degree Network Formation} (BDNF) game. In an
$(n,k)$-BDNF game, we are given $n$ nodes, a bound $k$ on the out-degree of
each node, and a weight $w_{vu}$ for each ordered pair $(v,u)$ representing the
traffic rate from node $v$ to node $u$. Each node $v$ uses up to $k$ directed
links to connect to other nodes with an objective to minimize its average
distance, using weights $w_{vu}$, to all other destinations. We study the
existence of pure Nash equilibria for $(n,k)$-BDNF games. We show that if the
weights are arbitrary, then a pure Nash wiring may not exist. Furthermore, it
is NP-hard to determine whether a pure Nash wiring exists for a given
$(n,k)$-BDNF instance. A major focus of this paper is on uniform $(n,k)$-BDNF
games, in which all weights are 1. We describe how to construct a pure Nash
equilibrium wiring given any $n$ and $k$, and establish that in all pure Nash
wirings the cost of individual nodes cannot differ by more than a factor of
nearly 2, whereas the diameter cannot exceed $O(\sqrt{n \log_k n})$. We also
analyze best-response walks on the configuration space defined by the uniform
game, and show that starting from any initial configuration, strong
connectivity is reached within $\Theta(n^2)$ rounds. Convergence to a pure Nash
equilibrium, however, is not guaranteed. We present simulation results that
suggest that loop-free best-response walks always exist, but may not be
polynomially bounded. We also study a special family of \emph{regular} wirings,
the class of Abelian Cayley graphs, in which all nodes imitate the same wiring
pattern, and show that if $n$ is sufficiently large no such regular wiring can
be a pure Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701072</id><created>2007-01-10</created><updated>2007-01-26</updated><authors><author><keyname>Voss</keyname><forenames>Jakob</forenames></author></authors><title>Tagging, Folksonomy &amp; Co - Renaissance of Manual Indexing?</title><categories>cs.IR</categories><comments>Preprint. 12 pages, 1 figure, 54 references</comments><acm-class>H.3.1</acm-class><abstract>  This paper gives an overview of current trends in manual indexing on the Web.
Along with a general rise of user generated content there are more and more
tagging systems that allow users to annotate digital resources with tags
(keywords) and share their annotations with other users. Tagging is frequently
seen in contrast to traditional knowledge organization systems or as something
completely new. This paper shows that tagging should better be seen as a
popular form of manual indexing on the Web. Difference between controlled and
free indexing blurs with sufficient feedback mechanisms. A revised typology of
tagging systems is presented that includes different user roles and knowledge
organization systems with hierarchical relationships and vocabulary control. A
detailed bibliography of current research in collaborative tagging is included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701073</id><created>2007-01-10</created><authors><author><keyname>Avigad</keyname><forenames>Jeremy</forenames></author><author><keyname>Donnelly</keyname><forenames>Kevin</forenames></author></authors><title>A decision procedure for linear &quot;big O&quot; equations</title><categories>cs.LO</categories><acm-class>F.4.1; I.2.3</acm-class><abstract>  Let $F$ be the set of functions from an infinite set, $S$, to an ordered
ring, $R$. For $f$, $g$, and $h$ in $F$, the assertion $f = g + O(h)$ means
that for some constant $C$, $|f(x) - g(x)| \leq C |h(x)|$ for every $x$ in $S$.
Let $L$ be the first-order language with variables ranging over such functions,
symbols for $0, +, -, \min, \max$, and absolute value, and a ternary relation
$f = g + O(h)$. We show that the set of quantifier-free formulas in this
language that are valid in the intended class of interpretations is decidable,
and does not depend on the underlying set, $S$, or the ordered ring, $R$. If
$R$ is a subfield of the real numbers, we can add a constant 1 function, as
well as multiplication by constants from any computable subfield. We obtain
further decidability results for certain situations in which one adds symbols
denoting the elements of a fixed sequence of functions of strictly increasing
rates of growth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701074</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701074</id><created>2007-01-10</created><authors><author><keyname>Vanclay</keyname><forenames>Jerome K</forenames></author></authors><title>On the robustness of the h-index</title><categories>cs.DL</categories><comments>10 pages, 4 tables, 1 figure</comments><journal-ref>Journal of the American Society for Information Science and
  Technology 58(10):1547-1550 (2007)</journal-ref><doi>10.1002/asi.20616</doi><abstract>  The h-index (Hirsch, 2005) is robust, remaining relatively unaffected by
errors in the long tails of the citations-rank distribution, such as
typographic errors that short-change frequently-cited papers and create bogus
additional records. This robustness, and the ease with which h-indices can be
verified, support the use of a Hirsch-type index over alternatives such as the
journal impact factor. These merits of the h-index apply to both individuals
and to journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701075</id><created>2007-01-10</created><authors><author><keyname>Takami</keyname><forenames>Toshiya</forenames></author><author><keyname>Maki</keyname><forenames>Jun</forenames></author><author><keyname>Ooba</keyname><forenames>Jun-ichi</forenames></author><author><keyname>Inadomi</keyname><forenames>Yuichi</forenames></author><author><keyname>Honda</keyname><forenames>Hiroaki</forenames></author><author><keyname>Kobayashi</keyname><forenames>Taizo</forenames></author><author><keyname>Nogita</keyname><forenames>Rie</forenames></author><author><keyname>Aoyagi</keyname><forenames>Mutsumi</forenames></author></authors><title>Open-architecture Implementation of Fragment Molecular Orbital Method
  for Peta-scale Computing</title><categories>cs.DC physics.comp-ph</categories><comments>6 pages, 9 figures, proceedings of the 2nd IEEE/ACM international
  workshop on high performance computing for nano-science and technology
  (HPCNano06)</comments><abstract>  We present our perspective and goals on highperformance computing for
nanoscience in accordance with the global trend toward &quot;peta-scale computing.&quot;
After reviewing our results obtained through the grid-enabled version of the
fragment molecular orbital method (FMO) on the grid testbed by the Japanese
Grid Project, National Research Grid Initiative (NAREGI), we show that FMO is
one of the best candidates for peta-scale applications by predicting its
effective performance in peta-scale computers. Finally, we introduce our new
project constructing a peta-scale application in an open-architecture
implementation of FMO in order to realize both goals of highperformance in
peta-scale computers and extendibility to multiphysics simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701076</id><created>2007-01-11</created><updated>2007-03-20</updated><authors><author><keyname>Danner</keyname><forenames>Norman</forenames></author><author><keyname>Royer</keyname><forenames>James S.</forenames></author></authors><title>Time-complexity semantics for feasible affine recursions (extended
  abstract)</title><categories>cs.LO</categories><comments>Typographical fixes; some rearrangement of material. A shortened
  version is to appear in S.B. Cooper, B. Lowe, A. Sorbi (eds.),_Computation in
  the Real World_ (Proceedings Computation in Europe 2007, Sienna),
  Springer-Verlag, Berlin, 2007</comments><acm-class>F.3.3; F.1.3</acm-class><abstract>  The authors' ATR programming formalism is a version of call-by-value PCF
under a complexity-theoretically motivated type system. ATR programs run in
type-2 polynomial-time and all standard type-2 basic feasible functionals are
ATR-definable (ATR types are confined to levels 0, 1, and 2). A limitation of
the original version of ATR is that the only directly expressible recursions
are tail-recursions. Here we extend ATR so that a broad range of affine
recursions are directly expressible. In particular, the revised ATR can fairly
naturally express the classic insertion- and selection-sort algorithms, thus
overcoming a sticking point of most prior implicit-complexity-based formalisms.
The paper's main work is in extending and simplifying the original
time-complexity semantics for ATR to develop a set of tools for extracting and
solving the higher-type recurrences arising from feasible affine recursions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701077</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701077</id><created>2007-01-11</created><updated>2007-08-09</updated><authors><author><keyname>Obermeyer</keyname><forenames>Karl J.</forenames></author><author><keyname>Ganguli</keyname><forenames>Anurag</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Asynchronous Distributed Searchlight Scheduling</title><categories>cs.MA cs.RO</categories><comments>Tech. report contains proofs corresponding to a paper to appear in
  Conference on Decision and Control 2007. In this version, minor typos have
  been fixed and some notation changed for clarity</comments><acm-class>I.2.11</acm-class><abstract>  This paper develops and compares two simple asynchronous distributed
searchlight scheduling algorithms for multiple robotic agents in nonconvex
polygonal environments. A searchlight is a ray emitted by an agent which cannot
penetrate the boundary of the environment. A point is detected by a searchlight
if and only if the point is on the ray at some instant. Targets are points
which can move continuously with unbounded speed. The objective of the proposed
algorithms is for the agents to coordinate the slewing (rotation about a point)
of their searchlights in a distributed manner, i.e., using only local sensing
and limited communication, such that any target will necessarily be detected in
finite time. The first algorithm we develop, called the DOWSS (Distributed One
Way Sweep Strategy), is a distributed version of a known algorithm described
originally in 1990 by Sugihara et al \cite{KS-IS-MY:90}, but it can be very
slow in clearing the entire environment because only one searchlight may slew
at a time. In an effort to reduce the time to clear the environment, we develop
a second algorithm, called the PTSS (Parallel Tree Sweep Strategy), in which
searchlights sweep in parallel if guards are placed according to an environment
partition belonging to a class we call PTSS partitions. Finally, we discuss how
DOWSS and PTSS could be combined with with deployment, or extended to
environments with holes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701078</id><created>2007-01-11</created><updated>2007-04-26</updated><authors><author><keyname>Sethuraman</keyname><forenames>Vignesh</forenames></author><author><keyname>Wang</keyname><forenames>Ligong</forenames></author><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>Low SNR Capacity of Fading Channels -- MIMO and Delay Spread</title><categories>cs.IT math.IT</categories><abstract>  Discrete-time Rayleigh fading multiple-input multiple-output (MIMO) channels
are considered, with no channel state information at the transmitter and
receiver. The fading is assumed to be correlated in time and independent from
antenna to antenna. Peak and average transmit power constraints are imposed,
either on the sum over antennas, or on each individual antenna. In both cases,
an upper bound and an asymptotic lower bound, as the signal-to-noise ratio
approaches zero, on the channel capacity are presented. The limit of normalized
capacity is identified under the sum power constraints, and, for a subclass of
channels, for individual power constraints. These results carry over to a SISO
channel with delay spread (i.e. frequency selective fading).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701079</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701079</id><created>2007-01-11</created><authors><author><keyname>Reznik</keyname><forenames>Yuriy A.</forenames></author></authors><title>Practical Binary Adaptive Block Coder</title><categories>cs.IT cs.DS math.IT</categories><abstract>  This paper describes design of a low-complexity algorithm for adaptive
encoding/ decoding of binary sequences produced by memoryless sources. The
algorithm implements universal block codes constructed for a set of contexts
identified by the numbers of non-zero bits in previous bits in a sequence. We
derive a precise formula for asymptotic redundancy of such codes, which refines
previous well-known estimate by Krichevsky and Trofimov, and provide
experimental verification of this result. In our experimental study we also
compare our implementation with existing binary adaptive encoders, such as
JBIG's Q-coder, and MPEG AVC (ITU-T H.264)'s CABAC algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701080</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701080</id><created>2007-01-12</created><authors><author><keyname>Shieh</keyname><forenames>Shin-Lin</forenames></author><author><keyname>Chen</keyname><forenames>Po-Ning</forenames></author><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author></authors><title>Analysis of the Sufficient Path Elimination Window for the
  Maximum-Likelihood Sequential-Search Decoding Algorithm for Binary
  Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. on Information Theory, 26 pages, 11
  figures</comments><abstract>  A common problem on sequential-type decoding is that at the signal-to-noise
ratio (SNR) below the one corresponding to the cutoff rate, the average
decoding complexity per information bit and the required stack size grow
rapidly with the information length. In order to alleviate the problem in the
maximum-likelihood sequential decoding algorithm (MLSDA), we propose to
directly eliminate the top path whose end node is $\Delta$-trellis-level prior
to the farthest one among all nodes that have been expanded thus far by the
sequential search. Following random coding argument, we analyze the
early-elimination window $\Delta$ that results in negligible performance
degradation for the MLSDA. Our analytical results indicate that the required
early elimination window for negligible performance degradation is just twice
of the constraint length for rate one-half convolutional codes. For rate
one-third convolutional codes, the required early-elimination window even
reduces to the constraint length. The suggestive theoretical level thresholds
almost coincide with the simulation results. As a consequence of the small
early-elimination window required for near maximum-likelihood performance, the
MLSDA with early-elimination modification rules out considerable computational
burdens, as well as memory requirement, by directly eliminating a big number of
the top paths, which makes the MLSDA with early elimination very suitable for
applications that dictate a low-complexity software implementation with near
maximum-likelihood performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701081</id><created>2007-01-12</created><authors><author><keyname>Serebrenik</keyname><forenames>Alexander</forenames></author><author><keyname>Vanhoof</keyname><forenames>Wim</forenames></author></authors><title>Fingerprinting Logic Programs</title><categories>cs.PL cs.SE</categories><comments>Paper presented at the 16th Workshop on Logic-based methods in
  Programming Languages (WLPE2006)</comments><abstract>  In this work we present work in progress on functionality duplication
detection in logic programs. Eliminating duplicated functionality recently
became prominent in context of refactoring. We describe a quantitative approach
that allows to measure the ``similarity'' between two predicate definitions.
Moreover, we show how to compute a so-called ``fingerprint'' for every
predicate. Fingerprints capture those characteristics of the predicate that are
significant when searching for duplicated functionality. Since reasoning on
fingerprints is much easier than reasoning on predicate definitions, comparing
the fingerprints is a promising direction in automated code duplication in
logic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701082</id><created>2007-01-12</created><authors><author><keyname>Mesnard</keyname><forenames>Fred</forenames></author><author><keyname>Serebrenik</keyname><forenames>Alexander</forenames></author></authors><title>Recurrence with affine level mappings is P-time decidable for CLP(R)</title><categories>cs.PL cs.LO</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><acm-class>D.1.6; F.3.2</acm-class><abstract>  In this paper we introduce a class of constraint logic programs such that
their termination can be proved by using affine level mappings. We show that
membership to this class is decidable in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701083</identifier>
 <datestamp>2008-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701083</id><created>2007-01-13</created><authors><author><keyname>Gottlob</keyname><forenames>Georg</forenames></author><author><keyname>Samer</keyname><forenames>Marko</forenames></author></authors><title>A Backtracking-Based Algorithm for Computing Hypertree-Decompositions</title><categories>cs.DS cs.AI</categories><comments>19 pages, 6 figures, 3 tables</comments><acm-class>I.2.8</acm-class><journal-ref>ACM Journal of Experimental Algorithmics (JEA) 13(1):1.1-1.19,
  2008.</journal-ref><doi>10.1145/1412228.1412229</doi><abstract>  Hypertree decompositions of hypergraphs are a generalization of tree
decompositions of graphs. The corresponding hypertree-width is a measure for
the cyclicity and therefore tractability of the encoded computation problem.
Many NP-hard decision and computation problems are known to be tractable on
instances whose structure corresponds to hypergraphs of bounded
hypertree-width. Intuitively, the smaller the hypertree-width, the faster the
computation problem can be solved. In this paper, we present the new
backtracking-based algorithm det-k-decomp for computing hypertree
decompositions of small width. Our benchmark evaluations have shown that
det-k-decomp significantly outperforms opt-k-decomp, the only exact hypertree
decomposition algorithm so far. Even compared to the best heuristic algorithm,
we obtained competitive results as long as the hypergraphs are not too large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701084</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701084</id><created>2007-01-12</created><updated>2007-04-22</updated><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames><affiliation>Los Alamos</affiliation></author><author><keyname>Stepanov</keyname><forenames>Mikhail</forenames><affiliation>UA, Tucson</affiliation></author></authors><title>Pseudo-codeword Landscape</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>5 pages, 2 figures, proceedings of ISIT '07</comments><report-no>LA-UR# 07-0144</report-no><abstract>  We discuss the performance of Low-Density-Parity-Check (LDPC) codes decoded
by means of Linear Programming (LP) at moderate and large
Signal-to-Noise-Ratios (SNR). Utilizing a combination of the previously
introduced pseudo-codeword-search method and a new &quot;dendro&quot; trick, which allows
us to reduce the complexity of the LP decoding, we analyze the dependence of
the Frame-Error-Rate (FER) on the SNR. Under Maximum-A-Posteriori (MAP)
decoding the dendro-code, having only checks with connectivity degree three,
performs identically to its original code with high-connectivity checks. For a
number of popular LDPC codes performing over the Additive-White-Gaussian-Noise
(AWGN) channel we found that either an error-floor sets at a relatively low
SNR, or otherwise a transient asymptote, characterized by a faster decay of FER
with the SNR increase, precedes the error-floor asymptote. We explain these
regimes in terms of the pseudo-codeword spectra of the codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701085</identifier>
 <datestamp>2007-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701085</id><created>2007-01-12</created><updated>2007-07-24</updated><authors><author><keyname>Thomas</keyname><forenames>James Harold</forenames></author></authors><title>Variations on the Fibonacci Universal Code</title><categories>cs.IT cs.CR math.IT</categories><abstract>  This note presents variations on the Fibonacci universal code, that may also
be called the Gopala-Hemachandra code, that can have applications in source
coding as well as in cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701086</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701086</id><created>2007-01-12</created><updated>2008-09-09</updated><authors><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames><affiliation>Wayne State</affiliation></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames><affiliation>Los Alamos</affiliation></author></authors><title>Loop Calculus and Belief Propagation for q-ary Alphabet: Loop Tower</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>5 pages, 2 figures, proceedings of ISIT '07, misprints corrected</comments><report-no>LA-UR# 07-0149</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loop Calculus introduced in [Chertkov, Chernyak '06] constitutes a new
theoretical tool that explicitly expresses the symbol Maximum-A-Posteriori
(MAP) solution of a general statistical inference problem via a solution of the
Belief Propagation (BP) equations. This finding brought a new significance to
the BP concept, which in the past was thought of as just a loop-free
approximation. In this paper we continue a discussion of the Loop Calculus. We
introduce an invariant formulation which allows to generalize the Loop Calculus
approach to a q-are alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701087</id><created>2007-01-13</created><updated>2007-04-27</updated><authors><author><keyname>Rennard</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Artificiality in Social Sciences</title><categories>cs.MA</categories><comments>14 pages</comments><acm-class>I.2.11</acm-class><journal-ref>Rennard, J.-P., Artificiality in Social Sciences, in Rennard,
  J.-P. (Ed.), Handbook of Research on Nature Inspired Computing for Economics
  and Management, p.1-15, IGR, 2006</journal-ref><abstract>  This text provides with an introduction to the modern approach of
artificiality and simulation in social sciences. It presents the relationship
between complexity and artificiality, before introducing the field of
artificial societies which greatly benefited from the computer power fast
increase, gifting social sciences with formalization and experimentation tools
previously owned by &quot;hard&quot; sciences alone. It shows that as &quot;a new way of doing
social sciences&quot;, artificial societies should undoubtedly contribute to a
renewed approach in the study of sociality and should play a significant part
in the elaboration of original theories of social phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701088</id><created>2007-01-15</created><updated>2007-03-29</updated><authors><author><keyname>Furtek</keyname><forenames>Frederick</forenames></author></authors><title>A Theory and Calculus for Reasoning about Sequential Behavior</title><categories>cs.LO cs.DM</categories><comments>102 double-spaced pages, 17 figures. Abstract and introduction
  revised 29 March 2007 to improve readability</comments><acm-class>F.4.1; D.2.4; G.2.1</acm-class><abstract>  Basic results in combinatorial mathematics provide the foundation for a
theory and calculus for reasoning about sequential behavior. A key concept of
the theory is a generalization of Boolean implicant which deals with statements
of the form:
  A sequence of Boolean expressions alpha is an implicant of a set of sequences
of Boolean expressions A
  This notion of a generalized implicant takes on special significance when
each of the sequences in the set A describes a disallowed pattern of behavior.
That is because a disallowed sequence of Boolean expressions represents a
logical/temporal dependency, and because the implicants of a set of disallowed
Boolean sequences A are themselves disallowed and represent precisely those
dependencies that follow as a logical consequence from the dependencies
represented by A. The main result of the theory is a necessary and sufficient
condition for a sequence of Boolean expressions to be an implicant of a regular
set of sequences of Boolean expressions. This result is the foundation for two
new proof methods. Sequential resolution is a generalization of Boolean
resolution which allows new logical/temporal dependencies to be inferred from
existing dependencies. Normalization starts with a model (system) and a set of
logical/temporal dependencies and determines which of those dependencies are
satisfied by the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701089</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701089</id><created>2007-01-14</created><updated>2010-04-08</updated><authors><author><keyname>Bienvenu</keyname><forenames>Laurent</forenames></author><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Stephan</keyname><forenames>Frank</forenames></author></authors><title>Constructive Dimension and Turing Degrees</title><categories>cs.CC cs.IT math.IT</categories><comments>The version of this paper appearing in Theory of Computing Systems,
  45(4):740-755, 2009, had an error in the proof of Theorem 2.4, due to
  insufficient care with the choice of delta. This version modifies that proof
  to fix the error.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the constructive Hausdorff and packing dimensions of
Turing degrees. The main result is that every infinite sequence S with
constructive Hausdorff dimension dim_H(S) and constructive packing dimension
dim_P(S) is Turing equivalent to a sequence R with dim_H(R) &lt;= (dim_H(S) /
dim_P(S)) - epsilon, for arbitrary epsilon &gt; 0. Furthermore, if dim_P(S) &gt; 0,
then dim_P(R) &gt;= 1 - epsilon. The reduction thus serves as a *randomness
extractor* that increases the algorithmic randomness of S, as measured by
constructive dimension.
  A number of applications of this result shed new light on the constructive
dimensions of Turing degrees. A lower bound of dim_H(S) / dim_P(S) is shown to
hold for the Turing degree of any sequence S. A new proof is given of a
previously-known zero-one law for the constructive packing dimension of Turing
degrees. It is also shown that, for any regular sequence S (that is, dim_H(S) =
dim_P(S)) such that dim_H(S) &gt; 0, the Turing degree of S has constructive
Hausdorff and packing dimension equal to 1.
  Finally, it is shown that no single Turing reduction can be a universal
constructive Hausdorff dimension extractor, and that bounded Turing reductions
cannot extract constructive Hausdorff dimension. We also exhibit sequences on
which weak truth-table and bounded Turing reductions differ in their ability to
extract dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701090</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701090</id><created>2007-01-15</created><updated>2008-01-03</updated><authors><author><keyname>Mittelbach</keyname><forenames>Martin</forenames><affiliation>Dresden University of Technology</affiliation></author><author><keyname>Mueller</keyname><forenames>Christian</forenames><affiliation>Dresden University of Technology</affiliation></author><author><keyname>Schubert</keyname><forenames>Konrad</forenames><affiliation>Dresden University of Technology</affiliation></author></authors><title>Ergodic Capacity of Discrete- and Continuous-Time, Frequency-Selective
  Rayleigh Fading Channels with Correlated Scattering</title><categories>cs.IT math.IT</categories><comments>- presented at IEEE Globecom 2007 - version v3: substantially revised
  - version v4: correction of minor typing errors</comments><abstract>  We study the ergodic capacity of a frequency-selective Rayleigh fading
channel with correlated scattering, which finds application in the area of UWB.
Under an average power constraint, we consider a single-user, single-antenna
transmission. Coherent reception is assumed with full CSI at the receiver and
no CSI at the transmitter. We distinguish between a continuous- and a
discrete-time channel, modeled either as random process or random vector with
generic covariance. As a practically relevant example, we examine an
exponentially attenuated Ornstein-Uhlenbeck process in detail. Finally, we give
numerical results, discuss the relation between the continuous- and the
discrete-time channel model and show the significant impact of correlated
scattering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701091</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701091</id><created>2007-01-15</created><authors><author><keyname>Savin</keyname><forenames>Valentin</forenames></author></authors><title>Iterative LDPC decoding using neighborhood reliabilities</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures</comments><abstract>  In this paper we study the impact of the processing order of nodes of a
bipartite graph, on the performance of an iterative message-passing decoding.
To this end, we introduce the concept of neighborhood reliabilities of graph's
nodes. Nodes reliabilities are calculated at each iteration and then are used
to obtain a processing order within a serial or serial/parallel scheduling. The
basic idea is that by processing first the most reliable data, the decoder is
reinforced before processing the less reliable one. Using neighborhood
reliabilities, the Min-Sum decoder of LDPC codes approaches the performance of
the Sum-Product decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701092</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701092</id><created>2007-01-15</created><authors><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Sharif</keyname><forenames>Masoud</forenames></author></authors><title>The Multiplexing Gain of MIMO X-Channels with Partial Transmit
  Side-Information</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT 2007</comments><abstract>  In this paper, we obtain the scaling laws of the sum-rate capacity of a MIMO
X-channel, a 2 independent sender, 2 independent receiver channel with messages
from each transmitter to each receiver, at high signal to noise ratios (SNR).
The X-channel has sparked recent interest in the context of cooperative
networks and it encompasses the interference, multiple access, and broadcast
channels as special cases. Here, we consider the case with partially
cooperative transmitters in which only partial and asymmetric side-information
is available at one of the transmitters. It is proved that when there are M
antennas at all four nodes, the sum-rate scales like 2Mlog(SNR) which is in
sharp contrast to [\lfloor 4M/3 \rfloor,4M/3]log(SNR) for non-cooperative
X-channels \cite{maddah-ali,jafar_degrees}. This further proves that, in terms
of sum-rate scaling at high SNR, partial side-information at one of the
transmitters and full side-information at both transmitters are equivalent in
the MIMO X-channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701093</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701093</id><created>2007-01-15</created><authors><author><keyname>Ebrahimi</keyname><forenames>Masoud</forenames></author><author><keyname>Maddah-Ali</keyname><forenames>Mohammad</forenames></author><author><keyname>Khandani</keyname><forenames>Amir</forenames></author></authors><title>Throughput Scaling Laws for Wireless Networks with Fading Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE ISIT 2007</comments><abstract>  A network of $n$ wireless communication links is considered. Fading is
assumed to be the dominant factor affecting the strength of the channels
between nodes. The objective is to analyze the achievable throughput of the
network when power allocation is allowed. By proposing a decentralized on-off
power allocation strategy, a lower bound on the achievable throughput is
obtained for a general fading model. In particular, under Rayleigh fading
conditions the achieved sum-rate is of order $\log n$, which is, by a constant
factor, larger than what is obtained with a centralized scheme in the work of
Gowaikar et al. Similar to most of previous works on large networks, the
proposed scheme assigns a vanishingly small rate for each link. However, it is
shown that by allowing the sum-rate to decrease by a factor $\alpha&lt;1$, this
scheme is capable of providing non-zero rate-per-links of order $\Theta(1)$. To
obtain larger non-zero rate-per-links, the proposed scheme is modified to a
centralized version. It turns out that for the same number of active links the
centralized scheme achieves a much larger rate-per-link. Moreover, at large
values of rate-per-link, it achieves a sum-rate close to $\log n$, i.e., the
maximum achieved by the decentralized scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701094</id><created>2007-01-16</created><authors><author><keyname>Ingelrest</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIFL, INRIA Futurs</affiliation></author><author><keyname>Simplot-Ryl</keyname><forenames>David</forenames><affiliation>LIFL, INRIA Futurs</affiliation></author></authors><title>Maximizing the Probability of Delivery of Multipoint Relay Broadcast
  Protocol in Wireless Ad Hoc Networks with a Realistic Physical Layer</title><categories>cs.NI</categories><proxy>ccsd hal-00124728</proxy><journal-ref>Proceedings of the 2nd International Conference on Mobile Ad-hoc
  and Sensor Networks (MSN 2006) (2006) 143</journal-ref><abstract>  It is now commonly accepted that the unit disk graph used to model the
physical layer in wireless networks does not reflect real radio transmissions,
and that the lognormal shadowing model better suits to experimental
simulations. Previous work on realistic scenarios focused on unicast, while
broadcast requirements are fundamentally different and cannot be derived from
unicast case. Therefore, broadcast protocols must be adapted in order to still
be efficient under realistic assumptions. In this paper, we study the
well-known multipoint relay protocol (MPR). In the latter, each node has to
choose a set of neighbors to act as relays in order to cover the whole 2-hop
neighborhood. We give experimental results showing that the original method
provided to select the set of relays does not give good results with the
realistic model. We also provide three new heuristics in replacement and their
performances which demonstrate that they better suit to the considered model.
The first one maximizes the probability of correct reception between the node
and the considered relays multiplied by their coverage in the 2-hop
neighborhood. The second one replaces the coverage by the average of the
probabilities of correct reception between the considered neighbor and the
2-hop neighbors it covers. Finally, the third heuristic keeps the same concept
as the second one, but tries to maximize the coverage level of the 2-hop
neighborhood: 2-hop neighbors are still being considered as uncovered while
their coverage level is not higher than a given coverage threshold, many
neighbors may thus be selected to cover the same 2-hop neighbors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701095</id><created>2007-01-16</created><authors><author><keyname>Cabalar</keyname><forenames>Pedro</forenames></author><author><keyname>Ferraris</keyname><forenames>Paolo</forenames></author></authors><title>Propositional theories are strongly equivalent to logic programs</title><categories>cs.AI cs.LO</categories><comments>15 pages</comments><abstract>  This paper presents a property of propositional theories under the answer
sets semantics (called Equilibrium Logic for this general syntax): any theory
can always be reexpressed as a strongly equivalent disjunctive logic program,
possibly with negation in the head. We provide two different proofs for this
result: one involving a syntactic transformation, and one that constructs a
program starting from the countermodels of the theory in the intermediate logic
of here-and-there.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701096</id><created>2007-01-16</created><updated>2007-01-22</updated><authors><author><keyname>Maurice</keyname><forenames>Margenstern</forenames></author></authors><title>About the domino problem in the hyperbolic plane, a new solution</title><categories>cs.CG</categories><comments>60 pages, 16 figures</comments><acm-class>F.2.2</acm-class><abstract>  In this paper we improve the approach of a previous paper about the domino
problem in the hyperbolic plane, see arXiv.cs.CG/0603093. This time, we prove
that the general problem of the hyperbolic plane with \`a la Wang tiles is
undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701097</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701097</id><created>2007-01-16</created><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>MacWilliams Identity for the Rank Metric</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE ISIT 2007</comments><abstract>  This paper investigates the relationship between the rank weight distribution
of a linear code and that of its dual code. The main result of this paper is
that, similar to the MacWilliams identity for the Hamming metric, the rank
weight distribution of any linear code can be expressed as an analytical
expression of that of its dual code. Remarkably, our new identity has a similar
form to the MacWilliams identity for the Hamming metric. Our new identity
provides a significant analytical tool to the rank weight distribution analysis
of linear codes. We use a linear space based approach in the proof for our new
identity, and adapt this approach to provide an alternative proof of the
MacWilliams identity for the Hamming metric. Finally, we determine the
relationship between moments of the rank distribution of a linear code and
those of its dual code, and provide an alternative derivation of the rank
weight distribution of maximum rank distance codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701098</identifier>
 <datestamp>2008-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701098</id><created>2007-01-16</created><updated>2008-05-07</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Packing and Covering Properties of Rank Metric Codes</title><categories>cs.IT math.IT</categories><comments>23 pages, 1 table. Submitted to IEEE Transactions on Information
  Theory</comments><abstract>  This paper investigates packing and covering properties of codes with the
rank metric. First, we investigate packing properties of rank metric codes.
Then, we study sphere covering properties of rank metric codes, derive bounds
on their parameters, and investigate their asymptotic covering properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701099</id><created>2007-01-16</created><authors><author><keyname>Yang</keyname><forenames>Shaohua</forenames></author><author><keyname>Kavcic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>On the Feedback Capacity of Power Constrained Gaussian Noise Channels
  with Memory</title><categories>cs.IT math.IT</categories><comments>Transaction on Information Theory, accepted version, first version
  submitted on Oct 22, 2003</comments><abstract>  For a stationary additive Gaussian-noise channel with a rational noise power
spectrum of a finite-order $L$, we derive two new results for the feedback
capacity under an average channel input power constraint. First, we show that a
very simple feedback-dependent Gauss-Markov source achieves the feedback
capacity, and that Kalman-Bucy filtering is optimal for processing the
feedback. Based on these results, we develop a new method for optimizing the
channel inputs for achieving the Cover-Pombra block-length-$n$ feedback
capacity by using a dynamic programming approach that decomposes the
computation into $n$ sequentially identical optimization problems where each
stage involves optimizing $O(L^2)$ variables. Second, we derive the explicit
maximal information rate for stationary feedback-dependent sources. In general,
evaluating the maximal information rate for stationary sources requires solving
only a few equations by simple non-linear programming. For first-order
autoregressive and/or moving average (ARMA) noise channels, this optimization
admits a closed form maximal information rate formula. The maximal information
rate for stationary sources is a lower bound on the feedback capacity, and it
equals the feedback capacity if the long-standing conjecture, that stationary
sources achieve the feedback capacity, holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701100</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701100</id><created>2007-01-16</created><authors><author><keyname>Yang</keyname><forenames>Shaohua</forenames></author><author><keyname>Kavcic</keyname><forenames>Aleksandar</forenames></author></authors><title>Delayed Feedback Capacity of Stationary Sources over Linear Gaussian
  Noise Channels</title><categories>cs.IT math.IT</categories><comments>submitted to ISIT 2007</comments><abstract>  We consider a linear Gaussian noise channel used with delayed feedback. The
channel noise is assumed to be a ARMA (autoregressive and/or moving average)
process. We reformulate the Gaussian noise channel into an intersymbol
interference channel with white noise, and show that the delayed-feedback of
the original channel is equivalent to the instantaneous-feedback of the derived
channel. By generalizing results previously developed for Gaussian channels
with instantaneous feedback and applying them to the derived intersymbol
interference channel, we show that conditioned on the delayed feedback, a
conditional Gauss-Markov source achieves the feedback capacity and its Markov
memory length is determined by the noise spectral order and the feedback delay.
A Kalman-Bucy filter is shown to be optimal for processing the feedback. The
maximal information rate for stationary sources is derived in terms of channel
input power constraint and the steady state solution of the Riccati equation of
the Kalman-Bucy filter used in the feedback loop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701101</id><created>2007-01-16</created><authors><author><keyname>Davis</keyname><forenames>Philip M.</forenames></author></authors><title>Citation advantage of Open Access articles likely explained by quality
  differential and media effects</title><categories>cs.DL cs.GL</categories><comments>Letter to the editor of PLoS Biology
  http://biology.plosjournals.org/perlserv/?request=read-response&amp;doi=10.1371/journal.pbio.0040157#r1438</comments><abstract>  In a study of articles published in the Proceedings of the National Academy
of Sciences, Gunther Eysenbach discovered a significant citation advantage for
those articles made freely-available upon publication (Eysenbach 2006). While
the author attempted to control for confounding factors that may have explained
the citation differential, the study was unable to control for characteristics
of the article that may have led some authors to pay the additional page
charges ($1,000) for immediate OA status. OA articles published in PNAS were
more than twice as likely to be featured on the front cover of the journal
(3.3% vs. 1.4%), nearly twice as likely to be picked up by the media (15% vs.
8%) and when cited reached, on average, nearly twice as many news outlets as
subscription-based articles (4.2 vs. 2.6). The citation advantage of Open
Access articles in PNAS may likely be explained by a quality differential and
the amplification of media effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701102</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701102</id><created>2007-01-16</created><updated>2011-08-30</updated><authors><author><keyname>Schipani</keyname><forenames>Davide</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Coding Solutions for the Secure Biometric Storage Problem</title><categories>cs.IT cs.CR math.IT</categories><comments>the final version appeared in Proceedings Information Theory Workshop
  (ITW) 2010, IEEE copyright</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the problem of securely storing biometric passwords, such
as fingerprints and irises. With the help of coding theory Juels and Wattenberg
derived in 1999 a scheme where similar input strings will be accepted as the
same biometric. In the same time nothing could be learned from the stored data.
They called their scheme a &quot;fuzzy commitment scheme&quot;. In this paper we will
revisit the solution of Juels and Wattenberg and we will provide answers to two
important questions: What type of error-correcting codes should be used and
what happens if biometric templates are not uniformly distributed, i.e. the
biometric data come with redundancy. Answering the first question will lead us
to the search for low-rate large-minimum distance error-correcting codes which
come with efficient decoding algorithms up to the designed distance. In order
to answer the second question we relate the rate required with a quantity
connected to the &quot;entropy&quot; of the string, trying to estimate a sort of
&quot;capacity&quot;, if we want to see a flavor of the converse of Shannon's noisy
coding theorem. Finally we deal with side-problems arising in a practical
implementation and we propose a possible solution to the main one that seems to
have so far prevented real life applications of the fuzzy scheme, as far as we
know.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701103</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701103</id><created>2007-01-17</created><authors><author><keyname>Venkiah</keyname><forenames>Auguste</forenames></author><author><keyname>Poulliat</keyname><forenames>Charly</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author></authors><title>Analysis and design of raptor codes for joint decoding using Information
  Content evolution</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to ISIT 2007</comments><abstract>  In this paper, we present an analytical analysis of the convergence of raptor
codes under joint decoding over the binary input additive white noise channel
(BIAWGNC), and derive an optimization method. We use Information Content
evolution under Gaussian approximation, and focus on a new decoding scheme that
proves to be more efficient: the joint decoding of the two code components of
the raptor code. In our general model, the classical tandem decoding scheme
appears to be a subcase, and thus, the design of LT codes is also possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701104</id><created>2007-01-17</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Umstaetter</keyname><forenames>Walther</forenames></author></authors><title>Why is a new Journal of Informetrics needed?</title><categories>cs.DL cs.DB</categories><comments>9 pages, 3 figures</comments><abstract>  In our study we analysed 3.889 records which were indexed in the Library and
Information Science Abstracts (LISA) database in the research field of
informetrics. We can show the core journals of the field via a Bradford (power
law) distribution and corroborate on the basis of the restricted LISA data set
that it was the appropriate time to found a new specialized journal dedicated
to informetrics. According to Bradford's Law of scattering (pure quantitative
calculation), Egghe's Journal of Informetrics (JOI) first issue to appear in
2007, comes most probable at the right time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701105</id><created>2007-01-17</created><authors><author><keyname>Troncon</keyname><forenames>Remko</forenames></author><author><keyname>Janssens</keyname><forenames>Gerda</forenames></author></authors><title>A Delta Debugger for ILP Query Execution</title><categories>cs.PL cs.LG</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments (WLPE2006)</comments><abstract>  Because query execution is the most crucial part of Inductive Logic
Programming (ILP) algorithms, a lot of effort is invested in developing faster
execution mechanisms. These execution mechanisms typically have a low-level
implementation, making them hard to debug. Moreover, other factors such as the
complexity of the problems handled by ILP algorithms and size of the code base
of ILP data mining systems make debugging at this level a very difficult job.
In this work, we present the trace-based debugging approach currently used in
the development of new execution mechanisms in hipP, the engine underlying the
ACE Data Mining system. This debugger uses the delta debugging algorithm to
automatically reduce the total time needed to expose bugs in ILP execution,
thus making manual debugging step much lighter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701106</id><created>2007-01-17</created><authors><author><keyname>Deransart</keyname><forenames>Pierre</forenames></author></authors><title>On using Tracer Driver for External Dynamic Process Observation</title><categories>cs.PL</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments</comments><abstract>  One is interested here in the observation of dynamic processes starting from
the traces which they leave or those that one makes them produce. It is
considered here that it should be possible to make several observations
simultaneously, using a large variety of independently developed analyzers. For
this purpose, we introduce the original notion of ``full trace'' to capture the
idea that a process can be instrumented in such a way that it may broadcast all
information which could ever be requested by any kind of observer. Each
analyzer can then find in the full trace the data elements which it needs. This
approach uses what has been called a &quot;tracer driver&quot; which completes the tracer
and drives it to answer the requests of the analyzers. A tracer driver allows
to restrict the flow of information and makes this approach tractable. On the
other side, the potential size of a full trace seems to make the idea of full
trace unrealistic. In this work we explore the consequences of this notion in
term of potential efficiency, by analyzing the respective workloads between the
(full) tracer and many different analyzers, all being likely run in true
parallel environments. To illustrate this study, we use the example of the
observation of the resolution of constraints systems (proof-tree, search-tree
and propagation) using sophisticated visualization tools, as developed in the
project OADymPPaC (2001-2004). The processes considered here are computer
programs, but we believe the approach can be extended to many other kinds of
processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701107</id><created>2007-01-17</created><authors><author><keyname>Girgis</keyname><forenames>Hani</forenames></author><author><keyname>Jayaraman</keyname><forenames>Bharat</forenames></author></authors><title>JavaTA: A Logic-based Debugger for Java</title><categories>cs.PL</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments (WLPE2006)</comments><abstract>  This paper presents a logic based approach to debugging Java programs. In
contrast with traditional debugging we propose a debugging methodology for Java
programs using logical queries on individual execution states and also over the
history of execution. These queries were arrived at by a systematic study of
errors in object-oriented programs in our earlier research. We represent the
salient events during the execution of a Java program by a logic database, and
implement the queries as logic programs. Such an approach allows us to answer a
number of useful and interesting queries about a Java program, such as the
calling sequence that results in a certain outcome, the state of an object at a
particular execution point, etc. Our system also provides the ability to
compose new queries during a debugging session. We believe that logic
programming offers a significant contribution to the art of object-oriented
programs debugging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701108</id><created>2007-01-17</created><authors><author><keyname>Mera</keyname><forenames>Edison</forenames></author><author><keyname>Lopez-Garcia</keyname><forenames>Pedro</forenames></author><author><keyname>Puebla</keyname><forenames>German</forenames></author><author><keyname>Carro</keyname><forenames>Manuel</forenames></author><author><keyname>Hermenegildo</keyname><forenames>Manuel</forenames></author></authors><title>Towards Execution Time Estimation for Logic Programs via Static Analysis
  and Profiling</title><categories>cs.PL</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments</comments><abstract>  Effective static analyses have been proposed which infer bounds on the number
of resolutions or reductions. These have the advantage of being independent
from the platform on which the programs are executed and have been shown to be
useful in a number of applications, such as granularity control in parallel
execution. On the other hand, in distributed computation scenarios where
platforms with different capabilities come into play, it is necessary to
express costs in metrics that include the characteristics of the platform. In
particular, it is specially interesting to be able to infer upper and lower
bounds on actual execution times. With this objective in mind, we propose an
approach which combines compile-time analysis for cost bounds with a one-time
profiling of the platform in order to determine the values of certain
parameters for a given platform. These parameters calibrate a cost model which,
from then on, is able to compute statically time bound functions for procedures
and to predict with a significant degree of accuracy the execution times of
such procedures in the given platform. The approach has been implemented and
integrated in the CiaoPP system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701109</id><created>2007-01-17</created><authors><author><keyname>Chitnis</keyname><forenames>Siddharth</forenames></author><author><keyname>Yennamani</keyname><forenames>Madhu</forenames></author><author><keyname>Gupta</keyname><forenames>Gopal</forenames></author></authors><title>ExSched: Solving Constraint Satisfaction Problems with the Spreadsheet
  Paradigm</title><categories>cs.PL</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments (WLPE2006)</comments><abstract>  We report on the development of a general tool called ExSched, implemented as
a plug-in for Microsoft Excel, for solving a class of constraint satisfaction
problems. The traditional spreadsheet paradigm is based on attaching arithmetic
expressions to individual cells and then evaluating them. The ExSched interface
generalizes the spreadsheet paradigm to allow finite domain constraints to be
attached to the individual cells that are then solved to get a solution. This
extension provides a user-friendly interface for solving constraint
satisfaction problems that can be modeled as 2D tables, such as scheduling
problems, timetabling problems, product configuration, etc. ExSched can be
regarded as a spreadsheet interface to CLP(FD) that hides the syntactic and
semantic complexity of CLP(FD) and enables novice users to solve many
scheduling and timetabling problems interactively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701110</id><created>2007-01-17</created><authors><author><keyname>Henriksen</keyname><forenames>Kim</forenames></author><author><keyname>Gallagher</keyname><forenames>John</forenames></author></authors><title>A Web-based Tool Combining Different Type Analyses</title><categories>cs.PL</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments (WLPE2006)</comments><abstract>  There are various kinds of type analysis of logic programs. These include for
example inference of types that describe an over-approximation of the success
set of a program, inference of well-typings, and abstractions based on given
types. Analyses can be descriptive or prescriptive or a mixture of both, and
they can be goal-dependent or goal-independent. We describe a prototype tool
that can be accessed from a web browser, allowing various type analyses to be
run. The first goal of the tool is to allow the analysis results to be examined
conveniently by clicking on points in the original program clauses, and to
highlight ill-typed program constructs, empty types or other type anomalies.
Secondly the tool allows combination of the various styles of analysis. For
example, a descriptive regular type can be automatically inferred for a given
program, and then that type can be used to generate the minimal &quot;domain model&quot;
of the program with respect to the corresponding pre-interpretation, which can
give more precise information than the original descriptive type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701111</id><created>2007-01-17</created><authors><author><keyname>Albert</keyname><forenames>Elvira</forenames></author><author><keyname>Arenas</keyname><forenames>Puri</forenames></author><author><keyname>Puebla</keyname><forenames>German</forenames></author></authors><title>Some Issues on Incremental Abstraction-Carrying Code</title><categories>cs.PL</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments (WLPE2006)</comments><abstract>  Abstraction-Carrying Code (ACC) has recently been proposed as a framework for
proof-carrying code (PCC) in which the code supplier provides a program
together with an abstraction (or abstract model of the program) whose validity
entails compliance with a predefined safety policy. The abstraction thus plays
the role of safety certificate and its generation (and validation) is carried
out automatically by a fixed-point analyzer. Existing approaches for PCC are
developed under the assumption that the consumer reads and validates the entire
program w.r.t. the full certificate at once, in a non incremental way. In this
abstract, we overview the main issues on incremental ACC. In particular, in the
context of logic programming, we discuss both the generation of incremental
certificates and the design of an incremental checking algorithm for untrusted
updates of a (trusted) program, i.e., when a producer provides a modified
version of a previously validated program. By update, we refer to any arbitrary
change on a program, i.e., the extension of the program with new predicates,
the deletion of existing predicates and the replacement of existing predicates
by new versions for them. We also discuss how each kind of update affects the
incremental extension in terms of accuracy and correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701112</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701112</id><created>2007-01-17</created><authors><author><keyname>Kohnert</keyname><forenames>Axel</forenames></author></authors><title>(l,s)-Extension of Linear Codes</title><categories>cs.IT math.CO math.IT</categories><comments>8 pages</comments><acm-class>E.4</acm-class><abstract>  We construct new linear codes with high minimum distance d. In at least 12
cases these codes improve the minimum distance of the previously known best
linear codes for fixed parameters n,k. Among these new codes there is an
optimal ternary [88,8,54] code.
  We develop an algorithm, which starts with already good codes C, i.e. codes
with high minimum distance d for given length n and dimension k over the field
GF(q). The algorithm is based on the newly defined (l,s)-extension. This is a
generalization of the well-known method of adding a parity bit in the case of a
binary linear code of odd minimum weight. (l,s)-extension tries to extend the
generator matrix of C by adding l columns with the property that at least s of
the l letters added to each of the codewords of minimum weight in C are
different from 0. If one finds such columns the minimum distance of the
extended code is d+s provided that the second smallest weight in C was at least
d+s. The question whether such columns exist can be settled using a Diophantine
system of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701113</id><created>2007-01-17</created><authors><author><keyname>Colcombet</keyname><forenames>Thomas</forenames><affiliation>GALION</affiliation></author></authors><title>On factorisation forests</title><categories>cs.LO</categories><comments>27 pages</comments><proxy>ccsd hal-00125047</proxy><acm-class>F.4</acm-class><abstract>  The theorem of factorisation forests shows the existence of nested
factorisations -- a la Ramsey -- for finite words. This theorem has important
applications in semigroup theory, and beyond. The purpose of this paper is to
illustrate the importance of this approach in the context of automata over
infinite words and trees. We extend the theorem of factorisation forest in two
directions: we show that it is still valid for any word indexed by a linear
ordering; and we show that it admits a deterministic variant for words indexed
by well-orderings. A byproduct of this work is also an improvement on the known
bounds for the original result. We apply the first variant for giving a
simplified proof of the closure under complementation of rational sets of words
indexed by countable scattered linear orderings. We apply the second variant in
the analysis of monadic second-order logic over trees, yielding new results on
monadic interpretations over trees. Consequences of it are new caracterisations
of prefix-recognizable structures and of the Caucal hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701114</identifier>
 <datestamp>2011-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701114</id><created>2007-01-17</created><updated>2007-03-15</updated><authors><author><keyname>Vega-Paez</keyname><forenames>Ignacio</forenames></author><author><keyname>Pulido</keyname><forenames>Georgina G.</forenames></author><author><keyname>Ortega</keyname><forenames>Jose Angel</forenames></author></authors><title>The problem determination of Functional Dependencies between attributes
  Relation Scheme in the Relational Data Model. El problema de determinar
  Dependencias Funcionales entre atributos en los esquemas en el Modelo
  Relacional</title><categories>cs.DB cs.DS</categories><report-no>IBP-Memo 2006 07, Sep 2006</report-no><journal-ref>International Journal of Multidisciplinary Sciences and
  Engineering, Vol. 2, No. 5, 2011, 1-4</journal-ref><abstract>  An alternative definition of the concept is given of functional dependence
among the attributes of the relational schema in the Relational Model, this
definition is obtained in terms of the set theory. For that which a theorem is
demonstrated that establishes equivalence and on the basis theorem an algorithm
is built for the search of the functional dependences among the attributes. The
algorithm is illustrated by a concrete example
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701115</id><created>2007-01-18</created><authors><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author><author><keyname>Mora-Garcia</keyname><forenames>Antonio</forenames></author><author><keyname>Laredo</keyname><forenames>J. L. J.</forenames></author><author><keyname>Lupion</keyname><forenames>Juan</forenames></author><author><keyname>Tricas</keyname><forenames>Fernando</forenames></author></authors><title>Browser-based distributed evolutionary computation: performance and
  scaling behavior</title><categories>cs.DC cs.NE</categories><comments>Submitted to GECCO 2007</comments><abstract>  The challenge of ad-hoc computing is to find the way of taking advantage of
spare cycles in an efficient way that takes into account all capabilities of
the devices and interconnections available to them. In this paper we explore
distributed evolutionary computation based on the Ruby on Rails framework,
which overlays a Model-View-Controller on evolutionary computation. It allows
anybody with a web browser (that is, mostly everybody connected to the
Internet) to participate in an evolutionary computation experiment. Using a
straightforward farming model, we consider different factors, such as the size
of the population used. We are mostly interested in how they impact on
performance, but also the scaling behavior when a non-trivial number of
computers is applied to the problem. Experiments show the impact of different
packet sizes on performance, as well as a quite limited scaling behavior, due
to the characteristics of the server. Several solutions for that problem are
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701116</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701116</id><created>2007-01-18</created><updated>2008-11-01</updated><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>The Impact of CSI and Power Allocation on Relay Channel Capacity and
  Cooperation Strategies</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Wireless
  Communications</comments><journal-ref>IEEE Trans. Wireless Commun., vol. 7, no. 12, pp. 5380-5389, Dec.
  2008</journal-ref><doi>10.1109/T-WC.2008.071185</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capacity gains from transmitter and receiver cooperation are compared in a
relay network where the cooperating nodes are close together. Under
quasi-static phase fading, when all nodes have equal average transmit power
along with full channel state information (CSI), it is shown that transmitter
cooperation outperforms receiver cooperation, whereas the opposite is true when
power is optimally allocated among the cooperating nodes but only CSI at the
receiver (CSIR) is available. When the nodes have equal power with CSIR only,
cooperative schemes are shown to offer no capacity improvement over
non-cooperation under the same network power constraint. When the system is
under optimal power allocation with full CSI, the decode-and-forward
transmitter cooperation rate is close to its cut-set capacity upper bound, and
outperforms compress-and-forward receiver cooperation. Under fast Rayleigh
fading in the high SNR regime, similar conclusions follow. Cooperative systems
provide resilience to fading in channel magnitudes; however, capacity becomes
more sensitive to power allocation, and the cooperating nodes need to be closer
together for the decode-and-forward scheme to be capacity-achieving. Moreover,
to realize capacity improvement, full CSI is necessary in transmitter
cooperation, while in receiver cooperation optimal power allocation is
essential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701117</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701117</id><created>2007-01-18</created><updated>2007-06-12</updated><authors><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author></authors><title>Maximum Entropy in the framework of Algebraic Statistics: A First Step</title><categories>cs.IT cs.SC math.IT</categories><abstract>  Algebraic statistics is a recently evolving field, where one would treat
statistical models as algebraic objects and thereby use tools from
computational commutative algebra and algebraic geometry in the analysis and
computation of statistical models. In this approach, calculation of parameters
of statistical models amounts to solving set of polynomial equations in several
variables, for which one can use celebrated Grobner bases theory. Owing to the
important role of information theory in statistics, this paper as a first step,
explores the possibility of describing maximum and minimum entropy (ME) models
in the framework of algebraic statistics. We show that ME-models are toric
models (a class of algebraic statistical models) when the constraint functions
(that provide the information about the underlying random variable) are integer
valued functions, and the set of statistical models that results from
ME-methods are indeed an affine variety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701118</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701118</id><created>2007-01-18</created><authors><author><keyname>Maddah-Ali</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Mahdavi-Doost</keyname><forenames>Hajar</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Optimal Order of Decoding for Max-Min Fairness in $K$-User Memoryless
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>11 Pages, Submitted to IEEE International Symposium on Information
  Theory(ISIT 2007)</comments><abstract>  A $K$-user memoryless interference channel is considered where each receiver
sequentially decodes the data of a subset of transmitters before it decodes the
data of the designated transmitter. Therefore, the data rate of each
transmitter depends on (i) the subset of receivers which decode the data of
that transmitter, (ii) the decoding order, employed at each of these receivers.
In this paper, a greedy algorithm is developed to find the users which are
decoded at each receiver and the corresponding decoding order such that the
minimum rate of the users is maximized. It is proven that the proposed
algorithm is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701119</id><created>2007-01-19</created><authors><author><keyname>Ivankov</keyname><forenames>Petr R.</forenames></author><author><keyname>Ivankov</keyname><forenames>Nikolay P.</forenames></author></authors><title>The framework for simulation of dynamics of mechanical aggregates</title><categories>cs.CE</categories><comments>7 pages, 4 figures</comments><acm-class>J.9</acm-class><abstract>  A framework for simulation of dynamics of mechanical aggregates has been
developed. This framework enables us to build model of aggregate from models of
its parts. Framework is a part of universal framework for science and
engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701120</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701120</id><created>2007-01-19</created><authors><author><keyname>Chernov</keyname><forenames>A.</forenames></author><author><keyname>Hutter</keyname><forenames>M.</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J.</forenames></author></authors><title>Algorithmic Complexity Bounds on Future Prediction Errors</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>21 pages</comments><journal-ref>Information and Computation, Vol.205,Nr.2 (2007) 242-261</journal-ref><doi>10.1016/j.ic.2006.10.004</doi><abstract>  We bound the future loss when predicting any (computably) stochastic sequence
online. Solomonoff finitely bounded the total deviation of his universal
predictor $M$ from the true distribution $mu$ by the algorithmic complexity of
$mu$. Here we assume we are at a time $t&gt;1$ and already observed $x=x_1...x_t$.
We bound the future prediction performance on $x_{t+1}x_{t+2}...$ by a new
variant of algorithmic complexity of $mu$ given $x$, plus the complexity of the
randomness deficiency of $x$. The new complexity is monotone in its condition
in the sense that this complexity can only decrease if the condition is
prolonged. We also briefly discuss potential generalizations to Bayesian model
classes and to classification problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701121</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701121</id><created>2007-01-19</created><authors><author><keyname>Tu</keyname><forenames>Changhe</forenames><affiliation>Shandong University</affiliation></author><author><keyname>Wang</keyname><forenames>Wenping</forenames><affiliation>University of Hong Kong</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Wang</keyname><forenames>Jiaye</forenames><affiliation>Shandong University</affiliation></author></authors><title>Signature Sequence of Intersection Curve of Two Quadrics for Exact
  Morphological Classification</title><categories>cs.CG cs.SC</categories><proxy>ccsd hal-00123473</proxy><abstract>  We present an efficient method for classifying the morphology of the
intersection curve of two quadrics (QSIC) in PR3, 3D real projective space;
here, the term morphology is used in a broad sense to mean the shape,
topological, and algebraic properties of a QSIC, including singularity,
reducibility, the number of connected components, and the degree of each
irreducible component, etc. There are in total 35 different QSIC morphologies
with non-degenerate quadric pencils. For each of these 35 QSIC morphologies,
through a detailed study of the eigenvalue curve and the index function jump we
establish a characterizing algebraic condition expressed in terms of the Segre
characteristics and the signature sequence of a quadric pencil. We show how to
compute a signature sequence with rational arithmetic so as to determine the
morphology of the intersection curve of any two given quadrics. Two immediate
applications of our results are the robust topological classification of QSIC
in computing B-rep surface representation in solid modeling and the derivation
of algebraic conditions for collision detection of quadric primitives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701122</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701122</id><created>2007-01-19</created><updated>2008-04-11</updated><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames></author><author><keyname>Hill</keyname><forenames>Patricia M.</forenames></author><author><keyname>Zaffanella</keyname><forenames>Enea</forenames></author></authors><title>Applications of Polyhedral Computations to the Analysis and Verification
  of Hardware and Software Systems</title><categories>cs.CG cs.MS</categories><comments>51 pages, 11 figures</comments><acm-class>D.2.4; F.3.1</acm-class><abstract>  Convex polyhedra are the basis for several abstractions used in static
analysis and computer-aided verification of complex and sometimes mission
critical systems. For such applications, the identification of an appropriate
complexity-precision trade-off is a particularly acute problem, so that the
availability of a wide spectrum of alternative solutions is mandatory. We
survey the range of applications of polyhedral computations in this area; give
an overview of the different classes of polyhedra that may be adopted; outline
the main polyhedral operations required by automatic analyzers and verifiers;
and look at some possible combinations of polyhedra with other numerical
abstractions that have the potential to improve the precision of the analysis.
Areas where further theoretical investigations can result in important
contributions are highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701123</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701123</id><created>2007-01-19</created><updated>2007-04-11</updated><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>Feasible Depth</title><categories>cs.CC cs.IT math.IT</categories><comments>Accepted to Computation and Logic in the Real World, Proceedings of
  the 3rd Conference on Computability in Europe (CiE), 2007</comments><abstract>  This paper introduces two complexity-theoretic formulations of Bennett's
logical depth: finite-state depth and polynomial-time depth. It is shown that
for both formulations, trivial and random infinite sequences are shallow, and a
slow growth law holds, implying that deep sequences cannot be created easily
from shallow sequences. Furthermore, the E analogue of the halting language is
shown to be polynomial-time deep, by proving a more general result: every
language to which a nonnegligible subset of E can be reduced in uniform
exponential time is polynomial-time deep.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701124</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701124</id><created>2007-01-19</created><authors><author><keyname>Ye</keyname><forenames>Chunxuan</forenames></author><author><keyname>Reznik</keyname><forenames>Alex</forenames></author></authors><title>Group Secret Key Generation Algorithms</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to 2007 IEEE International Symposium on Information Theory</comments><abstract>  We consider a pair-wise independent network where every pair of terminals in
the network observes a common pair-wise source that is independent of all the
sources accessible to the other pairs. We propose a method for secret key
agreement in such a network that is based on well-established point-to-point
techniques and repeated application of the one-time pad. Three specific
problems are investigated. 1) Each terminal's observations are correlated only
with the observations of a central terminal. All these terminals wish to
generate a common secret key. 2) In a pair-wise independent network, two
designated terminals wish to generate a secret key with the help of other
terminals. 3) All the terminals in a pair-wise independent network wish to
generate a common secret key. A separate protocol for each of these problems is
proposed. Furthermore, we show that the protocols for the first two problems
are optimal and the protocol for the third problem is efficient, in terms of
the resulting secret key rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701125</id><created>2007-01-19</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Universal Algorithmic Intelligence: A mathematical top-&gt;down approach</title><categories>cs.AI cs.LG</categories><comments>70 pages</comments><report-no>IDSIA-01-03</report-no><journal-ref>In Artificial General Intelligence, Springer (2007) 227-290</journal-ref><abstract>  Sequential decision theory formally solves the problem of rational agents in
uncertain worlds if the true environmental prior probability distribution is
known. Solomonoff's theory of universal induction formally solves the problem
of sequence prediction for unknown prior distribution. We combine both ideas
and get a parameter-free theory of universal Artificial Intelligence. We give
strong arguments that the resulting AIXI model is the most intelligent unbiased
agent possible. We outline how the AIXI model can formally solve a number of
problem classes, including sequence prediction, strategic games, function
minimization, reinforcement and supervised learning. The major drawback of the
AIXI model is that it is uncomputable. To overcome this problem, we construct a
modified algorithm AIXItl that is still effectively more intelligent than any
other time t and length l bounded agent. The computation time of AIXItl is of
the order t x 2^l. The discussion includes formal definitions of intelligence
order relations, the horizon problem and relations of the AIXI theory to other
AI approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701126</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701126</id><created>2007-01-19</created><authors><author><keyname>Chuang</keyname><forenames>Allen</forenames></author><author><keyname>Fabregas</keyname><forenames>Albert Guillen i</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Optimal Throughput-Diversity-Delay Tradeoff in MIMO ARQ Block-Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>51 pages, 15 figures. Submitted to IEEE Transactions on Information
  Theory</comments><abstract>  In this paper, we consider an automatic-repeat-request (ARQ) retransmission
protocol signaling over a block-fading multiple-input, multiple-output (MIMO)
channel. Unlike previous work, we allow for multiple fading blocks within each
transmission (ARQ round), and we constrain the transmitter to fixed rate codes
constructed over complex signal constellations. In particular, we examine the
general case of average input-power-constrained constellations as well as the
practically important case of finite discrete constellations. This scenario is
a suitable model for practical wireless communications systems employing
orthogonal frequency division multiplexing techniques over a MIMO ARQ channel.
Two cases of fading dynamics are considered, namely short-term static fading
where channel fading gains change randomly for each ARQ round, and long-term
static fading where channel fading gains remain constant over all ARQ rounds
pertaining to a given message. As our main result, we prove that for the
block-fading MIMO ARQ channel with discrete input signal constellation
satisfying a short-term power constraint, the optimal signal-to-noise ratio
(SNR) exponent is given by a modified Singleton bound, relating all the system
parameters. To demonstrate the practical significance of the theoretical
analysis, we present numerical results showing that practical
Singleton-bound-achieving maximum distance separable codes achieve the optimal
SNR exponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701127</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701127</id><created>2007-01-20</created><updated>2007-12-28</updated><authors><author><keyname>Kondor</keyname><forenames>Risi</forenames></author></authors><title>A novel set of rotationally and translationally invariant features for
  images based on the non-commutative bispectrum</title><categories>cs.CV cs.AI</categories><comments>The claim that the invariants uniquely determine the original image
  had to be dropped</comments><acm-class>I.4.7; I.2.10; I.5.4</acm-class><abstract>  We propose a new set of rotationally and translationally invariant features
for image or pattern recognition and classification. The new features are cubic
polynomials in the pixel intensities and provide a richer representation of the
original image than most existing systems of invariants. Our construction is
based on the generalization of the concept of bispectrum to the
three-dimensional rotation group SO(3), and a projection of the image onto the
sphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701128</id><created>2007-01-22</created><authors><author><keyname>Rao</keyname><forenames>M. V. Panduranga</forenames></author></authors><title>Interference Automata</title><categories>cs.CC</categories><comments>19 pages. A preliminary version appears under the title &quot;On a Model
  of Computation based on Optical Interference&quot; in Proc. of the 16-th
  Australasian Workshop on Combinatorial Algorithms (AWOCA'05), pp. 249-261</comments><abstract>  We propose a computing model, the Two-Way Optical Interference Automata
(2OIA), that makes use of the phenomenon of optical interference. We introduce
this model to investigate the increase in power, in terms of language
recognition, of a classical Deterministic Finite Automaton (DFA) when endowed
with the facility of optical interference. The question is in the spirit of
Two-Way Finite Automata With Quantum and Classical States (2QCFA) [A. Ambainis
and J. Watrous, Two-way Finite Automata With Quantum and Classical States,
Theoretical Computer Science, 287 (1), 299-311, (2002)] wherein the classical
DFA is augmented with a quantum component of constant size. We test the power
of 2OIA against the languages mentioned in the above paper. We give efficient
2OIA algorithms to recognize languages for which 2QCFA machines have been shown
to exist, as well as languages whose status vis-a-vis 2QCFA has been posed as
open questions. Finally we show the existence of a language that cannot be
recognized by a 2OIA but can be recognized by an $O(n^3)$ space Turing machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701129</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701129</id><created>2007-01-20</created><updated>2007-04-23</updated><authors><author><keyname>Sharma</keyname><forenames>Naresh</forenames></author><author><keyname>Pinnamraju</keyname><forenames>Pavan R.</forenames></author><author><keyname>Papadias</keyname><forenames>Constantinos B.</forenames></author></authors><title>Space-time codes with controllable ML decoding complexity for any number
  of transmit antennas</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in ISIT, June 2007, Nice, France</comments><doi>10.1109/ISIT.2007.4557660</doi><abstract>  We construct a class of linear space-time block codes for any number of
transmit antennas that have controllable ML decoding complexity with a maximum
rate of 1 symbol per channel use. The decoding complexity for $M$ transmit
antennas can be varied from ML decoding of $2^{\lceil \log_2M \rceil -1}$
symbols together to single symbol ML decoding. For ML decoding of $2^{\lceil
\log_2M \rceil - n}$ ($n=1,2,...$) symbols together, a diversity of
$\min(M,2^{\lceil \log_2M \rceil-n+1})$ can be achieved. Numerical results show
that the performance of the constructed code when $2^{\lceil \log_2M \rceil-1}$
symbols are decoded together is quite close to the performance of ideal rate-1
orthogonal codes (that are non-existent for more than 2 transmit antennas).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701130</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701130</id><created>2007-01-20</created><authors><author><keyname>Schmidt</keyname><forenames>Thomas C.</forenames></author><author><keyname>W&#xe4;hlisch</keyname><forenames>Matthias</forenames></author><author><keyname>Zhang</keyname><forenames>Ying</forenames></author></authors><title>On the Correlation of Geographic and Network Proximity at Internet Edges
  and its Implications for Mobile Unicast and Multicast Routing</title><categories>cs.NI cs.AR cs.PF</categories><comments>6 pages including 6 figures</comments><acm-class>C.2.3; C.2.5; C.2.6; C.4</acm-class><journal-ref>in Proceedings of the IEEE ICN'07, IEEE Computer Society Press,
  Washington, DC, USA, April 2007</journal-ref><abstract>  Significant effort has been invested recently to accelerate handover
operations in a next generation mobile Internet. Corresponding works for
developing efficient mobile multicast management are emergent. Both problems
simultaneously expose routing complexity between subsequent points of
attachment as a characteristic parameter for handover performance in access
networks.
  As continuous mobility handovers necessarily occur between access routers
located in geographic vicinity, this paper investigates on the hypothesis that
geographically adjacent edge networks attain a reduced network distances as
compared to arbitrary Internet nodes. We therefore evaluate and analyze edge
distance distributions in various regions for clustered IP ranges on their
geographic location such as a city. We use traceroute to collect packet
forwarding path and round-trip-time of each intermediate node to scan-wise
derive an upper bound of the node distances. Results of different scanning
origins are compared to obtain the best estimation of network distance of each
pair. Our results are compared with corresponding analysis of CAIDA Skitter
data, overall leading to fairly stable, reproducible edge distance
distributions. As a first conclusion on expected impact on handover performance
measures, our results indicate a general optimum for handover anticipation time
in 802.11 networks of 25 ms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701131</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701131</id><created>2007-01-21</created><updated>2007-04-01</updated><authors><author><keyname>Zhang</keyname><forenames>Jialiang</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Effective Beam Width of Directional Antennas in Wireless Ad Hoc Networks</title><categories>cs.IT math.IT</categories><abstract>  It is known at a qualitative level that directional antennas can be used to
boost the capacity of wireless ad hoc networks. Lacking is a measure to
quantify this advantage and to compare directional antennas of different
footprint patterns. This paper introduces the concept of the effective beam
width (and the effective null width as its dual counterpart) as a measure which
quantitatively captures the capacity-boosting capability of directional
antennas. Beam width is commonly defined to be the directional angle spread
within which the main-lobe beam power is above a certain threshold. In
contrast, our effective beam width definition lumps the effects of the (i)
antenna pattern, (ii) active-node distribution, and (iii) channel
characteristics, on network capacity into a single quantitative measure. We
investigate the mathematical properties of the effective beam width and show
how the convenience afforded by these properties can be used to analyze the
effectiveness of complex directional antenna patterns in boosting network
capacity, with fading and multi-user interference taken into account. In
particular, we derive the extent to which network capacity can be scaled with
the use of phased array antennas. We show that a phased array antenna with N
elements can boost transport capacity of an Aloha-like network by a factor of
order N^1.620.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701132</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701132</id><created>2007-01-21</created><updated>2007-01-23</updated><authors><author><keyname>Feron</keyname><forenames>Eric</forenames><affiliation>School of Aerospace Engineering, Georgia Institute of Technology</affiliation></author><author><keyname>Roozbehani</keyname><forenames>Mardavij</forenames><affiliation>Department of Aeronautics and Astronautics, Massachusetts Institue of Technology</affiliation></author></authors><title>Certifying controls and systems software</title><categories>cs.SE</categories><comments>12 pages, 2 figures, 1 Matlab Code. To be submitted to AIAA journal
  of guidance and control. In this revised version, support and funding
  resources were added to the acknowledgement section. LIDS Publication #: 2745</comments><report-no>LIDS # 2745</report-no><abstract>  Software system certification presents itself with many challenges, including
the necessity to certify the system at the level of functional requirements,
code and binary levels, the need to chase down run-time errors, and the need
for proving timing properties of the eventual, compiled system. This paper
illustrates possible approaches for certifying code that arises from control
systems requirements as far as stability properties are concerned. The relative
simplicity of the certification process should encourage the development of
systematic procedures for certifying control system codes for more complex
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701133</id><created>2007-01-21</created><authors><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Cheriton</keyname><forenames>David</forenames></author></authors><title>The Case for Redundant Arrays of Internet Links (RAIL)</title><categories>cs.NI</categories><abstract>  It is well-known that wide-area networks face today several performance and
reliability problems. In this work, we propose to solve these problems by
connecting two or more local-area networks together via a Redundant Array of
Internet Links (or RAIL) and by proactively replicating each packet over these
links. In that sense, RAIL is for networks what RAID (Redundant Array of
Inexpensive Disks) was for disks. In this paper, we describe the RAIL approach,
present our prototype (called the RAILedge), and evaluate its performance.
First, we demonstrate that using multiple Internet links significantly improves
the end-to-end performance in terms of network-level as well as
application-level metrics for Voice-over-IP and TCP. Second, we show that a
delay padding mechanism is needed to complement RAIL when there is significant
delay disparity between the paths. Third, we show that two paths provide most
of the benefit, if carefully managed. Finally, we discuss a RAIL-network
architecture, where RAILedges make use of path redundancy, route control and
application-specific mechanisms, to improve WAN performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701134</identifier>
 <datestamp>2007-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701134</id><created>2007-01-21</created><updated>2007-08-01</updated><authors><author><keyname>Zhao</keyname><forenames>Wenbing</forenames></author></authors><title>Byzantine Fault Tolerance for Nondeterministic Applications</title><categories>cs.DC</categories><comments>To appear in the proceedings of the 3rd IEEE International Symposium
  on Dependable, Autonomic and Secure Computing, 2007</comments><abstract>  All practical applications contain some degree of nondeterminism. When such
applications are replicated to achieve Byzantine fault tolerance (BFT), their
nondeterministic operations must be controlled to ensure replica consistency.
To the best of our knowledge, only the most simplistic types of replica
nondeterminism have been dealt with. Furthermore, there lacks a systematic
approach to handling common types of nondeterminism. In this paper, we propose
a classification of common types of replica nondeterminism with respect to the
requirement of achieving Byzantine fault tolerance, and describe the design and
implementation of the core mechanisms necessary to handle such nondeterminism
within a Byzantine fault tolerance framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701135</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701135</id><created>2007-01-21</created><authors><author><keyname>KE</keyname><forenames>Jinyun</forenames></author></authors><title>Complex networks and human language</title><categories>cs.CL</categories><abstract>  This paper introduces how human languages can be studied in light of recent
development of network theories. There are two directions of exploration. One
is to study networks existing in the language system. Various lexical networks
can be built based on different relationships between words, being semantic or
syntactic. Recent studies have shown that these lexical networks exhibit
small-world and scale-free features. The other direction of exploration is to
study networks of language users (i.e. social networks of people in the
linguistic community), and their role in language evolution. Social networks
also show small-world and scale-free features, which cannot be captured by
random or regular network models. In the past, computational models of language
change and language emergence often assume a population to have a random or
regular structure, and there has been little discussion how network structures
may affect the dynamics. In the second part of the paper, a series of
simulation models of diffusion of linguistic innovation are used to illustrate
the importance of choosing realistic conditions of population structure for
modeling language change. Four types of social networks are compared, which
exhibit two categories of diffusion dynamics. While the questions about which
type of networks are more appropriate for modeling still remains, we give some
preliminary suggestions for choosing the type of social networks for modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701136</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701136</id><created>2007-01-21</created><authors><author><keyname>Hajjem</keyname><forenames>Chawki</forenames></author><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>Citation Advantage For OA Self-Archiving Is Independent of Journal
  Impact Factor, Article Age, and Number of Co-Authors</title><categories>cs.IR cs.DL</categories><abstract>  Eysenbach has suggested that the OA (Green) self-archiving advantage might
just be an artifact of potential uncontrolled confounding factors such as
article age (older articles may be both more cited and more likely to be
self-archived), number of authors (articles with more authors might be more
cited and more self-archived), subject matter (the subjects that are cited
more, self-archive more), country (same thing), number of authors, citation
counts of authors, etc. Chawki Hajjem (doctoral candidate, UQaM) had already
shown that the OA advantage was present in all cases when articles were
analysed separately by age, subject matter or country. He has now done a
multiple regression analysis jointly testing (1) article age, (2) journal
impact factor, (3) number of authors, and (4) OA self-archiving as separate
factors for 442,750 articles in 576 (biomedical) journals across 11 years, and
has shown that each of the four factors contributes an independent,
statistically significant increment to the citation counts. The
OA-self-archiving advantage remains a robust, independent factor. Having
successfully responded to his challenge, we now challenge Eysenbach to
demonstrate -- by testing a sufficiently broad and representative sample of
journals at all levels of the journal quality, visibility and prestige
hierarchy -- that his finding of a citation advantage for Gold OA (articles
published OA on the high-profile website of the only journal he tested (PNAS)
over Green OA articles in the same journal (self-archived on the author's
website) was not just an artifact of having tested only one very high-profile
journal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701137</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701137</id><created>2007-01-21</created><authors><author><keyname>Hajjem</keyname><forenames>Chawki</forenames></author><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>The Open Access Citation Advantage: Quality Advantage Or Quality Bias?</title><categories>cs.IR cs.DL</categories><abstract>  Many studies have now reported the positive correlation between Open Access
(OA) self-archiving and citation counts (&quot;OA Advantage,&quot; OAA). But does this
OAA occur because (QB) authors are more likely to self-selectively self-archive
articles that are more likely to be cited (self-selection &quot;Quality Bias&quot;: QB)?
or because (QA) articles that are self-archived are more likely to be cited
(&quot;Quality Advantage&quot;: QA)? The probable answer is both. Three studies [by (i)
Kurtz and co-workers in astrophysics, (ii) Moed in condensed matter physics,
and (iii) Davis &amp; Fromerth in mathematics] had reported the OAA to be due to QB
[plus Early Advantage, EA, from self-archiving the preprint before publication,
in (i) and (ii)] rather than QA. These three fields, however, (1) have less of
a postprint access problem than most other fields and (i) and (ii) also happen
to be among the minority of fields that (2) make heavy use of prepublication
preprints. Chawki Hajjem has now analyzed preliminary evidence based on over
100,000 articles from multiple fields, comparing self-selected self-archiving
with mandated self-archiving to estimate the contributions of QB and QA to the
OAA. Both factors contribute, and the contribution of QA is greater.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701138</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701138</id><created>2007-01-22</created><updated>2007-02-27</updated><authors><author><keyname>Bruyere</keyname><forenames>Veronique</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Francois</forenames></author></authors><title>Real-Time Model-Checking: Parameters everywhere</title><categories>cs.LO</categories><acm-class>F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (February
  27, 2007) lmcs:1056</journal-ref><doi>10.2168/LMCS-3(1:7)2007</doi><abstract>  In this paper, we study the model-checking and parameter synthesis problems
of the logic TCTL over discrete-timed automata where parameters are allowed
both in the model (timed automaton) and in the property (temporal formula). Our
results are as follows. On the negative side, we show that the model-checking
problem of TCTL extended with parameters is undecidable over discrete-timed
automata with only one parametric clock. The undecidability result needs
equality in the logic. On the positive side, we show that the model-checking
and the parameter synthesis problems become decidable for a fragment of the
logic where equality is not allowed. Our method is based on automata theoretic
principles and an extension of our method to express durations of runs in timed
automata using Presburger arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701139</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701139</id><created>2007-01-22</created><authors><author><keyname>Mor</keyname><forenames>Yishay</forenames></author><author><keyname>Rosenschein</keyname><forenames>Jeffrey S.</forenames></author></authors><title>Time and the Prisoner's Dilemma</title><categories>cs.GT cs.AI</categories><comments>Proceedings of the First International Conference on Multiagent
  Systems (ICMAS95), : 276-282, 1995</comments><abstract>  This paper examines the integration of computational complexity into game
theoretic models. The example focused on is the Prisoner's Dilemma, repeated
for a finite length of time. We show that a minimal bound on the players'
computational ability is sufficient to enable cooperative behavior.
  In addition, a variant of the repeated Prisoner's Dilemma game is suggested,
in which players have the choice of opting out. This modification enriches the
game and suggests dominance of cooperative strategies.
  Competitive analysis is suggested as a tool for investigating sub-optimal
(but computationally tractable) strategies and game theoretic models in
general. Using competitive analysis, it is shown that for bounded players, a
sub-optimal strategy might be the optimal choice, given resource limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701140</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701140</id><created>2007-01-22</created><updated>2007-02-26</updated><authors><author><keyname>Pasareanu</keyname><forenames>Corina S.</forenames></author><author><keyname>Pelanek</keyname><forenames>Radek</forenames></author><author><keyname>Visser</keyname><forenames>Willem</forenames></author></authors><title>Predicate Abstraction with Under-approximation Refinement</title><categories>cs.GT</categories><comments>22 pages, 3 figures, accepted for publication in Logical Methods in
  Computer Science journal (special issue CAV 2005)</comments><acm-class>D.2.4; F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (February
  26, 2007) lmcs:893</journal-ref><doi>10.2168/LMCS-3(1:5)2007</doi><abstract>  We propose an abstraction-based model checking method which relies on
refinement of an under-approximation of the feasible behaviors of the system
under analysis. The method preserves errors to safety properties, since all
analyzed behaviors are feasible by definition. The method does not require an
abstract transition relation to be generated, but instead executes the concrete
transitions while storing abstract versions of the concrete states, as
specified by a set of abstraction predicates. For each explored transition the
method checks, with the help of a theorem prover, whether there is any loss of
precision introduced by abstraction. The results of these checks are used to
decide termination or to refine the abstraction by generating new abstraction
predicates. If the (possibly infinite) concrete system under analysis has a
finite bisimulation quotient, then the method is guaranteed to eventually
explore an equivalent finite bisimilar structure. We illustrate the application
of the approach for checking concurrent programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701141</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701141</id><created>2007-01-22</created><updated>2009-02-10</updated><authors><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author><author><keyname>Moa</keyname><forenames>B.</forenames></author></authors><title>The Fundamental Theorems of Interval Analysis</title><categories>cs.NA</categories><comments>8 pages</comments><report-no>DCS-316-IR</report-no><acm-class>G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expressions are not functions. Confusing the two concepts or failing to
define the function that is computed by an expression weakens the rigour of
interval arithmetic. We give such a definition and continue with the required
re-statements and proofs of the fundamental theorems of interval arithmetic and
interval analysis.
  Revision Feb. 10, 2009: added reference to and acknowledgement of P. Taylor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701142</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701142</id><created>2007-01-22</created><authors><author><keyname>Bein</keyname><forenames>Wolfgang</forenames></author><author><keyname>Larmore</keyname><forenames>Lawrence L.</forenames></author><author><keyname>Reischuk</keyname><forenames>R&#xfc;diger</forenames></author></authors><title>Knowledge State Algorithms: Randomization with Limited Information</title><categories>cs.DS</categories><comments>17 pages, 2 figures</comments><acm-class>F.1.2; F.2.3</acm-class><abstract>  We introduce the concept of knowledge states; many well-known algorithms can
be viewed as knowledge state algorithms. The knowledge state approach can be
used to to construct competitive randomized online algorithms and study the
tradeoff between competitiveness and memory. A knowledge state simply states
conditional obligations of an adversary, by fixing a work function, and gives a
distribution for the algorithm. When a knowledge state algorithm receives a
request, it then calculates one or more &quot;subsequent&quot; knowledge states, together
with a probability of transition to each. The algorithm then uses randomization
to select one of those subsequents to be the new knowledge state. We apply the
method to the paging problem. We present optimally competitive algorithm for
paging for the cases where the cache sizes are k=2 and k=3. These algorithms
use only a very limited number of bookmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701143</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701143</id><created>2007-01-22</created><updated>2011-06-20</updated><authors><author><keyname>Wang</keyname><forenames>Xing M.</forenames></author></authors><title>Dirac Notation, Fock Space and Riemann Metric Tensor in Information
  Retrieval Models</title><categories>cs.IR math-ph math.MP</categories><comments>Removed appendix B; introduced Concept Fock Space; made some minor
  corrections or modifications</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using Dirac Notation as a powerful tool, we investigate the three classical
Information Retrieval (IR) models and some their extensions. We show that
almost all such models can be described by vectors in Occupation Number
Representations (ONR) of Fock spaces with various specifications on, e.g.,
occupation number, inner product or term-term interactions. As important cases
of study, Concept Fock Space (CFS) is introduced for Boolean model; the basic
formulas for Singular Value Decomposition (SVD) of Latent Semantic Indexing
(LSI) Model are manipulated in terms of Dirac notation. And, based on SVD, a
Riemannian metric tensor is introduced, which not only can be used to calculate
the relevance of documents to a query, but also may be used to measure the
closeness of documents in data clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701144</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701144</id><created>2007-01-23</created><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Trusted Ticket Systems and Applications</title><categories>cs.CR</categories><comments>Accepted full research paper at IFIP sec2007, Sandton, South Africa,
  14-16 May 2007</comments><abstract>  Trusted Computing is a security base technology that will perhaps be
ubiquitous in a few years in personal computers and mobile devices alike.
Despite its neutrality with respect to applications, it has raised some privacy
concerns. We show that trusted computing can be applied for service access
control in a manner protecting users' privacy. We construct a ticket system --
a concept which is at the heart of Identity Management -- relying solely on the
capabilities of the trusted platform module and the standards specified by the
Trusted Computing Group. Two examples show how it can be used for pseudonymous
and protected service access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701145</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701145</id><created>2007-01-23</created><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author><author><keyname>Hett</keyname><forenames>Christian</forenames></author></authors><title>Non-Repudiation in Internet Telephony</title><categories>cs.CR</categories><comments>Accepted full research paper at IFIP sec2007, Sandton, South Africa,
  14-16 May 2007</comments><abstract>  We present a concept to achieve non-repudiation for natural language
conversations over the Internet. The method rests on chained electronic
signatures applied to pieces of packet-based, digital, voice communication. It
establishes the integrity and authenticity of the bidirectional data stream and
its temporal sequence and thus the security context of a conversation. The
concept is close to the protocols for Voice over the Internet (VoIP), provides
a high level of inherent security, and extends naturally to multilateral
non-repudiation, e.g., for conferences. Signatures over conversations can
become true declarations of will in analogy to electronically signed, digital
documents. This enables binding verbal contracts, in principle between
unacquainted speakers, and in particular without witnesses. A reference
implementation of a secure VoIP archive is exhibited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701146</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701146</id><created>2007-01-23</created><updated>2009-10-05</updated><authors><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>State constraints and list decoding for the AVC</title><categories>cs.IT math.IT</categories><comments>22 pages, significantly changed version submitted to IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  List decoding for arbitrarily varying channels (AVCs) under state constraints
is investigated. It is shown that rates within $\epsilon$ of the randomized
coding capacity of AVCs with input-dependent state can be achieved under
maximal error with list decoding using lists of size $O(1/\epsilon)$. Under
average error an achievable rate region and converse bound are given for lists
of size $L$. These bounds are based on two different notions of
symmetrizability and do not coincide in general. An example is given that shows
that for list size $L$ the capacity may be positive but strictly smaller than
the randomized coding capacity. This behavior is different than the situation
without state constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701147</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701147</id><created>2007-01-24</created><authors><author><keyname>Hanus</keyname><forenames>Michael</forenames></author></authors><title>A Generic Analysis Environment for Curry Programs</title><categories>cs.PL</categories><comments>Paper presented at the 16th Workshop on Logic-based Methods in
  Programming Environments</comments><abstract>  We present CurryBrowser, a generic analysis environment for the declarative
multi-paradigm language Curry. CurryBrowser supports browsing through the
program code of an application written in Curry, i.e., the main module and all
directly or indirectly imported modules. Each module can be shown in different
formats (e.g., source code, interface, intermediate code) and, inside each
module, various properties of functions defined in this module can be analyzed.
In order to support the integration of various program analyses, CurryBrowser
has a generic interface to connect local and global analyses implemented in
Curry. CurryBrowser is completely implemented in Curry using libraries for GUI
programming and meta-programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701148</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701148</id><created>2007-01-24</created><authors><author><keyname>Vanhoof</keyname><forenames>Wim</forenames></author><author><keyname>Munoz-Hernandez</keyname><forenames>Susana</forenames></author></authors><title>Proceedings of the 16th Workshop in Logic-based Methods in Programming
  Environments (WLPE2006)</title><categories>cs.PL</categories><acm-class>D.2.6; D.1.6</acm-class><abstract>  This volume contains the papers presented at WLPE'06: the 16th Workshop on
Logic-based Methods in Programming Environments held on August 16, 2006 in the
Seattle Sheraton Hotel and Towers, Seattle, Washington (USA). It was organised
as a satellite workshop of ICLP'06, the 22th International Conference on Logic
Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701149</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701149</id><created>2007-01-24</created><updated>2007-02-02</updated><authors><author><keyname>Oyman</keyname><forenames>Ozgur</forenames></author><author><keyname>Paulraj</keyname><forenames>Arogyaswami J.</forenames></author></authors><title>Power-Bandwidth Tradeoff in Dense Multi-Antenna Relay Networks</title><categories>cs.IT math.IT</categories><comments>12 pages, to appear in IEEE Transactions on Wireless Communications</comments><abstract>  We consider a dense fading multi-user network with multiple active
multi-antenna source-destination pair terminals communicating simultaneously
through a large common set of $K$ multi-antenna relay terminals in the full
spatial multiplexing mode. We use Shannon-theoretic tools to analyze the
tradeoff between energy efficiency and spectral efficiency (known as the power-
bandwidth tradeoff) in meaningful asymptotic regimes of signal-to-noise ratio
(SNR) and network size. We design linear distributed multi-antenna relay
beamforming (LDMRB) schemes that exploit the spatial signature of multi-user
interference and characterize their power-bandwidth tradeoff under a system
wide power constraint on source and relay transmissions. The impact of multiple
users, multiple relays and multiple antennas on the key performance measures of
the high and low SNR regimes is investigated in order to shed new light on the
possible reduction in power and bandwidth requirements through the usage of
such practical relay cooperation techniques. Our results indicate that
point-to-point coded multi-user networks supported by distributed relay
beamforming techniques yield enhanced energy efficiency and spectral
efficiency, and with appropriate signaling and sufficient antenna degrees of
freedom, can achieve asymptotically optimal power-bandwidth tradeoff with the
best possible (i.e., as in the cutset bound) energy scaling of $K^{-1}$ and the
best possible spectral efficiency slope at any SNR for large number of relay
terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701150</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701150</id><created>2007-01-24</created><authors><author><keyname>Brun</keyname><forenames>Luc</forenames><affiliation>GREYC</affiliation></author><author><keyname>Kropatsch</keyname><forenames>Walter G.</forenames><affiliation>PRIP</affiliation></author></authors><title>Contains and Inside relationships within combinatorial Pyramids</title><categories>cs.CV</categories><comments>35 pages</comments><proxy>ccsd hal-00125425</proxy><journal-ref>Pattern Recognition 39 (01/04/2006) 515-526</journal-ref><abstract>  Irregular pyramids are made of a stack of successively reduced graphs
embedded in the plane. Such pyramids are used within the segmentation framework
to encode a hierarchy of partitions. The different graph models used within the
irregular pyramid framework encode different types of relationships between
regions. This paper compares different graph models used within the irregular
pyramid framework according to a set of relationships between regions. We also
define a new algorithm based on a pyramid of combinatorial maps which allows to
determine if one region contains the other using only local calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701151</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701151</id><created>2007-01-25</created><authors><author><keyname>Cheng</keyname><forenames>Howard</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Hanrot</keyname><forenames>Guillaume</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Thom&#xe9;</keyname><forenames>Emmanuel</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Zima</keyname><forenames>Eugene</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Zimmermann</keyname><forenames>Paul</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Time- and Space-Efficient Evaluation of Some Hypergeometric Constants</title><categories>cs.SC</categories><proxy>ccsd inria-00126428</proxy><abstract>  The currently best known algorithms for the numerical evaluation of
hypergeometric constants such as $\zeta(3)$ to $d$ decimal digits have time
complexity $O(M(d) \log^2 d)$ and space complexity of $O(d \log d)$ or $O(d)$.
Following work from Cheng, Gergel, Kim and Zima, we present a new algorithm
with the same asymptotic complexity, but more efficient in practice. Our
implementation of this algorithm improves slightly over existing programs for
the computation of $\pi$, and we announce a new record of 2 billion digits for
$\zeta(3)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701152</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701152</id><created>2007-01-25</created><authors><author><keyname>Mahdavi-Doost</keyname><forenames>Hajar</forenames></author><author><keyname>Ebrahimi</keyname><forenames>Masoud</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Characterization of Rate Region in Interference Channels with
  Constrained Power</title><categories>cs.IT math.IT</categories><comments>21 Pages, The Conference Version is Submitted to IEEE International
  Symposium on Information Theory (ISIT2007)</comments><abstract>  In this paper, an $n$-user Gaussian interference channel, where the power of
the transmitters are subject to some upper-bounds is studied. We obtain a
closed-form expression for the rate region of such a channel based on the
Perron-Frobenius theorem. While the boundary of the rate region for the case of
unconstrained power is a well-established result, this is the first result for
the case of constrained power. We extend this result to the time-varying
channels and obtain a closed-form solution for the rate region of such
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701153</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701153</id><created>2007-01-25</created><authors><author><keyname>Fori&#x161;ek</keyname><forenames>Michal</forenames></author><author><keyname>Katreniak</keyname><forenames>Branislav</forenames></author><author><keyname>Katreniakov&#xe1;</keyname><forenames>Jana</forenames></author><author><keyname>Kr&#xe1;lovi&#x10d;</keyname><forenames>Rastislav</forenames></author><author><keyname>Kr&#xe1;lovi&#x10d;</keyname><forenames>Richard</forenames></author><author><keyname>Koutn&#xfd;</keyname><forenames>Vladim&#xed;r</forenames></author><author><keyname>Pardubsk&#xe1;</keyname><forenames>Dana</forenames></author><author><keyname>Plachetka</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Rovan</keyname><forenames>Branislav</forenames></author></authors><title>Online Bandwidth Allocation</title><categories>cs.DS cs.NI</categories><abstract>  The paper investigates a version of the resource allocation problem arising
in the wireless networking, namely in the OVSF code reallocation process. In
this setting a complete binary tree of a given height $n$ is considered,
together with a sequence of requests which have to be served in an online
manner. The requests are of two types: an insertion request requires to
allocate a complete subtree of a given height, and a deletion request frees a
given allocated subtree. In order to serve an insertion request it might be
necessary to move some already allocated subtrees to other locations in order
to free a large enough subtree. We are interested in the worst case average
number of such reallocations needed to serve a request.
  It was proved in previous work that the competitive ratio of the optimal
online algorithm solving this problem is between 1.5 and O(n). We partially
answer the question about its exact value by giving an O(1)-competitive online
algorithm.
  Same model has been used in the context of memory management systems, and
analyzed for the number of reallocations needed to serve a request in the worst
case. In this setting, our result is a corresponding amortized analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701154</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701154</id><created>2007-01-25</created><updated>2007-02-23</updated><authors><author><keyname>Tesson</keyname><forenames>Pascal</forenames></author><author><keyname>Therien</keyname><forenames>Denis</forenames></author></authors><title>Logic Meets Algebra: the Case of Regular Languages</title><categories>cs.LO</categories><comments>37 pages</comments><acm-class>D.3.1; F.1.1; F.1.3; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (February
  23, 2007) lmcs:901</journal-ref><doi>10.2168/LMCS-3(1:4)2007</doi><abstract>  The study of finite automata and regular languages is a privileged meeting
point of algebra and logic. Since the work of Buchi, regular languages have
been classified according to their descriptive complexity, i.e. the type of
logical formalism required to define them. The algebraic point of view on
automata is an essential complement of this classification: by providing
alternative, algebraic characterizations for the classes, it often yields the
only opportunity for the design of algorithms that decide expressibility in
some logical fragment.
  We survey the existing results relating the expressibility of regular
languages in logical fragments of MSO[S] with algebraic properties of their
minimal automata. In particular, we show that many of the best known results in
this area share the same underlying mechanics and rely on a very strong
relation between logical substitutions and block-products of pseudovarieties of
monoid. We also explain the impact of these connections on circuit complexity
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701155</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701155</id><created>2007-01-25</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Surajit</forenames></author><author><keyname>Bosworth</keyname><forenames>Adam</forenames></author><author><keyname>Layman</keyname><forenames>Andrew</forenames></author><author><keyname>Reichart</keyname><forenames>Don</forenames></author><author><keyname>Venkatrao</keyname><forenames>Murali</forenames></author><author><keyname>Pellow</keyname><forenames>Frank</forenames></author><author><keyname>Pirahesh</keyname><forenames>Hamid</forenames></author></authors><title>Data Cube: A Relational Aggregation Operator Generalizing Group-By,
  Cross-Tab, and Sub-Totals</title><categories>cs.DB</categories><proxy>gray</proxy><journal-ref>Data Mining and Knowledge Discovery 1(1): 29-53 (1997)</journal-ref><abstract>  Data analysis applications typically aggregate data across many dimensions
looking for anomalies or unusual patterns. The SQL aggregate functions and the
GROUP BY operator produce zero-dimensional or one-dimensional aggregates.
Applications need the N-dimensional generalization of these operators. This
paper defines that operator, called the data cube or simply cube. The cube
operator generalizes the histogram, cross-tabulation, roll-up, drill-down, and
sub-total constructs found in most report writers. The novelty is that cubes
are relations. Consequently, the cube operator can be imbedded in more complex
non-procedural data analysis programs. The cube operator treats each of the N
aggregation attributes as a dimension of N-space. The aggregate of a particular
set of attribute values is a point in this space. The set of points forms an
N-dimensional cube. Super-aggregates are computed by aggregating the N-cube to
lower dimensional spaces. This paper (1) explains the cube and roll-up
operators, (2) shows how they fit in SQL, (3) explains how users can define new
aggregate functions for cubes, and (4) discusses efficient techniques to
compute the cube. Many of these features are being added to the SQL Standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701156</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701156</id><created>2007-01-25</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Data Management: Past, Present, and Future</title><categories>cs.DB</categories><proxy>gray</proxy><report-no>MSR-TR-96-18</report-no><journal-ref>IEEE Computer 29(10): 38-46 (1996)</journal-ref><abstract>  Soon most information will be available at your fingertips, anytime,
anywhere. Rapid advances in storage, communications, and processing allow us
move all information into Cyberspace. Software to define, search, and visualize
online information is also a key to creating and accessing online information.
This article traces the evolution of data management systems and outlines
current trends. Data management systems began by automating traditional tasks:
recording transactions in business, science, and commerce. This data consisted
primarily of numbers and character strings. Today these systems provide the
infrastructure for much of our society, allowing fast, reliable, secure, and
automatic access to data distributed throughout the world. Increasingly these
systems automatically design and manage access to the data. The next steps are
to automate access to richer forms of data: images, sound, video, maps, and
other media. A second major challenge is automatically summarizing and
abstracting data in anticipation of user requests. These multi-media databases
and tools to access them will be a cornerstone of our move to Cyberspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701157</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701157</id><created>2007-01-25</created><authors><author><keyname>Berenson</keyname><forenames>Hal</forenames></author><author><keyname>Bernstein</keyname><forenames>Phil</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Melton</keyname><forenames>Jim</forenames></author><author><keyname>O'Neil</keyname><forenames>Elizabeth</forenames></author><author><keyname>O'Neil</keyname><forenames>Patrick</forenames></author></authors><title>A Critique of ANSI SQL Isolation Levels</title><categories>cs.DB</categories><proxy>gray</proxy><report-no>MSR-TR-95-51</report-no><journal-ref>Proc. ACM SIGMOD 95, pp. 1-10, San Jose CA, June 1995</journal-ref><abstract>  ANSI SQL-92 defines Isolation Levels in terms of phenomena: Dirty Reads,
Non-Repeatable Reads, and Phantoms. This paper shows that these phenomena and
the ANSI SQL definitions fail to characterize several popular isolation levels,
including the standard locking implementations of the levels. Investigating the
ambiguities of the phenomena leads to clearer definitions; in addition new
phenomena that better characterize isolation types are introduced. An important
multiversion isolation type, Snapshot Isolation, is defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701158</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701158</id><created>2007-01-25</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Queues Are Databases</title><categories>cs.DB</categories><proxy>gray</proxy><report-no>MSR-TR-95-56</report-no><abstract>  Message-oriented-middleware (MOM) has become an small industry. MOM offers
queued transaction processing as an advance over pure client-server transaction
processing. This note makes four points: Queued transaction processing is less
general than direct transaction processing. Queued systems are built on top of
direct systems. You cannot build a direct system atop a queued system. It is
difficult to build direct, conversational, or distributed transactions atop a
queued system. Queues are interesting databases with interesting concurrency
control. It is best to build these mechanisms into a standard database system
so other applications can use these interesting features. Queue systems need
DBMS functionality. Queues need security, configuration, performance
monitoring, recovery, and reorganization utilities. Database systems already
have these features. A full-function MOM system duplicates these database
features. Queue managers are simple TP-monitors managing server pools driven by
queues. Database systems are encompassing many server pool features as they
evolve to TP-lite systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701159</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701159</id><created>2007-01-25</created><authors><author><keyname>Heber</keyname><forenames>Gerd</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Supporting Finite Element Analysis with a Relational Database Backend,
  Part I: There is Life beyond Files</title><categories>cs.DB cs.CE</categories><proxy>gray</proxy><report-no>MSR-TR-2005-49</report-no><abstract>  In this paper, we show how to use a Relational Database Management System in
support of Finite Element Analysis. We believe it is a new way of thinking
about data management in well-understood applications to prepare them for two
major challenges, - size and integration (globalization). Neither extreme size
nor integration (with other applications over the Web) was a design concern 30
years ago when the paradigm for FEA implementation first was formed. On the
other hand, database technology has come a long way since its inception and it
is past time to highlight its usefulness to the field of scientific computing
and computer based engineering. This series aims to widen the list of
applications for database designers and for FEA users and application
developers to reap some of the benefits of database development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701160</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701160</id><created>2007-01-25</created><authors><author><keyname>Heber</keyname><forenames>Gerd</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Supporting Finite Element Analysis with a Relational Database Backend,
  Part II: Database Design and Access</title><categories>cs.DB cs.CE</categories><proxy>gray</proxy><report-no>MSR-TR-2006-21</report-no><abstract>  This is Part II of a three article series on using databases for Finite
Element Analysis (FEA). It discusses (1) db design, (2) data loading, (3)
typical use cases during grid building, (4) typical use cases during simulation
(get and put), (5) typical use cases during analysis (also done in Part III)
and some performance measures of these cases. It argues that using a database
is simpler to implement than custom data schemas, has better performance
because it can use data parallelism, and better supports FEA modularity and
tool evolution because database schema evolution, data independence, and
self-defining data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701161</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701161</id><created>2007-01-25</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Levine</keyname><forenames>Charles</forenames></author></authors><title>Thousands of DebitCredit Transactions-Per-Second: Easy and Inexpensive</title><categories>cs.DB cs.PF</categories><proxy>gray</proxy><report-no>MSR-TR-2005-39</report-no><abstract>  A $2k computer can execute about 8k transactions per second. This is 80x more
than one of the largest US bank's 1970's traffic - it approximates the total US
1970's financial transaction volume. Very modest modern computers can easily
solve yesterday's problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701162</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701162</id><created>2007-01-25</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>A Measure of Transaction Processing 20 Years Later</title><categories>cs.DB cs.PF</categories><comments>This article appeared in the IEEE Data Engineering, Fall 2005</comments><proxy>gray</proxy><report-no>MSR-TR-2005-57</report-no><abstract>  This provides a retrospective of the paper &quot;A Measure of Transaction
Processing&quot; published in 1985. It shows that transaction processing peak
performance and price-peformance have improved about 100,000x respectively and
that sort/sequential performance has approximately doubled each year (so a
million fold improvement) even though processor performance plateaued in 1995.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701163</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701163</id><created>2007-01-25</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author><author><keyname>Fekete</keyname><forenames>Gyorgy</forenames></author></authors><title>Using Table Valued Functions in SQL Server 2005 To Implement a Spatial
  Data Library</title><categories>cs.DB cs.CE</categories><proxy>gray</proxy><report-no>MSR-TR-2005-122</report-no><abstract>  This article explains how to add spatial search functions (point-near-point
and point in polygon) to Microsoft SQL Server 2005 using C# and table-valued
functions. It is possible to use this library to add spatial search to your
application without writing any special code. The library implements the
public-domain C# Hierarchical Triangular Mesh (HTM) algorithms from Johns
Hopkins University. That C# library is connected to SQL Server 2005 via a set
of scalar-valued and table-valued functions. These functions act as a spatial
index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701164</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701164</id><created>2007-01-25</created><authors><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Fekete</keyname><forenames>George</forenames></author><author><keyname>Kunszt</keyname><forenames>Peter Z.</forenames></author><author><keyname>Kukol</keyname><forenames>Peter</forenames></author><author><keyname>Thakar</keyname><forenames>Ani</forenames></author></authors><title>Indexing the Sphere with the Hierarchical Triangular Mesh</title><categories>cs.DB cs.DS</categories><proxy>gray</proxy><report-no>MSR-TR-2005-123</report-no><abstract>  We describe a method to subdivide the surface of a sphere into spherical
triangles of similar, but not identical, shapes and sizes. The Hierarchical
Triangular Mesh (HTM) is a quad-tree that is particularly good at supporting
searches at different resolutions, from arc seconds to hemispheres. The
subdivision scheme is universal, providing the basis for addressing and for
fast lookups. The HTM provides the basis for an efficient geospatial indexing
scheme in relational databases where the data have an inherent location on
either the celestial sphere or the Earth. The HTM index is superior to
cartographical methods using coordinates with singularities at the poles. We
also describe a way to specify surface regions that efficiently represent
spherical query areas. This article presents the algorithms used to identify
the HTM triangles covering such regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701165</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701165</id><created>2007-01-25</created><authors><author><keyname>Bell</keyname><forenames>Gordon</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author></authors><title>Petascale Computational Systems</title><categories>cs.DB cs.AR</categories><proxy>gray</proxy><abstract>  Computational science is changing to be data intensive. Super-Computers must
be balanced systems; not just CPU farms but also petascale IO and networking
arrays. Anyone building CyberInfrastructure should allocate resources to
support a balanced Tier-1 through Tier-3 design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701166</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701166</id><created>2007-01-25</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>van Ingen</keyname><forenames>Catharine</forenames></author></authors><title>Empirical Measurements of Disk Failure Rates and Error Rates</title><categories>cs.DB cs.AR</categories><proxy>gray</proxy><report-no>MSR-TR-2005-166</report-no><abstract>  The SATA advertised bit error rate of one error in 10 terabytes is
frightening. We moved 2 PB through low-cost hardware and saw five disk read
error events, several controller failures, and many system reboots caused by
security patches. We conclude that SATA uncorrectable read errors are not yet a
dominant system-fault source - they happen, but are rare compared to other
problems. We also conclude that UER (uncorrectable error rate) is not the
relevant metric for our needs. When an uncorrectable read error happens, there
are typically several damaged storage blocks (and many uncorrectable read
errors.) Also, some uncorrectable read errors may be masked by the operating
system. The more meaningful metric for data architects is Mean Time To Data
Loss (MTTDL.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701167</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701167</id><created>2007-01-25</created><authors><author><keyname>Nieto-Santisteban</keyname><forenames>Maria A.</forenames></author><author><keyname>Thakar</keyname><forenames>Aniruddha R.</forenames></author><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Large-Scale Query and XMatch, Entering the Parallel Zone</title><categories>cs.DB cs.CE</categories><comments>Astronomical Data Analysis Software and Systems XV in San Lorenzo de
  El Escorial, Madrid, Spain, October 2005, to appear in the ASP Conference
  Series</comments><proxy>gray</proxy><report-no>MSR-TR-2005- 169</report-no><abstract>  Current and future astronomical surveys are producing catalogs with millions
and billions of objects. On-line access to such big datasets for data mining
and cross-correlation is usually as highly desired as unfeasible. Providing
these capabilities is becoming critical for the Virtual Observatory framework.
In this paper we present various performance tests that show how using
Relational Database Management Systems (RDBMS) and a Zoning algorithm to
partition and parallelize the computation, we can facilitate large-scale query
and cross-match.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701168</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701168</id><created>2007-01-25</created><authors><author><keyname>Sears</keyname><forenames>Russell</forenames></author><author><keyname>Van Ingen</keyname><forenames>Catharine</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>To BLOB or Not To BLOB: Large Object Storage in a Database or a
  Filesystem?</title><categories>cs.DB</categories><proxy>gray</proxy><report-no>MSR-TR-2006-45</report-no><journal-ref>CIDR 2007</journal-ref><abstract>  Application designers often face the question of whether to store large
objects in a filesystem or in a database. Often this decision is made for
application design simplicity. Sometimes, performance measurements are also
used. This paper looks at the question of fragmentation - one of the
operational issues that can affect the performance and/or manageability of the
system as deployed long term. As expected from the common wisdom, objects
smaller than 256KB are best stored in a database while objects larger than 1M
are best stored in the filesystem. Between 256KB and 1MB, the read:write ratio
and rate of object overwrite or replacement are important factors. We used the
notion of &quot;storage age&quot; or number of object overwrites as way of normalizing
wall clock time. Storage age allows our results or similar such results to be
applied across a number of read:write ratios and object replacement rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701169</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701169</id><created>2007-01-25</created><updated>2007-01-27</updated><authors><author><keyname>Shenouda</keyname><forenames>Michael Botros</forenames></author><author><keyname>Davidson</keyname><forenames>T. N.</forenames></author></authors><title>A Framework for Designing MIMO systems with Decision Feedback
  Equalization or Tomlinson-Harashima Precoding</title><categories>cs.IT math.IT</categories><comments>To appear in ICASSP 2007</comments><abstract>  We consider joint transceiver design for general Multiple-Input
Multiple-Output communication systems that implement interference
(pre-)subtraction, such as those based on Decision Feedback Equalization (DFE)
or Tomlinson-Harashima precoding (THP). We develop a unified framework for
joint transceiver design by considering design criteria that are expressed as
functions of the Mean Square Error (MSE) of the individual data streams. By
deriving two inequalities that involve the logarithms of the individual MSEs,
we obtain optimal designs for two classes of communication objectives, namely
those that are Schur-convex and Schur-concave functions of these logarithms.
For Schur-convex objectives, the optimal design results in data streams with
equal MSEs. This design simultaneously minimizes the total MSE and maximizes
the mutual information for the DFE-based model. For Schur-concave objectives,
the optimal DFE design results in linear equalization and the optimal THP
design results in linear precoding. The proposed framework embraces a wide
range of design objectives and can be regarded as a counterpart of the existing
framework of linear transceiver design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701170</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701170</id><created>2007-01-26</created><authors><author><keyname>Szlavecz</keyname><forenames>Katalin</forenames></author><author><keyname>Terzis</keyname><forenames>Andreas</forenames></author><author><keyname>Ozer</keyname><forenames>Stuart</forenames></author><author><keyname>Musaloiu-E</keyname><forenames>Razvan</forenames></author><author><keyname>Cogan</keyname><forenames>Joshua</forenames></author><author><keyname>Small</keyname><forenames>Sam</forenames></author><author><keyname>Burns</keyname><forenames>Randal</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author></authors><title>Life Under Your Feet: An End-to-End Soil Ecology Sensor Network,
  Database, Web Server, and Analysis Service</title><categories>cs.DB cs.CE</categories><proxy>gray</proxy><report-no>MSR TR 2006 90</report-no><abstract>  Wireless sensor networks can revolutionize soil ecology by providing
measurements at temporal and spatial granularities previously impossible. This
paper presents a soil monitoring system we developed and deployed at an urban
forest in Baltimore as a first step towards realizing this vision. Motes in
this network measure and save soil moisture and temperature in situ every
minute. Raw measurements are periodically retrieved by a sensor gateway and
stored in a central database where calibrated versions are derived and stored.
The measurement database is published through Web Services interfaces. In
addition, analysis tools let scientists analyze current and historical data and
help manage the sensor network. The article describes the system design, what
we learned from the deployment, and initial results obtained from the sensors.
The system measures soil factors with unprecedented temporal precision.
However, the deployment required device-level programming, sensor calibration
across space and time, and cross-referencing measurements with external
sources. The database, web server, and data analysis design required
considerable innovation and expertise. So, the ratio of computer-scientists to
ecologists was 3:1. Before sensor networks can fulfill their potential as
instruments that can be easily deployed by scientists, these technical problems
must be addressed so that the ratio is one nerd per ten ecologists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701171</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701171</id><created>2007-01-26</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Nieto-Santisteban</keyname><forenames>Maria A.</forenames></author><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author></authors><title>The Zones Algorithm for Finding Points-Near-a-Point or Cross-Matching
  Spatial Datasets</title><categories>cs.DB cs.DS</categories><proxy>gray</proxy><report-no>MSR TR 2006 52</report-no><abstract>  Zones index an N-dimensional Euclidian or metric space to efficiently support
points-near-a-point queries either within a dataset or between two datasets.
The approach uses relational algebra and the B-Tree mechanism found in almost
all relational database systems. Hence, the Zones Algorithm gives a
portable-relational implementation of points-near-point, spatial cross-match,
and self-match queries. This article corrects some mistakes in an earlier
article we wrote on the Zones Algorithm and describes some algorithmic
improvements. The Appendix includes an implementation of point-near-point,
self-match, and cross-match using the USGS city and stream gauge database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701172</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701172</id><created>2007-01-26</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author><author><keyname>Budavari</keyname><forenames>Tamas</forenames></author><author><keyname>Lupton</keyname><forenames>Robert</forenames></author><author><keyname>Nieto-Santisteban</keyname><forenames>Maria</forenames></author><author><keyname>Thakar</keyname><forenames>Ani</forenames></author></authors><title>Cross-Matching Multiple Spatial Observations and Dealing with Missing
  Data</title><categories>cs.DB cs.CE</categories><proxy>gray</proxy><report-no>MSR TR 2006-175</report-no><abstract>  Cross-match spatially clusters and organizes several astronomical
point-source measurements from one or more surveys. Ideally, each object would
be found in each survey. Unfortunately, the observation conditions and the
objects themselves change continually. Even some stationary objects are missing
in some observations; sometimes objects have a variable light flux and
sometimes the seeing is worse. In most cases we are faced with a substantial
number of differences in object detections between surveys and between
observations taken at different times within the same survey or instrument.
Dealing with such missing observations is a difficult problem. The first step
is to classify misses as ephemeral - when the object moved or simply
disappeared, masked - when noise hid or corrupted the object observation, or
edge - when the object was near the edge of the observational field. This
classification and a spatial library to represent and manipulate observational
footprints help construct a Match table recording both hits and misses.
Transitive closure clusters friends-of-friends into object bundles. The bundle
summary statistics are recorded in a Bundle table. This design is an evolution
of the Sloan Digital Sky Survey cross-match design that compared overlapping
observations taken at different times. Cross-Matching Multiple Spatial
Observations and Dealing with Missing Data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701173</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701173</id><created>2007-01-26</created><authors><author><keyname>Singh</keyname><forenames>Vik</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Thakar</keyname><forenames>Ani</forenames></author><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author><author><keyname>Raddick</keyname><forenames>Jordan</forenames></author><author><keyname>Boroski</keyname><forenames>Bill</forenames></author><author><keyname>Lebedeva</keyname><forenames>Svetlana</forenames></author><author><keyname>Yanny</keyname><forenames>Brian</forenames></author></authors><title>SkyServer Traffic Report - The First Five Years</title><categories>cs.DB cs.CE</categories><proxy>gray</proxy><report-no>MSR TR-2006-190</report-no><abstract>  The SkyServer is an Internet portal to the Sloan Digital Sky Survey Catalog
Archive Server. From 2001 to 2006, there were a million visitors in 3 million
sessions generating 170 million Web hits, 16 million ad-hoc SQL queries, and 62
million page views. The site currently averages 35 thousand visitors and 400
thousand sessions per month. The Web and SQL logs are public. We analyzed
traffic and sessions by duration, usage pattern, data product, and client type
(mortal or bot) over time. The analysis shows (1) the site's popularity, (2)
the educational website that delivered nearly fifty thousand hours of
interactive instruction, (3) the relative use of interactive, programmatic, and
batch-local access, (4) the success of offering ad-hoc SQL, personal database,
and batch job access to scientists as part of the data publication, (5) the
continuing interest in &quot;old&quot; datasets, (6) the usage of SQL constructs, and (7)
a novel approach of using the corpus of correct SQL queries to suggest similar
but correct statements when a user presents an incorrect SQL statement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701174</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701174</id><created>2007-01-26</created><updated>2009-03-11</updated><authors><author><keyname>Hadzilacos</keyname><forenames>T.</forenames></author><author><keyname>Kalles</keyname><forenames>D.</forenames></author><author><keyname>Koumanakos</keyname><forenames>D.</forenames></author><author><keyname>Mitsionis</keyname><forenames>V.</forenames></author></authors><title>A Prototype for Educational Planning Using Course Constraints to
  Simulate Student Populations</title><categories>cs.AI cs.CY cs.DS cs.SC</categories><comments>Contains 9 pages, 3 figures, 1 table. Text updated as of February 27,
  2009. Submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance learning universities usually afford their students the flexibility
to advance their studies at their own pace. This can lead to a considerable
fluctuation of student populations within a program's courses, possibly
affecting the academic viability of a program as well as the related required
resources. Providing a method that estimates this population could be of
substantial help to university management and academic personnel. We describe
how to use course precedence constraints to calculate alternative tuition paths
and then use Markov models to estimate future populations. In doing so, we
identify key issues of a large scale potential deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701175</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701175</id><created>2007-01-26</created><authors><author><keyname>Hadzilacos</keyname><forenames>Th.</forenames></author><author><keyname>Kalles</keyname><forenames>D.</forenames></author><author><keyname>Pouliopoulou</keyname><forenames>M.</forenames></author></authors><title>On the Software and Knowledge Engineering Aspects of the Educational
  Process</title><categories>cs.SE cs.DL</categories><comments>Contains 21 sparse pages, 8 figures. Accepted for publication in
  International Journal of Software Engineering and Knowledge Engineering
  (IJSEKE). Keywords: Tools for interactive learning and teaching, Modelling,
  Distance Learning</comments><abstract>  The Hellenic Open University has embarked on a large-scale effort to enhance
its textbook-based material with content that demonstrably supports the basic
tenets of distance learning. The challenge is to set up a framework that allows
for the production-level creation, distribution and consumption of content, and
at the same time, evaluate the effort in terms of technological, educational
and organizational knowledge gained. This paper presents a model of the
educational process that is used as a development backbone and argues about its
conceptual and technical practicality at large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701176</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701176</id><created>2007-01-26</created><authors><author><keyname>Frisch</keyname><forenames>Alain</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Hosoya</keyname><forenames>Haruo</forenames><affiliation>CST</affiliation></author></authors><title>Towards Practical Typechecking for Macro Tree Transducers</title><categories>cs.PL</categories><proxy>ccsd inria-00126895</proxy><abstract>  Macro tree transducers (mtt) are an important model that both covers many
useful XML transformations and allows decidable exact typechecking. This paper
reports our first step toward an implementation of mtt typechecker that has a
practical efficiency. Our approach is to represent an input type obtained from
a backward inference as an alternating tree automaton, in a style similar to
Tozawa's XSLT0 typechecking. In this approach, typechecking reduces to checking
emptiness of an alternating tree automaton. We propose several optimizations
(Cartesian factorization, state partitioning) on the backward inference process
in order to produce much smaller alternating tree automata than the naive
algorithm, and we present our efficient algorithm for checking emptiness of
alternating tree automata, where we exploit the explicit representation of
alternation for local optimizations. Our preliminary experiments confirm that
our algorithm has a practical performance that can typecheck simple
transformations with respect to the full XHTML in a reasonable time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701177</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701177</id><created>2007-01-26</created><updated>2008-08-17</updated><authors><author><keyname>Chakraborty</keyname><forenames>Roudra</forenames></author><author><keyname>Sengupta</keyname><forenames>Debapriya</forenames></author><author><keyname>Sinha</keyname><forenames>Sagnik</forenames></author></authors><title>Pitch Tracking of Acoustic Signals based on Average Squared Mean
  Difference Function</title><categories>cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a method of pitch tracking based on variance minimization of
locally periodic subsamples of an acoustic signal is presented. Replicates
along the length of the periodically sampled data of the signal vector are
taken and locally averaged sample variances are minimized to estimate the
fundamental frequency. Using this method, pitch tracking of any text
independent voiced signal is possible for different speakers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701178</identifier>
 <datestamp>2008-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701178</id><created>2007-01-26</created><updated>2008-03-18</updated><authors><author><keyname>Ermis</keyname><forenames>Erhan B.</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Distributed Detection in Sensor Networks with Limited Range Sensors</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><abstract>  We consider a multi-object detection problem over a sensor network (SNET)
with limited range sensors. This problem complements the widely considered
decentralized detection problem where all sensors observe the same object.
While the necessity for global collaboration is clear in the decentralized
detection problem, the benefits of collaboration with limited range sensors is
unclear and has not been widely explored. In this paper we develop a
distributed detection approach based on recent development of the false
discovery rate (FDR). We first extend the FDR procedure and develop a
transformation that exploits complete or partial knowledge of either the
observed distributions at each sensor or the ensemble (mixture) distribution
across all sensors. We then show that this transformation applies to
multi-dimensional observations, thus extending FDR to multi-dimensional
settings. We also extend FDR theory to cases where distributions under both
null and positive hypotheses are uncertain. We then propose a robust
distributed algorithm to perform detection. We further demonstrate scalability
to large SNETs by showing that the upper bound on the communication complexity
scales linearly with the number of sensors that are in the vicinity of objects
and is independent of the total number of sensors. Finally, we deal with
situations where the sensing model may be uncertain and establish robustness of
our techniques to such uncertainties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701179</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701179</id><created>2007-01-27</created><authors><author><keyname>Dieudonn&#xe9;</keyname><forenames>Yoann</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LaRIA</affiliation></author></authors><title>Scatter of Weak Robots</title><categories>cs.DC</categories><proxy>ccsd hal-00126990</proxy><abstract>  In this paper, we first formalize the problem to be solved, i.e., the Scatter
Problem (SP). We then show that SP cannot be deterministically solved. Next, we
propose a randomized algorithm for this problem. The proposed solution is
trivially self-stabilizing. We then show how to design a self-stabilizing
version of any deterministic solution for the Pattern Formation and the
Gathering problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701180</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701180</id><created>2007-01-27</created><authors><author><keyname>Murtagh</keyname><forenames>F.</forenames></author><author><keyname>Mothe</keyname><forenames>J.</forenames></author><author><keyname>Englmeier</keyname><forenames>K.</forenames></author></authors><title>Ontology from Local Hierarchical Structure in Text</title><categories>cs.IR</categories><comments>35 pp., 12 figures</comments><acm-class>H.5; I.5.3; H.5.2; I.7.2; H.3</acm-class><abstract>  We study the notion of hierarchy in the context of visualizing textual data
and navigating text collections. A formal framework for ``hierarchy'' is given
by an ultrametric topology. This provides us with a theoretical foundation for
concept hierarchy creation. A major objective is {\em scalable} annotation or
labeling of concept maps. Serendipitously we pursue other objectives such as
deriving common word pair (and triplet) phrases, i.e., word 2- and 3-grams. We
evaluate our approach using (i) a collection of texts, (ii) a single text
subdivided into successive parts (for which we provide an interactive
demonstrator), and (iii) a text subdivided at the sentence or line level. While
detailing a generic framework, a distinguishing feature of our work is that we
focus on {\em locality} of hierarchic structure in order to extract semantic
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701181</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701181</id><created>2007-01-27</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>A Note on Local Ultrametricity in Text</title><categories>cs.CL</categories><comments>18 pp</comments><acm-class>I.5.3; I.7.2; H.3</acm-class><abstract>  High dimensional, sparsely populated data spaces have been characterized in
terms of ultrametric topology. This implies that there are natural, not
necessarily unique, tree or hierarchy structures defined by the ultrametric
topology. In this note we study the extent of local ultrametric topology in
texts, with the aim of finding unique ``fingerprints'' for a text or corpus,
discriminating between texts from different domains, and opening up the
possibility of exploiting hierarchical structures in the data. We use coherent
and meaningful collections of over 1000 texts, comprising over 1.3 million
words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701182</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701182</id><created>2007-01-28</created><authors><author><keyname>Burnashev</keyname><forenames>Marat</forenames></author></authors><title>Supplement to: Code Spectrum and Reliability Function: Binary Symmetric
  Channel</title><categories>cs.IT math.IT</categories><comments>to appear in Problems of Information Transmission, 2007, v. 43, no. 1</comments><abstract>  A much simpler proof of Theorem 1 from M.Burnashev &quot;Code spectrum and
reliability function: Binary symmetric channel&quot; is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701183</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701183</id><created>2007-01-29</created><authors><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Certification of the QR factor R, and of lattice basis reducedness</title><categories>cs.SC cs.NA</categories><proxy>ccsd hal-00127059</proxy><report-no>Vil06-1</report-no><acm-class>I.1.2; F.2.1; G.1.3; G.4</acm-class><abstract>  Given a lattice basis of n vectors in Z^n, we propose an algorithm using
12n^3+O(n^2) floating point operations for checking whether the basis is
LLL-reduced. If the basis is reduced then the algorithm will hopefully answer
''yes''. If the basis is not reduced, or if the precision used is not
sufficient with respect to n, and to the numerical properties of the basis, the
algorithm will answer ''failed''. Hence a positive answer is a rigorous
certificate. For implementing the certificate itself, we propose a floating
point algorithm for computing (certified) error bounds for the entries of the R
factor of the QR matrix factorization. This algorithm takes into account all
possible approximation and rounding errors. The cost 12n^3+O(n^2) of the
certificate is only six times more than the cost of numerical algorithms for
computing the QR factorization itself, and the certificate may be implemented
using matrix library routines only. We report experiments that show that for a
reduced basis of adequate dimension and quality the certificate succeeds, and
establish the effectiveness of the certificate. This effectiveness is applied
for certifying the output of fastest existing floating point heuristics of LLL
reduction, without slowing down the whole process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701184</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701184</id><created>2007-01-29</created><updated>2007-02-26</updated><authors><author><keyname>Hoffmann</keyname><forenames>Joerg</forenames></author><author><keyname>Gomes</keyname><forenames>Carla</forenames></author><author><keyname>Selman</keyname><forenames>Bart</forenames></author></authors><title>Structure and Problem Hardness: Goal Asymmetry and DPLL Proofs in&lt;br&gt;
  SAT-Based Planning</title><categories>cs.AI</categories><acm-class>I.2.8; I.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (February
  26, 2007) lmcs:1170</journal-ref><doi>10.2168/LMCS-3(1:6)2007</doi><abstract>  In Verification and in (optimal) AI Planning, a successful method is to
formulate the application as boolean satisfiability (SAT), and solve it with
state-of-the-art DPLL-based procedures. There is a lack of understanding of why
this works so well. Focussing on the Planning context, we identify a form of
problem structure concerned with the symmetrical or asymmetrical nature of the
cost of achieving the individual planning goals. We quantify this sort of
structure with a simple numeric parameter called AsymRatio, ranging between 0
and 1. We run experiments in 10 benchmark domains from the International
Planning Competitions since 2000; we show that AsymRatio is a good indicator of
SAT solver performance in 8 of these domains. We then examine carefully crafted
synthetic planning domains that allow control of the amount of structure, and
that are clean enough for a rigorous analysis of the combinatorial search
space. The domains are parameterized by size, and by the amount of structure.
The CNFs we examine are unsatisfiable, encoding one planning step less than the
length of the optimal plan. We prove upper and lower bounds on the size of the
best possible DPLL refutations, under different settings of the amount of
structure, as a function of size. We also identify the best possible sets of
branching variables (backdoors). With minimum AsymRatio, we prove exponential
lower bounds, and identify minimal backdoors of size linear in the number of
variables. With maximum AsymRatio, we identify logarithmic DPLL refutations
(and backdoors), showing a doubly exponential gap between the two structural
extreme cases. The reasons for this behavior -- the proof arguments --
illuminate the prototypical patterns of structure causing the empirical
behavior observed in the competition benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701185</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701185</id><created>2007-01-29</created><updated>2014-11-14</updated><authors><author><keyname>Gurski</keyname><forenames>Frank</forenames></author></authors><title>Graph Operations on Clique-Width Bounded Graphs</title><categories>cs.DS cs.DM</categories><comments>25 pages</comments><acm-class>E.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we survey the behavior of various graph operations on the graph
parameters clique-width and NLC-width. We give upper and lower bounds for the
clique-width and NLC-width of the modified graphs in terms of the clique-width
and NLC-width of the involved graphs. Therefore we consider the binary graph
operations join, disjoint union, union, products, corona, substitution, and
1-sum, and the unary graph operations subgraph, edge complement, bipartite edge
complement, power of graphs, line graphs, local complementation, switching,
edge addition, edge deletion, edge subdivision, vertex identification, and
vertex addition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701186</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701186</id><created>2007-01-29</created><updated>2007-05-24</updated><authors><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>LIRMM, LP2A</affiliation></author><author><keyname>Melquiond</keyname><forenames>Guillaume</forenames><affiliation>LIP, INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Certification of bounds on expressions involving rounded operators</title><categories>cs.MS</categories><abstract>  Gappa uses interval arithmetic to certify bounds on mathematical expressions
that involve rounded as well as exact operators. Gappa generates a theorem with
its proof for each bound treated. The proof can be checked with a higher order
logic automatic proof checker, either Coq or HOL Light, and we have developed a
large companion library of verified facts for Coq dealing with the addition,
multiplication, division, and square root, in fixed- and floating-point
arithmetics. Gappa uses multiple-precision dyadic fractions for the endpoints
of intervals and performs forward error analysis on rounded operators when
necessary. When asked, Gappa reports the best bounds it is able to reach for a
given expression in a given context. This feature is used to quickly obtain
coarse bounds. It can also be used to identify where the set of facts and
automatic techniques implemented in Gappa becomes insufficient. Gappa handles
seamlessly additional properties expressed as interval properties or rewriting
rules in order to establish more intricate bounds. Recent work showed that
Gappa is perfectly suited to the proof of correctness of small pieces of
software. Proof obligations can be written by designers, produced by
third-party tools or obtained by overloading arithmetic operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701187</identifier>
 <datestamp>2011-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701187</id><created>2007-01-29</created><updated>2011-11-30</updated><authors><author><keyname>Chaki</keyname><forenames>Sagar</forenames></author><author><keyname>Schallhart</keyname><forenames>Christian</forenames></author><author><keyname>Veith</keyname><forenames>Helmut</forenames></author></authors><title>Verification Across Intellectual Property Boundaries</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many industries, the importance of software components provided by
third-party suppliers is steadily increasing. As the suppliers seek to secure
their intellectual property (IP) rights, the customer usually has no direct
access to the suppliers' source code, and is able to enforce the use of
verification tools only by legal requirements. In turn, the supplier has no
means to convince the customer about successful verification without revealing
the source code. This paper presents an approach to resolve the conflict
between the IP interests of the supplier and the quality interests of the
customer. We introduce a protocol in which a dedicated server (called the
&quot;amanat&quot;) is controlled by both parties: the customer controls the verification
task performed by the amanat, while the supplier controls the communication
channels of the amanat to ensure that the amanat does not leak information
about the source code. We argue that the protocol is both practically useful
and mathematically sound. As the protocol is based on well-known (and
relatively lightweight) cryptographic primitives, it allows a straightforward
implementation on top of existing verification tool chains. To substantiate our
security claims, we establish the correctness of the protocol by cryptographic
reduction proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701188</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701188</id><created>2007-01-29</created><authors><author><keyname>Eberly</keyname><forenames>Wayne</forenames><affiliation>UCALGARY</affiliation></author><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames><affiliation>UWO</affiliation></author><author><keyname>Giorgi</keyname><forenames>Pascal</forenames><affiliation>LP2A</affiliation></author><author><keyname>Storjohann</keyname><forenames>Arne</forenames><affiliation>UWO</affiliation></author><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Faster Inversion and Other Black Box Matrix Computations Using Efficient
  Block Projections</title><categories>cs.SC cs.NA</categories><proxy>ccsd hal-00127807</proxy><report-no>EGGSV07-1</report-no><acm-class>I.1.2; F.2.1; G.1.3; G.4</acm-class><abstract>  Block projections have been used, in [Eberly et al. 2006], to obtain an
efficient algorithm to find solutions for sparse systems of linear equations. A
bound of softO(n^(2.5)) machine operations is obtained assuming that the input
matrix can be multiplied by a vector with constant-sized entries in softO(n)
machine operations. Unfortunately, the correctness of this algorithm depends on
the existence of efficient block projections, and this has been conjectured. In
this paper we establish the correctness of the algorithm from [Eberly et al.
2006] by proving the existence of efficient block projections over sufficiently
large fields. We demonstrate the usefulness of these projections by deriving
improved bounds for the cost of several matrix problems, considering, in
particular, ``sparse'' matrices that can be be multiplied by a vector using
softO(n) field operations. We show how to compute the inverse of a sparse
matrix over a field F using an expected number of softO(n^(2.27)) operations in
F. A basis for the null space of a sparse matrix, and a certification of its
rank, are obtained at the same cost. An application to Kaltofen and Villard's
Baby-Steps/Giant-Steps algorithms for the determinant and Smith Form of an
integer matrix yields algorithms requiring softO(n^(2.66)) machine operations.
The derived algorithms are all probabilistic of the Las Vegas type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701189</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701189</id><created>2007-01-30</created><authors><author><keyname>Manne</keyname><forenames>Fredrik</forenames><affiliation>LRI</affiliation></author><author><keyname>Mjelde</keyname><forenames>Morten</forenames><affiliation>LRI</affiliation></author><author><keyname>Pilard</keyname><forenames>Laurence</forenames><affiliation>LRI</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LRI</affiliation></author></authors><title>A New Self-Stabilizing Maximal Matching Algorithm</title><categories>cs.DS cs.DC</categories><proxy>ccsd inria-00127899</proxy><abstract>  The maximal matching problem has received considerable attention in the
self-stabilizing community. Previous work has given different self-stabilizing
algorithms that solves the problem for both the adversarial and fair
distributed daemon, the sequential adversarial daemon, as well as the
synchronous daemon. In the following we present a single self-stabilizing
algorithm for this problem that unites all of these algorithms in that it
stabilizes in the same number of moves as the previous best algorithms for the
sequential adversarial, the distributed fair, and the synchronous daemon. In
addition, the algorithm improves the previous best moves complexities for the
distributed adversarial daemon from O(n^2) and O(delta m) to O(m) where n is
the number of processes, m is thenumber of edges, and delta is the maximum
degree in the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701190</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701190</id><created>2007-01-29</created><authors><author><keyname>Jacobs</keyname><forenames>Thomas</forenames></author><author><keyname>Harwood</keyname><forenames>Aaron</forenames></author></authors><title>A Peer-to-Peer Browsable File Index using a Popularity Based Global
  Namespace</title><categories>cs.DC cs.NI</categories><acm-class>C.2.4</acm-class><abstract>  The distribution of files using decentralized, peer-to-peer (P2P) systems,
has significant advantages over centralized approaches. It is however more
difficult to settle on the best approach for file sharing. Most file sharing
systems are based on query string searches, leading to a relatively simple but
inefficient broadcast or to an efficient but relatively complicated index in a
structured environment. In this paper we use a browsable peer-to-peer file
index consisting of files which serve as directory nodes, interconnecting to
form a directory network. We implemented the system based on BitTorrent and
Kademlia. The directory network inherits all of the advantages of
decentralization and provides browsable, efficient searching. To avoid conflict
between users in the P2P system while also imposing no additional restrictions,
we allow multiple versions of each directory node to simultaneously exist --
using popularity as the basis for default browsing behavior. Users can freely
add files and directory nodes to the network. We show, using a simulation of
user behavior and file quality, that the popularity based system consistently
leads users to a high quality directory network; above the average quality of
user updates. Q
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701191</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701191</id><created>2007-01-30</created><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>LIENS</affiliation></author></authors><title>The parallel implementation of the Astr\'{e}e static analyzer</title><categories>cs.PL cs.PF</categories><proxy>ccsd hal-00128097</proxy><acm-class>D.2.4</acm-class><journal-ref>APLAS: Programming languages and systems (2005) 86-96</journal-ref><doi>10.1007/11575467_7</doi><abstract>  The Astr\'{e}e static analyzer is a specialized tool that can prove the
absence of runtime errors, including arithmetic overflows, in large critical
programs. Keeping analysis times reasonable for industrial use is one of the
design objectives. In this paper, we discuss the parallel implementation of the
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701192</identifier>
 <datestamp>2008-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701192</id><created>2007-01-30</created><updated>2008-05-22</updated><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>LIENS, Verimag - Imag</affiliation></author></authors><title>The pitfalls of verifying floating-point computations</title><categories>cs.PL cs.NA</categories><acm-class>D.2.4; D.3.1; F.3.1; G.1.0; G.4</acm-class><journal-ref>ACM Transactions on Programming Languages and Systems 30, 3 (2008)
  12</journal-ref><doi>10.1145/1353445.1353446</doi><abstract>  Current critical systems commonly use a lot of floating-point computations,
and thus the testing or static analysis of programs containing floating-point
operators has become a priority. However, correctly defining the semantics of
common implementations of floating-point is tricky, because semantics may
change with many factors beyond source-code level, such as choices made by
compilers. We here give concrete examples of problems that can appear and
solutions to implement in analysis software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701193</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701193</id><created>2007-01-30</created><authors><author><keyname>Blanchet</keyname><forenames>Bruno</forenames><affiliation>LIENS</affiliation></author><author><keyname>Cousot</keyname><forenames>Patrick</forenames><affiliation>LIENS</affiliation></author><author><keyname>Cousot</keyname><forenames>Radhia</forenames><affiliation>STIX</affiliation></author><author><keyname>Feret</keyname><forenames>Jer&#xf4;me</forenames><affiliation>LIENS</affiliation></author><author><keyname>Mauborgne</keyname><forenames>Laurent</forenames><affiliation>LIENS</affiliation></author><author><keyname>Min&#xe9;</keyname><forenames>Antoine</forenames><affiliation>LIENS</affiliation></author><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>LIENS</affiliation></author><author><keyname>Rival</keyname><forenames>Xavier</forenames><affiliation>LIENS</affiliation></author></authors><title>A Static Analyzer for Large Safety-Critical Software</title><categories>cs.PL cs.PF</categories><proxy>ccsd hal-00128135</proxy><acm-class>D.2.4; D.3.1; F.3.1; F.3.2</acm-class><journal-ref>PLDI: Conference on Programming Language Design and Implementation
  (2003) 196 - 207</journal-ref><doi>10.1145/781131.781153</doi><abstract>  We show that abstract interpretation-based static program analysis can be
made efficient and precise enough to formally verify a class of properties for
a family of large programs with few or no false alarms. This is achieved by
refinement of a general purpose static analyzer and later adaptation to
particular programs of the family by the end-user through parametrization. This
is applied to the proof of soundness of data manipulation operations at the
machine level for periodic synchronous safety critical embedded software. The
main novelties are the design principle of static analyzers by refinement and
adaptation through parametrization, the symbolic manipulation of expressions to
improve the precision of abstract transfer functions, the octagon, ellipsoid,
and decision tree abstract domains, all with sound handling of rounding errors
in floating point computations, widening strategies (with thresholds, delayed)
and the automatic determination of the parameters (parametrized packing).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701194</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701194</id><created>2007-01-30</created><authors><author><keyname>Buk</keyname><forenames>Solomija</forenames></author><author><keyname>Rovenchak</keyname><forenames>Andrij</forenames></author></authors><title>Menzerath-Altmann Law for Syntactic Structures in Ukrainian</title><categories>cs.CL</categories><comments>8 pages; submitted to the Proceedings of the International scientific
  conference on Modern Methods in Linguistics held in honour of the anniversary
  of Prof. Gabriel L. Altmann (October 23rd and 24th, 2006, Budmerice Castle,
  Slovakia)</comments><journal-ref>Glottotheory. Vol. 1, No. 1, pp 10-17 (2008)</journal-ref><abstract>  In the paper, the definition of clause suitable for an automated processing
of a Ukrainian text is proposed. The Menzerath-Altmann law is verified on the
sentence level and the parameters for the dependences of the clause length
counted in words and syllables on the sentence length counted in clauses are
calculated for &quot;Perekhresni Stezhky&quot; (&quot;The Cross-Paths&quot;), a novel by Ivan
Franko.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701195</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701195</id><created>2007-01-30</created><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>LIENS</affiliation></author></authors><title>An Abstract Monte-Carlo Method for the Analysis of Probabilistic
  Programs</title><categories>cs.PL cs.PF</categories><proxy>ccsd hal-00128138</proxy><journal-ref>POPL: Annual Symposium on Principles of Programming Languages
  (2001) 93 - 101</journal-ref><doi>10.1145/360204.360211</doi><abstract>  We introduce a new method, combination of random testing and abstract
interpretation, for the analysis of programs featuring both probabilistic and
non-probabilistic nondeterminism. After introducing &quot;ordinary&quot; testing, we show
how to combine testing and abstract interpretation and give formulas linking
the precision of the results to the number of iterations. We then discuss
complexity and optimization issues and end with some experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701196</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701196</id><created>2007-01-30</created><updated>2007-07-26</updated><authors><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>One-bit Distributed Sensing and Coding for Field Estimation in Sensor
  Networks</title><categories>cs.IT math.IT</categories><comments>Fixed typos, otherwise same as V2. 27 pages (in one column review
  format), 4 figures. Submitted to IEEE Transactions on Signal Processing.
  Current version is updated for journal submission: revised author list,
  modified formulation and framework. Previous version appeared in Proceedings
  of Allerton Conference On Communication, Control, and Computing 2006</comments><doi>10.1109/TSP.2008.926192</doi><abstract>  This paper formulates and studies a general distributed field reconstruction
problem using a dense network of noisy one-bit randomized scalar quantizers in
the presence of additive observation noise of unknown distribution. A
constructive quantization, coding, and field reconstruction scheme is developed
and an upper-bound to the associated mean squared error (MSE) at any point and
any snapshot is derived in terms of the local spatio-temporal smoothness
properties of the underlying field. It is shown that when the noise, sensor
placement pattern, and the sensor schedule satisfy certain weak technical
requirements, it is possible to drive the MSE to zero with increasing sensor
density at points of field continuity while ensuring that the per-sensor
bitrate and sensing-related network overhead rate simultaneously go to zero.
The proposed scheme achieves the order-optimal MSE versus sensor density
scaling behavior for the class of spatially constant spatio-temporal fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701197</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701197</id><created>2007-01-30</created><updated>2008-09-30</updated><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>On Delayed Sequential Coding of Correlated Sources</title><categories>cs.IT math.IT</categories><comments>35 pages, 7 figures. This work has been submitted to the IEEE for
  possible publication. Parts of this work were presented at 2007 Information
  Theory and Applications Workshop (ITA'07) and 2007 IEEE International
  Symposium on Information Theory (ISIT'07)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by video coding applications, the problem of sequential coding of
correlated sources with encoding and/or decoding frame-delays is studied. The
fundamental tradeoffs between individual frame rates, individual frame
distortions, and encoding/decoding frame-delays are derived in terms of a
single-letter information-theoretic characterization of the rate-distortion
region for general inter-frame source correlations and certain types of
potentially frame specific and coupled single-letter fidelity criteria. The
sum-rate-distortion region is characterized in terms of generalized directed
information measures highlighting their role in delayed sequential source
coding problems. For video sources which are spatially stationary memoryless
and temporally Gauss-Markov, MSE frame distortions, and a sum-rate constraint,
our results expose the optimality of idealized differential predictive coding
among all causal sequential coders, when the encoder uses a positive rate to
describe each frame. Somewhat surprisingly, causal sequential encoding with
one-frame-delayed noncausal sequential decoding can exactly match the
sum-rate-MSE performance of joint coding for all nontrivial MSE-tuples
satisfying certain positive semi-definiteness conditions. Thus, even a single
frame-delay holds potential for yielding significant performance improvements.
Generalizations to higher order Markov sources are also presented and
discussed. A rate-distortion performance equivalence between, causal sequential
encoding with delayed noncausal sequential decoding, and, delayed noncausal
sequential encoding with causal sequential decoding, is also established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701198</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701198</id><created>2007-01-30</created><authors><author><keyname>D'Souza</keyname><forenames>R. M.</forenames></author><author><keyname>Borgs</keyname><forenames>C.</forenames></author><author><keyname>Chayes</keyname><forenames>J. T.</forenames></author><author><keyname>Berger</keyname><forenames>N.</forenames></author><author><keyname>Kleinberg</keyname><forenames>R. D.</forenames></author></authors><title>Fitting the WHOIS Internet data</title><categories>cs.NI</categories><comments>Supplemental information for &quot;Emergence of Tempered Preferential
  Attachment From Optimization&quot;, to appear (open access) PNAS USA, 2007</comments><abstract>  We consider the RIPE WHOIS Internet data as characterized by the Cooperative
Association for Internet Data Analysis (CAIDA), and show that the Tempered
Preferential Attachment model [1] provides an excellent fit to this data.
  [1] D'Souza, Borgs, Chayes, Berger and Kleinberg, to appear PNAS USA, 2007.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701199</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701199</id><created>2007-01-31</created><updated>2007-05-24</updated><authors><author><keyname>Norte</keyname><forenames>Stephane</forenames></author><author><keyname>Lobo</keyname><forenames>Fernando G.</forenames></author></authors><title>A Virtual Logo Keyboard for People with Motor Disabilities</title><categories>cs.HC</categories><comments>11 pages, 6 figures</comments><report-no>200701</report-no><acm-class>H.5.2; K.3.1; K.4.2</acm-class><abstract>  In our society, people with motor impairments are oftentimes socially
excluded from their environment. This is unfortunate because every human being
should have the possibility to obtain the necessary conditions to live a normal
life. Although there is technology to assist people with motor impairments, few
systems are targeted for programming environments. We have created a system,
called Logo Keyboard, to assist people with motor disabilities to program with
the Logo programming language. With this special keyboard we can help more
people to get involved into computer programming and to develop projects in
different areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0701200</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0701200</id><created>2007-01-31</created><authors><author><keyname>Detienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>Reasoning from a schema and from an analog in software code reuse</title><categories>cs.SE</categories><proxy>ccsd inria-00128343</proxy><journal-ref>Dans Fourth Workshop on Empirical Studies of Programmers, ESP91
  (1991) 5-22</journal-ref><abstract>  The activity of design involves the decomposition of problems into
subproblems and the development and evaluation of solutions. In many cases,
solution development is not done from scratch. Designers often evoke and adapt
solutions developed in the past. These solutions may come from an internal
source, i.e. the memory of the designers, and/or from an external source. The
goal of this paper is to analyse the characteristics of the cognitive
mechanisms, the knowledge and the representations involved in the code reuse
activity performed by experienced programmers. More generally, the focus is the
control structure of the reuse activity. Data collected in an experiment in
which programmers had to design programs are analyzed. Two code reuse
situations are distinguished depending on whether or not the processes involved
in reuse start before the elaboration of what acts as a source-solution. Our
analysis highlights the use of reasoning from a schema and from an analog in
the code reuse activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702001</id><created>2007-02-01</created><authors><author><keyname>Robillard</keyname><forenames>Pierre</forenames><affiliation>INRIA</affiliation></author><author><keyname>D'Astous</keyname><forenames>Patrick</forenames><affiliation>INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>INRIA</affiliation></author></authors><title>Measuring Cognitive Activities in Software Engineering</title><categories>cs.HC</categories><proxy>ccsd inria-00128348</proxy><journal-ref>Dans ICSE98, 20th International Conference on Software Engineering
  (1998)</journal-ref><abstract>  This paper presents an approach to the study of cognitive activities in
collaborative software development. This approach has been developed by a
multidisciplinary team made up of software engineers and cognitive
psychologists. The basis of this approach is to improve our understanding of
software development by observing professionals at work. The goal is to derive
lines of conduct or good practices based on observations and analyses of the
processes that are naturally used by software engineers. The strategy involved
is derived from a standard approach in cognitive science. It is based on the
videotaping of the activities of software engineers, transcription of the
videos, coding of the transcription, defining categories from the coded
episodes and defining cognitive behaviors or dialogs from the categories. This
project presents two original contributions that make this approach generic in
software engineering. The first contribution is the introduction of a formal
hierarchical coding scheme, which will enable comparison of various types of
observations. The second is the merging of psychological and statistical
analysis approaches to build a cognitive model. The details of this new
approach are illustrated with the initial data obtained from the analysis of
technical review meetings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702002</id><created>2007-02-01</created><authors><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>INRIA, LEI</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Wiedenbeck</keyname><forenames>Susan</forenames></author></authors><title>The Effect of Object-Oriented Programming Expertise in Several
  Dimensions of Comprehension Strategies</title><categories>cs.HC</categories><proxy>ccsd inria-00128351</proxy><journal-ref>Dans IWPC'98, Sixth International Workshop on Program
  Comprehension (1998)</journal-ref><abstract>  This study analyzes object-oriented (OO) program comprehension by experts and
novices. We examine the effect of expertise in three dimensions of
comprehension strategies: the scope of the comprehension, the top-down versus
bottom-up direction of the processes, and the guidance of the comprehension
activity. Overall, subjects were similar in the scope of their comprehension,
although the experts tended to consult more files. We found strong evidence of
top-down, inference-driven behaviors, as well as multiple guidance in expert
comprehension. We also found evidence of execution-based guidance and less use
of top-down processes in novice comprehension. Guidance by inheritance and
composition relationships in the OO program was not dominant, but nevertheless
played a substantial role in expert program comprehension. However, these
static relationships more closely tied to the OO nature of the program were
exploited poorly by novices. To conclude, these results are discussed with
respect to the literature on procedural program comprehension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702003</id><created>2007-02-01</created><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>Expert Programming Knowledge: a Schema-Based Approach</title><categories>cs.HC</categories><proxy>ccsd inria-00128352</proxy><journal-ref>Psychology of ProgrammingAcademic Press (Ed.) (1990) 205-222</journal-ref><abstract>  The topic of this chapter is the role of expert programming knowledge in the
understanding activity. In the &quot;schema-based approach&quot;, the role of semantic
structures is emphasized whereas, in the &quot;control-flow approach&quot;, the role of
syntactic structures is emphasized. Data which support schema-based models of
understanding are presented. Data which are more consistent with the
&quot;control-flow approach&quot; allow to discuss the limits of the former kind of
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702004</id><created>2007-02-01</created><authors><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>What model(s) for program understanding?</title><categories>cs.HC</categories><proxy>ccsd inria-00128353</proxy><journal-ref>Dans UCIS'96, Conference on Using Complex Information Systems
  (1996)</journal-ref><abstract>  The first objective of this paper is to present and discuss various types of
models of program understanding. They are discussed in relation to models of
text understanding. The second objective of this paper is to assess the effect
of purpose for reading, or more specifically programming task, on the cognitive
processes involved and representations constructed in program understanding.
This is done in the theoretical framework of van Dijk and Kintsch's model of
text understanding (1983).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702005</id><created>2007-02-01</created><authors><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>INRIA, LEI</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author></authors><title>An empirical study of software reuse by experts in object-oriented
  design</title><categories>cs.HC</categories><proxy>ccsd inria-00128354</proxy><journal-ref>Dans INTERACT'95 (1995)</journal-ref><abstract>  This paper presents an empirical study of the software reuse activity by
expert designers in the context of object-oriented design. Our study focuses on
the three following aspects of reuse : (1) the interaction between some design
processes, e.g. constructing a problem representation, searching for and
evaluating solutions, and reuse processes, i.e. retrieving and using previous
solutions, (2) the mental processes involved in reuse, e.g. example-based
retrieval or bottom-up versus top-down expanding of the solution, and (3) the
mental representations constructed throughout the reuse activity, e.g. dynamic
versus static representations. Some implications of these results for the
specification of software reuse support environments are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702006</id><created>2007-02-01</created><authors><author><keyname>Martin</keyname><forenames>G&#xe9;raldine</forenames><affiliation>INRIA</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA</affiliation></author><author><keyname>Lavigne</keyname><forenames>Elisabeth</forenames></author></authors><title>Negotiation in collaborative assessment of design solutions: an
  empirical study on a Concurrent Engineering process</title><categories>cs.HC</categories><proxy>ccsd inria-00128355</proxy><journal-ref>Dans CE'2000, International Conference on Concurrent Engineering
  (2000)</journal-ref><abstract>  In Concurrent engineering, design solutions are not only produced by
individuals specialized in a given field. Due to the team nature of the design
activity, solutions are negotiated. Our objective is to analyse the
argumentation processes leading to these negotiated solutions. These processes
take place in the meetings which group together specialists with a co-design
aim. We conducted cognitive ergonomics research work during the definition
phase of an aeronautical design project in which the participants work in
Concurrent Engineering. We recorded, retranscribed and analysed 7
multi-speciality meetings. These meetings were organised, as needed, to assess
the integration of the solutions of each speciality into a global solution. We
found that there are three main design proposal assessment modes which can be
combined in these meetings: (a) analytical assessment mode, (b) comparative
assessment mode (c) analogical assessment mode. Within these assessment modes,
different types of arguments are used. Furthermore we found a typical temporal
negotiation process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702007</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702007</id><created>2007-02-01</created><authors><author><keyname>Chaporkar</keyname><forenames>Prasanna</forenames></author><author><keyname>Kansanen</keyname><forenames>Kimmo</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Ralf R.</forenames></author></authors><title>Power Optimal Scheduling for Guaranteed Throughput in Multi-access
  Fading Channels</title><categories>cs.IT math.IT</categories><abstract>  A power optimal scheduling algorithm that guarantees desired throughput and
bounded delay to each user is developed for fading multi-access multi-band
systems. The optimization is over the joint space of all rate allocation and
coding strategies. The proposed scheduling assigns rates on each band based
only on the current system state, and subsequently uses optimal multi-user
signaling to achieve these rates. The scheduling is computationally simple, and
hence scalable. Due to uplink-downlink duality, all the results extend in
straightforward fashion to the broadcast channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702008</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702008</id><created>2007-02-01</created><updated>2007-07-14</updated><authors><author><keyname>Rajan</keyname><forenames>G. Susinder</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>MMSE Optimal Algebraic Space-Time Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, journal version to appear in IEEE Transactions on
  Wireless Communications. Conference version appeared in NCC 2007, IIT Kanpur,
  India</comments><abstract>  Design of Space-Time Block Codes (STBCs) for Maximum Likelihood (ML)
reception has been predominantly the main focus of researchers. However, the ML
decoding complexity of STBCs becomes prohibitive large as the number of
transmit and receive antennas increase. Hence it is natural to resort to a
suboptimal reception technique like linear Minimum Mean Squared Error (MMSE)
receiver. Barbarossa et al and Liu et al have independently derived necessary
and sufficient conditions for a full rate linear STBC to be MMSE optimal, i.e
achieve least Symbol Error Rate (SER). Motivated by this problem, certain
existing high rate STBC constructions from crossed product algebras are
identified to be MMSE optimal. Also, it is shown that a certain class of codes
from cyclic division algebras which are special cases of crossed product
algebras are MMSE optimal. Hence, these STBCs achieve least SER when MMSE
reception is employed and are fully diverse when ML reception is employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702009</identifier>
 <datestamp>2007-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702009</id><created>2007-02-01</created><updated>2007-07-18</updated><authors><author><keyname>Venkataramanan</keyname><forenames>Ramji</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>On Evaluating the Rate-Distortion Function of Sources with Feed-Forward
  and the Capacity of Channels with Feedback</title><categories>cs.IT math.IT</categories><comments>5 pages, Submitted to ISIT 2007. Corrected typos, latest version that
  appeared in ISIT 2007</comments><abstract>  We study the problem of computing the rate-distortion function for sources
with feed-forward and the capacity for channels with feedback. The formulas
(involving directed information) for the optimal rate-distortion function with
feed-forward and channel capacity with feedback are multi-letter expressions
and cannot be computed easily in general. In this work, we derive conditions
under which these can be computed for a large class of sources/channels with
memory and distortion/cost measures. Illustrative examples are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702010</id><created>2007-02-01</created><authors><author><keyname>Carette</keyname><forenames>Jacques</forenames></author></authors><title>A canonical form for some piecewise defined functions</title><categories>cs.SC cs.MS</categories><comments>submitted to ISSAC 2007</comments><acm-class>I.1.1</acm-class><abstract>  We define a canonical form for piecewise defined functions. We show that this
has a wider range of application as well as better complexity properties than
previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702011</id><created>2007-02-01</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pucella</keyname><forenames>Riccardo</forenames></author></authors><title>Dealing With Logical Omniscience: Expressiveness and Pragmatics</title><categories>cs.LO cs.AI</categories><comments>24 pages. Submitted for publication</comments><abstract>  We examine four approaches for dealing with the logical omniscience problem
and their potential applicability: the syntactic approach, awareness,
algorithmic knowledge, and impossible possible worlds. Although in some
settings these approaches are equi-expressive and can capture all epistemic
states, in other settings of interest (especially with probability in the
picture), we show that they are not equi-expressive. We then consider the
pragmatics of dealing with logical omniscience-- how to choose an approach and
construct an appropriate model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702012</id><created>2007-02-01</created><authors><author><keyname>Sorokina</keyname><forenames>Daria</forenames></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames></author><author><keyname>Warner</keyname><forenames>Simeon</forenames></author><author><keyname>Ginsparg</keyname><forenames>Paul</forenames></author></authors><title>Plagiarism Detection in arXiv</title><categories>cs.DB cs.DL cs.IR</categories><comments>Sixth International Conference on Data Mining (ICDM'06), Dec 2006</comments><doi>10.1109/ICDM.2006.126</doi><abstract>  We describe a large-scale application of methods for finding plagiarism in
research document collections. The methods are applied to a collection of
284,834 documents collected by arXiv.org over a 14 year period, covering a few
different research disciplines. The methodology efficiently detects a variety
of problematic author behaviors, and heuristics are developed to reduce the
number of false positives. The methods are also efficient enough to implement
as a real-time submission screen for a collection many times larger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702013</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702013</id><created>2007-02-01</created><updated>2009-01-16</updated><authors><author><keyname>Gurvits</keyname><forenames>Leonid</forenames></author></authors><title>A polynomial time algorithm to approximate the mixed volume within a
  simply exponential factor</title><categories>cs.CG cs.CC math.CO</categories><comments>a journal version, accepted to Discrete and Computational Geometry</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let ${\bf K} = (K_1, ..., K_n)$ be an $n$-tuple of convex compact subsets in
the Euclidean space $\R^n$, and let $V(\cdot)$ be the Euclidean volume in
$\R^n$. The Minkowski polynomial $V_{{\bf K}}$ is defined as $V_{{\bf
K}}(\lambda_1, ... ,\lambda_n) = V(\lambda_1 K_1 +, ..., + \lambda_n K_n)$ and
the mixed volume $V(K_1, ..., K_n)$ as $$ V(K_1, ..., K_n) =
\frac{\partial^n}{\partial \lambda_1...\partial \lambda_n} V_{{\bf
K}}(\lambda_1 K_1 +, ..., + \lambda_n K_n). $$ Our main result is a poly-time
algorithm which approximates $V(K_1, ..., K_n)$ with multiplicative error $e^n$
and with better rates if the affine dimensions of most of the sets $K_i$ are
small. Our approach is based on a particular approximation of $\log(V(K_1, ...,
K_n))$ by a solution of some convex minimization problem. We prove the mixed
volume analogues of the Van der Waerden and Schrijver-Valiant conjectures on
the permanent. These results, interesting on their own, allow us to justify the
abovementioned approximation by a convex minimization, which is solved using
the ellipsoid method and a randomized poly-time time algorithm for the
approximation of the volume of a convex set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702014</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702014</id><created>2007-02-02</created><updated>2008-03-10</updated><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Karp</keyname><forenames>Richard M.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Probabilistic Analysis of Linear Programming Decoding</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear, IEEE Transactions on Information Theory, (replaces shorter
  version that appeared in SODA'07)</comments><abstract>  We initiate the probabilistic analysis of linear programming (LP) decoding of
low-density parity-check (LDPC) codes. Specifically, we show that for a random
LDPC code ensemble, the linear programming decoder of Feldman et al. succeeds
in correcting a constant fraction of errors with high probability. The fraction
of correctable errors guaranteed by our analysis surpasses previous
non-asymptotic results for LDPC codes, and in particular exceeds the best
previous finite-length result on LP decoding by a factor greater than ten. This
improvement stems in part from our analysis of probabilistic bit-flipping
channels, as opposed to adversarial channels. At the core of our analysis is a
novel combinatorial characterization of LP decoding success, based on the
notion of a generalized matching. An interesting by-product of our analysis is
to establish the existence of ``probabilistic expansion'' in random bipartite
graphs, in which one requires only that almost every (as opposed to every) set
of a certain size expands, for sets much larger than in the classical
worst-case setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702015</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702015</id><created>2007-02-02</created><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Network Coding for Distributed Storage Systems</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in INFOCOM 2007</comments><abstract>  Peer-to-peer distributed storage systems provide reliable access to data
through redundancy spread over nodes across the Internet. A key goal is to
minimize the amount of bandwidth used to maintain that redundancy. Storing a
file using an erasure code, in fragments spread across nodes, promises to
require less redundancy and hence less maintenance bandwidth than simple
replication to provide the same level of reliability. However, since fragments
must be periodically replaced as nodes fail, a key question is how to generate
a new fragment in a distributed way while transferring as little data as
possible across the network.
  In this paper, we introduce a general technique to analyze storage
architectures that combine any form of coding and replication, as well as
presenting two new schemes for maintaining redundancy using erasure codes.
First, we show how to optimally generate MDS fragments directly from existing
fragments in the system. Second, we introduce a new scheme called Regenerating
Codes which use slightly larger fragments than MDS but have lower overall
bandwidth use. We also show through simulation that in realistic environments,
Regenerating Codes can reduce maintenance bandwidth use by 25 percent or more
compared with the best previous design--a hybrid of replication and erasure
codes--while simplifying system architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702016</identifier>
 <datestamp>2008-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702016</id><created>2007-02-02</created><updated>2007-03-27</updated><authors><author><keyname>Courcelle</keyname><forenames>Bruno</forenames><affiliation>LaBRI</affiliation></author></authors><title>A multivariate interlace polynomial</title><categories>cs.LO cs.DM</categories><comments>Draft version ; will be expanded before submission to a journal</comments><proxy>ccsd hal-00128622</proxy><journal-ref>Electronic Journal of Combinatories 15, 1 (2008) R69</journal-ref><abstract>  We define a multivariate polynomial that generalizes several interlace
polynomials defined by Arratia, Bollobas and Sorkin on the one hand, and Aigner
and van der Holst on the other. We follow the route traced by Sokal, who
defined a multivariate generalization of Tutte's polynomial. We also show that
bounded portions of our interlace polynomial can be evaluated in polynomial
time for graphs of bounded clique-width. Its full evaluation is necessarly
exponential just because of the size of the result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702017</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702017</id><created>2007-02-02</created><authors><author><keyname>Aulin</keyname><forenames>Tor M.</forenames></author></authors><title>Comment on Improved Analysis of List Decoding and Its Application to
  Convolutional Codes and Turbo Codes</title><categories>cs.IT math.IT</categories><comments>3 pages</comments><abstract>  In a recent paper [1] an improved analysis concerning the analysis of List
Decoding was presented. The event that the correct codeword is excluded from
the list is central. For the additive white Gaussian noise (AWGN) channel an
important quantity is the in [1] called effective Euclidean distance. This was
earlier considered in [2] under the name Vector Euclidean Distance, where also
a simple mathematical expression for this quantity was easily derived for any
list size. In [1], a geometrical analysis gives this when the list size is 1, 2
or 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702018</identifier>
 <datestamp>2013-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702018</id><created>2007-02-02</created><updated>2008-04-11</updated><authors><author><keyname>Harrison</keyname><forenames>M. T.</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>I.</forenames></author></authors><title>Estimation of the Rate-Distortion Function</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>18 pages, no figures [v2: removed an example with an error; corrected
  typos; a shortened version will appear in IEEE Trans. Inform. Theory]</comments><journal-ref>IEEE Transactions on Information Theory, 54 (2008): 3757-3762</journal-ref><doi>10.1109/TIT.2008.926387</doi><abstract>  Motivated by questions in lossy data compression and by theoretical
considerations, we examine the problem of estimating the rate-distortion
function of an unknown (not necessarily discrete-valued) source from empirical
data. Our focus is the behavior of the so-called &quot;plug-in&quot; estimator, which is
simply the rate-distortion function of the empirical distribution of the
observed data. Sufficient conditions are given for its consistency, and
examples are provided to demonstrate that in certain cases it fails to converge
to the true rate-distortion function. The analysis of its performance is
complicated by the fact that the rate-distortion function is not continuous in
the source distribution; the underlying mathematical problem is closely related
to the classical problem of establishing the consistency of maximum likelihood
estimators. General consistency results are given for the plug-in estimator
applied to a broad class of sources, including all stationary and ergodic ones.
A more general class of estimation problems is also considered, arising in the
context of lossy data compression when the allowed class of coding
distributions is restricted; analogous results are developed for the plug-in
estimator in that case. Finally, consistency theorems are formulated for
modified (e.g., penalized) versions of the plug-in, and for estimating the
optimal reproduction distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702019</id><created>2007-02-02</created><authors><author><keyname>Gariel</keyname><forenames>Maxime</forenames></author><author><keyname>Clarke</keyname><forenames>John-Paul</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>A Dynamic I/O Model for TRACON Traffic Management</title><categories>cs.OH</categories><comments>16 pages, 19 figures eps</comments><abstract>  This work investigates the TRACON flow management around a major airport.
Aircraft flows are analyzed through a study of TRACON trajectories records.
Rerouting and queuing processes are highlighted and airport characteristics are
shown as function of the number of planes in the TRACON. Then, a simple
input-output TRACON queuing and landing model is proposed. This model is
calibrated and validated using available TRACON data. It reproduces the same
phenomenon as the real system. This model is used to show the impact of
limiting the number of aircrafts in the TRACON. A limited number of aircraft
does not increase delays but reduces the controller's workload and increases
safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702020</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702020</id><created>2007-02-05</created><updated>2007-05-17</updated><authors><author><keyname>Yang</keyname><forenames>Qinqin</forenames></author><author><keyname>Qin</keyname><forenames>Zhongping</forenames></author></authors><title>Construction of Minimal Tail-Biting Trellises for Codes over Finite
  Abelian Groups</title><categories>cs.IT math.IT</categories><comments>11 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  A definition of atomic codeword for a group code is presented. Some
properties of atomic codewords of group codes are investigated. Using these
properties, it is shown that every minimal tail-biting trellis for a group code
over a finite abelian group can be constructed from its characteristic
generators, which extends the work of Koetter and Vardy who treated the case of
a linear code over a field. We also present an efficient algorithm for
constructing the minimal tail-biting trellis of a group code over a finite
abelian group, given a generator matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702021</identifier>
 <datestamp>2009-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702021</id><created>2007-02-03</created><updated>2009-11-14</updated><authors><author><keyname>Wang</keyname><forenames>Xing M.</forenames></author></authors><title>Probability Bracket Notation, Probability Vectors, Markov Chains and
  Stochastic Processes</title><categories>cs.OH math.PR</categories><comments>36 pages; two tables</comments><acm-class>G.3; J.2; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dirac notation has been widely used for vectors in Hilbert spaces of Quantum
Theories and now also in Information Retrieval. In this paper, we propose to
use Probability Bracket Notation (PBN) for probability modeling. The new
symbols are defined similarly (but not identically) as in Dirac notation. By
using PBN to represent fundamental definitions and theorems for discrete and
continuous random variables, we show that PBN could play a similar role in
probability sample space as Dirac notation in Hilbert space. We also find a
close relation between our system state P-kets and probability vectors in
Markov chains. In the end, we apply PBN to some important stochastic processes,
present the master equation of time-continuous Markov chains in both
Schrodinger and Heisenberg pictures. We identify our system state P-bra with
Doi's state function and Peliti's standard bra. We summarize the similarities
and differences between PBN and Dirac Notation in the two tables of Appendix A.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702022</id><created>2007-02-04</created><authors><author><keyname>Li</keyname><forenames>Chunxi</forenames></author><author><keyname>Chen</keyname><forenames>Changjia</forenames></author></authors><title>Gnutella: Topology Dynamics On Phase Space</title><categories>cs.NI</categories><comments>11 pages, 14 figures</comments><abstract>  In this paper, the topology dynamic of Gnutella is studied through phase
space. The dynamic changes in peer degree are studied as a time series in two
dimensional phase space which is defined as the number of connected leaves and
the number of connected ultras. The reported degrees are concentrated in three
special Software related regions that we named as Ultra Stable Region, Leaf
Stable Region and Transition Belt. A method is proposed to classify degree
traces in phase space into different classes. Connection churn then is studied
along with the churn in degree. It shows that the topological structure of
Gnutella is rather stable in its connection degree but not the topology itself.
The connection drop rate is estimated and the live time of connections is
inferred afterwards. M/M/m/m loss queue system is introduced to model the
degree keeping process in Gnutella. This model revealed that the degree stable
is ensured by large new connection efforts. In other words the stable in
topological structure of Gnutella is a results of essential unstable in its
topology. That opens a challenge to the basic design philosophy of this
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702023</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702023</id><created>2007-02-04</created><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>High-rate, Multi-Symbol-Decodable STBCs from Clifford Algebras</title><categories>cs.IT math.IT</categories><comments>5 pages; Proceedings of Thirteenth National Conference on
  Communications (NCC 2007),, IIT Kanpur, January 27-29, 2007, pp.368-372</comments><abstract>  It is well known that Space-Time Block Codes (STBCs) obtained from Orthogonal
Designs (ODs) are single-symbol-decodable (SSD) and from Quasi-Orthogonal
Designs (QODs) are double-symbol decodable. However, there are SSD codes that
are not obtainable from ODs and DSD codes that are not obtainable from QODs. In
this paper a method of constructing $g$-symbol decodable ($g$-SD) STBCs using
representations of Clifford algebras are presented which when specialized to
$g=1,2$ gives SSD and DSD codes respectively. For the number of transmit
antennas $2^a$ the rate (in complex symbols per channel use) of the $g$-SD
codes presented in this paper is $\frac{a+1-g}{2^{a-g}}$. The maximum rate of
the DSD STBCs from QODs reported in the literature is $\frac{a}{2^{a-1}}$ which
is smaller than the rate $\frac{a-1}{2^{a-2}}$ of the DSD codes of this paper,
for $2^a$ transmit antennas. In particular, the reported DSD codes for 8 and 16
transmit antennas offer rates 1 and 3/4 respectively whereas the known STBCs
from QODs offer only 3/4 and 1/2 respectively. The construction of this paper
is applicable for any number of transmit antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702024</identifier>
 <datestamp>2007-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702024</id><created>2007-02-04</created><updated>2007-07-30</updated><authors><author><keyname>Chertkov</keyname><forenames>M.</forenames><affiliation>Los Alamos</affiliation></author><author><keyname>Stepanov</keyname><forenames>M.</forenames><affiliation>UA, Tucson</affiliation></author></authors><title>Searching for low weight pseudo-codewords</title><categories>cs.IT math.IT</categories><comments>7 pages, 6 figures, proceedings of ITA'07, San Diego</comments><report-no>LA-UR # 07-0509</report-no><abstract>  Belief Propagation (BP) and Linear Programming (LP) decodings of Low Density
Parity Check (LDPC) codes are discussed. We summarize results of
instanton/pseudo-codeword approach developed for analysis of the error-floor
domain of the codes. Instantons are special, code and decoding specific,
configurations of the channel noise contributing most to the Frame-Error-Rate
(FER). Instantons are decoded into pseudo-codewords. Instanton/pseudo-codeword
with the lowest weight describes the largest Signal-to-Noise-Ratio (SNR)
asymptotic of FER, while the whole spectra of the low weight instantons is
descriptive of the FER vs SNR profile in the extended error-floor domain.
First, we describe a general optimization method that allows to find the
instantons for any coding/decoding. Second, we introduce LP-specific
pseudo-codeword search algorithm that allows efficient calculations of the
pseudo-codeword spectra. Finally, we discuss results of combined BP/LP
error-floor exploration experiments for two model codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702025</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702025</id><created>2007-02-04</created><authors><author><keyname>Pueschel</keyname><forenames>Markus</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Algebraic Signal Processing Theory: Cooley-Tukey Type Algorithms for
  DCTs and DSTs</title><categories>cs.IT cs.DS math.IT</categories><comments>31 pages, more information at http://www.ece.cmu.edu/~smart</comments><acm-class>F.2.1</acm-class><abstract>  This paper presents a systematic methodology based on the algebraic theory of
signal processing to classify and derive fast algorithms for linear transforms.
Instead of manipulating the entries of transform matrices, our approach derives
the algorithms by stepwise decomposition of the associated signal models, or
polynomial algebras. This decomposition is based on two generic methods or
algebraic principles that generalize the well-known Cooley-Tukey FFT and make
the algorithms' derivations concise and transparent. Application to the 16
discrete cosine and sine transforms yields a large class of fast algorithms,
many of which have not been found before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702026</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702026</id><created>2007-02-05</created><authors><author><keyname>Gautam</keyname><forenames>Ravi Shankar</forenames></author></authors><title>Shape preservation behavior of spline curves</title><categories>cs.GR</categories><comments>54 pages</comments><acm-class>I.3.5</acm-class><abstract>  Shape preservation behavior of a spline consists of criterial conditions for
preserving convexity, inflection, collinearity, torsion and coplanarity shapes
of data polgonal arc. We present our results which acts as an improvement in
the definitions of and provide geometrical insight into each of the above shape
preservation criteria. We also investigate the effect of various results from
the literature on various shape preservation criteria. These results have not
been earlier refered in the context of shape preservation behaviour of splines.
We point out that each curve segment need to satisfy more than one shape
preservation criteria. We investigate the conflict between different shape
preservation criteria 1)on each curve segment and 2)of adjacent curve segments.
We derive simplified formula for shape preservation criteria for cubic curve
segments. We study the shape preservation behavior of cubic Catmull-Rom splines
and see that, though being very simple spline curve, it indeed satisfy all the
shape preservation criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702027</id><created>2007-02-05</created><authors><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author></authors><title>The Suspension Calculus and its Relationship to Other Explicit
  Treatments of Substitution in Lambda Calculi</title><categories>cs.LO cs.PL</categories><comments>84 pages</comments><abstract>  The intrinsic treatment of binding in the lambda calculus makes it an ideal
data structure for representing syntactic objects with binding such as
formulas, proofs, types, and programs. Supporting such a data structure in an
implementation is made difficult by the complexity of the substitution
operation relative to lambda terms. In this paper we present the suspension
calculus, an explicit treatment of meta level binding in the lambda calculus.
We prove properties of this calculus which make it a suitable replacement for
the lambda calculus in implementation. Finally, we compare the suspension
calculus with other explicit treatments of substitution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702028</identifier>
 <datestamp>2011-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702028</id><created>2007-02-05</created><updated>2011-07-21</updated><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Dezert</keyname><forenames>Jean</forenames></author></authors><title>Uniform and Partially Uniform Redistribution Rules</title><categories>cs.AI</categories><comments>4 pages; &quot;Advances and Applications of DSmT for Plausible and
  Paradoxical reasoning for Information Fusion&quot;, International Workshop
  organized by the Bulgarian IST Centre of Competence in 21st Century, December
  14, 2006, Bulg. Acad. of Sciences, Sofia, Bulgaria</comments><acm-class>I.4.8</acm-class><journal-ref>International Journal of Uncertainty, Fuzziness and
  Knowledge-Based Systems (IJUFKS), World Scientific, Vol. 19, No. 6, 921-937,
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short paper introduces two new fusion rules for combining quantitative
basic belief assignments. These rules although very simple have not been
proposed in literature so far and could serve as useful alternatives because of
their low computation cost with respect to the recent advanced Proportional
Conflict Redistribution rules developed in the DSmT framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702029</id><created>2007-02-05</created><authors><author><keyname>Szegedy</keyname><forenames>Mario</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>On the variance of subset sum estimation</title><categories>cs.DS</categories><comments>20 pages, 1 figure</comments><acm-class>C.2.3; E.1; F.2; G.3; H.3</acm-class><abstract>  For high volume data streams and large data warehouses, sampling is used for
efficient approximate answers to aggregate queries over selected subsets.
Mathematically, we are dealing with a set of weighted items and want to support
queries to arbitrary subset sums. With unit weights, we can compute subset
sizes which together with the previous sums provide the subset averages. The
question addressed here is which sampling scheme we should use to get the most
accurate subset sum estimates.
  We present a simple theorem on the variance of subset sum estimation and use
it to prove variance optimality and near-optimality of subset sum estimation
with different known sampling schemes. This variance is measured as the average
over all subsets of any given size. By optimal we mean there is no set of input
weights for which any sampling scheme can have a better average variance. Such
powerful results can never be established experimentally. The results of this
paper are derived mathematically. For example, we show that appropriately
weighted systematic sampling is simultaneously optimal for all subset sizes.
More standard schemes such as uniform sampling and
probability-proportional-to-size sampling with replacement can be arbitrarily
bad.
  Knowing the variance optimality of different sampling schemes can help
deciding which sampling scheme to apply in a given context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702030</id><created>2007-02-05</created><authors><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author></authors><title>Optimizing the SINR operating point of spatial networks</title><categories>cs.IT math.IT</categories><comments>Presented at Information Theory and Applications Workshop, UC San
  Diego, January 2007. 7 pages</comments><abstract>  This paper addresses the following question, which is of interest in the
design and deployment of a multiuser decentralized network. Given a total
system bandwidth of W Hz and a fixed data rate constraint of R bps for each
transmission, how many frequency slots N of size W/N should the band be
partitioned into to maximize the number of simultaneous transmissions in the
network? In an interference-limited ad-hoc network, dividing the available
spectrum results in two competing effects: on the positive side, it reduces the
number of users on each band and therefore decreases the interference level
which leads to an increased SINR, while on the negative side the SINR
requirement for each transmission is increased because the same information
rate must be achieved over a smaller bandwidth. Exploring this tradeoff between
bandwidth and SINR and determining the optimum value of N in terms of the
system parameters is the focus of the paper. Using stochastic geometry, we
analytically derive the optimal SINR threshold (which directly corresponds to
the optimal spectral efficiency) on this tradeoff curve and show that it is a
function of only the path loss exponent. Furthermore, the optimal SINR point
lies between the low-SINR (power-limited) and high-SINR (bandwidth-limited)
regimes. In order to operate at this optimal point, the number of frequency
bands (i.e., the reuse factor) should be increased until the threshold SINR,
which is an increasing function of the reuse factor, is equal to the optimal
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702031</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702031</id><created>2007-02-05</created><authors><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Ravindran</keyname><forenames>Niranjay</forenames></author></authors><title>Quantized vs. Analog Feedback for the MIMO Downlink: A Comparison
  between Zero-Forcing Based Achievable Rates</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT, January 2007. 5 pages</comments><abstract>  We consider a MIMO fading broadcast channel and compare the achievable
ergodic rates when the channel state information at the transmitter is provided
by analog noisy feedback or by quantized (digital) feedback. The superiority of
digital feedback is shown, with perfect or imperfect CSIR, whenever the number
of feedback channel uses per channel coefficient is larger than 1. Also, we
show that by proper design of the digital feedback link, errors in the feedback
have a minor effect even by using very simple uncoded modulation. Finally, we
show that analog feedback achieves a fraction 1 - 2F of the optimal
multiplexing gain even in the presence of a feedback delay, when the fading
belongs to the class of Doppler processes with normalized maximum Doppler
frequency shift 0 &lt;= F &lt;= 1/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702032</id><created>2007-02-05</created><authors><author><keyname>Andersen</keyname><forenames>Reid</forenames></author></authors><title>Finding large and small dense subgraphs</title><categories>cs.DS</categories><comments>12 pages, no figures</comments><acm-class>F.2.2; G.2.2</acm-class><abstract>  We consider two optimization problems related to finding dense subgraphs. The
densest at-least-k-subgraph problem (DalkS) is to find an induced subgraph of
highest average degree among all subgraphs with at least k vertices, and the
densest at-most-k-subgraph problem (DamkS) is defined similarly. These problems
are related to the well-known densest k-subgraph problem (DkS), which is to
find the densest subgraph on exactly k vertices. We show that DalkS can be
approximated efficiently, while DamkS is nearly as hard to approximate as the
densest k-subgraph problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702033</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702033</id><created>2007-02-05</created><updated>2009-07-10</updated><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Purkayastha</keyname><forenames>Punarbasu</forenames></author></authors><title>Bounds on ordered codes and orthogonal arrays</title><categories>cs.IT math.CO math.IT</categories><comments>Final version, minor corrections</comments><journal-ref>Moscow Mathematical Journal, vol. 9, no. 2, 2009, pp. 211-243.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive new estimates of the size of codes and orthogonal arrays in the
ordered Hamming space (the Niederreiter-Rosenbloom-Tsfasman space). We also
show that the eigenvalues of the ordered Hamming scheme, the association scheme
that describes the combinatorics of the space, are given by the multivariable
Krawtchouk polynomials, and establish some of their properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702034</id><created>2007-02-06</created><authors><author><keyname>Jeganathan</keyname><forenames>L.</forenames></author><author><keyname>Rama</keyname><forenames>R.</forenames></author></authors><title>Graph Splicing System</title><categories>cs.DM</categories><comments>13 pages,5 figures</comments><acm-class>F.1.1</acm-class><abstract>  The string splicing was introduced by Tom Head which stands as an abstract
model for the DNA recombination under the influence of restriction enzymes. The
complex chemical process of three dimensional molecules in three dimensional
space can be modeled using graphs. The graph splicing systems which were
studied so far, can only be applied to a particular type of graphs which could
be interpreted as linear or circular graphs. In this paper, we take a different
and a novel approach to splice two graphs and introduce a splicing system for
graphs that can be applied to all types of graphs. Splicing two graphs can be
thought of as a new operation, among the graphs, that generates many new graphs
from the given two graphs. Taking a different line of thinking, some of the
graph theoretical results of the splicing are studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702035</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702035</id><created>2007-02-06</created><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author></authors><title>New Models for the Correlation in Sensor Data</title><categories>cs.IT math.IT</categories><comments>3 pages, 2 figures</comments><abstract>  In this paper, we propose two new models of spatial correlations in sensor
data in a data-gathering sensor network. A particular property of these models
is that if a sensor node knows in \textit{how many} bits it needs to transmit
its data, then it also knows \textit{which} bits of its data it needs to
transmit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702036</id><created>2007-02-06</created><authors><author><keyname>Dixon</keyname><forenames>Clare</forenames></author><author><keyname>Fisher</keyname><forenames>Michael</forenames></author><author><keyname>Konev</keyname><forenames>Boris</forenames></author><author><keyname>Lisitsa</keyname><forenames>Alexei</forenames></author></authors><title>Efficient First-Order Temporal Logic for Infinite-State Systems</title><categories>cs.LO</categories><comments>16 pages, 2 figures</comments><acm-class>F.4.1; F.3.1; D.2.2; D.2.4</acm-class><abstract>  In this paper we consider the specification and verification of
infinite-state systems using temporal logic. In particular, we describe
parameterised systems using a new variety of first-order temporal logic that is
both powerful enough for this form of specification and tractable enough for
practical deductive verification. Importantly, the power of the temporal
language allows us to describe (and verify) asynchronous systems, communication
delays and more complex properties such as liveness and fairness properties.
These aspects appear difficult for many other approaches to infinite-state
verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702037</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702037</id><created>2007-02-07</created><authors><author><keyname>Kim</keyname><forenames>Minkyu</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Aggarwal</keyname><forenames>Varun</forenames></author><author><keyname>O'Reilly</keyname><forenames>Una-May</forenames></author><author><keyname>Kim</keyname><forenames>Wonsik</forenames></author><author><keyname>Ahn</keyname><forenames>Chang Wook</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>Evolutionary Approaches to Minimizing Network Coding Resources</title><categories>cs.NI cs.IT math.IT</categories><comments>9 pages, 6 figures, accepted to the 26th Annual IEEE Conference on
  Computer Communications (INFOCOM 2007)</comments><abstract>  We wish to minimize the resources used for network coding while achieving the
desired throughput in a multicast scenario. We employ evolutionary approaches,
based on a genetic algorithm, that avoid the computational complexity that
makes the problem NP-hard. Our experiments show great improvements over the
sub-optimal solutions of prior methods. Our new algorithms improve over our
previously proposed algorithm in three ways. First, whereas the previous
algorithm can be applied only to acyclic networks, our new method works also
with networks with cycles. Second, we enrich the set of components used in the
genetic algorithm, which improves the performance. Third, we develop a novel
distributed framework. Combining distributed random network coding with our
distributed optimization yields a network coding protocol where the resources
used for coding are optimized in the setup phase by running our evolutionary
algorithm at each node of the network. We demonstrate the effectiveness of our
approach by carrying out simulations on a number of different sets of network
topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702038</id><created>2007-02-07</created><authors><author><keyname>Kim</keyname><forenames>Minkyu</forenames></author><author><keyname>Aggarwal</keyname><forenames>Varun</forenames></author><author><keyname>O'Reilly</keyname><forenames>Una-May</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Kim</keyname><forenames>Wonsik</forenames></author></authors><title>Genetic Representations for Evolutionary Minimization of Network Coding
  Resources</title><categories>cs.NE cs.NI</categories><comments>10 pages, 3 figures, accepted to the 4th European Workshop on the
  Application of Nature-Inspired Techniques to Telecommunication Networks and
  Other Connected Systems (EvoCOMNET 2007)</comments><abstract>  We demonstrate how a genetic algorithm solves the problem of minimizing the
resources used for network coding, subject to a throughput constraint, in a
multicast scenario. A genetic algorithm avoids the computational complexity
that makes the problem NP-hard and, for our experiments, greatly improves on
sub-optimal solutions of established methods. We compare two different genotype
encodings, which tradeoff search space size with fitness landscape, as well as
the associated genetic operators. Our finding favors a smaller encoding despite
its fewer intermediate solutions and demonstrates the impact of the modularity
enforced by genetic operators on the performance of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702039</id><created>2007-02-07</created><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Goaoc</keyname><forenames>Xavier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Holmsen</keyname><forenames>Andreas</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Petitjean</keyname><forenames>Sylvain</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Hadwiger and Helly-type theorems for disjoint unit spheres</title><categories>cs.CG</categories><proxy>ccsd inria-00103856</proxy><journal-ref>Discrete and Computational Geometry (2006)</journal-ref><abstract>  We prove Helly-type theorems for line transversals to disjoint unit balls in
$\R^{d}$. In particular, we show that a family of $n \geq 2d$ disjoint unit
balls in $\R^d$ has a line transversal if, for some ordering $\prec$ of the
balls, any subfamily of 2d balls admits a line transversal consistent with
$\prec$. We also prove that a family of $n \geq 4d-1$ disjoint unit balls in
$\R^d$ admits a line transversal if any subfamily of size $4d-1$ admits a
transversal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702040</id><created>2007-02-07</created><authors><author><keyname>Guiraud</keyname><forenames>Yves</forenames></author></authors><title>Polygraphs for termination of left-linear term rewriting systems</title><categories>cs.LO math.CT</categories><comments>15 pages</comments><acm-class>F.4</acm-class><abstract>  We present a methodology for proving termination of left-linear term
rewriting systems (TRSs) by using Albert Burroni's polygraphs, a kind of
rewriting systems on algebraic circuits. We translate the considered TRS into a
polygraph of minimal size whose termination is proven with a polygraphic
interpretation, then we get back the property on the TRS. We recall Yves
Lafont's general translation of TRSs into polygraphs and known links between
their termination properties. We give several conditions on the original TRS,
including being a first-order functional program, that ensure that we can
reduce the size of the polygraphic translation. We also prove sufficient
conditions on the polygraphic interpretations of a minimal translation to imply
termination of the original TRS. Examples are given to compare this method with
usual polynomial interpretations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702041</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702041</id><created>2007-02-07</created><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author></authors><title>The Fibers and Range of Reduction Graphs in Ciliates</title><categories>cs.LO</categories><comments>24 pages, 13 figures</comments><report-no>LIACS Technical Report 2007-01</report-no><journal-ref>Acta Informatica, Volume 45, Number 5 / July, 2008, Pages 383-402</journal-ref><doi>10.1007/s00236-008-0074-3</doi><abstract>  The biological process of gene assembly has been modeled based on three types
of string rewriting rules, called string pointer rules, defined on so-called
legal strings. It has been shown that reduction graphs, graphs that are based
on the notion of breakpoint graph in the theory of sorting by reversal, for
legal strings provide valuable insights into the gene assembly process. We
characterize which legal strings obtain the same reduction graph (up to
isomorphism), and moreover we characterize which graphs are (isomorphic to)
reduction graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702042</id><created>2007-02-07</created><authors><author><keyname>Lopes</keyname><forenames>Luis</forenames></author><author><keyname>Martins</keyname><forenames>Francisco</forenames></author><author><keyname>Silva</keyname><forenames>Miguel S.</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>A Formal Model for Programming Wireless Sensor Networks</title><categories>cs.DC cs.PL</categories><comments>14 pages, 0 figures, Submitted for Publication</comments><abstract>  In this paper we present new developments in the expressiveness and in the
theory of a Calculus for Sensor Networks (CSN). We combine a network layer of
sensor devices with a local object model to describe sensor devices with state.
The resulting calculus is quite small and yet very expressive. We also present
a type system and a type invariance result for the calculus. These results
provide the fundamental framework for the development of programming languages
and run-time environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702043</id><created>2007-02-07</created><authors><author><keyname>Ho&#xe0;ng</keyname><forenames>Ch&#xed;nh T.</forenames></author><author><keyname>Kami&#x144;ski</keyname><forenames>Marcin</forenames></author><author><keyname>Lozin</keyname><forenames>Vadim</forenames></author><author><keyname>Sawada</keyname><forenames>J.</forenames></author><author><keyname>Shu</keyname><forenames>X.</forenames></author></authors><title>Deciding k-colourability of $P_5$-free graphs in polynomial time</title><categories>cs.DS</categories><acm-class>G.2.2</acm-class><abstract>  The problem of computing the chromatic number of a $P_5$-free graph is known
to be NP-hard. In contrast to this negative result, we show that determining
whether or not a $P_5$-free graph admits a $k$-colouring, for each fixed number
of colours $k$, can be done in polynomial time. If such a colouring exists, our
algorithm produces it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702044</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702044</id><created>2007-02-07</created><updated>2008-08-11</updated><authors><author><keyname>Hunter</keyname><forenames>Andrew M.</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author></authors><title>Transmission Capacity of Ad Hoc Networks with Spatial Diversity</title><categories>cs.IT math.IT</categories><comments>16 pages, 10 figures, to appear in IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives the outage probability and transmission capacity of ad hoc
wireless networks with nodes employing multiple antenna diversity techniques,
for a general class of signal distributions. This analysis allows system
performance to be quantified for fading or non-fading environments. The
transmission capacity is given for interference-limited uniformly random
networks on the entire plane with path loss exponent $\alpha&gt;2$ in which nodes
use: (1) static beamforming through $M$ sectorized antennas, for which the
increase in transmission capacity is shown to be $\Theta(M^2)$ if the antennas
are without sidelobes, but less in the event of a nonzero sidelobe level; (2)
dynamic eigen-beamforming (maximal ratio transmission/combining), in which the
increase is shown to be $\Theta(M^{\frac{2}{\alpha}})$; (3) various transmit
antenna selection and receive antenna selection combining schemes, which give
appreciable but rapidly diminishing gains; and (4) orthogonal space-time block
coding, for which there is only a small gain due to channel hardening,
equivalent to Nakagami-$m$ fading for increasing $m$. It is concluded that in
ad hoc networks, static and dynamic beamforming perform best, selection
combining performs well but with rapidly diminishing returns with added
antennas, and that space-time block coding offers only marginal gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702045</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702045</id><created>2007-02-07</created><updated>2007-02-09</updated><authors><author><keyname>Etkin</keyname><forenames>Raul</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author><author><keyname>Wang</keyname><forenames>Hua</forenames></author></authors><title>Gaussian Interference Channel Capacity to Within One Bit</title><categories>cs.IT math.IT</categories><abstract>  The capacity of the two-user Gaussian interference channel has been open for
thirty years. The understanding on this problem has been limited. The best
known achievable region is due to Han-Kobayashi but its characterization is
very complicated. It is also not known how tight the existing outer bounds are.
In this work, we show that the existing outer bounds can in fact be arbitrarily
loose in some parameter ranges, and by deriving new outer bounds, we show that
a simplified Han-Kobayashi type scheme can achieve to within a single bit the
capacity for all values of the channel parameters. We also show that the scheme
is asymptotically optimal at certain high SNR regimes. Using our results, we
provide a natural generalization of the point-to-point classical notion of
degrees of freedom to interference-limited scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702046</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702046</id><created>2007-02-08</created><updated>2014-11-01</updated><authors><author><keyname>Su</keyname><forenames>Shenghui</forenames></author><author><keyname>Lv</keyname><forenames>Shuwang</forenames></author></authors><title>Design and Analysis of the REESSE1+ Public Key Cryptosystem v2.21</title><categories>cs.CR cs.CC</categories><comments>21 pages</comments><acm-class>F.1.3; F.2.1</acm-class><journal-ref>Theoretical Computer Science, v426-427, Apr. 2012, pp. 91-117</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the authors give the definitions of a coprime sequence and a
lever function, and describe the five algorithms and six characteristics of a
prototypal public key cryptosystem which is used for encryption and signature,
and based on three new problems and one existent problem: the multivariate
permutation problem (MPP), the anomalous subset product problem (ASPP), the
transcendental logarithm problem (TLP), and the polynomial root finding problem
(PRFP). Prove by reduction that MPP, ASPP, and TLP are computationally at least
equivalent to the discrete logarithm problem (DLP) in the same prime field, and
meanwhile find some evidence which inclines people to believe that the new
problems are harder than DLP each, namely unsolvable in DLP subexponential
time. Demonstrate the correctness of the decryption and the verification,
deduce the probability of a plaintext solution being nonunique is nearly zero,
and analyze the exact securities of the cryptosystem against recovering a
plaintext from a ciphertext, extracting a private key from a public key or a
signature, and forging a signature through known signatures, public keys, and
messages on the assumption that IFP, DLP, and LSSP can be solved. Studies
manifest that the running times of effectual attack tasks are greater than or
equal to O(2^n) so far when n = 80, 96, 112, or 128 with lgM = 696, 864, 1030,
or 1216. As viewed from utility, it should be researched further how to
decrease the length of a modulus and to increase the speed of the decryption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702047</id><created>2007-02-08</created><authors><author><keyname>Spakowski</keyname><forenames>Holger</forenames></author><author><keyname>Tripathi</keyname><forenames>Rahul</forenames></author></authors><title>Hierarchical Unambiguity</title><categories>cs.CC</categories><acm-class>F.1.2; F.1.3</acm-class><abstract>  We develop techniques to investigate relativized hierarchical unambiguous
computation. We apply our techniques to generalize known constructs involving
relativized unambiguity based complexity classes (UP and \mathcal{UP}) to new
constructs involving arbitrary higher levels of the relativized unambiguous
polynomial hierarchy (UPH). Our techniques are developed on constraints imposed
by hierarchical arrangement of unambiguous nondeterministic polynomial-time
Turing machines, and so they differ substantially, in applicability and in
nature, from standard methods (such as the switching lemma [Hastad,
Computational Limitations of Small-Depth Circuits, MIT Press, 1987]), which
play roles in carrying out similar generalizations.
  Aside from achieving these generalizations, we resolve a question posed by
Cai, Hemachandra, and Vyskoc [J. Cai, L. Hemachandra, and J. Vyskoc, Promises
and fault-tolerant database access, In K. Ambos-Spies, S. Homer, and U.
Schoening, editors, Complexity Theory, pages 101-146. Cambridge University
Press, 1993] on an issue related to nonadaptive Turing access to UP and
adaptive smart Turing access to \mathcal{UP}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702048</id><created>2007-02-08</created><authors><author><keyname>Wakita</keyname><forenames>Ken</forenames></author><author><keyname>Tsurumi</keyname><forenames>Toshiyuki</forenames></author></authors><title>Finding Community Structure in Mega-scale Social Networks</title><categories>cs.CY physics.soc-ph</categories><comments>9 pages, 15 figures</comments><acm-class>H.2.8; G.2.2; H.3</acm-class><abstract>  Community analysis algorithm proposed by Clauset, Newman, and Moore (CNM
algorithm) finds community structure in social networks. Unfortunately, CNM
algorithm does not scale well and its use is practically limited to networks
whose sizes are up to 500,000 nodes. The paper identifies that this
inefficiency is caused from merging communities in unbalanced manner. The paper
introduces three kinds of metrics (consolidation ratio) to control the process
of community analysis trying to balance the sizes of the communities being
merged. Three flavors of CNM algorithms are built incorporating those metrics.
The proposed techniques are tested using data sets obtained from existing
social networking service that hosts 5.5 million users. All the methods exhibit
dramatic improvement of execution efficiency in comparison with the original
CNM algorithm and shows high scalability. The fastest method processes a
network with 1 million nodes in 5 minutes and a network with 4 million nodes in
35 minutes, respectively. Another one processes a network with 500,000 nodes in
50 minutes (7 times faster than the original algorithm), finds community
structures that has improved modularity, and scales to a network with 5.5
million.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702049</id><created>2007-02-08</created><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Parameterized Algorithms for Directed Maximum Leaf Problems</title><categories>cs.DS cs.DM</categories><abstract>  We prove that finding a rooted subtree with at least $k$ leaves in a digraph
is a fixed parameter tractable problem. A similar result holds for finding
rooted spanning trees with many leaves in digraphs from a wide family $\cal L$
that includes all strong and acyclic digraphs. This settles completely an open
question of Fellows and solves another one for digraphs in $\cal L$. Our
algorithms are based on the following combinatorial result which can be viewed
as a generalization of many results for a `spanning tree with many leaves' in
the undirected case, and which is interesting on its own: If a digraph $D\in
\cal L$ of order $n$ with minimum in-degree at least 3 contains a rooted
spanning tree, then $D$ contains one with at least $(n/2)^{1/5}-1$ leaves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702050</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702050</id><created>2007-02-08</created><updated>2007-02-13</updated><authors><author><keyname>Hehn</keyname><forenames>Thorsten</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author><author><keyname>Laendner</keyname><forenames>Stefan</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author></authors><title>Permutation Decoding and the Stopping Redundancy Hierarchy of Linear
  Block Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2007; v2: BER/FER curves in Fig. 1 &amp; 2
  updated</comments><abstract>  We investigate the stopping redundancy hierarchy of linear block codes and
its connection to permutation decoding techniques. An element in the ordered
list of stopping redundancy values represents the smallest number of possibly
linearly dependent rows in any parity-check matrix of a code that avoids
stopping sets of a given size. Redundant parity-check equations can be shown to
have a similar effect on decoding performance as permuting the coordinates of
the received codeword according to a selected set of automorphisms of the code.
Based on this finding we develop new decoding strategies for data transmission
over the binary erasure channel that combine iterative message passing and
permutation decoding in order to avoid errors confined to stopping sets. We
also introduce the notion of s-SAD sets, containing the smallest number of
automorphisms of a code with the property that they move any set of not more
than s erasures into positions that do not correspond to stopping sets within a
judiciously chosen parity-check matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702051</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702051</id><created>2007-02-08</created><authors><author><keyname>Tekin</keyname><forenames>Ender</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>The Gaussian multiple access wire-tap channel: wireless secrecy and
  cooperative jamming</title><categories>cs.IT cs.CR math.IT</categories><comments>Presented at the Information Theory and Applications Workshop, ITA07,
  February 2007, San Diego, CA</comments><abstract>  We consider the General Gaussian Multiple Access Wire-Tap Channel (GGMAC-WT).
In this scenario, multiple users communicate with an intended receiver in the
presence of an intelligent and informed eavesdropper. We define two suitable
secrecy measures, termed individual and collective, to reflect the confidence
in the system for this multi-access environment. We determine achievable rates
such that secrecy to some pre-determined degree can be maintained, using
Gaussian codebooks. We also find outer bounds for the case when the
eavesdropper receives a degraded version of the intended receiver's signal. In
the degraded case, Gaussian codewords are shown to achieve the sum capacity for
collective constraints. In addition, a TDMA scheme is shown to also achieve sum
capacity for both sets of constraints. Numerical results showing the new rate
region are presented and compared with the capacity region of the Gaussian
Multiple-Access Channel (GMAC) with no secrecy constraints. We then find the
secrecy sum-rate maximizing power allocations for the transmitters, and show
that a cooperative jamming scheme can be used to increase achievable rates in
this scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702052</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702052</id><created>2007-02-08</created><authors><author><keyname>Tauste-Campo</keyname><forenames>Adria</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>On Random Network Coding for Multicast</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures. Submitted to 2007 IEEE International Symposium on
  Information Theory</comments><abstract>  Random linear network coding is a particularly decentralized approach to the
multicast problem. Use of random network codes introduces a non-zero
probability however that some sinks will not be able to successfully decode the
required sources. One of the main theoretical motivations for random network
codes stems from the lower bound on the probability of successful decoding
reported by Ho et. al. (2003). This result demonstrates that all sinks in a
linearly solvable network can successfully decode all sources provided that the
random code field size is large enough. This paper develops a new bound on the
probability of successful decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702053</id><created>2007-02-08</created><authors><author><keyname>Badr</keyname><forenames>Andrew</forenames></author><author><keyname>Shipman</keyname><forenames>Ian</forenames></author></authors><title>The DFAs of Finitely Different Languages</title><categories>cs.CC</categories><acm-class>F.1.1; F.4.3</acm-class><abstract>  Two languages are &quot;finitely different&quot; if their symmetric difference is
finite. We consider the DFAs of finitely different regular languages and find
major structural similarities. We proceed to consider the smallest DFAs that
recognize a language finitely different from some given DFA. Such &quot;f-minimal&quot;
DFAs are not unique, and this non-uniqueness is characterized. Finally, we
offer a solution to the minimization problem of finding such f-minimal DFAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702054</id><created>2007-02-09</created><updated>2007-04-13</updated><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Thang</keyname><forenames>Nguyen Kim</forenames></author></authors><title>Nash equilibria in Voronoi games on graphs</title><categories>cs.GT cs.DS</categories><abstract>  In this paper we study a game where every player is to choose a vertex
(facility) in a given undirected graph. All vertices (customers) are then
assigned to closest facilities and a player's payoff is the number of customers
assigned to it. We show that deciding the existence of a Nash equilibrium for a
given graph is NP-hard which to our knowledge is the first result of this kind
for a zero-sum game. We also introduce a new measure, the social cost
discrepancy, defined as the ratio of the costs between the worst and the best
Nash equilibria. We show that the social cost discrepancy in our game is
Omega(sqrt(n/k)) and O(sqrt(kn)), where n is the number of vertices and k the
number of players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702055</id><created>2007-02-09</created><authors><author><keyname>Paraskevov</keyname><forenames>A. V.</forenames></author></authors><title>On the possibility of making the complete computer model of a human
  brain</title><categories>cs.NE</categories><abstract>  The development of the algorithm of a neural network building by the
corresponding parts of a DNA code is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702056</id><created>2007-02-09</created><authors><author><keyname>Mohamed</keyname><forenames>Hanene</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A probabilistic analysis of a leader election algorithm</title><categories>cs.DS</categories><proxy>ccsd hal-00130117</proxy><journal-ref>Fourth Colloquium on Mathematics and Computer Science Algorithms,
  Trees, Combinatorics and Probabilities (2006) 225-236</journal-ref><abstract>  A {\em leader election} algorithm is an elimination process that divides
recursively into tow subgroups an initial group of n items, eliminates one
subgroup and continues the procedure until a subgroup is of size 1. In this
paper the biased case is analyzed. We are interested in the {\em cost} of the
algorithm, i.e. the number of operations needed until the algorithm stops.
Using a probabilistic approach, the asymptotic behavior of the algorithm is
shown to be related to the behavior of a hitting time of two random sequences
on [0,1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702057</identifier>
 <datestamp>2007-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702057</id><created>2007-02-09</created><updated>2007-07-01</updated><authors><author><keyname>Bahramgiri</keyname><forenames>Mohsen</forenames></author><author><keyname>Beigi</keyname><forenames>Salman</forenames></author></authors><title>An Efficient Algorithm to Recognize Locally Equivalent Graphs in
  Non-Binary Case</title><categories>cs.DS</categories><comments>21 pages, no figures, minor corrections</comments><abstract>  Let $v$ be a vertex of a graph $G$. By the local complementation of $G$ at
$v$ we mean to complement the subgraph induced by the neighbors of $v$. This
operator can be generalized as follows. Assume that, each edge of $G$ has a
label in the finite field $\mathbf{F}_q$. Let $(g_{ij})$ be set of labels
($g_{ij}$ is the label of edge $ij$). We define two types of operators. For the
first one, let $v$ be a vertex of $G$ and $a\in \mathbf{F}_q$, and obtain the
graph with labels $g'_{ij}=g_{ij}+ag_{vi}g_{vj}$. For the second, if $0\neq
b\in \mathbf{F}_q$ the resulted graph is a graph with labels $g''_{vi}=bg_{vi}$
and $g''_{ij}=g_{ij}$, for $i,j$ unequal to $v$. It is clear that if the field
is binary, the operators are just local complementations that we described.
  The problem of whether two graphs are equivalent under local complementations
has been studied, \cite{bouchalg}. Here we consider the general case and
assuming that $q$ is odd, present the first known efficient algorithm to verify
whether two graphs are locally equivalent or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702058</id><created>2007-02-09</created><authors><author><keyname>Li</keyname><forenames>Kia Kai</forenames></author></authors><title>Exploring k-Colorability</title><categories>cs.CC</categories><abstract>  An introductory paper to the graph k-colorability problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702059</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702059</id><created>2007-02-09</created><updated>2010-10-07</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Redundancy-Related Bounds on Generalized Huffman Codes</title><categories>cs.IT math.IT</categories><comments>15 pages, 4 figures, incorporates and extends arXiv:cs/0605099 and
  arXiv:0809.1264v1</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new lower and upper bounds for the compression rate of
binary prefix codes optimized over memoryless sources according to various
nonlinear codeword length objectives. Like the most well-known redundancy
bounds for minimum average redundancy coding - Huffman coding - these are in
terms of a form of entropy and/or the probability of an input symbol, often the
most probable one. The bounds here, some of which are tight, improve on known
bounds of the form L in [H,H+1), where H is some form of entropy in bits (or,
in the case of redundancy objectives, 0) and L is the length objective, also in
bits. The objectives explored here include exponential-average length, maximum
pointwise redundancy, and exponential-average pointwise redundancy (also called
dth exponential redundancy). The first of these relates to various problems
involving queueing, uncertainty, and lossless communications; the second
relates to problems involving Shannon coding and universal modeling. For these
two objectives we also explore the related problem of the necessary and
sufficient conditions for the shortest codeword of a code being a specific
length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702060</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702060</id><created>2007-02-10</created><updated>2008-02-07</updated><authors><author><keyname>Richomme</keyname><forenames>Gw&#xe9;na&#xeb;l</forenames><affiliation>LaRIA</affiliation></author></authors><title>A local balance property of episturmian words</title><categories>cs.DM</categories><proxy>ccsd hal-00130229</proxy><report-no>LaRIA-LRR-2007-02</report-no><abstract>  We prove that episturmian words and Arnoux-Rauzy sequences can be
characterized using a local balance property. We also give a new
characterization of epistandard words and show that the set of finite words
that are not factors of an episturmian word is not context-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702061</id><created>2007-02-10</created><authors><author><keyname>Richomme</keyname><forenames>Gw&#xe9;na&#xeb;l</forenames><affiliation>LaRIA</affiliation></author></authors><title>Sudo-Lyndon</title><categories>cs.DM</categories><proxy>ccsd hal-00130231</proxy><report-no>LaRIA-LRR-2007-03</report-no><abstract>  Based on Lyndon words, a new Sudoku-like puzzle is presented and some
relative theoretical questions are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702062</identifier>
 <datestamp>2007-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702062</id><created>2007-02-11</created><authors><author><keyname>Gammaitoni</keyname><forenames>Luca</forenames></author></authors><title>Noise Limited Computational Speed</title><categories>cs.AR cs.PF</categories><acm-class>B.1.3; B.7.0; B.8.1; B.8.2</acm-class><journal-ref>L. Gammaitoni, Applied Physics Letters, 11/2007, Volume 91, p.3,
  (2007)</journal-ref><doi>10.1063/1.2817968</doi><abstract>  In modern transistor based logic gates, the impact of noise on computation
has become increasingly relevant since the voltage scaling strategy, aimed at
decreasing the dissipated power, has increased the probability of error due to
the reduced switching threshold voltages. In this paper we discuss the role of
noise in a two state model that mimic the dynamics of standard logic gates and
show that the presence of the noise sets a fundamental limit to the computing
speed. An optimal idle time interval that minimizes the error probability, is
derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702063</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702063</id><created>2007-02-10</created><authors><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>Entropy vectors and network codes</title><categories>cs.IT cs.NI math.IT</categories><abstract>  We consider a network multicast example that relates the solvability of the
multicast problem with the existence of an entropy function. As a result, we
provide an alternative approach to the proving of the insufficiency of linear
(and abelian) network codes and demonstrate the utility of non-Shannon
inequalities to tighten outer bounds on network coding capacity regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702064</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702064</id><created>2007-02-10</created><authors><author><keyname>Chan</keyname><forenames>Terence H.</forenames></author></authors><title>Group characterizable entropy functions</title><categories>cs.IT math.IT</categories><abstract>  This paper studies properties of entropy functions that are induced by groups
and subgroups. We showed that many information theoretic properties of those
group induced entropy functions also have corresponding group theoretic
interpretations. Then we propose an extension method to find outer bound for
these group induced entropy functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702065</identifier>
 <datestamp>2007-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702065</id><created>2007-02-10</created><updated>2007-07-31</updated><authors><author><keyname>Dridi</keyname><forenames>R.</forenames></author><author><keyname>Petitot</keyname><forenames>M.</forenames></author></authors><title>Towards a New ODE Solver Based on Cartan's Equivalence Method</title><categories>cs.SC</categories><acm-class>I.1.2</acm-class><abstract>  The aim of the present paper is to propose an algorithm for a new ODE--solver
which should improve the abilities of current solvers to handle second order
differential equations. The paper provides also a theoretical result revealing
the relationship between the change of coordinates, that maps the generic
equation to a given target equation, and the symmetry $\D$-groupoid of this
target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702066</id><created>2007-02-10</created><authors><author><keyname>Gallet</keyname><forenames>Matthieu</forenames><affiliation>LIP, INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Robert</keyname><forenames>Yves</forenames><affiliation>LIP, INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Vivien</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LIP, INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Comments on ``Design and performance evaluation of load distribution
  strategies for multiple loads on heterogeneous linear daisy chain networks''</title><categories>cs.DC</categories><proxy>ccsd inria-00130294</proxy><abstract>  Min, Veeravalli, and Barlas proposed strategies to minimize the overall
execution time of one or several divisible loads on a heterogeneous linear
network, using one or more installments. We show on a very simple example that
the proposed approach does not always produce a solution and that, when it
does, the solution is often suboptimal. We also show how to find an optimal
scheduling for any instance, once the number of installments per load is given.
Finally, we formally prove that under a linear cost model, as in the original
paper, an optimal schedule has an infinite number of installments. Such a cost
model can therefore not be sed to design practical multi-installment
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702067</id><created>2007-02-10</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>The Haar Wavelet Transform of a Dendrogram: Additional Notes</title><categories>cs.IR</categories><comments>37 pp, 1 fig. Supplementary material to &quot;The Haar Wavelet Transform
  of a Dendrogram&quot;, http://arxiv.org/abs/cs.IR/0608107</comments><acm-class>I.5.3; H.3.1; I.1.m; I.7.m</acm-class><abstract>  We consider the wavelet transform of a finite, rooted, node-ranked, $p$-way
tree, focusing on the case of binary ($p = 2$) trees. We study a Haar wavelet
transform on this tree. Wavelet transforms allow for multiresolution analysis
through translation and dilation of a wavelet function. We explore how this
works in our tree context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702068</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702068</id><created>2007-02-11</created><updated>2007-04-16</updated><authors><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author><author><keyname>Pescosolido</keyname><forenames>Loreto</forenames></author></authors><title>Distributed Decision Through Self-Synchronizing Sensor Networks in the
  Presence of Propagation Delays and Nonreciprocal Channels</title><categories>cs.IT cs.MA math.IT</categories><comments>Conference paper. Journal version submitted to IEEE Transactions on
  Signal Processing, January 10, 2007. Paper accepted for the publication on
  the VIII IEEE Workshop on Signal Processing Advances in Wireless
  Communications, (SPAWC 2007), January 22, 2007</comments><abstract>  In this paper we propose and analyze a distributed algorithm for achieving
globally optimal decisions, either estimation or detection, through a
self-synchronization mechanism among linearly coupled integrators initialized
with local measurements. We model the interaction among the nodes as a directed
graph with weights dependent on the radio interface and we pose special
attention to the effect of the propagation delays occurring in the exchange of
data among sensors, as a function of the network geometry. We derive necessary
and sufficient conditions for the proposed system to reach a consensus on
globally optimal decision statistics. One of the major results proved in this
work is that a consensus is achieved for any bounded delay condition if and
only if the directed graph is quasi-strongly connected. We also provide a
closed form expression for the global consensus, showing that the effect of
delays is, in general, to introduce a bias in the final decision. The closed
form expression is also useful to modify the consensus mechanism in order to
get rid of the bias with minimum extra complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702069</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702069</id><created>2007-02-11</created><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Dabrowski</keyname><forenames>Frederique</forenames></author></authors><title>Feasible reactivity in a synchronous pi-calculus</title><categories>cs.LO</categories><proxy>ccsd hal-00130322</proxy><journal-ref>Proceedings ACM SIGPLAN Principles and Practice of Declarative
  Programming (16/07/2007) 221-231</journal-ref><abstract>  Reactivity is an essential property of a synchronous program. Informally, it
guarantees that at each instant the program fed with an input will `react'
producing an output. In the present work, we consider a refined property that
we call ` feasible reactivity'. Beyond reactivity, this property guarantees
that at each instant both the size of the program and its reaction time are
bounded by a polynomial in the size of the parameters at the beginning of the
computation and the size of the largest input. We propose a method to annotate
programs and we develop related static analysis techniques that guarantee
feasible reactivity for programs expressed in the S-pi-calculus. The latter is
a synchronous version of the pi-calculus based on the SL synchronous
programming model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702070</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702070</id><created>2007-02-12</created><authors><author><keyname>Fresia</keyname><forenames>Maria</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>A Practical Approach to Lossy Joint Source-Channel Coding</title><categories>cs.IT math.IT</categories><comments>51 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  This work is devoted to practical joint source channel coding. Although the
proposed approach has more general scope, for the sake of clarity we focus on a
specific application example, namely, the transmission of digital images over
noisy binary-input output-symmetric channels. The basic building blocks of most
state-of the art source coders are: 1) a linear transformation; 2) scalar
quantization of the transform coefficients; 3) probability modeling of the
sequence of quantization indices; 4) an entropy coding stage. We identify the
weakness of the conventional separated source-channel coding approach in the
catastrophic behavior of the entropy coding stage. Hence, we replace this stage
with linear coding, that maps directly the sequence of redundant quantizer
output symbols into a channel codeword. We show that this approach does not
entail any loss of optimality in the asymptotic regime of large block length.
However, in the practical regime of finite block length and low decoding
complexity our approach yields very significant improvements. Furthermore, our
scheme allows to retain the transform, quantization and probability modeling of
current state-of the art source coders, that are carefully matched to the
features of specific classes of sources. In our working example, we make use of
``bit-planes'' and ``contexts'' model defined by the JPEG2000 standard and we
re-interpret the underlying probability model as a sequence of conditionally
Markov sources. The Markov structure allows to derive a simple successive
coding and decoding scheme, where the latter is based on iterative Belief
Propagation. We provide a construction example of the proposed scheme based on
punctured Turbo Codes and we demonstrate the gain over a conventional separated
scheme by running extensive numerical experiments on test images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702071</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702071</id><created>2007-02-12</created><authors><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>What is needed to exploit knowledge of primary transmissions?</title><categories>cs.IT math.IT</categories><comments>Combination of two papers submitted to ISIT'07 and DySPAN '07</comments><abstract>  Recently, Tarokh and others have raised the possibility that a cognitive
radio might know the interference signal being transmitted by a strong primary
user in a non-causal way, and use this knowledge to increase its data rates.
However, there is a subtle difference between knowing the signal transmitted by
the primary and the actual interference at our receiver since there is a
wireless channel between these two points. We show that even an unknown phase
results in a substantial decrease in the data rates that can be achieved, and
thus there is a need to feedback interference channel estimates to the
cognitive transmitter. We then consider the case of fading channels. We derive
an upper bound on the rate for given outage error probability for faded dirt.
We give a scheme that uses appropriate &quot;training&quot; to obtain such estimates and
quantify this scheme's required overhead as a function of the relevant
coherence time and interference power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702072</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702072</id><created>2007-02-12</created><authors><author><keyname>Codish</keyname><forenames>Michael</forenames></author><author><keyname>Lagoon</keyname><forenames>Vitaly</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author></authors><title>Logic Programming with Satisfiability</title><categories>cs.PL cs.AI</categories><comments>8 pages, 3 figures, 1 table</comments><journal-ref>Theory and Practice of Logic Programming: 8(1):121-128, 2008</journal-ref><abstract>  This paper presents a Prolog interface to the MiniSat satisfiability solver.
Logic program- ming with satisfiability combines the strengths of the two
paradigms: logic programming for encoding search problems into satisfiability
on the one hand and efficient SAT solving on the other. This synergy between
these two exposes a programming paradigm which we propose here as a logic
programming pearl. To illustrate logic programming with SAT solving we give an
example Prolog program which solves instances of Partial MAXSAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702073</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702073</id><created>2007-02-12</created><authors><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author></authors><title>Tradeoff between decoding complexity and rate for codes on graphs</title><categories>cs.IT cs.CC math.IT</categories><abstract>  We consider transmission over a general memoryless channel, with bounded
decoding complexity per bit under message passing decoding. We show that the
achievable rate is bounded below capacity if there is a finite success in the
decoding in a specified number of operations per bit at the decoder for some
codes on graphs. These codes include LDPC and LDGM codes. Good performance with
low decoding complexity suggests strong local structures in the graphs of these
codes, which are detrimental to the code rate asymptotically. The proof method
leads to an interesting necessary condition on the code structures which could
achieve capacity with bounded decoding complexity. We also show that if a code
sequence achieves a rate epsilon close to the channel capacity, the decoding
complexity scales at least as O(log(1/epsilon).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702074</id><created>2007-02-13</created><updated>2007-04-20</updated><authors><author><keyname>Diaz</keyname><forenames>Josep</forenames></author><author><keyname>Mitsche</keyname><forenames>Dieter</forenames></author><author><keyname>Perez</keyname><forenames>Xavier</forenames></author></authors><title>Dynamic Random Geometric Graphs</title><categories>cs.DM</categories><abstract>  In this work we introduce Dynamic Random Geometric Graphs as a basic rough
model for mobile wireless sensor networks, where communication distances are
set to the known threshold for connectivity of static random geometric graphs.
We provide precise asymptotic results for the expected length of the
connectivity and disconnectivity periods of the network. We believe the formal
tools developed in this work could be of use in future studies in more concrete
settings. In addition, for static random geometric graphs at the threshold for
connectivity, we provide asymptotic expressions on the probability of existence
of components according to their sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702075</id><created>2007-02-13</created><authors><author><keyname>Ling</keyname><forenames>Maurice HT</forenames></author></authors><title>Firebird Database Backup by Serialized Database Table Dump</title><categories>cs.DB</categories><comments>5 pages</comments><acm-class>H.2.7; E.5</acm-class><journal-ref>Ling, Maurice HT. 2007. Firebird Database Backup by Serialized
  Database Table Dump. The Python Papers 2 (1): 10-14</journal-ref><abstract>  This paper presents a simple data dump and load utility for Firebird
databases which mimics mysqldump in MySQL. This utility, fb_dump and fb_load,
for dumping and loading respectively, retrieves each database table using
kinterbasdb and serializes the data using marshal module. This utility has two
advantages over the standard Firebird database backup utility, gbak. Firstly,
it is able to backup and restore single database tables which might help to
recover corrupted databases. Secondly, the output is in text-coded format (from
marshal module) making it more resilient than a compressed text backup, as in
the case of using gbak.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702076</identifier>
 <datestamp>2007-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702076</id><created>2007-02-13</created><updated>2007-06-28</updated><authors><author><keyname>Eyraud-Dubois</keyname><forenames>Lionel</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Legrand</keyname><forenames>Arnaud</forenames><affiliation>ID-IMAG, INRIA Rh&#xf4;ne-Alpes / ID-IMAG</affiliation></author><author><keyname>Quinson</keyname><forenames>Martin</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Vivien</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author></authors><title>A First Step Towards Automatically Building Network Representations</title><categories>cs.DC</categories><abstract>  To fully harness Grids, users or middlewares must have some knowledge on the
topology of the platform interconnection network. As such knowledge is usually
not available, one must uses tools which automatically build a topological
network model through some measurements. In this article, we define a
methodology to assess the quality of these network model building tools, and we
apply this methodology to representatives of the main classes of model builders
and to two new algorithms. We show that none of the main existing techniques
build models that enable to accurately predict the running time of simple
application kernels for actual platforms. However some of the new algorithms we
propose give excellent results in a wide range of situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702077</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702077</id><created>2007-02-13</created><updated>2007-06-12</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Properties of Rank Metric Codes</title><categories>cs.IT math.IT</categories><comments>44 pages, 3 figures. Submitted to IEEE Transactions on Information
  Theory on March 6th</comments><abstract>  This paper investigates general properties of codes with the rank metric. We
first investigate asymptotic packing properties of rank metric codes. Then, we
study sphere covering properties of rank metric codes, derive bounds on their
parameters, and investigate their asymptotic covering properties. Finally, we
establish several identities that relate the rank weight distribution of a
linear code to that of its dual code. One of our identities is the counterpart
of the MacWilliams identity for the Hamming metric, and it has a different form
from the identity by Delsarte.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702078</id><created>2007-02-13</created><authors><author><keyname>Andersen</keyname><forenames>Reid</forenames></author></authors><title>A Local Algorithm for Finding Dense Subgraphs</title><categories>cs.DS cs.CC</categories><comments>14 pages, no figures</comments><acm-class>F.2.2; G.2.2</acm-class><abstract>  We present a local algorithm for finding dense subgraphs of bipartite graphs,
according to the definition of density proposed by Kannan and Vinay. Our
algorithm takes as input a bipartite graph with a specified starting vertex,
and attempts to find a dense subgraph near that vertex. We prove that for any
subgraph S with k vertices and density theta, there are a significant number of
starting vertices within S for which our algorithm produces a subgraph S' with
density theta / O(log n) on at most O(D k^2) vertices, where D is the maximum
degree. The running time of the algorithm is O(D k^2), independent of the
number of vertices in the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702079</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702079</id><created>2007-02-14</created><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Lee</keyname><forenames>Mira</forenames></author></authors><title>The Hadwiger Number of Jordan Regions is Unbounded</title><categories>cs.CG math.MG</categories><abstract>  We show that for every n &gt; 0 there is a planar topological disk A_0 and n
translates A_1, A_2, ..., A_n of A_0 such that the interiors of A_0, ... A_n
are pairwise disjoint, but with each A_i touching A_0 for 1 &lt;= i &lt;= n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702080</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702080</id><created>2007-02-13</created><updated>2007-06-26</updated><authors><author><keyname>Aronov</keyname><forenames>Boris</forenames></author><author><keyname>de Berg</keyname><forenames>Mark</forenames></author><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Haverkort</keyname><forenames>Herman</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author><author><keyname>Vigneron</keyname><forenames>Antoine</forenames></author></authors><title>Sparse geometric graphs with small dilation</title><categories>cs.CG</categories><abstract>  Given a set S of n points in R^D, and an integer k such that 0 &lt;= k &lt; n, we
show that a geometric graph with vertex set S, at most n - 1 + k edges, maximum
degree five, and dilation O(n / (k+1)) can be computed in time O(n log n). For
any k, we also construct planar n-point sets for which any geometric graph with
n-1+k edges has dilation Omega(n/(k+1)); a slightly weaker statement holds if
the points of S are required to be in convex position.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702081</id><created>2007-02-14</created><authors><author><keyname>Dale</keyname><forenames>Rick</forenames></author></authors><title>Random Sentences from a Generalized Phrase-Structure Grammar Interpreter</title><categories>cs.CL</categories><comments>Brief paper with source code and examples</comments><abstract>  In numerous domains in cognitive science it is often useful to have a source
for randomly generated corpora. These corpora may serve as a foundation for
artificial stimuli in a learning experiment (e.g., Ellefson &amp; Christiansen,
2000), or as input into computational models (e.g., Christiansen &amp; Dale, 2001).
The following compact and general C program interprets a phrase-structure
grammar specified in a text file. It follows parameters set at a Unix or
Unix-based command-line and generates a corpus of random sentences from that
grammar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702082</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702082</id><created>2007-02-14</created><authors><author><keyname>Tyukin</keyname><forenames>Ivan</forenames></author><author><keyname>Tyukina</keyname><forenames>Tatiana</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Cees</forenames></author></authors><title>Invariant template matching in systems with spatiotemporal coding: a
  vote for instability</title><categories>cs.CV cs.AI</categories><comments>52 pages, 12 figures</comments><acm-class>G.1.6; G.1.7; I.2.0; I.2.8; I.2.10; I.4.4; I.5.0; I.5.2</acm-class><journal-ref>Neural Networks, vol. 22, no. 4, (2009), 425-449</journal-ref><doi>10.1016/j.neunet.2009.01.014</doi><abstract>  We consider the design of a pattern recognition that matches templates to
images, both of which are spatially sampled and encoded as temporal sequences.
The image is subject to a combination of various perturbations. These include
ones that can be modeled as parameterized uncertainties such as image blur,
luminance, translation, and rotation as well as unmodeled ones. Biological and
neural systems require that these perturbations be processed through a minimal
number of channels by simple adaptation mechanisms. We found that the most
suitable mathematical framework to meet this requirement is that of weakly
attracting sets. This framework provides us with a normative and unifying
solution to the pattern recognition problem. We analyze the consequences of its
explicit implementation in neural systems. Several properties inherent to the
systems designed in accordance with our normative mathematical argument
coincide with known empirical facts. This is illustrated in mental rotation,
visual search and blur/intensity adaptation. We demonstrate how our results can
be applied to a range of practical problems in template matching and pattern
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702083</id><created>2007-02-14</created><authors><author><keyname>Serebrenik</keyname><forenames>Alexander</forenames></author><author><keyname>Schrijvers</keyname><forenames>Tom</forenames></author><author><keyname>Demoen</keyname><forenames>Bart</forenames></author></authors><title>Improving Prolog programs: Refactoring for Prolog</title><categories>cs.SE</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><report-no>2006-1</report-no><acm-class>D.2.7; D.1.6</acm-class><abstract>  Refactoring is an established technique from the object-oriented (OO)
programming community to restructure code: it aims at improving software
readability, maintainability and extensibility. Although refactoring is not
tied to the OO-paradigm in particular, its ideas have not been applied to Logic
Programming until now.
  This paper applies the ideas of refactoring to Prolog programs. A catalogue
is presented listing refactorings classified according to scope. Some of the
refactorings have been adapted from the OO-paradigm, while others have been
specifically designed for Prolog. The discrepancy between intended and
operational semantics in Prolog is also addressed by some of the refactorings.
  In addition, ViPReSS, a semi-automatic refactoring browser, is discussed and
the experience with applying ViPReSS to a large Prolog legacy system is
reported. The main conclusion is that refactoring is both a viable technique in
Prolog and a rather desirable one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702084</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702084</id><created>2007-02-14</created><authors><author><keyname>Radunovic</keyname><forenames>Bozidar</forenames></author><author><keyname>Boudec</keyname><forenames>Jean-Yves Le</forenames></author><author><keyname>Knopp</keyname><forenames>Raymond</forenames></author></authors><title>Performance of Ultra-Wideband Impulse Radio in Presence of Impulsive
  Interference</title><categories>cs.IT math.IT</categories><abstract>  We analyze the performance of coherent impulsive-radio (IR) ultra-wideband
(UWB) channel in presence of the interference generated by concurrent
transmissions of the systems with the same impulsive radio. We derive a novel
algorithm, using Monte-Carlo method, to calculate a lower bound on the rate
that can be achieved using maximum-likelihood estimator. Using this bound we
show that such a channel is very robust to interference, in contrast to the
nearest-neighbor detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702085</id><created>2007-02-14</created><authors><author><keyname>Carchiolo</keyname><forenames>V.</forenames></author><author><keyname>Malgeri</keyname><forenames>M.</forenames></author><author><keyname>Mangioni</keyname><forenames>G.</forenames></author><author><keyname>Nicosia</keyname><forenames>V.</forenames></author></authors><title>Social Behaviours Applied to P2P Systems: An efficient Algorithm for
  Resource Organisation</title><categories>cs.DC cs.IR</categories><comments>5 Pages; 8 Figures; Presented at COPS 2006 -- WETICE -- Manchester
  (UK)</comments><journal-ref>15th IEEE International Workshops on Enabling Technologies:
  Infrastructure for Collaborative Enterprises, 2006. WETICE '06. June 2006
  Page(s):65 - 72</journal-ref><abstract>  P2P systems are a great solution to the problem of distributing resources.
The main issue of P2P networks is that searching and retrieving resources
shared by peers is usually expensive and does not take into account
similarities among peers. In this paper we present preliminary simulations of
PROSA, a novel algorithm for P2P network structuring, inspired by social
behaviours. Peers in PROSA self--organise in social groups of similar peers,
called ``semantic--groups'', depending on the resources they are sharing. Such
a network smoothly evolves to a small--world graph, where queries for resources
are efficiently and effectively routed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702086</id><created>2007-02-14</created><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Protection of DVB Systems by Trusted Computing</title><categories>cs.CR</categories><comments>Accepted contribution to the IEEE International Symposium on
  Broadband Multimedia Systems and Broadcasting 2007, 28-29 March 2007 at the
  Orange County Convention Center, Orlando, FL, USA; 7 pages, 4 figures</comments><abstract>  We describe a concept to employ Trusted Computing technology to secure
Conditional Access Systems (CAS) for DVB. Central is the embedding of a trusted
platform module (TPM) into the set-top-box or residential home gateway. Various
deployment scenarios exhibit possibilities of charging co-operation with mobile
network operators (MNO), or other payment providers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702087</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702087</id><created>2007-02-14</created><authors><author><keyname>Glisse</keyname><forenames>Marc</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lazard</keyname><forenames>Sylvain</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>An Upper Bound on the Average Size of Silhouettes</title><categories>cs.CG</categories><proxy>ccsd inria-00130035</proxy><abstract>  It is a widely observed phenomenon in computer graphics that the size of the
silhouette of a polyhedron is much smaller than the size of the whole
polyhedron. This paper provides, for the first time, theoretical evidence
supporting this for a large class of objects, namely for polyhedra that
approximate surfaces in some reasonable way; the surfaces may be non-convex and
non-differentiable and they may have boundaries. We prove that such polyhedra
have silhouettes of expected size $O(\sqrt{n})$ where the average is taken over
all points of view and n is the complexity of the polyhedron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702088</id><created>2007-02-16</created><authors><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Paths Beyond Local Search: A Nearly Tight Bound for Randomized
  Fixed-Point Computation</title><categories>cs.GT</categories><acm-class>F.1.2; F.1.3</acm-class><abstract>  In 1983, Aldous proved that randomization can speedup local search. For
example, it reduces the query complexity of local search over [1:n]^d from
Theta (n^{d-1}) to O (d^{1/2}n^{d/2}). It remains open whether randomization
helps fixed-point computation. Inspired by this open problem and recent
advances on equilibrium computation, we have been fascinated by the following
question:
  Is a fixed-point or an equilibrium fundamentally harder to find than a local
optimum? In this paper, we give a nearly-tight bound of Omega(n)^{d-1} on the
randomized query complexity for computing a fixed point of a discrete Brouwer
function over [1:n]^d. Since the randomized query complexity of global
optimization over [1:n]^d is Theta (n^{d}), the randomized query model over
[1:n]^d strictly separates these three important search problems: Global
optimization is harder than fixed-point computation, and fixed-point
computation is harder than local search. Our result indeed demonstrates that
randomization does not help much in fixed-point computation in the query model;
the deterministic complexity of this problem is Theta (n^{d-1}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702089</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702089</id><created>2007-02-15</created><updated>2009-04-22</updated><authors><author><keyname>Keet</keyname><forenames>C. Maria</forenames></author></authors><title>Mapping the Object-Role Modeling language ORM2 into Description Logic
  language DLRifd</title><categories>cs.LO</categories><comments>17 pages, 2 figures. Changes: added references and proofs of
  correctness of encoding, fixed typos</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, several efforts have been made to enhance conceptual data
modelling with automated reasoning to improve the model's quality and derive
implicit information. One approach to achieve this in implementations, is to
constrain the language. Advances in Description Logics can help choosing the
right language to have greatest expressiveness yet to remain within the
decidable fragment of first order logic to realise a workable implementation
with good performance using DL reasoners. The best fit DL language appears to
be the ExpTime-complete DLRifd. To illustrate trade-offs and highlight features
of the modelling languages, we present a precise transformation of the mappable
features of the very expressive (undecidable) ORM/ORM2 conceptual data
modelling languages to exactly DLRifd. Although not all ORM2 features can be
mapped, this is an interesting fragment because it has been shown that DLRifd
can also encode UML Class Diagrams and EER, and therefore can foster
interoperation between conceptual data models and research into ontological
aspects of the modelling languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702090</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702090</id><created>2007-02-16</created><updated>2007-02-19</updated><authors><author><keyname>Ahn</keyname><forenames>Hee-Kap</forenames></author><author><keyname>Bae</keyname><forenames>Sang Won</forenames></author><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author></authors><title>Aperture-Angle and Hausdorff-Approximation of Convex Figures</title><categories>cs.CG math.MG</categories><comments>Fixed incorrect affiliation</comments><abstract>  The aperture angle alpha(x, Q) of a point x not in Q in the plane with
respect to a convex polygon Q is the angle of the smallest cone with apex x
that contains Q. The aperture angle approximation error of a compact convex set
C in the plane with respect to an inscribed convex polygon Q of C is the
minimum aperture angle of any x in C Q with respect to Q. We show that for any
compact convex set C in the plane and any k &gt; 2, there is an inscribed convex
k-gon Q of C with aperture angle approximation error (1 - 2/(k+1)) pi. This
bound is optimal, and settles a conjecture by Fekete from the early 1990s. The
same proof technique can be used to prove a conjecture by Brass: If a polygon P
admits no approximation by a sub-k-gon (the convex hull of k vertices of P)
with Hausdorff distance sigma, but all subpolygons of P (the convex hull of
some vertices of P) admit such an approximation, then P is a (k+1)-gon. This
implies the following result: For any k &gt; 2 and any convex polygon P of
perimeter at most 1 there is a sub-k-gon Q of P such that the
Hausdorff-distance of P and Q is at most 1/(k+1) * sin(pi/(k+1)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702091</id><created>2007-02-16</created><authors><author><keyname>Jungers</keyname><forenames>Raphael M.</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author></authors><title>Observable Graphs</title><categories>cs.MA</categories><comments>15 pages, 8 figures</comments><abstract>  An edge-colored directed graph is \emph{observable} if an agent that moves
along its edges is able to determine his position in the graph after a
sufficiently long observation of the edge colors. When the agent is able to
determine his position only from time to time, the graph is said to be
\emph{partly observable}. Observability in graphs is desirable in situations
where autonomous agents are moving on a network and one wants to localize them
(or the agent wants to localize himself) with limited information. In this
paper, we completely characterize observable and partly observable graphs and
show how these concepts relate to observable discrete event systems and to
local automata. Based on these characterizations, we provide polynomial time
algorithms to decide observability, to decide partial observability, and to
compute the minimal number of observations necessary for finding the position
of an agent. In particular we prove that in the worst case this minimal number
of observations increases quadratically with the number of nodes in the graph.
  From this it follows that it may be necessary for an agent to pass through
the same node several times before he is finally able to determine his position
in the graph. We then consider the more difficult question of assigning colors
to a graph so as to make it observable and we prove that two different versions
of this problem are NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702092</id><created>2007-02-16</created><authors><author><keyname>Altug</keyname><forenames>Yucel</forenames></author><author><keyname>Ayerden</keyname><forenames>N. Polat</forenames></author><author><keyname>Mihcak</keyname><forenames>M. Kivanc</forenames></author><author><keyname>Anarim</keyname><forenames>Emin</forenames></author></authors><title>A Note on the Periodicity and the Output Rate of Bit Search Type
  Generators</title><categories>cs.CR</categories><comments>20 pages, 2 figures and submitted to IEEE Transactions on Information
  Theory</comments><abstract>  We investigate the bit-search type irregular decimation algorithms that are
used within LFSR-based stream ciphers. In particular, we concentrate on BSG and
ABSG, and consider two different setups for the analysis. In the first case,
the input is assumed to be a m-sequence; we show that all possible output
sequences can be classified into two sets, each of which is characterized by
the equivalence of their elements up to shifts. Furthermore, we prove that the
cardinality of each of these sets is equal to the period of one of its elements
and subsequently derive the first known bounds on the expected output period
(assuming that no subperiods exist). In the second setup, we work in a
probabilistic framework and assume that the input sequence is evenly
distributed (i.e., independent identically distributed Bernoulli process with
probability 1/2). Under these assumptions, we derive closed-form expressions
for the distribution of the output length and the output rate, which is shown
to be asymptotically Gaussian-distributed and concentrated around the mean with
exponential tightness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702093</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702093</id><created>2007-02-16</created><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Tchamkerten</keyname><forenames>Aslan</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Secure Broadcasting</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, Special issue
  on Information Theoretic Security</comments><abstract>  Wyner's wiretap channel is extended to parallel broadcast channels and fading
channels with multiple receivers. In the first part of the paper, we consider
the setup of parallel broadcast channels with one sender, multiple intended
receivers, and one eavesdropper. We study the situations where the sender
broadcasts either a common message or independent messages to the intended
receivers. We derive upper and lower bounds on the common-message-secrecy
capacity, which coincide when the users are reversely degraded. For the case of
independent messages we establish the secrecy sum-capacity when the users are
reversely degraded.
  In the second part of the paper we apply our results to fading channels:
perfect channel state information of all intended receivers is known globally,
whereas the eavesdropper channel is known only to her. For the common message
case, a somewhat surprising result is proven: a positive rate can be achieved
independently of the number of intended receivers. For independent messages, an
opportunistic transmission scheme is presented that achieves the secrecy
sum-capacity in the limit of large number of receivers. Our results are stated
for a fast fading channel model. Extensions to the block fading model are also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702094</id><created>2007-02-16</created><authors><author><keyname>Fuduric</keyname><forenames>Darko</forenames></author><author><keyname>Horvat</keyname><forenames>Marko</forenames></author><author><keyname>Zagar</keyname><forenames>Mario</forenames></author></authors><title>Authentication via wireless networks</title><categories>cs.OH</categories><comments>5 pages, 6 figures, 1 table, MIPRO Conference in Opatija, Croatia,
  2006</comments><journal-ref>MIPRO, 2006</journal-ref><abstract>  Personal authentication is an important process we encounter almost every
day; when we are logging on a computer, entering a company where we work, or a
restricted area, when we are using our plastic credit cards to pay for a
service or to complete some other financial transaction, etc. In each of these
processes of personal authentication some kind of magnetic or optical token is
required. But by using novel technologies like mobile computing and wireless
networking, it is possible to avoid carrying multitude of ID cards or
remembering a number of PIN codes. Article shows how to efficiently
authenticate users via Personal Area Networks (PAN) like Bluetooth or IrDA
using commonplace AES (Rijndel) or MD5 encryption. This method can be
implemented on many types of mobile devices like Pocket PC PDA with Windows CE
(Windows Mobile 2003) real-time operating system, or any other customized OS,
so we will explain all components and key features of such basic system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702095</id><created>2007-02-16</created><authors><author><keyname>Mahalanobis</keyname><forenames>Ayan</forenames></author></authors><title>A note on using finite non-abelian $p$-groups in the MOR cryptosystem</title><categories>cs.CR math.GR</categories><abstract>  The MOR cryptosystem is a natural generalization of the El-Gamal cryptosystem
to non-abelian groups. Using a $p$-group, a cryptosystem was built by this
author in 'A simple generalization of El-Gamal cryptosystem to non-abelian
groups'. It seems reasonable to assume the cryptosystem is as secure as the
El-Gamal cryptosystem over finite fields. A natural question arises can one
make a better cryptosystem using $p$-groups? In this paper we show that the
answer is no.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702096</id><created>2007-02-16</created><authors><author><keyname>Iclanzan</keyname><forenames>David</forenames></author><author><keyname>Dumitrescu</keyname><forenames>Dan</forenames></author></authors><title>Overcoming Hierarchical Difficulty by Hill-Climbing the Building Block
  Structure</title><categories>cs.NE cs.AI</categories><comments>submited to GECCO 2007 (jan 31)</comments><acm-class>G.1.6; I.2.8</acm-class><abstract>  The Building Block Hypothesis suggests that Genetic Algorithms (GAs) are
well-suited for hierarchical problems, where efficient solving requires proper
problem decomposition and assembly of solution from sub-solution with strong
non-linear interdependencies. The paper proposes a hill-climber operating over
the building block (BB) space that can efficiently address hierarchical
problems. The new Building Block Hill-Climber (BBHC) uses past hill-climb
experience to extract BB information and adapts its neighborhood structure
accordingly. The perpetual adaptation of the neighborhood structure allows the
method to climb the hierarchical structure solving successively the
hierarchical levels. It is expected that for fully non deceptive hierarchical
BB structures the BBHC can solve hierarchical problems in linearithmic time.
Empirical results confirm that the proposed method scales almost linearly with
the problem size thus clearly outperforms population based recombinative
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702097</identifier>
 <datestamp>2011-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702097</id><created>2007-02-16</created><authors><author><keyname>Atkinson</keyname><forenames>M. D.</forenames></author><author><keyname>van Ditmarsch</keyname><forenames>H. P.</forenames></author><author><keyname>Roehling</keyname><forenames>S.</forenames></author></authors><title>Avoiding bias in cards cryptography</title><categories>cs.CR cs.MA</categories><comments>11 pages</comments><journal-ref>Australasian Journal of Combinatorics 44:3-17, 2009</journal-ref><abstract>  We outline the need for stricter requirements for unconditionally secure
cryptographic protocols inspired by the Russian Cards problem. A new
requirement CA4 is proposed that checks for bias in single card occurrence in
announcements consisting of alternatives for players' holdings of cards. This
requirement CA4 is shown to be equivalent to an alternative requirement CA5.
All announcements found to satisfy CA4 are 2-designs. We also show that all
binary designs are 3-designs. Instead of avoiding bias in announcements
produced by such protocols, one may as well apply unbiased protocols such that
patterns in announcements become meaningless. We gave two examples of such
protocols for card deal parameters (3,3,1), i.e. two of the players hold three
cards, and the remaining player, playing the role of eavesdropper, holds a
single card.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702098</id><created>2007-02-18</created><authors><author><keyname>Salo</keyname><forenames>Jari</forenames></author></authors><title>A Sum-Product Model as a Physical Basis for Shadow Fading</title><categories>cs.OH</categories><comments>23 pages, 9 figs. To be revised and maybe submitted</comments><abstract>  Shadow fading (slow fading) effects play a central role in mobile
communication system design and analysis. Experimental evidence indicates that
shadow fading exhibits log-normal power distribution almost universally, and
yet it is still not well understood what causes this. In this paper, we propose
a versatile sum-product signal model as a physical basis for shadow fading.
Simulation results imply that the proposed model results in log-normally
distributed local mean power regardless of the distributions of the
interactions in the radio channel, and hence it is capable of explaining the
log-normality in a wide variety of propagation scenarios. The sum-product model
also includes as its special cases the conventional product model as well as
the recently proposed sum model, and improves upon these by: a) being
applicable in both global and local distance scales; b) being more plausible
from physical point of view; c) providing better goodness-of-fit to log-normal
distribution than either of these models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702099</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702099</id><created>2007-02-17</created><updated>2007-12-11</updated><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames></author><author><keyname>Maric</keyname><forenames>Ivana</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author><author><keyname>Yates</keyname><forenames>Roy D.</forenames></author></authors><title>Discrete Memoryless Interference and Broadcast Channels with
  Confidential Messages: Secrecy Rate Regions</title><categories>cs.IT math.IT</categories><comments>to appear Special Issue of IEEE Transactions on Information Theory on
  Information Theoretic Security</comments><abstract>  We study information-theoretic security for discrete memoryless interference
and broadcast channels with independent confidential messages sent to two
receivers. Confidential messages are transmitted to their respective receivers
with information-theoretic secrecy. That is, each receiver is kept in total
ignorance with respect to the message intended for the other receiver. The
secrecy level is measured by the equivocation rate at the eavesdropping
receiver. In this paper, we present inner and outer bounds on secrecy capacity
regions for these two communication systems. The derived outer bounds have an
identical mutual information expression that applies to both channel models.
The difference is in the input distributions over which the expression is
optimized. The inner bound rate regions are achieved by random binning
techniques. For the broadcast channel, a double-binning coding scheme allows
for both joint encoding and preserving of confidentiality. Furthermore, we show
that, for a special case of the interference channel, referred to as the switch
channel, the two bound bounds meet. Finally, we describe several transmission
schemes for Gaussian interference channels and derive their achievable rate
regions while ensuring mutual information-theoretic secrecy. An encoding scheme
in which transmitters dedicate some of their power to create artificial noise
is proposed and shown to outperform both time-sharing and simple multiplexed
transmission of the confidential messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702100</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702100</id><created>2007-02-18</created><authors><author><keyname>Vanka</keyname><forenames>Sundaram</forenames></author><author><keyname>Dehghani</keyname><forenames>M. J.</forenames></author><author><keyname>Prabhu</keyname><forenames>K. M. M.</forenames></author><author><keyname>Aravind</keyname><forenames>R.</forenames></author></authors><title>A Class of Multi-Channel Cosine Modulated IIR Filter Banks</title><categories>cs.IT math.IT</categories><comments>18 pages, 8 figures</comments><abstract>  This paper presents a class of multi-channel cosine-modulated filter banks
satisfying the perfect reconstruction (PR) property using an IIR prototype
filter. By imposing a suitable structure on the polyphase filter coefficients,
we show that it is possible to greatly simplify the PR condition, while
preserving the causality and stability of the system. We derive closed-form
expressions for the synthesis filters and also study the numerical stability of
the filter bank using frame theoretic bounds. Further, we show that it is
possible to implement this filter bank with much lower number of arithmetic
operations when compared to FIR filter banks with comparable performance. The
filter bank's modular structure also lends itself to efficient VLSI
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702101</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702101</id><created>2007-02-18</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>An identity of Chernoff bounds with an interpretation in statistical
  physics and applications in information theory</title><categories>cs.IT math.IT</categories><comments>29 pages, 1 figure. Submitted to IEEE Trans. on Information Theory</comments><abstract>  An identity between two versions of the Chernoff bound on the probability a
certain large deviations event, is established. This identity has an
interpretation in statistical physics, namely, an isothermal equilibrium of a
composite system that consists of multiple subsystems of particles. Several
information--theoretic application examples, where the analysis of this large
deviations probability naturally arises, are then described from the viewpoint
of this statistical mechanical interpretation. This results in several
relationships between information theory and statistical physics, which we
hope, the reader will find insightful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702102</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702102</id><created>2007-02-18</created><authors><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author><author><keyname>Mitzel</keyname><forenames>Kevin</forenames></author><author><keyname>Yang</keyname><forenames>Sichao</forenames></author></authors><title>Paging and Registration in Cellular Networks: Jointly Optimal Policies
  and an Iterative Algorithm</title><categories>cs.IT cs.NI math.IT</categories><comments>13 pages, submitted to IEEE Trans. Information Theory</comments><abstract>  This paper explores optimization of paging and registration policies in
cellular networks. Motion is modeled as a discrete-time Markov process, and
minimization of the discounted, infinite-horizon average cost is addressed. The
structure of jointly optimal paging and registration policies is investigated
through the use of dynamic programming for partially observed Markov processes.
It is shown that there exist policies with a certain simple form that are
jointly optimal, though the dynamic programming approach does not directly
provide an efficient method to find the policies.
  An iterative algorithm for policies with the simple form is proposed and
investigated. The algorithm alternates between paging policy optimization and
registration policy optimization. It finds a pair of individually optimal
policies, but an example is given showing that the policies need not be jointly
optimal. Majorization theory and Riesz's rearrangement inequality are used to
show that jointly optimal paging and registration policies are given for
symmetric or Gaussian random walk models by the nearest-location-first paging
policy and distance threshold registration policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702103</id><created>2007-02-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Exploring the academic invisible web</title><categories>cs.DL</categories><comments>13 pages, 3 figures</comments><journal-ref>Library Hi Tech, 24 (2006) 4. pp. 529-539</journal-ref><abstract>  Purpose: To provide a critical review of Bergman's 2001 study on the Deep
Web. In addition, we bring a new concept into the discussion, the Academic
Invisible Web (AIW). We define the Academic Invisible Web as consisting of all
databases and collections relevant to academia but not searchable by the
general-purpose internet search engines. Indexing this part of the Invisible
Web is central to scientific search engines. We provide an overview of
approaches followed thus far. Design/methodology/approach: Discussion of
measures and calculations, estimation based on informetric laws. Literature
review on approaches for uncovering information from the Invisible Web.
Findings: Bergman's size estimate of the Invisible Web is highly questionable.
We demonstrate some major errors in the conceptual design of the Bergman paper.
A new (raw) size estimate is given. Research limitations/implications: The
precision of our estimate is limited due to a small sample size and lack of
reliable data. Practical implications: We can show that no single library alone
will be able to index the Academic Invisible Web. We suggest collaboration to
accomplish this task. Originality/value: Provides library managers and those
interested in developing academic search engines with data on the size and
attributes of the Academic Invisible Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702104</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702104</id><created>2007-02-19</created><authors><author><keyname>Chatzigeorgiou</keyname><forenames>Ioannis</forenames></author><author><keyname>Rodrigues</keyname><forenames>Miguel R. D.</forenames></author><author><keyname>Wassell</keyname><forenames>Ian J.</forenames></author><author><keyname>Carrasco</keyname><forenames>Rolando</forenames></author></authors><title>A Union Bound Approximation for Rapid Performance Evaluation of
  Punctured Turbo Codes</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, 1 table, Proceedings of the 41st Conference on
  Information Sciences and Systems, Baltimore, USA, March 14-16, 2007</comments><abstract>  In this paper, we present a simple technique to approximate the performance
union bound of a punctured turbo code. The bound approximation exploits only
those terms of the transfer function that have a major impact on the overall
performance. We revisit the structure of the constituent convolutional encoder
and we develop a rapid method to calculate the most significant terms of the
transfer function of a turbo encoder. We demonstrate that, for a large
interleaver size, this approximation is very accurate. Furthermore, we apply
our proposed method to a family of punctured turbo codes, which we call
pseudo-randomly punctured codes. We conclude by emphasizing the benefits of our
approach compared to those employed previously. We also highlight the
advantages of pseudo-random puncturing over other puncturing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702105</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702105</id><created>2007-02-19</created><authors><author><keyname>Donoho</keyname><forenames>David</forenames></author><author><keyname>Kakavand</keyname><forenames>Hossein</forenames></author><author><keyname>Mammen</keyname><forenames>James</forenames></author></authors><title>The Simplest Solution to an Underdetermined System of Linear Equations</title><categories>cs.IT math.IT</categories><comments>Proceedings of the IEEE International Symposium on Information Theory
  Seattle, Washington, July 9-14, 2006</comments><abstract>  Consider a d*n matrix A, with d&lt;n. The problem of solving for x in y=Ax is
underdetermined, and has infinitely many solutions (if there are any). Given y,
the minimum Kolmogorov complexity solution (MKCS) of the input x is defined to
be an input z (out of many) with minimum Kolmogorov-complexity that satisfies
y=Az. One expects that if the actual input is simple enough, then MKCS will
recover the input exactly. This paper presents a preliminary study of the
existence and value of the complexity level up to which such a complexity-based
recovery is possible. It is shown that for the set of all d*n binary matrices
(with entries 0 or 1 and d&lt;n), MKCS exactly recovers the input for an
overwhelming fraction of the matrices provided the Kolmogorov complexity of the
input is O(d). A weak converse that is loose by a log n factor is also
established for this case. Finally, we investigate the difficulty of finding a
matrix that has the property of recovering inputs with complexity of O(d) using
MKCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702106</id><created>2007-02-19</created><authors><author><keyname>Robert</keyname><forenames>Charles</forenames><affiliation>LORIA</affiliation></author><author><keyname>Adigun</keyname><forenames>Ranmi</forenames><affiliation>YABATECH</affiliation></author></authors><title>Wild, Wild Wikis: A way forward</title><categories>cs.IR</categories><proxy>ccsd inria-00131878</proxy><journal-ref>Dans The Fifth International Conference on Creating, Connecting
  and Collaborating through Computing, C5 2007 (2007)</journal-ref><abstract>  Wikis can be considered as public domain knowledge sharing system. They
provide opportunity for those who may not have the privilege to publish their
thoughts through the traditional methods. They are one of the fastest growing
systems of online encyclopaedia. In this study, we consider the importance of
wikis as a way of creating, sharing and improving public knowledge. We identify
some of the problems associated with wikis to include, (a) identification of
the identities of information and its creator (b) accuracy of information (c)
justification of the credibility of authors (d) vandalism of quality of
information (e) weak control over the contents. A solution to some of these
problems is sought through the use of an annotation model. The model assumes
that contributions in wikis can be seen as annotation to the initial document.
It proposed a systematic control of contributors and contributions to the
initiative and the keeping of records of what existed and what was done to
initial documents. We believe that with this model, analysis can be done on the
progress of wiki initiatives. We assumed that using this model, wikis can be
better used for creation and sharing of knowledge for public use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702107</id><created>2007-02-19</created><authors><author><keyname>Robert</keyname><forenames>Charles A.</forenames><affiliation>LORIA</affiliation></author></authors><title>AMIEDoT: An annotation model for document tracking and recommendation
  service</title><categories>cs.IR</categories><proxy>ccsd inria-00131880</proxy><journal-ref>Dans International Joint Conferences on Computer, Information, and
  Systems Sciences, and Engineering, (CIS2E 06) (2007)</journal-ref><abstract>  The primary objective of document annotation in whatever form, manual or
electronic is to allow those who may not have control to original document to
provide personal view on information source. Beyond providing personal
assessment to original information sources, we are looking at a situation where
annotation made can be used as additional source of information for document
tracking and recommendation service. Most of the annotation tools existing
today were conceived for their independent use with no reference to the creator
of the annotation. We propose AMIEDoT (Annotation Model for Information
Exchange and Document Tracking) an annotation model that can assist in document
tracking and recommendation service. The model is based on three parameters in
the acts of annotation. We believe that introducing document parameters, time
and the parameters of the creator of annotation into an annotation process can
be a dependable source to know, who used a document, when a document was used
and for what a document was used for. Beyond document tracking, our model can
be used in not only for selective dissemination of information but for
recommendation services. AMIEDoT can also be used for information sharing and
information reuse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702108</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702108</id><created>2007-02-19</created><updated>2008-09-16</updated><authors><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Orthogonal Codes for Robust Low-Cost Communication</title><categories>cs.IT math.IT</categories><comments>2nd revision, accepted for publication</comments><report-no>USC CSI Technical Report CSI-07-02-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal coding schemes, known to asymptotically achieve the capacity per
unit cost (CPUC) for single-user ergodic memoryless channels with a zero-cost
input symbol, are investigated for single-user compound memoryless channels,
which exhibit uncertainties in their input-output statistical relationships. A
minimax formulation is adopted to attain robustness. First, a class of
achievable rates per unit cost (ARPUC) is derived, and its utility is
demonstrated through several representative case studies. Second, when the
uncertainty set of channel transition statistics satisfies a convexity
property, optimization is performed over the class of ARPUC through utilizing
results of minimax robustness. The resulting CPUC lower bound indicates the
ultimate performance of the orthogonal coding scheme, and coincides with the
CPUC under certain restrictive conditions. Finally, still under the convexity
property, it is shown that the CPUC can generally be achieved, through
utilizing a so-called mixed strategy in which an orthogonal code contains an
appropriate composition of different nonzero-cost input symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702109</id><created>2007-02-19</created><authors><author><keyname>Robert</keyname><forenames>Charles A.</forenames><affiliation>LORIA</affiliation></author><author><keyname>Amos</keyname><forenames>David</forenames><affiliation>LORIA</affiliation></author></authors><title>AMIE: An annotation model for information research</title><categories>cs.IR</categories><proxy>ccsd inria-00131891</proxy><journal-ref>Dans International Conference on Computers in Education, (2006)</journal-ref><abstract>  The objective of most users for consulting any information database,
information warehouse or the internet is to resolve one problem or the other.
Available online or offline annotation tools were not conceived with the
objective of assisting users in their bid to resolve a decisional problem.
Apart from the objective and usage of annotation tools, how these tools are
conceived and classified has implication on their usage. Several criteria have
been used to categorize annotation concepts. Typically annotation are conceived
based on how it affect the organization of document been considered for
annotation or the organization of the resulting annotation. Our approach is
annotation that will assist in information research for decision making.
Annotation model for information exchange (AMIE) was conceived with the
objective of information sharing and reuse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702110</id><created>2007-02-19</created><authors><author><keyname>Aksahin</keyname><forenames>Saltuk</forenames></author></authors><title>Security Implications of Converged Networks and Protecting Them, without
  Compromising Efficiency</title><categories>cs.NI</categories><comments>64 pages</comments><acm-class>C.2.1; C.2.0; C.2.2</acm-class><abstract>  This dissertation has extensively looked into all aspects of VoIP
commu-nications technology, and information presented in preceding chapters,
which build up a solid framework to discuss the conceptual design model, and
investigate features that could be incorporated for actual Pro-jects, with
parameters that are tested on field values. The dissertation follows a
five-course model, for answering different questions, both tech-nical and
businesslike, around central issues, that have been crucial to explanation of
the topic; starting with a general overview of VoIP tech-nology, analyzing
current VoIP encryption methods, identifying security threats, designing a
robust VoIP system based on particulars discussed in preceding chapters, and
finally, a VoIP simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702111</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702111</id><created>2007-02-19</created><updated>2007-02-28</updated><authors><author><keyname>Casado</keyname><forenames>Andres I. Vila</forenames></author><author><keyname>Griot</keyname><forenames>Miguel</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Informed Dynamic Scheduling for Belief-Propagation Decoding of LDPC
  Codes</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures</comments><abstract>  Low-Density Parity-Check (LDPC) codes are usually decoded by running an
iterative belief-propagation, or message-passing, algorithm over the factor
graph of the code. The traditional message-passing schedule consists of
updating all the variable nodes in the graph, using the same pre-update
information, followed by updating all the check nodes of the graph, again,
using the same pre-update information. Recently several studies show that
sequential scheduling, in which messages are generated using the latest
available information, significantly improves the convergence speed in terms of
number of iterations. Sequential scheduling raises the problem of finding the
best sequence of message updates. This paper presents practical scheduling
strategies that use the value of the messages in the graph to find the next
message to be updated. Simulation results show that these informed update
sequences require significantly fewer iterations than standard sequential
schedules. Furthermore, the paper shows that informed scheduling solves some
standard trapping set errors. Therefore, it also outperforms traditional
scheduling for a large numbers of iterations. Complexity and implementability
issues are also addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702112</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702112</id><created>2007-02-19</created><updated>2008-01-25</updated><authors><author><keyname>Tekin</keyname><forenames>Ender</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>The General Gaussian Multiple Access and Two-Way Wire-Tap Channels:
  Achievable Rates and Cooperative Jamming</title><categories>cs.IT cs.CR math.IT</categories><comments>IEEE Transactions on Information Theory, Special Issue on Information
  Theoretic Security</comments><abstract>  The General Gaussian Multiple Access Wire-Tap Channel (GGMAC-WT) and the
Gaussian Two-Way Wire-Tap Channel (GTW-WT) are considered. In the GGMAC-WT,
multiple users communicate with an intended receiver in the presence of an
eavesdropper who receives their signals through another GMAC. In the GTW-WT,
two users communicate with each other over a common Gaussian channel, with an
eavesdropper listening through a GMAC. A secrecy measure that is suitable for
this multi-terminal environment is defined, and achievable secrecy rate regions
are found for both channels. For both cases, the power allocations maximizing
the achievable secrecy sum-rate are determined. It is seen that the optimum
policy may prevent some terminals from transmission in order to preserve the
secrecy of the system. Inspired by this construct, a new scheme,
\ital{cooperative jamming}, is proposed, where users who are prevented from
transmitting according to the secrecy sum-rate maximizing power allocation
policy &quot;jam&quot; the eavesdropper, thereby helping the remaining users. This scheme
is shown to increase the achievable secrecy sum-rate. Overall, our results show
that in multiple-access scenarios, users can help each other to collectively
achieve positive secrecy rates. In other words, cooperation among users can be
invaluable for achieving secrecy for the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702113</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702113</id><created>2007-02-19</created><updated>2010-07-21</updated><authors><author><keyname>Pritchard</keyname><forenames>David</forenames></author><author><keyname>Thurimella</keyname><forenames>Ramakrishna</forenames></author></authors><title>Fast Computation of Small Cuts via Cycle Space Sampling</title><categories>cs.DC cs.DS</categories><comments>Previous version appeared in Proc. 35th ICALP, pages 145--160, 2008</comments><acm-class>F.1.2; F.2.2; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new sampling-based method to determine cuts in an undirected
graph. For a graph (V, E), its cycle space is the family of all subsets of E
that have even degree at each vertex. We prove that with high probability,
sampling the cycle space identifies the cuts of a graph. This leads to simple
new linear-time sequential algorithms for finding all cut edges and cut pairs
(a set of 2 edges that form a cut) of a graph.
  In the model of distributed computing in a graph G=(V, E) with O(log V)-bit
messages, our approach yields faster algorithms for several problems. The
diameter of G is denoted by Diam, and the maximum degree by Delta. We obtain
simple O(Diam)-time distributed algorithms to find all cut edges,
2-edge-connected components, and cut pairs, matching or improving upon previous
time bounds. Under natural conditions these new algorithms are universally
optimal --- i.e. a Omega(Diam)-time lower bound holds on every graph. We obtain
a O(Diam+Delta/log V)-time distributed algorithm for finding cut vertices; this
is faster than the best previous algorithm when Delta, Diam = O(sqrt(V)). A
simple extension of our work yields the first distributed algorithm with
sub-linear time for 3-edge-connected components. The basic distributed
algorithms are Monte Carlo, but they can be made Las Vegas without increasing
the asymptotic complexity.
  In the model of parallel computing on the EREW PRAM our approach yields a
simple algorithm with optimal time complexity O(log V) for finding cut pairs
and 3-edge-connected components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702114</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702114</id><created>2007-02-19</created><authors><author><keyname>Pritchard</keyname><forenames>David</forenames></author></authors><title>Nearest Neighbor Network Traversal</title><categories>cs.DC</categories><abstract>  A mobile agent in a network wants to visit every node of an n-node network,
using a small number of steps. We investigate the performance of the following
``nearest neighbor'' heuristic: always go to the nearest unvisited node. If the
network graph never changes, then from (Rosenkrantz, Stearns and Lewis, 1977)
and (Hurkens and Woeginger, 2004) it follows that Theta(n log n) steps are
necessary and sufficient in the worst case. We give a simpler proof of the
upper bound and an example that improves the best known lower bound.
  We investigate how the performance of this heuristic changes when it is
distributively implemented in a network. Even if network edges are allow to
fail over time, we show that the nearest neighbor strategy never runs for more
than O(n^2) iterations. We also show that any strategy can be forced to take at
least n(n-1)/2 steps before all nodes are visited, if the edges of the network
are deleted in an adversarial way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702115</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702115</id><created>2007-02-20</created><updated>2007-04-15</updated><authors><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Guessing based on length functions</title><categories>cs.IT cs.CR math.IT</categories><comments>16 pages, Submitted to IEEE Transactions on Information Theory,
  Special issue on Information Theoretic Security, Simplified proof of
  Proposition 2</comments><abstract>  A guessing wiretapper's performance on a Shannon cipher system is analyzed
for a source with memory. Close relationships between guessing functions and
length functions are first established. Subsequently, asymptotically optimal
encryption and attack strategies are identified and their performances analyzed
for sources with memory. The performance metrics are exponents of guessing
moments and probability of large deviations. The metrics are then characterized
for unifilar sources. Universal asymptotically optimal encryption and attack
strategies are also identified for unifilar sources. Guessing in the increasing
order of Lempel-Ziv coding lengths is proposed for finite-state sources, and
shown to be asymptotically optimal. Finally, competitive optimality properties
of guessing in the increasing order of description lengths and Lempel-Ziv
coding lengths are demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702116</identifier>
 <datestamp>2008-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702116</id><created>2007-02-20</created><updated>2008-04-25</updated><authors><author><keyname>Baelde</keyname><forenames>David</forenames></author><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author><author><keyname>Miller</keyname><forenames>Dale</forenames></author><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author></authors><title>The Bedwyr system for model checking over syntactic expressions</title><categories>cs.LO</categories><comments>6 page system description. Appeared in CADE 2007</comments><journal-ref>CADE 2007: 21th Conference on Automated Deduction, Frank Pfenning,
  editor, LNAI 4603, pages 391-397. Springer, 2007</journal-ref><abstract>  Bedwyr is a generalization of logic programming that allows model checking
directly on syntactic expressions possibly containing bindings. This system,
written in OCaml, is a direct implementation of two recent advances in the
theory of proof search. The first is centered on the fact that both finite
success and finite failure can be captured in the sequent calculus by
incorporating inference rules for definitions that allow fixed points to be
explored. As a result, proof search in such a sequent calculus can capture
simple model checking problems as well as may and must behavior in operational
semantics. The second is that higher-order abstract syntax is directly
supported using term-level $\lambda$-binders and the $\nabla$ quantifier. These
features allow reasoning directly on expressions containing bound variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702117</id><created>2007-02-20</created><updated>2007-02-22</updated><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Couture</keyname><forenames>Mathieu</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author><author><keyname>Xu</keyname><forenames>Daming</forenames></author></authors><title>On a family of strong geometric spanners that admit local routing
  strategies</title><categories>cs.CG</categories><abstract>  We introduce a family of directed geometric graphs, denoted $\paz$, that
depend on two parameters $\lambda$ and $\theta$. For $0\leq
\theta&lt;\frac{\pi}{2}$ and ${1/2} &lt; \lambda &lt; 1$, the $\paz$ graph is a strong
$t$-spanner, with $t=\frac{1}{(1-\lambda)\cos\theta}$. The out-degree of a node
in the $\paz$ graph is at most $\lfloor2\pi/\min(\theta,
\arccos\frac{1}{2\lambda})\rfloor$. Moreover, we show that routing can be
achieved locally on $\paz$. Next, we show that all strong $t$-spanners are also
$t$-spanners of the unit disk graph. Simulations for various values of the
parameters $\lambda$ and $\theta$ indicate that for random point sets, the
spanning ratio of $\paz$ is better than the proven theoretical bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702118</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702118</id><created>2007-02-20</created><authors><author><keyname>Lee</keyname><forenames>Kwankyu</forenames></author></authors><title>Interpolation-based Decoding of Alternant Codes</title><categories>cs.IT math.IT</categories><comments>submitted to the journal of Advances in Mathematics of Communications</comments><abstract>  We formulate the classical decoding algorithm of alternant codes afresh based
on interpolation as in Sudan's list decoding of Reed-Solomon codes, and thus
get rid of the key equation and the linear recurring sequences in the theory.
The result is a streamlined exposition of the decoding algorithm using a bit of
the theory of Groebner bases of modules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702119</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702119</id><created>2007-02-21</created><updated>2009-08-25</updated><authors><author><keyname>G</keyname><forenames>Raju Renjit.</forenames></author></authors><title>Ulam's Conjecture is True for Connected Graphs</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This submission has been withdrawn at the request of the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702120</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702120</id><created>2007-02-21</created><updated>2007-02-28</updated><authors><author><keyname>Ouaknine</keyname><forenames>Joel</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>On the decidability and complexity of Metric Temporal Logic over finite
  words</title><categories>cs.LO cs.CC</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 1 (February
  28, 2007) lmcs:1080</journal-ref><doi>10.2168/LMCS-3(1:8)2007</doi><abstract>  Metric Temporal Logic (MTL) is a prominent specification formalism for
real-time systems. In this paper, we show that the satisfiability problem for
MTL over finite timed words is decidable, with non-primitive recursive
complexity. We also consider the model-checking problem for MTL: whether all
words accepted by a given Alur-Dill timed automaton satisfy a given MTL
formula. We show that this problem is decidable over finite words. Over
infinite words, we show that model checking the safety fragment of MTL--which
includes invariance and time-bounded response properties--is also decidable.
These results are quite surprising in that they contradict various claims to
the contrary that have appeared in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702121</identifier>
 <datestamp>2009-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702121</id><created>2007-02-21</created><updated>2009-11-22</updated><authors><author><keyname>Wang</keyname><forenames>Xing M.</forenames></author></authors><title>Induced Hilbert Space, Markov Chain, Diffusion Map and Fock Space in
  Thermophysics</title><categories>cs.OH math.PR</categories><comments>25 pages</comments><acm-class>H.3.3; G.3; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we continue to explore Probability Bracket Notation (PBN),
proposed in our previous article. Using both Dirac vector bracket notation
(VBN) and PBN, we define induced Hilbert space and induced sample space, and
propose that there exists an equivalence relation between a Hilbert space and a
sample space constructed from the same base observable(s). Then we investigate
Markov transition matrices and their eigenvectors to make diffusion maps with
two examples: a simple graph theory example, to serve as a prototype of
bidirectional transition operator; a famous text document example in IR
literature, to serve as a tutorial of diffusion map in text document space. We
show that the sample space of the Markov chain and the Hilbert space spanned by
the eigenvectors of the transition matrix are not equivalent. At the end, we
apply our PBN and equivalence proposal to Thermophysics by associating sample
(phase) space with the Hilbert space of a single particle and the Fock space of
many-particle systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702122</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702122</id><created>2007-02-22</created><authors><author><keyname>Michel</keyname><forenames>Thomas</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>Transmitter and Precoding Order Optimization for Nonlinear Downlink
  Beamforming</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Int. Symposium on Inf. Theory (ISIT) 2007</comments><abstract>  The downlink of a multiple-input multiple output (MIMO) broadcast channel
(BC) is considered, where each receiver is equipped with a single antenna and
the transmitter performs nonlinear Dirty-Paper Coding (DPC). We present an
efficient algorithm that finds the optimum transmit filters and power
allocation as well as the optimum precoding order(s) possibly affording
time-sharing between individual DPC orders. Subsequently necessary and
sufficient conditions for the optimality of an arbitrary precoding order are
derived. Based on these we propose a suboptimal algorithm showing excellent
performance and having low complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702123</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702123</id><created>2007-02-22</created><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author><author><keyname>Shtrakov</keyname><forenames>Vladimir</forenames></author></authors><title>Tree automata and separable sets of input variables</title><categories>cs.CC cs.DM</categories><comments>8 pages, 2 figures</comments><acm-class>F.1.1; F.1.3</acm-class><journal-ref>J. FILOMAT, v. 15, 2001, University of Nis, 61-71 p., ISSN
  0354-5180 (http://www.pmf.ni.ac.yu/sajt/publikacije/filomat_15.html)</journal-ref><abstract>  We consider the computational complexity of tree transducers, depending on
their separable sets of input variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702124</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702124</id><created>2007-02-22</created><updated>2012-03-02</updated><authors><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Kim</keyname><forenames>Jeong Han</forenames></author><author><keyname>saberi</keyname><forenames>Amin</forenames></author></authors><title>A Sequential Algorithm for Generating Random Graphs</title><categories>cs.CC cs.DM</categories><comments>39 pages</comments><journal-ref>Algorithmica (2010) 58: 860-910</journal-ref><doi>10.1007/s00453-009-9340-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a nearly-linear time algorithm for counting and randomly
generating simple graphs with a given degree sequence in a certain range. For
degree sequence $(d_i)_{i=1}^n$ with maximum degree $d_{\max}=O(m^{1/4-\tau})$,
our algorithm generates almost uniform random graphs with that degree sequence
in time $O(m\,d_{\max})$ where $m=\f{1}{2}\sum_id_i$ is the number of edges in
the graph and $\tau$ is any positive constant. The fastest known algorithm for
uniform generation of these graphs McKay Wormald (1990) has a running time of
$O(m^2d_{\max}^2)$. Our method also gives an independent proof of McKay's
estimate McKay (1985) for the number of such graphs.
  We also use sequential importance sampling to derive fully Polynomial-time
Randomized Approximation Schemes (FPRAS) for counting and uniformly generating
random graphs for the same range of $d_{\max}=O(m^{1/4-\tau})$.
  Moreover, we show that for $d = O(n^{1/2-\tau})$, our algorithm can generate
an asymptotically uniform $d$-regular graph. Our results improve the previous
bound of $d = O(n^{1/3-\tau})$ due to Kim and Vu (2004) for regular graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702125</id><created>2007-02-22</created><authors><author><keyname>Pluch</keyname><forenames>Philipp</forenames></author><author><keyname>Wakounig</keyname><forenames>Samo</forenames></author></authors><title>Bayesian Network Tomography and Inference</title><categories>cs.NI</categories><abstract>  The aim of this technical report is to give a short overview of known
techniques for network tomography (introduced in the paper of Vardi (1996)),
extended by a Bayesian approach originating Tebaldi and West (1998). Since the
studies of A.K. Erlang (1878-1929) on telephone networks in the last
millennium, lots of needs are seen in todays applications of networks and
network tomography, so for instance networks are a critical component of the
information structure supporting finance, commerce and even civil and national
defence. An attack on a network can be performed as an intrusion in the network
or as sending a lot of fault information and disturbing the network flow. Such
attacks can be detected by modelling the traffic flows in a network, by
counting the source destination packets and even by measuring counts over time
and by drawing a comparison with this 'time series' for instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702126</id><created>2007-02-22</created><authors><author><keyname>Nicosia</keyname><forenames>V.</forenames></author><author><keyname>Mangioni</keyname><forenames>G.</forenames></author><author><keyname>Carchiolo</keyname><forenames>V.</forenames></author><author><keyname>Malgeri</keyname><forenames>M.</forenames></author></authors><title>Efficient Searching and Retrieval of Documents in PROSA</title><categories>cs.DC cs.IR</categories><comments>12 pages, 3 figures</comments><abstract>  Retrieving resources in a distributed environment is more difficult than
finding data in centralised databases. In the last decade P2P system arise as
new and effective distributed architectures for resource sharing, but searching
in such environments could be difficult and time-consuming. In this paper we
discuss efficiency of resource discovery in PROSA, a self-organising P2P system
heavily inspired by social networks. All routing choices in PROSA are made
locally, looking only at the relevance of the next peer to each query. We show
that PROSA is able to effectively answer queries for rare documents, forwarding
them through the most convenient path to nodes that much probably share
matching resources. This result is heavily related to the small-world structure
that naturally emerges in PROSA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702127</id><created>2007-02-22</created><authors><author><keyname>Nicosia</keyname><forenames>V.</forenames></author><author><keyname>Mangioni</keyname><forenames>G.</forenames></author><author><keyname>Carchiolo</keyname><forenames>V.</forenames></author><author><keyname>Malgeri</keyname><forenames>M.</forenames></author></authors><title>Exploiting social networks dynamics for P2P resource organisation</title><categories>cs.DC cs.IR</categories><comments>9 pages, 4 figures</comments><journal-ref>Lecture Notes on Computer Science (LNCS) 4263 (2006)</journal-ref><abstract>  In this paper we present a formal description of PROSA, a P2P resource
management system heavily inspired by social networks. Social networks have
been deeply studied in the last two decades in order to understand how
communities of people arise and grow. It is a widely known result that networks
of social relationships usually evolves to small-worlds, i.e. networks where
nodes are strongly connected to neighbours and separated from all other nodes
by a small amount of hops. This work shows that algorithms implemented into
PROSA allow to obtain an efficient small-world P2P network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702128</id><created>2007-02-22</created><updated>2007-04-18</updated><authors><author><keyname>Huang</keyname><forenames>Xiangao</forenames></author><author><keyname>Huang</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Xiaozhou</forenames></author><author><keyname>Wang</keyname><forenames>Chao</forenames></author><author><keyname>Wang</keyname><forenames>Zhu jing</forenames></author><author><keyname>Wang</keyname><forenames>Tao</forenames></author></authors><title>Reconstructing the Nonlinear Filter Function of LILI-128 Stream Cipher
  Based on Complexity</title><categories>cs.CR</categories><comments>6 pages, 1 figure</comments><abstract>  In this letter we assert that we have reconstructed the nonlinear filter
function of LILI-128 stream cipher on IBM notebook PC using MATLAB. Our
reconstruction need approximately 2^12~2^13 and the attack consumes 5825.016
sec (using tic and toc sentences of MATLAB) or 5825.016/3600=1.6181hours. We
got the expression of the nonlinear filter function fd of Lili-128 which has 46
items from liner items to nonlinear items based on complexity, the phase space
reconstruction, Clustering and nonlinear prediction. We have verified our
reconstruction result correctness by simulating the overview of Lili-128
keystream generators using our getting fd and implement designers reference
module of the Lili-128 stream cipher, and two methods produce the same
synchronous keystream sequence on same initial state, so that our research work
proves that the nonlinear filter function of LILI-128 stream cipher is
successfully reconstructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702129</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702129</id><created>2007-02-22</created><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author></authors><title>Tree Automata and Essential Input Variables</title><categories>cs.CC cs.DM</categories><comments>10 pages, 2 figures, 60th Workshop on General Algebra, June 22-25,
  2000, TU Dresden</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>J. Contributions to General Algebra, v.13, Verlag Johannes Heyn,
  Klagenfurt, 2001, 309-319 p</journal-ref><abstract>  We introduce and study the essential inputs (variables) for terms (trees) and
tree automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702130</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702130</id><created>2007-02-22</created><authors><author><keyname>Schmidt</keyname><forenames>Georg</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir R.</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author></authors><title>Syndrome Decoding of Reed-Solomon Codes Beyond Half the Minimum Distance
  based on Shift-Register Synthesis</title><categories>cs.IT math.IT</categories><comments>14 pages, 5 figures</comments><abstract>  In this paper, a new approach for decoding low-rate Reed-Solomon codes beyond
half the minimum distance is considered and analyzed. Unlike the Sudan
algorithm published in 1997, this new approach is based on multi-sequence
shift-register synthesis, which makes it easy to understand and simple to
implement. The computational complexity of this shift-register based algorithm
is of the same order as the complexity of the well-known Berlekamp-Massey
algorithm. Moreover, the error correcting radius coincides with the error
correcting radius of the original Sudan algorithm, and the practical decoding
performance observed on a q-ary symmetric channel (QSC) is virtually identical
to the decoding performance of the Sudan algorithm. Bounds for the failure and
error probability as well as for the QSC decoding performance of the new
algorithm are derived, and the performance is illustrated by means of examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702131</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702131</id><created>2007-02-22</created><authors><author><keyname>Macpherson</keyname><forenames>Graham B.</forenames></author><author><keyname>Reese</keyname><forenames>Jason M.</forenames></author></authors><title>AICA: a New Pair Force Evaluation Method for Parallel Molecular Dynamics
  in Arbitrary Geometries</title><categories>cs.CE cs.DC</categories><abstract>  A new algorithm for calculating intermolecular pair forces in Molecular
Dynamics (MD) simulations on a distributed parallel computer is presented. The
Arbitrary Interacting Cells Algorithm (AICA) is designed to operate on
geometrical domains defined by an unstructured, arbitrary polyhedral mesh,
which has been spatially decomposed into irregular portions for
parallelisation. It is intended for nano scale fluid mechanics simulation by MD
in complex geometries, and to provide the MD component of a hybrid MD/continuum
simulation. AICA has been implemented in the open-source computational toolbox
OpenFOAM, and verified against a published MD code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702132</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702132</id><created>2007-02-22</created><updated>2009-02-05</updated><authors><author><keyname>Chandrasekhar</keyname><forenames>Vikram</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Uplink Capacity and Interference Avoidance for Two-Tier Femtocell
  Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>To be published in the IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-tier femtocell networks-- comprising a conventional macrocellular network
plus embedded femtocell hotspots-- offer an economically viable solution to
achieving high cellular user capacity and improved coverage. With universal
frequency reuse and DS-CDMA transmission however, the ensuing cross-tier
cochannel interference (CCI) causes unacceptable outage probability. This paper
develops an uplink capacity analysis and interference avoidance strategy in
such a two-tier CDMA network. We evaluate a network-wide area spectral
efficiency metric called the \emph{operating contour (OC)} defined as the
feasible combinations of the average number of active macrocell users and
femtocell base stations (BS) per cell-site that satisfy a target outage
constraint. The capacity analysis provides an accurate characterization of the
uplink outage probability, accounting for power control, path-loss and
shadowing effects. Considering worst case CCI at a corner femtocell, results
reveal that interference avoidance through a time-hopped CDMA physical layer
and sectorized antennas allows about a 7x higher femtocell density, relative to
a split spectrum two-tier network with omnidirectional femtocell antennas. A
femtocell exclusion region and a tier selection based handoff policy offers
modest improvements in the OCs. These results provide guidelines for the design
of robust shared spectrum two-tier networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702133</id><created>2007-02-22</created><authors><author><keyname>Yatsenko</keyname><forenames>Vadim</forenames></author></authors><title>Fast Exact Method for Solving the Travelling Salesman Problem</title><categories>cs.CC</categories><comments>4 pages, 4 figures</comments><acm-class>I.2.8; G.1.6</acm-class><abstract>  This paper describes TSP exact solution of polynomial complexity. It is
considered properties of proposed method. Effectiveness of proposed solution is
illustrated by outcomes of computer modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702134</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702134</id><created>2007-02-23</created><updated>2012-06-27</updated><authors><author><keyname>Sati</keyname><forenames>Pankaj</forenames></author></authors><title>Patterns of technological progress: A Predictability-Based Perspective</title><categories>cs.CY</categories><comments>Paper has been withdrawn</comments><acm-class>K.4</acm-class><abstract>  The paper tries to identify new emerging patterns in the context of
technological progress. Just as industrialization is associated with
rationalization, mechanization, and automation, the Internet age is associated
with computer models, embedded knowledge, and collaboration. Comparison among
patterns is highlighted and analysis is done from predictability-based
perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702135</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702135</id><created>2007-02-23</created><authors><author><keyname>Zwart</keyname><forenames>Simon Portegies</forenames></author><author><keyname>Belleman</keyname><forenames>Robert</forenames></author><author><keyname>Geldof</keyname><forenames>Peter</forenames></author></authors><title>High Performance Direct Gravitational N-body Simulations on Graphics
  Processing Units</title><categories>cs.PF</categories><comments>Submitted to New Astronomy</comments><doi>10.1016/j.newast.2007.05.004</doi><abstract>  We present the results of gravitational direct $N$-body simulations using the
commercial graphics processing units (GPU) NVIDIA Quadro FX1400 and GeForce
8800GTX, and compare the results with GRAPE-6Af special purpose hardware. The
force evaluation of the $N$-body problem was implemented in Cg using the GPU
directly to speed-up the calculations. The integration of the equations of
motions were, running on the host computer, implemented in C using the 4th
order predictor-corrector Hermite integrator with block time steps. We find
that for a large number of particles ($N \apgt 10^4$) modern graphics
processing units offer an attractive low cost alternative to GRAPE special
purpose hardware. A modern GPU continues to give a relatively flat scaling with
the number of particles, comparable to that of the GRAPE. Using the same time
step criterion the total energy of the $N$-body system was conserved better
than to one in $10^6$ on the GPU, which is only about an order of magnitude
worse than obtained with GRAPE. For $N\apgt 10^6$ the GeForce 8800GTX was about
20 times faster than the host computer. Though still about an order of
magnitude slower than GRAPE, modern GPU's outperform GRAPE in their low cost,
long mean time between failure and the much larger onboard memory; the
GRAPE-6Af holds at most 256k particles whereas the GeForce 8800GTF can hold 9
million particles in memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702136</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702136</id><created>2007-02-23</created><authors><author><keyname>Damyanov</keyname><forenames>Ivo</forenames></author><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author></authors><title>Essential Inputs and Minimal Tree Automata</title><categories>cs.CC cs.DM</categories><comments>7 pages, 1 figure, Sixth International Conference on Discrete
  Mathematics and Applications, 31.08-02.09.2001, Bansko</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Proc. of ICDMA, 31.08-02.09.2001, Bansko, v.6, 77-85 p</journal-ref><abstract>  We continue studying essential inputs of trees and automata. Strongly
essential inputs of trees are introduced and studied. Various examples for
application in Computer Science are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702137</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702137</id><created>2007-02-23</created><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author></authors><title>Tree Automata and Essential Subtrees</title><categories>cs.CC cs.DM</categories><comments>9 pages, 2 figures, Sixth International Conference on Discrete
  Mathematics and Applications, Bansko, 2001</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Proc. of ICDMA, 31.08-02.09.2001, Bansko, v.6, 51-60 p</journal-ref><abstract>  We introduce essential subtrees for terms (trees) and tree automata . There
are some results concerning independent sets of subtrees and separable sets for
a tree and an automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702138</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702138</id><created>2007-02-23</created><authors><author><keyname>Jalden</keyname><forenames>J.</forenames></author><author><keyname>Ottersten</keyname><forenames>B.</forenames></author></authors><title>On the Maximal Diversity Order of Spatial Multiplexing with Transmit
  Antenna Selection</title><categories>cs.IT math.IT</categories><comments>10 pages. Submitted to the IEEE Transactions on Information Theory</comments><abstract>  Zhang et. al. recently derived upper and lower bounds on the achievable
diversity of an N_R x N_T i.i.d. Rayleigh fading multiple antenna system using
transmit antenna selection, spatial multiplexing and a linear receiver
structure. For the case of L = 2 transmitting (out of N_T available) antennas
the bounds are tight and therefore specify the maximal diversity order. For the
general case with L &lt;= min(N_R,N_T) transmitting antennas it was conjectured
that the maximal diversity is (N_T-L+1)(N_R-L+1) which coincides with the lower
bound. Herein, we prove this conjecture for the zero forcing and zero forcing
decision feedback (with optimal detection ordering) receiver structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702139</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702139</id><created>2007-02-23</created><authors><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author><author><keyname>Kholosha</keyname><forenames>Alexander</forenames></author><author><keyname>Ness</keyname><forenames>Geir Jarle</forenames></author></authors><title>Characterization of $m$-Sequences of Lengths $2^{2k}-1$ and $2^k-1$ with
  Three-Valued Crosscorrelation</title><categories>cs.CR cs.DM</categories><comments>23 pages</comments><abstract>  Considered is the distribution of the crosscorrelation between $m$-sequences
of length $2^m-1$, where $m=2k$, and $m$-sequences of shorter length $2^k-1$.
New pairs of $m$-sequences with three-valued crosscorrelation are found and the
complete correlation distribution is determined. Finally, we conjecture that
there are no more cases with a three-valued crosscorrelation apart from the
ones proven here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702140</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702140</id><created>2007-02-23</created><authors><author><keyname>Wilkinson</keyname><forenames>Dennis M.</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Assessing the Value of Coooperation in Wikipedia</title><categories>cs.DL cs.CY physics.soc-ph</categories><abstract>  Since its inception six years ago, the online encyclopedia Wikipedia has
accumulated 6.40 million articles and 250 million edits, contributed in a
predominantly undirected and haphazard fashion by 5.77 million unvetted
volunteers. Despite the apparent lack of order, the 50 million edits by 4.8
million contributors to the 1.5 million articles in the English-language
Wikipedia follow strong certain overall regularities. We show that the
accretion of edits to an article is described by a simple stochastic mechanism,
resulting in a heavy tail of highly visible articles with a large number of
edits. We also demonstrate a crucial correlation between article quality and
number of edits, which validates Wikipedia as a successful collaborative
effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702141</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702141</id><created>2007-02-23</created><authors><author><keyname>Crenshaw</keyname><forenames>Tanya L.</forenames></author><author><keyname>Chambers</keyname><forenames>Erin Wolf</forenames></author><author><keyname>Metcalf</keyname><forenames>Heather</forenames></author><author><keyname>Thakkar</keyname><forenames>Umesh</forenames></author></authors><title>Recruitment, Preparation, Retention: A case study of computing culture
  at the University of Illinois at Urbana-Champaign</title><categories>cs.GL</categories><comments>37 pages, 13 figures. For better quality figures, please download the
  .pdf from
  http://www.cs.uiuc.edu/research/techreports.php?report=UIUCDCS-R-2007-2811</comments><report-no>UIUCDCS-R-2007-2811</report-no><acm-class>K.3.2</acm-class><abstract>  Computer science is seeing a decline in enrollment at all levels of
education, including undergraduate and graduate study. This paper reports on
the results of a study conducted at the University of Illinois at
Urbana-Champaign which evaluated students attitudes regarding three areas which
can contribute to improved enrollment in the Department of Computer Science:
Recruitment, preparation and retention. The results of our study saw two
themes. First, the department's tight research focus appears to draw
significant attention from other activities -- such as teaching, service, and
other community-building activities -- that are necessary for a department's
excellence. Yet, as demonstrated by our second theme, one partial solution is
to better promote such activities already employed by the department to its
students and faculty. Based on our results, we make recommendations for
improvements and enhancements based on the current state of practice at peer
institutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702142</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702142</id><created>2007-02-23</created><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Brooks</keyname><forenames>Martin</forenames></author><author><keyname>Yan</keyname><forenames>Yuhong</forenames></author></authors><title>An Optimal Linear Time Algorithm for Quasi-Monotonic Segmentation</title><categories>cs.DS cs.DB</categories><comments>Appeared in ICDM 2005</comments><abstract>  Monotonicity is a simple yet significant qualitative characteristic. We
consider the problem of segmenting an array in up to K segments. We want
segments to be as monotonic as possible and to alternate signs. We propose a
quality metric for this problem, present an optimal linear time algorithm based
on novel formalism, and compare experimentally its performance to a linear time
top-down regression algorithm. We show that our algorithm is faster and more
accurate. Applications include pattern recognition and qualitative modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702143</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702143</id><created>2007-02-23</created><authors><author><keyname>Kaser</keyname><forenames>Owen</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Attribute Value Reordering For Efficient Hybrid OLAP</title><categories>cs.DB</categories><journal-ref>Owen Kaser, Daniel Lemire, Attribute Value Reordering For
  Efficient Hybrid OLAP, Information Sciences, Volume 176, Issue 16, 2006,
  Pages 2304-2336</journal-ref><doi>10.1016/j.ins.2005.09.005</doi><abstract>  The normalization of a data cube is the ordering of the attribute values. For
large multidimensional arrays where dense and sparse chunks are stored
differently, proper normalization can lead to improved storage efficiency. We
show that it is NP-hard to compute an optimal normalization even for 1x3
chunks, although we find an exact algorithm for 1x2 chunks. When dimensions are
nearly statistically independent, we show that dimension-wise attribute
frequency sorting is an optimal normalization and takes time O(d n log(n)) for
data cubes of size n^d. When dimensions are not independent, we propose and
evaluate several heuristics. The hybrid OLAP (HOLAP) storage mechanism is
already 19%-30% more efficient than ROLAP, but normalization can improve it
further by 9%-13% for a total gain of 29%-44% over ROLAP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702144</identifier>
 <datestamp>2009-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702144</id><created>2007-02-23</created><updated>2008-09-15</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Maclachlan</keyname><forenames>Anna</forenames></author></authors><title>Slope One Predictors for Online Rating-Based Collaborative Filtering</title><categories>cs.DB</categories><comments>In SIAM Data Mining (SDM'05), Newport Beach, California, April 21-23,
  2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rating-based collaborative filtering is the process of predicting how a user
would rate a given item from other user ratings. We propose three related slope
one schemes with predictors of the form f(x) = x + b, which precompute the
average difference between the ratings of one item and another for users who
rated both. Slope one algorithms are easy to implement, efficient to query,
reasonably accurate, and they support both online queries and dynamic updates,
which makes them good candidates for real-world systems. The basic slope one
scheme is suggested as a new reference scheme for collaborative filtering. By
factoring in items that a user liked separately from items that a user
disliked, we achieve results competitive with slower memory-based schemes over
the standard benchmark EachMovie and Movielens data sets while better
fulfilling the desiderata of CF applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702145</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702145</id><created>2007-02-24</created><authors><author><keyname>Venugopal</keyname><forenames>Srikumar</forenames></author><author><keyname>Nadiminti</keyname><forenames>Krishna</forenames></author><author><keyname>Gibbins</keyname><forenames>Hussein</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Designing a Resource Broker for Heterogeneous Grids</title><categories>cs.DC cs.SE</categories><comments>26 pages, 15 figures</comments><report-no>GRIDS-TR-2007-2</report-no><acm-class>C.2.4; D.2.11</acm-class><abstract>  Grids provide uniform access to aggregations of heterogeneous resources and
services such as computers, networks and storage owned by multiple
organizations. However, such a dynamic environment poses many challenges for
application composition and deployment. In this paper, we present the design of
the Gridbus Grid resource broker that allows users to create applications and
specify different objectives through different interfaces without having to
deal with the complexity of Grid infrastructure. We present the unique
requirements that motivated our design and discuss how these provide
flexibility in extending the functionality of the broker to support different
low-level middlewares and user interfaces. We evaluate the broker with
different job profiles and Grid middleware and conclude with the lessons learnt
from our development experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702146</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702146</id><created>2007-02-24</created><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author></authors><title>A Local Tree Structure is NOT Sufficient for the Local Optimality of
  Message-Passing Decoding in Low Density Parity Check Codes</title><categories>cs.IT math.IT</categories><comments>Comments, submitted to IEEE Transactions on Information Theory</comments><abstract>  We address the problem,`Is a local tree structure sufficient for the local
optimality of message passing algorithm in low density parity check codes?'.It
is shown that the answer is negative. Using this observation, we pinpoint a
flaw in the proof of Theorem 1 in the paper `The Capacity of Low-Density
Parity-Check Codes Under Message-Passing Decoding' by Thomas J. Richardson and
R\&quot;udiger L.Urbanke\cite{RUCapacity}. We further provide a new proof of that
theorem based on a different argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702147</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702147</id><created>2007-02-24</created><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>On the Complexity of Exact Maximum-Likelihood Decoding for
  Asymptotically Good Low Density Parity Check Codes</title><categories>cs.IT math.IT</categories><comments>an attempt at exploring the communication complexity limit,5
  pages,submitted to 2007 IEEE International Symposium on Information Theory
  (ISIT 2007)</comments><abstract>  Since the classical work of Berlekamp, McEliece and van Tilborg, it is well
known that the problem of exact maximum-likelihood (ML) decoding of general
linear codes is NP-hard. In this paper, we show that exact ML decoding of a
classs of asymptotically good error correcting codes--expander codes, a special
case of low density parity check (LDPC) codes--over binary symmetric channels
(BSCs) is possible with an expected polynomial complexity. More precisely, for
any bit-flipping probability, $p$, in a nontrivial range, there exists a rate
region of non-zero support and a family of asymptotically good codes, whose
error probability decays exponentially in coding length $n$, for which ML
decoding is feasible in expected polynomial time. Furthermore, as $p$
approaches zero, this rate region approaches the channel capacity region. The
result is based on the existence of polynomial-time suboptimal decoding
algorithms that provide an ML certificate and the ability to compute the
probability that the suboptimal decoder yields the ML solution. One such ML
certificate decoder is the LP decoder of Feldman; we also propose a more
efficient $O(n^2)$ algorithm based on the work of Sipser and Spielman and the
Ford-Fulkerson algorithm. The results can be extended to AWGN channels and
suggest that it may be feasible to eliminate the error floor phenomenon
associated with message-passage decoding of LDPC codes in the high SNR regime.
Finally, we observe that the argument of Berlekamp, McEliece and van Tilborg
can be used to show that ML decoding of the considered class of codes
constructed from LDPC codes with regular left degree, of which the considered
expander codes are a special case, remains NP-hard; thus giving an interesting
contrast between the worst-case and expected complexities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702148</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702148</id><created>2007-02-25</created><authors><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Linking Microscopic and Macroscopic Models for Evolution: Markov Chain
  Network Training and Conservation Law Approximations</title><categories>cs.CE cs.IT cs.NA cs.NE math.IT</categories><comments>21 pages, 5 figures</comments><journal-ref>Markov Chain network training and conservation law approximations:
  Linking microscopic and macroscopic models for evolution, Melnik, R.V.N.,
  Applied Mathematics and Computation, 199 (1), 315--333, 2008</journal-ref><abstract>  In this paper, a general framework for the analysis of a connection between
the training of artificial neural networks via the dynamics of Markov chains
and the approximation of conservation law equations is proposed. This framework
allows us to demonstrate an intrinsic link between microscopic and macroscopic
models for evolution via the concept of perturbed generalized dynamic systems.
The main result is exemplified with a number of illustrative examples where
efficient numerical approximations follow directly from network-based
computational models, viewed here as Markov chain approximations. Finally,
stability and consistency conditions of such computational models are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702149</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702149</id><created>2007-02-25</created><authors><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Coupling Control and Human-Centered Automation in Mathematical Models of
  Complex Systems</title><categories>cs.CE cs.AI cs.HC cs.IT math.IT</categories><comments>19 pages</comments><abstract>  In this paper we analyze mathematically how human factors can be effectively
incorporated into the analysis and control of complex systems. As an example,
we focus our discussion around one of the key problems in the Intelligent
Transportation Systems (ITS) theory and practice, the problem of speed control,
considered here as a decision making process with limited information
available. The problem is cast mathematically in the general framework of
control problems and is treated in the context of dynamically changing
environments where control is coupled to human-centered automation. Since in
this case control might not be limited to a small number of control settings,
as it is often assumed in the control literature, serious difficulties arise in
the solution of this problem. We demonstrate that the problem can be reduced to
a set of Hamilton-Jacobi-Bellman equations where human factors are incorporated
via estimations of the system Hamiltonian. In the ITS context, these
estimations can be obtained with the use of on-board equipment like
sensors/receivers/actuators, in-vehicle communication devices, etc. The
proposed methodology provides a way to integrate human factor into the solving
process of the models for other complex dynamic systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702150</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702150</id><created>2007-02-25</created><authors><author><keyname>Gray</keyname><forenames>Robert M.</forenames></author><author><keyname>Hashimoto</keyname><forenames>Takeshi</forenames></author></authors><title>A note on rate-distortion functions for nonstationary Gaussian
  autoregressive processes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><acm-class>E.4</acm-class><abstract>  Source coding theorems and Shannon rate-distortion functions were studied for
the discrete-time Wiener process by Berger and generalized to nonstationary
Gaussian autoregressive processes by Gray and by Hashimoto and Arimoto.
Hashimoto and Arimoto provided an example apparently contradicting the methods
used in Gray, implied that Gray's rate-distortion evaluation was not correct in
the nonstationary case, and derived a new formula that agreed with previous
results for the stationary case and held in the nonstationary case. In this
correspondence it is shown that the rate-distortion formulas of Gray and
Hashimoto and Arimoto are in fact consistent and that the example of of
Hashimoto and Arimoto does not form a counter example to the methods or results
of the earlier paper. Their results do provide an alternative, but equivalent,
formula for the rate-distortion function in the nonstationary case and they
provide a concrete example that the classic Kolmogorov formula differs from the
autoregressive formula when the autoregressive source is not stationary. Some
observations are offered on the different versions of the Toeplitz asymptotic
eigenvalue distribution theorem used in the two papers to emphasize how a
slight modification of the classic theorem avoids the problems with certain
singularities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702151</identifier>
 <datestamp>2008-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702151</id><created>2007-02-25</created><updated>2008-04-14</updated><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author><author><keyname>Zaniolo</keyname><forenames>Carlo</forenames></author></authors><title>Succinct Sampling on Streams</title><categories>cs.DS</categories><abstract>  A streaming model is one where data items arrive over long period of time,
either one item at a time or in bursts. Typical tasks include computing various
statistics over a sliding window of some fixed time-horizon. What makes the
streaming model interesting is that as the time progresses, old items expire
and new ones arrive. One of the simplest and central tasks in this model is
sampling. That is, the task of maintaining up to $k$ uniformly distributed
items from a current time-window as old items expire and new ones arrive. We
call sampling algorithms {\bf succinct} if they use provably optimal (up to
constant factors) {\bf worst-case} memory to maintain $k$ items (either with or
without replacement). We stress that in many applications structures that have
{\em expected} succinct representation as the time progresses are not
sufficient, as small probability events eventually happen with probability 1.
Thus, in this paper we ask the following question: are Succinct Sampling on
Streams (or $S^3$-algorithms)possible, and if so for what models? Perhaps
somewhat surprisingly, we show that $S^3$-algorithms are possible for {\em all}
variants of the problem mentioned above, i.e. both with and without replacement
and both for one-at-a-time and bursty arrival models. Finally, we use $S^3$
algorithms to solve various problems in sliding windows model, including
frequency moments, counting triangles, entropy and density estimations. For
these problems we present \emph{first} solutions with provable worst-case
memory guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702152</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702152</id><created>2007-02-25</created><authors><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author></authors><title>A Simplified Suspension Calculus and its Relationship to Other Explicit
  Substitution Calculi</title><categories>cs.LO</categories><comments>38 pages</comments><abstract>  This paper concerns the explicit treatment of substitutions in the lambda
calculus. One of its contributions is the simplification and rationalization of
the suspension calculus that embodies such a treatment. The earlier version of
this calculus provides a cumbersome encoding of substitution composition, an
operation that is important to the efficient realization of reduction. This
encoding is simplified here, resulting in a treatment that is easy to use
directly in applications. The rationalization consists of the elimination of a
practically inconsequential flexibility in the unravelling of substitutions
that has the inadvertent side effect of losing contextual information in terms;
the modified calculus now has a structure that naturally supports logical
analyses, such as ones related to the assignment of types, over lambda terms.
The overall calculus is shown to have pleasing theoretical properties such as a
strongly terminating sub-calculus for substitution and confluence even in the
presence of term meta variables that are accorded a grafting interpretation.
Another contribution of the paper is the identification of a broad set of
properties that are desirable for explicit substitution calculi to support and
a classification of a variety of proposed systems based on these. The
suspension calculus is used as a tool in this study. In particular, mappings
are described between it and the other calculi towards understanding the
characteristics of the latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702153</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702153</id><created>2007-02-26</created><authors><author><keyname>Burke</keyname><forenames>Kyle</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Games on the Sperner Triangle</title><categories>cs.GT cs.CC</categories><comments>18 pages, 19 figures. Uses paithan.sty</comments><acm-class>F.1.3</acm-class><abstract>  We create a new two-player game on the Sperner Triangle based on Sperner's
lemma. Our game has simple rules and several desirable properties. First, the
game is always certain to have a winner. Second, like many other interesting
games such as Hex and Geography, we prove that deciding whether one can win our
game is a PSPACE-complete problem. Third, there is an elegant balance in the
game such that neither the first nor the second player always has a decisive
advantage. We provide a web-based version of the game, playable at:
http://cs-people.bu.edu/paithan/spernerGame/ . In addition we propose other
games, also based on fixed-point theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702154</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702154</id><created>2007-02-27</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>On the Capacity of the Single Source Multiple Relay Single Destination
  Mesh Network</title><categories>cs.IT cs.NI math.IT</categories><comments>to appear in Elsevier Ad Hoc Networks: Special Issue on Wireless Mesh
  Networks, accepted on 9 Dec. 2006</comments><journal-ref>Elsevier Ad Hoc Networks: Special Issue on Wireless Mesh Networks,
  Vol. 5, No. 6, pp. 786-800, Aug. 2007.</journal-ref><doi>10.1016/j.adhoc.2006.12.006</doi><abstract>  In this paper, we derive the information theoretic capacity of a special
class of mesh networks. A mesh network is a heterogeneous wireless network in
which the transmission among power limited nodes is assisted by powerful
relays, which use the same wireless medium. We investigate the mesh network
when there is one source, one destination, and multiple relays, which we call
the single source multiple relay single destination (SSMRSD) mesh network. We
derive the asymptotic capacity of the SSMRSD mesh network when the relay powers
grow to infinity. Our approach is as follows. We first look at an upper bound
on the information theoretic capacity of these networks in a Gaussian setting.
We then show that this bound is achievable asymptotically using the
compress-and-forward strategy for the multiple relay channel. We also perform
numerical computations for the case when the relays have finite powers. We
observe that even when the relay power is only a few times larger than the
source power, the compress-and-forward rate gets close to the capacity. The
results indicate the value of cooperation in wireless mesh networks. The
capacity characterization quantifies how the relays can cooperate, using the
compress-and-forward strategy, to either conserve node energy or to increase
transmission rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702155</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702155</id><created>2007-02-27</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>On a characterization of cellular automata in tilings of the hyperbolic
  plane</title><categories>cs.DM cs.CG</categories><acm-class>F.2.2</acm-class><journal-ref>International Journal of Foundations of Computer Science, volume
  19,(5), (2008), 1235-1257</journal-ref><abstract>  In this paper, we look at the extention of Hedlund's characterization of
cellular automata to the case of cellular automata in the hyperbolic plane.
This requires an additionnal condition. The new theorem is proved with full
details in the case of the pentagrid and in the case of the ternary heptagrid
and enough indications to show that it holds also on the grids $\{p,q\}$ of the
hyperbolic plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702156</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702156</id><created>2007-02-27</created><updated>2008-06-06</updated><authors><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Analysis of Steiner subtrees of Random Trees for Traceroute Algorithms</title><categories>cs.NI cs.DS</categories><proxy>ccsd inria-00133676</proxy><journal-ref>Random Structures and Algorithms, 35(2):194-215, September 2009</journal-ref><abstract>  We consider in this paper the problem of discovering, via a traceroute
algorithm, the topology of a network, whose graph is spanned by an infinite
branching process. A subset of nodes is selected according to some criterion.
As a measure of efficiency of the algorithm, the Steiner distance of the
selected nodes, i.e. the size of the spanning sub-tree of these nodes, is
investigated. For the selection of nodes, two criteria are considered: A node
is randomly selected with a probability, which is either independent of the
depth of the node (uniform model) or else in the depth biased model, is
exponentially decaying with respect to its depth. The limiting behavior the
size of the discovered subtree is investigated for both models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702157</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702157</id><created>2007-02-27</created><authors><author><keyname>Ripeanu</keyname><forenames>Matei</forenames></author><author><keyname>Iamnitchi</keyname><forenames>Adriana</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Rogers</keyname><forenames>Anne</forenames></author></authors><title>In Search of Simplicity: A Self-Organizing Multi-Source Multicast
  Overlay</title><categories>cs.DC cs.NI cs.PF</categories><report-no>DSL-TR-2007-02</report-no><abstract>  Multicast communication primitives have broad utility as building blocks for
distributed applications. The challenge is to create and maintain the
distributed structures that support these primitives while accounting for
volatile end nodes and variable network characteristics. Most solutions
proposed to date rely on complex algorithms or global information, thus
limiting the scale of deployments and acceptance outside the academic realm.
This article introduces a low-complexity, self organizing solution for
maintaining multicast trees, that we refer to as UMM (Unstructured Multi-source
Multicast). UMM uses traditional distributed systems techniques: layering,
soft-state, and passive data collection to adapt to the dynamics of the
physical network and maintain data dissemination trees. The result is a simple,
adaptive system with lower overheads than more complex alternatives. We have
implemented UMM and evaluated it on a 100-node PlanetLab testbed and on up to
1024-node emulated ModelNet networks Extensive experimental evaluations
demonstrate UMM's low overhead, efficient network usage compared to alternative
solutions, and ability to quickly adapt to network changes and to recover from
failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702158</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702158</id><created>2007-02-27</created><authors><author><keyname>Chen</keyname><forenames>Yunxia</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Joint Design and Separation Principle for Opportunistic Spectrum Access
  in the Presence of Sensing Errors</title><categories>cs.NI</categories><comments>43 pages, 10 figures, submitted to IEEE Transactions on Information
  Theory in Feb. 2007</comments><acm-class>C.2.1</acm-class><abstract>  We address the design of opportunistic spectrum access (OSA) strategies that
allow secondary users to independently search for and exploit instantaneous
spectrum availability. Integrated in the joint design are three basic
components: a spectrum sensor that identifies spectrum opportunities, a sensing
strategy that determines which channels in the spectrum to sense, and an access
strategy that decides whether to access based on imperfect sensing outcomes.
  We formulate the joint PHY-MAC design of OSA as a constrained partially
observable Markov decision process (POMDP). Constrained POMDPs generally
require randomized policies to achieve optimality, which are often intractable.
By exploiting the rich structure of the underlying problem, we establish a
separation principle for the joint design of OSA. This separation principle
reveals the optimality of myopic policies for the design of the spectrum sensor
and the access strategy, leading to closed-form optimal solutions. Furthermore,
decoupling the design of the sensing strategy from that of the spectrum sensor
and the access strategy, the separation principle reduces the constrained POMDP
to an unconstrained one, which admits deterministic optimal policies. Numerical
examples are provided to study the design tradeoffs, the interaction between
the spectrum sensor and the sensing and access strategies, and the robustness
of the ensuing design to model mismatch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702159</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702159</id><created>2007-02-27</created><authors><author><keyname>Botelho</keyname><forenames>Fabiano C.</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author><author><keyname>Ziviani</keyname><forenames>Nivio</forenames></author></authors><title>Perfect Hashing for Data Management Applications</title><categories>cs.DS cs.DB</categories><comments>12 pages</comments><report-no>RT.DCC.002/2007</report-no><acm-class>E.1</acm-class><abstract>  Perfect hash functions can potentially be used to compress data in connection
with a variety of data management tasks. Though there has been considerable
work on how to construct good perfect hash functions, there is a gap between
theory and practice among all previous methods on minimal perfect hashing. On
one side, there are good theoretical results without experimentally proven
practicality for large key sets. On the other side, there are the theoretically
analyzed time and space usage algorithms that assume that truly random hash
functions are available for free, which is an unrealistic assumption. In this
paper we attempt to bridge this gap between theory and practice, using a number
of techniques from the literature to obtain a novel scheme that is
theoretically well-understood and at the same time achieves an
order-of-magnitude increase in performance compared to previous ``practical''
methods. This improvement comes from a combination of a novel, theoretically
optimal perfect hashing scheme that greatly simplifies previous methods, and
the fact that our algorithm is designed to make good use of the memory
hierarchy. We demonstrate the scalability of our algorithm by considering a set
of over one billion URLs from the World Wide Web of average length 64, for
which we construct a minimal perfect hash function on a commodity PC in a
little more than 1 hour. Our scheme produces minimal perfect hash functions
using slightly more than 3 bits per key. For perfect hash functions in the
range $\{0,...,2n-1\}$ the space usage drops to just over 2 bits per key (i.e.,
one bit more than optimal for representing the key). This is significantly
below of what has been achieved previously for very large values of $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702160</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702160</id><created>2007-02-27</created><authors><author><keyname>Pitt</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>A Quantifier-Free String Theory for ALOGTIME Reasoning</title><categories>cs.CC</categories><comments>147 pages, PhD thesis (completed in 2000)</comments><acm-class>F.1.3; F.2.2</acm-class><abstract>  The main contribution of this work is the definition of a quantifier-free
string theory T_1 suitable for formalizing ALOGTIME reasoning. After describing
L_1 -- a new, simple, algebraic characterization of the complexity class
ALOGTIME based on strings instead of numbers -- the theory T_1 is defined
(based on L_1), and a detailed formal development of T_1 is given.
  Then, theorems of T_1 are shown to translate into families of propositional
tautologies that have uniform polysize Frege proofs, T_1 is shown to prove the
soundness of a particular Frege system F, and F is shown to provably p-simulate
any proof system whose soundness can be proved in T_1. Finally, T_1 is compared
with other theories for ALOGTIME reasoning in the literature.
  To our knowledge, this is the first formal theory for ALOGTIME reasoning
whose basic objects are strings instead of numbers, and the first
quantifier-free theory formalizing ALOGTIME reasoning in which a direct proof
of the soundness of some Frege system has been given (in the case of
first-order theories, such a proof was first given by Arai for his theory AID).
Also, the polysize Frege proofs we give for the propositional translations of
theorems of T_1 are considerably simpler than those for other theories, and so
is our proof of the soundness of a particular F-system in T_1. Together with
the simplicity of T_1's recursion schemes, axioms, and rules these facts
suggest that T_1 is one of the most natural theories available for ALOGTIME
reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702161</identifier>
 <datestamp>2008-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702161</id><created>2007-02-27</created><updated>2007-12-25</updated><authors><author><keyname>Wang</keyname><forenames>Ying</forenames></author><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>Perfectly Secure Steganography: Capacity, Error Exponents, and Code
  Constructions</title><categories>cs.IT cs.CR math.IT</categories><comments>To appear in IEEE Trans. on Information Theory, June 2008; ignore
  Version 2 as the file was corrupted</comments><abstract>  An analysis of steganographic systems subject to the following perfect
undetectability condition is presented in this paper. Following embedding of
the message into the covertext, the resulting stegotext is required to have
exactly the same probability distribution as the covertext. Then no statistical
test can reliably detect the presence of the hidden message. We refer to such
steganographic schemes as perfectly secure. A few such schemes have been
proposed in recent literature, but they have vanishing rate. We prove that
communication performance can potentially be vastly improved; specifically, our
basic setup assumes independently and identically distributed (i.i.d.)
covertext, and we construct perfectly secure steganographic codes from public
watermarking codes using binning methods and randomized permutations of the
code. The permutation is a secret key shared between encoder and decoder. We
derive (positive) capacity and random-coding exponents for perfectly-secure
steganographic systems. The error exponents provide estimates of the code
length required to achieve a target low error probability. We address the
potential loss in communication performance due to the perfect-security
requirement. This loss is the same as the loss obtained under a weaker order-1
steganographic requirement that would just require matching of first-order
marginals of the covertext and stegotext distributions. Furthermore, no loss
occurs if the covertext distribution is uniform and the distortion metric is
cyclically symmetric; steganographic capacity is then achieved by randomized
linear codes. Our framework may also be useful for developing computationally
secure steganographic systems that have near-optimal communication performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702162</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702162</id><created>2007-02-28</created><updated>2008-01-18</updated><authors><author><keyname>Pang</keyname><forenames>Jong-Shi</forenames></author><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author><author><keyname>Facchinei</keyname><forenames>Francisco</forenames></author><author><keyname>Wang</keyname><forenames>Chaoxiong</forenames></author></authors><title>Distributed Power Allocation with Rate Constraints in Gaussian Parallel
  Interference Channels</title><categories>cs.IT cs.GT math.IT</categories><comments>Paper submitted to IEEE Transactions on Information Theory, February
  17, 2007. Revised January 11, 2008</comments><abstract>  This paper considers the minimization of transmit power in Gaussian parallel
interference channels, subject to a rate constraint for each user. To derive
decentralized solutions that do not require any cooperation among the users, we
formulate this power control problem as a (generalized) Nash equilibrium game.
We obtain sufficient conditions that guarantee the existence and nonemptiness
of the solution set to our problem. Then, to compute the solutions of the game,
we propose two distributed algorithms based on the single user waterfilling
solution: The \emph{sequential} and the \emph{simultaneous} iterative
waterfilling algorithms, wherein the users update their own strategies
sequentially and simultaneously, respectively. We derive a unified set of
sufficient conditions that guarantee the uniqueness of the solution and global
convergence of both algorithms. Our results are applicable to all practical
distributed multipoint-to-multipoint interference systems, either wired or
wireless, where a quality of service in terms of information rate must be
guaranteed for each link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702163</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702163</id><created>2007-02-28</created><authors><author><keyname>Zhang</keyname><forenames>Di</forenames></author><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>First Passage Time for Multivariate Jump-diffusion Stochastic Models
  With Applications in Finance</title><categories>cs.CE cs.NA</categories><comments>Keywords: Monte-Carlo simulations, first passage time, multivariate
  jump-diffusion process; 10 pages, 3 figures</comments><abstract>  The ``first passage-time'' (FPT) problem is an important problem with a wide
range of applications in mathematics, physics, biology and finance.
Mathematically, such a problem can be reduced to estimating the probability of
a (stochastic) process first to reach a critical level or threshold. While in
other areas of applications the FPT problem can often be solved analytically,
in finance we usually have to resort to the application of numerical
procedures, in particular when we deal with jump-diffusion stochastic processes
(JDP). In this paper, we develop a Monte-Carlo-based methodology for the
solution of the FPT problem in the context of a multivariate jump-diffusion
stochastic process. The developed methodology is tested by using different
parameters, the simulation results indicate that the developed methodology is
much more efficient than the conventional Monte Carlo method. It is an
efficient tool for further practical applications, such as the analysis of
default correlation and predicting barrier options in finance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702164</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702164</id><created>2007-02-28</created><authors><author><keyname>Zhang</keyname><forenames>Di</forenames></author><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Monte-Carlo Simulations of the First Passage Time for Multivariate
  Jump-Diffusion Processes in Financial Applications</title><categories>cs.CE cs.NA</categories><comments>Keywords: First passage time; Monte Carlo simulation; Multivariate
  jump-diffusion processes; Credit risk</comments><abstract>  Many problems in finance require the information on the first passage time
(FPT) of a stochastic process. Mathematically, such problems are often reduced
to the evaluation of the probability density of the time for such a process to
cross a certain level, a boundary, or to enter a certain region. While in other
areas of applications the FPT problem can often be solved analytically, in
finance we usually have to resort to the application of numerical procedures,
in particular when we deal with jump-diffusion stochastic processes (JDP). In
this paper, we propose a Monte-Carlo-based methodology for the solution of the
first passage time problem in the context of multivariate (and correlated)
jump-diffusion processes. The developed technique provide an efficient tool for
a number of applications, including credit risk and option pricing. We
demonstrate its applicability to the analysis of the default rates and default
correlations of several different, but correlated firms via a set of empirical
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702165</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702165</id><created>2007-02-28</created><authors><author><keyname>Zhang</keyname><forenames>Di</forenames></author><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Efficient estimation of default correlation for multivariate
  jump-diffusion processes</title><categories>cs.CE cs.NA</categories><comments>Keywords: Default correlation, First passage time problem, Monte
  Carlo simulation</comments><abstract>  Evaluation of default correlation is an important task in credit risk
analysis. In many practical situations, it concerns the joint defaults of
several correlated firms, the task that is reducible to a first passage time
(FPT) problem. This task represents a great challenge for jump-diffusion
processes (JDP), where except for very basic cases, there are no analytical
solutions for such problems. In this contribution, we generalize our previous
fast Monte-Carlo method (non-correlated jump-diffusion cases) for multivariate
(and correlated) jump-diffusion processes. This generalization allows us, among
other things, to evaluate the default events of several correlated assets based
on a set of empirical data. The developed technique is an efficient tool for a
number of other applications, including credit risk and option pricing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702166</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702166</id><created>2007-02-28</created><authors><author><keyname>Zhang</keyname><forenames>Di</forenames></author><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Solving Stochastic Differential Equations with Jump-Diffusion
  Efficiently: Applications to FPT Problems in Credit Risk</title><categories>cs.CE cs.NA</categories><comments>Keywords: Default Correlation, First Passage Time, Multivariate
  Jump-Diffusion Processes, Monte-Carlo Simulation, Multivariate Uniform
  Sampling Method</comments><abstract>  The first passage time (FPT) problem is ubiquitous in many applications. In
finance, we often have to deal with stochastic processes with jump-diffusion,
so that the FTP problem is reducible to a stochastic differential equation with
jump-diffusion. While the application of the conventional Monte-Carlo procedure
is possible for the solution of the resulting model, it becomes computationally
inefficient which severely restricts its applicability in many practically
interesting cases. In this contribution, we focus on the development of
efficient Monte-Carlo-based computational procedures for solving the FPT
problem under the multivariate (and correlated) jump-diffusion processes. We
also discuss the implementation of the developed Monte-Carlo-based technique
for multivariate jump-diffusion processes driving by several compound Poisson
shocks. Finally, we demonstrate the application of the developed methodologies
for analyzing the default rates and default correlations of differently rated
firms via historical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702167</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702167</id><created>2007-02-28</created><authors><author><keyname>Wang</keyname><forenames>Linxiang X.</forenames></author><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Finite Volume Analysis of Nonlinear Thermo-mechanical Dynamics of Shape
  Memory Alloys</title><categories>cs.CE cs.NA</categories><comments>Keywords: shape memory alloys, phase transformations, nonlinear
  thermo-elasticity, finite volume method</comments><abstract>  In this paper, the finite volume method is developed to analyze coupled
dynamic problems of nonlinear thermoelasticity. The major focus is given to the
description of martensitic phase transformations essential in the modelling of
shape memory alloys. Computational experiments are carried out to study the
thermo-mechanical wave interactions in a shape memory alloy rod, and a patch.
Both mechanically and thermally induced phase transformations, as well as
hysteresis effects, in a one-dimensional structure are successfully simulated
with the developed methodology. In the two-dimensional case, the main focus is
given to square-to-rectangular transformations and examples of martensitic
combinations under different mechanical loadings are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702168</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702168</id><created>2007-02-28</created><authors><author><keyname>Wang</keyname><forenames>Linxiang X.</forenames></author><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Simulation of Phase Combinations in Shape Memory Alloys Patches by
  Hybrid Optimization Methods</title><categories>cs.CE cs.NA</categories><comments>Keywords: phase combinations, shape memory alloys, variational
  problem, genetic algorithm, quasi-Newton methods</comments><abstract>  In this paper, phase combinations among martensitic variants in shape memory
alloys patches and bars are simulated by a hybrid optimization methodology. The
mathematical model is based on the Landau theory of phase transformations. Each
stable phase is associated with a local minimum of the free energy function,
and the phase combinations are simulated by minimizing the bulk energy. At low
temperature, the free energy function has double potential wells leading to
non-convexity of the optimization problem. The methodology proposed in the
present paper is based on an initial estimate of the global solution by a
genetic algorithm, followed by a refined quasi-Newton procedure to locally
refine the optimum. By combining the local and global search algorithms, the
phase combinations are successfully simulated. Numerical experiments are
presented for the phase combinations in a SMA patch under several typical
mechanical loadings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702169</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702169</id><created>2007-02-28</created><updated>2007-05-15</updated><authors><author><keyname>Laird</keyname><forenames>James</forenames></author></authors><title>Bistable Biorders: A Sequential Domain Theory</title><categories>cs.PL cs.LO</categories><comments>To appear in LMCS</comments><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 2 (May 15,
  2007) lmcs:913</journal-ref><doi>10.2168/LMCS-3(2:5)2007</doi><abstract>  We give a simple order-theoretic construction of a Cartesian closed category
of sequential functions. It is based on bistable biorders, which are sets with
a partial order -- the extensional order -- and a bistable coherence, which
captures equivalence of program behaviour, up to permutation of top (error) and
bottom (divergence). We show that monotone and bistable functions (which are
required to preserve bistably bounded meets and joins) are strongly sequential,
and use this fact to prove universality results for the bistable biorder
semantics of the simply-typed lambda-calculus (with atomic constants), and an
extension with arithmetic and recursion.
  We also construct a bistable model of SPCF, a higher-order functional
programming language with non-local control. We use our universality result for
the lambda-calculus to show that the semantics of SPCF is fully abstract. We
then establish a direct correspondence between bistable functions and
sequential algorithms by showing that sequential data structures give rise to
bistable biorders, and that each bistable function between such biorders is
computed by a sequential algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702170</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702170</id><created>2007-02-28</created><authors><author><keyname>Tiedemann</keyname><forenames>Peter</forenames></author><author><keyname>Andersen</keyname><forenames>Henrik Reif</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>Generic Global Constraints based on MDDs</title><categories>cs.AI</categories><comments>Preliminary 15 pages version of the tech-report cs.AI/0611141</comments><abstract>  Constraint Programming (CP) has been successfully applied to both constraint
satisfaction and constraint optimization problems. A wide variety of
specialized global constraints provide critical assistance in achieving a good
model that can take advantage of the structure of the problem in the search for
a solution. However, a key outstanding issue is the representation of 'ad-hoc'
constraints that do not have an inherent combinatorial nature, and hence are
not modeled well using narrowly specialized global constraints. We attempt to
address this issue by considering a hybrid of search and compilation.
Specifically we suggest the use of Reduced Ordered Multi-Valued Decision
Diagrams (ROMDDs) as the supporting data structure for a generic global
constraint. We give an algorithm for maintaining generalized arc consistency
(GAC) on this constraint that amortizes the cost of the GAC computation over a
root-to-leaf path in the search tree without requiring asymptotically more
space than used for the MDD. Furthermore we present an approach for
incrementally maintaining the reduced property of the MDD during the search,
and show how this can be used for providing domain entailment detection.
Finally we discuss how to apply our approach to other similar data structures
such as AOMDDs and Case DAGs. The technique used can be seen as an extension of
the GAC algorithm for the regular language constraint on finite length input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702171</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702171</id><created>2007-02-28</created><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author><author><keyname>Rozenberg</keyname><forenames>Grzegorz</forenames></author></authors><title>How Overlap Determines the Macronuclear Genes in Ciliates</title><categories>cs.LO</categories><comments>22 pages, 14 figures</comments><report-no>LIACS Technical Report 2007-02</report-no><abstract>  Formal models for gene assembly in ciliates have been developed, in
particular the string pointer reduction system (SPRS) and the graph pointer
reduction system (GPRS). The reduction graph is a valuable tool within the
SPRS, revealing much information about how gene assembly is performed for a
given gene. The GPRS is more abstract than the SPRS and not all information
present in the SPRS is retained in the GPRS. As a consequence the reduction
graph cannot be defined for the GPRS in general, but we show that it can be
defined (in an equivalent manner as defined for the SPRS) if we restrict
ourselves to so-called realistic overlap graphs. Fortunately, only these graphs
correspond to genes occurring in nature. Defining the reduction graph within
the GPRS allows one to carry over several results within the SPRS that rely on
the reduction graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0702172</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0702172</id><created>2007-02-28</created><authors><author><keyname>Wang</keyname><forenames>Linxiang X.</forenames></author><author><keyname>Melnik</keyname><forenames>Roderick V. N.</forenames></author></authors><title>Numerical Model For Vibration Damping Resulting From the First Order
  Phase Transformations</title><categories>cs.CE cs.NA</categories><comments>Keywords: martensite transformation, thermo-mechanical coupling,
  vibration damping, Ginzburg-Landau theory</comments><abstract>  A numerical model is constructed for modelling macroscale damping effects
induced by the first order martensite phase transformations in a shape memory
alloy rod. The model is constructed on the basis of the modified
Landau-Ginzburg theory that couples nonlinear mechanical and thermal fields.
The free energy function for the model is constructed as a double well function
at low temperature, such that the external energy can be absorbed during the
phase transformation and converted into thermal form. The Chebyshev spectral
methods are employed together with backward differentiation for the numerical
analysis of the problem. Computational experiments performed for different
vibration energies demonstrate the importance of taking into account damping
effects induced by phase transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703001</id><created>2007-02-28</created><authors><author><keyname>Coury</keyname><forenames>Michael D.</forenames></author></authors><title>Embedding Graphs into the Extended Grid</title><categories>cs.DM cs.DS</categories><comments>4 pages, 2 figures</comments><acm-class>G.2.2</acm-class><abstract>  Let $G=(V,E)$ be an arbitrary undirected source graph to be embedded in a
target graph $EM$, the extended grid with vertices on integer grid points and
edges to nearest and next-nearest neighbours. We present an algorithm showing
how to embed $G$ into $EM$ in both time and space $O(|V|^2)$ using the new
notions of islands and bridges. An island is a connected subgraph in the target
graph which is mapped from exactly one vertex in the source graph while a
bridge is an edge between two islands which is mapped from exactly one edge in
the source graph. This work is motivated by real industrial applications in the
field of quantum computing and a need to efficiently embed source graphs in the
extended grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703002</identifier>
 <datestamp>2015-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703002</id><created>2007-02-28</created><updated>2010-02-05</updated><authors><author><keyname>Simeonov</keyname><forenames>Plamen L.</forenames></author></authors><title>Integral Biomathics: A Post-Newtonian View into the Logos of Bios (On
  the New Meaning, Relations and Principles of Life in Science)</title><categories>cs.NE cs.CC</categories><comments>85 pages, 6 figures</comments><acm-class>F.1.1; F.4.0; H.1.1; I.2.0; J.3</acm-class><journal-ref>Progress in Biophysics and Molecular Biology, Vol. 102, Issues
  2-3, 2010, pp. 85-121</journal-ref><doi>10.1016/j.pbiomolbio.2010.01.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is an attempt for a state-of-the-art survey of natural and life
sciences with the goal to define the scope and address the central questions of
an original research program. It is focused on the phenomena of emergence,
adaptive dynamics and evolution of self-assembling, self-organizing,
self-maintaining and self-replicating biosynthetic systems viewed from a
newly-arranged perspective and understanding of computation and communication
in the living nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703003</id><created>2007-02-28</created><authors><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author><author><keyname>Moa</keyname><forenames>B.</forenames></author><author><keyname>Somosan</keyname><forenames>S. C.</forenames></author></authors><title>Functions to Support Input and Output of Intervals</title><categories>cs.NA</categories><comments>16 pages, 13 figures with listings</comments><report-no>DCS-311-IR</report-no><acm-class>G.1.0</acm-class><abstract>  Interval arithmetic is hardly feasible without directed rounding as provided,
for example, by the IEEE floating-point standard. Equally essential for
interval methods is directed rounding for conversion between the external
decimal and internal binary numerals. This is not provided by the standard I/O
libraries. Conversion algorithms exist that guarantee identity upon conversion
followed by its inverse. Although it may be possible to adapt these algorithms
for use in decimal interval I/O, we argue that outward rounding in radix
conversion is computationally a simpler problem than guaranteeing identity.
Hence it is preferable to develop decimal interval I/O ab initio, which is what
we do in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703004</id><created>2007-03-01</created><authors><author><keyname>Heylighen</keyname><forenames>Francis</forenames></author></authors><title>Accelerating Socio-Technological Evolution: from ephemeralization and
  stigmergy to the global brain</title><categories>cs.CY cs.NI</categories><comments>To appear in: &quot;Globalization as an Evolutionary Process: Modeling
  Global Change&quot;, edited by George Modelski, Tessaleno Devezas, and William
  Thompson, London: Routledge</comments><abstract>  Evolution is presented as a trial-and-error process that produces a
progressive accumulation of knowledge. At the level of technology, this leads
to ephemeralization, i.e. ever increasing productivity, or decreasing of the
friction that normally dissipates resources. As a result, flows of matter,
energy and information circulate ever more easily across the planet. This
global connectivity increases the interactions between agents, and thus the
possibilities for conflict. However, evolutionary progress also reduces social
friction, via the creation of institutions. The emergence of such &quot;mediators&quot;
is facilitated by stigmergy: the unintended collaboration between agents
resulting from their actions on a shared environment. The Internet is a near
ideal medium for stigmergic interaction. Quantitative stigmergy allows the web
to learn from the activities of its users, thus becoming ever better at helping
them to answer their queries. Qualitative stigmergy stimulates agents to
collectively develop novel knowledge. Both mechanisms have direct analogues in
the functioning of the human brain. This leads us to envision the future,
super-intelligent web as a &quot;global brain&quot; for humanity. The feedback between
social and technological advances leads to an extreme acceleration of
innovation. An extrapolation of the corresponding hyperbolic growth model would
forecast a singularity around 2040. This can be interpreted as the evolutionary
transition to the Global Brain regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703005</identifier>
 <datestamp>2008-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703005</id><created>2007-03-01</created><updated>2008-01-23</updated><authors><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Sutivong</keyname><forenames>Arak</forenames></author><author><keyname>Cover</keyname><forenames>Thomas M.</forenames></author></authors><title>State Amplification</title><categories>cs.IT math.IT</categories><comments>9 pages, 4 figures, submitted to IEEE Trans. Inform. Theory, revised</comments><abstract>  We consider the problem of transmitting data at rate R over a state dependent
channel p(y|x,s) with the state information available at the sender and at the
same time conveying the information about the channel state itself to the
receiver. The amount of state information that can be learned at the receiver
is captured by the mutual information I(S^n; Y^n) between the state sequence
S^n and the channel output Y^n. The optimal tradeoff is characterized between
the information transmission rate R and the state uncertainty reduction rate
\Delta, when the state information is either causally or noncausally available
at the sender. This result is closely related and in a sense dual to a recent
study by Merhav and Shamai, which solves the problem of masking the state
information from the receiver rather than conveying it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703006</id><created>2007-03-01</created><authors><author><keyname>Chen</keyname><forenames>Jing-Chao</forenames></author></authors><title>XORSAT: An Efficient Algorithm for the DIMACS 32-bit Parity Problem</title><categories>cs.DS</categories><abstract>  The DIMACS 32-bit parity problem is a satisfiability (SAT) problem hard to
solve. So far, EqSatz by Li is the only solver which can solve this problem.
However, This solver is very slow. It is reported that it spent 11855 seconds
to solve a par32-5 instance on a Maxintosh G3 300 MHz. The paper introduces a
new solver, XORSAT, which splits the original problem into two parts:
structured part and random part, and then solves separately them with WalkSAT
and an XOR equation solver. Based our empirical observation, XORSAT is
surprisingly fast, which is approximately 1000 times faster than EqSatz. For a
par32-5 instance, XORSAT took 2.9 seconds, while EqSatz took 2844 seconds on
Intel Pentium IV 2.66GHz CPU. We believe that this method significantly
different from traditional methods is also useful beyond this domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703007</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703007</id><created>2007-03-02</created><updated>2007-11-20</updated><authors><author><keyname>Bonfante</keyname><forenames>Guillaume</forenames></author><author><keyname>Guiraud</keyname><forenames>Yves</forenames></author></authors><title>Intensional properties of polygraphs</title><categories>cs.LO cs.CC math.CT</categories><comments>Proceedings of TERMGRAPH 2007, Electronic Notes in Computer Science
  (to appear), 12 pages, minor changes from previous version</comments><acm-class>F.1.1; F.4</acm-class><journal-ref>Electronic Notes in Theoretical Computer Science 203(1):65-77
  (2008)</journal-ref><doi>10.1016/j.entcs.2008.03.034</doi><abstract>  We present polygraphic programs, a subclass of Albert Burroni's polygraphs,
as a computational model, showing how these objects can be seen as first-order
functional programs. We prove that the model is Turing complete. We use
polygraphic interpretations, a termination proof method introduced by the
second author, to characterize polygraphic programs that compute in polynomial
time. We conclude with a characterization of polynomial time functions and
non-deterministic polynomial time functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703008</id><created>2007-03-02</created><authors><author><keyname>Chatel</keyname><forenames>Sophie</forenames></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames></author></authors><title>Strategies in object-oriented design</title><categories>cs.HC</categories><proxy>ccsd inria-00118171</proxy><journal-ref>Acta Psychologica 91 (1996) 245-269</journal-ref><abstract>  This paper presents a study aiming to analyse the design strategies of
experts in object-oriented programming. We report an experiment conducted with
four experts. Each subject solved three problems. Our results show that three
strategies may be used in program design according to the solution structure.
An object-centred strategy and a function-centred strategy are used when the
solution has a hierarchical structure with vertical communication between
objects. In this case, the plan which guides the design activity is
declarative. A procedure-centred strategy is used when the solution has a flat
structure with horizontal communication between objects. In this case, the plan
which guides the design activity is procedural. These results are discussed in
relation with results on design strategies in procedural design. Furthermore,
our results provide insight into the knowledge structures of experts in
object-oriented design. To conclude, we point out limitations of this study and
discuss implications of our results for Human-Computer Interaction systems, in
particular for systems assisting experts in their design activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703009</id><created>2007-03-02</created><authors><author><keyname>Sack</keyname><forenames>Warren</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>D&#xe9;tienne</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Ducheneaut</keyname><forenames>Nicholas</forenames><affiliation>LEI</affiliation></author><author><keyname>Burkhardt</keyname><forenames>Jean-Marie</forenames><affiliation>LEI</affiliation></author><author><keyname>Mahendran</keyname><forenames>Dilan</forenames><affiliation>INRIA Rocquencourt, EIFFEL</affiliation></author><author><keyname>Barcellini</keyname><forenames>Flore</forenames><affiliation>INRIA Rocquencourt, EIFFEL</affiliation></author></authors><title>A Methodological Framework for Socio-Cognitive Analyses of Collaborative
  Design of Open Source Software</title><categories>cs.HC</categories><proxy>ccsd inria-00117296</proxy><journal-ref>Computer Supported Cooperative Work (CSCW), the Journal of
  Collaborative Computing 15, 2-3 (2006) 229-250</journal-ref><abstract>  Open Source Software (OSS) development challenges traditional software
engineering practices. In particular, OSS projects are managed by a large
number of volunteers, working freely on the tasks they choose to undertake. OSS
projects also rarely rely on explicit system-level design, or on project plans
or schedules. Moreover, OSS developers work in arbitrary locations and
collaborate almost exclusively over the Internet, using simple tools such as
email and software code tracking databases (e.g. CVS). All the characteristics
above make OSS development akin to weaving a tapestry of heterogeneous
components. The OSS design process relies on various types of actors: people
with prescribed roles, but also elements coming from a variety of information
spaces (such as email and software code). The objective of our research is to
understand the specific hybrid weaving accomplished by the actors of this
distributed, collective design process. This, in turn, challenges traditional
methodologies used to understand distributed software engineering: OSS
development is simply too &quot;fibrous&quot; to lend itself well to analysis under a
single methodological lens. In this paper, we describe the methodological
framework we articulated to analyze collaborative design in the Open Source
world. Our framework focuses on the links between the heterogeneous components
of a project's hybrid network. We combine ethnography, text mining, and
socio-technical network analysis and visualization to understand OSS
development in its totality. This way, we are able to simultaneously consider
the social, technical, and cognitive aspects of OSS development. We describe
our methodology in detail, and discuss its implications for future research on
distributed collective practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703010</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703010</id><created>2007-03-02</created><updated>2009-02-04</updated><authors><author><keyname>Byrka</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Aardal</keyname><forenames>Karen</forenames></author></authors><title>An optimal bifactor approximation algorithm for the metric uncapacitated
  facility location problem</title><categories>cs.DS</categories><comments>A journal version</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a 1.5-approximation algorithm for the metric uncapacitated facility
location problem (UFL), which improves on the previously best known
1.52-approximation algorithm by Mahdian, Ye and Zhang. Note, that the
approximability lower bound by Guha and Khuller is 1.463.
  An algorithm is a {\em ($\lambda_f$,$\lambda_c$)-approximation algorithm} if
the solution it produces has total cost at most $\lambda_f \cdot F^* +
\lambda_c \cdot C^*$, where $F^*$ and $C^*$ are the facility and the connection
cost of an optimal solution. Our new algorithm, which is a modification of the
$(1+2/e)$-approximation algorithm of Chudak and Shmoys, is a
(1.6774,1.3738)-approximation algorithm for the UFL problem and is the first
one that touches the approximability limit curve $(\gamma_f, 1+2e^{-\gamma_f})$
established by Jain, Mahdian and Saberi. As a consequence, we obtain the first
optimal approximation algorithm for instances dominated by connection costs.
When combined with a (1.11,1.7764)-approximation algorithm proposed by Jain et
al., and later analyzed by Mahdian et al., we obtain the overall approximation
guarantee of 1.5 for the metric UFL problem. We also describe how to use our
algorithm to improve the approximation ratio for the 3-level version of UFL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703011</id><created>2007-03-02</created><authors><author><keyname>Alt</keyname><forenames>Helmut</forenames></author><author><keyname>Buchin</keyname><forenames>Maike</forenames></author></authors><title>Can we Compute the Similarity Between Surfaces?</title><categories>cs.CG cs.CC</categories><acm-class>F.2.2; F.1.1</acm-class><abstract>  A suitable measure for the similarity of shapes represented by parameterized
curves or surfaces is the Fr\'echet distance. Whereas efficient algorithms are
known for computing the Fr\'echet distance of polygonal curves, the same
problem for triangulated surfaces is NP-hard. Furthermore, it remained open
whether it is computable at all. Here, using a discrete approximation we show
that it is {\em upper semi-computable}, i.e., there is a non-halting Turing
machine which produces a monotone decreasing sequence of rationals converging
to the result. It follows that the decision problem, whether the Fr\'echet
distance of two given surfaces lies below some specified value, is recursively
enumerable.
  Furthermore, we show that a relaxed version of the problem, the computation
of the {\em weak Fr\'echet distance} can be solved in polynomial time. For
this, we give a computable characterization of the weak Fr\'echet distance in a
geometric data structure called the {\em free space diagram}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703012</id><created>2007-03-02</created><authors><author><keyname>Ravichandar</keyname><forenames>Ramya</forenames></author><author><keyname>Arthur</keyname><forenames>James D.</forenames></author><author><keyname>P&#xe9;rez-Qui&#xf1;ones</keyname><forenames>Manuel</forenames></author></authors><title>Pre-Requirement Specification Traceability: Bridging the Complexity Gap
  through Capabilities</title><categories>cs.SE</categories><comments>This paper appears in International Symposium on Grand Challenges in
  Traceability, TEFSE/GCT 2007. 10 pages, 7 Figures</comments><acm-class>D.2.1</acm-class><abstract>  Pre-Requirement Specification traceability is the activity of capturing
relations between requirements and their sources, in particular user needs.
Requirements are formal technical specifications in the solution space; needs
are natural language expressions codifying user expectations in the problem
space. Current traceability techniques are challenged by the complexity gap
that results from the disparity between the spaces, and thereby, often neglect
traceability to and from requirements. We identify the existence of an
intermediary region -- the transition space -- which structures the progression
from needs to requirements. More specifically, our approach to developing
change-tolerant systems, termed Capabilities Engineering, identifies highly
cohesive, minimally coupled, optimized functional abstractions called
Capabilities in the transition space. These Capabilities link the problem and
solution spaces through directives (entities derived from user needs).
Directives connect the problem and transition spaces; Capabilities link the
transition and solution spaces. Furthermore, the process of Capabilities
Engineering addresses specific traceability challenges. It supports the
evolution of traces, provides semantic and structural information about
dependencies, incorporates human factors, generates traceability relations with
negligible overhead, and thereby, fosters pre-Requirement Specification
traceability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703013</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703013</id><created>2007-03-03</created><authors><author><keyname>Limouzy</keyname><forenames>Vincent</forenames><affiliation>LIAFA</affiliation></author><author><keyname>De Montgolfier</keyname><forenames>Fabien</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Rao</keyname><forenames>Micha&#xeb;l</forenames><affiliation>LIAFA</affiliation></author></authors><title>NLC-2 graph recognition and isomorphism</title><categories>cs.DS</categories><comments>soumis \`{a} WG 2007; 12p</comments><proxy>ccsd hal-00134605</proxy><journal-ref>Dans Lecture Notes In Computer Science - Graph-Theoretic Concepts
  in Computer Science 33rd International Workshop, WG 2007, Dornburg, Germany,
  June 21-23, 2007., Dornburg : Allemagne (2007)</journal-ref><doi>10.1007/978-3-540-74839-7_9</doi><abstract>  NLC-width is a variant of clique-width with many application in graph
algorithmic. This paper is devoted to graphs of NLC-width two. After giving new
structural properties of the class, we propose a $O(n^2 m)$-time algorithm,
improving Johansson's algorithm \cite{Johansson00}. Moreover, our alogrithm is
simple to understand. The above properties and algorithm allow us to propose a
robust $O(n^2 m)$-time isomorphism algorithm for NLC-2 graphs. As far as we
know, it is the first polynomial-time algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703014</identifier>
 <datestamp>2013-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703014</id><created>2007-03-03</created><updated>2013-10-23</updated><authors><author><keyname>Toumpis</keyname><forenames>Stavros</forenames></author></authors><title>Asymptotic Capacity Bounds for Wireless Networks with Non-Uniform
  Traffic</title><categories>cs.NI</categories><journal-ref>Asymptotic Capacity Bounds for Wireless Networks with Non-Uniform
  Traffic Patterns, S. Toumpis, IEEE Trans. Wireless Comm., vol. 7, no. 6, pp.
  2231-2242, June 2008</journal-ref><doi>10.1109/TWC.2008.061010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop bounds on the capacity of wireless networks when the traffic is
non-uniform, i.e., not all nodes are required to receive and send similar
volumes of traffic. Our results are asymptotic, i.e., they hold with
probability going to unity as the number of nodes goes to infinity. We study
\emph{(i)} asymmetric networks, where the numbers of sources and destinations
of traffic are unequal, \emph{(ii)} multicast networks, in which each created
packet has multiple destinations, \emph{(iii)} cluster networks, that consist
of clients and a limited number of cluster heads, and each client wants to
communicate with any of the cluster heads, and \emph{(iv)} hybrid networks, in
which the nodes are supported by a limited infrastructure. Our findings
quantify the fundamental capabilities of these wireless networks to handle
traffic bottlenecks, and point to correct design principles that achieve the
capacity without resorting to overly complicated protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703015</id><created>2007-03-03</created><authors><author><keyname>Shkotin</keyname><forenames>Alex</forenames></author></authors><title>Graph representation of context-free grammars</title><categories>cs.LO</categories><comments>4 pages, 3 figures</comments><acm-class>D.3.1; E.1</acm-class><abstract>  In modern mathematics, graphs figure as one of the better-investigated class
of mathematical objects. Various properties of graphs, as well as
graph-processing algorithms, can be useful if graphs of a certain kind are used
as denotations for CF-grammars. Furthermore, graph are well adapted to various
extensions (one kind of such extensions being attributes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703016</identifier>
 <datestamp>2007-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703016</id><created>2007-03-03</created><updated>2007-11-05</updated><authors><author><keyname>Annpureddy</keyname><forenames>Venkata Sreekanta</forenames></author><author><keyname>Marathe</keyname><forenames>Devdutt V.</forenames></author><author><keyname>Ramya</keyname><forenames>T. R.</forenames></author><author><keyname>Bhashyam</keyname><forenames>Srikrishna</forenames></author></authors><title>Outage Probability of Multiple-Input Single-Output (MISO) Systems with
  Delayed Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications Jan 2007, Revised
  Jun 2007, Revised Nov 2007</comments><acm-class>E.4</acm-class><abstract>  We investigate the effect of feedback delay on the outage probability of
multiple-input single-output (MISO) fading channels. Channel state information
at the transmitter (CSIT) is a delayed version of the channel state information
available at the receiver (CSIR). We consider two cases of CSIR: (a) perfect
CSIR and (b) CSI estimated at the receiver using training symbols. With perfect
CSIR, under a short-term power constraint, we determine: (a) the outage
probability for beamforming with imperfect CSIT (BF-IC) analytically, and (b)
the optimal spatial power allocation (OSPA) scheme that minimizes outage
numerically. Results show that, for delayed CSIT, BF-IC is close to optimal for
low SNR and uniform spatial power allocation (USPA) is close to optimal at high
SNR. Similarly, under a long-term power constraint, we show that BF-IC is close
to optimal for low SNR and USPA is close to optimal at high SNR. With imperfect
CSIR, we obtain an upper bound on the outage probability with USPA and BF-IC.
Results show that the loss in performance due to imperfection in CSIR is not
significant, if the training power is chosen appropriately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703017</identifier>
 <datestamp>2008-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703017</id><created>2007-03-04</created><updated>2008-06-05</updated><authors><author><keyname>Kim</keyname><forenames>Sang Joon</forenames></author><author><keyname>Mitran</keyname><forenames>Patrick</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Performance Bounds for Bi-Directional Coded Cooperation Protocols</title><categories>cs.IT math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In coded bi-directional cooperation, two nodes wish to exchange messages over
a shared half-duplex channel with the help of a relay. In this paper, we derive
performance bounds for this problem for each of three protocols.
  The first protocol is a two phase protocol were both users simultaneously
transmit during the first phase and the relay alone transmits during the
second. In this protocol, our bounds are tight and a multiple-access channel
transmission from the two users to the relay followed by a coded broadcast-type
transmission from the relay to the users achieves all points in the two-phase
capacity region.
  The second protocol considers sequential transmissions from the two users
followed by a transmission from the relay while the third protocol is a hybrid
of the first two protocols and has four phases. In the latter two protocols the
inner and outer bounds are not identical, and differ in a manner similar to the
inner and outer bounds of Cover's relay channel. Numerical evaluation shows
that at least in some cases of interest our bounds do not differ significantly.
  Finally, in the Gaussian case with path loss, we derive achievable rates and
compare the relative merits of each protocol in various regimes. This case is
of interest in cellular systems. Surprisingly, we find that in some cases, the
achievable rate region of the four phase protocol sometimes contains points
that are outside the outer bounds of the other protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703018</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703018</id><created>2007-03-05</created><updated>2010-07-06</updated><authors><author><keyname>Matsuoka</keyname><forenames>Satoshi</forenames></author></authors><title>A Coding Theoretic Study on MLL proof nets</title><categories>cs.LO cs.DM</categories><comments>minor modifications</comments><doi>10.1017/S0960129511000582</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coding theory is very useful for real world applications. A notable example
is digital television. Basically, coding theory is to study a way of detecting
and/or correcting data that may be true or false. Moreover coding theory is an
area of mathematics, in which there is an interplay between many branches of
mathematics, e.g., abstract algebra, combinatorics, discrete geometry,
information theory, etc. In this paper we propose a novel approach for
analyzing proof nets of Multiplicative Linear Logic (MLL) by coding theory. We
define families of proof structures and introduce a metric space for each
family. In each family, 1. an MLL proof net is a true code element; 2. a proof
structure that is not an MLL proof net is a false (or corrupted) code element.
The definition of our metrics reflects the duality of the multiplicative
connectives elegantly. In this paper we show that in the framework one
error-detecting is possible but one error-correcting not. Our proof of the
impossibility of one error-correcting is interesting in the sense that a proof
theoretical property is proved using a graph theoretical argument. In addition,
we show that affine logic and MLL + MIX are not appropriate for this framework.
That explains why MLL is better than such similar logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703019</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703019</id><created>2007-03-05</created><updated>2009-09-17</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Newman</keyname><forenames>Ilan</forenames></author><author><keyname>Weimann</keyname><forenames>Oren</forenames></author></authors><title>The Stackelberg Minimum Spanning Tree Game</title><categories>cs.GT cs.DS</categories><comments>v3: Referees' comments incorporated. A preliminary version appeared
  in the proceedings of the 10th Workshop on Algorithms and Data Structures
  (WADS 2007)</comments><journal-ref>Algorithmica, vol. 59, no. 2, pp. 129--144, 2011</journal-ref><doi>10.1007/s00453-009-9299-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a one-round two-player network pricing game, the Stackelberg
Minimum Spanning Tree game or StackMST.
  The game is played on a graph (representing a network), whose edges are
colored either red or blue, and where the red edges have a given fixed cost
(representing the competitor's prices). The first player chooses an assignment
of prices to the blue edges, and the second player then buys the cheapest
possible minimum spanning tree, using any combination of red and blue edges.
The goal of the first player is to maximize the total price of purchased blue
edges. This game is the minimum spanning tree analog of the well-studied
Stackelberg shortest-path game.
  We analyze the complexity and approximability of the first player's best
strategy in StackMST. In particular, we prove that the problem is APX-hard even
if there are only two different red costs, and give an approximation algorithm
whose approximation ratio is at most $\min \{k,1+\ln b,1+\ln W\}$, where $k$ is
the number of distinct red costs, $b$ is the number of blue edges, and $W$ is
the maximum ratio between red costs. We also give a natural integer linear
programming formulation of the problem, and show that the integrality gap of
the fractional relaxation asymptotically matches the approximation guarantee of
our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703020</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703020</id><created>2007-03-05</created><authors><author><keyname>Hansson</keyname><forenames>Anders</forenames></author><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>Counting preimages of TCP reordering patterns</title><categories>cs.DS cs.DM math.CO</categories><abstract>  Packet reordering is an important property of network traffic that should be
captured by analytical models of the Transmission Control Protocol (TCP). We
study a combinatorial problem motivated by RESTORED, a TCP modeling methodology
that incorporates information about packet dynamics. A significant component of
this model is a many-to-one mapping B that transforms sequences of packet IDs
into buffer sequences, in a manner that is compatible with TCP semantics. We
show that the following hold:
  1. There exists a linear time algorithm that, given a buffer sequence W of
length n, decides whether there exists a permutation A of 1,2,..., n such that
$A\in B^{-1}(W)$ (and constructs such a permutation, when it exists).
  2. The problem of counting the number of permutations in $B^{-1}(W)$ has a
polynomial time algorithm.
  We also show how to extend these results to sequences of IDs that contain
repeated packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703021</id><created>2007-03-05</created><authors><author><keyname>Wang</keyname><forenames>Wen-Li</forenames></author><author><keyname>Tang</keyname><forenames>Mei-Huei</forenames></author></authors><title>Addressing Components' Evolvement and Execution Behavior to Measure
  Component-Based Software Reliability</title><categories>cs.SE</categories><abstract>  Software reliability is an important quality attrib-ute, often evaluated as
either a function of time or of system structures. The goal of this study is to
have this metric cover both for component-based software, be-cause its
reliability strongly depends on the quality of constituent components and their
interactions. To achieve this, we apply a convolution modeling ap-proach, based
on components' execution behavior, to integrate their individual reliability
evolvement and simultaneously address failure fixes in the time do-main.
Modeling at the component level can be more economical to accommodate software
evolution, be-cause the reliability metric can be evaluated by reus-ing the
quality measures of unaffected components and adapting only to the affected
ones to save cost. The adaptation capability also supports the incremental
software development processes that constantly add in new components over time.
Experiments were con-ducted to discuss the usefulness of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703022</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703022</id><created>2007-03-05</created><authors><author><keyname>Bai</keyname><forenames>Dongwoon</forenames></author><author><keyname>Mitran</keyname><forenames>Patrick</forenames></author><author><keyname>Ghassemzadeh</keyname><forenames>Saeed S.</forenames></author><author><keyname>Miller</keyname><forenames>Robert R.</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Rate of Channel Hardening of Antenna Selection Diversity Schemes and Its
  Implication on Scheduling</title><categories>cs.IT math.IT</categories><comments>24 pages, 6 figures, 1table, Submitted to IEEE Transactions on
  Information Theory</comments><abstract>  For a multiple antenna system, we compute the asymptotic distribution of
antenna selection gain when the transmitter selects the transmit antenna with
the strongest channel. We use this to asymptotically estimate the underlying
channel capacity distributions, and demonstrate that unlike
multiple-input/multiple-output (MIMO) systems, the channel for antenna
selection systems hardens at a slower rate, and thus a significant multiuser
scheduling gain can exist - O(1/ log m) for channel selection as opposed to
O(1/ sqrt{m}) for MIMO, where m is the number of transmit antennas.
Additionally, even without this scheduling gain, it is demonstrated that
transmit antenna selection systems outperform open loop MIMO systems in low
signal-to-interference-plus-noise ratio (SINR) regimes, particularly for a
small number of receive antennas. This may have some implications on wireless
system design, because most of the users in modern wireless systems have low
SINRs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703023</id><created>2007-03-05</created><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Haverkort</keyname><forenames>Herman</forenames></author><author><keyname>Lee</keyname><forenames>Mira</forenames></author></authors><title>Computing a Minimum-Dilation Spanning Tree is NP-hard</title><categories>cs.CG</categories><abstract>  In a geometric network G = (S, E), the graph distance between two vertices u,
v in S is the length of the shortest path in G connecting u to v. The dilation
of G is the maximum factor by which the graph distance of a pair of vertices
differs from their Euclidean distance. We show that given a set S of n points
with integer coordinates in the plane and a rational dilation delta &gt; 1, it is
NP-hard to determine whether a spanning tree of S with dilation at most delta
exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703024</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703024</id><created>2007-03-06</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Algorithmic Information Theory: a brief non-technical guide to the field</title><categories>cs.IT cs.CC math.IT</categories><comments>11 LaTeX pages.
  http://www.scholarpedia.org/article/Algorithmic_information_theory</comments><journal-ref>Scholarpedia, 2:3 (2007) page 2519</journal-ref><abstract>  This article is a brief guide to the field of algorithmic information theory
(AIT), its underlying philosophy, and the most important concepts. AIT arises
by mixing information theory and computation theory to obtain an objective and
absolute notion of information in an individual object, and in so doing gives
rise to an objective and robust notion of randomness of individual objects.
This is in contrast to classical information theory that is based on random
variables and communication, and has no bearing on information and randomness
of individual objects. After a brief overview, the major subfields,
applications, history, and a map of the field are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703025</id><created>2007-03-06</created><authors><author><keyname>Gilbert</keyname><forenames>Jean Charles</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Jonsson</keyname><forenames>Xavier</forenames></author></authors><title>LIBOPT - An environment for testing solvers on heterogeneous collections
  of problems - Version 1.0</title><categories>cs.MS cs.NA math.OC</categories><proxy>ccsd inria-00135013</proxy><abstract>  The Libopt environment is both a methodology and a set of tools that can be
used for testing, comparing, and profiling solvers on problems belonging to
various collections. These collections can be heterogeneous in the sense that
their problems can have common features that differ from one collection to the
other. Libopt brings a unified view on this composite world by offering, for
example, the possibility to run any solver on any problem compatible with it,
using the same Unix/Linux command. The environment also provides tools for
comparing the results obtained by solvers on a specified set of problems. Most
of the scripts going with the Libopt environment have been written in Perl.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703026</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703026</id><created>2007-03-06</created><updated>2008-05-14</updated><authors><author><keyname>Boldo</keyname><forenames>Sylvie</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>ELIAUS</affiliation></author><author><keyname>Giorgi</keyname><forenames>Pascal</forenames><affiliation>LIRMM</affiliation></author></authors><title>Formal proof for delayed finite field arithmetic using floating point
  operators</title><categories>cs.SC</categories><comments>8th Conference on Real Numbers and Computers, Saint Jacques de
  Compostelle : Espagne (2008)</comments><abstract>  Formal proof checkers such as Coq are capable of validating proofs of
correction of algorithms for finite field arithmetics but they require
extensive training from potential users. The delayed solution of a triangular
system over a finite field mixes operations on integers and operations on
floating point numbers. We focus in this report on verifying proof obligations
that state that no round off error occurred on any of the floating point
operations. We use a tool named Gappa that can be learned in a matter of
minutes to generate proofs related to floating point arithmetic and hide
technicalities of formal proof checkers. We found that three facilities are
missing from existing tools. The first one is the ability to use in Gappa new
lemmas that cannot be easily expressed as rewriting rules. We coined the second
one ``variable interchange'' as it would be required to validate loop
interchanges. The third facility handles massive loop unrolling and argument
instantiation by generating traces of execution for a large number of cases. We
hope that these facilities may sometime in the future be integrated into
mainstream code validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703027</identifier>
 <datestamp>2008-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703027</id><created>2007-03-06</created><updated>2008-05-31</updated><authors><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>ISC</affiliation></author></authors><title>Interroger un corpus par le sens</title><categories>cs.CL cs.IR</categories><comments>13 pp</comments><proxy>ccsd hal-00134911</proxy><journal-ref>Dans &quot;Mots, termes et contextes&quot;, Actes des septi\`emes Journ\'ees
  scientifiques du r\'eseau de chercheurs Lexicologie, Terminologie, Traduction
  - Bruxelles : Belgique (2005)</journal-ref><abstract>  In textual knowledge management, statistical methods prevail. Nonetheless,
some difficulties cannot be overcome by these methodologies. I propose a
symbolic approach using a complete textual analysis to identify which analysis
level can improve the the answers provided by a system. The approach identifies
word senses and relation between words and generates as many rephrasings as
possible. Using synonyms and derivative, the system provides new utterances
without changing the original meaning of the sentences. Such a way, an
information can be retrieved whatever the question or answer's wording may be.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703028</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703028</id><created>2007-03-06</created><updated>2007-05-24</updated><authors><author><keyname>Collange</keyname><forenames>Sylvain</forenames><affiliation>LP2A</affiliation></author><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>LP2A, LIRMM</affiliation></author><author><keyname>Defour</keyname><forenames>David</forenames><affiliation>LP2A</affiliation></author></authors><title>Graphic processors to speed-up simulations for the design of high
  performance solar receptors</title><categories>cs.DC physics.class-ph</categories><abstract>  Graphics Processing Units (GPUs) are now powerful and flexible systems
adapted and used for other purposes than graphics calculations (General Purpose
computation on GPU -- GPGPU). We present here a prototype to be integrated into
simulation codes that estimate temperature, velocity and pressure to design
next generations of solar receptors. Such codes will delegate to our
contribution on GPUs the computation of heat transfers due to radiations. We
use Monte-Carlo line-by-line ray-tracing through finite volumes. This means
data-parallel arithmetic transformations on large data structures. Our
prototype is inspired on the source code of GPUBench. Our performances on two
recent graphics cards (Nvidia 7800GTX and ATI RX1800XL) show some speed-up
higher than 400 compared to CPU implementations leaving most of CPU computing
resources available. As there were some questions pending about the accuracy of
the operators implemented in GPUs, we start this report with a survey and some
contributed tests on the various floating point units available on GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703029</id><created>2007-03-06</created><updated>2007-04-12</updated><authors><author><keyname>Friedland</keyname><forenames>Shmuel</forenames></author></authors><title>FPRAS for computing a lower bound for weighted matching polynomial of
  graphs</title><categories>cs.CC cs.DM</categories><comments>16 pages</comments><abstract>  We give a fully polynomial randomized approximation scheme to compute a lower
bound for the matching polynomial of any weighted graph at a positive argument.
For the matching polynomial of complete bipartite graphs with bounded weights
these lower bounds are asymptotically optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703030</id><created>2007-03-07</created><authors><author><keyname>Rybnikov</keyname><forenames>Konstantin</forenames></author></authors><title>An Efficient Local Approach to Convexity Testing of Piecewise-Linear
  Hypersurfaces</title><categories>cs.CG</categories><comments>3 figures</comments><acm-class>D.2.4; I.3.5</acm-class><abstract>  We show that a closed piecewise-linear hypersurface immersed in $R^n$ ($n\ge
3$) is the boundary of a convex body if and only if every point in the interior
of each $(n-3)$-face has a neighborhood that lies on the boundary of some
convex body; no assumptions about the hypersurface's topology are needed. We
derive this criterion from our generalization of Van Heijenoort's (1952)
theorem on locally convex hypersurfaces in $R^n$ to spherical spaces. We also
give an easy-to-implement convexity testing algorithm, which is based on our
criterion. For $R^3$ the number of arithmetic operations used by the algorithm
is at most linear in the number of vertices, while in general it is at most
linear in the number of incidences between the $(n-2)$-faces and $(n-3)$-faces.
When the dimension $n$ is not fixed and only ring arithmetic is allowed, the
algorithm still remains polynomial. Our method works in more general situations
than the convexity verification algorithms developed by Mehlhorn et al. (1996)
and Devillers et al. (1998) -- for example, our method does not require the
input surface to be orientable, nor it requires the input data to include
normal vectors to the facets that are oriented &quot;in a coherent way&quot;. For $R^3$
the complexity of our algorithm is the same as that of previous algorithms; for
higher dimensions there seems to be no clear winner, but our approach is the
only one that easily handles inputs in which the facet normals are not known to
be coherently oriented or are not given at all. Furthermore, our method can be
extended to piecewise-polynomial surfaces of small degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703031</id><created>2007-03-07</created><authors><author><keyname>Creed</keyname><forenames>Paidi</forenames></author></authors><title>Sampling Eulerian orientations of triangular lattice graphs</title><categories>cs.DM cs.DS</categories><comments>23 pages</comments><abstract>  We consider the problem of sampling from the uniform distribution on the set
of Eulerian orientations of subgraphs of the triangular lattice. Although it is
known that this can be achieved in polynomial time for any graph, the algorithm
studied here is more natural in the context of planar Eulerian graphs. We
analyse the mixing time of a Markov chain on the Eulerian orientations of a
planar graph which moves between orientations by reversing the edges of
directed faces. Using path coupling and the comparison method we obtain a
polynomial upper bound on the mixing time of this chain for any solid subgraph
of the triangular lattice. By considering the conductance of the chain we show
that there exist subgraphs with holes for which the chain will always take an
exponential amount of time to converge. Finally, as an additional justification
for studying a Markov chain on the set of Eulerian orientations of planar
graphs, we show that the problem of counting Eulerian orientations remains
#P-complete when restricted to planar graphs.
  A preliminary version of this work appeared as an extended abstract in the
2nd Algorithms and Complexity in Durham workshop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703032</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703032</id><created>2007-03-07</created><authors><author><keyname>Enge</keyname><forenames>Andreas</forenames><affiliation>INRIA FUTURS, INRIA Futurs</affiliation></author><author><keyname>Gaudry</keyname><forenames>Pierrick</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>An $L (1/3 + \epsilon)$ Algorithm for the Discrete Logarithm Problem for
  Low Degree Curves</title><categories>cs.CR math.AG</categories><proxy>ccsd inria-00135324</proxy><journal-ref>Dans Eurocrypt 2007 (2007)</journal-ref><doi>10.1007/978-3-540-72540-4_22</doi><abstract>  The discrete logarithm problem in Jacobians of curves of high genus $g$ over
finite fields $\FF_q$ is known to be computable with subexponential complexity
$L_{q^g}(1/2, O(1))$. We present an algorithm for a family of plane curves
whose degrees in $X$ and $Y$ are low with respect to the curve genus, and
suitably unbalanced. The finite base fields are arbitrary, but their sizes
should not grow too fast compared to the genus. For this family, the group
structure can be computed in subexponential time of $L_{q^g}(1/3, O(1))$, and a
discrete logarithm computation takes subexponential time of
$L_{q^g}(1/3+\epsilon, o(1))$ for any positive $\epsilon$. These runtime bounds
rely on heuristics similar to the ones used in the number field sieve or the
function field sieve algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703033</identifier>
 <datestamp>2008-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703033</id><created>2007-03-07</created><updated>2008-03-04</updated><authors><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>VALORIA</affiliation></author></authors><title>Time Warp Edit Distance with Stiffness Adjustment for Time Series
  Matching</title><categories>cs.IR</categories><acm-class>I.5</acm-class><journal-ref>IEEE Transaction on Pattern Analysis and Machine Intelligence 31,
  2 (2009) 306-318</journal-ref><doi>10.1109/TPAMI.2008.76</doi><abstract>  In a way similar to the string-to-string correction problem we address time
series similarity in the light of a time-series-to-time-series-correction
problem for which the similarity between two time series is measured as the
minimum cost sequence of &quot;edit operations&quot; needed to transform one time series
into another. To define the &quot;edit operations&quot; we use the paradigm of a
graphical editing process and end up with a dynamic programming algorithm that
we call Time Warp Edit Distance (TWED). TWED is slightly different in form from
Dynamic Time Warping, Longest Common Subsequence or Edit Distance with Real
Penalty algorithms. In particular, it highlights a parameter which drives a
kind of stiffness of the elastic measure along the time axis. We show that the
similarity provided by TWED is a metric potentially useful in time series
retrieval applications since it could benefit from the triangular inequality
property to speed up the retrieval process while tuning the parameters of the
elastic measure. In that context, a lower bound is derived to relate the
matching of time series into down sampled representation spaces to the matching
into the original space. Empiric quality of the TWED distance is evaluated on a
simple classification task. Compared to Edit Distance, Dynamic Time Warping,
Longest Common Subsequnce and Edit Distance with Real Penalty, TWED has proven
to be quite effective on the considered experimental task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703034</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703034</id><created>2007-03-07</created><authors><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author></authors><title>Nanoscale Communication with Brownian Motion</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures</comments><abstract>  In this paper, the problem of communicating using chemical messages
propagating using Brownian motion, rather than electromagnetic messages
propagating as waves in free space or along a wire, is considered. This problem
is motivated by nanotechnological and biotechnological applications, where the
energy cost of electromagnetic communication might be prohibitive. Models are
given for communication using particles that propagate with Brownian motion,
and achievable capacity results are given. Under conservative assumptions, it
is shown that rates exceeding one bit per particle are achievable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703035</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703035</id><created>2007-03-08</created><updated>2007-04-20</updated><authors><author><keyname>Bhattad</keyname><forenames>Kapil</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>On the Distortion SNR Exponent of Some Layered Transmission Schemes</title><categories>cs.IT math.IT</categories><comments>26 Pages. 10 figures, Submitted to IEEE Trans. on IT</comments><abstract>  We consider the problem of joint source-channel coding for transmitting K
samples of a complex Gaussian source over T = bK uses of a block-fading
multiple input multiple output (MIMO) channel with M transmit and N receive
antennas. We consider the case when we are allowed to code over L blocks. The
channel gain is assumed to be constant over a block and channel gains for
different blocks are assumed to be independent. The performance measure of
interest is the rate of decay of the expected mean squared error with the
signal-to-noise ratio (SNR), called the distortion SNR exponent. We first show
that using a broadcast strategy of Gunduz and Erkip, but with a different power
and rate allocation policy, the optimal distortion SNR exponent can be achieved
for bandwidth efficiencies 0 &lt; b &lt; (|N-M|+1)/min(M,N). This is the first time
the optimal exponent is characterized for 1/min(M,N) &lt; b &lt; (|N-M |+ 1)/ min(M,
N). Also, for b &gt; MNL^2, we show that the broadcast scheme achieves the optimal
exponent of MNL. Special cases of this result have been derived for the L=1
case and for M=N=1 by Gunduz and Erkip. We then propose a digital layered
transmission scheme that uses both time layering and superposition. This
includes many previously known schemes as special cases. The proposed scheme is
at least as good as the currently best known schemes for the entire range of
bandwidth efficiencies, whereas at least for some M, N, and b, it is strictly
better than the currently best known schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703036</identifier>
 <datestamp>2008-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703036</id><created>2007-03-08</created><updated>2008-03-08</updated><authors><author><keyname>Creignou</keyname><forenames>Jean</forenames><affiliation>IMB</affiliation></author></authors><title>Constructions of Grassmannian Simplices</title><categories>cs.IT math.IT</categories><comments>22 pages, 3 figures</comments><proxy>ccsd hal-00135498</proxy><abstract>  In this article an explicit method (relying on representation theory) to
construct packings in Grassmannian space is presented. Infinite families of
configurations having only one non-trivial set of principal angles are found
using 2-transitive groups. These packings are proved to reach the simplex bound
and are therefore optimal w.r.t. the chordal distance. The construction is
illustrated by an example on the symmetric group. Then some natural extends and
consequences of this situation are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703037</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703037</id><created>2007-03-08</created><authors><author><keyname>Ahn</keyname><forenames>Hee-Kap</forenames></author><author><keyname>Alt</keyname><forenames>Helmut</forenames></author><author><keyname>Asano</keyname><forenames>Tetsuo</forenames></author><author><keyname>Bae</keyname><forenames>Sang Won</forenames></author><author><keyname>Brass</keyname><forenames>Peter</forenames></author><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Na</keyname><forenames>Hyeon-Suk</forenames></author><author><keyname>Shin</keyname><forenames>Chan-Su</forenames></author><author><keyname>Wolff</keyname><forenames>Alexander</forenames></author></authors><title>Constructing Optimal Highways</title><categories>cs.CG</categories><comments>13 pages, 9 figures, preliminary version appeared at CATS'07</comments><journal-ref>International Journal of Foundations of Computer Science
  20(2009):3-23</journal-ref><doi>10.1142/S0129054109006425</doi><abstract>  For two points $p$ and $q$ in the plane, a straight line $h$, called a
highway, and a real $v&gt;1$, we define the \emph{travel time} (also known as the
\emph{city distance}) from $p$ and $q$ to be the time needed to traverse a
quickest path from $p$ to $q$, where the distance is measured with speed $v$ on
$h$ and with speed 1 in the underlying metric elsewhere.
  Given a set $S$ of $n$ points in the plane and a highway speed $v$, we
consider the problem of finding a \emph{highway} that minimizes the maximum
travel time over all pairs of points in $S$. If the orientation of the highway
is fixed, the optimal highway can be computed in linear time, both for the
$L_1$- and the Euclidean metric as the underlying metric. If arbitrary
orientations are allowed, then the optimal highway can be computed in $O(n^{2}
\log n)$ time. We also consider the problem of computing an optimal pair of
highways, one being horizontal, one vertical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703038</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703038</id><created>2007-03-08</created><authors><author><keyname>Zhou</keyname><forenames>Chan</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>Delay and Throughput Optimal Scheduling for OFDM Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE International Symposium on Information Theory
  (ISIT2007)</comments><journal-ref>publisched in Proc. IEEE Globecom 2007</journal-ref><abstract>  In this paper a scheduling policy is presented which minimizes the average
delay of the users. The scheduling scheme is investigated both by analysis and
simulations carried out in the context of Orthogonal Frequency Division
Multiplexing (OFDM) broadcast channels (BC). First the delay optimality is
obtained for a static scenario providing solutions for specific subproblems,
then the analysis is carried over to the dynamic scheme. Furthermore auxiliary
tools are given for proving throughput optimality. Finally simulations show the
superior performance of the presented scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703039</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703039</id><created>2007-03-08</created><updated>2007-05-04</updated><authors><author><keyname>Colcombet</keyname><forenames>Thomas</forenames></author><author><keyname>L&#xf6;ding</keyname><forenames>Christof</forenames></author></authors><title>Transforming structures by set interpretations</title><categories>cs.LO</categories><comments>36 pages</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 2 (May 4,
  2007) lmcs:745</journal-ref><doi>10.2168/LMCS-3(2:4)2007</doi><abstract>  We consider a new kind of interpretation over relational structures: finite
sets interpretations. Those interpretations are defined by weak monadic
second-order (WMSO) formulas with free set variables. They transform a given
structure into a structure with a domain consisting of finite sets of elements
of the orignal structure. The definition of these interpretations directly
implies that they send structures with a decidable WMSO theory to structures
with a decidable first-order theory. In this paper, we investigate the
expressive power of such interpretations applied to infinite deterministic
trees. The results can be used in the study of automatic and tree-automatic
structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703040</id><created>2007-03-08</created><authors><author><keyname>Bakman</keyname><forenames>Yefim</forenames><affiliation>Tel-Aviv University</affiliation></author></authors><title>Why the Standard Data Processing should be changed</title><categories>cs.MS</categories><abstract>  The basic statistical methods of data representation did not change since
their emergence. Their simplicity was dictated by the intricacies of
computations in the before computers epoch. It turns out that such approach is
not uniquely possible in the presence of quick computers. The suggested here
method improves significantly the reliability of data processing and their
graphical representation. In this paper we show problems of the standard data
processing which can bring to incorrect results. A method solving these
problems is proposed. It is based on modification of data representation. The
method was implemented in a computer program Consensus5. The program
performances are illustrated through varied examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703041</id><created>2007-03-08</created><authors><author><keyname>Fertalj</keyname><forenames>Kresimir</forenames></author><author><keyname>Horvat</keyname><forenames>Marko</forenames></author></authors><title>Comparing Architectures of Mobile Applications</title><categories>cs.OH</categories><comments>8 pages, 7 figures, 6 tables. Proceedings of the 5th WSEAS
  International Conference on Automation &amp; Information in Venice, Italy</comments><journal-ref>WSEAS Trans. on COMMUNICATIONS, Issue 4, Volume 3, October 2004,
  pp. 946-952</journal-ref><abstract>  This article describes various advantages and disadvantages of SMS, WAP, J2ME
and Windows CE technologies in designing mobile applications. In defining the
architecture of any software application it is important to get the best
trade-off between platform's possibilities and design requirements. Achieving
optimum software design is even more important with mobile applications where
all computer resources are limited. Therefore, it is important to have a
comparative analysis of all relevant contemporary approaches in designing
mobile applications. As always, the choice between these technologies is
determined by application requirements and system capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703042</id><created>2007-03-09</created><authors><author><keyname>Brozovsky</keyname><forenames>Lukas</forenames></author><author><keyname>Petricek</keyname><forenames>Vaclav</forenames></author></authors><title>Recommender System for Online Dating Service</title><categories>cs.IR cs.SE</categories><comments>Accepted for Znalosti 2007</comments><acm-class>H.3.3</acm-class><abstract>  Users of online dating sites are facing information overload that requires
them to manually construct queries and browse huge amount of matching user
profiles. This becomes even more problematic for multimedia profiles. Although
matchmaking is frequently cited as a typical application for recommender
systems, there is a surprising lack of work published in this area. In this
paper we describe a recommender system we implemented and perform a
quantitative comparison of two collaborative filtering (CF) and two global
algorithms. Results show that collaborative filtering recommenders
significantly outperform global algorithms that are currently used by dating
sites. A blind experiment with real users also confirmed that users prefer CF
based recommendations to global popularity recommendations. Recommender systems
show a great potential for online dating where they could improve the value of
the service to users and improve monetization of the service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703043</id><created>2007-03-09</created><authors><author><keyname>Petricek</keyname><forenames>Vaclav</forenames></author><author><keyname>Cox</keyname><forenames>Ingemar J.</forenames></author><author><keyname>Han</keyname><forenames>Hui</forenames></author><author><keyname>Councill</keyname><forenames>Isaac G.</forenames></author><author><keyname>Giles</keyname><forenames>C. Lee</forenames></author></authors><title>A Comparison of On-Line Computer Science Citation Databases</title><categories>cs.DL</categories><comments>ECDL 2005</comments><acm-class>H.3.7</acm-class><abstract>  This paper examines the difference and similarities between the two on-line
computer science citation databases DBLP and CiteSeer. The database entries in
DBLP are inserted manually while the CiteSeer entries are obtained autonomously
via a crawl of the Web and automatic processing of user submissions. CiteSeer's
autonomous citation database can be considered a form of self-selected on-line
survey. It is important to understand the limitations of such databases,
particularly when citation information is used to assess the performance of
authors, institutions and funding bodies.
  We show that the CiteSeer database contains considerably fewer single author
papers. This bias can be modeled by an exponential process with intuitive
explanation. The model permits us to predict that the DBLP database covers
approximately 24% of the entire literature of Computer Science. CiteSeer is
also biased against low-cited papers.
  Despite their difference, both databases exhibit similar and significantly
different citation distributions compared with previous analysis of the Physics
community. In both databases, we also observe that the number of authors per
paper has been increasing over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703044</id><created>2007-03-09</created><authors><author><keyname>Thibault</keyname><forenames>Samuel</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Hinderer</keyname><forenames>Sebastien</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>BrlAPI: Simple, Portable, Concurrent, Application-level Control of
  Braille Terminals</title><categories>cs.HC</categories><proxy>ccsd inria-00135946</proxy><journal-ref>Dans International Conference on Information and Communication
  Technology Accessibility (ICTA) (2007)</journal-ref><abstract>  Screen readers can drive braille devices for allowing visually impaired users
to access computer environments, by providing them the same information as
sighted users. But in some cases, this view is not easy to use on a braille
device. In such cases, it would be much more useful to let applications provide
their own braille feedback, specially adapted to visually impaired users. Such
applications would then need the ability to output braille ; however, allowing
both screen readers and applications access a wide panel of braille devices is
not a trivial task. We present an abstraction layer that applications may use
to communicate with braille devices. They do not need to deal with the
specificities of each device, but can do so if necessary. We show how several
applications can communicate with one braille device concurrently, with BrlAPI
making sensible choices about which application eventually gets access to the
device. The description of a widely used implementation of BrlAPI is included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703045</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703045</id><created>2007-03-09</created><authors><author><keyname>Ak&#xe7;akaya</keyname><forenames>Mehmet</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Performance Bounds on Sparse Representations Using Redundant Frames</title><categories>cs.IT math.IT</categories><comments>8 pages, 1 figure, Submitted to IEEE Transactions on Signal
  Processing</comments><abstract>  We consider approximations of signals by the elements of a frame in a complex
vector space of dimension $N$ and formulate both the noiseless and the noisy
sparse representation problems. The noiseless representation problem is to find
sparse representations of a signal $\mathbf{r}$ given that such representations
exist. In this case, we explicitly construct a frame, referred to as the
Vandermonde frame, for which the noiseless sparse representation problem can be
solved uniquely using $O(N^2)$ operations, as long as the number of non-zero
coefficients in the sparse representation of $\mathbf{r}$ is $\epsilon N$ for
some $0 \le \epsilon \le 0.5$, thus improving on a result of Candes and Tao
\cite{Candes-Tao}. We also show that $\epsilon \le 0.5$ cannot be relaxed
without violating uniqueness.
  The noisy sparse representation problem is to find sparse representations of
a signal $\mathbf{r}$ satisfying a distortion criterion. In this case, we
establish a lower bound on the trade-off between the sparsity of the
representation, the underlying distortion and the redundancy of any given
frame.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703046</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703046</id><created>2007-03-09</created><updated>2007-07-17</updated><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author></authors><title>Optimal Power Allocation for Distributed Detection over MIMO Channels in
  Wireless Sensor Networks</title><categories>cs.IT math.IT</categories><comments>14 pages, 31 figures, under review for IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2008.924639</doi><abstract>  In distributed detection systems with wireless sensor networks, the
communication between sensors and a fusion center is not perfect due to
interference and limited transmitter power at the sensors to combat noise at
the fusion center's receiver. The problem of optimizing detection performance
with such imperfect communication brings a new challenge to distributed
detection. In this paper, sensors are assumed to have independent but
nonidentically distributed observations, and a multi-input/multi-output (MIMO)
channel model is included to account for imperfect communication between the
sensors and the fusion center. The J-divergence between the distributions of
the detection statistic under different hypotheses is used as a performance
criterion in order to provide a tractable analysis. Optimizing the performance
(in terms of the J-divergence) with individual and total transmitter power
constraints on the sensors is studied, and the corresponding power allocation
scheme is provided. It is interesting to see that the proposed power allocation
is a tradeoff between two factors, the communication channel quality and the
local decision quality. For the case with orthogonal channels under certain
conditions, the power allocation can be solved by a weighted water-filling
algorithm. Simulations show that, to achieve the same performance, the proposed
power allocation in certain cases only consumes as little as 25 percent of the
total power used by an equal power allocation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703047</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703047</id><created>2007-03-09</created><authors><author><keyname>Farmanbar</keyname><forenames>Hamid</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Precoding for the AWGN Channel with Discrete Interference</title><categories>cs.IT math.IT</categories><comments>29 Pages, 9 figures, Submitted to IEEE Transactions on Information
  Theory</comments><abstract>  $M$-ary signal transmission over AWGN channel with additive $Q$-ary
interference where the sequence of i.i.d. interference symbols is known
causally at the transmitter is considered. Shannon's theorem for channels with
side information at the transmitter is used to formulate the capacity of the
channel. It is shown that by using at most $MQ-Q+1$ out of $M^Q$ input symbols
of the \emph{associated} channel, the capacity is achievable. For the special
case where the Gaussian noise power is zero, a sufficient condition, which is
independent of interference, is given for the capacity to be $\log_2 M$ bits
per channel use. The problem of maximization of the transmission rate under the
constraint that the channel input given any current interference symbol is
uniformly distributed over the channel input alphabet is investigated. For this
setting, the general structure of a communication system with optimal precoding
is proposed. The extension of the proposed precoding scheme to continuous
channel input alphabet is also investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703048</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703048</id><created>2007-03-09</created><updated>2007-03-20</updated><authors><author><keyname>Hu</keyname><forenames>Luoquan</forenames></author><author><keyname>Yu</keyname><forenames>Han</forenames></author><author><keyname>Chen</keyname><forenames>Yifan</forenames></author></authors><title>Path Loss Models Based on Stochastic Rays</title><categories>cs.IT math.IT</categories><comments>23 pages, 11 figures, 18 References, to appear in IET Microwaves,
  Antenna &amp; Propagation In subsection '3.2 The generic stochastic ray model',
  Eq. (17): The original expression is false, now it is modified</comments><abstract>  In this paper, two-dimensional percolation lattices are applied to describe
wireless propagation environment, and stochastic rays are employed to model the
trajectories of radio waves. We first derive the probability that a stochastic
ray undergoes certain number of collisions at a specific spatial location.
Three classes of stochastic rays with different constraint conditions are
considered: stochastic rays of random walks, and generic stochastic rays with
two different anomalous levels. Subsequently, we obtain the closed-form
formulation of mean received power of radio waves under non line-of-sight
conditions for each class of stochastic ray. Specifically, the determination of
model parameters and the effects of lattice structures on the path loss are
investigated. The theoretical results are validated by comparison with
experimental data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703049</id><created>2007-03-10</created><authors><author><keyname>Karpov</keyname><forenames>Oleg N.</forenames></author><author><keyname>Savenkova</keyname><forenames>Olga A.</forenames></author></authors><title>Algorithm of Segment-Syllabic Synthesis in Speech Recognition Problem</title><categories>cs.SD cs.CL</categories><comments>11 pages, 4 figures</comments><abstract>  Speech recognition based on the syllable segment is discussed in this paper.
The principal search methods in space of states for the speech recognition
problem by segment-syllabic parameters trajectory synthesis are investigated.
Recognition as comparison the parameters trajectories in chosen speech units on
the sections of the segmented speech is realized. Some experimental results are
given and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703050</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703050</id><created>2007-03-11</created><authors><author><keyname>Bisnik</keyname><forenames>Nabhendra</forenames></author><author><keyname>Abouzeid</keyname><forenames>Alhussein A.</forenames></author></authors><title>On The Capacity Deficit of Mobile Wireless Ad Hoc Networks: A Rate
  Distortion Formulation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  Overheads incurred by routing protocols diminish the capacity available for
relaying useful data in a mobile wireless ad hoc network. Discovering lower
bounds on the amount of protocol overhead incurred for routing data packets is
important for the development of efficient routing protocols, and for
characterizing the actual (effective) capacity available for network users.
This paper presents an information-theoretic framework for characterizing the
minimum routing overheads of geographic routing in a network with mobile nodes.
specifically, the minimum overhead problem is formulated as a rate-distortion
problem. The formulation may be applied to networks with arbitrary traffic
arrival and location service schemes. Lower bounds are derived for the minimum
overheads incurred for maintaining the location of destination nodes and
consistent neighborhood information in terms of node mobility and packet
arrival process. This leads to a characterization of the deficit caused by the
routing overheads on the overall transport capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703051</id><created>2007-03-11</created><updated>2007-03-18</updated><authors><author><keyname>Ding</keyname><forenames>Yu</forenames></author></authors><title>An ExpTime Procedure for Description Logic $\mathcal{ALCQI}$ (Draft)</title><categories>cs.LO</categories><comments>This paper is submitted in 2007</comments><abstract>  A worst-case ExpTime tableau-based decision procedure is outlined for the
satisfiability problem in $\mathcal{ALCQI}$ w.r.t. general axioms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703052</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703052</id><created>2007-03-12</created><authors><author><keyname>Hollanti</keyname><forenames>C.</forenames></author><author><keyname>Lahtonen</keyname><forenames>J.</forenames></author><author><keyname>Ranto</keyname><forenames>K.</forenames></author><author><keyname>Vehkalahti</keyname><forenames>R.</forenames></author></authors><title>On the densest MIMO lattices from cyclic division algebras</title><categories>cs.IT math.IT</categories><comments>33 pages, 1 figure, submitted to IEEE Trans. on Inform. Theory Dec.
  2006</comments><acm-class>H.1.1</acm-class><journal-ref>IEEE Trans. Inf. Theory, vol. 55(8), Aug. 2009, pp. 3751-3780</journal-ref><abstract>  It is shown why the discriminant of a maximal order within a cyclic division
algebra must be minimized in order to get the densest possible matrix lattices
with a prescribed nonvanishing minimum determinant. Using results from class
field theory a lower bound to the minimum discriminant of a maximal order with
a given center and index (= the number of Tx/Rx antennas) is derived. Also
numerous examples of division algebras achieving our bound are given. E.g. we
construct a matrix lattice with QAM coefficients that has 2.5 times as many
codewords as the celebrated Golden code of the same minimum determinant. We
describe a general algorithm due to Ivanyos and Ronyai for finding maximal
orders within a cyclic division algebra and discuss our enhancements to this
algorithm. We also consider general methods for finding cyclic division
algebras of a prescribed index achieving our lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703053</id><created>2007-03-12</created><authors><author><keyname>Erus</keyname><forenames>Guray</forenames><affiliation>CRIP5</affiliation></author><author><keyname>Lom&#xe9;nie</keyname><forenames>Nicolas</forenames><affiliation>CRIP5</affiliation></author></authors><title>Extraction of cartographic objects in high resolution satellite images
  for object model generation</title><categories>cs.CV</categories><proxy>ccsd hal-00136179</proxy><journal-ref>4th Workshop on pattern Recognition in Remote Sensing in
  conjunction with ICPR2006 (08/2006) 00-00</journal-ref><abstract>  The aim of this study is to detect man-made cartographic objects in
high-resolution satellite images. New generation satellites offer a sub-metric
spatial resolution, in which it is possible (and necessary) to develop methods
at object level rather than at pixel level, and to exploit structural features
of objects. With this aim, a method to generate structural object models from
manually segmented images has been developed. To generate the model from
non-segmented images, extraction of the objects from the sample images is
required. A hybrid method of extraction (both in terms of input sources and
segmentation algorithms) is proposed: A region based segmentation is applied on
a 10 meter resolution multi-spectral image. The result is used as marker in a
&quot;marker-controlled watershed method using edges&quot; on a 2.5 meter resolution
panchromatic image. Very promising results have been obtained even on images
where the limits of the target objects are not apparent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703054</id><created>2007-03-12</created><authors><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Jungers</keyname><forenames>Raphael M.</forenames></author></authors><title>Linear time algorithms for Clobber</title><categories>cs.GT</categories><abstract>  We prove that the single-player game clobber is solvable in linear time when
played on a line or on a cycle. For this purpose, we show that this game is
equivalent to an optimization problem on a set of words defined by seven
classes of forbidden patterns. We also prove that, playing on the cycle, it is
always possible to remove at least 2n/3 pawns, and we give a conformation for
which it is not possible to do better, answering questions recently asked by
Faria et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703055</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703055</id><created>2007-03-12</created><authors><author><keyname>Pelckmans</keyname><forenames>Kristiaan</forenames></author><author><keyname>De Brabanter</keyname><forenames>Jos</forenames></author><author><keyname>Suykens</keyname><forenames>Johan A. K.</forenames></author><author><keyname>De Moor</keyname><forenames>Bart</forenames></author></authors><title>Support and Quantile Tubes</title><categories>cs.IT cs.LG math.IT</categories><abstract>  This correspondence studies an estimator of the conditional support of a
distribution underlying a set of i.i.d. observations. The relation with mutual
information is shown via an extension of Fano's theorem in combination with a
generalization bound based on a compression argument. Extensions to estimating
the conditional quantile interval, and statistical guarantees on the minimal
convex hull are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703056</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703056</id><created>2007-03-12</created><updated>2008-12-08</updated><authors><author><keyname>Aouiche</keyname><forenames>Kamel</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Unasssuming View-Size Estimation Techniques in OLAP</title><categories>cs.DB cs.PF</categories><comments>Published in ICEIS 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even if storage was infinite, a data warehouse could not materialize all
possible views due to the running time and update requirements. Therefore, it
is necessary to estimate quickly, accurately, and reliably the size of views.
Many available techniques make particular statistical assumptions and their
error can be quite large. Unassuming techniques exist, but typically assume we
have independent hashing for which there is no known practical implementation.
We adapt an unassuming estimator due to Gibbons and Tirthapura: its theoretical
bounds do not make unpractical assumptions. We compare this technique
experimentally with stochastic probabilistic counting, LogLog probabilistic
counting, and multifractal statistical models. Our experiments show that we can
reliably and accurately (within 10%, 19 times out 20) estimate view sizes over
large data sets (1.5 GB) within minutes, using almost no memory. However, only
Gibbons-Tirthapura provides universally tight estimates irrespective of the
size of the view. For large views, probabilistic counting has a small edge in
accuracy, whereas the competitive sampling-based method (multifractal) we
tested is an order of magnitude faster but can sometimes provide poor estimates
(relative error of 100%). In our tests, LogLog probabilistic counting is not
competitive. Experimental validation on the US Census 1990 data set and on the
Transaction Processing Performance (TPC H) data set is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703057</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703057</id><created>2007-03-12</created><authors><author><keyname>Pezeshki</keyname><forenames>Ali</forenames></author><author><keyname>Calderbank</keyname><forenames>A. Robert</forenames></author><author><keyname>Moran</keyname><forenames>William</forenames></author><author><keyname>Howard</keyname><forenames>Stephen D.</forenames></author></authors><title>Doppler Resilient Waveforms with Perfect Autocorrelation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, March 2007</comments><abstract>  We describe a method of constructing a sequence of phase coded waveforms with
perfect autocorrelation in the presence of Doppler shift. The constituent
waveforms are Golay complementary pairs which have perfect autocorrelation at
zero Doppler but are sensitive to nonzero Doppler shifts. We extend this
construction to multiple dimensions, in particular to radar polarimetry, where
the two dimensions are realized by orthogonal polarizations. Here we determine
a sequence of two-by-two Alamouti matrices where the entries involve Golay
pairs and for which the sum of the matrix-valued ambiguity functions vanish at
small Doppler shifts. The Prouhet-Thue-Morse sequence plays a key role in the
construction of Doppler resilient sequences of Golay pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703058</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703058</id><created>2007-03-13</created><updated>2008-12-08</updated><authors><author><keyname>Aouiche</keyname><forenames>Kamel</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>A Comparison of Five Probabilistic View-Size Estimation Techniques in
  OLAP</title><categories>cs.DB cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data warehouse cannot materialize all possible views, hence we must
estimate quickly, accurately, and reliably the size of views to determine the
best candidates for materialization. Many available techniques for view-size
estimation make particular statistical assumptions and their error can be
large. Comparatively, unassuming probabilistic techniques are slower, but they
estimate accurately and reliability very large view sizes using little memory.
We compare five unassuming hashing-based view-size estimation techniques
including Stochastic Probabilistic Counting and LogLog Probabilistic Counting.
Our experiments show that only Generalized Counting, Gibbons-Tirthapura, and
Adaptive Counting provide universally tight estimates irrespective of the size
of the view; of those, only Adaptive Counting remains constantly fast as we
increase the memory budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703059</id><created>2007-03-12</created><authors><author><keyname>Landsberg</keyname><forenames>J. M.</forenames></author></authors><title>Geometry and the complexity of matrix multiplication</title><categories>cs.CC math.AG math.RT</categories><comments>34 pages, 4 figures</comments><abstract>  We survey results in algebraic complexity theory, focusing on matrix
multiplication. Our goals are
  (i.) to show how open questions in algebraic complexity theory are naturally
posed as questions in geometry and representation theory, (ii.) to motivate
researchers to work on these questions, and (iii.) to point out relations with
more general problems in geometry. The key geometric objects for our study are
the secant varieties of Segre varieties. We explain how these varieties are
also useful for algebraic statistics, the study of phylogenetic invariants, and
quantum computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703060</id><created>2007-03-12</created><authors><author><keyname>Salmeron</keyname><forenames>Jose L.</forenames></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>Redesigning Decision Matrix Method with an indeterminacy-based inference
  process</title><categories>cs.AI</categories><comments>12 pages, 4 figures, one table</comments><acm-class>I.2.11</acm-class><journal-ref>A short version published in Advances in Fuzzy Sets and Systems,
  Vol. 1(2), 263-271, 2006</journal-ref><abstract>  For academics and practitioners concerned with computers, business and
mathematics, one central issue is supporting decision makers. In this paper, we
propose a generalization of Decision Matrix Method (DMM), using Neutrosophic
logic. It emerges as an alternative to the existing logics and it represents a
mathematical model of uncertainty and indeterminacy. This paper proposes the
Neutrosophic Decision Matrix Method as a more realistic tool for decision
making. In addition, a de-neutrosophication process is included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703061</identifier>
 <datestamp>2008-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703061</id><created>2007-03-13</created><updated>2008-03-25</updated><authors><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank</forenames></author></authors><title>Coding for Errors and Erasures in Random Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>This revised paper contains some minor changes and clarifications</comments><abstract>  The problem of error-control in random linear network coding is considered. A
``noncoherent'' or ``channel oblivious'' model is assumed where neither
transmitter nor receiver is assumed to have knowledge of the channel transfer
characteristic. Motivated by the property that linear network coding is
vector-space preserving, information transmission is modelled as the injection
into the network of a basis for a vector space $V$ and the collection by the
receiver of a basis for a vector space $U$. A metric on the projective geometry
associated with the packet space is introduced, and it is shown that a minimum
distance decoder for this metric achieves correct decoding if the dimension of
the space $V \cap U$ is sufficiently large. If the dimension of each codeword
is restricted to a fixed integer, the code forms a subset of a finite-field
Grassmannian, or, equivalently, a subset of the vertices of the corresponding
Grassmann graph. Sphere-packing and sphere-covering bounds as well as a
generalization of the Singleton bound are provided for such codes. Finally, a
Reed-Solomon-like code construction, related to Gabidulin's construction of
maximum rank-distance codes, is described and a Sudan-style ``list-1'' minimum
distance decoding algorithm is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703062</id><created>2007-03-13</created><authors><author><keyname>Coquelin</keyname><forenames>Pierre-Arnaud</forenames><affiliation>CMAP</affiliation></author><author><keyname>Munos</keyname><forenames>R&#xe9;mi</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Bandit Algorithms for Tree Search</title><categories>cs.LG</categories><proxy>ccsd inria-00136198</proxy><abstract>  Bandit based methods for tree search have recently gained popularity when
applied to huge trees, e.g. in the game of go (Gelly et al., 2006). The UCT
algorithm (Kocsis and Szepesvari, 2006), a tree search method based on Upper
Confidence Bounds (UCB) (Auer et al., 2002), is believed to adapt locally to
the effective smoothness of the tree. However, we show that UCT is too
``optimistic'' in some cases, leading to a regret O(exp(exp(D))) where D is the
depth of the tree. We propose alternative bandit algorithms for tree search.
First, a modification of UCT using a confidence sequence that scales
exponentially with the horizon depth is proven to have a regret O(2^D
\sqrt{n}), but does not adapt to possible smoothness in the tree. We then
analyze Flat-UCB performed on the leaves and provide a finite regret bound with
high probability. Then, we introduce a UCB-based Bandit Algorithm for Smooth
Trees which takes into account actual smoothness of the rewards for performing
efficient ``cuts'' of sub-optimal branches with high confidence. Finally, we
present an incremental tree search version which applies when the full tree is
too big (possibly infinite) to be entirely represented and show that with high
probability, essentially only the optimal branches is indefinitely developed.
We illustrate these methods on a global optimization problem of a Lipschitz
function, given noisy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703063</id><created>2007-03-13</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Ayesta</keyname><forenames>Urtzi</forenames><affiliation>LAAS</affiliation></author><author><keyname>Piunovskiy</keyname><forenames>Alexei</forenames></author></authors><title>Convergence and Optimal Buffer Sizing for Window Based AIMD Congestion
  Control</title><categories>cs.NI</categories><proxy>ccsd inria-00136205</proxy><abstract>  We study the interaction between the AIMD (Additive Increase Multiplicative
Decrease) congestion control and a bottleneck router with Drop Tail buffer. We
consider the problem in the framework of deterministic hybrid models. First, we
show that the hybrid model of the interaction between the AIMD congestion
control and bottleneck router always converges to a cyclic behavior. We
characterize the cycles. Necessary and sufficient conditions for the absence of
multiple jumps of congestion window in the same cycle are obtained. Then, we
propose an analytical framework for the optimal choice of the router buffer
size. We formulate the problem of the optimal router buffer size as a
multi-criteria optimization problem, in which the Lagrange function corresponds
to a linear combination of the average goodput and the average delay in the
queue. The solution to the optimization problem provides further evidence that
the buffer size should be reduced in the presence of traffic aggregation. Our
analytical results are confirmed by simulations performed with Simulink and the
NS simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703064</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703064</id><created>2007-03-13</created><updated>2007-04-26</updated><authors><author><keyname>Khoussainov</keyname><forenames>Bakhadyr</forenames></author><author><keyname>Nies</keyname><forenames>Andre</forenames></author><author><keyname>Rubin</keyname><forenames>Sasha</forenames></author><author><keyname>Stephan</keyname><forenames>Frank</forenames></author></authors><title>Automatic Structures: Richness and Limitations</title><categories>cs.DM cs.LO</categories><acm-class>F.1.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 2 (April 26,
  2007) lmcs:902</journal-ref><doi>10.2168/LMCS-3(2:2)2007</doi><abstract>  We study the existence of automatic presentations for various algebraic
structures. An automatic presentation of a structure is a description of the
universe of the structure by a regular set of words, and the interpretation of
the relations by synchronised automata. Our first topic concerns characterising
classes of automatic structures. We supply a characterisation of the automatic
Boolean algebras, and it is proven that the free Abelian group of infinite
rank, as well as certain Fraisse limits, do not have automatic presentations.
In particular, the countably infinite random graph and the random partial order
do not have automatic presentations. Furthermore, no infinite integral domain
is automatic. Our second topic is the isomorphism problem. We prove that the
complexity of the isomorphism problem for the class of all automatic structures
is \Sigma_1^1-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703065</id><created>2007-03-13</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>Satisfying assignments of Random Boolean CSP: Clusters and Overlaps</title><categories>cs.DM cond-mat.dis-nn cs.CC</categories><abstract>  The distribution of overlaps of solutions of a random CSP is an indicator of
the overall geometry of its solution space. For random $k$-SAT, nonrigorous
methods from Statistical Physics support the validity of the ``one step replica
symmetry breaking'' approach. Some of these predictions were rigorously
confirmed in \cite{cond-mat/0504070/prl} \cite{cond-mat/0506053}. There it is
proved that the overlap distribution of random $k$-SAT, $k\geq 9$, has
discontinuous support. Furthermore, Achlioptas and Ricci-Tersenghi proved that,
for random $k$-SAT, $k\geq 8$. and constraint densities close enough to the
phase transition there exists an exponential number of clusters of satisfying
assignments; moreover, the distance between satisfying assignments in different
clusters is linear.
  We aim to understand the structural properties of random CSP that lead to
solution clustering. To this end, we prove two results on the cluster structure
of solutions for binary CSP under the random model from Molloy (STOC 2002)
  1. For all constraint sets $S$ (described explicitly in Creignou and Daude
(2004), Istrate (2005)) s.t. $SAT(S)$ has a sharp threshold and all $q\in
(0,1]$, $q$-overlap-$SAT(S)$ has a sharp threshold (i.e. the first step of the
approach in Mora et al. works in all nontrivial cases). 2. For any constraint
density value $c&lt;1$, the set of solutions of a random instance of 2-SAT form,
w.h.p., a single cluster. Also, for and any $q\in (0,1]$ such an instance has
w.h.p. two satisfying assignment of overlap $\sim q$. Thus, as expected from
Statistical Physics predictions, the second step of the approach in Mora et al.
fails for 2-SAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703066</id><created>2007-03-14</created><authors><author><keyname>Cohen</keyname><forenames>Charon</forenames></author><author><keyname>Lobstein</keyname><forenames>Hudry</forenames></author></authors><title>Discriminating and Identifying Codes in the Binary Hamming Space</title><categories>cs.DM</categories><abstract>  Let $F^n$ be the binary $n$-cube, or binary Hamming space of dimension $n$,
endowed with the Hamming distance, and ${\cal E}^n$ (respectively, ${\cal
O}^n$) the set of vectors with even (respectively, odd) weight. For $r\geq 1$
and $x\in F^n$, we denote by $B_r(x)$ the ball of radius $r$ and centre $x$. A
code $C\subseteq F^n$ is said to be $r$-identifying if the sets $B_r(x) \cap
C$, $x\in F^n$, are all nonempty and distinct. A code $C\subseteq {\cal E}^n$
is said to be $r$-discriminating if the sets $B_r(x) \cap C$, $x\in {\cal
O}^n$, are all nonempty and distinct. We show that the two definitions, which
were given for general graphs, are equivalent in the case of the Hamming space,
in the following sense: for any odd $r$, there is a bijection between the set
of $r$-identifying codes in $F^n$ and the set of $r$-discriminating codes in
$F^{n+1}$. We then extend previous studies on constructive upper bounds for the
minimum cardinalities of identifying codes in the Hamming space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703067</id><created>2007-03-14</created><updated>2007-03-20</updated><authors><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Target assignment for robotic networks: asymptotic performance under
  limited communication</title><categories>cs.RO</categories><comments>2007 ACC paper including proofs; Corrected typos</comments><abstract>  We are given an equal number of mobile robotic agents, and distinct target
locations. Each agent has simple integrator dynamics, a limited communication
range, and knowledge of the position of every target. We address the problem of
designing a distributed algorithm that allows the group of agents to divide the
targets among themselves and, simultaneously, leads each agent to reach its
unique target. We do not require connectivity of the communication graph at any
time. We introduce a novel assignment-based algorithm with the following
features: initial assignments and robot motions follow a greedy rule, and
distributed refinements of the assignment exploit an implicit circular ordering
of the targets. We prove correctness of the algorithm, and give worst-case
asymptotic bounds on the time to complete the assignment as the environment
grows with the number of agents. We show that among a certain class of
distributed algorithms, our algorithm is asymptotically optimal. The analysis
utilizes results on the Euclidean traveling salesperson problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703068</id><created>2007-03-14</created><updated>2007-03-14</updated><authors><author><keyname>Jackson</keyname><forenames>Kenneth R.</forenames></author><author><keyname>Jaimungal</keyname><forenames>Sebastian</forenames></author><author><keyname>Surkov</keyname><forenames>Vladimir</forenames></author></authors><title>Option Valuation using Fourier Space Time Stepping</title><categories>cs.CE</categories><abstract>  It is well known that the Black-Scholes-Merton model suffers from several
deficiencies. Jump-diffusion and Levy models have been widely used to partially
alleviate some of the biases inherent in this classical model. Unfortunately,
the resulting pricing problem requires solving a more difficult partial-integro
differential equation (PIDE) and although several approaches for solving the
PIDE have been suggested in the literature, none are entirely satisfactory. All
treat the integral and diffusive terms asymmetrically and are difficult to
extend to higher dimensions. We present a new, efficient algorithm, based on
transform methods, which symmetrically treats the diffusive and integrals
terms, is applicable to a wide class of path-dependent options (such as
Bermudan, barrier, and shout options) and options on multiple assets, and
naturally extends to regime-switching Levy models. We present a concise study
of the precision and convergence properties of our algorithm for several
classes of options and Levy models and demonstrate that the algorithm is
second-order in space and first-order in time for path-dependent options.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703069</id><created>2007-03-14</created><updated>2007-05-02</updated><authors><author><keyname>Fodor</keyname><forenames>Paul</forenames></author></authors><title>Portlet Wrappers using JavaScript</title><categories>cs.SE</categories><acm-class>H.5.2; D.3.3</acm-class><abstract>  In this paper we extend the classical portal (with static portlets) design
with HTML DOM Web clipping on the client browser using dynamic JavaScript
portlets: the portal server supplies the user/passwords for all services
through https and the client browser retrieves web pages and
cuts/selects/changes the desired parts using paths (XPath) in the Web page
structure. This operation brings along a set of advantages: dynamic wrapping of
existing legacy websites in the client browser, the reloading of only changed
portlets instead of whole portal, low bandwidth on the server, the elimination
of re-writing the URL links in the portal, and last but not least, a support
for Java applets in portlets by putting the login cookies on the client
browser. Our solution is compliant with JSR168 Portlet Specification allowing
portability across all vendor platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703070</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703070</id><created>2007-03-14</created><updated>2007-05-02</updated><authors><author><keyname>Fodor</keyname><forenames>Paul</forenames></author></authors><title>Flexible Audio Streams</title><categories>cs.HC</categories><acm-class>H.5.2</acm-class><abstract>  Tremendous research effort was invested in audio browsers and machine
learning techniques to decode the structure of Web pages in order to put them
into an audio format. In this paper, we address a simpler and efficient
solution for the creation of an audio browser of VOICEXML generated from
RSS/Atom stream feeds. We developed a multimodal (audio and graphical) portal
application that offers RSS/Atom feeds. By utilizing sing our system, the user
can interact using voice or graphic commands, listen and watch digital content,
such as news, blogs feeds, podcasts, and even access email and personal
schedules. The portal system permits the use of security credentials
(user/password authentication) to collect secure RSS/Atom stream in the
multimodal browser to connect the user to specific personal services. A series
experiments have been conducted to evaluate the performance of the RSS reader
and navigator. Our system is extremely beneficial for a wide range of
applications, from interfaces for the visual impaired users to browsers for
mobile telephonic interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703071</id><created>2007-03-14</created><updated>2007-05-02</updated><authors><author><keyname>Fodor</keyname><forenames>Paul</forenames></author></authors><title>Automatic Annotation of XHTML Pages with Audio Components</title><categories>cs.OH</categories><acm-class>H.5.2</acm-class><abstract>  In this paper we present Deiush, a multimodal system for browsing hypertext
Web documents. The Deiush system is based on our novel approach to
automatically annotate hypertext Web documents (i.e. XHTML pages) with
browsable audio components. It combines two key technologies: (1) middleware
automatic separation of Web documents through structural and semantic analysis
which is annotated with audio components, transforming them into XHTML+VoiceXML
format to represent multimodal dialog; and (2) Opera Browser, an already
standardized browser which we adopt as an interface of the XHTML+VoiceXML
output of annotating. This paper describes the annotation technology of Deiush
and presents an initial system evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703072</id><created>2007-03-14</created><updated>2007-03-27</updated><authors><author><keyname>Fodor</keyname><forenames>Paul</forenames></author></authors><title>Domain Directed Dialogs for Decision Processes</title><categories>cs.OH</categories><acm-class>H.5.2</acm-class><abstract>  The search for a standardized optimum way to communicate using natural
language dialog has involved a lot of research. However, due to the diversity
of communication domains, we think that this is extremely difficult to achieve
and different dialogue management techniques should be applied for different
situations. Our work presents the basis of a communication mechanism that
supports decision processes, is based on decision trees, and minimizes the
number of steps (turn-takes) in the dialogue. The initial dialog workflow is
automatically generated and the user's interaction with the system can also
change the decision tree and create new dialog paths with optimized cost. The
decision tree represents the chronological ordering of the actions (via the
parent-child relationship) and uses an object frame to represent the
information state (capturing the notion of context). This paper presents our
framework, the formalism for interaction and dialogue, and an evaluation of the
system compared to relevant dialog planning frameworks (i.e. finite state
diagrams, frame-based, information state and planning-based dialogue systems).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703073</id><created>2007-03-15</created><updated>2007-03-16</updated><authors><author><keyname>Min&#xe9;</keyname><forenames>Antoine</forenames><affiliation>LIENS</affiliation></author></authors><title>A New Numerical Abstract Domain Based on Difference-Bound Matrices</title><categories>cs.PL</categories><comments>(update: reversed author first and last names)</comments><proxy>ccsd hal-00136665</proxy><journal-ref>Program As Data Objects II (PADOII) (05/2001) 155-172</journal-ref><abstract>  This paper presents a new numerical abstract domain for static analysis by
abstract interpretation. This domain allows us to represent invariants of the
form (x-y&lt;=c) and (+/-x&lt;=c), where x and y are variables values and c is an
integer or real constant. Abstract elements are represented by Difference-Bound
Matrices, widely used by model-checkers, but we had to design new operators to
meet the needs of abstract interpretation. The result is a complete lattice of
infinite height featuring widening, narrowing and common transfer functions. We
focus on giving an efficient O(n2) representation and graph-based O(n3)
algorithms - where n is the number of variables|and claim that this domain
always performs more precisely than the well-known interval domain. To
illustrate the precision/cost tradeoff of this domain, we have implemented
simple abstract interpreters for toy imperative and parallel languages which
allowed us to prove some non-trivial algorithms correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703074</id><created>2007-03-15</created><updated>2007-03-16</updated><authors><author><keyname>Min&#xe9;</keyname><forenames>Antoine</forenames><affiliation>LIENS</affiliation></author></authors><title>Field-Sensitive Value Analysis of Embedded C Programs with Union Types
  and Pointer Arithmetics</title><categories>cs.PL</categories><comments>(update: reversed author first and last names)</comments><proxy>ccsd hal-00136650</proxy><journal-ref>Languages, Compilers, and Tools for Embedded Systems (LCTES)
  (06/2006) 54-63</journal-ref><abstract>  We propose a memory abstraction able to lift existing numerical static
analyses to C programs containing union types, pointer casts, and arbitrary
pointer arithmetics. Our framework is that of a combined points-to and
data-value analysis. We abstract the contents of compound variables in a
field-sensitive way, whether these fields contain numeric or pointer values,
and use stock numerical abstract domains to find an overapproximation of all
possible memory states--with the ability to discover relationships between
variables. A main novelty of our approach is the dynamic mapping scheme we use
to associate a flat collection of abstract cells of scalar type to the set of
accessed memory locations, while taking care of byte-level aliases - i.e., C
variables with incompatible types allocated in overlapping memory locations. We
do not rely on static type information which can be misleading in C programs as
it does not account for all the uses a memory zone may be put to. Our work was
incorporated within the Astr\'{e}e static analyzer that checks for the absence
of run-time-errors in embedded, safety-critical, numerical-intensive software.
It replaces the former memory domain limited to well-typed, union-free,
pointer-cast free data-structures. Early results demonstrate that this
abstraction allows analyzing a larger class of C programs, without much cost
overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703075</id><created>2007-03-15</created><updated>2007-03-16</updated><authors><author><keyname>Min&#xe9;</keyname><forenames>Antoine</forenames><affiliation>LIENS</affiliation></author></authors><title>A Few Graph-Based Relational Numerical Abstract Domains</title><categories>cs.PL</categories><comments>(update: reversed author first and last names)</comments><proxy>ccsd hal-00136663</proxy><journal-ref>Static Analysis Symposium (SAS) (09/2002) 117-132</journal-ref><abstract>  This article presents the systematic design of a class of relational
numerical abstract domains from non-relational ones. Constructed domains
represent sets of invariants of the form (vj - vi in C), where vj and vi are
two variables, and C lives in an abstraction of P(Z), P(Q), or P(R). We will
call this family of domains weakly relational domains. The underlying concept
allowing this construction is an extension of potential graphs and
shortest-path closure algorithms in exotic-like algebras. Example constructions
are given in order to retrieve well-known domains as well as new ones. Such
domains can then be used in the Abstract Interpretation framework in order to
design various static analyses. Amajor benfit of this construction is its
modularity, allowing to quickly implement new abstract domains from existing
ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703076</id><created>2007-03-15</created><updated>2007-03-16</updated><authors><author><keyname>Min&#xe9;</keyname><forenames>Antoine</forenames><affiliation>LIENS</affiliation></author></authors><title>Symbolic Methods to Enhance the Precision of Numerical Abstract Domains</title><categories>cs.PL</categories><comments>(update: reversed author first and last names)</comments><proxy>ccsd hal-00136661</proxy><journal-ref>Verification, Abstract Interpretation and Model Checking (VMCAI)
  (01/2006) 348-363</journal-ref><abstract>  We present lightweight and generic symbolic methods to improve the precison
of numerical static analyses based on Abstract Interpretation. The main idea is
to simplify numerical expressions before they are fed to abstract transfer
functions. An important novelty is that these simplifications are performed
on-the-fly, using information gathered dynamically by the analyzer. A first
method, called &quot;linearization,&quot; allows abstracting arbitrary expressions into
affine forms with interval coefficients while simplifying them. A second
method, called &quot;symbolic constant propagation,&quot; enhances the simplification
feature of the linearization by propagating assigned expressions in a symbolic
way. Combined together, these methods increase the relationality level of
numerical abstract domains and make them more robust against program
transformations. We show how they can be integrated within the classical
interval, octagon and polyhedron domains. These methods have been incorporated
within the Astr\'{e}e static analyzer that checks for the absence of run-time
errors in embedded critical avionics software. We present an experimental proof
of their usefulness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703077</id><created>2007-03-15</created><updated>2007-03-16</updated><authors><author><keyname>Min&#xe9;</keyname><forenames>Antoine</forenames><affiliation>LIENS</affiliation></author></authors><title>Relational Abstract Domains for the Detection of Floating-Point Run-Time
  Errors</title><categories>cs.PL</categories><comments>(update: reversed author first and last names)</comments><proxy>ccsd hal-00136662</proxy><journal-ref>European Symposium on Programming (ESOP) (03/2004) 3-17</journal-ref><abstract>  We present a new idea to adapt relational abstract domains to the analysis of
IEEE 754-compliant floating-point numbers in order to statically detect,
through abstract Interpretation-based static analyses, potential floating-point
run-time exceptions such as overflows or invalid operations. In order to take
the non-linearity of rounding into account, expressions are modeled as linear
forms with interval coefficients. We show how to extend already existing
numerical abstract domains, such as the octagon abstract domain, to efficiently
abstract transfer functions based on interval linear forms. We discuss specific
fixpoint stabilization techniques and give some experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703078</id><created>2007-03-15</created><authors><author><keyname>Oechtering</keyname><forenames>Tobias J.</forenames></author><author><keyname>Bjelakovic</keyname><forenames>Igor</forenames></author><author><keyname>Schnurr</keyname><forenames>Clemens</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>Broadcast Capacity Region of Two-Phase Bidirectional Relaying</title><categories>cs.IT math.IT</categories><comments>25 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory</comments><abstract>  In a three-node network a half-duplex relay node enables bidirectional
communication between two nodes with a spectral efficient two phase protocol.
In the first phase, two nodes transmit their message to the relay node, which
decodes the messages and broadcast a re-encoded composition in the second
phase. In this work we determine the capacity region of the broadcast phase. In
this scenario each receiving node has perfect information about the message
that is intended for the other node. The resulting set of achievable rates of
the two-phase bidirectional relaying includes the region which can be achieved
by applying XOR on the decoded messages at the relay node. We also prove the
strong converse for the maximum error probability and show that this implies
that the $[\eps_1,\eps_2]$-capacity region defined with respect to the average
error probability is constant for small values of error parameters $\eps_1$,
$\eps_2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703079</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703079</id><created>2007-03-15</created><updated>2007-04-26</updated><authors><author><keyname>Engelfriet</keyname><forenames>Joost</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author></authors><title>Automata with Nested Pebbles Capture First-Order Logic with Transitive
  Closure</title><categories>cs.LO</categories><comments>Paper for Logical Methods in Computer Science, 27 pages, 1 figure</comments><acm-class>F.1.1; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 3, Issue 2 (April 26,
  2007) lmcs:1198</journal-ref><doi>10.2168/LMCS-3(2:3)2007</doi><abstract>  String languages recognizable in (deterministic) log-space are characterized
either by two-way (deterministic) multi-head automata, or following Immerman,
by first-order logic with (deterministic) transitive closure. Here we elaborate
this result, and match the number of heads to the arity of the transitive
closure. More precisely, first-order logic with k-ary deterministic transitive
closure has the same power as deterministic automata walking on their input
with k heads, additionally using a finite set of nested pebbles. This result is
valid for strings, ordered trees, and in general for families of graphs having
a fixed automaton that can be used to traverse the nodes of each of the graphs
in the family. Other examples of such families are grids, toruses, and
rectangular mazes. For nondeterministic automata, the logic is restricted to
positive occurrences of transitive closure.
  The special case of k=1 for trees, shows that single-head deterministic
tree-walking automata with nested pebbles are characterized by first-order
logic with unary deterministic transitive closure. This refines our earlier
result that placed these automata between first-order and monadic second-order
logic on trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703080</id><created>2007-03-15</created><authors><author><keyname>Dutta</keyname><forenames>Joy</forenames></author><author><keyname>Fodor</keyname><forenames>Paul</forenames></author></authors><title>A Systematic Approach to Web-Application Development</title><categories>cs.SE</categories><acm-class>H.5.2; D.3.3</acm-class><abstract>  Designing a web-application from a specification involves a series of
well-planned and well executed steps leading to the final product. This often
involves critical changes in design while testing the application, which itself
is slow and cumbersome. Traditional approaches either fully automate the
web-application development process, or let developers write everything from
scratch. Our approach is based on a middle-ground, with precise control on the
workflow and usage of a set of custom-made software tools to automate a
significant part of code generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703081</id><created>2007-03-15</created><authors><author><keyname>Grohe</keyname><forenames>Martin</forenames></author><author><keyname>Hernich</keyname><forenames>Andre</forenames></author><author><keyname>Schweikardt</keyname><forenames>Nicole</forenames></author></authors><title>Randomized Computations on Large Data Sets: Tight Lower Bounds</title><categories>cs.DB cs.CC</categories><comments>29 pages, 2 figures, full version of PODS'06 paper</comments><acm-class>F.1.3; F.1.1</acm-class><abstract>  We study the randomized version of a computation model (introduced by Grohe,
Koch, and Schweikardt (ICALP'05); Grohe and Schweikardt (PODS'05)) that
restricts random access to external memory and internal memory space.
Essentially, this model can be viewed as a powerful version of a data stream
model that puts no cost on sequential scans of external memory (as other models
for data streams) and, in addition, (like other external memory models, but
unlike streaming models), admits several large external memory devices that can
be read and written to in parallel.
  We obtain tight lower bounds for the decision problems set equality, multiset
equality, and checksort. More precisely, we show that any randomized
one-sided-error bounded Monte Carlo algorithm for these problems must perform
Omega(log N) random accesses to external memory devices, provided that the
internal memory size is at most O(N^(1/4)/log N), where N denotes the size of
the input data.
  From the lower bound on the set equality problem we can infer lower bounds on
the worst case data complexity of query evaluation for the languages XQuery,
XPath, and relational algebra on streaming data. More precisely, we show that
there exist queries in XQuery, XPath, and relational algebra, such that any
(randomized) Las Vegas algorithm that evaluates these queries must perform
Omega(log N) random accesses to external memory devices, provided that the
internal memory size is at most O(N^(1/4)/log N).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703082</id><created>2007-03-15</created><authors><author><keyname>Rasch</keyname><forenames>Christian</forenames></author><author><keyname>Satzger</keyname><forenames>Thomas</forenames></author></authors><title>Remarks on the O(N) Implementation of the Fast Marching Method</title><categories>cs.NA</categories><comments>7 pages, 2 figures</comments><abstract>  The fast marching algorithm computes an approximate solution to the eikonal
equation in O(N log N) time, where the factor log N is due to the
administration of a priority queue. Recently, Yatziv, Bartesaghi and Sapiro
have suggested to use an untidy priority queue, reducing the overall complexity
to O(N) at the price of a small error in the computed solution. In this paper,
we give an explicit estimate of the error introduced, which is based on a
discrete comparison principle. This estimates implies in particular that the
choice of an accuracy level that is independent of the speed function F results
in the complexity bound O(Fmax /Fmin N). A numerical experiment illustrates
this robustness problem for large ratios Fmax /Fmin .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703083</id><created>2007-03-15</created><updated>2007-03-15</updated><authors><author><keyname>McCown</keyname><forenames>Frank</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Characterization of Search Engine Caches</title><categories>cs.DL cs.CY</categories><comments>5 pages, 9 figures, IS&amp;T Archiving 2007, May, 2007</comments><abstract>  Search engines provide cached copies of indexed content so users will have
something to &quot;click on&quot; if the remote resource is temporarily or permanently
unavailable. Depending on their proprietary caching strategies, search engines
will purge their indexes and caches of resources that exceed a threshold of
unavailability. Although search engine caches are provided only as an aid to
the interactive user, we are interested in building reliable preservation
services from the aggregate of these limited caching services. But first, we
must understand the contents of search engine caches. In this paper, we have
examined the cached contents of Ask, Google, MSN and Yahoo to profile such
things as overlap between index and cache, size, MIME type and &quot;staleness&quot; of
the cached resources. We also examined the overlap of the various caches with
the holdings of the Internet Archive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703084</id><created>2007-03-15</created><updated>2007-03-16</updated><authors><author><keyname>Min&#xe9;</keyname><forenames>Antoine</forenames><affiliation>LIENS</affiliation></author></authors><title>The Octagon Abstract Domain</title><categories>cs.PL</categories><comments>(update: reversed author first and last names)</comments><proxy>ccsd hal-00136664</proxy><journal-ref>Analysis, Slicing and Transformation (AST) (10/2001) 310-319</journal-ref><abstract>  This article presents a new numerical abstract domain for static analysis by
abstract interpretation. It extends a former numerical abstract domain based on
Difference-Bound Matrices and allows us to represent invariants of the form
(+/-x+/-y&lt;=c), where x and y are program variables and c is a real constant. We
focus on giving an efficient representation based on Difference-Bound Matrices
- O(n2) memory cost, where n is the number of variables - and graph-based
algorithms for all common abstract operators - O(n3) time cost. This includes a
normal form algorithm to test equivalence of representation and a widening
operator to compute least fixpoint approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703085</id><created>2007-03-15</created><authors><author><keyname>Gu</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author></authors><title>Dimension and Relative Frequencies</title><categories>cs.CC</categories><abstract>  We show how to calculate the finite-state dimension (equivalently, the
finite-state compressibility) of a saturated sets $X$ consisting of {\em all}
infinite sequences $S$ over a finite alphabet $\Sigma_m$ satisfying some given
condition $P$ on the asymptotic frequencies with which various symbols from
$\Sigma_m$ appear in $S$. When the condition $P$ completely specifies an
empirical probability distribution $\pi$ over $\Sigma_m$, i.e., a limiting
frequency of occurrence for {\em every} symbol in $\Sigma_m$, it has been known
since 1949 that the Hausdorff dimension of $X$ is precisely $\CH(\pi)$, the
Shannon entropy of $\pi$, and the finite-state dimension was proven to have
this same value in 2001.
  The saturated sets were studied by Volkmann and Cajar decades ago. It got
attention again only with the recent developments in multifractal analysis by
Barreira, Saussol, Schmeling, and separately Olsen. However, the powerful
methods they used -- ergodic theory and multifractal analysis -- do not yield a
value for the finite-state (or even computable) dimension in an obvious manner.
  We give a pointwise characterization of finite-state dimensions of saturated
sets. Simultaneously, we also show that their finite-state dimension and strong
dimension coincide with their Hausdorff and packing dimension respectively,
though the techniques we use are completely elementary. Our results
automatically extend to less restrictive effective settings (e.g.,
constructive, computable, and polynomial-time dimensions).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703086</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703086</id><created>2007-03-15</created><updated>2007-06-03</updated><authors><author><keyname>Kouvakis</keyname><forenames>John</forenames></author><author><keyname>Georgatos</keyname><forenames>Fotis</forenames></author></authors><title>A Technical Report On Grid Benchmarking using SEE V.O</title><categories>cs.PF</categories><comments>5 pages, 12 figures including tables of results, SEE VO</comments><report-no>TR-MOD07-001</report-no><abstract>  Grids include heterogeneous resources, which are based on different hardware
and software architectures or components. In correspondence with this diversity
of the infrastructure, the execution time of any single job, as well as the
total grid performance can both be affected substantially, which can be
demonstrated by measurements. Running a simple benchmarking suite can show this
heterogeneity and give us results about the differences over the grid sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703087</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703087</id><created>2007-03-15</created><updated>2007-04-12</updated><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Social Information Processing in Social News Aggregation</title><categories>cs.CY cs.AI cs.HC cs.MA</categories><comments>Extended version of the paper submitted to IEEE Internet Computing's
  special issue on Social Search</comments><doi>10.1109/MIC.2007.136</doi><abstract>  The rise of the social media sites, such as blogs, wikis, Digg and Flickr
among others, underscores the transformation of the Web to a participatory
medium in which users are collaboratively creating, evaluating and distributing
information. The innovations introduced by social media has lead to a new
paradigm for interacting with information, what we call 'social information
processing'. In this paper, we study how social news aggregator Digg exploits
social information processing to solve the problems of document recommendation
and rating. First, we show, by tracking stories over time, that social networks
play an important role in document recommendation. The second contribution of
this paper consists of two mathematical models. The first model describes how
collaborative rating and promotion of stories emerges from the independent
decisions made by many users. The second model describes how a user's
influence, the number of promoted stories and the user's social network,
changes in time. We find qualitative agreement between predictions of the model
and user data gathered from Digg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703088</identifier>
 <datestamp>2011-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703088</id><created>2007-03-15</created><authors><author><keyname>Vega-Paez</keyname><forenames>Ignacio</forenames></author><author><keyname>Hernandez-Hernandez</keyname><forenames>Carlos Alberto</forenames></author></authors><title>Plot 94 in ambiance X-Window</title><categories>cs.CV cs.GR</categories><report-no>IBP-TR1995-01</report-no><journal-ref>Proceedings in Information Systems Analysis and Synthesis ISAS
  1995, 5th, International Symposium on Systems Research, Informatics and
  Cybernetics, pp. 135-139, August 16-20, 95, Baden-Baden, Germany</journal-ref><abstract>  &lt;PLOT &gt; is a collection of routines to draw surfaces, contours and so on. In
this work we are presenting a version, that functions over work stations with
the operative system UNIX, that count with the graphic ambiance X-WINDOW with
the tools XLIB and OSF/MOTIF. This implant was realized for the work stations
DEC 5000-200, DEC IPX, and DEC ALFA of the CINVESTAV (Center of Investigation
and Advanced Studies). Also implanted in SILICON GRAPHICS of the CENAC
(National Center of Calculation of the Polytechnic National Institute
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703089</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703089</id><created>2007-03-15</created><authors><author><keyname>Vega-Paez</keyname><forenames>Ignacio</forenames></author><author><keyname>T</keyname><forenames>Feliu D. Sagols</forenames></author></authors><title>Space Program Language (SPL/SQL) for the Relational Approach of the
  Spatial Databases</title><categories>cs.DB cs.CG</categories><report-no>IBP-TR1995-02</report-no><journal-ref>Proceedings in Information Systems Analysis and Synthesis ISAS
  1995, 5th International Symposium on Systems Research, Informatics and
  Cybernetics, pp. 89-93 August 16-20, 95, Baden-Baden, Germany</journal-ref><abstract>  In this project we are presenting a grammar which unify the design and
development of spatial databases. In order to make it, we combine nominal and
spatial information, the former is represented by the relational model and
latter by a modification of the same model. The modification lets to represent
spatial data structures (as Quadtrees, Octrees, etc.) in a integrated way. This
grammar is important because with it we can create tools to build systems that
combine spatial-nominal characteristics such as Geographical Information
Systems (GIS), Hypermedia Systems, Computed Aided Design Systems (CAD), and so
on
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703090</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703090</id><created>2007-03-16</created><authors><author><keyname>Inderjeet</keyname><forenames>Kaur</forenames></author><author><keyname>Kanchan</keyname><forenames>Sharma</forenames></author><author><keyname>M</keyname><forenames>Kulkarni.</forenames></author></authors><title>Orthogonal Frequency Division Multiplexing: An Overview</title><categories>cs.IT math.IT</categories><comments>7 Pages, 5 Figures</comments><abstract>  Orthogonal Frequency Division Multiplexing (OFDM) is a multi-carrier
modulation scheme that provides efficient bandwidth utilization and robustness
against time dispersive channels. This paper deals with the basic system model
for OFDM based systems and with self-interference, or the corruption of desired
signal by itself in OFDM systems. A simple transceiver based on OFDM modulation
is presented. Important impairments in OFDM systems are mathematically analyzed
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703091</id><created>2007-03-16</created><authors><author><keyname>Landragin</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Denis</keyname><forenames>Alexandre</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Ricci</keyname><forenames>Annalisa</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Multimodal Meaning Representation for Generic Dialogue Systems
  Architectures</title><categories>cs.AI cs.MM</categories><proxy>ccsd hal-00137088</proxy><journal-ref>Proceedings of the Fourth International Conference on Language
  Resources and Evaluation (LREC 2004) (2004) 521-524</journal-ref><abstract>  An unified language for the communicative acts between agents is essential
for the design of multi-agents architectures. Whatever the type of interaction
(linguistic, multimodal, including particular aspects such as force feedback),
whatever the type of application (command dialogue, request dialogue, database
querying), the concepts are common and we need a generic meta-model. In order
to tend towards task-independent systems, we need to clarify the modules
parameterization procedures. In this paper, we focus on the characteristics of
a meta-model designed to represent meaning in linguistic and multimodal
applications. This meta-model is called MMIL for MultiModal Interface Language,
and has first been specified in the framework of the IST MIAMM European
project. What we want to test here is how relevant is MMIL for a completely
different context (a different task, a different interaction type, a different
linguistic domain). We detail the exploitation of MMIL in the framework of the
IST OZONE European project, and we draw the conclusions on the role of MMIL in
the parameterization of task-independent dialogue managers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703092</id><created>2007-03-19</created><authors><author><keyname>Basuchowdhuri</keyname><forenames>Partha</forenames></author></authors><title>Comparing BB84 and Authentication-Aided Kak's Three-Stage Quantum
  Protocol</title><categories>cs.CR</categories><comments>9 pages, 4 figures</comments><abstract>  This paper compares the popular quantum key distribution (QKD) protocol BB84
with the more recent Kak's three-stage protocol and the latter is shown to be
more secure. A theoretical representation of an authentication-aided version of
Kak's three-stage protocol is provided that makes it possible to deal with the
man-in-the-middle attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703093</id><created>2007-03-19</created><authors><author><keyname>Vershynin</keyname><forenames>Roman</forenames></author></authors><title>Some problems in asymptotic convex geometry and random matrices
  motivated by numerical algorithms</title><categories>cs.CG cs.DS cs.NA</categories><comments>12 pages, no figures. Based on the talk at the 2006 conference on
  Banach Spaces and their applications in analysis</comments><acm-class>G.1.6; G.1.3</acm-class><abstract>  The simplex method in Linear Programming motivates several problems of
asymptotic convex geometry. We discuss some conjectures and known results in
two related directions -- computing the size of projections of high dimensional
polytopes and estimating the norms of random matrices and their inverses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703094</id><created>2007-03-20</created><authors><author><keyname>Powell</keyname><forenames>Olivier</forenames></author><author><keyname>Nikolesteas</keyname><forenames>Sotiris</forenames></author></authors><title>Geographic Routing Around Obstacles in Wireless Sensor Networks</title><categories>cs.DC</categories><comments>37 pages, 23 figures</comments><abstract>  Geographic routing is becoming the protocol of choice for many sensor network
applications. The current state of the art is unsatisfactory: some algorithms
are very efficient, however they require a preliminary planarization of the
communication graph. Planarization induces overhead and is not realistic in
many scenarios. On the otherhand, georouting algorithms which do not rely on
planarization have fairly low success rates and either fail to route messages
around all but the simplest obstacles or have a high topology control overhead
(e.g. contour detection algorithms). To overcome these limitations, we propose
GRIC, the first lightweight and efficient on demand (i.e. all-to-all)
geographic routing algorithm which does not require planarization and has
almost 100% delivery rates (when no obstacles are added). Furthermore, the
excellent behavior of our algorithm is maintained even in the presence of large
convex obstacles. The case of hard concave obstacles is also studied; such
obstacles are hard instances for which performance diminishes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703095</id><created>2007-03-20</created><authors><author><keyname>Ma</keyname><forenames>Jian</forenames></author><author><keyname>Sun</keyname><forenames>Zengqi</forenames></author></authors><title>Copula Component Analysis</title><categories>cs.IR cs.AI</categories><abstract>  A framework named Copula Component Analysis (CCA) for blind source separation
is proposed as a generalization of Independent Component Analysis (ICA). It
differs from ICA which assumes independence of sources that the underlying
components may be dependent with certain structure which is represented by
Copula. By incorporating dependency structure, much accurate estimation can be
made in principle in the case that the assumption of independence is
invalidated. A two phrase inference method is introduced for CCA which is based
on the notion of multidimensional ICA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703096</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703096</id><created>2007-03-20</created><updated>2008-09-09</updated><authors><author><keyname>Donev</keyname><forenames>Aleksandar</forenames></author></authors><title>Asynchronous Event-Driven Particle Algorithms</title><categories>cs.OH</categories><comments>To appear in Simulation: Transactions of the Society for Modeling and
  Simulation International, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present, in a unifying way, the main components of three asynchronous
event-driven algorithms for simulating physical systems of interacting
particles. The first example, hard-particle molecular dynamics, is well-known.
We also present a recently-developed diffusion kinetic Monte Carlo algorithm,
as well as a novel stochastic molecular-dynamics algorithm that builds on the
Direct Simulation Monte Carlo. We explain how to effectively combine
asynchronous event-driven with classical time-driven or with synchronous
event-driven handling. Finally, we discuss some promises and challenges for
event-driven simulation of realistic physical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703097</id><created>2007-03-20</created><authors><author><keyname>Erdelyi</keyname><forenames>Gabor</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author><author><keyname>Spakowski</keyname><forenames>Holger</forenames></author></authors><title>On Approximating Optimal Weighted Lobbying, and Frequency of Correctness
  versus Average-Case Polynomial Time</title><categories>cs.GT cs.CC cs.MA</categories><report-no>URCS-TR-2007-914</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><abstract>  We investigate issues related to two hard problems related to voting, the
optimal weighted lobbying problem and the winner problem for Dodgson elections.
Regarding the former, Christian et al. [CFRS06] showed that optimal lobbying is
intractable in the sense of parameterized complexity. We provide an efficient
greedy algorithm that achieves a logarithmic approximation ratio for this
problem and even for a more general variant--optimal weighted lobbying. We
prove that essentially no better approximation ratio than ours can be proven
for this greedy algorithm.
  The problem of determining Dodgson winners is known to be complete for
parallel access to NP [HHR97]. Homan and Hemaspaandra [HH06] proposed an
efficient greedy heuristic for finding Dodgson winners with a guaranteed
frequency of success, and their heuristic is a ``frequently self-knowingly
correct algorithm.'' We prove that every distributional problem solvable in
polynomial time on the average with respect to the uniform distribution has a
frequently self-knowingly correct polynomial-time algorithm. Furthermore, we
study some features of probability weight of correctness with respect to
Procaccia and Rosenschein's junta distributions [PR07].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703098</id><created>2007-03-21</created><authors><author><keyname>Gubin</keyname><forenames>Sergey</forenames></author></authors><title>Polynomial time algorithm for 3-SAT. Examples of use</title><categories>cs.CC cs.DM cs.DS cs.LO</categories><comments>19 pages</comments><acm-class>F.2.0; G.2.1; G.2.2</acm-class><abstract>  The algorithm checks the propositional formulas for patterns of
unsatisfiability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703099</id><created>2007-03-21</created><authors><author><keyname>Altman</keyname><forenames>E.</forenames></author><author><keyname>Avrachenkov</keyname><forenames>K.</forenames></author><author><keyname>Bonneau</keyname><forenames>N.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author><author><keyname>El-Azouzi</keyname><forenames>R.</forenames></author><author><keyname>Menasche</keyname><forenames>D. Sadoc</forenames></author></authors><title>Constrained Cost-Coupled Stochastic Games with Independent State
  Processes</title><categories>cs.IT cs.GT math.IT</categories><comments>7 pages, submitted in september 2006 to Operations Research Letters</comments><abstract>  We consider a non-cooperative constrained stochastic games with N players
with the following special structure. With each player there is an associated
controlled Markov chain. The transition probabilities of the i-th Markov chain
depend only on the state and actions of controller i. The information structure
that we consider is such that each player knows the state of its own MDP and
its own actions. It does not know the states of, and the actions taken by other
players. Finally, each player wishes to minimize a time-average cost function,
and has constraints over other time-avrage cost functions. Both the cost that
is minimized as well as those defining the constraints depend on the state and
actions of all players. We study in this paper the existence of a Nash
equilirium. Examples in power control in wireless communications are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703100</id><created>2007-03-21</created><authors><author><keyname>Lin</keyname><forenames>Guolong</forenames></author><author><keyname>Rajaraman</keyname><forenames>Rajmohan</forenames></author></authors><title>Approximation Algorithms for Multiprocessor Scheduling under Uncertainty</title><categories>cs.DC cs.CC cs.DS</categories><comments>12 pages, 2 encapsulated postscript figures</comments><abstract>  Motivated by applications in grid computing and project management, we study
multiprocessor scheduling in scenarios where there is uncertainty in the
successful execution of jobs when assigned to processors. We consider the
problem of multiprocessor scheduling under uncertainty, in which we are given n
unit-time jobs and m machines, a directed acyclic graph C giving the
dependencies among the jobs, and for every job j and machine i, the probability
p_{ij} of the successful completion of job j when scheduled on machine i in any
given particular step. The goal of the problem is to find a schedule that
minimizes the expected makespan, that is, the expected completion time of all
the jobs.
  The problem of multiprocessor scheduling under uncertainty was introduced by
Malewicz and was shown to be NP-hard even when all the jobs are independent. In
this paper, we present polynomial-time approximation algorithms for the
problem, for special cases of the dag C. We obtain an O(log(n))-approximation
for the case of independent jobs, an
O(log(m)log(n)log(n+m)/loglog(n+m))-approximation when C is a collection of
disjoint chains, an O(log(m)log^2(n))-approximation when C is a collection of
directed out- or in-trees, and an
O(log(m)log^2(n)log(n+m)/loglog(n+m))-approximation when C is a directed
forest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703101</id><created>2007-03-21</created><authors><author><keyname>Breuel</keyname><forenames>Thomas M.</forenames></author></authors><title>A Note on Approximate Nearest Neighbor Methods</title><categories>cs.IR cs.CC cs.CV</categories><comments>The report was originally written in 2005 and does not reference
  information after that date</comments><abstract>  A number of authors have described randomized algorithms for solving the
epsilon-approximate nearest neighbor problem. In this note I point out that the
epsilon-approximate nearest neighbor property often fails to be a useful
approximation property, since epsilon-approximate solutions fail to satisfy the
necessary preconditions for using nearest neighbors for classification and
related tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703102</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703102</id><created>2007-03-21</created><updated>2007-04-11</updated><authors><author><keyname>Singh</keyname><forenames>Ashish Kumar</forenames></author><author><keyname>Aziz</keyname><forenames>Adnan</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Orshansky</keyname><forenames>Michael</forenames></author></authors><title>Generation of Efficient Codes for Realizing Boolean Functions in
  Nanotechnologies</title><categories>cs.IT cs.DM math.IT</categories><comments>6 pages, 5 Figures</comments><abstract>  We address the challenge of implementing reliable computation of Boolean
functions in future nanocircuit fabrics. Such fabrics are projected to have
very high defect rates. We overcome this limitation by using a combination of
cheap but unreliable nanodevices and reliable but expensive CMOS devices. In
our approach, defect tolerance is achieved through a novel coding of Boolean
functions; specifically, we exploit the dont cares of Boolean functions
encountered in multi-level Boolean logic networks for constructing better
codes. We show that compared to direct application of existing coding
techniques, the coding overhead in terms of extra bits can be reduced, on
average by 23%, and savings can go up to 34%. We demonstrate that by
incorporating efficient coding techniques more than a 40% average yield
improvement is possible in case of 1% and 0.1% defect rates. With 0.1% defect
density, the savings can be up to 90%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703103</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703103</id><created>2007-03-21</created><updated>2009-06-29</updated><authors><author><keyname>Tao</keyname><forenames>Jia</forenames></author><author><keyname>Gadia</keyname><forenames>Shashi</forenames></author><author><keyname>Cheng</keyname><forenames>Tsz Shing</forenames></author></authors><title>Concept of a Value in Multilevel Security Databases</title><categories>cs.DB</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703104</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703104</id><created>2007-03-22</created><updated>2007-05-02</updated><authors><author><keyname>Matsui</keyname><forenames>Hajime</forenames></author><author><keyname>Mita</keyname><forenames>Seiichi</forenames></author></authors><title>Encoding via Gr\&quot;obner bases and discrete Fourier transforms for several
  types of algebraic codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, To be presented at IEEE International Symposium
  on Information Theory 2007</comments><abstract>  We propose a novel encoding scheme for algebraic codes such as codes on
algebraic curves, multidimensional cyclic codes, and hyperbolic cascaded
Reed-Solomon codes and present numerical examples. We employ the recurrence
from the Gr\&quot;obner basis of the locator ideal for a set of rational points and
the two-dimensional inverse discrete Fourier transform. We generalize the
functioning of the generator polynomial for Reed-Solomon codes and develop
systematic encoding for various algebraic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703105</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703105</id><created>2007-03-22</created><updated>2008-12-10</updated><authors><author><keyname>Wu</keyname><forenames>Yingquan</forenames></author></authors><title>New List Decoding Algorithms for Reed-Solomon and BCH Codes</title><categories>cs.IT cs.CC math.IT</categories><journal-ref>IEEE Trans. Inform. Theory, Aug. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we devise a rational curve fitting algorithm and apply it to
the list decoding of Reed-Solomon and BCH codes. The proposed list decoding
algorithms exhibit the following significant properties. 1 The algorithm
corrects up to $n(1-\sqrt{1-D})$ errors for a (generalized) $(n, k, d=n-k+1)$
Reed-Solomon code, which matches the Johnson bound, where $D\eqdef \frac{d}{n}$
denotes the normalized minimum distance. In comparison with the Guruswami-Sudan
algorithm, which exhibits the same list correction capability, the former
requires multiplicity, which dictates the algorithmic complexity,
$O(n(1-\sqrt{1-D}))$, whereas the latter requires multiplicity $O(n^2(1-D))$.
With the up-to-date most efficient implementation, the former has complexity
$O(n^{6}(1-\sqrt{1-D})^{7/2})$, whereas the latter has complexity
$O(n^{10}(1-D)^4)$. 2. With the multiplicity set to one, the derivative list
correction capability precisely sits in between the conventional hard-decision
decoding and the optimal list decoding. Moreover, the number of candidate
codewords is upper bounded by a constant for a fixed code rate and thus, the
derivative algorithm exhibits quadratic complexity $O(n^2)$. 3. By utilizing
the unique properties of the Berlekamp algorithm, the algorithm corrects up to
$\frac{n}{2}(1-\sqrt{1-2D})$ errors for a narrow-sense $(n, k, d)$ binary BCH
code, which matches the Johnson bound for binary codes. The algorithmic
complexity is $O(n^{6}(1-\sqrt{1-2D})^7)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703106</id><created>2007-03-22</created><authors><author><keyname>Wang</keyname><forenames>Shengbao</forenames></author></authors><title>Practical Identity-Based Encryption (IBE) in Multiple PKG Environments
  and Its Applications</title><categories>cs.CR</categories><comments>A work in progress, any comment and suggestion will be highly
  appreciated by the author</comments><acm-class>K.6.5</acm-class><abstract>  In this paper, we present a new identity-based encryption (IBE) scheme using
bilinear pairings. Our IBE scheme enjoys the same \textsf{Key Extraction} and
\textsf{Decryption} algorithms with the famous IBE scheme of Boneh and Franklin
(BF-IBE for short), while differs from the latter in that it has modified
\textsf{Setup} and \textsf{Encryption} algorithms.
  Compared with BF-IBE, we show that ours are more practical in a multiple
private key generator (PKG) environment, mainly due to that the session secret
$g_{ID}$ could be pre-computed \emph{before} any interaction, and the sender
could encrypt a message using $g_{ID}$ prior to negotiating with the intended
recipient(s). As an application of our IBE scheme, we also derive an escrowed
ElGamal scheme which possesses certain good properties in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703107</id><created>2007-03-22</created><updated>2007-03-29</updated><authors><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh{&#xf4;}ne-Alpes</affiliation></author><author><keyname>Liogkas</keyname><forenames>Nikitas</forenames><affiliation>UCLA</affiliation></author><author><keyname>Kohler</keyname><forenames>Eddie</forenames><affiliation>UCLA</affiliation></author><author><keyname>Zhang</keyname><forenames>Lixia</forenames><affiliation>UCLA</affiliation></author></authors><title>Clustering and Sharing Incentives in BitTorrent Systems</title><categories>cs.NI</categories><comments>This article is the author version of a paper accepted at ACM
  SIGMETRICS'2007. In particular, this paper is different from the technical
  report inria-00112066, version 1 - 21 November 2006. The technical report
  inria-00112066, version 1 - 21 November 2006 is a extended version of this
  paper (same title and authors, but different content) Version 2 is the same
  content as version 1, but with a different class in order to match the camera
  ready format for SIGMETRICS</comments><proxy>ccsd inria-00137444</proxy><journal-ref>Dans ACM SIGMETRICS'2007 (2007)</journal-ref><abstract>  Peer-to-peer protocols play an increasingly instrumental role in Internet
content distribution. It is therefore important to gain a complete
understanding of how these protocols behave in practice and how their operating
parameters affect overall system performance. This paper presents the first
detailed experimental investigation of the peer selection strategy in the
popular BitTorrent protocol. By observing more than 40 nodes in instrumented
private torrents, we validate three protocol properties that, though believed
to hold, have not been previously demonstrated experimentally: the clustering
of similar-bandwidth peers, the effectiveness of BitTorrent's sharing
incentives, and the peers' high uplink utilization. In addition, we observe
that BitTorrent's modified choking algorithm in seed state provides uniform
service to all peers, and that an underprovisioned initial seed leads to
absence of peer clustering and less effective sharing incentives. Based on our
results, we provide guidelines for seed provisioning by content providers, and
discuss a tracker protocol extension that addresses an identified limitation of
the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703108</id><created>2007-03-22</created><authors><author><keyname>Dhar</keyname><forenames>Sourav</forenames></author><author><keyname>Bera</keyname><forenames>Rabindranath</forenames></author><author><keyname>Mal</keyname><forenames>K.</forenames></author></authors><title>Wireless Lan to Support Multimedia Communication Using Spread Spectrum
  Technology</title><categories>cs.NI</categories><comments>URSI 0ctober 22-29 2005, 4pages, 6 figures</comments><abstract>  Wireless LAN is currently enjoying rapid deployment in University
departments, business offices, hospitals and homes. It becomes an inexpensive
technology and allows multiple numbers of the households to simultaneously
access the internet while roaming about the house. In the present work, the
design and development of a wireless LAN is highlighted which utilizes direct
sequence spread spectrum (DSSS) technology at 900MHz RF carrier frequency in
its physical layer. This provides enormous security in the physical layer and
hence it is very difficult to hack or jam the network. The installation cost is
also less due to the use of 900 MHz RF carrier frequency..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703109</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703109</id><created>2007-03-22</created><updated>2007-05-07</updated><authors><author><keyname>Kaser</keyname><forenames>Owen</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Tag-Cloud Drawing: Algorithms for Cloud Visualization</title><categories>cs.DS</categories><comments>To appear in proceedings of Tagging and Metadata for Social
  Information Organization (WWW 2007)</comments><abstract>  Tag clouds provide an aggregate of tag-usage statistics. They are typically
sent as in-line HTML to browsers. However, display mechanisms suited for
ordinary text are not ideal for tags, because font sizes may vary widely on a
line. As well, the typical layout does not account for relationships that may
be known between tags. This paper presents models and algorithms to improve the
display of tag clouds that consist of in-line HTML, as well as algorithms that
use nested tables to achieve a more general 2-dimensional layout in which tag
relationships are considered. The first algorithms leverage prior work in
typesetting and rectangle packing, whereas the second group of algorithms
leverage prior work in Electronic Design Automation. Experiments show our
algorithms can be efficiently implemented and perform well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703110</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703110</id><created>2007-03-22</created><updated>2013-06-06</updated><authors><author><keyname>Blasiak</keyname><forenames>Jonah</forenames></author><author><keyname>Mulmuley</keyname><forenames>Ketan D.</forenames></author><author><keyname>Sohoni</keyname><forenames>Milind</forenames></author></authors><title>Geometric Complexity Theory IV: nonstandard quantum group for the
  Kronecker problem</title><categories>cs.CC</categories><comments>145 pages. This is the final journal version to appear in the Memoirs
  of the American Mathematical Society</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kronecker coefficient g_{\lambda \mu \nu} is the multiplicity of the
GL(V)\times GL(W)-irreducible V_\lambda \otimes W_\mu in the restriction of the
GL(X)-irreducible X_\nu via the natural map GL(V)\times GL(W) \to GL(V \otimes
W), where V, W are \mathbb{C}-vector spaces and X = V \otimes W. A fundamental
open problem in algebraic combinatorics is to find a positive combinatorial
formula for these coefficients.
  We construct two quantum objects for this problem, which we call the
nonstandard quantum group and nonstandard Hecke algebra. We show that the
nonstandard quantum group has a compact real form and its representations are
completely reducible, that the nonstandard Hecke algebra is semisimple, and
that they satisfy an analog of quantum Schur-Weyl duality.
  Using these nonstandard objects as a guide, we follow the approach of Adsul,
Sohoni, and Subrahmanyam to construct, in the case dim(V) = dim(W) =2, a
representation \check{X}_\nu of the nonstandard quantum group that specializes
to Res_{GL(V) \times GL(W)} X_\nu at q=1. We then define a global crystal basis
+HNSTC(\nu) of \check{X}_\nu that solves the two-row Kronecker problem: the
number of highest weight elements of +HNSTC(\nu) of weight (\lambda,\mu) is the
Kronecker coefficient g_{\lambda \mu \nu}. We go on to develop the beginnings
of a graphical calculus for this basis, along the lines of the U_q(\sl_2)
graphical calculus, and use this to organize the crystal components of
+HNSTC(\nu) into eight families. This yields a fairly simple, explicit and
positive formula for two-row Kronecker coefficients, generalizing a formula of
Brown, van Willigenburg, and Zabrocki. As a byproduct of the approach, we also
obtain a rule for the decomposition of Res_{GL_2 \times GL_2 \rtimes \S_2}
X_\nu into irreducibles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703111</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703111</id><created>2007-03-22</created><authors><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Hou</keyname><forenames>Y. Thomas</forenames></author></authors><title>Maximum Weighted Sum Rate of Multi-Antenna Broadcast Channels</title><categories>cs.IT math.IT</categories><abstract>  Recently, researchers showed that dirty paper coding (DPC) is the optimal
transmission strategy for multiple-input multiple-output broadcast channels
(MIMO-BC). In this paper, we study how to determine the maximum weighted sum of
DPC rates through solving the maximum weighted sum rate problem of the dual
MIMO multiple access channel (MIMO-MAC) with a sum power constraint. We first
simplify the maximum weighted sum rate problem such that enumerating all
possible decoding orders in the dual MIMO-MAC is unnecessary. We then design an
efficient algorithm based on conjugate gradient projection (CGP) to solve the
maximum weighted sum rate problem. Our proposed CGP method utilizes the
powerful concept of Hessian conjugacy. We also develop a rigorous algorithm to
solve the projection problem. We show that CGP enjoys provable convergence,
nice scalability, and great efficiency for large MIMO-BC systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703112</id><created>2007-03-22</created><authors><author><keyname>Ramesh</keyname><forenames>Bharath</forenames></author><author><keyname>Varadarajan</keyname><forenames>Srinidhi</forenames></author></authors><title>User-level DSM System for Modern High-Performance Interconnection
  Networks</title><categories>cs.DC</categories><comments>6 pages, 5 figures</comments><acm-class>C.2.4; D.1.3; D.4.2</acm-class><abstract>  In this paper, we introduce a new user-level DSM system which has the ability
to directly interact with underlying interconnection networks. The DSM system
provides the application programmer a flexible API to program parallel
applications either using shared memory semantics over physically distributed
memory or to use an efficient remote memory demand paging technique. We also
introduce a new time slice based memory consistency protocol which is used by
the DSM system. We present preliminary results from our implementation on a
small Opteron Linux cluster interconnected over Myrinet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703113</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703113</id><created>2007-03-23</created><authors><author><keyname>Aouiche</keyname><forenames>Kamel</forenames></author><author><keyname>Darmont</keyname><forenames>Jerome</forenames></author><author><keyname>Boussaid</keyname><forenames>Omar</forenames></author><author><keyname>Bentayeb</keyname><forenames>Fadila</forenames></author></authors><title>Automatic Selection of Bitmap Join Indexes in Data Warehouses</title><categories>cs.DB</categories><abstract>  The queries defined on data warehouses are complex and use several join
operations that induce an expensive computational cost. This cost becomes even
more prohibitive when queries access very large volumes of data. To improve
response time, data warehouse administrators generally use indexing techniques
such as star join indexes or bitmap join indexes. This task is nevertheless
complex and fastidious. Our solution lies in the field of data warehouse
auto-administration. In this framework, we propose an automatic index selection
strategy. We exploit a data mining technique ; more precisely frequent itemset
mining, in order to determine a set of candidate indexes from a given workload.
Then, we propose several cost models allowing to create an index configuration
composed by the indexes providing the best profit. These models evaluate the
cost of accessing data using bitmap join indexes, and the cost of updating and
storing these indexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703114</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703114</id><created>2007-03-23</created><authors><author><keyname>Aouiche</keyname><forenames>Kamel</forenames></author><author><keyname>Jouve</keyname><forenames>Pierre-Emmanuel</forenames></author><author><keyname>Darmont</keyname><forenames>Jerome</forenames></author></authors><title>Clustering-Based Materialized View Selection in Data Warehouses</title><categories>cs.DB</categories><abstract>  Materialized view selection is a non-trivial task. Hence, its complexity must
be reduced. A judicious choice of views must be cost-driven and influenced by
the workload experienced by the system. In this paper, we propose a framework
for materialized view selection that exploits a data mining technique
(clustering), in order to determine clusters of similar queries. We also
propose a view merging algorithm that builds a set of candidate views, as well
as a greedy process for selecting a set of views to materialize. This selection
is based on cost models that evaluate the cost of accessing data using views
and the cost of storing these views. To validate our strategy, we executed a
workload of decision-support queries on a test data warehouse, with and without
using our strategy. Our experimental results demonstrate its efficiency, even
when storage space is limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703115</identifier>
 <datestamp>2007-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703115</id><created>2007-03-23</created><updated>2007-06-18</updated><authors><author><keyname>Kryssanov</keyname><forenames>Victor V.</forenames></author><author><keyname>Kuleshov</keyname><forenames>Evgeny L.</forenames></author><author><keyname>Rinaldo</keyname><forenames>Frank J.</forenames></author><author><keyname>Ogawa</keyname><forenames>Hitoshi</forenames></author></authors><title>We cite as we communicate: A communication model for the citation
  process</title><categories>cs.DL cs.CY physics.data-an</categories><comments>12 pages, 4 figures in the new version. A preprint originally
  completed in March, 2007; new version with a slightly expanded discussion and
  new figures added</comments><abstract>  Building on ideas from linguistics, psychology, and social sciences about the
possible mechanisms of human decision-making, we propose a novel theoretical
framework for the citation analysis. Given the existing trend to investigate
citation statistics in the context of various forms of power and Zipfian laws,
we show that the popular models of citation have poor predictive ability and
can hardly provide for an adequate explanation of the observed behavior of the
empirical data. An alternative model is then derived, using the apparatus of
statistical mechanics. The model is applied to approximate the citation
frequencies of scientific articles from two large collections, and it
demonstrates a predictive potential much superior to the one of any of the
citation models known to the authors from the literature. Some analytical
properties of the developed model are discussed, and conclusions are drawn.
Directions for future work are also given at the paper's end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703116</identifier>
 <datestamp>2007-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703116</id><created>2007-03-23</created><updated>2007-06-28</updated><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames></author><author><keyname>Hill</keyname><forenames>Patricia M.</forenames></author><author><keyname>Pescetti</keyname><forenames>Andrea</forenames></author><author><keyname>Zaffanella</keyname><forenames>Enea</forenames></author></authors><title>On the Design of Generic Static Analyzers for Modern Imperative
  Languages</title><categories>cs.PL cs.LO</categories><comments>72 pages</comments><acm-class>F.3.1; F.3.2</acm-class><abstract>  The design and implementation of precise static analyzers for significant
fragments of modern imperative languages like C, C++, Java and Python is a
challenging problem. In this paper, we consider a core imperative language that
has several features found in mainstream languages such as those including
recursive functions, run-time system and user-defined exceptions, and a
realistic data and memory model. For this language we provide a concrete
semantics --characterizing both finite and infinite computations-- and a
generic abstract semantics that we prove sound with respect to the concrete
one. We say the abstract semantics is generic since it is designed to be
completely parametric on the analysis domains: in particular, it provides
support for \emph{relational} domains (i.e., abstract domains that can capture
the relationships between different data objects). We also sketch how the
proposed methodology can be extended to accommodate a larger language that
includes pointers, compound data objects and non-structured control flow
mechanisms. The approach, which is based on structured, big-step
$\mathrm{G}^\infty\mathrm{SOS}$ operational semantics and on abstract
interpretation, is modular in that the overall static analyzer is naturally
partitioned into components with clearly identified responsibilities and
interfaces, something that greatly simplifies both the proof of correctness and
the implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703117</id><created>2007-03-23</created><authors><author><keyname>Laredo</keyname><forenames>J. L. J.</forenames></author><author><keyname>Eiben</keyname><forenames>E. A.</forenames></author><author><keyname>Schoenauer</keyname><forenames>M.</forenames></author><author><keyname>Castillo</keyname><forenames>P. A.</forenames></author><author><keyname>Mora</keyname><forenames>A. M.</forenames></author><author><keyname>Fernandez</keyname><forenames>F.</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author></authors><title>Self-adaptive Gossip Policies for Distributed Population-based
  Algorithms</title><categories>cs.DC</categories><comments>Submitted to Europar 2007</comments><abstract>  Gossipping has demonstrate to be an efficient mechanism for spreading
information among P2P networks. Within the context of P2P computing, we propose
the so-called Evolvable Agent Model for distributed population-based algorithms
which uses gossipping as communication policy, and represents every individual
as a self-scheduled single thread. The model avoids obsolete nodes in the
population by defining a self-adaptive refresh rate which depends on the
latency and bandwidth of the network. Such a mechanism balances the migration
rate to the congestion of the links pursuing global population coherence. We
perform an experimental evaluation of this model on a real parallel system and
observe how solution quality and algorithm speed scale with the number of
processors with this seamless approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703118</identifier>
 <datestamp>2015-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703118</id><created>2007-03-23</created><updated>2007-03-24</updated><authors><author><keyname>de Vries</keyname><forenames>Andreas</forenames></author></authors><title>Mathematical model of interest matchmaking in electronic social networks</title><categories>cs.CY cs.AI</categories><comments>6 pages, 3 figures</comments><acm-class>I.2.4; H.3.5; J.4; G.2.3; C.2.4</acm-class><journal-ref>Applied Mathematics 5 (16) 2014, 2619-2629</journal-ref><doi>10.4236/am.2014.516250</doi><abstract>  The problem of matchmaking in electronic social networks is formulated as an
optimization problem. In particular, a function measuring the matching degree
of fields of interest of a search profile with those of an advertising profile
is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703119</id><created>2007-03-23</created><updated>2007-03-26</updated><authors><author><keyname>Daitch</keyname><forenames>Samuel I.</forenames></author><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author></authors><title>Support-Graph Preconditioners for 2-Dimensional Trusses</title><categories>cs.NA</categories><abstract>  We use support theory, in particular the fretsaw extensions of Shklarski and
Toledo, to design preconditioners for the stiffness matrices of 2-dimensional
truss structures that are stiffly connected. Provided that all the lengths of
the trusses are within constant factors of each other, that the angles at the
corners of the triangles are bounded away from 0 and $\pi$, and that the
elastic moduli and cross-sectional areas of all the truss elements are within
constant factors of each other, our preconditioners allow us to solve linear
equations in the stiffness matrices to accuracy $\epsilon$ in time $O (n^{5/4}
(\log^{2}n \log \log n)^{3/4} \log (1/\epsilon))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703120</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703120</id><created>2007-03-23</created><authors><author><keyname>Palaiyanur</keyname><forenames>Hari</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Sequential decoding for lossless streaming source coding with side
  information</title><categories>cs.IT math.IT</categories><comments>42 pages, Submitted to IT Transactions</comments><abstract>  The problem of lossless fixed-rate streaming coding of discrete memoryless
sources with side information at the decoder is studied. A random time-varying
tree-code is used to sequentially bin strings and a Stack Algorithm with a
variable bias uses the side information to give a delay-universal coding system
for lossless source coding with side information. The scheme is shown to give
exponentially decaying probability of error with delay, with exponent equal to
Gallager's random coding exponent for sources with side information. The mean
of the random variable of computation for the stack decoder is bounded, and
conditions on the bias are given to guarantee a finite $\rho^{th}$ moment for
$0 \leq \rho \leq 1$.
  Further, the problem is also studied in the case where there is a discrete
memoryless channel between encoder and decoder. The same scheme is slightly
modified to give a joint-source channel encoder and Stack Algorithm-based
sequential decoder using side information. Again, by a suitable choice of bias,
the probability of error decays exponentially with delay and the random
variable of computation has a finite mean. Simulation results for several
examples are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703121</identifier>
 <datestamp>2008-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703121</id><created>2007-03-23</created><updated>2007-09-14</updated><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Chyzak</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Lecerf</keyname><forenames>Gr&#xe9;goire</forenames><affiliation>LM-Versailles</affiliation></author><author><keyname>Schost</keyname><forenames>&#xc9;ric</forenames></author></authors><title>Differential Equations for Algebraic Functions</title><categories>cs.SC math.CA</categories><proxy>ccsd inria-00138206</proxy><journal-ref>ISSAC'07, pages 25--32, ACM Press, 2007.</journal-ref><doi>10.1145/1277548.1277553</doi><abstract>  It is classical that univariate algebraic functions satisfy linear
differential equations with polynomial coefficients. Linear recurrences follow
for the coefficients of their power series expansions. We show that the linear
differential equation of minimal order has coefficients whose degree is cubic
in the degree of the function. We also show that there exists a linear
differential equation of order linear in the degree whose coefficients are only
of quadratic degree. Furthermore, we prove the existence of recurrences of
order and degree close to optimal. We study the complexity of computing these
differential equations and recurrences. We deduce a fast algorithm for the
expansion of algebraic series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703122</id><created>2007-03-23</created><authors><author><keyname>Kr&#xe1;lovi&#x10d;</keyname><forenames>Rastislav</forenames></author><author><keyname>Kr&#xe1;lovi&#x10d;</keyname><forenames>Richard</forenames></author></authors><title>Rapid Almost-Complete Broadcasting in Faulty Networks</title><categories>cs.DC</categories><comments>Conference: Sirocco 2007</comments><acm-class>C.2.1</acm-class><abstract>  This paper studies the problem of broadcasting in synchronous point-to-point
networks, where one initiator owns a piece of information that has to be
transmitted to all other vertices as fast as possible. The model of fractional
dynamic faults with threshold is considered: in every step either a fixed
number $T$, or a fraction $\alpha$, of sent messages can be lost depending on
which quantity is larger.
  As the main result we show that in complete graphs and hypercubes it is
possible to inform all but a constant number of vertices, exhibiting only a
logarithmic slowdown, i.e. in time $O(D\log n)$ where $D$ is the diameter of
the network and $n$ is the number of vertices.
  Moreover, for complete graphs under some additional conditions (sense of
direction, or $\alpha&lt;0.55$) the remaining constant number of vertices can be
informed in the same time, i.e. $O(\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703123</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703123</id><created>2007-03-23</created><authors><author><keyname>Taghavi</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Adaptive Methods for Linear Programming Decoding</title><categories>cs.IT math.IT</categories><comments>22 pages, 8 figures. Submitted to IEEE Transactions on Information
  Theory</comments><abstract>  Detectability of failures of linear programming (LP) decoding and the
potential for improvement by adding new constraints motivate the use of an
adaptive approach in selecting the constraints for the underlying LP problem.
In this paper, we make a first step in studying this method, and show that it
can significantly reduce the complexity of the problem, which was originally
exponential in the maximum check-node degree. We further show that adaptively
adding new constraints, e.g. by combining parity checks, can provide large
gains in the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703124</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703124</id><created>2007-03-26</created><authors><author><keyname>Liou</keyname><forenames>Cheng-Yuan</forenames></author><author><keyname>Wu</keyname><forenames>Tai-Hei</forenames></author><author><keyname>Lee</keyname><forenames>Chia-Ying</forenames></author></authors><title>Modelling Complexity in Musical Rhythm</title><categories>cs.AI</categories><comments>21 pages, 13 figures, 2 tables</comments><journal-ref>Complexity 15(4) (2010) 19~30 final form at
  http://www3.interscience.wiley.com/cgi-bin/fulltext/123191810/PDFSTART</journal-ref><abstract>  This paper constructs a tree structure for the music rhythm using the
L-system. It models the structure as an automata and derives its complexity. It
also solves the complexity for the L-system. This complexity can resolve the
similarity between trees. This complexity serves as a measure of psychological
complexity for rhythms. It resolves the music complexity of various
compositions including the Mozart effect K488.
  Keyword: music perception, psychological complexity, rhythm, L-system,
automata, temporal associative memory, inverse problem, rewriting rule,
bracketed string, tree similarity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703125</identifier>
 <datestamp>2007-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703125</id><created>2007-03-24</created><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>Intrinsic dimension of a dataset: what properties does one expect?</title><categories>cs.LG</categories><comments>6 pages, 6 figures, 1 table, latex with IEEE macros, final submission
  to Proceedings of the 22nd IJCNN (Orlando, FL, August 12-17, 2007)</comments><journal-ref>Proceedings of the 20th International Joint Conference on Neural
  Networks (IJCNN'2007), Orlando, Florida (Aug. 12--17, 2007), pp. 1775--1780.</journal-ref><abstract>  We propose an axiomatic approach to the concept of an intrinsic dimension of
a dataset, based on a viewpoint of geometry of high-dimensional structures. Our
first axiom postulates that high values of dimension be indicative of the
presence of the curse of dimensionality (in a certain precise mathematical
sense). The second axiom requires the dimension to depend smoothly on a
distance between datasets (so that the dimension of a dataset and that of an
approximating principal manifold would be close to each other). The third axiom
is a normalization condition: the dimension of the Euclidean $n$-sphere $\s^n$
is $\Theta(n)$. We give an example of a dimension function satisfying our
axioms, even though it is in general computationally unfeasible, and discuss a
computationally cheap function satisfying most but not all of our axioms (the
``intrinsic dimensionality'' of Ch\'avez et al.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703126</id><created>2007-03-25</created><updated>2007-04-09</updated><authors><author><keyname>Tucci</keyname><forenames>Michele</forenames></author></authors><title>Evolutionary Socioeconomics: Notes on the Computer Simulation according
  to the de Finetti - Simon Principia</title><categories>cs.CY</categories><comments>PDF, 29 pages, 3 graphs; minor changes</comments><acm-class>K.4.0; K.6.0; I.6.0</acm-class><abstract>  The present note includes explanatory comments about the synergic interaction
within the sphere of the socioeconomic analysis between the two following
theoretical frameworks. (I). The Darwinian evolutionary model. (II). The
computer simulation in accordance with the principia established by Bruno de
Finetti and Herbert Simon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703127</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703127</id><created>2007-03-25</created><authors><author><keyname>Zhdanov</keyname><forenames>Alexander</forenames></author></authors><title>Isochronous Data Transmission With Rates Close to Channel Capacity</title><categories>cs.IT math.IT</categories><abstract>  The existing ARQ schemes (including a hybrid ARQ) have a throughput depending
on packet error probability. In this paper we describe a strategy for delay
tolerant applications which provide a constant throughput until the algorithm
robustness criterion is not failed. The algorithm robustness criterion is
applied to find the optimum size of the retransmission block in the assumption
of the small changes of coding rate within the rate compatible codes family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703128</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703128</id><created>2007-03-25</created><updated>2007-04-08</updated><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Physarum machine: Implementation of Kolmogorov-Uspensky machine in
  biological substrat</title><categories>cs.AR cs.CC</categories><comments>First presented at Los Alamos &quot;Unconventional Computation 2007&quot;
  conference, Santa Fe, NM, 20-23 March 2007</comments><acm-class>F.1.1</acm-class><journal-ref>Paralllel Processing Letters Vol. 17, No. 4 (December 2007) pp.
  455-467</journal-ref><doi>10.1142/S0129626407003150</doi><abstract>  We implement Kolmogorov-Uspensky machine on a plasmodium of true slime mold
{\em Physarum polycephalum}. We provide experimental findings on realization of
the machine instructions, illustrate basic operations, and elements of
programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703129</identifier>
 <datestamp>2008-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703129</id><created>2007-03-26</created><updated>2008-03-15</updated><authors><author><keyname>Geraci</keyname><forenames>Joseph</forenames></author><author><keyname>Van Bussel</keyname><forenames>Frank</forenames></author></authors><title>A theorem on the quantum evaluation of Weight Enumerators for a certain
  class of Cyclic Codes with a note on Cyclotomic cosets</title><categories>cs.IT math.IT quant-ph</categories><abstract>  This note is a stripped down version of a published paper on the Potts
partition function, where we concentrate solely on the linear coding aspect of
our approach. It is meant as a resource for people interested in coding theory
but who do not know much of the mathematics involved and how quantum
computation may provide a speed up in the computation of a very important
quantity in coding theory. We provide a theorem on the quantum computation of
the Weight Enumerator polynomial for a restricted family of cyclic codes. The
complexity of obtaining an exact evaluation is $O(k^{2s}(\log q)^{2})$, where
$s$ is a parameter which determines the class of cyclic codes in question, $q$
is the characteristic of the finite field over which the code is defined, and
$k$ is the dimension of the code. We also provide an overview of cyclotomic
cosets and discuss applications including how they can be used to speed up the
computation of the weight enumerator polynomial (which is related to the Potts
partition function). We also give an algorithm which returns the coset leaders
and the size of each coset from the list $\{0,1,2,...,N-1\}$, whose time
complexity is soft-O(N). This algorithm uses standard techniques but we include
it as a resource for students. Note that cyclotomic cosets do not improve the
asymptotic complexity of the computation of weight enumerators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703130</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703130</id><created>2007-03-26</created><authors><author><keyname>Doukari</keyname><forenames>Omar</forenames><affiliation>LSIS</affiliation></author><author><keyname>Jeansoulin</keyname><forenames>Robert</forenames><affiliation>IGM-LabInfo</affiliation></author></authors><title>Space-contained conflict revision, for geographic information</title><categories>cs.AI</categories><comments>14 pages</comments><proxy>ccsd hal-00138447</proxy><journal-ref>Proc. of 10th AGILE International Conference on Geographic
  Information Science, AGILE 2007. (07/05/2007) 1-14</journal-ref><abstract>  Using qualitative reasoning with geographic information, contrarily, for
instance, with robotics, looks not only fastidious (i.e.: encoding knowledge
Propositional Logics PL), but appears to be computational complex, and not
tractable at all, most of the time. However, knowledge fusion or revision, is a
common operation performed when users merge several different data sets in a
unique decision making process, without much support. Introducing logics would
be a great improvement, and we propose in this paper, means for deciding -a
priori- if one application can benefit from a complete revision, under only the
assumption of a conjecture that we name the &quot;containment conjecture&quot;, which
limits the size of the minimal conflicts to revise. We demonstrate that this
conjecture brings us the interesting computational property of performing a
not-provable but global, revision, made of many local revisions, at a tractable
size. We illustrate this approach on an application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703131</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703131</id><created>2007-03-26</created><authors><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>Open Access Scientometrics and the UK Research Assessment Exercise</title><categories>cs.IR cs.DL</categories><abstract>  Scientometric predictors of research performance need to be validated by
showing that they have a high correlation with the external criterion they are
trying to predict. The UK Research Assessment Exercise (RAE), together with the
growing movement toward making the full-texts of research articles freely
available on the web -- offer a unique opportunity to test and validate a
wealth of old and new scientometric predictors, through multiple regression
analysis: Publications, journal impact factors, citations, co-citations,
citation chronometrics (age, growth, latency to peak, decay rate),
hub/authority scores, h-index, prior funding, student counts, co-authorship
scores, endogamy/exogamy, textual proximity, download/co-downloads and their
chronometrics, etc. can all be tested and validated jointly, discipline by
discipline, against their RAE panel rankings in the forthcoming parallel
panel-based and metric RAE in 2008. The weights of each predictor can be
calibrated to maximize the joint correlation with the rankings. Open Access
Scientometrics will provide powerful new means of navigating, evaluating,
predicting and analyzing the growing Open Access database, as well as powerful
incentives for making it grow faster. ~
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703132</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703132</id><created>2007-03-27</created><authors><author><keyname>Peshkin</keyname><forenames>Leonid</forenames></author></authors><title>Structure induction by lossless graph compression</title><categories>cs.DS cs.IT cs.LG math.IT</categories><comments>10 pages, 7 figures, 2 tables published in Proceedings of the Data
  Compression Conference, 2007</comments><acm-class>I.2.6; G.2.2; E.1; E.4; F.4.2; G.2.3; I.3.5; I.4.2; I.5.3; J.3</acm-class><journal-ref>In proceedings of the Data Compression Conference, 2007, pp 53-62,
  published by the IEEE Computer Society Press</journal-ref><abstract>  This work is motivated by the necessity to automate the discovery of
structure in vast and evergrowing collection of relational data commonly
represented as graphs, for example genomic networks. A novel algorithm, dubbed
Graphitour, for structure induction by lossless graph compression is presented
and illustrated by a clear and broadly known case of nested structure in a DNA
molecule. This work extends to graphs some well established approaches to
grammatical inference previously applied only to strings. The bottom-up graph
compression problem is related to the maximum cardinality (non-bipartite)
maximum cardinality matching problem. The algorithm accepts a variety of graph
types including directed graphs and graphs with labeled nodes and arcs. The
resulting structure could be used for representation and classification of
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703133</id><created>2007-03-27</created><authors><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Goldberg</keyname><forenames>Paul W.</forenames></author></authors><title>Computing Good Nash Equilibria in Graphical Games</title><categories>cs.GT cs.DS cs.MA</categories><comments>25 pages. Short version appears in ACM EC'07</comments><abstract>  This paper addresses the problem of fair equilibrium selection in graphical
games. Our approach is based on the data structure called the {\em best
response policy}, which was proposed by Kearns et al. \cite{kls} as a way to
represent all Nash equilibria of a graphical game. In \cite{egg}, it was shown
that the best response policy has polynomial size as long as the underlying
graph is a path. In this paper, we show that if the underlying graph is a
bounded-degree tree and the best response policy has polynomial size then there
is an efficient algorithm which constructs a Nash equilibrium that guarantees
certain payoffs to all participants. Another attractive solution concept is a
Nash equilibrium that maximizes the social welfare. We show that, while exactly
computing the latter is infeasible (we prove that solving this problem may
involve algebraic numbers of an arbitrarily high degree), there exists an FPTAS
for finding such an equilibrium as long as the best response policy has
polynomial size. These two algorithms can be combined to produce Nash
equilibria that satisfy various fairness criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703134</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703134</id><created>2007-03-27</created><updated>2008-01-07</updated><authors><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Alfonseca</keyname><forenames>Manuel</forenames></author><author><keyname>Ortega</keyname><forenames>Alfonso</forenames></author></authors><title>Automatic Generation of Benchmarks for Plagiarism Detection Tools using
  Grammatical Evolution</title><categories>cs.NE cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><acm-class>J.1; I.2.2; D.2.8</acm-class><abstract>  This paper has been withdrawn by the authors due to a major rewriting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703135</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703135</id><created>2007-03-27</created><authors><author><keyname>Savova</keyname><forenames>Virginia</forenames></author><author><keyname>Peshkin</keyname><forenames>Leonid</forenames></author></authors><title>Dependency Parsing with Dynamic Bayesian Network</title><categories>cs.CL cs.AI</categories><comments>6 pages</comments><acm-class>I.2.7; I.2.1; G.3; H.3.1</acm-class><journal-ref>In proceedings of American Association for Artificial Intelligence
  AAAI 2005</journal-ref><abstract>  Exact parsing with finite state automata is deemed inappropriate because of
the unbounded non-locality languages overwhelmingly exhibit. We propose a way
to structure the parsing task in order to make it amenable to local
classification methods. This allows us to build a Dynamic Bayesian Network
which uncovers the syntactic dependency structure of English sentences.
Experiments with the Wall Street Journal demonstrate that the model
successfully learns from labeled data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703136</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703136</id><created>2007-03-28</created><updated>2011-02-14</updated><authors><author><keyname>Freire</keyname><forenames>Manuel</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>del Rosal</keyname><forenames>Emilio</forenames></author></authors><title>Uncovering Plagiarism Networks</title><categories>cs.IT cs.SI math.IT</categories><comments>19 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plagiarism detection in educational programming assignments is still a
problematic issue in terms of resource waste, ethical controversy, legal risks,
and technical complexity. This paper presents AC, a modular plagiarism
detection system. The design is portable across platforms and assignment
formats and provides easy extraction into the internal assignment
representation. Multiple similarity measures have been incorporated, both
existing and newly-developed. Statistical analysis and several graphical
visualizations aid in the interpretation of analysis results. The system has
been evaluated with a survey that encompasses several academic semesters of use
at the authors' institution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703137</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703137</id><created>2007-03-27</created><authors><author><keyname>Sudarsan</keyname><forenames>Rajesh</forenames></author><author><keyname>Ribbens</keyname><forenames>Calvin J.</forenames></author></authors><title>ReSHAPE: A Framework for Dynamic Resizing and Scheduling of Homogeneous
  Applications in a Parallel Environment</title><categories>cs.DC</categories><comments>15 pages, 10 figures, 5 tables Submitted to International Conference
  on Parallel Processing (ICPP'07)</comments><acm-class>C.1.4</acm-class><abstract>  Applications in science and engineering often require huge computational
resources for solving problems within a reasonable time frame. Parallel
supercomputers provide the computational infrastructure for solving such
problems. A traditional application scheduler running on a parallel cluster
only supports static scheduling where the number of processors allocated to an
application remains fixed throughout the lifetime of execution of the job. Due
to the unpredictability in job arrival times and varying resource requirements,
static scheduling can result in idle system resources thereby decreasing the
overall system throughput. In this paper we present a prototype framework
called ReSHAPE, which supports dynamic resizing of parallel MPI applications
executed on distributed memory platforms. The framework includes a scheduler
that supports resizing of applications, an API to enable applications to
interact with the scheduler, and a library that makes resizing viable.
Applications executed using the ReSHAPE scheduler framework can expand to take
advantage of additional free processors or can shrink to accommodate a high
priority application, without getting suspended. In our research, we have
mainly focused on structured applications that have two-dimensional data arrays
distributed across a two-dimensional processor grid. The resize library
includes algorithms for processor selection and processor mapping. Experimental
results show that the ReSHAPE framework can improve individual job turn-around
time and overall system throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703138</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703138</id><created>2007-03-28</created><authors><author><keyname>Peshkin</keyname><forenames>Leonid</forenames></author><author><keyname>Savova</keyname><forenames>Virginia</forenames></author></authors><title>Reinforcement Learning for Adaptive Routing</title><categories>cs.LG cs.AI cs.NI</categories><acm-class>C.2.1; C.2.2; C.2.4; C.2.6; F.1.1; I.2.6; I.2.8; I.2.9</acm-class><journal-ref>In Proceedings of the Intnl Joint Conf on Neural Networks (IJCNN),
  2002</journal-ref><abstract>  Reinforcement learning means learning a policy--a mapping of observations
into actions--based on feedback from the environment. The learning can be
viewed as browsing a set of policies while evaluating them by trial through
interaction with the environment. We present an application of gradient ascent
algorithm for reinforcement learning to a complex domain of packet routing in
network communication and compare the performance of this algorithm to other
routing methods on a benchmark problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703139</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703139</id><created>2007-03-28</created><updated>2007-12-13</updated><authors><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author><author><keyname>Anelli</keyname><forenames>Pascal</forenames></author></authors><title>TCP throughput guarantee in the DiffServ Assured Forwarding service:
  what about the results?</title><categories>cs.NI</categories><abstract>  Since the proposition of Quality of Service architectures by the IETF, the
interaction between TCP and the QoS services has been intensively studied. This
paper proposes to look forward to the results obtained in terms of TCP
throughput guarantee in the DiffServ Assured Forwarding (DiffServ/AF) service
and to present an overview of the different proposals to solve the problem. It
has been demonstrated that the standardized IETF DiffServ conditioners such as
the token bucket color marker and the time sliding window color maker were not
good TCP traffic descriptors. Starting with this point, several propositions
have been made and most of them presents new marking schemes in order to
replace or improve the traditional token bucket color marker. The main problem
is that TCP congestion control is not designed to work with the AF service.
Indeed, both mechanisms are antagonists. TCP has the property to share in a
fair manner the bottleneck bandwidth between flows while DiffServ network
provides a level of service controllable and predictable. In this paper, we
build a classification of all the propositions made during these last years and
compare them. As a result, we will see that these conditioning schemes can be
separated in three sets of action level and that the conditioning at the
network edge level is the most accepted one. We conclude that the problem is
still unsolved and that TCP, conditioned or not conditioned, remains
inappropriate to the DiffServ/AF service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703140</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703140</id><created>2007-03-28</created><authors><author><keyname>Beauquier</keyname><forenames>Dani&#xe8;le</forenames><affiliation>LACL</affiliation></author><author><keyname>Gauche</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LACL</affiliation></author></authors><title>How to Guarantee Secrecy for Cryptographic Protocols</title><categories>cs.CR</categories><comments>19 pages</comments><proxy>ccsd hal-00138766</proxy><journal-ref>Rapport interne (03/2007)</journal-ref><abstract>  In this paper we propose a general definition of secrecy for cryptographic
protocols in the Dolev-Yao model. We give a sufficient condition ensuring
secrecy for protocols where rules have encryption depth at most two, that is
satisfied by almost all practical protocols. The only allowed primitives in the
class of protocols we consider are pairing and encryption with atomic keys.
Moreover, we describe an algorithm of practical interest which transforms a
cryptographic protocol into a secure one from the point of view of secrecy,
without changing its original goal with respect to secrecy of nonces and keys,
provided the protocol satisfies some conditions. These conditions are not very
restrictive and are satisfied for most practical protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703141</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703141</id><created>2007-03-28</created><updated>2007-03-29</updated><authors><author><keyname>Hamada</keyname><forenames>Mitsuru</forenames></author></authors><title>Constructive Conjugate Codes for Quantum Error Correction and
  Cryptography</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure. Ver.2: statement in Theorem 7.1 was revised to a
  more general one, which the proof (unchanged except a couple of lines after
  Eq.(11)) had really implied. A corollary to this theorem was added.
  Annotative parts on achievable rates (mainly after the proof of Theorem 7.1)
  were revised</comments><abstract>  A conjugate code pair is defined as a pair of linear codes either of which
contains the dual of the other. A conjugate code pair represents the essential
structure of the corresponding Calderbank-Shor-Steane (CSS) quantum
error-correcting code. It is known that conjugate code pairs are applicable to
quantum cryptography. In this work, a polynomial construction of conjugate code
pairs is presented. The constructed pairs achieve the highest known achievable
rate on additive channels, and are decodable with algorithms of polynomial
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703142</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703142</id><created>2007-03-28</created><authors><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Conti</keyname><forenames>Andrea</forenames></author><author><keyname>Tralli</keyname><forenames>Velio</forenames></author></authors><title>Pragmatic Space-Time Trellis Codes for Block Fading Channels</title><categories>cs.IT math.IT</categories><abstract>  A pragmatic approach for the construction of space-time codes over block
fading channels is investigated. The approach consists in using common
convolutional encoders and Viterbi decoders with suitable generators and rates,
thus greatly simplifying the implementation of space-time codes. For the design
of pragmatic space-time codes a methodology is proposed and applied, based on
the extension of the concept of generalized transfer function for convolutional
codes over block fading channels. Our search algorithm produces the
convolutional encoder generators of pragmatic space-time codes for various
number of states, number of antennas and fading rate. Finally it is shown that,
for the investigated cases, the performance of pragmatic space-time codes is
better than that of previously known space-time codes, confirming that they are
a valuable choice in terms of both implementation complexity and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703143</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703143</id><created>2007-03-28</created><authors><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>How much feedback is required in MIMO Broadcast Channels?</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Inform. Theory</comments><abstract>  In this paper, a downlink communication system, in which a Base Station (BS)
equipped with M antennas communicates with N users each equipped with K receive
antennas ($K \leq M$), is considered. It is assumed that the receivers have
perfect Channel State Information (CSI), while the BS only knows the partial
CSI, provided by the receivers via feedback. The minimum amount of feedback
required at the BS, to achieve the maximum sum-rate capacity in the asymptotic
case of $N \to \infty$ and different ranges of SNR is studied. In the fixed and
low SNR regimes, it is demonstrated that to achieve the maximum sum-rate, an
infinite amount of feedback is required. Moreover, in order to reduce the gap
to the optimum sum-rate to zero, in the fixed SNR regime, the minimum amount of
feedback scales as $\theta(\ln \ln \ln N)$, which is achievable by the Random
Beam-Forming scheme proposed in [14]. In the high SNR regime, two cases are
considered; in the case of $K &lt; M$, it is proved that the minimum amount of
feedback bits to reduce the gap between the achievable sum-rate and the maximum
sum-rate to zero grows logaritmically with SNR, which is achievable by the
&quot;Generalized Random Beam-Forming&quot; scheme, proposed in [18]. In the case of $K =
M$, it is shown that by using the Random Beam-Forming scheme and the total
amount of feedback not growing with SNR, the maximum sum-rate capacity is
achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703144</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703144</id><created>2007-03-28</created><authors><author><keyname>Sadrabadi</keyname><forenames>Mehdi Ansari</forenames></author><author><keyname>Maddah-Ali</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On The Capacity Of Time-Varying Channels With Periodic Feedback</title><categories>cs.IT math.IT</categories><comments>9 pages, 1 figure, Journal</comments><abstract>  The capacity of time-varying channels with periodic feedback at the
transmitter is evaluated. It is assumed that the channel state information is
perfectly known at the receiver and is fed back to the transmitter at the
regular time-intervals. The system capacity is investigated in two cases: i)
finite state Markov channel, and ii) additive white Gaussian noise channel with
time-correlated fading. In the first case, it is shown that the capacity is
achievable by multiplexing multiple codebooks across the channel. In the second
case, the channel capacity and the optimal adaptive coding is obtained. It is
shown that the optimal adaptation can be achieved by a single Gaussian
codebook, while adaptively allocating the total power based on the side
information at the transmitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703145</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703145</id><created>2007-03-28</created><updated>2007-04-03</updated><authors><author><keyname>Murthy</keyname><forenames>Sandeep</forenames></author></authors><title>The Simultaneous Triple Product Property and Group-theoretic Results for
  the Exponent of Matrix Multiplication</title><categories>cs.DS cs.CC math.GR</categories><comments>14 pages</comments><acm-class>F.2.1</acm-class><abstract>  We describe certain special consequences of certain elementary methods from
group theory for studying the algebraic complexity of matrix multiplication, as
developed by H. Cohn, C. Umans et. al. in 2003 and 2005. The measure of
complexity here is the exponent of matrix multiplication, a real parameter
between 2 and 3, which has been conjectured to be 2. More specifically, a
finite group may simultaneously &quot;realize&quot; several independent matrix
multiplications via its regular algebra if it has a family of triples of
&quot;index&quot; subsets which satisfy the so-called simultaneous triple product
property (STPP), in which case the complexity of these several multiplications
does not exceed the rank (complexity) of the algebra. This leads to bounds for
the exponent in terms of the size of the group and the sizes of its STPP
triples, as well as the dimensions of its distinct irreducible representations.
Wreath products of Abelian with symmetric groups appear especially important,
in this regard, and we give an example of such a group which shows that the
exponent is less than 2.84, and could be possibly be as small as 2.02 depending
on the number of simultaneous matrix multiplications it realizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703146</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703146</id><created>2007-03-29</created><updated>2012-05-07</updated><authors><author><keyname>Gubin</keyname><forenames>Sergey</forenames></author></authors><title>A Polynomial Time Algorithm for SAT</title><categories>cs.CC cs.DM cs.DS cs.LO</categories><comments>Update, 30 pages</comments><report-no>MCCCC 23,24,25</report-no><acm-class>F.2.0; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Article presents the compatibility matrix method and illustrates it with the
application to P vs NP problem. The method is a generalization of descriptive
geometry: in the method, we draft problems and solve them utilizing the image
creation technique. The method reveals: P = NP = PSPACE
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703147</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703147</id><created>2007-03-29</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>The finite tiling problem is undecidable in the hyperbolic plane</title><categories>cs.CG cs.DM</categories><acm-class>F.2.2; G.2.1</acm-class><journal-ref>The Finite Tiling Problem Is Undecidable in the Hyperbolic Plane,
  International Journal of Foundations of Computer Science, 19(4), (2008),
  971-982</journal-ref><doi>10.1142/S0129054108006078</doi><abstract>  In this paper, we consider the finite tiling problem which was proved
undecidable in the Euclidean plane by Jarkko Kari in 1994. Here, we prove that
the same problem for the hyperbolic plane is also undecidable.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="100000" completeListSize="102538">1122234|101001</resumptionToken>
</ListRecords>
</OAI-PMH>
