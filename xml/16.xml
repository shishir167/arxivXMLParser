<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:45:28Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|15001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3835</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3835</id><created>2010-07-22</created><authors><author><keyname>Lopes</keyname><forenames>Nuno P.</forenames></author><author><keyname>Navarro</keyname><forenames>Juan A.</forenames></author><author><keyname>Rybalchenko</keyname><forenames>Andrey</forenames></author><author><keyname>Singh</keyname><forenames>Atul</forenames></author></authors><title>Applying Prolog to Develop Distributed Systems</title><categories>cs.PL cs.DC</categories><journal-ref>Theory and Practice of Logic Programming, 26th Int'l. Conference
  on Logic Programming (ICLP'10) Special Issue, 10(4-6):691-707, July 2010</journal-ref><doi>10.1017/S1471068410000360</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Development of distributed systems is a difficult task. Declarative
programming techniques hold a promising potential for effectively supporting
programmer in this challenge. While Datalog-based languages have been actively
explored for programming distributed systems, Prolog received relatively little
attention in this application area so far. In this paper we present a
Prolog-based programming system, called DAHL, for the declarative development
of distributed systems. DAHL extends Prolog with an event-driven control
mechanism and built-in networking procedures. Our experimental evaluation using
a distributed hash-table data structure, a protocol for achieving Byzantine
fault tolerance, and a distributed software model checker - all implemented in
DAHL - indicates the viability of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3836</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3836</id><created>2010-07-22</created><authors><author><keyname>Kurgansky</keyname><forenames>Oleksiy</forenames></author></authors><title>A state of a dynamic computational structure distributed in an
  environment: a model and its corollaries</title><categories>cs.FL cs.DC</categories><comments>11 pages, 5 figures</comments><msc-class>68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently there is great interest in computational models consisting of
underlying regular computational environments, and built on them distributed
computational structures. Examples of such models are cellular automata,
spatial computation and space-time crystallography. For any computational model
it is natural to define a functional equivalence of different but related
computational structures. In the finite automata theory an example of such
equivalence is automata homomorphism and, in particular, automata isomorphism.
If we continue to stick to the finite automata theory, a fundamental question
arise, what a state of a distributed computational structure is. This work is
devoted to particular solution of the issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3858</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3858</id><created>2010-07-22</created><authors><author><keyname>Sneyers</keyname><forenames>Jon</forenames></author><author><keyname>Meert</keyname><forenames>Wannes</forenames></author><author><keyname>Vennekens</keyname><forenames>Joost</forenames></author><author><keyname>Kameya</keyname><forenames>Yoshitaka</forenames></author><author><keyname>Sato</keyname><forenames>Taisuke</forenames></author></authors><title>CHR(PRISM)-based Probabilistic Logic Learning</title><categories>cs.PL cs.AI cs.LG cs.LO</categories><acm-class>D.1.6; D.3.1; F.3.2; G.3</acm-class><journal-ref>Theory and Practice of Logic Programming, 10(4-6), 433-447, 2010</journal-ref><doi>10.1017/S1471068410000207</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  PRISM is an extension of Prolog with probabilistic predicates and built-in
support for expectation-maximization learning. Constraint Handling Rules (CHR)
is a high-level programming language based on multi-headed multiset rewrite
rules.
  In this paper, we introduce a new probabilistic logic formalism, called
CHRiSM, based on a combination of CHR and PRISM. It can be used for high-level
rapid prototyping of complex statistical models by means of &quot;chance rules&quot;. The
underlying PRISM system can then be used for several probabilistic inference
tasks, including probability computation and parameter learning. We define the
CHRiSM language in terms of syntax and operational semantics, and illustrate it
with examples. We define the notion of ambiguous programs and define a
distribution semantics for unambiguous programs. Next, we describe an
implementation of CHRiSM, based on CHR(PRISM). We discuss the relation between
CHRiSM and other probabilistic logic programming languages, in particular PCHR.
Finally we identify potential application domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3862</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3862</id><created>2010-07-22</created><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Chen</keyname><forenames>Michael Z. Q.</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author></authors><title>Breaking an image encryption algorithm based on chaos</title><categories>cs.CR</categories><comments>9 pages, 4 figures</comments><doi>10.1142/S0218127411029641</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a chaos-based image encryption algorithm called MCKBA (Modified
Chaotic-Key Based Algorithm) was proposed. This paper analyzes the security of
MCKBA and finds that it can be broken with a differential attack, which
requires only four chosen plain-images. Performance of the attack is verified
by experimental results. In addition, some defects of MCKBA, including
insensitivity with respect to changes of plain-image/secret key, are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3878</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3878</id><created>2010-07-22</created><updated>2011-04-12</updated><authors><author><keyname>Danicic</keyname><forenames>Sebastian</forenames></author><author><keyname>Hierons</keyname><forenames>Robert M</forenames></author><author><keyname>Laurence</keyname><forenames>Michael R</forenames></author></authors><title>Complexity of Data Dependence problems for Program Schemas with
  Concurrency</title><categories>cs.CC cs.PL</categories><comments>21 pages, 6 figures (all included in cncurr.acm.tex source file)</comments><acm-class>D.3.3; D.3.4; F.2; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of deciding whether one point in a program is data dependent upon
another is fundamental to program analysis and has been widely studied. In this
paper we consider this problem at the abstraction level of program schemas in
which computations occur in the Herbrand domain of terms and predicate symbols,
which represent arbitrary predicate functions, are allowed. Given a vertex l in
the flowchart of a schema S having only equality (variable copying) assignments
and variables v,w, we show that it is PSPACE-hard to decide whether there
exists an execution of a program defined by S in which v holds the initial
value of w at at least one occurrence of l on the path of execution, with
membership in PSPACE holding provided there is a constant upper bound on the
arity of any predicate in S. We also consider the `dual' problem in which v is
required to hold the initial value of w at every occurrence of l, for which the
analogous results hold. Additionally, the former problem for programs with
non-deterministic branching (in effect, free schemas) in which assignments with
functions are allowed is proved to be polynomial-time decidable provided a
constant upper bound is placed upon the number of occurrences of the
concurrency operator in the schemas being considered. This result is promising
since many concurrent systems have a relatively small number of threads
(concurrent processes), especially when compared with the number of statements
they have.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3881</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3881</id><created>2010-07-22</created><updated>2010-10-16</updated><authors><author><keyname>Kolev</keyname><forenames>Vasil</forenames></author></authors><title>Orthogonal multifilters image processing of astronomical images from
  scanned photographic plates</title><categories>cs.CV cs.NA</categories><comments>6 pages, The ACM proceedings of CompSysTech 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper orthogonal multifilters for astronomical image processing are
presented. We obtained new orthogonal multifilters based on the orthogonal
wavelet of Haar and Daubechies. Recently, multiwavelets have been introduced as
a more powerful multiscale analysis tool. It adds several degrees of freedom in
multifilter design and makes it possible to have several useful properties such
as symmetry, orthogonality, short support, and a higher number of vanishing
moments simultaneously. Multifilter decomposition of scanned photographic
plates with astronomical images is made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3884</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3884</id><created>2010-07-22</created><updated>2010-07-29</updated><authors><author><keyname>de Campos</keyname><forenames>Cassio P.</forenames></author></authors><title>New Results for the MAP Problem in Bayesian Networks</title><categories>cs.AI cs.CC stat.ML</categories><comments>A couple of typos were fixed, as well as the notation in part of
  section 4, which was misleading. Theoretical and empirical results have not
  changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new results for the (partial) maximum a posteriori (MAP)
problem in Bayesian networks, which is the problem of querying the most
probable state configuration of some of the network variables given evidence.
First, it is demonstrated that the problem remains hard even in networks with
very simple topology, such as binary polytrees and simple trees (including the
Naive Bayes structure). Such proofs extend previous complexity results for the
problem. Inapproximability results are also derived in the case of trees if the
number of states per variable is not bounded. Although the problem is shown to
be hard and inapproximable even in very simple scenarios, a new exact algorithm
is described that is empirically fast in networks of bounded treewidth and
bounded number of states per variable. The same algorithm is used as basis of a
Fully Polynomial Time Approximation Scheme for MAP under such assumptions.
Approximation schemes were generally thought to be impossible for this problem,
but we show otherwise for classes of networks that are important in practice.
The algorithms are extensively tested using some well-known networks as well as
random generated cases to show their effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3886</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3886</id><created>2010-07-22</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Talgam-Cohen</keyname><forenames>Inbal</forenames></author></authors><title>A Direct Reduction from k-Player to 2-Player Approximate Nash
  Equilibrium</title><categories>cs.GT</categories><comments>21 pages</comments><doi>10.1007/978-3-642-16170-4_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a direct reduction from k-player games to 2-player games that
preserves approximate Nash equilibrium. Previously, the computational
equivalence of computing approximate Nash equilibrium in k-player and 2-player
games was established via an indirect reduction. This included a sequence of
works defining the complexity class PPAD, identifying complete problems for
this class, showing that computing approximate Nash equilibrium for k-player
games is in PPAD, and reducing a PPAD-complete problem to computing approximate
Nash equilibrium for 2-player games. Our direct reduction makes no use of the
concept of PPAD, thus eliminating some of the difficulties involved in
following the known indirect reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3896</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3896</id><created>2010-07-22</created><authors><author><keyname>Bross</keyname><forenames>Shraga I.</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>The State-Dependent Multiple-Access Channel with States Available at a
  Cribbing Encoder</title><categories>cs.IT math.IT</categories><comments>This is a longer version of a submission to the 2010 IEEE 26-th
  Convention of Electrical and Electronics Engineers in Israel (IEEEI 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-user discrete memoryless state-dependent multiple-access channel
(MAC) models a scenario in which two encoders transmit independent messages to
a single receiver via a MAC whose channel law is governed by the pair of
encoders' inputs and by an i.i.d. state random variable. In the cooperative
state-dependent MAC model it is further assumed that Message 1 is shared by
both encoders whereas Message 2 is known only to Encoder 2 - the cognitive
transmitter. The capacity of the cooperative state-dependent MAC where the
realization of the state sequence is known non-causally to the cognitive
encoder has been derived by Somekh-Baruch et. al.
  In this work we dispense of the assumption that Message 1 is shared a-priori
by both encoders. Instead, we study the case in which Encoder 2 cribs causally
from Encoder 1. We determine the capacity region for both, the case where
Encoder 2 cribs strictly causal and the case where Encoder 2 cribs causally
from Encoder 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3906</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3906</id><created>2010-07-22</created><authors><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>A colorful origin for the genetic code: Information theory, statistical
  mechanics and the emergence of molecular codes</title><categories>q-bio.GN cond-mat.stat-mech cs.IT math.IT physics.bio-ph q-bio.MN q-bio.PE</categories><comments>In press. Keywords: Molecular codes; Origin of the genetic code;
  Biological information channels; Error-load; Fitness; Rate-distortion theory;
  Origin of life</comments><journal-ref>Physics of Life Reviews,Corrected Proof, Available online 4 June
  2010, ISSN 1571-0645, DOI: 10.1016/j.plrev.2010.06.002.
  (http://www.sciencedirect.com/science/article/B75DC-507CRVN-2/2/6d92dd84761b902a2989798c7226b0c0)</journal-ref><doi>10.1016/j.plrev.2010.06.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The genetic code maps the sixty-four nucleotide triplets (codons) to twenty
amino-acids. While the biochemical details of this code were unraveled long
ago, its origin is still obscure. We review information-theoretic approaches to
the problem of the code's origin and discuss the results of a recent work that
treats the code in terms of an evolving, error-prone information channel. Our
model - which utilizes the rate-distortion theory of noisy communication
channels - suggests that the genetic code originated as a result of the
interplay of the three conflicting evolutionary forces: the needs for diverse
amino-acids, for error-tolerance and for minimal cost of resources. The
description of the code as an information channel allows us to mathematically
identify the fitness of the code and locate its emergence at a second-order
phase transition when the mapping of codons to amino-acids becomes nonrandom.
The noise in the channel brings about an error-graph, in which edges connect
codons that are likely to be confused. The emergence of the code is governed by
the topology of the error-graph, which determines the lowest modes of the
graph-Laplacian and is related to the map coloring problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3926</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3926</id><created>2010-07-21</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author></authors><title>Ear Identification by Fusion of Segmented Slice Regions using Invariant
  Features: An Experimental Manifold with Dual Fusion Approach</title><categories>cs.CV</categories><comments>12 pages, 3 figures</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper proposes a robust ear identification system which is developed by
fusing SIFT features of color segmented slice regions of an ear. The proposed
ear identification method makes use of Gaussian mixture model (GMM) to build
ear model with mixture of Gaussian using vector quantization algorithm and K-L
divergence is applied to the GMM framework for recording the color similarity
in the specified ranges by comparing color similarity between a pair of
reference ear and probe ear. SIFT features are then detected and extracted from
each color slice region as a part of invariant feature extraction. The
extracted keypoints are then fused separately by the two fusion approaches,
namely concatenation and the Dempster-Shafer theory. Finally, the fusion
approaches generate two independent augmented feature vectors which are used
for identification of individuals separately. The proposed identification
technique is tested on IIT Kanpur ear database of 400 individuals and is found
to achieve 98.25% accuracy for identification while top 5 matched criteria is
set for each subject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3934</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3934</id><created>2010-07-22</created><updated>2010-10-27</updated><authors><author><keyname>Bajovic</keyname><forenames>Dragana</forenames></author><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author><author><keyname>Sinopoli</keyname><forenames>Bruno</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Distributed Detection over Random Networks: Large Deviations Analysis</title><categories>cs.IT math.IT</categories><comments>see under arXiv:1010.5163v1 [cs.IT]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.3961</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.3961</id><created>2010-07-22</created><authors><author><keyname>de Guzman</keyname><forenames>Pablo Chico</forenames></author><author><keyname>Carro</keyname><forenames>Manuel</forenames></author><author><keyname>Warren</keyname><forenames>David S.</forenames></author></authors><title>Swapping Evaluation: A Memory-Scalable Solution for Answer-On-Demand
  Tabling</title><categories>cs.PL</categories><comments>16 pages, 5 figures, published in TPLP 2010</comments><journal-ref>Swapping Evaluation in TPLP, volume 10, number 4-6, year 2010,
  pages 401-416</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the differences among the various approaches to suspension-based
tabled evaluation is the scheduling strategy. The two most popular strategies
are local and batched evaluation.
  The former collects all the solutions to a tabled predicate before making any
one of them available outside the tabled computation. The latter returns
answers one by one before computing them all, which in principle is better if
only one answer (or a subset of the answers) is desired.
  Batched evaluation is closer to SLD evaluation in that it computes solutions
lazily as they are demanded, but it may need arbitrarily more memory than local
evaluation, which is able to reclaim memory sooner. Some programs which in
practice can be executed under the local strategy quickly run out of memory
under batched evaluation. This has led to the general adoption of local
evaluation at the expense of the more depth-first batched strategy.
  In this paper we study the reasons for the high memory consumption of batched
evaluation and propose a new scheduling strategy which we have termed swapping
evaluation. Swapping evaluation also returns answers one by one before
completing a tabled call, but its memory usage can be orders of magnitude less
than batched evaluation. An experimental implementation in the XSB system shows
that swapping evaluation is a feasible memory-scalable strategy that need not
compromise execution speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4002</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4002</id><created>2010-07-22</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Continuum Percolation in the Intrinsically Secure Communications Graph</title><categories>cs.IT cs.NI math.IT</categories><comments>Accepted in the IEEE International Symposium on Information Theory
  and its Applications (ISITA'10), Taichung, Taiwan, Oct. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intrinsically secure communications graph (iS-graph) is a random graph
which captures the connections that can be securely established over a
large-scale network, in the presence of eavesdroppers. It is based on
principles of information-theoretic security, widely accepted as the strictest
notion of security. In this paper, we are interested in characterizing the
global properties of the iS-graph in terms of percolation on the infinite
plane. We prove the existence of a phase transition in the Poisson iS-graph,
whereby an unbounded component of securely connected nodes suddenly arises as
we increase the density of legitimate nodes. Our work shows that long-range
communication in a wireless network is still possible when a secrecy constraint
is present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4011</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4011</id><created>2010-07-22</created><authors><author><keyname>Guillemot</keyname><forenames>Sylvain</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Perez</keyname><forenames>Anthony</forenames></author></authors><title>On the (non-)existence of polynomial kernels for Pl-free edge
  modification problems</title><categories>cs.DS</categories><doi>10.1007/978-3-642-17493-3_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph G = (V,E) and an integer k, an edge modification problem for a
graph property P consists in deciding whether there exists a set of edges F of
size at most k such that the graph H = (V,E \vartriangle F) satisfies the
property P. In the P edge-completion problem, the set F of edges is constrained
to be disjoint from E; in the P edge-deletion problem, F is a subset of E; no
constraint is imposed on F in the P edge-edition problem. A number of
optimization problems can be expressed in terms of graph modification problems
which have been extensively studied in the context of parameterized complexity.
When parameterized by the size k of the edge set F, it has been proved that if
P is an hereditary property characterized by a finite set of forbidden induced
subgraphs, then the three P edge-modification problems are FPT. It was then
natural to ask whether these problems also admit a polynomial size kernel.
Using recent lower bound techniques, Kratsch and Wahlstrom answered this
question negatively. However, the problem remains open on many natural graph
classes characterized by forbidden induced subgraphs. Kratsch and Wahlstrom
asked whether the result holds when the forbidden subgraphs are paths or cycles
and pointed out that the problem is already open in the case of P4-free graphs
(i.e. cographs). This paper provides positive and negative results in that line
of research. We prove that parameterized cograph edge modification problems
have cubic vertex kernels whereas polynomial kernels are unlikely to exist for
the Pl-free and Cl-free edge-deletion problems for large enough l.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4018</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4018</id><created>2010-07-22</created><updated>2010-09-02</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames><affiliation>IST Austria</affiliation></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames><affiliation>CNRS France</affiliation></author><author><keyname>Henzinger</keyname><forenames>Thomas A</forenames><affiliation>IST Austria and EPFL Switzerland</affiliation></author></authors><title>Expressiveness and Closure Properties for Quantitative Languages</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (August 30,
  2010) lmcs:1084</journal-ref><doi>10.2168/LMCS-6(3:10)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted automata are nondeterministic automata with numerical weights on
transitions. They can define quantitative languages~$L$ that assign to each
word~$w$ a real number~$L(w)$. In the case of infinite words, the value of a
run is naturally computed as the maximum, limsup, liminf, limit-average, or
discounted-sum of the transition weights. The value of a word $w$ is the
supremum of the values of the runs over $w$. We study expressiveness and
closure questions about these quantitative languages. We first show that the
set of words with value greater than a threshold can be non-$\omega$-regular
for deterministic limit-average and discounted-sum automata, while this set is
always $\omega$-regular when the threshold is isolated (i.e., some neighborhood
around the threshold contains no word). In the latter case, we prove that the
$\omega$-regular language is robust against small perturbations of the
transition weights. We next consider automata with transition weights Weighted
automata are nondeterministic automata with numerical weights ontransitions.
They can define quantitative languages~$L$ that assign to eachword~$w$ a real
number~$L(w)$. In the case of infinite words, the value of arun is naturally
computed as the maximum, limsup, liminf, limit-average, ordiscounted-sum of the
transition weights. The value of a word $w$ is thesupremum of the values of the
runs over $w$. We study expressiveness andclosure questions about these
quantitative languages. We first show that the set of words with value greater
than a threshold canbe non-$\omega$-regular for deterministic limit-average and
discounted-sumautomata, while this set is always $\omega$-regular when the
threshold isisolated (i.e., some neighborhood around the threshold contains no
word). Inthe latter case, we prove that the $\omega$-regular language is robust
againstsmall perturbations of the transition weights. We next consider automata
with transition weights $0$ or $1$ and show thatthey are as expressive as
general weighted automata in the limit-average case,but not in the
discounted-sum case. Third, for quantitative languages $L_1$ and~$L_2$, we
consider the operations$\max(L_1,L_2)$, $\min(L_1,L_2)$, and $1-L_1$, which
generalize the booleanoperations on languages, as well as the sum $L_1 + L_2$.
We establish theclosure properties of all classes of quantitative languages
with respect tothese four operations.$ or $ and show that they are as
expressive as general weighted automata in the limit-average case, but not in
the discounted-sum case. Third, for quantitative languages $L_1$ and~$L_2$, we
consider the operations $\max(L_1,L_2)$, $\min(L_1,L_2)$, and -L_1$, which
generalize the boolean operations on languages, as well as the sum $L_1 + L_2$.
We establish the closure properties of all classes of quantitative languages
with respect to these four operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4028</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4028</id><created>2010-07-22</created><authors><author><keyname>Alviano</keyname><forenames>Mario</forenames></author><author><keyname>Faber</keyname><forenames>Wolfgang</forenames></author><author><keyname>Leone</keyname><forenames>Nicola</forenames></author></authors><title>Disjunctive ASP with Functions: Decidable Queries and Effective
  Computation</title><categories>cs.LO</categories><comments>16 pages, 1 figure</comments><acm-class>F.4.1; I.2.4</acm-class><journal-ref>Theory and Practice of Logic Programming, 10(4-6): 497-512, 2010</journal-ref><doi>10.1017/S1471068410000244</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Querying over disjunctive ASP with functions is a highly undecidable task in
general. In this paper we focus on disjunctive logic programs with stratified
negation and functions under the stable model semantics (ASP^{fs}). We show
that query answering in this setting is decidable, if the query is finitely
recursive (ASP^{fs}_{fr}). Our proof yields also an effective method for query
evaluation. It is done by extending the magic set technique to ASP^{fs}_{fr}.
We show that the magic-set rewritten program is query equivalent to the
original one (under both brave and cautious reasoning). Moreover, we prove that
the rewritten program is also finitely ground, implying that it is decidable.
Importantly, finitely ground programs are evaluable using existing ASP solvers,
making the class of ASP^{fs}_{fr} queries usable in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4040</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4040</id><created>2010-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yisong</forenames></author><author><keyname>You</keyname><forenames>Jia-Huai</forenames></author><author><keyname>Yuan</keyname><forenames>Li Yan</forenames></author><author><keyname>Shen</keyname><forenames>Yi-Dong</forenames></author></authors><title>Loop Formulas for Description Logic Programs</title><categories>cs.AI cs.LO</categories><comments>29 pages, 1 figures (in pdf), a short version appeared in ICLP'10</comments><journal-ref>yisong Wang, Jia-Huai You, Li-Yan Yuan, Yi-Dong Shen: Loop
  formulas for description logic programs. TPLP 10(4-6): 531-545 (2010)</journal-ref><doi>10.1017/S1471068410000268</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Description Logic Programs (dl-programs) proposed by Eiter et al. constitute
an elegant yet powerful formalism for the integration of answer set programming
with description logics, for the Semantic Web. In this paper, we generalize the
notions of completion and loop formulas of logic programs to description logic
programs and show that the answer sets of a dl-program can be precisely
captured by the models of its completion and loop formulas. Furthermore, we
propose a new, alternative semantics for dl-programs, called the {\em canonical
answer set semantics}, which is defined by the models of completion that
satisfy what are called canonical loop formulas. A desirable property of
canonical answer sets is that they are free of circular justifications. Some
properties of canonical answer sets are also explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4053</identifier>
 <datestamp>2014-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4053</id><created>2010-07-23</created><authors><author><keyname>Enke</keyname><forenames>Harry</forenames><affiliation>AIP</affiliation></author><author><keyname>Steinmetz</keyname><forenames>Matthias</forenames><affiliation>AIP</affiliation></author><author><keyname>Adorf</keyname><forenames>Hans-Martin</forenames><affiliation>MPA</affiliation></author><author><keyname>Beck-Ratzka</keyname><forenames>Alexander</forenames><affiliation>AEI</affiliation></author><author><keyname>Breitling</keyname><forenames>Frank</forenames><affiliation>AIP</affiliation></author><author><keyname>Bruesemeister</keyname><forenames>Thomas</forenames><affiliation>ZAH</affiliation></author><author><keyname>Carlson</keyname><forenames>Arthur</forenames><affiliation>MPE</affiliation></author><author><keyname>Ensslin</keyname><forenames>Torsten</forenames><affiliation>MPA</affiliation></author><author><keyname>Hoegqvist</keyname><forenames>Mikael</forenames><affiliation>ZIB</affiliation></author><author><keyname>Nickelt</keyname><forenames>Iliya</forenames><affiliation>AIP</affiliation></author><author><keyname>Radke</keyname><forenames>Thomas</forenames><affiliation>AEI</affiliation></author><author><keyname>Reinefeld</keyname><forenames>Alexander</forenames><affiliation>ZIB</affiliation></author><author><keyname>Reiser</keyname><forenames>Angelika</forenames><affiliation>TUM</affiliation></author><author><keyname>Scholl</keyname><forenames>Tobias</forenames><affiliation>TUM</affiliation></author><author><keyname>Spurzem</keyname><forenames>Rainer</forenames><affiliation>ZAH, NAOC</affiliation></author><author><keyname>Steinacker</keyname><forenames>Juergen</forenames><affiliation>ZAH</affiliation></author><author><keyname>Voges</keyname><forenames>Wolfgang</forenames><affiliation>MPE</affiliation></author><author><keyname>Wambsganss</keyname><forenames>Joachim</forenames><affiliation>ZAH</affiliation></author><author><keyname>White</keyname><forenames>Steve</forenames><affiliation>AIP</affiliation></author></authors><title>AstroGrid-D: Grid Technology for Astronomical Science</title><categories>cs.DC astro-ph.IM cs.DB cs.NI</categories><comments>14 pages, 12 figures Subjects: data analysis, image processing,
  robotic telescopes, simulations, grid. Accepted for publication in New
  Astronomy</comments><journal-ref>New Astron.16:79-93,2011</journal-ref><doi>10.1016/j.newast.2010.07.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present status and results of AstroGrid-D, a joint effort of
astrophysicists and computer scientists to employ grid technology for
scientific applications. AstroGrid-D provides access to a network of
distributed machines with a set of commands as well as software interfaces. It
allows simple use of computer and storage facilities and to schedule or monitor
compute tasks and data management. It is based on the Globus Toolkit middleware
(GT4). Chapter 1 describes the context which led to the demand for advanced
software solutions in Astrophysics, and we state the goals of the project. We
then present characteristic astrophysical applications that have been
implemented on AstroGrid-D in chapter 2. We describe simulations of different
complexity, compute-intensive calculations running on multiple sites, and
advanced applications for specific scientific purposes, such as a connection to
robotic telescopes. We can show from these examples how grid execution improves
e.g. the scientific workflow. Chapter 3 explains the software tools and
services that we adapted or newly developed. Section 3.1 is focused on the
administrative aspects of the infrastructure, to manage users and monitor
activity. Section 3.2 characterises the central components of our architecture:
The AstroGrid-D information service to collect and store metadata, a file
management system, the data management system, and a job manager for automatic
submission of compute tasks. We summarise the successfully established
infrastructure in chapter 4, concluding with our future plans to establish
AstroGrid-D as a platform of modern e-Astronomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4057</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4057</id><created>2010-07-23</created><authors><author><keyname>Sang</keyname><forenames>Bo</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Zhang</keyname><forenames>Zhihong</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Xu</keyname><forenames>Dongyan</forenames></author><author><keyname>Huang</keyname><forenames>Yabing</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author></authors><title>Precise, Scalable and Online Request Tracing for Multi-tier Services of
  Black Boxes</title><categories>cs.DC</categories><comments>15 pages. 21 figures. This is an extended work of our paper: Z.
  Zhang, J. Zhan, Y. Li, L. Wang and D. Meng, Precise request tracing and
  performance debugging for multi-tier services of black boxes, The 39th
  IEEE/IFIP International Conference on Dependable Systems &amp; Networks (DSN
  '09), 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As more and more multi-tier services are developed from commercial
off-the-shelf components or heterogeneous middleware without source code
available, both developers and administrators need a request tracing tool to
(1) exactly know how a user request of interest travels through services of
black boxes; (2) obtain macro-level user request behavior information of
services without the necessity of inundating within massive logs. Previous
research efforts either accept imprecision of probabilistic correlation methods
or present precise but unscalable tracing approaches that have to collect and
analyze large amount of logs; Besides, previous precise request tracing
approaches of black boxes fail to propose macro-level abstractions that enables
debugging performance-in-the-large, and hence users have to manually interpret
massive logs. This paper introduces a precise, scalable and online request
tracing tool, named PreciseTracer, for multi-tier services of black boxes. Our
contributions are four-fold: first, we propose a precise request tracing
algorithm for multi-tier services of black boxes, which only uses
application-independent knowledge; second, we respectively present micro-level
and macro-level abstractions: component activity graphs and dominated causal
path patterns to represent causal paths of each individual request and
repeatedly executed causal paths that account for significant fractions; third,
we present two mechanisms: tracing on demand and sampling to significantly
increase system scalability; fourth, we design and implement an online request
tracing tool. PreciseTracer's fast response, low overhead and scalability make
it a promising tracing tool for large-scale production systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4063</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4063</id><created>2010-07-23</created><authors><author><keyname>Lust</keyname><forenames>Thibaut</forenames></author><author><keyname>Teghem</keyname><forenames>Jacques</forenames></author></authors><title>The multiobjective multidimensional knapsack problem: a survey and a new
  approach</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The knapsack problem (KP) and its multidimensional version (MKP) are basic
problems in combinatorial optimization. In this paper we consider their
multiobjective extension (MOKP and MOMKP), for which the aim is to obtain or to
approximate the set of efficient solutions. In a first step, we classify and
describe briefly the existing works, that are essentially based on the use of
metaheuristics. In a second step, we propose the adaptation of the two-phase
Pareto local search (2PPLS) to the resolution of the MOMKP. With this aim, we
use a very-large scale neighborhood (VLSN) in the second phase of the method,
that is the Pareto local search. We compare our results to state-of-the-art
results and we show that we obtain results never reached before by heuristics,
for the biobjective instances. Finally we consider the extension to
three-objective instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4065</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4065</id><created>2010-07-23</created><updated>2010-07-26</updated><authors><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames></author><author><keyname>Doria</keyname><forenames>Sidney</forenames></author><author><keyname>Senouci</keyname><forenames>Mustapha Reda</forenames></author></authors><title>A Tutorial on the Implementation of Ad-hoc On Demand Distance Vector
  (AODV) Protocol in Network Simulator (NS-2)</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Network Simulator (NS-2) is a most widely used network simulator. It has
the capabilities to simulate a range of networks including wired and wireless
networks. In this tutorial, we present the implementation of Ad Hoc On-Demand
Distance Vector (AODV) Protocol in NS-2. This tutorial is targeted to the
novice user who wants to understand the implementation of AODV Protocol in
NS-2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4066</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4066</id><created>2010-07-23</created><updated>2010-07-26</updated><authors><author><keyname>Khan</keyname><forenames>Zeeshan Ali</forenames></author><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames></author></authors><title>A Tutorial on Broadcasting Packets over Multiple-Channels in a
  Multi-Inferface Network Setting in NS-2</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the proliferation of cheaper electronic devices, wireless communication
over multiple-channels in a multi-interface network is now possible. For
instace, wireless sensor nodes can now operate over multiplechannels. Moreover,
cognitive radio sensor networks are also evolving, which also operates over
multiple-channels. In the market, we can find antennas that can support the
operation of multiple channels, for e.g. the cc2420 antenna that is used for
communication between wireless sensor nodes consists of 16 programmable
channels. The proper utilization of multiple-channels reduces the interference
between the nodes and increase the network throughput. Recently, a Cognitive
Radio Cognitive Network (CRCN) patch for NS-2 simulator has proposed to support
multi-channel multi-interface capability in NS-2. In this tutorial, we consider
how to simulate a multi-channel multiinterface wireless network using the NS-2
simulator. This tutorial is trageted to the novice users who wants to
understand the implementation of multi-channel multi-interface in NS-2. We take
the Cognitive Radio Cognitive Network (CRCN) patch for NS-2 simulator and
demonstrate broadcasting over multiple-channels in a multi-interface network
setting. In our seeting, node braodcasts the Hello packets to its neighbors.
Neighboring nodes receive the Hello packets if and only if they are tuned to
the same channel. We demonstrate through example that the tuning of receivers
can be done in two fashions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4068</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4068</id><created>2010-07-23</created><updated>2010-07-26</updated><authors><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames><affiliation>Supervisor</affiliation></author><author><keyname>Viana</keyname><forenames>Aline Carneiro</forenames><affiliation>Supervisor</affiliation></author></authors><title>Decoupling data dissemination from the mobile sink's trajectory in
  wireless sensor networks: Current Research and Open Issues</title><categories>cs.NI</categories><report-no>Masters Thesis, Laboratory of Signals and Systems, Supelec and
  University of Paris Sud-11, July 2008</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, firstly, we presents state of the art survey on Data
Management and Data Dissemination techniques with Mobile Sink. Moreover we
classify these techniques into two ample sub-categories. Under this
classification, we identify, review, compare, and highlight these techniques
and their pros and cons. We do a SWOT (Strength, Weaknesses, Opportunities,
Threats) analysis of each scheme. We also discuss where each scheme is
appropriate.
  Secondly, we presents a new distributed data management scheme which is based
upon Random Walk Based Membership Service to facilitate Data Dissemination in
Mobile Sink based Wireless Sensor Networks. Our proposed scheme efficiently
deals with the aforementioned problems and we also compare the characteristics
of our proposed scheme with the state-of-the-art data-dissemination schemes. We
propose using Random Walks (RWs) with uniformly distributed views to
disseminate data through the WSN with a controlled overhead. This is performed
by the use of a Random Walk Based Membership Service - the RaWMS. Our proposal
solves then the problems generated when (a) all nodes are storage motes, being
no aggregation performed (b) one center node plays the role of storage mote and
aggregates data from all the other nodes (c) replication is performed on all
nodes in the network.
  To the best of our knowledge, we are the first to propose an efficient data
dissemination approach (in terms of overhead, adaptiveness and
representativeness) to allow a mobile sink to gather a representative view of
the monitored region covered by n sensor nodes by only visiting any m nodes,
where hopefully m &lt;&lt; n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4106</identifier>
 <datestamp>2011-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4106</id><created>2010-07-23</created><updated>2011-10-04</updated><authors><author><keyname>Loulloudes</keyname><forenames>Nicholas</forenames></author><author><keyname>Pallis</keyname><forenames>George</forenames></author><author><keyname>Dikaiakos</keyname><forenames>Marios D.</forenames></author></authors><title>The Dynamics of Vehicular Networks in Urban Environments</title><categories>cs.OH</categories><comments>Revised our testbed with even more realistic mobility traces. Used
  the location of real Wi-Fi hotspots to simulate RSUs in our study. Used a
  larger, real mobility trace set, from taxis in Shanghai. Examine the
  implications of our findings in the design of VANET routing protocols by
  implementing in ns-3 two routing protocols (GPCR &amp; VADD). Updated the
  bibliography section with new research works</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Vehicular Ad hoc NETworks (VANETs) have emerged as a platform to support
intelligent inter-vehicle communication and improve traffic safety and
performance. The road-constrained, high mobility of vehicles, their unbounded
power source, and the emergence of roadside wireless infrastructures make
VANETs a challenging research topic. A key to the development of protocols for
inter-vehicle communication and services lies in the knowledge of the
topological characteristics of the VANET communication graph. This paper
explores the dynamics of VANETs in urban environments and investigates the
impact of these findings in the design of VANET routing protocols. Using both
real and realistic mobility traces, we study the networking shape of VANETs
under different transmission and market penetration ranges. Given that a number
of RSUs have to be deployed for disseminating information to vehicles in an
urban area, we also study their impact on vehicular connectivity. Through
extensive simulations we investigate the performance of VANET routing protocols
by exploiting the knowledge of VANET graphs analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4109</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4109</id><created>2010-07-23</created><updated>2010-09-08</updated><authors><author><keyname>Srivastava</keyname><forenames>Dhruv</forenames></author></authors><title>An Application-oriented Model for Wireless Sensor Networks integrated
  with Telecom Infra</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author. 8pages, 9figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to propose a significant way of remote access and real time
monitoring of a particular geographic area by integrating wireless sensor
clouds with existing Telecom infrastructure and applications built around them
through a gateway. This utility is very potent for environment monitoring in
harsh and inaccessible places like mines, nuclear reactors, etc. We demonstrate
a scaled down version of multi-hop network of wireless sensor nodes and its
integration with existing telecom network infrastructure via a gateway.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4112</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4112</id><created>2010-07-23</created><updated>2011-03-24</updated><authors><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bjorn</forenames></author></authors><title>Interference Alignment for Clustered Multicell Joint Decoding</title><categories>cs.IT math.IT</categories><comments>16 pages, 4 figures, 1 table</comments><doi>10.1186/1687-1499-2011-132</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicell joint processing has been proven to be very efficient in overcoming
the interference-limited nature of the cellular paradigm. However, for reasons
of practical implementation global multicell joint decoding is not feasible and
thus clusters of cooperating Base Stations have to be considered. In this
context, intercluster interference has to be mitigated in order to harvest the
full potential of multicell joint processing. In this paper, four scenarios of
intercluster interference are investigated, namely a) global multicell joint
processing, b) interference alignment, c) resource division multiple access and
d) cochannel interference allowance. Each scenario is modelled and analyzed
using the per-cell ergodic sum-rate capacity as a figure of merit. In this
process, a number of theorems are derived for analytically expressing the
asymptotic eigenvalue distributions of the channel covariance matrices. The
analysis is based on principles from Free Probability theory and especially
properties in the R and Stieltjes transform domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4114</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4114</id><created>2010-07-23</created><authors><author><keyname>Drescher</keyname><forenames>Christian</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>A Translational Approach to Constraint Answer Set Solving</title><categories>cs.LO</categories><comments>17 pages</comments><journal-ref>Theory and Practice of Logic Programming, 10(4-6), 465-480, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to enhancing Answer Set Programming (ASP) with
Constraint Processing techniques which allows for solving interesting
Constraint Satisfaction Problems in ASP. We show how constraints on finite
domains can be decomposed into logic programs such that unit-propagation
achieves arc, bound or range consistency. Experiments with our encodings
demonstrate their computational impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4122</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4122</id><created>2010-07-23</created><authors><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>A model for the emergence of the genetic code as a transition in a noisy
  information channel</title><categories>q-bio.QM cond-mat.stat-mech cs.IT math.IT physics.bio-ph</categories><comments>Keywords: genetic code, rate-distortion theory, biological
  information channels</comments><journal-ref>Journal of Theoretical Biology Volume 249, Issue 2, 21 November
  2007, Pages 331-342</journal-ref><doi>10.1016/j.jtbi.2007.07.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The genetic code maps the sixty-four nucleotide triplets (codons) to twenty
amino-acids. Some argue that the specific form of the code with its twenty
amino-acids might be a 'frozen accident' because of the overwhelming effects of
any further change. Others see it as a consequence of primordial biochemical
pathways and their evolution. Here we examine a scenario in which evolution
drives the emergence of a genetic code by selecting for an amino-acid map that
minimizes the impact of errors. We treat the stochastic mapping of codons to
amino-acids as a noisy information channel with a natural fitness measure.
Organisms compete by the fitness of their codes and, as a result, a genetic
code emerges at a supercritical transition in the noisy channel, when the
mapping of codons to amino-acids becomes nonrandom. At the phase transition, a
small expansion is valid and the emergent code is governed by smooth modes of
the Laplacian of errors. These modes are in turn governed by the topology of
the error-graph, in which codons are connected if they are likely to be
confused. This topology sets an upper bound - which is related to the classical
map-coloring problem - on the number of possible amino-acids. The suggested
scenario is generic and may describe a mechanism for the formation of other
error-prone biological codes, such as the recognition of DNA sites by proteins
in the transcription regulatory network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4124</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4124</id><created>2010-07-23</created><authors><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>A simple model for the evolution of molecular codes driven by the
  interplay of accuracy, diversity and cost</title><categories>q-bio.QM cs.IT math.IT physics.bio-ph</categories><comments>Keywords: molecular codes, rate-distortion theory, biological
  information channels, stochastic maps, genetic code, genetic networks</comments><journal-ref>Tsvi Tlusty 2008 Phys. Biol. 5 016001</journal-ref><doi>10.1088/1478-3975/5/1/016001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular codes translate information written in one type of molecules into
another molecular language. We introduce a simple model that treats molecular
codes as noisy information channels. An optimal code is a channel that conveys
information accurately and efficiently while keeping down the impact of errors.
The equipoise of the three conflicting needs, for minimal error-load, minimal
cost of resources and maximal diversity of vocabulary, defines the fitness of
the code. The model suggests a mechanism for the emergence of a code when
evolution varies the parameters that control this equipoise and the mapping
between the two molecular languages becomes non-random. This mechanism is
demonstrated by a simple toy model that is formally equivalent to a mean-field
Ising magnet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4134</identifier>
 <datestamp>2014-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4134</id><created>2010-07-23</created><authors><author><keyname>Karaman</keyname><forenames>Svebor</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Benois-Pineau</keyname><forenames>Jenny</forenames><affiliation>LaBRI</affiliation></author><author><keyname>M&#xe9;gret</keyname><forenames>R&#xe9;mi</forenames><affiliation>IMS</affiliation></author><author><keyname>Dovgalecs</keyname><forenames>Vladislavs</forenames><affiliation>IMS</affiliation></author><author><keyname>Dartigues</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>ISPED</affiliation></author><author><keyname>Ga&#xeb;stel</keyname><forenames>Yann</forenames><affiliation>ISPED</affiliation></author></authors><title>Human Daily Activities Indexing in Videos from Wearable Cameras for
  Monitoring of Patients with Dementia Diseases</title><categories>cs.MM stat.ML</categories><proxy>ccsd</proxy><journal-ref>ICPR 2010, Istanbul : Turquie (2010)</journal-ref><doi>10.1109/ICPR.2010.999</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our research focuses on analysing human activities according to a known
behaviorist scenario, in case of noisy and high dimensional collected data. The
data come from the monitoring of patients with dementia diseases by wearable
cameras. We define a structural model of video recordings based on a Hidden
Markov Model. New spatio-temporal features, color features and localization
features are proposed as observations. First results in recognition of
activities are promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4137</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4137</id><created>2010-07-22</created><authors><author><keyname>Iba</keyname><forenames>Takashi</forenames></author></authors><title>Scale-Free Networks Hidden in Chaotic Dynamical Systems</title><categories>nlin.CD cs.DM math.DS</categories><comments>20 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show our discovery that state-transition networks in
several chaotic dynamical systems are &quot;scale-free networks,&quot; with a technique
to understand a dynamical system as a whole, which we call the analysis for
&quot;Discretized-State Transition&quot; (DST) networks; This scale-free nature is found
universally in the logistic map, the sine map, the cubic map, the general
symmetric map, the sine-circle map, the Gaussian map, and the delayed logistic
map. Our findings prove that there is a hidden order in chaos, which has not
detected yet. Furthermore, we anticipate that our study opens up a new way to a
&quot;network analysis approach to dynamical systems&quot; for understanding complex
phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4149</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4149</id><created>2010-07-23</created><authors><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>A rate-distortion scenario for the emergence and evolution of noisy
  molecular codes</title><categories>q-bio.MN cond-mat.stat-mech cs.IT math.IT physics.bio-ph</categories><comments>PACS numbers: 87.10.+e, 87.14.Gg, 87.14.Ee</comments><journal-ref>Phys. Rev. Lett. 100, 048101 (2008)</journal-ref><doi>10.1103/PhysRevLett.100.048101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss, in terms of rate-distortion theory, the fitness of molecular
codes as the problem of designing an optimal information channel. The fitness
is governed by an interplay between the cost and quality of the channel, which
induces smoothness in the code. By incorporating this code fitness into
population dynamics models, we suggest that the emergence and evolution of
molecular codes may be explained by simple channel design considerations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4154</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4154</id><created>2010-07-22</created><authors><author><keyname>Kulich</keyname><forenames>Tomas</forenames></author></authors><title>Dynamic monopolies with randomized starting configuration</title><categories>cs.DM cs.DC</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Properties of systems with majority voting rules have been exhaustingly
studied. In this work we focus on the randomized case - where the system is
initialized by randomized initial set of seeds. Our main aim is to give an
asymptotic estimate for sampling probability, such that the initial set of
seeds is (is not) a dynamic monopoly almost surely. After presenting some
trivial examples, we present exhaustive results for toroidal mesh and random
4-regular graph under simple majority scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4157</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4157</id><created>2010-07-23</created><authors><author><keyname>Pettorossi</keyname><forenames>Alberto</forenames></author><author><keyname>Proietti</keyname><forenames>Maurizio</forenames></author><author><keyname>Senni</keyname><forenames>Valerio</forenames></author></authors><title>Transformations of Logic Programs on Infinite Lists</title><categories>cs.PL cs.LO</categories><comments>37 pages, including the appendix with proofs. This is an extended
  version of a paper published in Theory and Practice of Logic Programming, see
  below</comments><acm-class>D.1.6; D.2.4; F.3.1</acm-class><journal-ref>Theory and Practice of Logic Programming, Volume 10, Special Issue
  4-6, 383-399, 2010</journal-ref><doi>10.1017/S1471068410000177</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an extension of logic programs, called \omega-programs, that can
be used to define predicates over infinite lists. \omega-programs allow us to
specify properties of the infinite behavior of reactive systems and, in
general, properties of infinite sequences of events. The semantics of
\omega-programs is an extension of the perfect model semantics. We present
variants of the familiar unfold/fold rules which can be used for transforming
\omega-programs. We show that these new rules are correct, that is, their
application preserves the perfect model semantics. Then we outline a general
methodology based on program transformation for verifying properties of
\omega-programs. We demonstrate the power of our transformation-based
verification methodology by proving some properties of Buechi automata and
\omega-regular languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4172</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4172</id><created>2010-07-23</created><authors><author><keyname>Peters</keyname><forenames>Kirstin</forenames></author><author><keyname>Nestmann</keyname><forenames>Uwe</forenames></author></authors><title>Breaking Symmetries</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known result by Palamidessi tells us that {\pi}mix (the {\pi}-calculus
with mixed choice) is more expressive than {\pi}sep (its subset with only
separate choice). The proof of this result argues with their different
expressive power concerning leader election in symmetric networks. Later on,
Gorla of- fered an arguably simpler proof that, instead of leader election in
symmetric networks, employed the reducibility of &quot;incestual&quot; processes (mixed
choices that include both enabled senders and receivers for the same channel)
when running two copies in parallel. In both proofs, the role of breaking (ini-
tial) symmetries is more or less apparent. In this paper, we shed more light on
this role by re-proving the above result-based on a proper formalization of
what it means to break symmetries-without referring to another layer of the
distinguishing problem domain of leader election.
  Both Palamidessi and Gorla rephrased their results by stating that there is
no uniform and reason- able encoding from {\pi}mix into {\pi}sep . We indicate
how the respective proofs can be adapted and exhibit the consequences of
varying notions of uniformity and reasonableness. In each case, the ability to
break initial symmetries turns out to be essential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4177</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4177</id><created>2010-07-23</created><updated>2010-11-11</updated><authors><author><keyname>I&#xf1;iguez</keyname><forenames>Gerardo</forenames></author><author><keyname>Barrio</keyname><forenames>Rafael A.</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo K.</forenames></author></authors><title>Modelling opinion formation driven communities in social networks</title><categories>physics.soc-ph cs.CY nlin.AO</categories><comments>5 pages, 2 figures. Added references. To appear in Special Issue 2010
  of Computer Physics Communications</comments><journal-ref>Comput. Phys. Commun. 182, 1866 (2011)</journal-ref><doi>10.1016/j.cpc.2010.11.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper we proposed a model to study the dynamics of opinion
formation in human societies by a co-evolution process involving two distinct
time scales of fast transaction and slower network evolution dynamics. In the
transaction dynamics we take into account short range interactions as
discussions between individuals and long range interactions to describe the
attitude to the overall mood of society. The latter is handled by a uniformly
distributed parameter $\alpha$, assigned randomly to each individual, as
quenched personal bias. The network evolution dynamics is realized by rewiring
the societal network due to state variable changes as a result of transaction
dynamics. The main consequence of this complex dynamics is that communities
emerge in the social network for a range of values in the ratio between time
scales. In this paper we focus our attention on the attitude parameter $\alpha$
and its influence on the conformation of opinion and the size of the resulting
communities. We present numerical studies and extract interesting features of
the model that can be interpreted in terms of social behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4191</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4191</id><created>2010-07-23</created><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>Fast Moment Estimation in Data Streams in Optimal Space</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a space-optimal algorithm with update time
O(log^2(1/eps)loglog(1/eps)) for (1+eps)-approximating the pth frequency
moment, 0 &lt; p &lt; 2, of a length-n vector updated in a data stream. This provides
a nearly exponential improvement in the update time complexity over the
previous space-optimal algorithm of [Kane-Nelson-Woodruff, SODA 2010], which
had update time Omega(1/eps^2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4221</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4221</id><created>2010-07-23</created><updated>2010-10-01</updated><authors><author><keyname>Nowotniak</keyname><forenames>Robert</forenames></author><author><keyname>Kucharski</keyname><forenames>Jacek</forenames></author></authors><title>Building Blocks Propagation in Quantum-Inspired Genetic Algorithm</title><categories>cs.NE</categories><comments>16 pages, 7 figures</comments><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analysis of building blocks propagation in
Quantum-Inspired Genetic Algorithm, which belongs to a new class of
metaheuristics drawing their inspiration from both biological evolution and
unitary evolution of quantum systems. The expected number of quantum
chromosomes matching a schema has been analyzed and a random variable
corresponding to this issue has been introduced. The results have been compared
with Simple Genetic Algorithm. Also, it has been presented how selected binary
quantum chromosomes cover a domain of one-dimensional fitness function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4230</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4230</id><created>2010-07-23</created><updated>2012-04-03</updated><authors><author><keyname>Czumaj</keyname><forenames>Artur</forenames></author><author><keyname>Goldreich</keyname><forenames>Oded</forenames></author><author><keyname>Ron</keyname><forenames>Dana</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author><author><keyname>Shapira</keyname><forenames>Asaf</forenames></author><author><keyname>Sohler</keyname><forenames>Christian</forenames></author></authors><title>Finding Cycles and Trees in Sublinear Time</title><categories>cs.DS cs.DM</categories><comments>Keywords: Sublinear-Time Algorithms, Property Testing, Bounded-Degree
  Graphs, One-Sided vs Two-Sided Error Probability Updated version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present sublinear-time (randomized) algorithms for finding simple cycles
of length at least $k\geq 3$ and tree-minors in bounded-degree graphs. The
complexity of these algorithms is related to the distance of the graph from
being $C_k$-minor-free (resp., free from having the corresponding tree-minor).
In particular, if the graph is far (i.e., $\Omega(1)$-far) {from} being
cycle-free, i.e. if one has to delete a constant fraction of edges to make it
cycle-free, then the algorithm finds a cycle of polylogarithmic length in time
$\tildeO(\sqrt{N})$, where $N$ denotes the number of vertices. This time
complexity is optimal up to polylogarithmic factors.
  The foregoing results are the outcome of our study of the complexity of {\em
one-sided error} property testing algorithms in the bounded-degree graphs
model. For example, we show that cycle-freeness of $N$-vertex graphs can be
tested with one-sided error within time complexity
$\tildeO(\poly(1/\e)\cdot\sqrt{N})$. This matches the known $\Omega(\sqrt{N})$
query lower bound, and contrasts with the fact that any minor-free property
admits a {\em two-sided error} tester of query complexity that only depends on
the proximity parameter $\e$. For any constant $k\geq3$, we extend this result
to testing whether the input graph has a simple cycle of length at least $k$.
On the other hand, for any fixed tree $T$, we show that $T$-minor-freeness has
a one-sided error tester of query complexity that only depends on the proximity
parameter $\e$.
  Our algorithm for finding cycles in bounded-degree graphs extends to general
graphs, where distances are measured with respect to the actual number of
edges. Such an extension is not possible with respect to finding tree-minors in
$o(\sqrt{N})$ complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4236</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4236</id><created>2010-07-23</created><authors><author><keyname>Farnoud</keyname><forenames>Farzad</forenames><affiliation>Hassanzadeh</affiliation></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Sorting of Permutations by Cost-Constrained Transpositions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of finding the minimum decomposition of a permutation
in terms of transpositions with non-uniform cost. For arbitrary non-negative
cost functions, we describe polynomial-time, constant-approximation
decomposition algorithms. For metric-path costs, we describe exact
polynomial-time decomposition algorithms. Our algorithms represent a
combination of Viterbi-type algorithms and graph-search techniques for
minimizing the cost of individual transpositions, and dynamic programing
algorithms for finding minimum cost cycle decompositions. The presented
algorithms have applications in information theory, bioinformatics, and
algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4257</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4257</id><created>2010-07-24</created><updated>2011-04-04</updated><authors><author><keyname>Katkov</keyname><forenames>Mikhail</forenames></author></authors><title>Polynomial-time approximation scheme for Max-Cut problem</title><categories>cs.CC math.CO</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The community convinced me that this peace of crank was written by crackpot
trisector. I apologize for disturbing community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4266</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4266</id><created>2010-07-24</created><updated>2010-09-03</updated><authors><author><keyname>Hamana</keyname><forenames>Makoto</forenames><affiliation>Gunma Univesity</affiliation></author></authors><title>Initial Algebra Semantics for Cyclic Sharing Tree Structures</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  3, 2010) lmcs:1060</journal-ref><doi>10.2168/LMCS-6(3:15)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Terms are a concise representation of tree structures. Since they can be
naturally defined by an inductive type, they offer data structures in
functional programming and mechanised reasoning with useful principles such as
structural induction and structural recursion. However, for graphs or
&quot;tree-like&quot; structures - trees involving cycles and sharing - it remains
unclear what kind of inductive structures exists and how we can faithfully
assign a term representation of them. In this paper we propose a simple term
syntax for cyclic sharing structures that admits structural induction and
recursion principles. We show that the obtained syntax is directly usable in
the functional language Haskell and the proof assistant Agda, as well as
ordinary data structures such as lists and trees. To achieve this goal, we use
a categorical approach to initial algebra semantics in a presheaf category.
That approach follows the line of Fiore, Plotkin and Turi's models of abstract
syntax with variable binding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4268</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4268</id><created>2010-07-24</created><authors><author><keyname>Earl</keyname><forenames>Christopher</forenames></author><author><keyname>Might</keyname><forenames>Matthew</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>Pushdown Control-Flow Analysis of Higher-Order Programs</title><categories>cs.PL</categories><comments>The 2010 Workshop on Scheme and Functional Programming</comments><acm-class>F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-free approaches to static analysis gain precision over classical
approaches by perfectly matching returns to call sites---a property that
eliminates spurious interprocedural paths. Vardoulakis and Shivers's recent
formulation of CFA2 showed that it is possible (if expensive) to apply
context-free methods to higher-order languages and gain the same boost in
precision achieved over first-order programs.
  To this young body of work on context-free analysis of higher-order programs,
we contribute a pushdown control-flow analysis framework, which we derive as an
abstract interpretation of a CESK machine with an unbounded stack. One
instantiation of this framework marks the first polyvariant pushdown analysis
of higher-order programs; another marks the first polynomial-time analysis. In
the end, we arrive at a framework for control-flow analysis that can
efficiently compute pushdown generalizations of classical control-flow
analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4286</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4286</id><created>2010-07-24</created><authors><author><keyname>Jagannathan</keyname><forenames>Krishna</forenames></author><author><keyname>Markakis</keyname><forenames>Mihalis</forenames></author><author><keyname>Modiano</keyname><forenames>Eytan</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Queue Length Asymptotics for Generalized Max-Weight Scheduling in the
  presence of Heavy-Tailed Traffic</title><categories>cs.NI cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the asymptotic behavior of the steady-state queue length
distribution under generalized max-weight scheduling in the presence of
heavy-tailed traffic. We consider a system consisting of two parallel queues,
served by a single server. One of the queues receives heavy-tailed traffic, and
the other receives light-tailed traffic. We study the class of throughput
optimal max-weight-alpha scheduling policies, and derive an exact asymptotic
characterization of the steady-state queue length distributions. In particular,
we show that the tail of the light queue distribution is heavier than a
power-law curve, whose tail coefficient we obtain explicitly. Our asymptotic
characterization also contains an intuitively surprising result - the
celebrated max-weight scheduling policy leads to the worst possible tail of the
light queue distribution, among all non-idling policies. Motivated by the above
negative result regarding the max-weight-alpha policy, we analyze a
log-max-weight (LMW) scheduling policy. We show that the LMW policy guarantees
an exponentially decaying light queue tail, while still being throughput
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4294</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4294</id><created>2010-07-24</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>Properties of optimal prefix-free machines as instantaneous codes</title><categories>cs.IT math.IT math.LO</categories><comments>5 pages, no figures, final manuscript to appear in the Proceedings of
  the 2010 IEEE Information Theory Workshop, Dublin, Ireland, August 30 -
  September 3, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal prefix-free machine U is a universal decoding algorithm used to
define the notion of program-size complexity H(s) for a finite binary string s.
Since the set of all halting inputs for U is chosen to form a prefix-free set,
the optimal prefix-free machine U can be regarded as an instantaneous code for
noiseless source coding scheme. In this paper, we investigate the properties of
optimal prefix-free machines as instantaneous codes. In particular, we
investigate the properties of the set U^{-1}(s) of codewords associated with a
symbol s. Namely, we investigate the number of codewords in U^{-1}(s) and the
distribution of codewords in U^{-1}(s) for each symbol s, using the toolkit of
algorithmic information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4301</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4301</id><created>2010-07-25</created><authors><author><keyname>Izhak-Ratzin</keyname><forenames>Rafit</forenames></author><author><keyname>Park</keyname><forenames>Hyunggon</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Reinforcement Learning in BitTorrent Systems</title><categories>cs.NI</categories><comments>12 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research efforts have shown that the popular BitTorrent protocol does
not provide fair resource reciprocation and may allow free-riding. In this
paper, we propose a BitTorrent-like protocol that replaces the peer selection
mechanisms in the regular BitTorrent protocol with a novel reinforcement
learning (RL) based mechanism. Due to the inherent opration of P2P systems,
which involves repeated interactions among peers over a long period of time,
the peers can efficiently identify free-riders as well as desirable
collaborators by learning the behavior of their associated peers. Thus, it can
help peers improve their download rates and discourage free-riding, while
improving fairness in the system. We model the peers' interactions in the
BitTorrent-like network as a repeated interaction game, where we explicitly
consider the strategic behavior of the peers. A peer, which applies the
RL-based mechanism, uses a partial history of the observations on associated
peers' statistical reciprocal behaviors to determine its best responses and
estimate the corresponding impact on its expected utility. The policy
determines the peer's resource reciprocations with other peers, which would
maximize the peer's long-term performance, thereby making foresighted
decisions. We have implemented the proposed reinforcement-learning based
mechanism and incorporated it into an existing BitTorrent client. We have
performed extensive experiments on a controlled Planetlab test bed. Our results
confirm that our proposed protocol (1) promotes fairness in terms of incentives
to each peer's contribution e.g. high capacity peers improve their download
completion time by up to 33\%, (2) improves the system stability and robustness
e.g. reducing the peer selection luctuations by 57\%, and (3) discourages
free-riding e.g. peers reduce by 64\% their upload to \FR, in comparison to the
regular \BT~protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4303</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4303</id><created>2010-07-25</created><authors><author><keyname>Kuhn</keyname><forenames>Adrian</forenames></author><author><keyname>Erni</keyname><forenames>David</forenames></author><author><keyname>Nierstrasz</keyname><forenames>Oscar</forenames></author></authors><title>Embedding Spatial Software Visualization in the IDE: an Exploratory
  Study</title><categories>cs.SE cs.HC</categories><comments>To appear in proceedings of SOFTVIS 2010 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software visualization can be of great use for understanding and exploring a
software system in an intuitive manner. Spatial representation of software is a
promising approach of increasing interest. However, little is known about how
developers interact with spatial visualizations that are embedded in the IDE.
In this paper, we present a pilot study that explores the use of Software
Cartography for program comprehension of an unknown system. We investigated
whether developers establish a spatial memory of the system, whether clustering
by topic offers a sound base layout, and how developers interact with maps. We
report our results in the form of observations, hypotheses, and implications.
Key findings are a) that developers made good use of the map to inspect search
results and call graphs, and b) that developers found the base layout
surprising and often confusing. We conclude with concrete advice for the design
of embedded software maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4312</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4312</id><created>2010-07-25</created><authors><author><keyname>Backhausz</keyname><forenames>Agnes</forenames></author></authors><title>Limit distribution of degrees in random family trees</title><categories>math.PR cs.DM</categories><msc-class>05C80, 60C05, 60F15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a one-parameter model for evolution of random trees, which also includes
the Barabasi-Albert random tree, almost sure behavior and the limiting
distribution of the degree of a vertex in a fixed position are examined.
Results about Polya urn models are applied in the proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4324</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4324</id><created>2010-07-25</created><authors><author><keyname>Safeer</keyname><forenames>Yasir</forenames><affiliation>FAST - National University of Computer and Emerging Sciences</affiliation></author><author><keyname>Mustafa</keyname><forenames>Atika</forenames><affiliation>FAST - National University of Computer and Emerging Sciences</affiliation></author><author><keyname>Ali</keyname><forenames>Anis Noor</forenames><affiliation>FAST - National University of Computer and Emerging Sciences</affiliation></author></authors><title>Clustering Unstructured Data (Flat Files) - An Implementation in Text
  Mining Tool</title><categories>cs.IR</categories><comments>7 pages, 5 figures, 7 tables; Journal Ref: (IJCSIS) ISSN 1947-5500
  http://sites.google.com/site/ijcsis/
  http://sites.google.com/site/ijcsis/vol-8-no-2-may-2010
  http://www.docstoc.com/docs/43022093/Clustering-Unstructured-Data-%28Flat-Files%29---An-Implementation-in-Text-Mining-Tool/site/ijcsis/vol-8-no-2-may-2010</comments><acm-class>I.5.1; I.5.2; I.5.3; I.5.4; H.3.3</acm-class><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 8, No. 2, MAY 2010, pp. 174-180</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  With the advancement of technology and reduced storage costs, individuals and
organizations are tending towards the usage of electronic media for storing
textual information and documents. It is time consuming for readers to retrieve
relevant information from unstructured document collection. It is easier and
less time consuming to find documents from a large collection when the
collection is ordered or classified by group or category. The problem of
finding best such grouping is still there. This paper discusses the
implementation of k-Means clustering algorithm for clustering unstructured text
documents that we implemented, beginning with the representation of
unstructured text and reaching the resulting set of clusters. Based on the
analysis of resulting clusters for a sample set of documents, we have also
proposed a technique to represent documents that can further improve the
clustering result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4338</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4338</id><created>2010-07-25</created><updated>2012-08-06</updated><authors><author><keyname>Ng</keyname><forenames>H. T.</forenames></author><author><keyname>Nori</keyname><forenames>Franco</forenames></author></authors><title>A proposal for factorization using Kerr nonlinearities between three
  harmonic oscillators</title><categories>quant-ph cs.DS</categories><comments>21 pages, 5 figures; title changed, major revisions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an alternative method to factorize an integer by using three
harmonic oscillators. These oscillators are coupled together via specific Kerr
nonlinear interactions. This method can be applied even if two harmonic
oscillators are prepared in mixed states. As simple examples, we show how to
factorize N=15 and 35 using this approach. The effect of dissipation of the
harmonic oscillators on the performance of this method is studied. We also
study the realization of nonlinear interactions between the coupled
oscillators. However, the probability of finding the factors of a number is
inversely proportional to its input size. The probability becomes low when this
number is large. We discuss the limitations of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4371</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4371</id><created>2010-07-25</created><authors><author><keyname>Mahdaviani</keyname><forenames>Kaveh</forenames></author><author><keyname>Shahidi</keyname><forenames>Shervin</forenames></author><author><keyname>Haddadi</keyname><forenames>Shima</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author><author><keyname>Tellambura</keyname><forenames>Chintha</forenames></author></authors><title>Improving the Sphere-Packing Bound for Binary Codes over Memoryless
  Symmetric Channels</title><categories>cs.IT math.IT</categories><comments>5 pages,3 figures, Presented at the Forty-Seventh Annual Allerton
  Conference on Communication, Control, and Computing, Sep. 2009</comments><journal-ref>Communication, Control, and Computing, 2009. Allerton 2009. 47th
  Annual Allerton Conference on , vol., no., pp.553-557, Sept. 30 2009-Oct. 2
  2009</journal-ref><doi>10.1109/ALLERTON.2009.5394906</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lower bound on the minimum required code length of binary codes is
obtained. The bound is obtained based on observing a close relation between the
Ulam's liar game and channel coding. In fact, Spencer's optimal solution to the
game is used to derive this new bound which improves the famous Sphere-Packing
Bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4389</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4389</id><created>2010-07-26</created><updated>2011-03-03</updated><authors><author><keyname>Richa</keyname><forenames>Andrea</forenames></author><author><keyname>Scheideler</keyname><forenames>Christian</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author><author><keyname>Zhang</keyname><forenames>Jin</forenames></author></authors><title>AntiJam: Efficient Medium Access despite Adaptive and Reactive Jamming</title><categories>cs.DS cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intentional interference constitutes a major threat for communication
networks operating over a shared medium where availability is imperative.
Jamming attacks are often simple and cheap to implement. In particular, today's
jammers can perform physical carrier sensing in order to disrupt communication
more efficiently, specially in a network of simple wireless devices such as
sensor nodes, which usually operate over a single frequency (or a limited
frequency band) and which cannot benefit from the use of spread spectrum or
other more advanced technologies. This article proposes the medium access (MAC)
protocol \textsc{AntiJam} that is provably robust against a powerful reactive
adversary who can jam a $(1-\epsilon)$-portion of the time steps, where
$\epsilon$ is an arbitrary constant. The adversary uses carrier sensing to make
informed decisions on when it is most harmful to disrupt communications;
moreover, we allow the adversary to be adaptive and to have complete knowledge
of the entire protocol history. Our MAC protocol is able to make efficient use
of the non-jammed time periods and achieves an asymptotically optimal,
$\Theta{(1)}$-competitive throughput in this harsh scenario. In addition,
\textsc{AntiJam} features a low convergence time and has good fairness
properties. Our simulation results validate our theoretical results and also
show that our algorithm manages to guarantee constant throughput where the
802.11 MAC protocol basically fails to deliver any packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4400</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4400</id><created>2010-07-26</created><authors><author><keyname>Di Napoli</keyname><forenames>Edoardo</forenames></author><author><keyname>Bientinesi</keyname><forenames>Paolo</forenames></author></authors><title>Matrix Structure Exploitation in Generalized Eigenproblems Arising in
  Density Functional Theory</title><categories>physics.comp-ph cond-mat.mtrl-sci cs.DS</categories><comments>To appear in the proceedings of 8th International Conference on
  Numerical Analysis and Applied Mathematics (ICNAAM 2010)</comments><doi>10.1063/1.3498648</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short paper, the authors report a new computational approach in the
context of Density Functional Theory (DFT). It is shown how it is possible to
speed up the self-consistent cycle (iteration) characterizing one of the most
well-known DFT implementations: FLAPW. Generating the Hamiltonian and overlap
matrices and solving the associated generalized eigenproblems $Ax = \lambda Bx$
constitute the two most time-consuming fractions of each iteration. Two
promising directions, implementing the new methodology, are presented that will
ultimately improve the performance of the generalized eigensolver and save
computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4414</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4414</id><created>2010-07-26</created><updated>2012-01-17</updated><authors><author><keyname>Abyaneh</keyname><forenames>Mohammad Reza Sohizadeh</forenames></author></authors><title>On the Security of Non-Linear HB (NLHB) Protocol Against Passive Attack</title><categories>cs.CR</categories><comments>This paper is withdrwan due to duplication in DBLP site</comments><doi>10.1109/EUC.2010.86</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a variant of the HB authentication protocol for RFID systems, which relies
on the complexity of decoding linear codes against passive attacks, Madhavan et
al. presented Non-Linear HB(NLHB) protocol. In contrast to HB, NLHB relies on
the complexity of decoding a class of non-linear codes to render the passive
attacks proposed against HB ineffective. In this paper, we show that passive
attacks against HB protocol can still be applicable to NLHB and this protocol
does not provide the desired security margin. In our attack, we first linearize
the non-linear part of NLHB to obtain a HB equivalent for NLHB, and then
exploit the passive attack techniques proposed for the HB to evaluate the
security margin of NLHB. The results show that although NLHB's security margin
is relatively higher than HB against similar passive attack techniques, it has
been overestimated and, in contrary to what is claimed, NLHB is vulnerable to
passive attacks against HB, especially when the noise vector in the protocol
has a low weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4418</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4418</id><created>2010-07-26</created><updated>2011-02-18</updated><authors><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Distributed Source Coding of Correlated Gaussian Sources</title><categories>cs.IT math.IT</categories><comments>30 pages 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the distributed source coding system of $L$ correlated Gaussian
sources $Y_i,i=1,2,...,L$ which are noisy observations of correlated Gaussian
remote sources $X_k, k=1,2,...,K$. We assume that $Y^{L}={}^{\rm t}(Y_1,Y_2,$
$..., Y_L)$ is an observation of the source vector $X^K={}^{\rm t}(X_1,X_2,...,
X_K)$, having the form $Y^L=AX^K+N^L$, where $A$ is a $L\times K$ matrix and
$N^L={}^{\rm t}(N_1,N_2,...,N_L)$ is a vector of $L$ independent Gaussian
random variables also independent of $X^K$. In this system $L$ correlated
Gaussian observations are separately compressed by $L$ encoders and sent to the
information processing center. We study the remote source coding problem where
the decoder at the center attempts to reconstruct the remote source $X^K$. We
consider three distortion criteria based on the covariance matrix of the
estimation error on $X^K$. For each of those three criteria we derive explicit
inner and outer bounds of the rate distortion region. Next, in the case of
$K=L$ and $A=I_L$, we study the multiterminal source coding problem where the
decoder wishes to reconstruct the observation $Y^L=X^L+N^L$. To investigate
this problem we shall establish a result which provides a strong connection
between the remote source coding problem and the multiterminal source coding
problem. Using this result, we drive several new partial solutions to the
multiterminal source coding problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4427</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4427</id><created>2010-07-26</created><authors><author><keyname>Rosenberg</keyname><forenames>Dinah</forenames></author><author><keyname>Solan</keyname><forenames>Eilon</forenames></author><author><keyname>Vieille</keyname><forenames>Nicolas</forenames></author></authors><title>Strategic Information Exchange</title><categories>math.PR cs.GT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a class of two-player repeated games with incomplete information and
informational externalities. In these games, two states are chosen at the
outset, and players get private information on the pair, before engaging in
repeated play. The payoff of each player only depends on his `own' state and on
his own action. We study to what extent, and how, information can be exchanged
in equilibrium. We prove that provided the private information of each player
is valuable for the other player, the set of sequential equilibrium payoffs
converges to the set of feasible and individually rational payoffs as players
become patient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4438</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4438</id><created>2010-07-26</created><authors><author><keyname>Costa</keyname><forenames>V&#xed;tor Santos</forenames></author><author><keyname>Dutra</keyname><forenames>In&#xea;s</forenames></author><author><keyname>Rocha</keyname><forenames>Ricardo</forenames></author></authors><title>Threads and Or-Parallelism Unified</title><categories>cs.DC</categories><comments>17 pages, 21 figures, International Conference on Logic Programming
  (ICLP 2010)</comments><acm-class>D.1.6; D.1.3</acm-class><journal-ref>Theory and Practice of Logic Programming, Volume 10, Issue 4-6,
  July 2010, pp 417-432 Published online by Cambridge University Press 09 Jul
  2010</journal-ref><doi>10.1017/S1471068410000190</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main advantages of Logic Programming (LP) is that it provides an
excellent framework for the parallel execution of programs. In this work we
investigate novel techniques to efficiently exploit parallelism from real-world
applications in low cost multi-core architectures. To achieve these goals, we
revive and redesign the YapOr system to exploit or-parallelism based on a
multi-threaded implementation. Our new approach takes full advantage of the
state-of-the-art fast and optimized YAP Prolog engine and shares the underlying
execution environment, scheduler and most of the data structures used to
support YapOr's model. Initial experiments with our new approach consistently
achieve almost linear speedups for most of the applications, proving itself as
a good alternative for exploiting implicit parallelism in the currently
available low cost multi-core architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4440</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4440</id><created>2010-07-26</created><updated>2010-11-02</updated><authors><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Han</keyname><forenames>Xiao-Pu</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>Modeling correlated human dynamics</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We empirically study the activity patterns of individual blog-posting and
find significant memory effects. The memory coefficient first decays in a power
law and then turns to an exponential form. Moreover, the inter-event time
distribution displays a heavy-tailed nature with power-law exponent dependent
on the activity. Our findings challenge the priority-queue model that can not
reproduce the memory effects or the activity-dependent distributions. We think
there is another kind of human activity patterns driven by personal interests
and characterized by strong memory effects. Accordingly, we propose a simple
model based on temporal preference, which can well reproduce both the
heavy-tailed nature and the strong memory effects. This work helps in
understanding both the temporal regularities and the predictability of human
behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4446</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4446</id><created>2010-07-26</created><updated>2010-09-07</updated><authors><author><keyname>Van Horn</keyname><forenames>David</forenames></author><author><keyname>Might</keyname><forenames>Matthew</forenames></author></authors><title>Abstracting Abstract Machines</title><categories>cs.PL</categories><comments>The 15th ACM SIGPLAN International Conference on Functional
  Programming (ICFP'10), Baltimore, Maryland, September, 2010</comments><acm-class>F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a derivational approach to abstract interpretation that yields
novel and transparently sound static analyses when applied to well-established
abstract machines. To demonstrate the technique and support our claim, we
transform the CEK machine of Felleisen and Friedman, a lazy variant of
Krivine's machine, and the stack-inspecting CM machine of Clements and
Felleisen into abstract interpretations of themselves. The resulting analyses
bound temporal ordering of program events; predict return-flow and
stack-inspection behavior; and approximate the flow and evaluation of by-need
parameters. For all of these machines, we find that a series of well-known
concrete machine refactorings, plus a technique we call store-allocated
continuations, leads to machines that abstract into static analyses simply by
bounding their stores. We demonstrate that the technique scales up uniformly to
allow static analysis of realistic language features, including tail calls,
conditionals, side effects, exceptions, first-class continuations, and even
garbage collection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4465</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4465</id><created>2010-07-26</created><authors><author><keyname>Shaker</keyname><forenames>Sherif Welsen</forenames></author><author><keyname>Elramly</keyname><forenames>Salwa Hussien</forenames></author><author><keyname>Shehata</keyname><forenames>Khaled Ali</forenames></author></authors><title>FPGA Implementation of a Reconfigurable Viterbi Decoder for WiMAX
  Receiver</title><categories>cs.AR</categories><doi>10.1109/ICM.2009.5418636</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Field Programmable Gate Array technology (FPGA) is a highly configurable
option for implementing many sophisticated signal processing tasks in Software
Defined Radios (SDRs). Those types of radios are realized using highly
configurable hardware platforms. Convolutional codes are used in every robust
digital communication system and Viterbi algorithm is employed in wireless
communications to decode the convolutional codes. Such decoders are complex and
dissipate large amount of power. In this paper, a low power-reconfigurable
Viterbi decoder for WiMAX receiver is described using a VHDL code for FPGA
implementation. The proposed design is implemented on Xilinx Virtex-II Pro,
XC2vpx30 FPGA using the FPGA Advantage Pro package provided by Mentor Graphics
and ISE 10.1 by Xilinx.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4467</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4467</id><created>2010-07-26</created><authors><author><keyname>Savir</keyname><forenames>Yonatan</forenames></author><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>Molecular Recognition as an Information Channel: The Role of
  Conformational Changes</title><categories>q-bio.BM cs.IT math.IT physics.bio-ph</categories><comments>Keywords--Molecular information channels, molecular recognition,
  conformational proofreading.
  http://www.weizmann.ac.il/complex/tlusty/papers/IEEE2009b.pdf</comments><journal-ref>Workshop on Biological and Bio-Inspired Information Theory, 43rd
  Annual Conference on Information Sciences and Systems, March 18-20, 2009 2009
  , Page(s): 835 - 840</journal-ref><doi>10.1109/CISS.2009.5054833</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular recognition, which is essential in processing information in
biological systems, takes place in a crowded noisy biochemical environment and
requires the recognition of a specific target within a background of various
similar competing molecules. We consider molecular recognition as a
transmission of information via a noisy channel and use this analogy to gain
insights on the optimal, or fittest, molecular recognizer. We focus on the
optimal structural properties of the molecules such as flexibility and
conformation. We show that conformational changes upon binding, which often
occur during molecular recognition, may optimize the detection performance of
the recognizer. We thus suggest a generic design principle termed
'conformational proofreading' in which deformation enhances detection. We
evaluate the optimal flexibility of the molecular recognizer, which is
analogous to the stochasticity in a decision unit. In some scenarios, a
flexible recognizer, i.e., a stochastic decision unit, performs better than a
rigid, deterministic one. As a biological example, we discuss conformational
changes during homologous recombination, the process of genetic exchange
between two DNA strands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4471</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4471</id><created>2010-07-26</created><authors><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>The physical language of molecular codes: A rate-distortion approach to
  the evolution and emergence of biological codes</title><categories>q-bio.BM cs.IT math.IT physics.bio-ph</categories><comments>Index Terms--Molecular codes, rate-distortion theory, biological
  information networks, molecular recognition.
  http://www.weizmann.ac.il/complex/tlusty/papers/IEEE2009.pdf</comments><journal-ref>Workshop on Biological and Bio-Inspired Information Theory, 43rd
  Annual Conference on Information Sciences and Systems, March 18-20, 2009 2009
  , Page(s): 841 - 846</journal-ref><doi>10.1109/CISS.2009.5054834</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The function of the organism hinges on the performance of its
information-processing networks, which convey information via molecular
recognition. Many paths within these networks utilize molecular codebooks, such
as the genetic code, to translate information written in one class of molecules
into another molecular &quot;language&quot; . The present paper examines the emergence
and evolution of molecular codes in terms of rate-distortion theory and reviews
recent results of this approach. We discuss how the biological problem of
maximizing the fitness of an organism by optimizing its molecular coding
machinery is equivalent to the communication engineering problem of designing
an optimal information channel. The fitness of a molecular code takes into
account the interplay between the quality of the channel and the cost of
resources which the organism needs to invest in its construction and
maintenance. We analyze the dynamics of a population of organisms that compete
according to the fitness of their codes. The model suggests a generic mechanism
for the emergence of molecular codes as a phase transition in an information
channel. This mechanism is put into biological context and demonstrated in a
simple example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4476</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4476</id><created>2010-07-26</created><authors><author><keyname>Mauro</keyname><forenames>Maurizio Gabbrielli abd Jacopo</forenames></author><author><keyname>Meo</keyname><forenames>Maria Chiara</forenames></author><author><keyname>Sneyers</keyname><forenames>Jon</forenames></author></authors><title>Decidability properties for fragments of CHR</title><categories>cs.LO</categories><journal-ref>Theory and Practice of Logic Programming, volume 10, number 4-6,
  year 2010, pages 611-626</journal-ref><doi>10.1017/S1471068410000311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the decidability of termination for two CHR dialects which,
similarly to the Datalog like languages, are defined by using a signature which
does not allow function symbols (of arity &gt;0). Both languages allow the use of
the = built-in in the body of rules, thus are built on a host language that
supports unification. However each imposes one further restriction. The first
CHR dialect allows only range-restricted rules, that is, it does not allow the
use of variables in the body or in the guard of a rule if they do not appear in
the head. We show that the existence of an infinite computation is decidable
for this dialect. The second dialect instead limits the number of atoms in the
head of rules to one. We prove that in this case, the existence of a
terminating computation is decidable. These results show that both dialects are
strictly less expressive than Turing Machines. It is worth noting that the
language (without function symbols) without these restrictions is as expressive
as Turing Machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4518</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4518</id><created>2010-07-26</created><authors><author><keyname>Cullinan</keyname><forenames>M. P.</forenames></author></authors><title>Piecewise Convex-Concave Approximation in the $\ell_{\infty}$ Norm</title><categories>cs.NA</categories><comments>33 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that $\ff \in \reals^{n}$ is a vector of $n$ error-contaminated
measurements of $n$ smooth values measured at distinct and strictly ascending
abscissae. The following projective technique is proposed for obtaining a
vector of smooth approximations to these values. Find \yy\ minimizing $\| \yy -
\ff \|_{\infty}$ subject to the constraints that the second order consecutive
divided differences of the components of \yy\ change sign at most $q$ times.
This optimization problem (which is also of general geometrical interest) does
not suffer from the disadvantage of the existence of purely local minima and
allows a solution to be constructed in $O(nq)$ operations. A new algorithm for
doing this is developed and its effectiveness is proved. Some of the results of
applying it to undulating and peaky data are presented, showing that it is
economical and can give very good results, particularly for large
densely-packed data, even when the errors are quite large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4523</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4523</id><created>2010-07-26</created><authors><author><keyname>Yoneyama</keyname><forenames>Teruhiko</forenames></author><author><keyname>Das</keyname><forenames>Sanmay</forenames></author><author><keyname>Krishnamoorthy</keyname><forenames>Mukkai</forenames></author></authors><title>A Hybrid Model for Disease Spread and an Application to the SARS
  Pandemic</title><categories>cs.MA q-bio.OT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pandemics can cause immense disruption and damage to communities and
societies. Thus far, modeling of pandemics has focused on either large-scale
difference equation models like the SIR and the SEIR models, or detailed
micro-level simulations, which are harder to apply at a global scale. This
paper introduces a hybrid model for pandemics considering both global and local
spread of infections. We hypothesize that the spread of an infectious disease
between regions is significantly influenced by global traffic patterns and the
spread within a region is influenced by local conditions. Thus we model the
spread of pandemics considering the connections between regions for the global
spread of infection and population density based on the SEIR model for the
local spread of infection. We validate our hybrid model by carrying out a
simulation study for the spread of SARS pandemic of 2002-2003 using available
data on population, population density, and traffic networks between different
regions. While it is well-known that international relationships and global
traffic patterns significantly influence the spread of pandemics, our results
show that integrating these factors into relatively simple models can greatly
improve the results of modeling disease spread.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4527</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4527</id><created>2010-07-26</created><authors><author><keyname>Savir</keyname><forenames>Yonatan</forenames></author><author><keyname>Tlusty</keyname><forenames>Tsvi</forenames></author></authors><title>Optimal Design of a Molecular Recognizer: Molecular Recognition as a
  Bayesian Signal Detection Problem</title><categories>q-bio.MN cs.IT math.IT physics.bio-ph</categories><comments>Bayesian detection, conformational changes, molecular recognition,
  specificity. http://www.weizmann.ac.il/complex/tlusty/papers/IEEE2008.pdf</comments><journal-ref>IEEE Journal of Selected Topics in Signal Processing, vol. 2,
  issue 3, pp. 390-399, 2008</journal-ref><doi>10.1109/JSTSP.2008.923859</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous biological functions-such as enzymatic catalysis, the immune
response system, and the DNA-protein regulatory network-rely on the ability of
molecules to specifically recognize target molecules within a large pool of
similar competitors in a noisy biochemical environment. Using the basic
framework of signal detection theory, we treat the molecular recognition
process as a signal detection problem and examine its overall performance.
Thus, we evaluate the optimal properties of a molecular recognizer in the
presence of competition and noise. Our analysis reveals that the optimal design
undergoes a &quot;phase transition&quot; as the structural properties of the molecules
and interaction energies between them vary. In one phase, the recognizer should
be complementary in structure to its target (like a lock and a key), while in
the other, conformational changes upon binding, which often accompany molecular
recognition, enhance recognition quality. Using this framework, the abundance
of conformational changes may be explained as a result of increasing the
fitness of the recognizer. Furthermore, this analysis may be used in future
design of artificial signal processing devices based on biomolecules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4531</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4531</id><created>2010-07-26</created><updated>2010-10-18</updated><authors><author><keyname>Fishbain</keyname><forenames>Barak</forenames></author><author><keyname>Hochbaum</keyname><forenames>Dorit S.</forenames></author><author><keyname>Mueller</keyname><forenames>Stefan</forenames></author></authors><title>Competitive Analysis of Minimum-Cut Maximum Flow Algorithms in Vision
  Problems</title><categories>cs.CV cs.DM math.CO math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapid advances in image acquisition and storage technology underline the need
for algorithms that are capable of solving large scale image processing and
computer-vision problems. The minimum cut problem plays an important role in
processing many of these imaging problems such as, image and video
segmentation, stereo vision, multi-view reconstruction and surface fitting.
While several min-cut/max-flow algorithms can be found in the literature, their
performance in practice has been studied primarily outside the scope of
computer vision. We present here the results of a comprehensive computational
study, in terms of execution times and memory utilization, of four recently
published algorithms, which optimally solve the {\em s-t} cut and maximum flow
problems: (i) Goldberg's and Tarjan's {\em Push-Relabel}; (ii) Hochbaum's {\em
pseudoflow}; (iii) Boykov's and Kolmogorov's {\em augmenting paths}; and (iv)
Goldberg's {\em partial augment-relabel}. Our results demonstrate that the {\em
Hochbaum's pseudoflow} algorithm, is faster and utilizes less memory than the
other algorithms on all problem instances investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4540</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4540</id><created>2010-07-26</created><authors><author><keyname>Braginskiy</keyname><forenames>Evgeniy</forenames><affiliation>Shitz</affiliation></author><author><keyname>Steiner</keyname><forenames>Avi</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Broadcast Approach and Oblivious Cooperative Strategies for the Wireless
  Relay Channel - Part I: Sequential Decode-and-Forward (SDF)</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. On Wireless communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this two part paper we consider a wireless network in which a source
terminal communicates with a destination and a relay terminal is occasionally
present in close proximity to the source without source's knowledge, suggesting
oblivious protocols. The source-relay channel is assumed to be a fixed gain
AWGN due to the proximity while the source-destination and the
relay-destination channels are subject to a block flat Rayleigh fading. A
perfect CSI at the respective receivers only is assumed. With the average
throughput as a performance measure, we incorporate a two-layer broadcast
approach into two cooperative strategies based on the decode-and-forward scheme
- Sequential Decoded-and Forward (SDF) in part I and the Block-Markov (BM) in
part II. The broadcast approach splits the transmitted rate into superimposed
layers corresponding to a &quot;bad&quot; and a &quot;good&quot; channel states, allowing better
adaptation to the actual channel conditions In part I, the achievable rate
expressions for the SDF strategy are derived under the broadcast approach for
multiple settings including single user, MISO and the general relay setting
using successive decoding technique, both numerically and analytically.
Continuous broadcasting lower bounds are derived for the MISO and an oblivious
cooperation scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4542</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4542</id><created>2010-07-26</created><authors><author><keyname>Braginskiy</keyname><forenames>Evgeniy</forenames><affiliation>Shitz</affiliation></author><author><keyname>Steiner</keyname><forenames>Avi</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Broadcast Approach and Oblivious Cooperative Strategies for the Wireless
  Relay Channel - Part II: Block-Markov Decode-and-Forward (BMDF)</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the second in a two part series of papers on incorporation of the
broadcast approach into oblivious protocols for the relay channel where the
source and the relay are collocated. Part I described the broadcast approach
and its benefits in terms of achievable rates when used with the sequential
decode- and-forward (SDF) scheme. Part II investigates yet another oblivious
scheme, the Block-Markov decode- and-forward (BMDF) under the single and
two-layered transmissions. For the single layer, previously reported results
are enhanced and a conjecture regarding the optimal correlation coefficient
between the source and the relay's transmission is established. For the
discrete multi-layer transmission of two or more layers, it is shown that
perfect cooperation (2x1 MISO) rates are attained even with low collocation
gains at the expense of a longer delay, improving upon those achievable by the
SDF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4586</identifier>
 <datestamp>2012-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4586</id><created>2010-07-26</created><updated>2012-03-06</updated><authors><author><keyname>Jain</keyname><forenames>Kamal</forenames></author><author><keyname>Vazirani</keyname><forenames>Vijay</forenames></author></authors><title>Equilibrium Pricing of Semantically Substitutable Digital Goods</title><categories>cs.GT</categories><comments>This is a newer version with some more explanations and refinements
  added</comments><msc-class>91</msc-class><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of arriving at a principled method of pricing goods and services
was very satisfactorily solved for conventional goods; however, this solution
is not applicable to digital goods. This paper studies pricing of a special
class of digital goods, which we call {\em semantically substitutable digital
goods}. After taking into consideration idiosyncrasies of goods in this class,
we define a market model for it, together with a notion of equilibrium. We
prove existence of equilibrium prices for our market model using Kakutani's
fixed point theorem.
  The far reaching significance of a competitive equilibrium is made explicit
in the Fundamental Theorems of Welfare Economics. There are basic reasons due
to which these theorems are not applicable to digital goods. This naturally
leads to the question of whether the allocations of conventional goods are
rendered inefficient or &quot;socially unfair&quot; in the mixed economy we have
proposed. We prove that that is not the case and that in this sense, the
intended goal of Welfare Economics is still achieved in the mixed economy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4591</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4591</id><created>2010-07-26</created><updated>2011-02-10</updated><authors><author><keyname>Yokota</keyname><forenames>Rio</forenames></author><author><keyname>Bardhan</keyname><forenames>Jaydeep P.</forenames></author><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author><author><keyname>Barba</keyname><forenames>L. A.</forenames></author><author><keyname>Hamada</keyname><forenames>Tsuyoshi</forenames></author></authors><title>Biomolecular electrostatics using a fast multipole BEM on up to 512 GPUs
  and a billion unknowns</title><categories>cs.CE physics.chem-ph physics.comp-ph</categories><journal-ref>Comput. Phys. Commun., 182(6):1271-1283 (2011)</journal-ref><doi>10.1016/j.cpc.2011.02.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present teraflop-scale calculations of biomolecular electrostatics enabled
by the combination of algorithmic and hardware acceleration. The algorithmic
acceleration is achieved with the fast multipole method (FMM) in conjunction
with a boundary element method (BEM) formulation of the continuum electrostatic
model, as well as the BIBEE approximation to BEM. The hardware acceleration is
achieved through graphics processors, GPUs. We demonstrate the power of our
algorithms and software for the calculation of the electrostatic interactions
between biological molecules in solution. The applications demonstrated include
the electrostatics of protein--drug binding and several multi-million atom
systems consisting of hundreds to thousands of copies of lysozyme molecules.
The parallel scalability of the software was studied in a cluster at the
Nagasaki Advanced Computing Center, using 128 nodes, each with 4 GPUs. Delicate
tuning has resulted in strong scaling with parallel efficiency of 0.8 for 256
and 0.5 for 512 GPUs. The largest application run, with over 20 million atoms
and one billion unknowns, required only one minute on 512 GPUs. We are
currently adapting our BEM software to solve the linearized Poisson-Boltzmann
equation for dilute ionic solutions, and it is also designed to be flexible
enough to be extended for a variety of integral equation problems, ranging from
Poisson problems to Helmholtz problems in electromagnetics and acoustics to
high Reynolds number flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4602</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4602</id><created>2010-07-26</created><updated>2011-02-04</updated><authors><author><keyname>Zhang</keyname><forenames>Jian</forenames></author><author><keyname>Chen</keyname><forenames>Chaomei</forenames></author><author><keyname>Vogeley</keyname><forenames>Michael S.</forenames></author></authors><title>The Use of Scientific Data: A Content Analysis</title><categories>astro-ph.IM cs.DL</categories><comments>This paper has been withdrawn by the authors. To appear in
  publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, science has been coming into a new paradigm, called data-intensive
science. While current studies of the new phenomenon focused on building up
infrastructure for this new paradigm, yet a few studies concern users of
scientific data, particularly their usage practices in the newly emerging
paradigm, even though the importance of understanding users' work flow and
practices has been summoned. This study endeavors to improve our understanding
of users' data usage behavior through a content analysis of publications in a
frequently cited new paradigm-related project, Sloan Digital Sky Survey (SDSS).
We found that (1) nearly half studies used one data source only. A few studies
exploited three or more data sources; (2) the number of objects that were
analyzed in SDSS publications is in all scales from one digit to millions; (3)
different paper types may affect the data usage patterns; (4) Users are not
only consumers of scientific data. They are producers too; (5) studies that can
use multiple large scale data sources are relative rare. Issues of data
provenance, trust, and usability may prevent researchers from doing this kind
of research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4604</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4604</id><created>2010-07-26</created><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author><author><keyname>Marcus</keyname><forenames>Brian</forenames></author></authors><title>Concavity of Mutual Information Rate for Input-Restricted Finite-State
  Memoryless Channels at High SNR</title><categories>cs.IT math.IT</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a finite-state memoryless channel with i.i.d. channel state and
the input Markov process supported on a mixing finite-type constraint. We
discuss the asymptotic behavior of entropy rate of the output hidden Markov
chain and deduce that the mutual information rate of such a channel is concave
with respect to the parameters of the input Markov processes at high
signal-to-noise ratio. In principle, the concavity result enables good
numerical approximation of the maximum mutual information rate and capacity of
such a channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4606</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4606</id><created>2010-07-26</created><authors><author><keyname>Zhao</keyname><forenames>Qingchun</forenames></author><author><keyname>Yin</keyname><forenames>Hongxi</forenames></author></authors><title>Gbits/s physical-layer stream ciphers based on chaotic light</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose a novel high-speed stream cipher encryption scheme based on the
true random key generated by a chaotic semiconductor laser. A 5-Gbits/s
non-return-to-zero plaintext is successfully encrypted and decrypted using this
cryptography. The scheme can be applied in the areas of real-time high-speed
physical encryption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4636</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4636</id><created>2010-07-27</created><updated>2010-11-15</updated><authors><author><keyname>Durrett</keyname><forenames>Greg</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author><author><keyname>O'Reilly</keyname><forenames>Una-May</forenames></author></authors><title>Computational Complexity Analysis of Simple Genetic Programming On Two
  Problems Modeling Isolated Program Semantics</title><categories>cs.NE cs.CC cs.DS</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing the computational complexity of evolutionary algorithms for binary
search spaces has significantly increased their theoretical understanding. With
this paper, we start the computational complexity analysis of genetic
programming. We set up several simplified genetic programming algorithms and
analyze them on two separable model problems, ORDER and MAJORITY, each of which
captures an important facet of typical genetic programming problems. Both
analyses give first rigorous insights on aspects of genetic programming design,
highlighting in particular the impact of accepting or rejecting neutral moves
and the importance of a local mutation operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4660</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4660</id><created>2010-07-27</created><authors><author><keyname>Vuckovac</keyname><forenames>Rade</forenames></author></authors><title>About functions where function input describes inner working of the
  function</title><categories>cs.CC</categories><comments>9 pages, 8 figures draft only</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper argues an existence of a class of functions where function own
input makes function description. That fact have impact to the wide spectrum of
phenomena such as negative findings of Random Oracle Model in cryptography,
complexity in some rules of cellular automata (Wolfram rule 30) and determinism
in the true randomness to name just a few.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4663</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4663</id><created>2010-07-27</created><authors><author><keyname>Pan</keyname><forenames>Zan</forenames></author></authors><title>The Multiple Permutation Problem and Some Conjectures</title><categories>cs.DM math.CO</categories><comments>LaTeX, 16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we proposed an interesting problem that might be classified
into enumerative combinatorics. Featuring a distinctive two-fold dependence
upon the sequences' terms, our problem can be really difficult, which calls for
novel approaches to work it out for any given pair $(m,n)$. Complete or partial
solutions for $m=2, 3$ with smaller $n$'s are listed. Moreover, we have proved
the necessary condition for $p(m,n) \neq 0$ and suggested an elegant asymptotic
formula for $p(2,n)$. In addition, several challenging conjectures are
provided, together with concise comments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4707</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4707</id><created>2010-07-27</created><authors><author><keyname>K&#xf6;tzing</keyname><forenames>Timo</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author><author><keyname>Sudholt</keyname><forenames>Dirk</forenames></author><author><keyname>Wagner</keyname><forenames>Markus</forenames></author></authors><title>Simple Max-Min Ant Systems and the Optimization of Linear Pseudo-Boolean
  Functions</title><categories>cs.NE</categories><comments>19 pages, 2 figures</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With this paper, we contribute to the understanding of ant colony
optimization (ACO) algorithms by formally analyzing their runtime behavior. We
study simple MAX-MIN ant systems on the class of linear pseudo-Boolean
functions defined on binary strings of length 'n'. Our investigations point out
how the progress according to function values is stored in pheromone. We
provide a general upper bound of O((n^3 \log n)/ \rho) for two ACO variants on
all linear functions, where (\rho) determines the pheromone update strength.
Furthermore, we show improved bounds for two well-known linear pseudo-Boolean
functions called OneMax and BinVal and give additional insights using an
experimental study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4723</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4723</id><created>2010-07-27</created><authors><author><keyname>Waskita</keyname><forenames>A. A.</forenames></author><author><keyname>Prasetyo</keyname><forenames>N. A.</forenames></author><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>Public Infrastructure for Monte Carlo Simulation: publicMC@BATAN</title><categories>cs.DC</categories><comments>6 pages</comments><report-no>FISIKALIPI-09031</report-no><journal-ref>AIP Conf. Proc. 1244 (2010) 190-195</journal-ref><doi>10.1063/1.3462759</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first cluster-based public computing for Monte Carlo simulation in
Indonesia is introduced. The system has been developed to enable public to
perform Monte Carlo simulation on a parallel computer through an integrated and
user friendly dynamic web interface. The beta version, so called
publicMC@BATAN, has been released and implemented for internal users at the
National Nuclear Energy Agency (BATAN). In this paper the concept and
architecture of publicMC@BATAN are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4724</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4724</id><created>2010-07-27</created><authors><author><keyname>Jindal</keyname><forenames>Apoorva</forenames></author><author><keyname>Psounis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>CapEst: A Measurement-based Approach to Estimating Link Capacity in
  Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating link capacity in a wireless network is a complex task because the
available capacity at a link is a function of not only the current arrival rate
at that link, but also of the arrival rate at links which interfere with that
link as well as of the nature of interference between these links. Models which
accurately characterize this dependence are either too computationally complex
to be useful or lack accuracy. Further, they have a high implementation
overhead and make restrictive assumptions, which makes them inapplicable to
real networks.
  In this paper, we propose CapEst, a general, simple yet accurate,
measurement-based approach to estimating link capacity in a wireless network.
To be computationally light, CapEst allows inaccuracy in estimation; however,
using measurements, it can correct this inaccuracy in an iterative fashion and
converge to the correct estimate. Our evaluation shows that CapEst always
converged to within 5% of the correct value in less than 18 iterations. CapEst
is model-independent, hence, is applicable to any MAC/PHY layer and works with
auto-rate adaptation. Moreover, it has a low implementation overhead, can be
used with any application which requires an estimate of residual capacity on a
wireless link and can be implemented completely at the network layer without
any support from the underlying chipset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4748</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4748</id><created>2010-07-27</created><authors><author><keyname>Culotta</keyname><forenames>Aron</forenames></author></authors><title>Detecting influenza outbreaks by analyzing Twitter messages</title><categories>cs.IR cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze over 500 million Twitter messages from an eight month period and
find that tracking a small number of flu-related keywords allows us to forecast
future influenza rates with high accuracy, obtaining a 95% correlation with
national health statistics. We then analyze the robustness of this approach to
spurious keyword matches, and we propose a document classification component to
filter these misleading messages. We find that this document classifier can
reduce error rates by over half in simulated false alarm experiments, though
more research is needed to develop methods that are robust in cases of
extremely high noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4749</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4749</id><created>2010-07-27</created><updated>2010-09-22</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>How fractional counting affects the Impact Factor: Normalization in
  terms of differences in citation potentials among fields of science</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ISI-Impact Factors suffer from a number of drawbacks, among them the
statistics-why should one use the mean and not the median?-and the
incomparability among fields of science because of systematic differences in
citation behavior among fields. Can these drawbacks be counteracted by counting
citation weights fractionally instead of using whole numbers in the numerators?
(i) Fractional citation counts are normalized in terms of the citing sources
and thus would take into account differences in citation behavior among fields
of science. (ii) Differences in the resulting distributions can be tested
statistically for their significance at different levels of aggregation. (iii)
Fractional counting can be generalized to any document set including journals
or groups of journals, and thus the significance of differences among both
small and large sets can be tested. A list of fractionally counted Impact
Factors for 2008 is available online at
http://www.leydesdorff.net/weighted_if/weighted_if.xls. The in-between group
variance among the thirteen fields of science identified in the U.S. Science
and Engineering Indicators is not statistically significant after this
normalization. Although citation behavior differs largely between disciplines,
the reflection of these differences in fractionally counted citation
distributions could not be used as a reliable instrument for the
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4764</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4764</id><created>2010-07-27</created><updated>2010-09-07</updated><authors><author><keyname>Bollig</keyname><forenames>Benedikt</forenames><affiliation>LSV, ENS Cachan, CNRS</affiliation></author><author><keyname>Kuske</keyname><forenames>Dietrich</forenames><affiliation>Institut f&#xfc;r Informatik, Universit&#xe4;t Leipzig</affiliation></author><author><keyname>Meinecke</keyname><forenames>Ingmar</forenames><affiliation>Institut f&#xfc;r Informatik, Universit&#xe4;t Leipzig</affiliation></author></authors><title>Propositional Dynamic Logic for Message-Passing Systems</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  4, 2010) lmcs:1057</journal-ref><doi>10.2168/LMCS-6(3:16)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine a bidirectional propositional dynamic logic (PDL) for finite and
infinite message sequence charts (MSCs) extending LTL and TLC-. By this kind of
multi-modal logic we can express properties both in the entire future and in
the past of an event. Path expressions strengthen the classical until operator
of temporal logic. For every formula defining an MSC language, we construct a
communicating finite-state machine (CFM) accepting the same language. The CFM
obtained has size exponential in the size of the formula. This synthesis
problem is solved in full generality, i.e., also for MSCs with unbounded
channels. The model checking problem for CFMs and HMSCs turns out to be in
PSPACE for existentially bounded MSCs. Finally, we show that, for PDL with
intersection, the semantics of a formula cannot be captured by a CFM anymore.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4767</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4767</id><created>2010-07-27</created><updated>2011-02-10</updated><authors><author><keyname>Balduccini</keyname><forenames>Marcello</forenames></author><author><keyname>Girotto</keyname><forenames>Sara</forenames></author></authors><title>Formalization of Psychological Knowledge in Answer Set Programming and
  its Application</title><categories>cs.AI cs.LO</categories><comments>26th Int'l. Conference on Logic Programming (ICLP'10)</comments><journal-ref>Theory and Practice of Logic Programming, 10(4-6), 725-740, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore the use of Answer Set Programming (ASP) to
formalize, and reason about, psychological knowledge. In the field of
psychology, a considerable amount of knowledge is still expressed using only
natural language. This lack of a formalization complicates accurate studies,
comparisons, and verification of theories. We believe that ASP, a knowledge
representation formalism allowing for concise and simple representation of
defaults, uncertainty, and evolving domains, can be used successfully for the
formalization of psychological knowledge. To demonstrate the viability of ASP
for this task, in this paper we develop an ASP-based formalization of the
mechanics of Short-Term Memory. We also show that our approach can have rather
immediate practical uses by demonstrating an application of our formalization
to the task of predicting a user's interaction with a graphical interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4801</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4801</id><created>2010-07-27</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>MIMO Wiretap Channels with Arbitrarily Varying Eavesdropper Channel
  States</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, July 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a class of information theoretic secrecy problems is addressed
where the eavesdropper channel states are completely unknown to the legitimate
parties. In particular, MIMO wiretap channel models are considered where the
channel of the eavesdropper is arbitrarily varying over time. Assuming that the
number of antennas of the eavesdropper is limited, the secrecy rate of the MIMO
wiretap channel in the sense of strong secrecy is derived, and shown to match
with the converse in secure degrees of freedom. It is proved that there exists
a universal coding scheme that secures the confidential message against any
sequence of channel states experienced by the eavesdropper. This yields the
conclusion that secure communication is possible regardless of the location or
channel states of (potentially infinite number of) eavesdroppers. Additionally,
it is observed that, the present setting renders the secrecy capacity problems
for multi-terminal wiretap-type channels more tractable as compared the case
with full or partial knowledge of eavesdropper channel states. To demonstrate
this observation, secure degrees of freedom regions are derived for the
Gaussian MIMO multiple access wiretap channel (MIMO MAC-WT) and the Gaussian
MIMO broadcast wiretap channel (MIMO BC-WT) where the transmitter(s) and the
intended receiver(s) have the same number of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4840</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4840</id><created>2010-07-27</created><authors><author><keyname>Li</keyname><forenames>Qiao</forenames></author><author><keyname>Negi</keyname><forenames>Rohit</forenames></author></authors><title>Greedy Maximal Scheduling in Wireless Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages, 3 figures. A shorter version will appear in IEEE Globecom
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider greedy scheduling algorithms in wireless networks,
i.e., the schedules are computed by adding links greedily based on some
priority vector. Two special cases are considered: 1) Longest Queue First (LQF)
scheduling, where the priorities are computed using queue lengths, and 2)
Static Priority (SP) scheduling, where the priorities are pre-assigned. We
first propose a closed-form lower bound stability region for LQF scheduling,
and discuss the tightness result in some scenarios. We then propose an lower
bound stability region for SP scheduling with multiple priority vectors, as
well as a heuristic priority assignment algorithm, which is related to the
well-known Expectation-Maximization (EM) algorithm. The performance gain of the
proposed heuristic algorithm is finally confirmed by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4853</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4853</id><created>2010-07-27</created><updated>2010-08-03</updated><authors><author><keyname>Farhi</keyname><forenames>Nadir</forenames></author><author><keyname>Gaujal</keyname><forenames>Bruno</forenames></author></authors><title>Performance bounds in wormhole routing, a network calculus approach</title><categories>cs.PF cs.NI math.OC</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a model of performance bound calculus on feedforward networks
where data packets are routed under wormhole routing discipline. We are
interested in determining maximum end-to-end delays and backlogs of messages or
packets going from a source node to a destination node, through a given virtual
path in the network. Our objective here is to give a network calculus approach
for calculating the performance bounds. First we propose a new concept of
curves that we call packet curves. The curves permit to model constraints on
packet lengths of a given data flow, when the lengths are allowed to be
different. Second, we use this new concept to propose an approach for
calculating residual services for data flows served under non preemptive
service disciplines. Third, we model a binary switch (with two input ports and
two output ports), where data is served under wormhole discipline. We present
our approach for computing the residual services and deduce the worst case
bounds for flows passing through a wormhole binary switch. Finally, we
illustrate this approach in numerical examples, and show how to extend it to
feedforward networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4857</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4857</id><created>2010-07-27</created><authors><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>Short Note on Complexity of Multi-Value Byzantine Agreement</title><categories>cs.DC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized algorithm that achieves multi-valued Byzantine agreement with high
probability, and achieves optimal complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4864</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4864</id><created>2010-07-27</created><authors><author><keyname>Macko</keyname><forenames>Martin</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author><author><keyname>Steskal</keyname><forenames>&#x13d;ubo&#x161;</forenames></author></authors><title>Braess's Paradox for Flows Over Time</title><categories>cs.GT</categories><comments>19 pages, 6 figures, an extended version of paper accepted for SAGT
  2010</comments><doi>10.1007/978-3-642-16170-4_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the properties of Braess's paradox in the context of the model of
congestion games with flow over time introduced by Koch and Skutella. We
compare them to the well known properties of Braess's paradox for Wardrop's
model of games with static flows. We show that there are networks which do not
admit Braess's paradox in Wardrop's model, but which admit it in the model with
flow over time. Moreover, there is a topology that admits a much more severe
Braess's ratio for this model. Further, despite its symmetry for games with
static flow, we show that Braess's paradox is not symmetric for flows over
time. We illustrate that there are network topologies which exhibit Braess's
paradox, but for which the transpose does not. Finally, we conjecture a
necessary and sufficient condition of existence of Braess's paradox in a
network, and prove the condition of existence of the paradox either in the
network or in its transpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4868</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4868</id><created>2010-07-28</created><authors><author><keyname>Kharal</keyname><forenames>Athar</forenames></author></authors><title>Predicting Suicide Attacks: A Fuzzy Soft Set Approach</title><categories>cs.AI</categories><comments>Submitted manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper models a decision support system to predict the occurance of
suicide attack in a given collection of cities. The system comprises two parts.
First part analyzes and identifies the factors which affect the prediction.
Admitting incomplete information and use of linguistic terms by experts, as two
characteristic features of this peculiar prediction problem we exploit the
Theory of Fuzzy Soft Sets. Hence the Part 2 of the model is an algorithm vz.
FSP which takes the assessment of factors given in Part 1 as its input and
produces a possibility profile of cities likely to receive the accident. The
algorithm is of O(2^n) complexity. It has been illustrated by an example solved
in detail. Simulation results for the algorithm have been presented which give
insight into the strengths and weaknesses of FSP. Three different decision
making measures have been simulated and compared in our discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4872</identifier>
 <datestamp>2012-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4872</id><created>2010-07-28</created><updated>2012-10-24</updated><authors><author><keyname>Chandar</keyname><forenames>Venkat</forenames></author><author><keyname>Tchamkerten</keyname><forenames>Aslan</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Asynchronous Capacity per Unit Cost</title><categories>cs.IT math.IT</categories><comments>to be published in the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity per unit cost, or equivalently minimum cost to transmit one bit,
is a well-studied quantity. It has been studied under the assumption of full
synchrony between the transmitter and the receiver. In many applications, such
as sensor networks, transmissions are very bursty, with small amounts of bits
arriving infrequently at random times. In such scenarios, the cost of acquiring
synchronization is significant and one is interested in the fundamental limits
on communication without assuming a priori synchronization. In this paper, we
show that the minimum cost to transmit B bits of information asynchronously is
(B + \bar{H})k_sync, where k_sync is the synchronous minimum cost per bit and
\bar{H} is a measure of timing uncertainty equal to the entropy for most
reasonable arrival time distributions. This result holds when the transmitter
can stay idle at no cost and is a particular case of a general result which
holds for arbitrary cost functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4890</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4890</id><created>2010-07-28</created><updated>2010-07-30</updated><authors><author><keyname>Yuan</keyname><forenames>Lin</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Sang</keyname><forenames>Bo</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Wang</keyname><forenames>Haining</forenames></author></authors><title>PowerTracer: Tracing requests in multi-tier services to save cluster
  power consumption</title><categories>cs.DC</categories><comments>10 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As energy proportional computing gradually extends the success of DVFS
(Dynamic voltage and frequency scaling) to the entire system, DVFS control
algorithms will play a key role in reducing server clusters' power consumption.
The focus of this paper is to provide accurate cluster-level DVFS control for
power saving in a server cluster. To achieve this goal, we propose a request
tracing approach that online classifies the major causal path patterns of a
multi-tier service and monitors their performance data as a guide for accurate
DVFS control. The request tracing approach significantly decreases the time
cost of performance profiling experiments that aim to establish the empirical
performance model. Moreover, it decreases the controller complexity so that we
can introduce a much simpler feedback controller, which only relies on the
single-node DVFS modulation at a time as opposed to varying multiple CPU
frequencies simultaneously. Based on the request tracing approach, we present a
hybrid DVFS control system that combines an empirical performance model for
fast modulation at different load levels and a simpler feedback controller for
adaption. We implement a prototype of the proposed system, called PowerTracer,
and conduct extensive experiments on a 3-tier platform. Our experimental
results show that PowerTracer outperforms its peer in terms of power saving and
system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4908</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4908</id><created>2010-07-28</created><authors><author><keyname>Schneider-Kamp</keyname><forenames>Peter</forenames></author><author><keyname>Giesl</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Str&#xf6;der</keyname><forenames>Thomas</forenames></author><author><keyname>Serebrenik</keyname><forenames>Alexander</forenames></author><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>Automated Termination Analysis for Logic Programs with Cut</title><categories>cs.LO cs.PL</categories><journal-ref>Theory and Practice of Logic Programming, 10(4-6), 365-381, 2010</journal-ref><doi>10.1017/S1471068410000165</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Termination is an important and well-studied property for logic programs.
However, almost all approaches for automated termination analysis focus on
definite logic programs, whereas real-world Prolog programs typically use the
cut operator. We introduce a novel pre-processing method which automatically
transforms Prolog programs into logic programs without cuts, where termination
of the cut-free program implies termination of the original program. Hence
after this pre-processing, any technique for proving termination of definite
logic programs can be applied. We implemented this pre-processing in our
termination prover AProVE and evaluated it successfully with extensive
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4935</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4935</id><created>2010-07-28</created><updated>2011-01-01</updated><authors><author><keyname>Codish</keyname><forenames>Michael</forenames></author><author><keyname>Fekete</keyname><forenames>Yoav</forenames></author><author><keyname>Fuhs</keyname><forenames>Carsten</forenames></author><author><keyname>Schneider-Kamp</keyname><forenames>Peter</forenames></author></authors><title>Optimal Base Encodings for Pseudo-Boolean Constraints</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper formalizes the optimal base problem, presents an algorithm to
solve it, and describes its application to the encoding of Pseudo-Boolean
constraints to SAT. We demonstrate the impact of integrating our algorithm
within the Pseudo-Boolean constraint solver MINISAT+. Experimentation indicates
that our algorithm scales to bases involving numbers up to 1,000,000, improving
on the restriction in MINISAT+ to prime numbers up to 17. We show that, while
for many examples primes up to 17 do suffice, encoding with respect to optimal
bases reduces the CNF sizes and improves the subsequent SAT solving time for
many examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4955</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4955</id><created>2010-07-28</created><authors><author><keyname>Ruan</keyname><forenames>Liangzhong</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Decentralized Dynamic Hop Selection and Power Control in Cognitive
  Multi-hop Relay Systems</title><categories>cs.IT math.IT</categories><doi>10.1109/TWC.2010.081610.081319</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a cognitive multi-hop relay secondary user (SU)
system sharing the spectrum with some primary users (PU). The transmit power as
well as the hop selection of the cognitive relays can be dynamically adapted
according to the local (and causal) knowledge of the instantaneous channel
state information (CSI) in the multi-hop SU system. We shall determine a low
complexity, decentralized algorithm to maximize the average end-to-end
throughput of the SU system with dynamic spatial reuse. The problem is
challenging due to the decentralized requirement as well as the causality
constraint on the knowledge of CSI. Furthermore, the problem belongs to the
class of stochastic Network Utility Maximization (NUM) problems which is quite
challenging. We exploit the time-scale difference between the PU activity and
the CSI fluctuations and decompose the problem into a master problem and
subproblems. We derive an asymptotically optimal low complexity solution using
divide-and-conquer and illustrate that significant performance gain can be
obtained through dynamic hop selection and power control. The worst case
complexity and memory requirement of the proposed algorithm is O(M^2) and
O(M^3) respectively, where $M$ is the number of SUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4958</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4958</id><created>2010-07-28</created><updated>2011-02-14</updated><authors><author><keyname>Alur</keyname><forenames>Rajeev</forenames></author><author><keyname>Cerny</keyname><forenames>Pavol</forenames></author></authors><title>Algorithmic Verification of Single-Pass List Processing Programs</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce streaming data string transducers that map input data strings to
output data strings in a single left-to-right pass in linear time. Data strings
are (unbounded) sequences of data values, tagged with symbols from a finite
set, over a potentially infinite data domain that supports only the operations
of equality and ordering. The transducer uses a finite set of states, a finite
set of variables ranging over the data domain, and a finite set of variables
ranging over data strings. At every step, it can make decisions based on the
next input symbol, updating its state, remembering the input data value in its
data variables, and updating data-string variables by concatenating data-string
variables and new symbols formed from data variables, while avoiding
duplication. We establish that the problems of checking functional equivalence
of two streaming transducers, and of checking whether a streaming transducer
satisfies pre/post verification conditions specified by streaming acceptors
over input/output data-strings, are in PSPACE. We identify a class of
imperative and a class of functional programs, manipulating lists of data
items, which can be effectively translated to streaming data-string
transducers. The imperative programs dynamically modify a singly-linked heap by
changing next-pointers of heap-nodes and by adding new nodes. The main
restriction specifies how the next-pointers can be used for traversal. We also
identify an expressively equivalent fragment of functional programs that
traverse a list using syntactically restricted recursive calls. Our results
lead to algorithms for assertion checking and for checking functional
equivalence of two programs, written possibly in different programming styles,
for commonly used routines such as insert, delete, and reverse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4971</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4971</id><created>2010-07-28</created><authors><author><keyname>Oetsch</keyname><forenames>Johannes</forenames></author><author><keyname>P&#xfc;hrer</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Schwengerer</keyname><forenames>Martin</forenames></author><author><keyname>Tompits</keyname><forenames>Hans</forenames></author></authors><title>The System Kato: Detecting Cases of Plagiarism for Answer-Set Programs</title><categories>cs.LO</categories><journal-ref>Theory and Practice of Logic Programming, Volume 10, Special Issue
  4-6, July 2010, pp 759-775</journal-ref><doi>10.1017/S1471068410000402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plagiarism detection is a growing need among educational institutions and
solutions for different purposes exist. An important field in this direction is
detecting cases of source-code plagiarism. In this paper, we present the tool
Kato for supporting the detection of this kind of plagiarism in the area of
answer-set programming (ASP). Currently, the tool is implemented for DLV
programs but it is designed to handle other logic-programming dialects as well.
We review the basic features of Kato, introduce its theoretical underpinnings,
and discuss an application of Kato for plagiarism detection in the context of
courses on logic programming at the Vienna University of Technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4986</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4986</id><created>2010-07-28</created><authors><author><keyname>Oetsch</keyname><forenames>Johannes</forenames></author><author><keyname>P&#xfc;hrer</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Tompits</keyname><forenames>Hans</forenames></author></authors><title>Catching the Ouroboros: On Debugging Non-ground Answer-Set Programs</title><categories>cs.PL</categories><journal-ref>Theory and Practice of Logic Programming, Volume 10, Special Issue
  4-6, July 2010, pp 513-529</journal-ref><doi>10.1017/S1471068410000256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important issue towards a broader acceptance of answer-set programming
(ASP) is the deployment of tools which support the programmer during the coding
phase. In particular, methods for debugging an answer-set program are
recognised as a crucial step in this regard. Initial work on debugging in ASP
mainly focused on propositional programs, yet practical debuggers need to
handle programs with variables as well. In this paper, we discuss a debugging
technique that is directly geared towards non-ground programs. Following
previous work, we address the central debugging question why some
interpretation is not an answer set. The explanations provided by our method
are computed by means of a meta-programming technique, using a uniform encoding
of a debugging request in terms of ASP itself. Our method also permits programs
containing comparison predicates and integer arithmetics, thus covering a
relevant language class commonly supported by all state-of-the-art ASP solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.4993</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.4993</id><created>2010-07-28</created><authors><author><keyname>Mousavi</keyname><forenames>MohammadReza</forenames><affiliation>Eindhoven University of Technology</affiliation></author><author><keyname>Sala&#xfc;n</keyname><forenames>Gwen</forenames><affiliation>INRIA Grenoble - Rhone-Alpes</affiliation></author></authors><title>Proceedings Ninth International Workshop on the Foundations of
  Coordination Languages and Software Architectures</title><categories>cs.SE cs.DC cs.LO cs.PL</categories><proxy>EPTCS</proxy><acm-class>D.2.11; D.3.1; D.2.4; F.3.1; F.3.2</acm-class><journal-ref>EPTCS 30, 2010</journal-ref><doi>10.4204/EPTCS.30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of FOCLASA 2010, the 9th International
Workshop on the Foundations of Coordination Languages and Software
Architectures. FOCLASA 2010 was held in Paris, France on July 30th, 2010 as a
satellite event of the 21st International Conference on Concurrency Theory,
CONCUR 2010. The papers presented in this proceedings tackle different issues
that are currently central to our community, namely software adaptation, sensor
networks, distributed control, non-functional aspects of coordination such as
resources, timing and stochastics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5004</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5004</id><created>2010-07-28</created><authors><author><keyname>Treust</keyname><forenames>Mael Le</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author></authors><title>A Repeated Game Formulation of Energy-Efficient Decentralized Power
  Control</title><categories>math-ph cs.GT cs.IT math.IT math.MP</categories><comments>25 pages, 5 figures, accepted for publication in IEEE Transaction on
  Wireless Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decentralized multiple access channels where each transmitter wants to
selfishly maximize his transmission energy-efficiency are considered.
Transmitters are assumed to choose freely their power control policy and
interact (through multiuser interference) several times. It is shown that the
corresponding conflict of interest can have a predictable outcome, namely a
finitely or discounted repeated game equilibrium. Remarkably, it is shown that
this equilibrium is Pareto-efficient under reasonable sufficient conditions and
the corresponding decentralized power control policies can be implemented under
realistic information assumptions: only individual channel state information
and a public signal are required to implement the equilibrium strategies.
Explicit equilibrium conditions are derived in terms of minimum number of game
stages or maximum discount factor. Both analytical and simulation results are
provided to compare the performance of the proposed power control policies with
those already existing and exploiting the same information assumptions namely,
those derived for the one-shot and Stackelberg games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5024</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5024</id><created>2010-07-28</created><authors><author><keyname>Delgrande</keyname><forenames>James P.</forenames></author></authors><title>A Program-Level Approach to Revising Logic Programs under the Answer Set
  Semantics</title><categories>cs.AI</categories><journal-ref>Theory and Practice of Logic Programming, 10, 4--6, 2010, pp.
  565-580</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approach to the revision of logic programs under the answer set semantics
is presented. For programs P and Q, the goal is to determine the answer sets
that correspond to the revision of P by Q, denoted P * Q. A fundamental
principle of classical (AGM) revision, and the one that guides the approach
here, is the success postulate. In AGM revision, this stipulates that A is in K
* A. By analogy with the success postulate, for programs P and Q, this means
that the answer sets of Q will in some sense be contained in those of P * Q.
The essential idea is that for P * Q, a three-valued answer set for Q,
consisting of positive and negative literals, is first determined. The positive
literals constitute a regular answer set, while the negated literals make up a
minimal set of naf literals required to produce the answer set from Q. These
literals are propagated to the program P, along with those rules of Q that are
not decided by these literals. The approach differs from work in update logic
programs in two main respects. First, we ensure that the revising logic program
has higher priority, and so we satisfy the success postulate; second, for the
preference implicit in a revision P * Q, the program Q as a whole takes
precedence over P, unlike update logic programs, since answer sets of Q are
propagated to P. We show that a core group of the AGM postulates are satisfied,
as are the postulates that have been proposed for update logic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5030</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5030</id><created>2010-07-28</created><authors><author><keyname>Blanchet</keyname><forenames>Jose</forenames></author><author><keyname>Leder</keyname><forenames>Kevin</forenames></author><author><keyname>Shi</keyname><forenames>Yixi</forenames></author></authors><title>Analysis of a Splitting Estimator for Rare Event Probabilities in
  Jackson Networks</title><categories>math.PR cs.CE stat.CO</categories><comments>23 pages</comments><msc-class>82C80, 90B15, 60K25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a standard splitting algorithm for the rare-event simulation of
overflow probabilities in any subset of stations in a Jackson network at level
n, starting at a fixed initial position. It was shown in DeanDup09 that a
subsolution to the Isaacs equation guarantees that a subexponential number of
function evaluations (in n) suffice to estimate such overflow probabilities
within a given relative accuracy. Our analysis here shows that in fact
O(n^{2{\beta}+1}) function evaluations suffice to achieve a given relative
precision, where {\beta} is the number of bottleneck stations in the network.
This is the first rigorous analysis that allows to favorably compare splitting
against directly computing the overflow probability of interest, which can be
evaluated by solving a linear system of equations with O(n^{d}) variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5032</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5032</id><created>2010-07-28</created><updated>2011-04-28</updated><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Kesselheim</keyname><forenames>Thomas</forenames></author><author><keyname>V&#xf6;cking</keyname><forenames>Berthold</forenames></author></authors><title>Approximation Algorithms for Secondary Spectrum Auctions</title><categories>cs.DS cs.GT cs.NI</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study combinatorial auctions for the secondary spectrum market. In this
market, short-term licenses shall be given to wireless nodes for communication
in their local neighborhood. In contrast to the primary market, channels can be
assigned to multiple bidders, provided that the corresponding devices are well
separated such that the interference is sufficiently low. Interference
conflicts are described in terms of a conflict graph in which the nodes
represent the bidders and the edges represent conflicts such that the feasible
allocations for a channel correspond to the independent sets in the conflict
graph.
  In this paper, we suggest a novel LP formulation for combinatorial auctions
with conflict graph using a non-standard graph parameter, the so-called
inductive independence number. Taking into account this parameter enables us to
bypass the well-known lower bound of \Omega(n^{1-\epsilon}) on the
approximability of independent set in general graphs with n nodes (bidders). We
achieve significantly better approximation results by showing that interference
constraints for wireless networks yield conflict graphs with bounded inductive
independence number.
  Our framework covers various established models of wireless communication,
e.g., the protocol or the physical model. For the protocol model, we achieve an
O(\sqrt{k})-approximation, where k is the number of available channels. For the
more realistic physical model, we achieve an O(\sqrt{k} \log^2 n) approximation
based on edge-weighted conflict graphs. Combining our approach with the the
LP-based framework of Lavi and Swamy, we obtain incentive compatible mechanisms
for general bidders with arbitrary valuations on bundles of channels specified
in terms of demand oracles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5044</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5044</id><created>2010-07-28</created><authors><author><keyname>Leong</keyname><forenames>Derek</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Symmetric Allocations for Distributed Storage</title><categories>cs.IT math.IT</categories><comments>7 pages, 3 figures, extended version of an IEEE GLOBECOM 2010 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of optimally allocating a given total storage budget
in a distributed storage system. A source has a data object which it can code
and store over a set of storage nodes; it is allowed to store any amount of
coded data in each node, as long as the total amount of storage used does not
exceed the given budget. A data collector subsequently attempts to recover the
original data object by accessing each of the nodes independently with some
constant probability. By using an appropriate code, successful recovery occurs
when the total amount of data in the accessed nodes is at least the size of the
original data object. The goal is to find an optimal storage allocation that
maximizes the probability of successful recovery. This optimization problem is
challenging because of its discrete nature and nonconvexity, despite its simple
formulation. Symmetric allocations (in which all nonempty nodes store the same
amount of data), though intuitive, may be suboptimal; the problem is nontrivial
even if we optimize over only symmetric allocations. Our main result shows that
the symmetric allocation that spreads the budget maximally over all nodes is
asymptotically optimal in a regime of interest. Specifically, we derive an
upper bound for the suboptimality of this allocation and show that the
performance gap vanishes asymptotically in the specified regime. Further, we
explicitly find the optimal symmetric allocation for a variety of cases. Our
results can be applied to distributed storage systems and other problems
dealing with reliability under uncertainty, including delay tolerant networks
(DTNs) and content delivery networks (CDNs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5080</identifier>
 <datestamp>2012-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5080</id><created>2010-07-28</created><updated>2012-08-29</updated><authors><author><keyname>Park</keyname><forenames>Jihoon</forenames></author><author><keyname>Pawe&#x142;czak</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Gr&#xf8;nsund</keyname><forenames>P&#xe5;l</forenames></author><author><keyname>&#x10c;abri&#x107;</keyname><forenames>Danijela</forenames></author></authors><title>Analysis Framework for Opportunistic Spectrum OFDMA and its Application
  to the IEEE 802.22 Standard</title><categories>cs.NI cs.IT cs.PF math.IT</categories><journal-ref>IEEE Transactions on Vehicular Technology, vol. 61, no. 5, pp.
  2271-2293, 2012</journal-ref><doi>10.1109/TVT.2012.2188550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analytical model that enables throughput evaluation of
Opportunistic Spectrum Orthogonal Frequency Division Multiple Access (OS-OFDMA)
networks. The core feature of the model, based on a discrete time Markov chain,
is the consideration of different channel and subchannel allocation strategies
under different Primary and Secondary user types, traffic and priority levels.
The analytical model also assesses the impact of different spectrum sensing
strategies on the throughput of OS-OFDMA network. The analysis applies to the
IEEE 802.22 standard, to evaluate the impact of two-stage spectrum sensing
strategy and varying temporal activity of wireless microphones on the IEEE
802.22 throughput. Our study suggests that OS-OFDMA with subchannel notching
and channel bonding could provide almost ten times higher throughput compared
with the design without those options, when the activity and density of
wireless microphones is very high. Furthermore, we confirm that OS-OFDMA
implementation without subchannel notching, used in the IEEE 802.22, is able to
support real-time and non-real-time quality of service classes, provided that
wireless microphones temporal activity is moderate (with approximately one
wireless microphone per 3,000 inhabitants with light urban population density
and short duty cycles). Finally, two-stage spectrum sensing option improves
OS-OFDMA throughput, provided that the length of spectrum sensing at every
stage is optimized using our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5088</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5088</id><created>2010-07-28</created><authors><author><keyname>Wams</keyname><forenames>Jan-Mark S.</forenames><affiliation>VU Amsterdam</affiliation></author><author><keyname>van Steen</keyname><forenames>Maarten</forenames><affiliation>VU Amsterdam</affiliation></author></authors><title>Simplified Distributed Programming with Micro Objects</title><categories>cs.DC</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 1-15</journal-ref><doi>10.4204/EPTCS.30.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing large-scale distributed applications can be a daunting task.
object-based environments have attempted to alleviate problems by providing
distributed objects that look like local objects. We advocate that this
approach has actually only made matters worse, as the developer needs to be
aware of many intricate internal details in order to adequately handle partial
failures. The result is an increase of application complexity. We present an
alternative in which distribution transparency is lessened in favor of clearer
semantics. In particular, we argue that a developer should always be offered
the unambiguous semantics of local objects, and that distribution comes from
copying those objects to where they are needed. We claim that it is often
sufficient to provide only small, immutable objects, along with facilities to
group objects into clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5089</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5089</id><created>2010-07-28</created><authors><author><keyname>Lacouture</keyname><forenames>Mayleen</forenames><affiliation>ASCOLA Research Team</affiliation></author><author><keyname>Grall</keyname><forenames>Herv&#xe9;</forenames><affiliation>ASCOLA Research Team</affiliation></author><author><keyname>Ledoux</keyname><forenames>Thomas</forenames><affiliation>ASCOLA Research Team</affiliation></author></authors><title>CREOLE: a Universal Language for Creating, Requesting, Updating and
  Deleting Resources</title><categories>cs.PL cs.NI cs.SE</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 16-30</journal-ref><doi>10.4204/EPTCS.30.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of Service-Oriented Computing, applications can be developed
following the REST (Representation State Transfer) architectural style. This
style corresponds to a resource-oriented model, where resources are manipulated
via CRUD (Create, Request, Update, Delete) interfaces. The diversity of CRUD
languages due to the absence of a standard leads to composition problems
related to adaptation, integration and coordination of services. To overcome
these problems, we propose a pivot architecture built around a universal
language to manipulate resources, called CREOLE, a CRUD Language for Resource
Edition. In this architecture, scripts written in existing CRUD languages, like
SQL, are compiled into Creole and then executed over different CRUD interfaces.
After stating the requirements for a universal language for manipulating
resources, we formally describe the language and informally motivate its
definition with respect to the requirements. We then concretely show how the
architecture solves adaptation, integration and coordination problems in the
case of photo management in Flickr and Picasa, two well-known service-oriented
applications. Finally, we propose a roadmap for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5090</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5090</id><created>2010-07-28</created><authors><author><keyname>Ben-Hafaiedh</keyname><forenames>Imene</forenames><affiliation>Universite Joseph Fourier/VERIMAG</affiliation></author><author><keyname>Graf</keyname><forenames>Susanne</forenames><affiliation>Universite Joseph Fourier/VERIMAG</affiliation></author><author><keyname>Khairallah</keyname><forenames>Hammadi</forenames><affiliation>Tunisia Polytechnic School</affiliation></author></authors><title>Implementing Distributed Controllers for Systems with Priorities</title><categories>cs.DC cs.PL cs.SE</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 31-46</journal-ref><doi>10.4204/EPTCS.30.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Implementing a component-based system in a distributed way so that it ensures
some global constraints is a challenging problem. We consider here abstract
specifications consisting of a composition of components and a controller given
in the form of a set of interactions and a priority order amongst them. In the
context of distributed systems, such a controller must be executed in a
distributed fashion while still respecting the global constraints imposed by
interactions and priorities.
  We present in this paper an implementation of an algorithm that allows a
distributed execution of systems with (binary) interactions and priorities. We
also present a comprehensive simulation analysis that shows how sensitive to
changes our algorithm is, in particular changes related to the degree of
conflict in the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5091</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5091</id><created>2010-07-28</created><authors><author><keyname>Kamali</keyname><forenames>Maryam</forenames><affiliation>IT-Department, Abo Akademi University</affiliation></author><author><keyname>Laibinis</keyname><forenames>Linas</forenames><affiliation>IT-Department, Abo Akademi University</affiliation></author><author><keyname>Petre</keyname><forenames>Luigia</forenames><affiliation>IT-Department, Abo Akademi University</affiliation></author><author><keyname>Sere</keyname><forenames>Kaisa</forenames><affiliation>IT-Department, Abo Akademi University</affiliation></author></authors><title>Self-Recovering Sensor-Actor Networks</title><categories>cs.DC cs.LO</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 47-61</journal-ref><doi>10.4204/EPTCS.30.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor-actor networks are a recent development of wireless networks
where both ordinary sensor nodes and more sophisticated and powerful nodes,
called actors, are present. In this paper we formalize a recently introduced
algorithm that recovers failed actor communication links via the existing
sensor infrastructure. We prove via refinement that the recovery is terminating
in a finite number of steps and is distributed, thus self-performed by the
actors. Most importantly, we prove that the recovery can be done at different
levels, via different types of links, such as direct actor links or indirect
links between the actors, in the latter case reusing the wireless
infrastructure of sensors. This leads to identifying coordination classes,
e.g., for delegating the most security sensitive coordination to the direct
actor-actor coordination links, the least real-time constrained coordination to
indirect links, and the safety critical coordination to both direct actor links
and indirect sensor paths between actors. Our formalization is done using the
theorem prover in the RODIN platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5092</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5092</id><created>2010-07-28</created><authors><author><keyname>Cubo</keyname><forenames>Javier</forenames><affiliation>University of Malaga</affiliation></author><author><keyname>Pimentel</keyname><forenames>Ernesto</forenames><affiliation>University of Malaga</affiliation></author><author><keyname>Sala&#xfc;n</keyname><forenames>Gwen</forenames><affiliation>Grenoble INP, INRIA-Grenoble, LIG</affiliation></author><author><keyname>Canal</keyname><forenames>Carlos</forenames><affiliation>University of Malaga</affiliation></author></authors><title>Handling Data-Based Concurrency in Context-Aware Service Protocols</title><categories>cs.SE</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 62-77</journal-ref><doi>10.4204/EPTCS.30.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dependency analysis is a technique to identify and determine data
dependencies between service protocols. Protocols evolving concurrently in the
service composition need to impose an order in their execution if there exist
data dependencies. In this work, we describe a model to formalise context-aware
service protocols. We also present a composition language to handle dynamically
the concurrent execution of protocols. This language addresses data dependency
issues among several protocols concurrently executed on the same user device,
using mechanisms based on data semantic matching. Our approach aims at
assisting the user in establishing priorities between these dependencies,
avoiding the occurrence of deadlock situations. Nevertheless, this process is
error-prone, since it requires human intervention. Therefore, we also propose
verification techniques to automatically detect possible inconsistencies
specified by the user while building the data dependency set. Our approach is
supported by a prototype tool we have implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5093</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5093</id><created>2010-07-28</created><authors><author><keyname>Imine</keyname><forenames>Abdessamad</forenames><affiliation>Nancy University and INRIA Grand-Est</affiliation></author></authors><title>On Coordinating Collaborative Objects</title><categories>cs.SE</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 78-92</journal-ref><doi>10.4204/EPTCS.30.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A collaborative object represents a data type (such as a text document)
designed to be shared by a group of dispersed users. The Operational
Transformation (OT) is a coordination approach used for supporting optimistic
replication for these objects. It allows the users to concurrently update the
shared data and exchange their updates in any order since the convergence of
all replicas, i.e. the fact that all users view the same data, is ensured in
all cases. However, designing algorithms for achieving convergence with the OT
approach is a critical and challenging issue. In this paper, we propose a
formal compositional method for specifying complex collaborative objects. The
most important feature of our method is that designing an OT algorithm for the
composed collaborative object can be done by reusing the OT algorithms of
component collaborative objects. By using our method, we can start from correct
small collaborative objects which are relatively easy to handle and
incrementally combine them to build more complex collaborative objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5094</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5094</id><created>2010-07-28</created><authors><author><keyname>Moon</keyname><forenames>Young-Joo</forenames><affiliation>Centrum Wiskunde Informatica</affiliation></author><author><keyname>Silva</keyname><forenames>Alexandra</forenames><affiliation>Centrum Wiskunde Informatica</affiliation></author><author><keyname>Krause</keyname><forenames>Christian</forenames><affiliation>Centrum Wiskunde Informatica</affiliation></author><author><keyname>Arbab</keyname><forenames>Farhad</forenames><affiliation>Centrum Wiskunde Informatica</affiliation></author></authors><title>A Compositional Semantics for Stochastic Reo Connectors</title><categories>cs.SE cs.PF</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 93-107</journal-ref><doi>10.4204/EPTCS.30.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a compositional semantics for the channel-based
coordination language Reo which enables the analysis of quality of service
(QoS) properties of service compositions. For this purpose, we annotate Reo
channels with stochastic delay rates and explicitly model data-arrival rates at
the boundary of a connector, to capture its interaction with the services that
comprise its environment. We propose Stochastic Reo automata as an extension of
Reo automata, in order to compositionally derive a QoS-aware semantics for Reo.
We further present a translation of Stochastic Reo automata to Continuous-Time
Markov Chains (CTMCs). This translation enables us to use third-party CTMC
verification tools to do an end-to-end performance analysis of service
compositions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5095</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5095</id><created>2010-07-28</created><authors><author><keyname>Jaghoori</keyname><forenames>Mohammad Mahdi</forenames><affiliation>LIACS and CWI</affiliation></author><author><keyname>Chothia</keyname><forenames>Tom</forenames><affiliation>University of Birmingham</affiliation></author></authors><title>Timed Automata Semantics for Analyzing Creol</title><categories>cs.LO cs.DC</categories><comments>In Proceedings FOCLASA 2010, arXiv:1007.4993</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 30, 2010, pp. 108-122</journal-ref><doi>10.4204/EPTCS.30.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a real-time semantics for the concurrent, object-oriented modeling
language Creol, by mapping Creol processes to a network of timed automata. We
can use our semantics to verify real time properties of Creol objects, in
particular to see whether processes can be scheduled correctly and meet their
end-to-end deadlines. Real-time Creol can be useful for analyzing, for
instance, abstract models of multi-core embedded systems. We show how analysis
can be done in Uppaal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5104</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5104</id><created>2010-07-28</created><authors><author><keyname>Davies</keyname><forenames>Jessica</forenames></author><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodystka</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>An Empirical Study of Borda Manipulation</title><categories>cs.AI</categories><comments>To appear in Proceedings of the Third International Workshop on
  Computational Social Choice</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of coalitional manipulation in elections using the
unweighted Borda rule. We provide empirical evidence of the manipulability of
Borda elections in the form of two new greedy manipulation algorithms based on
intuitions from the bin-packing and multiprocessor scheduling domains. Although
we have not been able to show that these algorithms beat existing methods in
the worst-case, our empirical evaluation shows that they significantly
outperform the existing method and are able to find optimal manipulations in
the vast majority of the randomly generated elections that we tested. These
empirical results provide further evidence that the Borda rule provides little
defense against coalitional manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5110</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5110</id><created>2010-07-29</created><authors><author><keyname>Patil</keyname><forenames>Manish</forenames></author><author><keyname>Shah</keyname><forenames>Rahul</forenames></author><author><keyname>Thankachan</keyname><forenames>Sharma V.</forenames></author></authors><title>Fully Dynamic Data Structure for Top-k Queries on Uncertain Data</title><categories>cs.DB cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Top-$k$ queries allow end-users to focus on the most important (top-$k$)
answers amongst those which satisfy the query. In traditional databases, a user
defined score function assigns a score value to each tuple and a top-$k$ query
returns $k$ tuples with the highest score. In uncertain database, top-$k$
answer depends not only on the scores but also on the membership probabilities
of tuples. Several top-$k$ definitions covering different aspects of
score-probability interplay have been proposed in recent
past~\cite{R10,R4,R2,R8}. Most of the existing work in this research field is
focused on developing efficient algorithms for answering top-$k$ queries on
static uncertain data. Any change (insertion, deletion of a tuple or change in
membership probability, score of a tuple) in underlying data forces
re-computation of query answers. Such re-computations are not practical
considering the dynamic nature of data in many applications. In this paper, we
propose a fully dynamic data structure that uses ranking function
$PRF^e(\alpha)$ proposed by Li et al.~\cite{R8} under the generally adopted
model of $x$-relations~\cite{R11}. $PRF^e$ can effectively approximate various
other top-$k$ definitions on uncertain data based on the value of parameter
$\alpha$. An $x$-relation consists of a number of $x$-tuples, where $x$-tuple
is a set of mutually exclusive tuples (up to a constant number) called
alternatives. Each $x$-tuple in a relation randomly instantiates into one tuple
from its alternatives. For an uncertain relation with $N$ tuples, our structure
can answer top-$k$ queries in $O(k\log N)$ time, handles an update in $O(\log
N)$ time and takes $O(N)$ space. Finally, we evaluate practical efficiency of
our structure on both synthetic and real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5114</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5114</id><created>2010-07-29</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Where are the hard manipulation problems?</title><categories>cs.AI cs.CC cs.GT cs.MA</categories><comments>Invited tutorial at the Third International Workshop on Computational
  Social Choice 2010</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One possible escape from the Gibbard-Satterthwaite theorem is computational
complexity. For example, it is NP-hard to compute if the STV rule can be
manipulated. However, there is increasing concern that such results may not re
ect the difficulty of manipulation in practice. In this tutorial, I survey
recent results in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5115</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5115</id><created>2010-07-29</created><authors><author><keyname>Abouelela</keyname><forenames>Mohamed</forenames><affiliation>University of Regina, Canada</affiliation></author><author><keyname>Benedicenti</keyname><forenames>Luigi</forenames><affiliation>University of Regina, Canada</affiliation></author></authors><title>Bayesian Network Based XP Process Modelling</title><categories>cs.SE</categories><comments>15 Pages, 7 Figures</comments><journal-ref>International Journal of Software Engineering &amp; Applications 1.3
  (2010) 1-15</journal-ref><doi>10.5121/ijsea.2010.1301</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A Bayesian Network based mathematical model has been used for modelling
Extreme Programming software development process. The model is capable of
predicting the expected finish time and the expected defect rate for each XP
release. Therefore, it can be used to determine the success/failure of any XP
Project. The model takes into account the effect of three XP practices, namely:
Pair Programming, Test Driven Development and Onsite Customer practices. The
model's predictions were validated against two case studies. Results show the
precision of our model especially in Predicting the project finish time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5117</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5117</id><created>2010-07-29</created><authors><author><keyname>Kanellopoulos</keyname><forenames>Yiannis</forenames><affiliation>University of Manchester, U.K</affiliation></author><author><keyname>Antonellis</keyname><forenames>Panos</forenames><affiliation>University Of Patras, Greece</affiliation></author><author><keyname>Antoniou</keyname><forenames>Dimitris</forenames><affiliation>University Of Patras, Greece</affiliation></author><author><keyname>Makris</keyname><forenames>Christos</forenames><affiliation>University Of Patras, Greece</affiliation></author><author><keyname>Theodoridis</keyname><forenames>Evangelos</forenames><affiliation>University Of Patras, Greece</affiliation></author><author><keyname>Tjortjis</keyname><forenames>Christos</forenames><affiliation>Univ. of Ioannina, Greece and</affiliation><affiliation>University of W. Macedonia, Greece</affiliation></author><author><keyname>Tsirakis</keyname><forenames>Nikos</forenames><affiliation>University Of Patras, Greece</affiliation></author></authors><title>Code Quality Evaluation Methodology Using The ISO/IEC 9126 Standard</title><categories>cs.SE</categories><comments>20 pages, 14 figures</comments><journal-ref>International Journal of Software Engineering &amp; Applications 1.3
  (2010) 17-36</journal-ref><doi>10.5121/ijsea.2010.1302</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This work proposes a methodology for source code quality and static behaviour
evaluation of a software system, based on the standard ISO/IEC-9126. It uses
elements automatically derived from source code enhanced with expert knowledge
in the form of quality characteristic rankings, allowing software engineers to
assign weights to source code attributes. It is flexible in terms of the set of
metrics and source code attributes employed, even in terms of the ISO/IEC-9126
characteristics to be assessed. We applied the methodology to two case studies,
involving five open source and one proprietary system. Results demonstrated
that the methodology can capture software quality trends and express expert
perceptions concerning system quality in a quantitative and systematic manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5120</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5120</id><created>2010-07-29</created><authors><author><keyname>Pini</keyname><forenames>Maria Silvia</forenames></author><author><keyname>Rossi</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>Brent</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Stable marriage problems with quantitative preferences</title><categories>cs.AI cs.GT cs.MA</categories><comments>To appear in Proceedings of Third International Workshop on
  Computational Social Choice, Dusseldorf, Germany, September 13-16, 2010</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stable marriage problem is a well-known problem of matching men to women
so that no man and woman, who are not married to each other, both prefer each
other. Such a problem has a wide variety of practical applications, ranging
from matching resident doctors to hospitals, to matching students to schools or
more generally to any two-sided market. In the classical stable marriage
problem, both men and women express a strict preference order over the members
of the other sex, in a qualitative way. Here we consider stable marriage
problems with quantitative preferences: each man (resp., woman) provides a
score for each woman (resp., man). Such problems are more expressive than the
classical stable marriage problems. Moreover, in some real-life situations it
is more natural to express scores (to model, for example, profits or costs)
rather than a qualitative preference ordering. In this context, we de?fine new
notions of stability and optimality, and we provide algorithms to find
marriages which are stable and/or optimal according to these notions. While
expressivity greatly increases by adopting quantitative preferences, we show
that in most cases the desired solutions can be found by adapting existing
algorithms for the classical stable marriage problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5123</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5123</id><created>2010-07-29</created><authors><author><keyname>Shireesha</keyname><forenames>P.</forenames><affiliation>KITS-Warangal, India and</affiliation></author><author><keyname>Sharma</keyname><forenames>S. S. V. N.</forenames><affiliation>Kakatiya University, India</affiliation></author></authors><title>Building Reusable Software Component For Optimization Check in ABAP
  Coding</title><categories>cs.SE</categories><comments>9 pages, 6 figures</comments><journal-ref>International Journal of Software Engineering &amp; Applications 1.3
  (2010) 38-46</journal-ref><doi>10.5121/ijsea.2010.1303</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Software component reuse is the software engineering practice of developing
new software products from existing components. A reuse library or component
reuse repository organizes stores and manages reusable components. This paper
describes how a reusable component is created, how it reuses the function and
checking if optimized code is being used in building programs and applications.
Finally providing coding guidelines, standards and best practices used for
creating reusable components and guidelines and best practices for making
configurable and easy to use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5126</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5126</id><created>2010-07-29</created><authors><author><keyname>Chua</keyname><forenames>Bee Bee</forenames><affiliation>University of Technology Sydney, Australia and</affiliation></author><author><keyname>Verner</keyname><forenames>June</forenames><affiliation>University of New South Wales, Australia</affiliation></author></authors><title>Examining Requirements Change Rework Effort: A Study</title><categories>cs.SE</categories><comments>17 pages, 8 figures</comments><journal-ref>International Journal of Software Engineering &amp; Applications 1.3
  (2010) 48-64</journal-ref><doi>10.5121/ijsea.2010.1304</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Although software managers are generally good at new project estimation,
their experience of scheduling rework tends to be poor. Inconsistent or
incorrect effort estimation can increase the risk that the completion time for
a project will be problematic. To continually alter software maintenance
schedules during software maintenance is a daunting task. Our proposed
framework, validated in a case study confirms that the variables resulting from
requirements changes suffer from a number of problems, e.g., the coding used,
end user involvement and user documentation. Our results clearly show a
significant impact on rework effort as a result of unexpected errors that
correlate with 1) weak characteristics and attributes as described in the
program's source lines of code, especially in data declarations and data
statements, 2) lack of communication between developers and users on a change
effects, and 3) unavailability of user documentation. To keep rework effort
under control, new criteria in change request forms are proposed. These
criteria are shown in a proposed framework; the more case studies that are
validated, the more reliable the result will be in determining the outcome of
effort rework estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5127</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5127</id><created>2010-07-29</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames><affiliation>University of Wuerzburg, Germany</affiliation></author></authors><title>Towards Performance Measurement And Metrics Based Analysis of PLA
  Applications</title><categories>cs.SE</categories><comments>15 pages, 12 figures</comments><journal-ref>International Journal of Software Engineering &amp; Applications 1.3
  (2010) 66-80</journal-ref><doi>10.5121/ijsea.2010.1305</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This article is about a measurement analysis based approach to help software
practitioners in managing the additional level complexities and variabilities
in software product line applications. The architecture of the proposed
approach i.e. ZAC is designed and implemented to perform preprocessesed source
code analysis, calculate traditional and product line metrics and visualize
results in two and three dimensional diagrams. Experiments using real time data
sets are performed which concluded with the results that the ZAC can be very
helpful for the software practitioners in understanding the overall structure
and complexity of product line applications. Moreover the obtained results
prove strong positive correlation between calculated traditional and product
line measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5129</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5129</id><created>2010-07-29</created><authors><author><keyname>Islam</keyname><forenames>Mohammed J.</forenames><affiliation>University of Windsor, Canada</affiliation></author><author><keyname>Ahmadi</keyname><forenames>Majid</forenames><affiliation>University of Windsor, Canada</affiliation></author><author><keyname>Sid-Ahmed</keyname><forenames>Maher A.</forenames><affiliation>University of Windsor, Canada</affiliation></author></authors><title>An Efficient Automatic Mass Classification Method In Digitized
  Mammograms Using Artificial Neural Network</title><categories>cs.CV</categories><comments>13 pages, 10 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  1.3 (2010) 1-13</journal-ref><doi>10.5121/ijaia.2010.1301</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we present an efficient computer aided mass classification
method in digitized mammograms using Artificial Neural Network (ANN), which
performs benign-malignant classification on region of interest (ROI) that
contains mass. One of the major mammographic characteristics for mass
classification is texture. ANN exploits this important factor to classify the
mass into benign or malignant. The statistical textural features used in
characterizing the masses are mean, standard deviation, entropy, skewness,
kurtosis and uniformity. The main aim of the method is to increase the
effectiveness and efficiency of the classification process in an objective
manner to reduce the numbers of false-positive of malignancies. Three layers
artificial neural network (ANN) with seven features was proposed for
classifying the marked regions into benign and malignant and 90.91% sensitivity
and 83.87% specificity is achieved that is very much promising compare to the
radiologist's sensitivity 75%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5130</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5130</id><created>2010-07-29</created><authors><author><keyname>Della Penna</keyname><forenames>Giuseppe</forenames><affiliation>University of L'Aquila, Italy</affiliation></author><author><keyname>Intrigila</keyname><forenames>Benedetto</forenames><affiliation>University of Rome, Italy and</affiliation></author><author><keyname>Magazzeni</keyname><forenames>Daniele</forenames><affiliation>University of Chieti, Italy</affiliation></author><author><keyname>Mercorio</keyname><forenames>Fabio</forenames><affiliation>University of L'Aquila, Italy</affiliation></author></authors><title>Resource-Optimal Planning For An Autonomous Planetary Vehicle</title><categories>cs.AI</categories><comments>15 pages, 4 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  1.3 (2010) 15-29</journal-ref><doi>10.5121/ijaia.2010.1302</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Autonomous planetary vehicles, also known as rovers, are small autonomous
vehicles equipped with a variety of sensors used to perform exploration and
experiments on a planet's surface. Rovers work in a partially unknown
environment, with narrow energy/time/movement constraints and, typically, small
computational resources that limit the complexity of on-line planning and
scheduling, thus they represent a great challenge in the field of autonomous
vehicles. Indeed, formal models for such vehicles usually involve hybrid
systems with nonlinear dynamics, which are difficult to handle by most of the
current planning algorithms and tools. Therefore, when offline planning of the
vehicle activities is required, for example for rovers that operate without a
continuous Earth supervision, such planning is often performed on simplified
models that are not completely realistic. In this paper we show how the
UPMurphi model checking based planning tool can be used to generate
resource-optimal plans to control the engine of an autonomous planetary
vehicle, working directly on its hybrid model and taking into account several
safety constraints, thus achieving very accurate results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5133</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5133</id><created>2010-07-29</created><authors><author><keyname>Lee</keyname><forenames>Ming-Chang</forenames><affiliation>Fooyin University, Taiwan and</affiliation></author><author><keyname>To</keyname><forenames>Chang</forenames><affiliation>Shu-Te University, Taiwan</affiliation></author></authors><title>Comparison of Support Vector Machine and Back Propagation Neural Network
  in Evaluating the Enterprise Financial Distress</title><categories>cs.LG</categories><comments>13 pages, 1 figure</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  1.3 (2010) 31-43</journal-ref><doi>10.5121/ijaia.2010.1303</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recently, applying the novel data mining techniques for evaluating enterprise
financial distress has received much research alternation. Support Vector
Machine (SVM) and back propagation neural (BPN) network has been applied
successfully in many areas with excellent generalization results, such as rule
extraction, classification and evaluation. In this paper, a model based on SVM
with Gaussian RBF kernel is proposed here for enterprise financial distress
evaluation. BPN network is considered one of the simplest and are most general
methods used for supervised training of multilayered neural network. The
comparative results show that through the difference between the performance
measures is marginal; SVM gives higher precision and lower error rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5136</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5136</id><created>2010-07-29</created><authors><author><keyname>Hsieh</keyname><forenames>Ming-Shing</forenames><affiliation>Aletheia University, Taiwan</affiliation></author></authors><title>Perceptual Copyright Protection Using Multiresolution Wavelet-Based
  Watermarking And Fuzzy Logic</title><categories>cs.MM</categories><comments>13 pages, 7 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  1.3 (2010) 45-57</journal-ref><doi>10.5121/ijaia.2010.1304</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, an efficiently DWT-based watermarking technique is proposed to
embed signatures in images to attest the owner identification and discourage
the unauthorized copying. This paper deals with a fuzzy inference filter to
choose the larger entropy of coefficients to embed watermarks. Unlike most
previous watermarking frameworks which embedded watermarks in the larger
coefficients of inner coarser subbands, the proposed technique is based on
utilizing a context model and fuzzy inference filter by embedding watermarks in
the larger-entropy coefficients of coarser DWT subbands. The proposed
approaches allow us to embed adaptive casting degree of watermarks for
transparency and robustness to the general image-processing attacks such as
smoothing, sharpening, and JPEG compression. The approach has no need the
original host image to extract watermarks. Our schemes have been shown to
provide very good results in both image transparency and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5137</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5137</id><created>2010-07-29</created><authors><author><keyname>Sridhar</keyname><forenames>Rajeswari</forenames><affiliation>Anna University-Chennai, India</affiliation></author><author><keyname>Amudha</keyname><forenames>A.</forenames><affiliation>Anna University-Chennai, India</affiliation></author><author><keyname>Karthiga</keyname><forenames>S.</forenames><affiliation>Anna University-Chennai, India</affiliation></author><author><keyname>T</keyname><forenames>Geetha</forenames><suffix>V</suffix><affiliation>Anna University-Chennai, India</affiliation></author></authors><title>Comparison Of Modified Dual Ternary Indexing And Multi-Key Hashing
  Algorithms For Music Information Retrieval</title><categories>cs.IR</categories><comments>11 pages, 5 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  1.3 (2010) 59-69</journal-ref><doi>10.5121/ijaia.2010.1305</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work we have compared two indexing algorithms that have been used to
index and retrieve Carnatic music songs. We have compared a modified algorithm
of the Dual ternary indexing algorithm for music indexing and retrieval with
the multi-key hashing indexing algorithm proposed by us. The modification in
the dual ternary algorithm was essential to handle variable length query phrase
and to accommodate features specific to Carnatic music. The dual ternary
indexing algorithm is adapted for Carnatic music by segmenting using the
segmentation technique for Carnatic music. The dual ternary algorithm is
compared with the multi-key hashing algorithm designed by us for indexing and
retrieval in which features like MFCC, spectral flux, melody string and
spectral centroid are used as features for indexing data into a hash table. The
way in which collision resolution was handled by this hash table is different
than the normal hash table approaches. It was observed that multi-key hashing
based retrieval had a lesser time complexity than dual-ternary based indexing
The algorithms were also compared for their precision and recall in which
multi-key hashing had a better recall than modified dual ternary indexing for
the sample data considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5139</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5139</id><created>2010-07-29</created><authors><author><keyname>Banerjee</keyname><forenames>Anuradha</forenames><affiliation>Kalyani Govt. Engg. College, India and</affiliation></author><author><keyname>Dutta</keyname><forenames>Paramartha</forenames><affiliation>Visva-Bharati University, India</affiliation></author></authors><title>Reputation-Based Attack-Resistant Cooperation Stimulation (RACS) For
  Mobile Ad hoc Networks</title><categories>cs.NI</categories><comments>20 pages, 4 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  1.3 (2010) 71-90</journal-ref><doi>10.5121/ijaia.2010.1306</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In mobile ad hoc networks (MANET), nodes usually belong to different
authorities and pursue different goals. In order to maximize their own
performance, nodes in such networks tend to be selfish and are not willing to
forward packets for benefit of others. Meanwhile, some nodes may behave
maliciously and try to disrupt the network through wasting other nodes
resources in a very large scale. In this article, we present a reputation-based
attack resistant cooperation stimulation (RACS) system which ensures that
damage caused by malicious nodes can be bounded and cooperation among the
selfish nodes can be enforced. Mathematical analyses of the system as well as
the simulation results have confirmed effectiveness of our proposed system.
RACS is completely self-organizing and distributed. It does not require any
tamper-proof hardware or central management policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5158</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5158</id><created>2010-07-29</created><authors><author><keyname>Atia</keyname><forenames>Ayman</forenames></author><author><keyname>Tsukuba</keyname><forenames>Jiro Tanaka University of</forenames></author><author><keyname>Japan)</keyname></author></authors><title>Interaction With Tilting Gestures In Ubiquitous Environments</title><categories>cs.HC</categories><comments>13 pages, 10 figures</comments><journal-ref>International Journal Of UbiComp 1.3 (2010) 1-13</journal-ref><doi>10.5121/iju.2010.1301</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we introduce a tilting interface that controls direction based
applications in ubiquitous environments. A tilt interface is useful for
situations that require remote and quick interactions or that are executed in
public spaces. We explored the proposed tilting interface with different
application types and classified the tilting interaction techniques. Augmenting
objects with sensors can potentially address the problem of the lack of
intuitive and natural input devices in ubiquitous environments. We have
conducted an experiment to test the usability of the proposed tilting interface
to compare it with conventional input devices and hand gestures. The experiment
results showed greater improvement of the tilt gestures in comparison with hand
gestures in terms of speed, accuracy, and user satisfaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5165</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5165</id><created>2010-07-29</created><authors><author><keyname>Shankar</keyname><forenames>R.</forenames><affiliation>Sri Manakula Vinayagar Engineering College and</affiliation></author><author><keyname>K</keyname><forenames>Timothy Rajkumar.</forenames><affiliation>Pondicherry Engineering College, India</affiliation></author><author><keyname>Dananjayan</keyname><forenames>P.</forenames><affiliation>Pondicherry Engineering College, India</affiliation></author></authors><title>Security Enhancement With Optimal QOS Using EAP-AKA In Hybrid Coupled
  3G-WLAN Convergence Network</title><categories>cs.NI</categories><comments>12 pages, 5 figures</comments><journal-ref>International Journal Of UbiComp 1.3 (2010) 31-42</journal-ref><doi>10.5121/iju.2010.1303</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The third generation partnership project (3GPP) has addressed the feasibility
of interworking and specified the interworking architecture and security
architecture for third generation (3G)-wireless local area network (WLAN), it
is developing, system architecture evolution (SAE)/ long term evolution (LTE)
architecture, for the next generation mobile communication system. To provide a
secure 3G-WLAN interworking in the SAE/LTE architecture, Extensible
authentication protocol-authentication and key agreement (EAP-AKA) is used.
However, EAP-AKA have several vulnerabilities. Therefore, this paper not only
analyses the threats and attacks in 3G-WLAN interworking but also proposes a
new authentication and key agreement protocol based on EAP-AKA. The proposed
protocol combines elliptic curve Diffie-Hellman (ECDH) with symmetric key
cryptosystem to overcome the vulnerabilities. The proposed protocol is used in
hybrid coupled 3G-WLAN convergence network to analyse its efficiency in terms
of QoS metrics, the results obtained using OPNET 14.5 shows that the proposed
protocol outperforms existing interworking protocols both in security and QoS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5168</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5168</id><created>2010-07-29</created><authors><author><keyname>Valli</keyname><forenames>R.</forenames><affiliation>Pondicherry Engineering College, India</affiliation></author><author><keyname>Dananjayan</keyname><forenames>P.</forenames><affiliation>Pondicherry Engineering College, India</affiliation></author></authors><title>A Non-Cooperative Game Theoretical Approach For Power Control In Virtual
  MIMO Wireless Sensor Network</title><categories>cs.NI</categories><comments>12 pages, 8 figures</comments><journal-ref>International Journal Of UbiComp 1.3 (2010) 44-55</journal-ref><doi>10.5121/iju.2010.1304</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Power management is one of the vital issue in wireless sensor networks, where
the lifetime of the network relies on battery powered nodes. Transmitting at
high power reduces the lifetime of both the nodes and the network. One
efficient way of power management is to control the power at which the nodes
transmit. In this paper, a virtual multiple input multiple output wireless
sensor network (VMIMO-WSN)communication architecture is considered and the
power control of sensor nodes based on the approach of game theory is
formulated. The use of game theory has proliferated, with a broad range of
applications in wireless sensor networking. Approaches from game theory can be
used to optimize node level as well as network wide performance. The game here
is categorized as an incomplete information game, in which the nodes do not
have complete information about the strategies taken by other nodes. For
virtual multiple input multiple output wireless sensor network architecture
considered, the Nash equilibrium is used to decide the optimal power level at
which a node needs to transmit, to maximize its utility. Outcome shows that the
game theoretic approach considered for VMIMO-WSN architecture achieves the best
utility, by consuming less power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5170</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5170</id><created>2010-07-29</created><authors><author><keyname>Perlaza</keyname><forenames>Samir M.</forenames></author><author><keyname>Tembine</keyname><forenames>Hamidou</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Satisfaction Equilibrium: A General Framework for QoS Provisioning in
  Self-Configuring Networks</title><categories>cs.NI cs.GT</categories><comments>Accepted for publication in Globecom 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the concept of equilibrium and quality of
service (QoS) provisioning in self-configuring wireless networks with
non-cooperative radio devices (RD). In contrast with the Nash equilibrium (NE),
where RDs are interested in selfishly maximizing its QoS, we present a concept
of equilibrium, named satisfaction equilibrium (SE), where RDs are interested
only in guaranteing a minimum QoS. We provide the conditions for the existence
and the uniqueness of the SE. Later, in order to provide an equilibrium
selection framework for the SE, we introduce the concept of effort or cost of
satisfaction, for instance, in terms of transmit power levels, constellation
sizes, etc. Using the idea of effort, the set of efficient SE (ESE) is defined.
At the ESE, transmitters satisfy their minimum QoS incurring in the lowest
effort. We prove that contrary to the (generalized) NE, at least one ESE always
exists whenever the network is able to simultaneously support the individual
QoS requests. Finally, we provide a fully decentralized algorithm to allow
self-configuring networks to converge to one of the SE relying only on local
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5171</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5171</id><created>2010-07-29</created><authors><author><keyname>Liu</keyname><forenames>Li</forenames><affiliation>University of Alabama, Alabama</affiliation></author><author><keyname>Dillon</keyname><forenames>Edward</forenames><affiliation>University of Alabama, Alabama</affiliation></author></authors><title>I-Interaction: An Intelligent In-Vehicle User Interaction Model</title><categories>cs.HC</categories><comments>11 pages, 4 figures</comments><journal-ref>International Journal Of UbiComp 1.3 (2010) 57-67</journal-ref><doi>10.5121/iju.2010.1305</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The automobile is always a point of interest where new technology has been
deployed. Because of this interest, human-vehicle interaction has been an
appealing area for much research in recent years. The current in-vehicle design
has been improved but still possesses some of the design from the traditional
interaction style. In this paper, we propose a new user-oriented model for
in-vehicle interaction model known as i-Interaction. The i-Interaction model
provides user with an intuitive approach to interact with the In-Vehicle
Information System (IVIS) by the keypad entry. It is the intent that the
proposed usability testing for this model will help improve the way research
and development is implemented from this topic. This model does not only
provide the user with a direct interaction in vehicles but also introduce a new
prospective that other research has not addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5180</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5180</id><created>2010-07-29</created><authors><author><keyname>Palu'</keyname><forenames>Alessandro Dal</forenames></author><author><keyname>Dovier</keyname><forenames>Agostino</forenames></author><author><keyname>Fogolari</keyname><forenames>Federico</forenames></author><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author></authors><title>CLP-based protein fragment assembly</title><categories>cs.AI cs.CE cs.PL q-bio.QM</categories><comments>special issue dedicated to ICLP 2010</comments><journal-ref>Theory and Practice of Logic Programming, special issue dedicated
  to ICLP 2010. 10(4-6): pp 709-724, July 2010</journal-ref><doi>10.1017/S1471068410000372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates a novel approach, based on Constraint Logic
Programming (CLP), to predict the 3D conformation of a protein via fragments
assembly. The fragments are extracted by a preprocessor-also developed for this
work- from a database of known protein structures that clusters and classifies
the fragments according to similarity and frequency. The problem of assembling
fragments into a complete conformation is mapped to a constraint solving
problem and solved using CLP. The constraint-based model uses a medium
discretization degree Ca-side chain centroid protein model that offers
efficiency and a good approximation for space filling. The approach adapts
existing energy models to the protein representation used and applies a large
neighboring search strategy. The results shows the feasibility and efficiency
of the method. The declarative nature of the solution allows to include future
extensions, e.g., different size fragments for better accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5188</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5188</id><created>2010-07-29</created><authors><author><keyname>Deng</keyname><forenames>Yuxin</forenames></author><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author></authors><title>Characterising Probabilistic Processes Logically</title><categories>cs.LO</categories><comments>18 pages</comments><acm-class>F.3.2; D.3.1</acm-class><doi>10.1007/978-3-642-16242-8_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we work on (bi)simulation semantics of processes that exhibit
both nondeterministic and probabilistic behaviour. We propose a probabilistic
extension of the modal mu-calculus and show how to derive characteristic
formulae for various simulation-like preorders over finite-state processes
without divergence. In addition, we show that even without the fixpoint
operators this probabilistic mu-calculus can be used to characterise these
behavioural relations in the sense that two states are equivalent if and only
if they satisfy the same set of formulae.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5195</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5195</id><created>2010-07-29</created><authors><author><keyname>G&#xf3;mez-Zamalloa</keyname><forenames>Miguel</forenames></author><author><keyname>Albert</keyname><forenames>Elvira</forenames></author><author><keyname>Puebla</keyname><forenames>Germ&#xe1;n</forenames></author></authors><title>Test Case Generation for Object-Oriented Imperative Languages in CLP</title><categories>cs.PL cs.SE</categories><journal-ref>Miguel G\'omez-Zamalloa, Elvira Albert, Germ\'an Puebla: Test Case
  Generation for Object-Oriented Imperative Languages in CLP. TPLP 10(4-6):
  659-674 (2010)</journal-ref><doi>10.1017/S1471068410000347</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Testing is a vital part of the software development process. Test Case
Generation (TCG) is the process of automatically generating a collection of
test cases which are applied to a system under test. White-box TCG is usually
performed by means of symbolic execution, i.e., instead of executing the
program on normal values (e.g., numbers), the program is executed on symbolic
values representing arbitrary values. When dealing with an object-oriented (OO)
imperative language, symbolic execution becomes challenging as, among other
things, it must be able to backtrack, complex heap-allocated data structures
should be created during the TCG process and features like inheritance, virtual
invocations and exceptions have to be taken into account. Due to its inherent
symbolic execution mechanism, we pursue in this paper that Constraint Logic
Programming (CLP) has a promising unexploited application field in TCG. We will
support our claim by developing a fully CLP-based framework to TCG of an OO
imperative language, and by assessing it on a corresponding implementation on a
set of challenging Java programs. A unique characteristic of our approach is
that it handles all language features using only CLP and without the need of
developing specific constraint operators (e.g., to model the heap).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5218</identifier>
 <datestamp>2011-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5218</id><created>2010-07-29</created><updated>2011-07-14</updated><authors><author><keyname>Kai</keyname><forenames>Cai Hong</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Applications of Belief Propagation in CSMA Wireless Networks</title><categories>cs.NI</categories><comments>A technical report of The Chinese University of Hong Kong</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The belief propagation (BP) algorithm is an efficient way to solve
&quot;inference&quot; problems in graphical models, such as Bayesian networks and Markov
random fields. The system-state probability distribution of CSMA wireless
networks is a Markov random field. An interesting question is how BP can help
the analysis and design of CSMA wireless networks. This paper explores three
such applications. First, we show how BP can be used to compute the throughputs
of different links in the network given their access intensities, defined as
the mean packet transmission time divided by the mean backoff countdown time.
Second, we propose an inverse-BP algorithm to solve the reverse problem: how to
set the access intensities of different links to meet their target throughputs?
Third, we introduce a BP-adaptive CSMA algorithm to find the link access
intensities that can achieve optimal system utility. BP solves the three
problems with exact results in tree networks. It may, however, lose accuracy in
networks with a loopy contention graph. We show how a generalized version of
BP, GBP, can be designed to solve the three problems with high accuracy for
networks with a loopy contention graph. Importantly, we show how the BP and GBP
algorithms in this paper can be implemented in a distributed manner, making
them useful in practical CSMA network opera-tion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5239</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5239</id><created>2010-07-29</created><updated>2010-08-02</updated><authors><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>TCP Reno over Adaptive CSMA</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  An interesting distributed adaptive CSMA MAC protocol, called adaptive CSMA,
was proposed recently to schedule any strictly feasible achievable rates inside
the capacity region. Of particular interest is the fact that the adaptive CSMA
can achieve a system utility arbitrarily close to that is achievable under a
central scheduler. However, a specially designed transport-layer rate
controller is needed for this result. An outstanding question is whether the
widely-installed TCP Reno is compatible with adaptive CSMA and can achieve the
same result. The answer to this question will determine how close to practical
deployment adaptive CSMA is. Our answer is yes and no. First, we observe that
running TCP Reno directly over adaptive CSMA results in severe starvation
problems. Effectively, its performance is no better than that of TCP Reno over
legacy CSMA (IEEE 802.11), and the potentials of adaptive CSMA cannot be
realized. Fortunately, we find that multi-connection TCP Reno over adaptive
CSMA with active queue management can materialize the advantages of adaptive
CSMA. NS-2 simulations demonstrate that our solution can alleviate starvation
and achieve fair and efficient rate allocation. Multi-connection TCP can be
implemented at either application or transport layer. Application-layer
implementation requires no kernel modification, making the solution readily
deployable in networks running adaptive CSMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5240</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5240</id><created>2010-07-28</created><updated>2012-02-17</updated><authors><author><keyname>Diaz</keyname><forenames>Josep</forenames></author><author><keyname>Marchetti-Spaccamela</keyname><forenames>Alberto</forenames></author><author><keyname>Mitsche</keyname><forenames>Dieter</forenames></author><author><keyname>Santi</keyname><forenames>Paolo</forenames></author><author><keyname>Stefa</keyname><forenames>Julinda</forenames></author></authors><title>Social-Aware Forwarding Improves Routing Performance in Pocket Switched
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several social-aware forwarding strategies have been recently introduced in
opportunistic networks, and proved effective in considerably in- creasing
routing performance through extensive simulation studies based on real-world
data. However, this performance improvement comes at the expense of storing a
considerable amount of state information (e.g, history of past encounters) at
the nodes. Hence, whether the benefits on routing performance comes directly
from the social-aware forwarding mechanism, or indirectly by the fact state
information is exploited is not clear. Thus, the question of whether
social-aware forwarding by itself is effective in improving opportunistic
network routing performance remained unaddressed so far. In this paper, we give
a first, positive answer to the above question, by investigating the expected
message delivery time as the size of the net- work grows larger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5249</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5249</id><created>2010-07-29</created><updated>2011-08-04</updated><authors><author><keyname>Bienvenu</keyname><forenames>Laurent</forenames></author><author><keyname>Day</keyname><forenames>Adam</forenames></author><author><keyname>Hoyrup</keyname><forenames>Mathieu</forenames></author><author><keyname>Mezhirov</keyname><forenames>Ilya</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>A constructive version of Birkhoff's ergodic theorem for Martin-L\&quot;of
  random points</title><categories>math.DS cs.LO math.PR</categories><comments>Improved version of the CiE'10 paper, with the strong form of
  Birkhoff's ergodic theorem for random points</comments><msc-class>28D05, 68Q30</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A theorem of Ku\v{c}era states that given a Martin-L\&quot;of random infinite
binary sequence {\omega} and an effectively open set A of measure less than 1,
some tail of {\omega} is not in A. We first prove several results in the same
spirit and generalize them via an effective version of a weak form of
Birkhoff's ergodic theorem. We then use this result to get a stronger form of
it, namely a very general effective version of Birkhoff's ergodic theorem,
which improves all the results previously obtained in this direction, in
particular those of V'Yugin, Nandakumar and Hoyrup, Rojas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5255</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5255</id><created>2010-07-29</created><authors><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Jialiang</forenames></author><author><keyname>Chau</keyname><forenames>Chi-Kin</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author></authors><title>Analysis of Frequency-Agile CSMA Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes and analyzes the performance of a simple frequency-agile
CSMA MAC protocol. In this MAC, a node carrier-senses multiple frequency
channels simultaneously, and it takes the first opportunity to transmit on any
one of the channels when allowed by the CSMA backoff mechanism. We show that
the frequency-agile MAC can effectively 1) boost throughput and 2) remove
temporal starvation. Furthermore, the MAC can be implemented on the existing
multiple-frequency setup in Wi-Fi using multi-radio technology, and it can
co-exist with the legacy MAC using single radio. This paper provides exact
stationary throughput analysis for regular 1D and thin-strip 2D CSMA networks
using a &quot;transfer-matrix&quot; approach. In addition, accurate approximations are
given for 2D grid networks. Our closed-form formulas accurately quantify the
throughput gain of frequency-agile CSMA. To characterize temporal starvation,
we use the metric of &quot;mean residual access time&quot; (MRAT). Our simulations and
closed-form approximations indicate that the frequency-agile MAC can totally
eliminate temporal starvation in 2D grid networks, reducing its MRAT by orders
of magnitude. Finally, this paper presents a &quot;coloring theorem&quot; to justify the
use of the frequency-agile MAC in general network topologies. Our analysis and
theorem suggest that with enough frequency channels, the frequency-agile MAC
can effectively decouple the detrimental interactions between neighboring links
responsible for low throughput and starvation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5282</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5282</id><created>2010-07-29</created><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Khatri</keyname><forenames>Sunil P.</forenames></author><author><keyname>Bezrukov</keyname><forenames>Sergey M.</forenames></author><author><keyname>Peper</keyname><forenames>Ferdinand</forenames></author><author><keyname>Gingl</keyname><forenames>Zoltan</forenames></author><author><keyname>Horvath</keyname><forenames>Tamas</forenames></author></authors><title>Noise-based deterministic logic and computing: a brief survey</title><categories>physics.data-an cs.IT math.IT physics.gen-ph</categories><comments>Invited paper</comments><journal-ref>International Journal of Unconventional Computing 7 (2011
  February) 101-113</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A short survey is provided about our recent explorations of the young topic
of noise-based logic. After outlining the motivation behind noise-based
computation schemes, we present a short summary of our ongoing efforts in the
introduction, development and design of several noise-based deterministic
multivalued logic schemes and elements. In particular, we describe classical,
instantaneous, continuum, spike and random-telegraph-signal based schemes with
applications such as circuits that emulate the brain's functioning and string
verification via a slow communication channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5318</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5318</id><created>2010-07-29</created><updated>2010-08-23</updated><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>Intrinsic Dimensionality</title><categories>cs.DS</categories><comments>4 pages, 4 figures, latex; diagram (c) has been corrected</comments><msc-class>68P20</msc-class><acm-class>H.2.4</acm-class><journal-ref>The SIGSPATIAL Special, vol. 2, No. 2 (2010), 8-11</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This entry for the SIGSPATIAL Special July 2010 issue on Similarity Searching
in Metric Spaces discusses the notion of intrinsic dimensionality of data in
the context of similarity search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5336</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5336</id><created>2010-07-29</created><authors><author><keyname>Wu</keyname><forenames>Yiyue</forenames></author><author><keyname>Achtzehn</keyname><forenames>Andreas</forenames></author><author><keyname>Petrova</keyname><forenames>Marina</forenames></author><author><keyname>Mahonen</keyname><forenames>Petri</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>The Value of Staying Current when Beamforming</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beamforming is a widely used method of provisioning high quality wireless
channels that leads to high data rates and simple decoding structures. It
requires feedback of Channel State Information (CSI) from receiver to
transmitter, and the accuracy of this information is limited by rate
constraints on the feedback channel and by delay. It is important to understand
how the performance gains associated with beamforming depend on the accuracy or
currency of the Channel State Information. This paper quantifies performance
degradation caused by aging of CSI. It uses outage probability to measure the
currency of CSI, and to discount the performance gains associated with ideal
beamforming. Outage probability is a function of the beamforming algorithm and
results are presented for Transmit Antenna Selection and other widely used
methods. These results are translated into effective diversity orders for
Multiple Input Single Output (MISO) and Multiuser Multiple Input Multiple
Output (MIMO) systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5341</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5341</id><created>2010-07-29</created><updated>2010-08-02</updated><authors><author><keyname>Pantazopoulos</keyname><forenames>Panagiotis</forenames></author><author><keyname>Karaliopoulos</keyname><forenames>Merkourios</forenames></author><author><keyname>Stavrakakis</keyname><forenames>Ioannis</forenames></author></authors><title>Scalable distributed service migration via Complex Networks Analysis</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With social networking sites providing increasingly richer context,
User-Centric Service (UCS) creation is expected to explode following a similar
success path to User-Generated Content. One of the major challenges in this
emerging highly user-centric networking paradigm is how to make these exploding
in numbers yet, individually, of vanishing demand services available in a
cost-effective manner. Of prime importance to the latter (and focus of this
paper) is the determination of the optimal location for hosting a UCS. Taking
into account the particular characteristics of UCS, we formulate the problem as
a facility location problem and devise a distributed and highly scalable
heuristic solution to it.
  Key to the proposed approach is the introduction of a novel metric drawing on
Complex Network Analysis. Given a current location of UCS, this metric helps to
a) identify a small subgraph of nodes with high capacity to act as service
demand concentrators; b) project on them a reduced yet accurate view of the
global demand distribution that preserves the key attraction forces on UCS;
and, ultimately, c) pave the service migration path towards its optimal
location in the network. The proposed iterative UCS migration algorithm, called
cDSMA, is extensively evaluated over synthetic and real-world network
topologies. Our results show that cDSMA achieves high accuracy, fast
convergence, remarkable insensitivity to the size and diameter of the network
and resilience to inaccurate estimates of demands for UCS across the network.
It is also shown to clearly outperform local-search heuristics for service
migration that constrain the subgraph to the immediate neighbourhood of the
node currently hosting UCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5354</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5354</id><created>2010-07-29</created><authors><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author><author><keyname>James</keyname><forenames>Ryan G.</forenames></author><author><keyname>Mahoney</keyname><forenames>John R.</forenames></author></authors><title>Synchronization and Control in Intrinsic and Designed Computation: An
  Information-Theoretic Analysis of Competing Models of Stochastic Computation</title><categories>cond-mat.stat-mech cs.IT math.IT nlin.CD stat.ML</categories><comments>25 pages, 13 figures, 1 table</comments><doi>10.1063/1.3489888</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We adapt tools from information theory to analyze how an observer comes to
synchronize with the hidden states of a finitary, stationary stochastic
process. We show that synchronization is determined by both the process's
internal organization and by an observer's model of it. We analyze these
components using the convergence of state-block and block-state entropies,
comparing them to the previously known convergence properties of the Shannon
block entropy. Along the way, we introduce a hierarchy of information
quantifiers as derivatives and integrals of these entropies, which parallels a
similar hierarchy introduced for block entropy. We also draw out the duality
between synchronization properties and a process's controllability. The tools
lead to a new classification of a process's alternative representations in
terms of minimality, synchronizability, and unifilarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5406</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5406</id><created>2010-07-30</created><authors><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author><author><keyname>Mennicke</keyname><forenames>Roy</forenames></author></authors><title>Tree structure compression with RePair</title><categories>cs.DS</categories><msc-class>68P15 (Primary), 68P30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce a new linear time compression algorithm, called
&quot;Re-pair for Trees&quot;, which compresses ranked ordered trees using linear
straight-line context-free tree grammars. Such grammars generalize
straight-line context-free string grammars and allow basic tree operations,
like traversal along edges, to be executed without prior decompression. Our
algorithm can be considered as a generalization of the &quot;Re-pair&quot; algorithm
developed by N. Jesper Larsson and Alistair Moffat in 2000. The latter
algorithm is a dictionary-based compression algorithm for strings. We also
introduce a succinct coding which is specialized in further compressing the
grammars generated by our algorithm. This is accomplished without loosing the
ability do directly execute queries on this compressed representation of the
input tree. Finally, we compare the grammars and output files generated by a
prototype of the Re-pair for Trees algorithm with those of similar compression
algorithms. The obtained results show that that our algorithm outperforms its
competitors in terms of compression ratio, runtime and memory usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5408</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5408</id><created>2010-07-30</created><authors><author><keyname>Taricco</keyname><forenames>Giorgio</forenames></author></authors><title>A Lower Bound to the Receiver Operating Characteristic of a Cognitive
  Radio Network</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory, July 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative cognitive radio networks are investigated by using an
information-theoretic approach. This approach consists of interpreting the
decision process carried out at the fusion center as a binary (asymmetric)
channel, whose input is the presence of a primary signal and output is the
fusion center decision itself. The error probabilities of this channel are the
false-alarm and missed-detection probabilities. After calculating the mutual
information between the binary random variable representing the primary signal
presence and the set of sensor (or secondary user) output samples, we apply the
data-processing inequality to derive a lower bound to the receiver operating
characteristic. This basic idea is developed through the paper in order to
consider the cases of full channel and signal knowledge and of knowledge in
probability distribution. The advantage of this approach is that the ROC lower
bound derived is independent of the particular type of spectrum detection
algorithm and fusion rule considered. Then, it can be used as a benchmark for
existing practical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5421</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5421</id><created>2010-07-30</created><authors><author><keyname>Christiansen</keyname><forenames>Henning</forenames></author><author><keyname>Have</keyname><forenames>Christian Theil</forenames></author><author><keyname>Lassen</keyname><forenames>Ole Torp</forenames></author><author><keyname>Petit</keyname><forenames>Matthieu</forenames></author></authors><title>Inference with Constrained Hidden Markov Models in PRISM</title><categories>cs.AI cs.LO cs.PL</categories><journal-ref>TPLP 2010, 10 (4-6) 449-464</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Hidden Markov Model (HMM) is a common statistical model which is widely
used for analysis of biological sequence data and other sequential phenomena.
In the present paper we show how HMMs can be extended with side-constraints and
present constraint solving techniques for efficient inference. Defining HMMs
with side-constraints in Constraint Logic Programming have advantages in terms
of more compact expression and pruning opportunities during inference.
  We present a PRISM-based framework for extending HMMs with side-constraints
and show how well-known constraints such as cardinality and all different are
integrated. We experimentally validate our approach on the biologically
motivated problem of global pairwise alignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5425</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5425</id><created>2010-07-30</created><authors><author><keyname>Fan</keyname><forenames>Zhong</forenames></author></authors><title>Distributed Demand Response and User Adaptation in Smart Grids</title><categories>cs.NI cs.DC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper proposes a distributed framework for demand response and user
adaptation in smart grid networks. In particular, we borrow the concept of
congestion pricing in Internet traffic control and show that pricing
information is very useful to regulate user demand and hence balance network
load. User preference is modeled as a willingness to pay parameter which can be
seen as an indicator of differential quality of service. Both analysis and
simulation results are presented to demonstrate the dynamics and convergence
behavior of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5442</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5442</id><created>2010-07-30</created><authors><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author><author><keyname>Pillwein</keyname><forenames>Veronika</forenames></author><author><keyname>Saminger-Platz</keyname><forenames>Susanne</forenames></author></authors><title>Dominance in the family of Sugeno-Weber t-norms</title><categories>math.FA cs.SC</categories><msc-class>26D07, 39B99, 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dominance relationship between two members of the family of Sugeno Weber
t-norms is proven by using a quantifer elimination algorithm. Further it is
shown that dominance is a transitive, and therefore also an order relation, on
this family of t-norms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5450</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5450</id><created>2010-07-30</created><authors><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Known Algorithms on Graphs of Bounded Treewidth are Probably Optimal</title><categories>cs.DS cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a number of lower bounds on the running time of algorithms solving
problems on graphs of bounded treewidth. We prove the results under the Strong
Exponential Time Hypothesis of Impagliazzo and Paturi. In particular, assuming
that SAT cannot be solved in (2-\epsilon)^{n}m^{O(1)} time, we show that for
any e &gt; 0; {\sc Independent Set} cannot be solved in (2-e)^{tw(G)}|V(G)|^{O(1)}
time, {\sc Dominating Set} cannot be solved in (3-e)^{tw(G)}|V(G)|^{O(1)} time,
{\sc Max Cut} cannot be solved in (2-e)^{tw(G)}|V(G)|^{O(1)} time, {\sc Odd
Cycle Transversal} cannot be solved in (3-e)^{tw(G)}|V(G)|^{O(1)} time, For any
$q \geq 3$, $q$-{\sc Coloring} cannot be solved in (q-e)^{tw(G)}|V(G)|^{O(1)}
time, {\sc Partition Into Triangles} cannot be solved in
(2-e)^{tw(G)}|V(G)|^{O(1)} time. Our lower bounds match the running times for
the best known algorithms for the problems, up to the e in the base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5459</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5459</id><created>2010-07-30</created><updated>2011-05-30</updated><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>Lopez</keyname><forenames>Yoann</forenames></author><author><keyname>Leguay</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author></authors><title>Relieving the Wireless Infrastructure: When Opportunistic Networks Meet
  Guaranteed Delays</title><categories>cs.NI</categories><comments>Accepted at IEEE WoWMoM 2011 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Major wireless operators are nowadays facing network capacity issues in
striving to meet the growing demands of mobile users. At the same time,
3G-enabled devices increasingly benefit from ad hoc radio connectivity (e.g.,
Wi-Fi). In this context of hybrid connectivity, we propose Push-and-track, a
content dissemination framework that harnesses ad hoc communication
opportunities to minimize the load on the wireless infrastructure while
guaranteeing tight delivery delays. It achieves this through a control loop
that collects user-sent acknowledgements to determine if new copies need to be
reinjected into the network through the 3G interface. Push-and-Track includes
multiple strategies to determine how many copies of the content should be
injected, when, and to whom. The short delay-tolerance of common content, such
as news or road traffic updates, make them suitable for such a system. Based on
a realistic large-scale vehicular dataset from the city of Bologna composed of
more than 10,000 vehicles, we demonstrate that Push-and-Track consistently
meets its delivery objectives while reducing the use of the 3G network by over
90%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5475</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5475</id><created>2010-07-30</created><authors><author><keyname>Gla&#xdf;er</keyname><forenames>Christian</forenames></author><author><keyname>Reitwie&#xdf;ner</keyname><forenames>Christian</forenames></author><author><keyname>Witek</keyname><forenames>Maximilian</forenames></author></authors><title>Balanced Combinations of Solutions in Multi-Objective Optimization</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every list of integers x_1, ..., x_m there is some j such that x_1 + ...
+ x_j - x_{j+1} - ... - x_m \approx 0. So the list can be nearly balanced and
for this we only need one alternation between addition and subtraction. But
what if the x_i are k-dimensional integer vectors? Using results from
topological degree theory we show that balancing is still possible, now with k
alternations.
  This result is useful in multi-objective optimization, as it allows a
polynomial-time computable balance of two alternatives with conflicting costs.
The application to two multi-objective optimization problems yields the
following results:
  - A randomized 1/2-approximation for multi-objective maximum asymmetric
traveling salesman, which improves and simplifies the best known approximation
for this problem.
  - A deterministic 1/2-approximation for multi-objective maximum weighted
satisfiability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5476</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5476</id><created>2010-07-30</created><authors><author><keyname>Laddha</keyname><forenames>Prerana</forenames></author></authors><title>Degree of Separation in Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>9 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the small-world concept, the entire world is connected through
short chains of acquaintances. In popular imagination this is captured in the
phrase six degrees of separation, implying that any two individuals are, at
most, six handshakes away. Social network analysis is the understanding of
concepts and information on relationships among interacting units in an
ecological system. In this analysis the properties of the actors are explained
in terms of the structures of links amongst them. In general, the relational
links between the actors are primary and the properties of the actors are
secondary. This paper presents two methods to calculate the average degree of
separation between the actors or nodes in a graph. We apply this approach to
other random graphs depicting social networks and then compare the
characteristics of these graphs with the average degree of separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5488</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5488</id><created>2010-07-30</created><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Plotkin</keyname><forenames>Gordon</forenames></author></authors><title>On CSP and the Algebraic Theory of Effects</title><categories>cs.LO</categories><doi>10.1007/978-1-84882-912-1_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider CSP from the point of view of the algebraic theory of effects,
which classifies operations as effect constructors or effect deconstructors; it
also provides a link with functional programming, being a refinement of Moggi's
seminal monadic point of view. There is a natural algebraic theory of the
constructors whose free algebra functor is Moggi's monad; we illustrate this by
characterising free and initial algebras in terms of two versions of the stable
failures model of CSP, one more general than the other. Deconstructors are
dealt with as homomorphisms to (possibly non-free) algebras.
  One can view CSP's action and choice operators as constructors and the rest,
such as concealment and concurrency, as deconstructors. Carrying this programme
out results in taking deterministic external choice as constructor rather than
general external choice. However, binary deconstructors, such as the CSP
concurrency operator, provide unresolved difficulties. We conclude by
presenting a combination of CSP with Moggi's computational {\lambda}-calculus,
in which the operators, including concurrency, are polymorphic. While the paper
mainly concerns CSP, it ought to be possible to carry over similar ideas to
other process calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5491</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5491</id><created>2010-07-30</created><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author></authors><title>The Coarsest Precongruences Respecting Safety and Liveness Properties</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper characterises the coarsest refinement preorders on labelled
transition systems that are precongruences for renaming and partially
synchronous interleaving operators, and respect all safety, liveness, and
conditional liveness properties, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5510</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5510</id><created>2010-07-30</created><updated>2011-03-19</updated><authors><author><keyname>Halko</keyname><forenames>Nathan</forenames></author><author><keyname>Martinsson</keyname><forenames>Per-Gunnar</forenames></author><author><keyname>Shkolnisky</keyname><forenames>Yoel</forenames></author><author><keyname>Tygert</keyname><forenames>Mark</forenames></author></authors><title>An algorithm for the principal component analysis of large data sets</title><categories>stat.CO cs.NA</categories><comments>17 pages, 3 figures (each with 2 or 3 subfigures), 2 tables (each
  with 2 subtables)</comments><journal-ref>SIAM Journal on Scientific Computing, 33 (5): 2580-2594, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently popularized randomized methods for principal component analysis
(PCA) efficiently and reliably produce nearly optimal accuracy --- even on
parallel processors --- unlike the classical (deterministic) alternatives. We
adapt one of these randomized methods for use with data sets that are too large
to be stored in random-access memory (RAM). (The traditional terminology is
that our procedure works efficiently &quot;out-of-core.&quot;) We illustrate the
performance of the algorithm via several numerical examples. For example, we
report on the PCA of a data set stored on disk that is so large that less than
a hundredth of it can fit in our computer's RAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1007.5514</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1007.5514</id><created>2010-07-30</created><authors><author><keyname>Koyuncu</keyname><forenames>Erdem</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>Distributed Beamforming in Wireless Multiuser Relay-Interference
  Networks with Quantized Feedback</title><categories>cs.IT math.IT</categories><comments>41 pages, 14 figures, submitted to IEEE Transactions on Information
  Theory, July 2010. This work was presented in part at IEEE Global
  Communications Conference (GLOBECOM), Nov. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study quantized beamforming in wireless amplify-and-forward
relay-interference networks with any number of transmitters, relays, and
receivers. We design the quantizer of the channel state information to minimize
the probability that at least one receiver incorrectly decodes its desired
symbol(s). Correspondingly, we introduce a generalized diversity measure that
encapsulates the conventional one as the first-order diversity. Additionally,
it incorporates the second-order diversity, which is concerned with the
transmitter power dependent logarithmic terms that appear in the error rate
expression. First, we show that, regardless of the quantizer and the amount of
feedback that is used, the relay-interference network suffers a second-order
diversity loss compared to interference-free networks. Then, two different
quantization schemes are studied: First, using a global quantizer, we show that
a simple relay selection scheme can achieve maximal diversity. Then, using the
localization method, we construct both fixed-length and variable-length local
(distributed) quantizers (fLQs and vLQs). Our fLQs achieve maximal first-order
diversity, whereas our vLQs achieve maximal diversity. Moreover, we show that
all the promised diversity and array gains can be obtained with arbitrarily low
feedback rates when the transmitter powers are sufficiently large. Finally, we
confirm our analytical findings through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0011</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0011</id><created>2010-07-30</created><authors><author><keyname>Kredel</keyname><forenames>Heinz</forenames></author></authors><title>Parallel and distributed Gr\&quot;obner bases computation in JAS</title><categories>cs.DC</categories><comments>14 pages, 8 tables, 13 figures</comments><msc-class>13P10</msc-class><acm-class>G.4; I.1.3; D.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers parallel Gr\&quot;obner bases algorithms on distributed
memory parallel computers with multi-core compute nodes. We summarize three
different Gr\&quot;obner bases implementations: shared memory parallel, pure
distributed memory parallel and distributed memory combined with shared memory
parallelism. The last algorithm, called distributed hybrid, uses only one
control communication channel between the master node and the worker nodes and
keeps polynomials in shared memory on a node. The polynomials are transported
asynchronous to the control-flow of the algorithm in a separate distributed
data structure. The implementation is generic and works for all implemented
(exact) fields. We present new performance measurements and discuss the
performance of the algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0042</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0042</id><created>2010-07-30</created><updated>2010-09-07</updated><authors><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author></authors><title>Weblog patterns and human dynamics with decreasing interest</title><categories>cs.SI physics.soc-ph</categories><comments>8 pages, 1 figures</comments><journal-ref>Eur. Phys. J. B 81, 341-344 (2011)</journal-ref><doi>10.1140/epjb/e2011-10722-1</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Weblog is the fourth way of network exchange after Email, BBS and MSN. Most
bloggers begin to write blogs with great interest, and then their interests
gradually achieve a balance with the passage of time. In order to describe the
phenomenon that people's interest in something gradually decreases until it
reaches a balance, we first propose the model that describes the attenuation of
interest and reflects the fact that people's interest becomes more stable after
a long time. We give a rigorous analysis on this model by non-homogeneous
Poisson processes. Our analysis indicates that the interval distribution of
arrival-time is a mixed distribution with exponential and power-law feature,
that is, it is a power law with an exponential cutoff. Second, we collect blogs
in ScienceNet.cn and carry on empirical studies on the interarrival time
distribution. The empirical results agree well with the analytical result,
obeying a special power law with the exponential cutoff, that is, a special
kind of Gamma distribution. These empirical results verify the model, providing
an evidence for a new class of phenomena in human dynamics. In human dynamics
there are other distributions, besides power-law distributions. These findings
demonstrate the variety of human behavior dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0044</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0044</id><created>2010-07-30</created><updated>2011-06-01</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Network Control: A Rate-Distortion Perspective</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to appear in ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's networks are controlled assuming pre-compressed and packetized data.
For video, this assumption of data packets abstracts out one of the key aspects
- the lossy compression problem. Therefore, first, this paper develops a
framework for network control that incorporates both source-rate and
source-distortion. Next, it decomposes the network control problem into an
application-layer compression control, a transport-layer congestion control and
a network-layer scheduling. It is shown that this decomposition is optimal for
concave utility functions. Finally, this paper derives further insights from
the developed rate-distortion framework by focusing on specific problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0045</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0045</id><created>2010-07-30</created><updated>2010-08-03</updated><authors><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Vyetrenko</keyname><forenames>Svitlana</forenames></author><author><keyname>Xia</keyname><forenames>Lingxiao</forenames></author></authors><title>Universal and Robust Distributed Network Codes</title><categories>cs.IT math.IT</categories><comments>12 pages, 7 figures, 1 table, under submission to INFOCOM 2011</comments><msc-class>68Q30</msc-class><acm-class>E.4; H.1.1; D.4.4; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random linear network codes can be designed and implemented in a distributed
manner, with low computational complexity. However, these codes are classically
implemented over finite fields whose size depends on some global network
parameters (size of the network, the number of sinks) that may not be known
prior to code design. Also, if new nodes join the entire network code may have
to be redesigned.
  In this work, we present the first universal and robust distributed linear
network coding schemes. Our schemes are universal since they are independent of
all network parameters. They are robust since if nodes join or leave, the
remaining nodes do not need to change their coding operations and the receivers
can still decode. They are distributed since nodes need only have topological
information about the part of the network upstream of them, which can be
naturally streamed as part of the communication protocol.
  We present both probabilistic and deterministic schemes that are all
asymptotically rate-optimal in the coding block-length, and have guarantees of
correctness. Our probabilistic designs are computationally efficient, with
order-optimal complexity. Our deterministic designs guarantee zero error
decoding, albeit via codes with high computational complexity in general. Our
coding schemes are based on network codes over ``scalable fields&quot;. Instead of
choosing coding coefficients from one field at every node, each node uses
linear coding operations over an ``effective field-size&quot; that depends on the
node's distance from the source node. The analysis of our schemes requires
technical tools that may be of independent interest. In particular, we
generalize the Schwartz-Zippel lemma by proving a non-uniform version, wherein
variables are chosen from sets of possibly different sizes. We also provide a
novel robust distributed algorithm to assign unique IDs to network nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0047</identifier>
 <datestamp>2012-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0047</id><created>2010-07-30</created><authors><author><keyname>Cheng</keyname><forenames>Yong</forenames><affiliation>Student Member, IEEE</affiliation></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames><affiliation>Senior Member, IEEE</affiliation></author><author><keyname>Long</keyname><forenames>Yi</forenames></author></authors><title>A Scalable Limited Feedback Design for Network MIMO using Per-Cell
  Product Codebook</title><categories>cs.IT math.IT</categories><comments>11 pages, 5 figures, Accepted to the IEEE transactions on Wireless
  Communication</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In network MIMO systems, channel state information is required at the
transmitter side to multiplex users in the spatial domain. Since perfect
channel knowledge is difficult to obtain in practice, \emph{limited feedback}
is a widely accepted solution. The {\em dynamic number of cooperating BSs} and
{\em heterogeneous path loss effects} of network MIMO systems pose new
challenges on limited feedback design. In this paper, we propose a scalable
limited feedback design for network MIMO systems with multiple base stations,
multiple users and multiple data streams for each user. We propose a {\em
limited feedback framework using per-cell product codebooks}, along with a {\em
low-complexity feedback indices selection algorithm}. We show that the proposed
per-cell product codebook limited feedback design can asymptotically achieve
the same performance as the joint-cell codebook approach. We also derive an
asymptotic \emph{per-user throughput loss} due to limited feedback with
per-cell product codebooks. Based on that, we show that when the number of
per-user feedback-bits $B_{k}$ is $\mathcal{O}\big( Nn_{T}n_{R}\log_{2}(\rho
g_{k}^{sum})\big)$, the system operates in the \emph{noise-limited} regime in
which the per-user throughput is $\mathcal{O} \left( n_{R} \log_{2} \big(
\frac{n_{R}\rho g_{k}^{sum}}{Nn_{T}} \big) \right)$. On the other hand, when
the number of per-user feedback-bits $B_{k}$ does not scale with the
\emph{system SNR} $\rho$, the system operates in the
\emph{interference-limited} regime where the per-user throughput is
$\mathcal{O}\left( \frac{n_{R}B_{k}}{(Nn_{T})^{2}} \right)$. Numerical results
show that the proposed design is very flexible to accommodate dynamic number of
cooperating BSs and achieves much better performance compared with other
baselines (such as the Givens rotation approach).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0050</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0050</id><created>2010-07-31</created><authors><author><keyname>L&#xfc;bben</keyname><forenames>Ralf</forenames></author><author><keyname>Fidler</keyname><forenames>Markus</forenames></author><author><keyname>Liebeherr</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>A Foundation for Stochastic Bandwidth Estimation of Networks with Random
  Service</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a stochastic foundation for bandwidth estimation of networks with
random service, where bandwidth availability is expressed in terms of bounding
functions with a defined violation probability. Exploiting properties of a
stochastic max-plus algebra and system theory, the task of bandwidth estimation
is formulated as inferring an unknown bounding function from measurements of
probing traffic. We derive an estimation methodology that is based on iterative
constant rate probes. Our solution provides evidence for the utility of packet
trains for bandwidth estimation in the presence of variable cross traffic.
Taking advantage of statistical methods, we show how our estimation method can
be realized in practice, with adaptive train lengths of probe packets, probing
rates, and replicated measurements required to achieve both high accuracy and
confidence levels. We evaluate our method in a controlled testbed network,
where we show the impact of cross traffic variability on the time-scales of
service availability, and provide a comparison with existing bandwidth
estimation tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0053</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0053</id><created>2010-07-31</created><updated>2010-08-13</updated><authors><author><keyname>Yao</keyname><forenames>Hongyi</forenames></author><author><keyname>Li</keyname><forenames>Xiaohang</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Achieving the Scaling Law of SNR-Monitoring in Dynamic Wireless Networks</title><categories>cs.NI</categories><comments>The revised version achieves the scaling law for general
  communication wireless networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The characteristics of wireless communication channels may vary with time due
to fading, environmental changes and movement of mobile wireless devices.
Tracking and estimating channel gains of wireless channels is therefore a
fundamentally important element of many wireless communication systems. In
particular, the receivers in many wireless networks need to estimate the
channel gains by means of a training sequence. This paper studies the scaling
law (on the network size) of the overhead for channel gain monitoring in
wireless network. We first investigate the scenario in which a receiver needs
to track the channel gains with respect to multiple transmitters. To be
concrete, suppose that there are n transmitters, and that in the current round
of channel-gain estimation, no more than k channels suffer significant
variations since the last round. We proves that &quot;\Theta(k\log((n+1)/k)) time
slots&quot; is the minimum number of time slots needed to catch up with the k varied
channels. At the same time, we propose a novel channel-gain monitoring scheme
named ADMOT to achieve the overhead lower-bound. ADMOT leverages recent
advances in compressive sensing in signal processing and interference
processing in wireless communication, to enable the receiver to estimate all n
channels in a reliable and computationally efficient manner within
O(k\log((n+1)/k)) time slots. To our best knowledge, all previous
channel-tracking schemes require \Theta(n) time slots regardless of k. Note
that based on above results for single receiver scenario, the scaling law of
general setting is achieved in which there are multiple transmitters, relay
nodes and receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0060</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0060</id><created>2010-07-31</created><authors><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author><author><keyname>Madan</keyname><forenames>Ritesh</forenames></author></authors><title>Belief Propagation Methods for Intercell Interference Coordination</title><categories>cs.NI</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a broad class of interference coordination and resource
allocation problems for wireless links where the goal is to maximize the sum of
functions of individual link rates. Such problems arise in the context of, for
example, fractional frequency reuse (FFR) for macro-cellular networks and
dynamic interference management in femtocells. The resulting optimization
problems are typically hard to solve optimally even using centralized
algorithms but are an essential computational step in implementing rate-fair
and queue stabilizing scheduling policies in wireless networks. We consider a
belief propagation framework to solve such problems approximately. In
particular, we construct approximations to the belief propagation iterations to
obtain computationally simple and distributed algorithms with low communication
overhead. Notably, our methods are very general and apply to, for example, the
optimization of transmit powers, transmit beamforming vectors, and sub-band
allocation to maximize the above objective. Numerical results for femtocell
deployments demonstrate that such algorithms compute a very good operating
point in typically just a couple of iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0063</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0063</id><created>2010-07-31</created><authors><author><keyname>Skobtsov</keyname><forenames>Y. A.</forenames></author><author><keyname>Ivanov</keyname><forenames>D. E.</forenames></author><author><keyname>Skobtsov</keyname><forenames>V. Y.</forenames></author><author><keyname>Ubar</keyname><forenames>R.</forenames></author><author><keyname>Raik</keyname><forenames>J.</forenames></author></authors><title>Evolutionary Approach to Test Generation for Functional BIST</title><categories>cs.NE</categories><comments>10 European Test Symposium. Informal Digest of Papers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, an evolutionary approach to test generation for functional BIST
is considered. The aim of the proposed scheme is to minimize the test data
volume by allowing the device's microprogram to test its logic, providing an
observation structure to the system, and generating appropriate test data for
the given architecture. Two methods of deriving a deterministic test set at
functional level are suggested. The first method is based on the classical
genetic algorithm with binary and arithmetic crossover and mutation operators.
The second one uses genetic programming, where test is represented as a
sequence of microoperations. In the latter case, we apply two-point crossover
based on exchanging test subsequences and mutation implemented as random
replacement of microoperations or operands. Experimental data of the program
realization showing the efficiency of the proposed methods are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0064</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0064</id><created>2010-07-31</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>Self-repairing Homomorphic Codes for Distributed Storage Systems</title><categories>cs.DC</categories><journal-ref>Infocom 2011, The 30th IEEE International Conference on Computer
  Communications</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erasure codes provide a storage efficient alternative to replication based
redundancy in (networked) storage systems. They however entail high
communication overhead for maintenance, when some of the encoded fragments are
lost and need to be replenished. Such overheads arise from the fundamental need
to recreate (or keep separately) first a copy of the whole object before any
individual encoded fragment can be generated and replenished. There has been
recently intense interest to explore alternatives, most prominent ones being
regenerating codes (RGC) and hierarchical codes (HC). We propose as an
alternative a new family of codes to improve the maintenance process, which we
call self-repairing codes (SRC), with the following salient features: (a)
encoded fragments can be repaired directly from other subsets of encoded
fragments without having to reconstruct first the original data, ensuring that
(b) a fragment is repaired from a fixed number of encoded fragments, the number
depending only on how many encoded blocks are missing and independent of which
specific blocks are missing. These properties allow for not only low
communication overhead to recreate a missing fragment, but also independent
reconstruction of different missing fragments in parallel, possibly in
different parts of the network. We analyze the static resilience of SRCs with
respect to traditional erasure codes, and observe that SRCs incur marginally
larger storage overhead in order to achieve the aforementioned properties. The
salient SRC properties naturally translate to low communication overheads for
reconstruction of lost fragments, and allow reconstruction with lower latency
by facilitating repairs in parallel. These desirable properties make
self-repairing codes a good and practical candidate for networked distributed
storage systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0074</identifier>
 <datestamp>2015-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0074</id><created>2010-07-31</created><updated>2010-12-21</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Brandt</keyname><forenames>Felix</forenames></author><author><keyname>Seedig</keyname><forenames>Hans Georg</forenames></author></authors><title>Stable partitions in additively separable hedonic games</title><categories>cs.GT cs.CC</categories><comments>13 pages, 5 Figures</comments><msc-class>91A12, 68Q15</msc-class><acm-class>F.2; J.4</acm-class><journal-ref>Artificial Intelligence 195, 2013</journal-ref><doi>10.1016/j.artint.2012.09.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important aspect in systems of multiple autonomous agents is the
exploitation of synergies via coalition formation. In this paper, we solve
various open problems concerning the computational complexity of stable
partitions in additively separable hedonic games. First, we propose a
polynomial-time algorithm to compute a contractually individually stable
partition. This contrasts with previous results such as the NP-hardness of
computing individually stable or Nash stable partitions. Secondly, we prove
that checking whether the core or the strict core exists is NP-hard in the
strong sense even if the preferences of the players are symmetric. Finally, it
is shown that verifying whether a partition consisting of the grand coalition
is contractually strict core stable or Pareto optimal is coNP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0075</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0075</id><created>2010-07-31</created><updated>2010-12-21</updated><authors><author><keyname>Peres</keyname><forenames>Yuval</forenames></author><author><keyname>Sinclair</keyname><forenames>Alistair</forenames></author><author><keyname>Sousi</keyname><forenames>Perla</forenames></author><author><keyname>Stauffer</keyname><forenames>Alexandre</forenames></author></authors><title>Mobile Geometric Graphs: Detection, Coverage and Percolation</title><categories>math.PR cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following dynamic Boolean model introduced by van den Berg,
Meester and White (1997). At time 0, let the nodes of the graph be a Poisson
point process in R^d with constant intensity and let each node move
independently according to Brownian motion. At any time t, we put an edge
between every pair of nodes if their distance is at most r. We study three
features in this model: detection (the time until a target point---fixed or
moving---is within distance r from some node of the graph), coverage (the time
until all points inside a finite box are detected by the graph), and
percolation (the time until a given node belongs to the infinite connected
component of the graph). We obtain precise asymptotics for these features by
combining ideas from stochastic geometry, coupling and multi-scale analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0092</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0092</id><created>2010-07-31</created><authors><author><keyname>Bin</keyname><forenames>Deng</forenames></author></authors><title>WLAN PIDS</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discuss two structures of WLAN system fit to Passenger Information
Display System which is partly of subway.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0125</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0125</id><created>2010-07-31</created><authors><author><keyname>Martinelli</keyname><forenames>Fabio</forenames></author><author><keyname>Sinclair</keyname><forenames>Alistair</forenames></author></authors><title>Mixing Time for the Solid-on-Solid Model</title><categories>math-ph cs.DS math.MP math.PR</categories><comments>A preliminary version of this paper appeared in Proceedings of the
  41st ACM Symposium on Theory of Computer Science (STOC), 2009, pages 571-580</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the mixing time of a natural local Markov chain (the Glauber
dynamics) on configurations of the solid-on-solid model of statistical physics.
This model has been proposed, among other things, as an idealization of the
behavior of contours in the Ising model at low temperatures. Our main result is
an upper bound on the mixing time of $O~(n^{3.5})$, which is tight within a
factor of $O~(sqrt{n})$. (The notation O~ hides factors that are logarithmic in
n.) The proof, which in addition gives some insight into the actual evolution
of the contours, requires the introduction of a number of novel analytical
techniques that we conjecture will have other applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0135</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0135</id><created>2010-07-31</created><authors><author><keyname>Hassan</keyname><forenames>A. H.</forenames></author><author><keyname>Fluke</keyname><forenames>C. J.</forenames></author><author><keyname>Barnes</keyname><forenames>D. G.</forenames></author></authors><title>Interactive Visualization of the Largest Radioastronomy Cubes</title><categories>astro-ph.IM cs.DC</categories><comments>15 pages, 12 figures, Accepted New Astronomy July 2010</comments><journal-ref>New Astronomy 16 (2011), pp. 100-109</journal-ref><doi>10.1016/j.newast.2010.07.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3D visualization is an important data analysis and knowledge discovery tool,
however, interactive visualization of large 3D astronomical datasets poses a
challenge for many existing data visualization packages. We present a solution
to interactively visualize larger-than-memory 3D astronomical data cubes by
utilizing a heterogeneous cluster of CPUs and GPUs. The system partitions the
data volume into smaller sub-volumes that are distributed over the rendering
workstations. A GPU-based ray casting volume rendering is performed to generate
images for each sub-volume, which are composited to generate the whole volume
output, and returned to the user. Datasets including the HI Parkes All Sky
Survey (HIPASS - 12 GB) southern sky and the Galactic All Sky Survey (GASS - 26
GB) data cubes were used to demonstrate our framework's performance. The
framework can render the GASS data cube with a maximum render time &lt; 0.3 second
with 1024 x 1024 pixels output resolution using 3 rendering workstations and 8
GPUs. Our framework will scale to visualize larger datasets, even of Terabyte
order, if proper hardware infrastructure is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0140</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0140</id><created>2010-07-31</created><authors><author><keyname>Shuaib</keyname><forenames>Mohammed Mahmod</forenames></author><author><keyname>Zainuddin</keyname><forenames>Zarita</forenames></author><author><keyname>Abu-Sulyman</keyname><forenames>Ibtesam M</forenames></author></authors><title>The Characteristics of the Factors That Govern the Preferred Force in
  the Social Force Model of Pedestrian Movement</title><categories>cs.IT math.IT</categories><comments>World Academy of Science, Engineering and Technology 62 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The social force model which belongs to the microscopic pedestrian studies
has been considered as the supremacy by many researchers and due to the main
feature of reproducing the self-organized phenomena resulted from pedestrian
dynamic. The Preferred Force which is a measurement of pedestrian's motivation
to adapt his actual velocity to his desired velocity is an essential term on
which the model was set up. This Force has gone through stages of development:
first of all, Helbing and Molnar (1995) have modeled the original force for the
normal situation. Second, Helbing and his co-workers (2000) have incorporated
the panic situation into this force by incorporating the panic parameter to
account for the panic situations. Third, Lakoba and Kaup (2005) have provided
the pedestrians some kind of intelligence by incorporating aspects of the
decision-making capability. In this paper, the authors analyze the most
important incorporations into the model regarding the preferred force. They
make comparisons between the different factors of these incorporations.
Furthermore, to enhance the decision-making ability of the pedestrians, they
introduce additional features such as the familiarity factor to the preferred
force to let it appear more representative of what actually happens in reality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0143</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0143</id><created>2010-07-31</created><updated>2011-02-25</updated><authors><author><keyname>Shi</keyname><forenames>Xiaomeng</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Lucani</keyname><forenames>Daniel</forenames></author></authors><title>When Both Transmitting and Receiving Energies Matter: An Application of
  Network Coding in Wireless Body Area Networks</title><categories>cs.NI</categories><comments>10 pages, 7 figures, submitted to the NC-Pro Workshop at IFIP
  Networking Conference 2011, and to appear in the conference proceedings,
  published by Springer-Verlag, in the Lecture Notes in Computer Science (LNCS)
  series</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network coding scheme for practical implementations of wireless body area
networks is presented, with the objective of providing reliability under
low-energy constraints. We propose a simple network layer protocol for star
networks, adapting redundancy based on both transmission and reception energies
for data and control packets, as well as channel conditions. Our numerical
results show that even for small networks, the amount of energy reduction
achievable can range from 29% to 87%, as the receiving energy per control
packet increases from equal to much larger than the transmitting energy per
data packet. The achievable gains increase as a) more nodes are added to the
network, and/or b) the channels seen by different sensor nodes become more
asymmetric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0147</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0147</id><created>2010-08-01</created><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Intervention Mechanism Design for Networks With Selfish Users</title><categories>cs.GT cs.MA</categories><comments>20 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-user network where a network manager and selfish users
interact. The network manager monitors the behavior of users and intervenes in
the interaction among users if necessary, while users make decisions
independently to optimize their individual objectives. In this paper, we
develop a framework of intervention mechanism design, which is aimed to
optimize the objective of the manager, or the network performance, taking the
incentives of selfish users into account. Our framework is general enough to
cover a wide range of application scenarios, and it has advantages over
existing approaches such as Stackelberg strategies and pricing. To design an
intervention mechanism and to predict the resulting operating point, we
formulate a new class of games called intervention games and a new solution
concept called intervention equilibrium. We provide analytic results about
intervention equilibrium and optimal intervention mechanisms in the case of a
benevolent manager with perfect monitoring. We illustrate these results with a
random access model. Our illustrative example suggests that intervention
requires less knowledge about users than pricing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0170</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0170</id><created>2010-08-01</created><authors><author><keyname>Moortgat</keyname><forenames>Michael</forenames></author></authors><title>Symmetric categorial grammar: residuation and Galois connections</title><categories>cs.CL</categories><comments>Submitted to the Jim Lambek Festschrift of Linguistic Analysis (LA,
  volume 36, to appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lambek-Grishin calculus is a symmetric extension of the Lambek calculus:
in addition to the residuated family of product, left and right division
operations of Lambek's original calculus, one also considers a family of
coproduct, right and left difference operations, related to the former by an
arrow-reversing duality. Communication between the two families is implemented
in terms of linear distributivity principles. The aim of this paper is to
complement the symmetry between (dual) residuated type-forming operations with
an orthogonal opposition that contrasts residuated and Galois connected
operations. Whereas the (dual) residuated operations are monotone, the Galois
connected operations (and their duals) are antitone. We discuss the algebraic
properties of the (dual) Galois connected operations, and generalize the
(co)product distributivity principles to include the negative operations. We
give a continuation-passing-style translation for the new type-forming
operations, and discuss some linguistic applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0178</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0178</id><created>2010-08-01</created><updated>2010-08-03</updated><authors><author><keyname>Gao</keyname><forenames>Lei</forenames></author></authors><title>Dictionary for Sparse Representation of Chirp Echo in Broadband Radar</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new dictionary for sparse representation of chirp echo in broadband radar
is put forward in this paper. Different with chirplet decomposition which
decomposes echo in time-frequency plane, the dictionary transforms the sparsity
of target observed by radar in distance range to the sparsity in frequency
domain by stretch processing and the sparse representation of echo is realized.
Using strict deduction with mathematics, the sparsity of echo in dictionary is
proved and the dictionary is orthogonal. In the application property, the
construction of dictionary is simple, the parameters that are needed for
dictionary can be obtained conveniently and the dictionary is convenient to
use. Furthermore, the object of application can be expanded to the echo of
multi-component chirps with single freedom degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0201</identifier>
 <datestamp>2011-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0201</id><created>2010-08-01</created><updated>2011-05-17</updated><authors><author><keyname>Singer</keyname><forenames>Sanja</forenames></author><author><keyname>Singer</keyname><forenames>Sasa</forenames></author><author><keyname>Novakovic</keyname><forenames>Vedran</forenames></author><author><keyname>Uscumlic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Dunjko</keyname><forenames>Vedran</forenames></author></authors><title>Novel Modifications of Parallel Jacobi Algorithms</title><categories>cs.NA math.NA</categories><comments>Accepted for publication in Numerical Algorithms</comments><msc-class>68W10 (Primary) 65F15, 65Y05, 65Y20 (Secondary)</msc-class><acm-class>G.1.3; G.4</acm-class><doi>10.1007/s11075-011-9473-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe two main classes of one-sided trigonometric and hyperbolic
Jacobi-type algorithms for computing eigenvalues and eigenvectors of Hermitian
matrices. These types of algorithms exhibit significant advantages over many
other eigenvalue algorithms. If the matrices permit, both types of algorithms
compute the eigenvalues and eigenvectors with high relative accuracy.
  We present novel parallelization techniques for both trigonometric and
hyperbolic classes of algorithms, as well as some new ideas on how pivoting in
each cycle of the algorithm can improve the speed of the parallel one-sided
algorithms. These parallelization approaches are applicable to both
distributed-memory and shared-memory machines.
  The numerical testing performed indicates that the hyperbolic algorithms may
be superior to the trigonometric ones, although, in theory, the latter seem
more natural.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0208</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0208</id><created>2010-08-01</created><updated>2010-08-03</updated><authors><author><keyname>Xu</keyname><forenames>Gang</forenames></author><author><keyname>Wang</keyname><forenames>Guozhao</forenames></author></authors><title>Parametric polynomial minimal surfaces of arbitrary degree</title><categories>cs.GR math.DG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weierstrass representation is a classical parameterization of minimal
surfaces. However, two functions should be specified to construct the
parametric form in Weierestrass representation. In this paper, we propose an
explicit parametric form for a class of parametric polynomial minimal surfaces
of arbitrary degree. It includes the classical Enneper surface for cubic case.
The proposed minimal surfaces also have some interesting properties such as
symmetry, containing straight lines and self-intersections. According to the
shape properties, the proposed minimal surface can be classified into four
categories with respect to $n=4k-1$ $n=4k+1$, $n=4k$ and $n=4k+2$. The explicit
parametric form of corresponding conjugate minimal surfaces is given and the
isometric deformation is also implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0212</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0212</id><created>2010-08-01</created><authors><author><keyname>Kanoria</keyname><forenames>Yashodhan</forenames></author></authors><title>An FPTAS for Bargaining Networks with Unequal Bargaining Powers</title><categories>cs.GT cs.MA</categories><comments>18 pages; Amin Saberi (Ed.): Internet and Network Economics - 6th
  International Workshop, WINE 2010, Stanford, CA, USA, December 13-17, 2010.
  Proceedings.</comments><journal-ref>Lecture Notes in Computer Science 6484 Springer (2010) 282-293</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bargaining networks model social or economic situations in which agents seek
to form the most lucrative partnership with another agent from among several
alternatives. There has been a flurry of recent research studying Nash
bargaining solutions (also called 'balanced outcomes') in bargaining networks,
so that we now know when such solutions exist, and also that they can be
computed efficiently, even by market agents behaving in a natural manner. In
this work we study a generalization of Nash bargaining, that models the
possibility of unequal 'bargaining powers'. This generalization was introduced
in [KB+10], where it was shown that the corresponding 'unequal division' (UD)
solutions exist if and only if Nash bargaining solutions exist, and also that a
certain local dynamics converges to UD solutions when they exist. However, the
bound on convergence time obtained for that dynamics was exponential in network
size for the unequal division case. This bound is tight, in the sense that
there exists instances on which the dynamics of [KB+10] converges only after
exponential time. Other approaches, such as the one of Kleinberg and Tardos, do
not generalize to the unsymmetrical case. Thus, the question of computational
tractability of UD solutions has remained open. In this paper, we provide an
FPTAS for the computation of UD solutions, when such solutions exist. On a
graph G=(V,E) with weights (i.e. pairwise profit opportunities) uniformly
bounded above by 1, our FPTAS finds an \eps-UD solution in time
poly(|V|,1/\eps). We also provide a fast local algorithm for finding \eps-UD
solution, providing further justification that a market can find such a
solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0213</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0213</id><created>2010-08-01</created><updated>2011-10-14</updated><authors><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Improved Parameterized Algorithms for Constraint Satisfaction</title><categories>cs.DS cs.CC</categories><comments>A preliminary version of this paper has been accepted for IPEC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many constraint satisfaction problems, the algorithm which chooses a
random assignment achieves the best possible approximation ratio. For instance,
a simple random assignment for {\sc Max-E3-Sat} allows 7/8-approximation and
for every $\eps &gt;0$ there is no polynomial-time ($7/8+\eps$)-approximation
unless P=NP. Another example is the {\sc Permutation CSP} of bounded arity.
Given the expected fraction $\rho$ of the constraints satisfied by a random
assignment (i.e. permutation), there is no $(\rho+\eps)$-approximation
algorithm for every $\eps &gt;0$, assuming the Unique Games Conjecture (UGC).
  In this work, we consider the following parameterization of constraint
satisfaction problems. Given a set of $m$ constraints of constant arity, can we
satisfy at least $\rho m +k$ constraint, where $\rho$ is the expected fraction
of constraints satisfied by a random assignment? {\sc Constraint Satisfaction
Problems above Average} have been posed in different forms in the literature
\cite{Niedermeier2006,MahajanRamanSikdar09}. We present a faster parameterized
algorithm for deciding whether $m/2+k/2$ equations can be simultaneously
satisfied over ${\mathbb F}_2$. As a consequence, we obtain $O(k)$-variable
bikernels for {\sc boolean CSPs} of arity $c$ for every fixed $c$, and for {\sc
permutation CSPs} of arity 3. This implies linear bikernels for many problems
under the &quot;above average&quot; parameterization, such as {\sc Max-$c$-Sat}, {\sc
Set-Splitting}, {\sc Betweenness} and {\sc Max Acyclic Subgraph}. As a result,
all the parameterized problems we consider in this paper admit $2^{O(k)}$-time
algorithms.
  We also obtain non-trivial hybrid algorithms for every Max $c$-CSP: for every
instance $I$, we can either approximate $I$ beyond the random assignment
threshold in polynomial time, or we can find an optimal solution to $I$ in
subexponential time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0223</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0223</id><created>2010-08-02</created><authors><author><keyname>Bagherikaram</keyname><forenames>Ghadamali</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author></authors><title>Secure Joint Source-Channel Coding With Side Information</title><categories>cs.IT math.IT</categories><comments>14 Pages, 4 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the problem of transmitting an i.i.d Gaussian source over an
i.i.d Gaussian wiretap channel with an i.i.d Gaussian side information is
considered. The intended receiver is assumed to have a certain minimum SNR and
the eavesdropper is assumed to have a strictly lower SNR compared to the
intended receiver. The objective is minimizing the distortion of source
reconstruction at the intended receiver. In this work, it is shown that unlike
the Gaussian wiretap channel without side information, Shannon's source-channel
separation coding scheme is not optimum in the sense of achieving the minimum
distortion. Three hybrid digital-analog secure joint source channel coding
schemes are then proposed which achieve the minimum distortion. The first
coding scheme is based on Costa's dirty paper coding scheme and wiretap channel
coding scheme when the analog source is not explicitly quantized. The second
coding scheme is based on the superposition of the secure digital signal and
the hybrid digital-analog signal. It is shown that for the problem of
communicating a Gaussian source over a Gaussian wiretap channel with side
information, there exists an infinite family of optimum secure joint
source-channel coding scheme. In the third coding scheme, the quantized signal
and the analog error signal are explicitly superimposed. It is shown that this
scheme provides an infinite family of optimum secure joint source-channel
channel coding schemes with a variable number of binning. Finally, the proposed
secure hybrid digital-analog schemes are analyzed under the main channel SNR
mismatch. It is proven that the proposed schemes can give a graceful
degradation of distortion with SNR under SNR mismatch, i.e., when the actual
SNR is larger than the designed SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0225</identifier>
 <datestamp>2013-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0225</id><created>2010-08-02</created><updated>2010-08-30</updated><authors><author><keyname>Salehi</keyname><forenames>Saeed</forenames></author></authors><title>Separating Bounded Arithmetics by Herbrand Consistency</title><categories>math.LO cs.LO</categories><comments>14 pages; Keywords: Bounded Arithmetics, Herbrand Consistency,
  $\Pi_1-$Conservative Extensions</comments><msc-class>Primary 03F30, 03F25, Secondary 03F05, 03F40</msc-class><doi>10.1093/logcom/exr005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of $\Pi_1-$separating the hierarchy of bounded arithmetic has
been studied in the paper. It is shown that the notion of Herbrand Consistency,
in its full generality, cannot $\Pi_1-$separate the theory ${\rm
I\Delta_0+\bigwedge_j\Omega_j}$ from ${\rm I\Delta_0}$; though it can
$\Pi_1-$separate ${\rm I\Delta_0+Exp}$ from ${\rm I\Delta_0}$. This extends a
result of L. A. Ko{\l}odziejczyk (2006), by showing the unprovability of the
Herbrand Consistency of ${\rm I\Delta_0}$ in the theory ${\rm
I\Delta_0+\bigwedge_j\Omega_j}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0227</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0227</id><created>2010-08-02</created><authors><author><keyname>Jiang</keyname><forenames>Libin</forenames></author><author><keyname>Leconte</keyname><forenames>Mathieu</forenames></author><author><keyname>Ni</keyname><forenames>Jian</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>Fast Mixing of Parallel Glauber Dynamics and Low-Delay CSMA Scheduling</title><categories>cs.NI cs.PF</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Glauber dynamics is a powerful tool to generate randomized, approximate
solutions to combinatorially difficult problems. It has been used to analyze
and design distributed CSMA (Carrier Sense Multiple Access) scheduling
algorithms for multi-hop wireless networks. In this paper we derive bounds on
the mixing time of a generalization of Glauber dynamics where multiple links
are allowed to update their states in parallel and the fugacity of each link
can be different. The results can be used to prove that the average queue
length (and hence, the delay) under the parallel Glauber dynamics based CSMA
grows polynomially in the number of links for wireless networks with
bounded-degree interference graphs when the arrival rate lies in a fraction of
the capacity region. We also show that in specific network topologies, the
low-delay capacity region can be further improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0235</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0235</id><created>2010-08-02</created><authors><author><keyname>Das</keyname><forenames>Abhik</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Jafar</keyname><forenames>Syed</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>Network Coding for Multiple Unicasts: An Interference Alignment Approach</title><categories>cs.IT math.IT</categories><comments>5 pages, appeared in ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of network coding for multiple unicast
connections in networks represented by directed acyclic graphs. The concept of
interference alignment, traditionally used in interference networks, is
extended to analyze the performance of linear network coding in this setup and
to provide a systematic code design approach. It is shown that, for a broad
class of three-source three-destination unicast networks, a rate corresponding
to half the individual source-destination min-cut is achievable via alignment
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0256</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0256</id><created>2010-08-02</created><authors><author><keyname>Brenner</keyname><forenames>Hai</forenames></author><author><keyname>Nissim</keyname><forenames>Kobbi</forenames></author></authors><title>Impossibility of Differentially Private Universally Optimal Mechanisms</title><categories>cs.CR cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of a universally utility-maximizing privacy mechanism was recently
introduced by Ghosh, Roughgarden, and Sundararajan [STOC 2009]. These are
mechanisms that guarantee optimal utility to a large class of information
consumers, simultaneously, while preserving Differential Privacy [Dwork,
McSherry, Nissim, and Smith, TCC 2006]. Ghosh et al. have demonstrated, quite
surprisingly, a case where such a universally-optimal differentially-private
mechanisms exists, when the information consumers are Bayesian. This result was
recently extended by Gupte and Sundararajan [PODS 2010] to risk-averse
consumers.
  Both positive results deal with mechanisms (approximately) computing a single
count query (i.e., the number of individuals satisfying a specific property in
a given population), and the starting point of our work is a trial at extending
these results to similar settings, such as sum queries with non-binary
individual values, histograms, and two (or more) count queries. We show,
however, that universally-optimal mechanisms do not exist for all these
queries, both for Bayesian and risk-averse consumers.
  For the Bayesian case, we go further, and give a characterization of those
functions that admit universally-optimal mechanisms, showing that a
universally-optimal mechanism exists, essentially, only for a (single) count
query. At the heart of our proof is a representation of a query function $f$ by
its privacy constraint graph $G_f$ whose edges correspond to values resulting
by applying $f$ to neighboring databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0270</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0270</id><created>2010-08-02</created><authors><author><keyname>su</keyname><forenames>Qinliang</forenames></author><author><keyname>Huang</keyname><forenames>Aiping</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Xu</keyname><forenames>Kai</forenames></author><author><keyname>Yang</keyname><forenames>Jin</forenames></author></authors><title>A Non-Cooperative Method for Path Loss Estimation in Femtocell Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A macrocell superposed by indoor deployed femtocells forms a
geography-overlapped and spectrum-shared two tier network, which can
efficiently improve coverage and enhance system capacity. It is important for
reducing inter-tier co-channel interference that any femtocell user (FU) can
select suitable access channel according to the path losses between itself and
the macrocell users (MUs). Path loss should be estimated non-cooperatively
since information exchange is difficult between macrocell and femtocells. In
this paper, a novel method is proposed for FU to estimate the path loss between
itself and any MU independently. According to the adaptive modulation and
coding (AMC) mode information broadcasted by the macrocell base station (BS),
FU first estimates the path loss between BS and a MU by using Maximum a
Posteriori (MAP) method. The probability distribution function (PDF) and
statistics of the transmission power of the MU is then derived. According to
the sequence of received powers from the MU, FU estimates the path loss between
itself and the MU by using minimum mean square error (MMSE) method. Simulation
results show that the proposed method can efficiently estimate the path loss
between any FU and any MU in all kinds of conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0273</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0273</id><created>2010-08-02</created><authors><author><keyname>Dezert</keyname><forenames>Jean</forenames><affiliation>ONERA</affiliation></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames><affiliation>E3I2</affiliation></author></authors><title>Threat assessment of a possible Vehicle-Born Improvised Explosive Device
  using DSmT</title><categories>cs.AI</categories><comments>26 pages</comments><proxy>ccsd</proxy><journal-ref>Fusion 2010, Edinburgh : United Kingdom (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the solution about the threat of a VBIED (Vehicle-Born
Improvised Explosive Device) obtained with the DSmT (Dezert-Smarandache
Theory). This problem has been proposed recently to the authors by Simon
Maskell and John Lavery as a typical illustrative example to try to compare the
different approaches for dealing with uncertainty for decision-making support.
The purpose of this paper is to show in details how a solid justified solution
can be obtained from DSmT approach and its fusion rules thanks to a proper
modeling of the belief functions involved in this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0285</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0285</id><created>2010-08-02</created><authors><author><keyname>Thakur</keyname><forenames>Mohit</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>On optimizing low SNR wireless networks using network coding</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rate optimization for wireless networks with low SNR is investigated.
While the capacity in the limit of disappearing SNR is known to be linear for
fading and non-fading channels, we study the problem of operating in low SNR
wireless network with given node locations that use network coding over flows.
The model we develop for low SNR Gaussian broadcast channel and multiple access
channel respectively operates in a non-trivial feasible rate region. We show
that the problem reduces to the optimization of total network power which can
be casted as standard linear multi-commodity min-cost flow program with no
inherent combinatorially difficult structure when network coding is used with
non integer constraints (which is a reasonable assumption). This is essentially
due to the linearity of the capacity with respect to vanishing SNR which helps
avoid the effect of interference for the degraded broadcast channel and
multiple access environment in consideration, respectively. We propose a fully
decentralized Primal-Dual Subgradient Algorithm for achieving optimal rates on
each subgraph (i.e. hyperarcs) of the network to support the set of traffic
demands (multicast/unicast connections).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0322</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0322</id><created>2010-08-02</created><updated>2010-08-04</updated><authors><author><keyname>Tuller</keyname><forenames>Tamir</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author></authors><title>Co-evolution is Incompatible with the Markov Assumption in Phylogenetics</title><categories>q-bio.PE cs.AI cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov models are extensively used in the analysis of molecular evolution. A
recent line of research suggests that pairs of proteins with functional and
physical interactions co-evolve with each other. Here, by analyzing hundreds of
orthologous sets of three fungi and their co-evolutionary relations, we
demonstrate that co-evolutionary assumption may violate the Markov assumption.
Our results encourage developing alternative probabilistic models for the cases
of extreme co-evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0327</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0327</id><created>2010-08-02</created><updated>2010-10-01</updated><authors><author><keyname>Jitman</keyname><forenames>Somphong</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Udomkavanich</keyname><forenames>Patanee</forenames></author></authors><title>Skew Constacyclic Codes over Finite Chain Rings</title><categories>cs.IT math.IT math.RA</categories><comments>24 Pages, Submitted to Advances in Mathematics of Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skew polynomial rings over finite fields ([7] and [10]) and over Galois rings
([8]) have been used to study codes. In this paper, we extend this concept to
finite chain rings. Properties of skew constacyclic codes generated by monic
right divisors of $x^n-\lambda$, where $\lambda$ is a unit element, are
exhibited. When $\lambda^2=1$, the generators of Euclidean and Hermitian dual
codes of such codes are determined together with necessary and sufficient
conditions for them to be Euclidean and Hermitian self-dual. Of more interest
are codes over the ring $\mathbb{F}_{p^m}+u\mathbb{F}_{p^m}$. The structure of
all skew constacyclic codes is completely determined. This allows us to express
generators of Euclidean and Hermitian dual codes of skew cyclic and skew
negacyclic codes in terms of the generators of the original codes. An
illustration of all skew cyclic codes of length~2 over
$\mathbb{F}_{3}+u\mathbb{F}_{3}$ and their Euclidean and Hermitian dual codes
is also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0336</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0336</id><created>2010-08-02</created><authors><author><keyname>Garg</keyname><forenames>Ankit</forenames></author><author><keyname>Dwivedi</keyname><forenames>Rahul</forenames></author><author><keyname>Asawa</keyname><forenames>Krishna</forenames></author></authors><title>Close Clustering Based Automated Color Image Annotation</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most image-search approaches today are based on the text based tags
associated with the images which are mostly human generated and are subject to
various kinds of errors. The results of a query to the image database thus can
often be misleading and may not satisfy the requirements of the user. In this
work we propose our approach to automate this tagging process of images, where
image results generated can be fine filtered based on a probabilistic tagging
mechanism. We implement a tool which helps to automate the tagging process by
maintaining a training database, wherein the system is trained to identify
certain set of input images, the results generated from which are used to
create a probabilistic tagging mechanism. Given a certain set of segments in an
image it calculates the probability of presence of particular keywords. This
probability table is further used to generate the candidate tags for input
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0390</identifier>
 <datestamp>2013-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0390</id><created>2010-08-02</created><updated>2013-10-08</updated><authors><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory</forenames></author></authors><title>Efficient algorithms for three-dimensional axial and planar random
  assignment problems</title><categories>math.CO cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beautiful formulas are known for the expected cost of random two-dimensional
assignment problems, but in higher dimensions even the scaling is not known. In
three dimensions and above, the problem has natural &quot;Axial&quot; and &quot;Planar&quot;
versions, both of which are NP-hard. For 3-dimensional Axial random assignment
instances of size $n$, the cost scales as $\Omega(1/n)$, and a main result of
the present paper is a linear-time algorithm that, with high probability, finds
a solution of cost $O(n^{-1+o(1)})$. For 3-dimensional Planar assignment, the
lower bound is $\Omega(n)$, and we give a new efficient matching-based
algorithm that with high probability returns a solution with cost $O(n \log
n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0420</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0420</id><created>2010-08-02</created><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Modeling Network Coded TCP Throughput: A Simple Model and its Validation</title><categories>cs.IT cs.NI math.IT</categories><comments>9 pages, 12 figures, 1 table, submitted to IEEE INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the performance of TCP and TCP with network coding (TCP/NC) in
lossy wireless networks. We build upon the simple framework introduced by
Padhye et al. and characterize the throughput behavior of classical TCP as well
as TCP/NC as a function of erasure rate, round-trip time, maximum window size,
and duration of the connection. Our analytical results show that network coding
masks erasures and losses from TCP, thus preventing TCP's performance
degradation in lossy networks, such as wireless networks. It is further seen
that TCP/NC has significant throughput gains over TCP. In addition, we simulate
TCP and TCP/NC to verify our analysis of the average throughput and the window
evolution. Our analysis and simulation results show very close concordance and
support that TCP/NC is robust against erasures. TCP/NC is not only able to
increase its window size faster but also to maintain a large window size
despite losses within the network, whereas TCP experiences window closing
essentially because losses are mistakenly attributed to congestion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0425</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0425</id><created>2010-08-02</created><authors><author><keyname>Shaw</keyname><forenames>Bilal A.</forenames></author></authors><title>Quantum Steganography and Quantum Error-Correction</title><categories>quant-ph cs.IT math.IT</categories><comments>Ph.D. Thesis, University of Southern California, 2010, 137 pages, 19
  tables, and 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current thesis we first talk about the six-qubit quantum
error-correcting code and show its connections to entanglement-assisted
error-correcting coding theory and then to subsystem codes. This code bridges
the gap between the five-qubit (perfect) and Steane codes. We discuss two
methods to encode one qubit into six physical qubits. Each of the two examples
corrects an arbitrary single-qubit error. The first example is a degenerate
six-qubit quantum error-correcting code. We prove that a six-qubit code without
entanglement assistance cannot simultaneously possess a Calderbank-Shor-Steane
(CSS) stabilizer and correct an arbitrary single-qubit error. A corollary of
this result is that the Steane seven-qubit code is the smallest single-error
correcting CSS code. Our second example is the construction of a non-degenerate
six-qubit CSS entanglement-assisted code. This code uses one bit of
entanglement (an ebit) shared between the sender (Alice) and the receiver (Bob)
and corrects an arbitrary single-qubit error. In the second half of this thesis
we explore the yet uncharted and relatively undiscovered area of quantum
steganography. Steganography is the process of hiding secret information by
embedding it in an innocent message. We present protocols for hiding quantum
information in a codeword of a quantum error-correcting code passing through a
channel. Using either a shared classical secret key or shared entanglement
Alice disguises her information as errors in the channel. Bob can retrieve the
hidden information, but an eavesdropper (Eve) with the power to monitor the
channel, but without the secret key, cannot distinguish the message from
channel noise. We analyze how difficult it is for Eve to detect the presence of
secret messages, and estimate rates of steganographic communication and secret
key consumption for certain protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0440</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0440</id><created>2010-08-02</created><authors><author><keyname>Ling</keyname><forenames>Yibei</forenames></author><author><keyname>Chen</keyname><forenames>Wai</forenames></author><author><keyname>Hsing</keyname><forenames>Russell</forenames></author><author><keyname>Altintas</keyname><forenames>Onur</forenames></author></authors><title>Preserving HTTP Sessions in Vehicular Environments</title><categories>cs.NI</categories><journal-ref>IEEE Transactions on Vehicular Technology, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Internet in the in-vehicle environment is an evolving reality that
reflects the gradual maturity of wireless technologies. Its complexity is
reflected in the diversity of wireless technologies and dynamically changing
network environments. The ability to adapt to the dynamics of such environments
and to survive transient failures due to network handoffs are fundamentally
important in failure-prone vehicular environments. In this paper we identify
several new issues arising from network heterogeneity in vehicular environments
and concentrate on designing and implementing a network-aware prototype system
that supports HTTP session continuity in the presence of network volatility,
with the emphasis on the following specifically tailored features: (1)
automatic and transparent HTTP failure recovery, (2) network awareness and
adaptation, (3) application-layer preemptive network handoff. Experimental
results gathered from real application environments based on CDMA {\it 1xRTT}
and IEEE 802 networks are presented and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0441</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0441</id><created>2010-08-02</created><authors><author><keyname>Ling</keyname><forenames>Yibei</forenames></author><author><keyname>Mi</keyname><forenames>Jie</forenames></author></authors><title>An Optimal Trade-off between Content Freshness and Refresh Cost</title><categories>cs.IR</categories><journal-ref>Journal of Applied Probability, 41, 721-734, 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Caching is an effective mechanism for reducing bandwidth usage and
alleviating server load. However, the use of caching entails a compromise
between content freshness and refresh cost. An excessive refresh allows a high
degree of content freshness at a greater cost of system resource. Conversely, a
deficient refresh inhibits content freshness but saves the cost of resource
usages. To address the freshness-cost problem, we formulate the refresh
scheduling problem with a generic cost model and use this cost model to
determine an optimal refresh frequency that gives the best tradeoff between
refresh cost and content freshness. We prove the existence and uniqueness of an
optimal refresh frequency under the assumptions that the arrival of content
update is Poisson and the age-related cost monotonically increases with
decreasing freshness. In addition, we provide an analytic comparison of system
performance under fixed refresh scheduling and random refresh scheduling,
showing that with the same average refresh frequency two refresh schedulings
are mathematically equivalent in terms of the long-run average cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0451</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0451</id><created>2010-08-02</created><authors><author><keyname>Ling</keyname><forenames>Yibei</forenames></author><author><keyname>Chen</keyname><forenames>Shigang</forenames></author><author><keyname>Chiang</keyname><forenames>Cho-Yu Jason</forenames></author></authors><title>On Optimal Deadlock Detection Scheduling</title><categories>cs.DC</categories><journal-ref>IEEE Transactions on Computers, 55(9), 1178-1187 (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deadlock detection scheduling is an important, yet often overlooked problem
that can significantly affect the overall performance of deadlock handling.
Excessive initiation of deadlock detection increases overall message usage,
resulting in degraded system performance in the absence of deadlocks; while
insufficient initiation of deadlock detection increases the deadlock
persistence time, resulting in an increased deadlock resolution cost in the
presence of deadlocks. The investigation of this performance tradeoff, however,
is missing in the literature. This paper studies the impact of deadlock
detection scheduling on the overall performance of deadlock handling. In
particular, we show that there exists an optimal deadlock detection frequency
that yields the minimum long-run mean average cost, which is determined by the
message complexities of the deadlock detection and resolution algorithms being
used, as well as the rate of deadlock formation, denoted as $\lambda$. For the
best known deadlock detection and resolution algorithms, we show that the
asymptotically optimal frequency of deadlock detection scheduling that
minimizes the overall message overhead is ${\cal O}((\lambda n)^{1/3})$, when
the total number $n$ of processes is sufficiently large. Furthermore, we show
that in general fully distributed (uncoordinated) deadlock detection scheduling
cannot be performed as efficiently as centralized (coordinated) deadlock
detection scheduling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0501</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0501</id><created>2010-08-03</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Fouz</keyname><forenames>Mahmoud</forenames></author></authors><title>Quasi-Random Rumor Spreading: Reducing Randomness Can Be Costly</title><categories>cs.DS</categories><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a time-randomness tradeoff for the quasi-random rumor spreading
protocol proposed by Doerr, Friedrich and Sauerwald [SODA 2008] on complete
graphs. In this protocol, the goal is to spread a piece of information
originating from one vertex throughout the network. Each vertex is assumed to
have a (cyclic) list of its neighbors. Once a vertex is informed by one of its
neighbors, it chooses a position in its list uniformly at random and then
informs its neighbors starting from that position and proceeding in order of
the list. Angelopoulos, Doerr, Huber and Panagiotou [Electron.~J.~Combin.~2009]
showed that after $(1+o(1))(\log_2 n + \ln n)$ rounds, the rumor will have been
broadcasted to all nodes with probability $1 - o(1)$.
  We study the broadcast time when the amount of randomness available at each
node is reduced in natural way. In particular, we prove that if each node can
only make its initial random selection from every $\ell$-th node on its list,
then there exists lists such that $(1-\varepsilon) (\log_2 n + \ln n - \log_2
\ell - \ln \ell)+\ell-1$ steps are needed to inform every vertex with
probability at least $1-O\bigl(\exp\bigl(-\frac{n^\varepsilon}{2\ln
n}\bigr)\bigr)$. This shows that a further reduction of the amount of
randomness used in a simple quasi-random protocol comes at a loss of
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0502</identifier>
 <datestamp>2010-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0502</id><created>2010-08-03</created><updated>2010-08-12</updated><authors><author><keyname>Kazuma</keyname><forenames>Akamine</forenames></author><author><keyname>Fukuchi</keyname><forenames>Ken</forenames></author><author><keyname>Kimura</keyname><forenames>Akisato</forenames></author><author><keyname>Takagi</keyname><forenames>Shigeru</forenames></author></authors><title>Fully automatic extraction of salient objects from videos in near
  real-time</title><categories>cs.CV cs.GR cs.MM</categories><comments>submitted to Special Issue on High Performance Computation on
  Hardware Accelerators, the Computer Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic video segmentation plays an important role in a wide range of
computer vision and image processing applications. Recently, various methods
have been proposed for this purpose. The problem is that most of these methods
are far from real-time processing even for low-resolution videos due to the
complex procedures. To this end, we propose a new and quite fast method for
automatic video segmentation with the help of 1) efficient optimization of
Markov random fields with polynomial time of number of pixels by introducing
graph cuts, 2) automatic, computationally efficient but stable derivation of
segmentation priors using visual saliency and sequential update mechanism, and
3) an implementation strategy in the principle of stream processing with
graphics processor units (GPUs). Test results indicates that our method
extracts appropriate regions from videos as precisely as and much faster than
previous semi-automatic methods even though any supervisions have not been
incorporated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0521</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0521</id><created>2010-08-03</created><updated>2010-12-08</updated><authors><author><keyname>Virza</keyname><forenames>Madars</forenames></author></authors><title>Sensitivity versus block sensitivity of Boolean functions</title><categories>cs.CC</categories><comments>5 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining the maximal separation between sensitivity and block sensitivity
of Boolean functions is of interest for computational complexity theory. We
construct a sequence of Boolean functions with bs(f) = 1/2 s(f)^2 + 1/2 s(f).
The best known separation previously was bs(f) = 1/2 s(f)^2 due to Rubinstein.
We also report results of computer search for functions with at most 12
variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0528</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0528</id><created>2010-08-03</created><authors><author><keyname>Ifrim</keyname><forenames>Georgiana</forenames></author><author><keyname>Wiuf</keyname><forenames>Carsten</forenames></author></authors><title>Bounded Coordinate-Descent for Biological Sequence Classification in
  High Dimensional Predictor Space</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework for discriminative sequence classification where the
learner works directly in the high dimensional predictor space of all
subsequences in the training set. This is possible by employing a new
coordinate-descent algorithm coupled with bounding the magnitude of the
gradient for selecting discriminative subsequences fast. We characterize the
loss functions for which our generic learning algorithm can be applied and
present concrete implementations for logistic regression (binomial
log-likelihood loss) and support vector machines (squared hinge loss).
Application of our algorithm to protein remote homology detection and remote
fold recognition results in performance comparable to that of state-of-the-art
methods (e.g., kernel support vector machines). Unlike state-of-the-art
classifiers, the resulting classification models are simply lists of weighted
discriminative subsequences and can thus be interpreted and related to the
biological problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0530</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0530</id><created>2010-08-03</created><authors><author><keyname>Hansen</keyname><forenames>Thomas Dueholm</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author><author><keyname>Zwick</keyname><forenames>Uri</forenames></author></authors><title>Strategy iteration is strongly polynomial for 2-player turn-based
  stochastic games with a constant discount factor</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ye showed recently that the simplex method with Dantzig pivoting rule, as
well as Howard's policy iteration algorithm, solve discounted Markov decision
processes (MDPs), with a constant discount factor, in strongly polynomial time.
More precisely, Ye showed that both algorithms terminate after at most
$O(\frac{mn}{1-\gamma}\log(\frac{n}{1-\gamma}))$ iterations, where $n$ is the
number of states, $m$ is the total number of actions in the MDP, and
$0&lt;\gamma&lt;1$ is the discount factor. We improve Ye's analysis in two respects.
First, we improve the bound given by Ye and show that Howard's policy iteration
algorithm actually terminates after at most
$O(\frac{m}{1-\gamma}\log(\frac{n}{1-\gamma}))$ iterations. Second, and more
importantly, we show that the same bound applies to the number of iterations
performed by the strategy iteration (or strategy improvement) algorithm, a
generalization of Howard's policy iteration algorithm used for solving 2-player
turn-based stochastic games with discounted zero-sum rewards. This provides the
first strongly polynomial algorithm for solving these games, resolving a long
standing open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0539</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0539</id><created>2010-08-03</created><authors><author><keyname>Gomez-Herrero</keyname><forenames>German</forenames></author><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Rutanen</keyname><forenames>Kalle</forenames></author><author><keyname>Soriano</keyname><forenames>Miguel C.</forenames></author><author><keyname>Pipa</keyname><forenames>Gordon</forenames></author><author><keyname>Vicente</keyname><forenames>Raul</forenames></author></authors><title>Assessing coupling dynamics from an ensemble of time series</title><categories>cs.IT math.IT</categories><journal-ref>Entropy 17, 1958-1970 (2015)</journal-ref><doi>10.3390/e17041958</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding interdependency relations between (possibly multivariate) time series
provides valuable knowledge about the processes that generate the signals.
Information theory sets a natural framework for non-parametric measures of
several classes of statistical dependencies. However, a reliable estimation
from information-theoretic functionals is hampered when the dependency to be
assessed is brief or evolves in time. Here, we show that these limitations can
be overcome when we have access to an ensemble of independent repetitions of
the time series. In particular, we gear a data-efficient estimator of
probability densities to make use of the full structure of trial-based
measures. By doing so, we can obtain time-resolved estimates for a family of
entropy combinations (including mutual information, transfer entropy, and their
conditional counterparts) which are more accurate than the simple average of
individual estimates over trials. We show with simulated and real data that the
proposed approach allows to recover the time-resolved dynamics of the coupling
between different subsystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0541</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0541</id><created>2010-08-03</created><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author></authors><title>Determinant Sums for Undirected Hamiltonicity</title><categories>cs.DS</categories><comments>To appear at IEEE FOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Monte Carlo algorithm for Hamiltonicity detection in an
$n$-vertex undirected graph running in $O^*(1.657^{n})$ time. To the best of
our knowledge, this is the first superpolynomial improvement on the worst case
runtime for the problem since the $O^*(2^n)$ bound established for TSP almost
fifty years ago (Bellman 1962, Held and Karp 1962). It answers in part the
first open problem in Woeginger's 2003 survey on exact algorithms for NP-hard
problems.
  For bipartite graphs, we improve the bound to $O^*(1.414^{n})$ time. Both the
bipartite and the general algorithm can be implemented to use space polynomial
in $n$.
  We combine several recently resurrected ideas to get the results. Our main
technical contribution is a new reduction inspired by the algebraic sieving
method for $k$-Path (Koutis ICALP 2008, Williams IPL 2009). We introduce the
Labeled Cycle Cover Sum in which we are set to count weighted arc labeled cycle
covers over a finite field of characteristic two. We reduce Hamiltonicity to
Labeled Cycle Cover Sum and apply the determinant summation technique for Exact
Set Covers (Bj\&quot;orklund STACS 2010) to evaluate it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0548</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0548</id><created>2010-08-03</created><authors><author><keyname>Chen</keyname><forenames>Kanglin</forenames></author><author><keyname>Lorenz</keyname><forenames>Dirk A.</forenames></author></authors><title>Image sequence interpolation using optimal control</title><categories>cs.CV math.AP math.OC</categories><msc-class>49J20, 68U10, 65D18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of the generation of an intermediate image between two given
images in an image sequence is considered. The problem is formulated as an
optimal control problem governed by a transport equation. This approach bears
similarities with the Horn \&amp; Schunck method for optical flow calculation but
in fact the model is quite different. The images are modelled in $BV$ and an
analysis of solutions of transport equations with values in $BV$ is included.
Moreover, the existence of optimal controls is proven and necessary conditions
are derived. Finally, two algorithms are given and numerical results are
compared with existing methods. The new method is competitive with
state-of-the-art methods and even outperforms several existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0557</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0557</id><created>2010-08-03</created><updated>2010-08-04</updated><authors><author><keyname>Camacho-Rodr&#xed;guez</keyname><forenames>Jes&#xfa;s</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Katsifodimos</keyname><forenames>Asterios</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Manolescu</keyname><forenames>Ioana</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Roatis</keyname><forenames>Alexandra</forenames><affiliation>INRIA Saclay - Ile de France, UVT</affiliation></author></authors><title>LiquidXML: Adaptive XML Content Redistribution</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>ACM International Conference on Information and Knowledge
  Management, Toronto : Canada (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to demonstrate LiquidXML, a platform for managing large corpora of
XML documents in large-scale P2P networks. All LiquidXML peers may publish XML
documents to be shared with all the network peers. The challenge then is to
efficiently (re-)distribute the published content in the network, possibly in
overlapping, redundant fragments, to support efficient processing of queries at
each peer. The novelty of LiquidXML relies in its adaptive method of choosing
which data fragments are stored where, to improve performance. The &quot;liquid&quot;
aspect of XML management is twofold: XML data flows from many sources towards
many consumers, and its distribution in the network continuously adapts to
improve query performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0587</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0587</id><created>2010-08-03</created><authors><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Row Sampling for Matrix Algorithms via a Non-Commutative Bernstein Bound</title><categories>cs.DS</categories><comments>Working Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus the use of \emph{row sampling} for approximating matrix algorithms.
We give applications to matrix multipication; sparse matrix reconstruction;
and, \math{\ell_2} regression. For a matrix \math{\matA\in\R^{m\times d}} which
represents \math{m} points in \math{d\ll m} dimensions, all of these tasks can
be achieved in \math{O(md^2)} via the singular value decomposition (SVD). For
appropriate row-sampling probabilities (which typically depend on the norms of
the rows of the \math{m\times d} left singular matrix of \math{\matA} (the
\emph{leverage scores}), we give row-sampling algorithms with linear (up to
polylog factors) dependence on the stable rank of \math{\matA}. This result is
achieved through the application of non-commutative Bernstein bounds.
  We then give, to our knowledge, the first algorithms for computing
approximations to the appropriate row-sampling probabilities without going
through the SVD of \math{\matA}. Thus, these are the first \math{o(md^2)}
algorithms for row-sampling based approximations to the matrix algorithms which
use leverage scores as the sampling probabilities. The techniques we use to
approximate sampling according to the leverage scores uses some powerful recent
results in the theory of random projections for embedding, and may be of some
independent interest. We confess that one may perform all these matrix tasks
more efficiently using these same random projection methods, however the
resulting algorithms are in terms of a small number of linear combinations of
all the rows. In many applications, the actual rows of \math{\matA} have some
physical meaning and so methods based on a small number of the actual rows are
of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0602</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0602</id><created>2010-08-03</created><updated>2010-08-04</updated><authors><author><keyname>Cuff</keyname><forenames>Paul</forenames></author></authors><title>A Framework for Partial Secrecy</title><categories>cs.IT math.IT</categories><comments>Globecom 2010, 5 pages, no figures, uses IEEEtran.cls</comments><msc-class>94A60</msc-class><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider theoretical limits of partial secrecy in a setting where an
eavesdropper attempts to causally reconstruct an information sequence with low
distortion based on an intercepted transmission and the past of the sequence.
The transmitter and receiver have limited secret key at their disposal but not
enough to establish perfect secrecy with a one-time pad. From another
viewpoint, the eavesdropper is acting as an adversary, competing in a zero-sum
repeated game against the sender and receiver of the secrecy system. In this
case, the information sequence represents a sequence of actions, and the
distortion function captures the payoff of the game.
  We give an information theoretic region expressing the tradeoff between
secret key rate and max-min distortion for the eavesdropper. We also simplify
this characterization to a linear program. As an example, we discuss how to
optimally use secret key to hide Bernoulli-p bits from an eavesdropper so that
they incur maximal Hamming distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0616</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0616</id><created>2010-08-03</created><updated>2013-04-25</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author></authors><title>Formaleuros, Formalbitcoins, and Virtual Monies</title><categories>cs.CY</categories><comments>98 pages. Revision of arXiv.org/abs/1008.0616v1. The revision
  involves bringing the paper up to date with the appearance of Bitcoin, a
  significant update of the section on Islamic finance and interest
  prohibition, deletion of fragments of minor importance, an update of
  references, moving the ad hoc theory of definitions to an appendix, and a
  small change of the title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formalist positions towards money are considered from a perspective of formal
methods in computing. The Formaleuro (FEUR) as a dimension for monetary
quantities is proposed as well as the Formalbitcoin (FBTC) which represents an
item ready for circulation in a model of informational money.
  An attempt is made to understand the concept of money from scratch. In order
to provide a definition of money the need is felt to make use of a tailored
theory of definition. To that end a theory of imaginative definitions is
presented and its implications for definitions of money are sketched.
  It is argued that a theory of money may be dependent on the role of its
holder. A survey of some roles is given, with the so-called subordinate
administrative role (SAR) in a central position.
  The concepts of virtual memory and virtual machine are taken as the point of
departure for a definition of the notion of virtual money. It is argued that
from the perspective of a component (division) of a large organization (ORG)
its local financial system (LFS) provides a virtual money vm(LFS, ORG) which
may well fail to meet the most common general and acknowledged moneyness
criteria. Inverse moneyness preference is coined as phrase to assert the
tendency of top-management of ORG to make its virtual money deviate from these
criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0659</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0659</id><created>2010-08-03</created><updated>2010-08-07</updated><authors><author><keyname>Balafoutis</keyname><forenames>Thanasis</forenames></author><author><keyname>Stergiou</keyname><forenames>Kostas</forenames></author></authors><title>Evaluating and Improving Modern Variable and Revision Ordering
  Strategies in CSPs</title><categories>cs.AI</categories><comments>To appear in the Journal Fundamenta Informaticae (FI) IOS Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key factor that can dramatically reduce the search space during constraint
solving is the criterion under which the variable to be instantiated next is
selected. For this purpose numerous heuristics have been proposed. Some of the
best of such heuristics exploit information about failures gathered throughout
search and recorded in the form of constraint weights, while others measure the
importance of variable assignments in reducing the search space. In this work
we experimentally evaluate the most recent and powerful variable ordering
heuristics, and new variants of them, over a wide range of benchmarks. Results
demonstrate that heuristics based on failures are in general more efficient.
Based on this, we then derive new revision ordering heuristics that exploit
recorded failures to efficiently order the propagation list when arc
consistency is maintained during search. Interestingly, in addition to reducing
the number of constraint checks and list operations, these heuristics are also
able to cut down the size of the explored search tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0660</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0660</id><created>2010-08-03</created><authors><author><keyname>Balafoutis</keyname><forenames>Thanasis</forenames></author><author><keyname>Stergiou</keyname><forenames>Kostas</forenames></author></authors><title>Adaptive Branching for Constraint Satisfaction Problems</title><categories>cs.AI</categories><comments>To appear in Proceedings of the 19th European Conference on
  Artificial Intelligence - ECAI 2010</comments><journal-ref>In Proceedings of the 19th European Conference on Artificial
  Intelligence - ECAI 2010</journal-ref><doi>10.3233/978-1-60750-606-5-855</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two standard branching schemes for CSPs are d-way and 2-way branching.
Although it has been shown that in theory the latter can be exponentially more
effective than the former, there is a lack of empirical evidence showing such
differences. To investigate this, we initially make an experimental comparison
of the two branching schemes over a wide range of benchmarks. Experimental
results verify the theoretical gap between d-way and 2-way branching as we move
from a simple variable ordering heuristic like dom to more sophisticated ones
like dom/ddeg. However, perhaps surprisingly, experiments also show that when
state-of-the-art variable ordering heuristics like dom/wdeg are used then d-way
can be clearly more efficient than 2-way branching in many cases. Motivated by
this observation, we develop two generic heuristics that can be applied at
certain points during search to decide whether 2-way branching or a restricted
version of 2-way branching, which is close to d-way branching, will be
followed. The application of these heuristics results in an adaptive branching
scheme. Experiments with instantiations of the two generic heuristics confirm
that search with adaptive branching outperforms search with a fixed branching
scheme on a wide range of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0683</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0683</id><created>2010-08-03</created><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author><author><keyname>Xia</keyname><forenames>Mingji</forenames></author></authors><title>Holographic Algorithms with Matchgates Capture Precisely Tractable
  Planar #CSP</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Valiant introduced matchgate computation and holographic algorithms. A number
of seemingly exponential time problems can be solved by this novel algorithmic
paradigm in polynomial time. We show that, in a very strong sense, matchgate
computations and holographic algorithms based on them provide a universal
methodology to a broad class of counting problems studied in statistical
physics community for decades. They capture precisely those problems which are
#P-hard on general graphs but computable in polynomial time on planar graphs.
  More precisely, we prove complexity dichotomy theorems in the framework of
counting CSP problems. The local constraint functions take Boolean inputs, and
can be arbitrary real-valued symmetric functions. We prove that, every problem
in this class belongs to precisely three categories: (1) those which are
tractable (i.e., polynomial time computable) on general graphs, or (2) those
which are \#P-hard on general graphs but ractable on planar graphs, or (3)
those which are #P-hard even on planar graphs. The classification criteria are
explicit. Moreover, problems in category (2) are tractable on planar graphs
precisely by holographic algorithms with matchgates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0706</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0706</id><created>2010-08-04</created><authors><author><keyname>Lavoie</keyname><forenames>Allen</forenames></author><author><keyname>Krishnamoorthy</keyname><forenames>Mukkai</forenames></author></authors><title>Algorithmic Detection of Computer Generated Text</title><categories>stat.ML cs.CL</categories><report-no>10-07</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer generated academic papers have been used to expose a lack of
thorough human review at several computer science conferences. We assess the
problem of classifying such documents. After identifying and evaluating several
quantifiable features of academic papers, we apply methods from machine
learning to build a binary classifier. In tests with two hundred papers, the
resulting classifier correctly labeled papers either as human written or as
computer generated with no false classifications of computer generated papers
as human and a 2% false classification rate for human papers as computer
generated. We believe generalizations of these features are applicable to
similar classification problems. While most current text-based spam detection
techniques focus on the keyword-based classification of email messages, a new
generation of unsolicited computer-generated advertisements masquerade as
legitimate postings in online groups, message boards and social news sites. Our
results show that taking the formatting and contextual clues offered by these
environments into account may be of central importance when selecting features
with which to identify such unwanted postings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0716</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0716</id><created>2010-08-04</created><updated>2010-08-25</updated><authors><author><keyname>Prettenhofer</keyname><forenames>Peter</forenames></author><author><keyname>Stein</keyname><forenames>Benno</forenames></author></authors><title>Cross-Lingual Adaptation using Structural Correspondence Learning</title><categories>cs.IR</categories><acm-class>H.3.3; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cross-lingual adaptation, a special case of domain adaptation, refers to the
transfer of classification knowledge between two languages. In this article we
describe an extension of Structural Correspondence Learning (SCL), a recently
proposed algorithm for domain adaptation, for cross-lingual adaptation. The
proposed method uses unlabeled documents from both languages, along with a word
translation oracle, to induce cross-lingual feature correspondences. From these
correspondences a cross-lingual representation is created that enables the
transfer of classification knowledge from the source to the target language.
The main advantages of this approach over other approaches are its resource
efficiency and task specificity.
  We conduct experiments in the area of cross-language topic and sentiment
classification involving English as source language and German, French, and
Japanese as target languages. The results show a significant improvement of the
proposed method over a machine translation baseline, reducing the relative
error due to cross-lingual adaptation by an average of 30% (topic
classification) and 59% (sentiment classification). We further report on
empirical analyses that reveal insights into the use of unlabeled data, the
sensitivity with respect to important hyperparameters, and the nature of the
induced cross-lingual correspondences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0728</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0728</id><created>2010-08-04</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author></authors><title>Blind Spectrum Sensing by Information Theoretic Criteria for Cognitive
  Radios</title><categories>cs.IT math.IT</categories><comments>29 pages, 7 figures, 2 tables, submitted to IEEE Trans. on Vehicular
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is a fundamental and critical issue for opportunistic
spectrum access in cognitive radio networks. Among the many spectrum sensing
methods, the information theoretic criteria (ITC) based method is a promising
blind method which can reliably detect the primary users while requiring little
prior information. In this paper, we provide an intensive treatment on the ITC
sensing method. To this end, we first introduce a new over-determined channel
model constructed by applying multiple antennas or over sampling at the
secondary user in order to make the ITC applicable. Then, a simplified ITC
sensing algorithm is introduced, which needs to compute and compare only two
decision values. Compared with the original ITC sensing algorithm, the
simplified algorithm significantly reduces the computational complexity without
losing any performance. Applying the recent advances in random matrix theory,
we then derive closed-form expressions to tightly approximate both the
probability of false alarm and probability of detection. Based on the insight
derived from the analytical study, we further present a generalized ITC sensing
algorithm which can provide flexible tradeoff between the probability of
detection and probability of false alarm. Finally, comprehensive simulations
are carried out to evaluate the performance of the proposed ITC sensing
algorithms. Results show that they considerably outperform other blind spectrum
sensing methods in certain cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0730</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0730</id><created>2010-08-04</created><authors><author><keyname>Cheng</keyname><forenames>Peng</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Zhang</keyname><forenames>Wenjun</forenames></author></authors><title>A New SLNR-based Linear Precoding for Downlink Multi-User Multi-Stream
  MIMO Systems</title><categories>cs.IT math.IT</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal-to-leakage-and-noise ratio (SLNR) is a promising criterion for linear
precoder design in multi-user (MU) multiple-input multiple-output (MIMO)
systems. It decouples the precoder design problem and makes closed-form
solution available. In this letter, we present a new linear precoding scheme by
slightly relaxing the SLNR maximization for MU-MIMO systems with multiple data
streams per user. The precoding matrices are obtained by a general form of
simultaneous diagonalization of two Hermitian matrices. The new scheme reduces
the gap between the per-stream effective channel gains, an inherent limitation
in the original SLNR precoding scheme. Simulation results demonstrate that the
proposed precoding achieves considerable gains in error performance over the
original one for multi-stream transmission while maintaining almost the same
achievable sum-rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0735</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0735</id><created>2010-08-04</created><authors><author><keyname>Liu</keyname><forenames>Jianquan</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Xu</keyname><forenames>Youyun</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Superimposed XOR: Approaching Capacity Bounds of the Two-Way Relay
  Channels</title><categories>cs.IT math.IT</categories><comments>24 pages, 12 figures, extended version of IEEE GLOBECOM 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two-way relay channels, bitwise XOR and symbol-level superposition coding
are two popular network-coding based relaying schemes. However, neither of them
can approach the capacity bound when the channels in the broadcast phase are
asymmetric. In this paper, we present a new physical layer network coding
(PLNC) scheme, called \emph{superimposed XOR}. The new scheme advances the
existing schemes by specifically taking into account the channel asymmetry as
well as information asymmetry in the broadcast phase. We obtain its achievable
rate regions over Gaussian channels when integrated with two known time control
protocols in two-way relaying. We also demonstrate their average maximum
sum-rates and service delay performances over fading channels. Numerical
results show that the proposed superimposed XOR achieves a larger rate region
than both XOR and superposition and performs much better over fading channels.
We further deduce the boundary of its achievable rate region of the broadcast
phase in an explicit and analytical expression. Based on these results, we then
show that the gap to the capacity bound approaches zero at high signal-to-noise
ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0757</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0757</id><created>2010-08-04</created><authors><author><keyname>Chen</keyname><forenames>Zhineng</forenames></author><author><keyname>Cao</keyname><forenames>Juan</forenames></author><author><keyname>Song</keyname><forenames>Yicheng</forenames></author><author><keyname>Zhang</keyname><forenames>Yongdong</forenames></author><author><keyname>Li</keyname><forenames>Jintao</forenames></author></authors><title>Web Video Categorization based on Wikipedia Categories and
  Content-Duplicated Open Resources</title><categories>cs.MM</categories><comments>4 pages, 3 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach for web video categorization by
leveraging Wikipedia categories (WikiCs) and open resources describing the same
content as the video, i.e., content-duplicated open resources (CDORs). Note
that current approaches only col-lect CDORs within one or a few media forms and
ignore CDORs of other forms. We explore all these resources by utilizing WikiCs
and commercial search engines. Given a web video, its discrimin-ative Wikipedia
concepts are first identified and classified. Then a textual query is
constructed and from which CDORs are collected. Based on these CDORs, we
propose to categorize web videos in the space spanned by WikiCs rather than
that spanned by raw tags. Experimental results demonstrate the effectiveness of
both the proposed CDOR collection method and the WikiC voting catego-rization
algorithm. In addition, the categorization model built based on both WikiCs and
CDORs achieves better performance compared with the models built based on only
one of them as well as state-of-the-art approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0758</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0758</id><created>2010-08-04</created><authors><author><keyname>Pellicer-Lostao</keyname><forenames>Carmen</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author></authors><title>A Chaotic Approach to Market Dynamics</title><categories>nlin.CD cs.CE q-fin.TR</categories><comments>17 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Economy is demanding new models, able to understand and predict the evolution
of markets. To this respect, Econophysics is offering models of markets as
complex systems, such as the gas-like model, able to predict money
distributions observed in real economies. However, this model reveals some
technical hitches to explain the power law (Pareto) distribution, observed in
individuals with high incomes. Here, non linear dynamics is introduced in the
gas-like model. The results obtained demonstrate that a chaotic gas-like model
can reproduce the two money distributions observed in real economies
(Exponential and Pareto). Moreover, it is able to control the transition
between them. This may give some insight of the micro-level causes that
originate unfair distributions of money in a global society. Ultimately, the
chaotic model makes obvious the inherent instability of asymmetric scenarios,
where sinks of wealth appear in the market and doom it to complete inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0770</identifier>
 <datestamp>2012-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0770</id><created>2010-08-04</created><updated>2012-11-20</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Introduction to clarithmetic III</title><categories>cs.LO math.LO math.NT</categories><msc-class>03F50, 03F30, 03D75, 68Q10, 68T27, 68T30</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper constructs three new systems of clarithmetic (arithmetic
based on computability logic --- see http://www.cis.upenn.edu/~giorgi/cl.html):
CLA8, CLA9 and CLA10. System CLA8 is shown to be sound and extensionally
complete with respect to PA-provably recursive time computability. This is in
the sense that an arithmetical problem A has a t-time solution for some
PA-provably recursive function t iff A is represented by some theorem of CLA8.
System CLA9 is shown to be sound and intensionally complete with respect to
constructively PA-provable computability. This is in the sense that a sentence
X is a theorem of CLA9 iff, for some particular machine M, PA proves that M
computes (the problem represented by) X. And system CLA10 is shown to be sound
and intensionally complete with respect to not-necessarily-constructively
PA-provable computability. This means that a sentence X is a theorem of CLA10
iff PA proves that X is computable, even if PA does not &quot;know&quot; of any
particular machine M that computes X.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0775</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0775</id><created>2010-08-04</created><updated>2013-12-25</updated><authors><author><keyname>Bagdasaryan</keyname><forenames>Armen</forenames></author></authors><title>Systems Theoretic Techniques for Modeling, Control, and Decision Support
  in Complex Dynamic Systems</title><categories>cs.SY cs.AI cs.MA math.OC</categories><comments>58 pages, 24 figures, 1 table; a book chapter published by Bentham
  Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the problems of modeling, control, and decision support in complex
dynamic systems from a general system theoretic point of view. The main
characteristics of complex systems and of system approach to complex system
study are considered. We provide an overview and analysis of known existing
paradigms and methods of mathematical modeling and simulation of complex
systems, which support the processes of control and decision making. Then we
continue with the general dynamic modeling and simulation technique for complex
hierarchical systems functioning in control loop. Architectural and structural
models of computer information system intended for simulation and decision
support in complex systems are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0781</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0781</id><created>2010-08-04</created><updated>2010-08-19</updated><authors><author><keyname>Merkle</keyname><forenames>Johannes</forenames></author><author><keyname>Schwaiger</keyname><forenames>Michael</forenames></author><author><keyname>Bausinger</keyname><forenames>Oliver</forenames></author><author><keyname>Breitenstein</keyname><forenames>Marco</forenames></author><author><keyname>Elwart</keyname><forenames>Kristina</forenames></author><author><keyname>Nuppeney</keyname><forenames>Markus</forenames></author></authors><title>Towards Improving the NIST Fingerprint Image Quality (NFIQ) Algorithm
  (Extended Version)</title><categories>cs.CR</categories><comments>The present article is an extended version of the paper published at
  the BIOSIG conference (copyright by Gesellschaft f\&quot;ur Informatik)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The NIST Fingerprint Image Quality (NFIQ) algorithm has become a standard
method to assess fingerprint image quality. However, in many applications a
more accurate and reliable assessment is desirable. In this publication, we
report on our efforts to optimize the NFIQ algorithm by a re-training of the
underlying neural network based on a large fingerprint image database. Although
we only achieved a marginal improvement, our work has revealed several areas
for potential optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0807</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0807</id><created>2010-08-04</created><updated>2011-11-29</updated><authors><author><keyname>Merkle</keyname><forenames>Johannes</forenames></author><author><keyname>Ihmor</keyname><forenames>Heinrich</forenames></author><author><keyname>Korte</keyname><forenames>Ulrike</forenames></author><author><keyname>Niesing</keyname><forenames>Matthias</forenames></author><author><keyname>Schwaiger</keyname><forenames>Michael</forenames></author></authors><title>Performance of the Fuzzy Vault for Multiple Fingerprints (Extended
  Version)</title><categories>cs.CR</categories><comments>This article represents the full paper of a short version to appear
  in the Proceedings of BIOSIG 2010 (copyright of Gesellschaft f\&quot;ur
  Informatik)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fuzzy vault is an error tolerant authentication method that ensures the
privacy of the stored reference data. Several publications have proposed the
application of the fuzzy vault to fingerprints, but the results of subsequent
analyses indicate that a single finger does not contain sufficient information
for a secure implementation. In this contribution, we present an implementation
of a fuzzy vault based on minutiae information in several fingerprints aiming
at a security level comparable to current cryptographic applications. We
analyze and empirically evaluate the security, efficiency, and robustness of
the construction and several optimizations. The results allow an assessment of
the capacity of the scheme and an appropriate selection of parameters. Finally,
we report on a practical simulation conducted with ten users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0821</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0821</id><created>2010-08-04</created><updated>2013-09-25</updated><authors><author><keyname>Freer</keyname><forenames>Cameron E.</forenames><affiliation>Massachusetts Institute of Technology</affiliation></author><author><keyname>Kjos-Hanssen</keyname><forenames>Bjoern</forenames><affiliation>University of Hawaii at Manoa</affiliation></author></authors><title>Randomness extraction and asymptotic Hamming distance</title><categories>math.LO cs.CC cs.IT cs.LO math.IT</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  25, 2013) lmcs:889</journal-ref><doi>10.2168/LMCS-9(3:27)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a non-implication result in the Medvedev degrees by studying
sequences that are close to Martin-L\&quot;of random in asymptotic Hamming distance.
Our result is that the class of stochastically bi-immune sets is not Medvedev
reducible to the class of sets having complex packing dimension 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0823</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0823</id><created>2010-08-04</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author><author><keyname>Kozlenkov</keyname><forenames>Alexander</forenames></author><author><keyname>Boley</keyname><forenames>Harold</forenames></author></authors><title>A Homogeneous Reaction Rule Language for Complex Event Processing</title><categories>cs.AI</categories><comments>In Proc. 2nd International Workshop on Event Drive Architecture and
  Event Processing Systems (EDA-PS 2007) at VLDB 2007</comments><acm-class>I.2; H.2.4; I.2.5; I.2.4; K.6.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event-driven automation of reactive functionalities for complex event
processing is an urgent need in today's distributed service-oriented
architectures and Web-based event-driven environments. An important problem to
be addressed is how to correctly and efficiently capture and process the
event-based behavioral, reactive logic embodied in reaction rules, and
combining this with other conditional decision logic embodied, e.g., in
derivation rules. This paper elaborates a homogeneous integration approach that
combines derivation rules, reaction rules and other rule types such as
integrity constraints into the general framework of logic programming, the
industrial-strength version of declarative programming. We describe syntax and
semantics of the language, implement a distributed web-based middleware using
enterprise service technologies and illustrate its adequacy in terms of
expressiveness, efficiency and scalability through examples extracted from
industrial use cases. The developed reaction rule language provides expressive
features such as modular ID-based updates with support for external imports and
self-updates of the intensional and extensional knowledge bases, transactions
including integrity testing and roll-backs of update transition paths. It also
supports distributed complex event processing, event messaging and event
querying via efficient and scalable enterprise middleware technologies and
event/action reasoning based on an event/action algebra implemented by an
interval-based event calculus variant as a logic inference formalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0826</identifier>
 <datestamp>2016-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0826</id><created>2010-08-04</created><authors><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author></authors><title>The Emerging Scholarly Brain</title><categories>physics.soc-ph astro-ph.IM cs.DL cs.IR</categories><comments>to appear in Future Professional Communication in Astronomy-II
  (FPCA-II) editors A. Heck and A. Accomazzi</comments><doi>10.1007/978-1-4419-8369-5_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now a commonplace observation that human society is becoming a coherent
super-organism, and that the information infrastructure forms its emerging
brain. Perhaps, as the underlying technologies are likely to become billions of
times more powerful than those we have today, we could say that we are now
building the lizard brain for the future organism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0831</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0831</id><created>2010-08-04</created><authors><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author><author><keyname>Vondrak</keyname><forenames>Jan</forenames></author></authors><title>Is submodularity testable?</title><categories>cs.DS cs.DM</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of property testing of submodularity on the boolean
hypercube. Submodular functions come up in a variety of applications in
combinatorial optimization. For a vast range of algorithms, the existence of an
oracle to a submodular function is assumed. But how does one check if this
oracle indeed represents a submodular function?
  Consider a function f:{0,1}^n \rightarrow R. The distance to submodularity is
the minimum fraction of values of $f$ that need to be modified to make f
submodular. If this distance is more than epsilon &gt; 0, then we say that f is
epsilon-far from being submodular. The aim is to have an efficient procedure
that, given input f that is epsilon-far from being submodular, certifies that f
is not submodular. We analyze a very natural tester for this problem, and prove
that it runs in subexponential time. This gives the first non-trivial tester
for submodularity. On the other hand, we prove an interesting lower bound (that
is, unfortunately, quite far from the upper bound) suggesting that this tester
cannot be very efficient in terms of epsilon. This involves non-trivial
examples of functions which are far from submodular and yet do not exhibit too
many local violations.
  We also provide some constructions indicating the difficulty in designing a
tester for submodularity. We construct a partial function defined on
exponentially many points that cannot be extended to a submodular function, but
any strict subset of these values can be extended to a submodular function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0838</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0838</id><created>2010-08-04</created><authors><author><keyname>Magomedov</keyname><forenames>Isa</forenames></author><author><keyname>Khazamov</keyname><forenames>Omar</forenames></author></authors><title>Associative control processor with a rigid structure</title><categories>cs.AR cs.AI</categories><comments>16 pages, 7 figures</comments><acm-class>B.2.1</acm-class><journal-ref>DSTU Journal,2009,p. 445-453</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The approach of applying associative processor for decision making problem
was proposed. It focuses on hardware implementations of fuzzy processing
systems, associativity as effective management basis of fuzzy processor. The
structural approach is being developed resulting in a quite simple and compact
parallel associative memory unit (PAMU). The memory cost and speed comparison
of processors with rigid and soft-variable structure is given. Also the example
PAMU flashing is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0851</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0851</id><created>2010-08-04</created><updated>2010-12-07</updated><authors><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author><author><keyname>Gedalyahu</keyname><forenames>Kfir</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Identification of Parametric Underspread Linear Systems and
  Super-Resolution Radar</title><categories>cs.IT math.IT</categories><comments>Revised version of a journal paper submitted to IEEE Trans. Signal
  Processing: 30 pages, 17 figures</comments><doi>10.1109/TSP.2011.2114657</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of time-varying linear systems, which introduce both
time-shifts (delays) and frequency-shifts (Doppler-shifts), is a central task
in many engineering applications. This paper studies the problem of
identification of underspread linear systems (ULSs), whose responses lie within
a unit-area region in the delay Doppler space, by probing them with a known
input signal. It is shown that sufficiently-underspread parametric linear
systems, described by a finite set of delays and Doppler-shifts, are
identifiable from a single observation as long as the time bandwidth product of
the input signal is proportional to the square of the total number of delay
Doppler pairs in the system. In addition, an algorithm is developed that
enables identification of parametric ULSs from an input train of pulses in
polynomial time by exploiting recent results on sub-Nyquist sampling for time
delay estimation and classical results on recovery of frequencies from a sum of
complex exponentials. Finally, application of these results to super-resolution
target detection using radar is discussed. Specifically, it is shown that the
proposed procedure allows to distinguish between multiple targets with very
close proximity in the delay Doppler space, resulting in a resolution that
substantially exceeds that of standard matched-filtering based techniques
without introducing leakage effects inherent in recently proposed compressed
sensing-based radar methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0885</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0885</id><created>2010-08-04</created><updated>2010-12-28</updated><authors><author><keyname>Yu</keyname><forenames>Nam Yul</forenames></author></authors><title>Deterministic Construction of Partial Fourier Compressed Sensing
  Matrices Via Cyclic Difference Sets</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to crucial errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a novel technique where one can recover sparse signals
from the undersampled measurements. This paper studies a $K \times N$ partial
Fourier measurement matrix for compressed sensing which is deterministically
constructed via cyclic difference sets (CDS). Precisely, the matrix is
constructed by $K$ rows of the $N\times N$ inverse discrete Fourier transform
(IDFT) matrix, where each row index is from a $(N, K, \lambda)$ cyclic
difference set. The restricted isometry property (RIP) is statistically studied
for the deterministic matrix to guarantee the recovery of sparse signals. A
computationally efficient reconstruction algorithm is then proposed from the
structure of the matrix. Numerical results show that the reconstruction
algorithm presents competitive recovery performance with allowable
computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0909</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0909</id><created>2010-08-04</created><authors><author><keyname>Li</keyname><forenames>Qing'an</forenames></author><author><keyname>He</keyname><forenames>Yanxiang</forenames></author><author><keyname>Chen</keyname><forenames>Yong</forenames></author><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Wenwen</forenames></author></authors><title>A Heuristic Algorithm for optimizing Page Selection Instructions</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Page switching is a technique that increases the memory in microcontrollers
without extending the address buses. This technique is widely used in the
design of 8-bit MCUs. In this paper, we present an algorithm to reduce the
overhead of page switching. To pursue small code size, we place the emphasis on
the allocation of functions into suitable pages with a heuristic algorithm,
thereby the cost-effective placement of page selection instructions. Our
experimental results showed the optimization achieved a reduction in code size
of 13.2 percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0915</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0915</id><created>2010-08-05</created><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author></authors><title>A Decidable Dichotomy Theorem on Directed Graph Homomorphisms with
  Non-negative Weights</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of graph homomorphism problems has been the subject of intense
study. It is a long standing open problem to give a (decidable) complexity
dichotomy theorem for the partition function of directed graph homomorphisms.
In this paper, we prove a decidable complexity dichotomy theorem for this
problem and our theorem applies to all non-negative weighted form of the
problem: given any fixed matrix A with non-negative algebraic entries, the
partition function Z_A(G) of directed graph homomorphisms from any directed
graph G is either tractable in polynomial time or #P-hard, depending on the
matrix A. The proof of the dichotomy theorem is combinatorial, but involves the
definition of an infinite family of graph homomorphism problems. The proof of
its decidability is algebraic using properties of polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0919</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0919</id><created>2010-08-05</created><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>Compressive Sensing over Graphs</title><categories>cs.IT cs.NI math.IT</categories><msc-class>68R10, 60C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, motivated by network inference and tomography applications, we
study the problem of compressive sensing for sparse signal vectors over graphs.
In particular, we are interested in recovering sparse vectors representing the
properties of the edges from a graph. Unlike existing compressive sensing
results, the collective additive measurements we are allowed to take must
follow connected paths over the underlying graph. For a sufficiently connected
graph with $n$ nodes, it is shown that, using $O(k \log(n))$ path measurements,
we are able to recover any $k$-sparse link vector (with no more than $k$
nonzero elements), even though the measurements have to follow the graph path
constraints. We further show that the computationally efficient $\ell_1$
minimization can provide theoretical guarantees for inferring such $k$-sparse
vectors with $O(k \log(n))$ path measurements from the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0931</identifier>
 <datestamp>2012-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0931</id><created>2010-08-05</created><updated>2012-01-20</updated><authors><author><keyname>Boneh</keyname><forenames>Dan</forenames></author><author><keyname>Dagdelen</keyname><forenames>&#xd6;zg&#xfc;r</forenames></author><author><keyname>Fischlin</keyname><forenames>Marc</forenames></author><author><keyname>Lehmann</keyname><forenames>Anja</forenames></author><author><keyname>Schaffner</keyname><forenames>Christian</forenames></author><author><keyname>Zhandry</keyname><forenames>Mark</forenames></author></authors><title>Random Oracles in a Quantum World</title><categories>quant-ph cs.CR</categories><comments>38 pages, v2: many substantial changes and extensions, merged with a
  related paper by Boneh and Zhandry</comments><journal-ref>full version of Advances in Cryptology - ASIACRYPT 2011, pages
  41-69, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interest in post-quantum cryptography - classical systems that remain
secure in the presence of a quantum adversary - has generated elegant proposals
for new cryptosystems. Some of these systems are set in the random oracle model
and are proven secure relative to adversaries that have classical access to the
random oracle. We argue that to prove post-quantum security one needs to prove
security in the quantum-accessible random oracle model where the adversary can
query the random oracle with quantum states.
  We begin by separating the classical and quantum-accessible random oracle
models by presenting a scheme that is secure when the adversary is given
classical access to the random oracle, but is insecure when the adversary can
make quantum oracle queries. We then set out to develop generic conditions
under which a classical random oracle proof implies security in the
quantum-accessible random oracle model. We introduce the concept of a
history-free reduction which is a category of classical random oracle
reductions that basically determine oracle answers independently of the history
of previous queries, and we prove that such reductions imply security in the
quantum model. We then show that certain post-quantum proposals, including ones
based on lattices, can be proven secure using history-free reductions and are
therefore post-quantum secure. We conclude with a rich set of open problems in
this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0938</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0938</id><created>2010-08-05</created><updated>2011-01-13</updated><authors><author><keyname>Corominas-Murtra</keyname><forenames>Bernat</forenames></author><author><keyname>Fortuny</keyname><forenames>Jordi</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Ricard V.</forenames></author></authors><title>Emergence of Zipf's Law in the Evolution of Communication</title><categories>nlin.AO cond-mat.stat-mech cs.IT math-ph math.IT math.MP physics.soc-ph</categories><comments>7 pages, 2 figures</comments><doi>10.1103/PhysRevE.83.036115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zipf's law seems to be ubiquitous in human languages and appears to be a
universal property of complex communicating systems. Following the early
proposal made by Zipf concerning the presence of a tension between the efforts
of speaker and hearer in a communication system, we introduce evolution by
means of a variational approach to the problem based on Kullback's Minimum
Discrimination of Information Principle. Therefore, using a formalism fully
embedded in the framework of information theory, we demonstrate that Zipf's law
is the only expected outcome of an evolving, communicative system under a
rigorous definition of the communicative tension described by Zipf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0941</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0941</id><created>2010-08-05</created><authors><author><keyname>Radax</keyname><forenames>Wolfgang</forenames></author><author><keyname>Rengs</keyname><forenames>Bernhard</forenames></author></authors><title>Timing matters: Lessons From The CA Literature On Updating</title><categories>cs.MA nlin.AO nlin.CG</categories><comments>Prepared for the World Congress on Social Simulation WCSS 2010 in
  Kassel, Germany, September 6-9, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present article we emphasize the importance of modeling time in the
context of agent-based models. To this end, we present a (selective) survey of
the Cellular Automata-literature on updating and draw parallels to the issue of
agent activation in agent-based models. By means of two simple models,
Schelling's segregation model and Epstein's demographic prisoner's dilemma we
investigate the influence of choosing different regimes of agent activation.
Our experiments indicate that timing is not a critical issue for very simple
models but bears huge influence on model behavior and results as soon as the
degree of complexity increases only so slightly. After a brief review of the
way commonly used ABM simulation environments handle the issue of timing, we
draw some tentative conclusions about the importance of timing and the need for
more research towards that direction, similar to the concerted effort on
updating in cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0961</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0961</id><created>2010-08-05</created><authors><author><keyname>Haroutunian</keyname><forenames>Evgueni</forenames></author></authors><title>On the Shannon Cipher System With a Wiretapper Guessing Subject to
  Distortion and Reliability Requirements</title><categories>cs.IT math.IT</categories><comments>14 pages, 3 figures, Submitted to IEEE Transactions on Information
  Theory</comments><msc-class>94A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss the processes in the Shannon cipher system with
discrete memoryless source and a guessing wiretapper. The wiretapper observes a
cryptogram of $N$-vector of ciphered messages in the public channel and tries
to guess successively the vector of messages within given distortion level
$\Delta$ and small probability of error less than $\exp \{-NE\}$ with positive
reliability index $E$. The security of the system is measured by the expected
number of guesses which wiretapper needs for the approximate reconstruction of
the vector of source messages. The distortion, the reliability criteria and the
possibility of upper limiting the number of guesses extend the approach studied
by Merhav and Arikan. A single-letter characterization is given for the region
of pairs $(R_L,R)$ (of the rate $R_L$ of the maximum number of guesses $L(N)$
and the rate $R$ of the average number of guesses) in dependence on key rate
$R_K$, distortion level $\Delta$ and reliability $E$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.0968</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.0968</id><created>2010-08-05</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Mihaljevic</keyname><forenames>Miodrag J.</forenames></author></authors><title>An Information-Theoretic Analysis of the Security of Communication
  Systems Employing the Encoding-Encryption Paradigm</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a generic approach for providing enhanced security to
communication systems which encode their data for reliability before encrypting
it through a stream cipher for security. We call this counter-intuitive
technique the {\em encoding-encryption} paradigm, and use as motivating example
the standard for mobile telephony GSM. The enhanced security is based on a
dedicated homophonic or wire-tap channel coding that introduces pure
randomness, combined with the randomness of the noise occurring over the
communication channel. Security evaluation regarding recovery of the secret key
employed in the keystream generator is done through an information theoretical
approach. We show that with the aid of a dedicated wire-tap encoder, the amount
of uncertainty that the adversary must face about the secret key given all the
information he could gather during different passive or active attacks he can
mount, is a decreasing function of the sample available for cryptanalysis. This
means that the wire-tap encoder can indeed provide an information theoretical
security level over a period of time, but after a large enough sample is
collected the function tends to zero, entering a regime in which a
computational security analysis is needed for estimation of the resistance
against the secret key recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1043</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1043</id><created>2010-08-05</created><authors><author><keyname>Chen</keyname><forenames>Zengmao</forenames></author><author><keyname>Wang</keyname><forenames>Cheng-Xiang</forenames></author><author><keyname>Hong</keyname><forenames>Xuemin</forenames></author><author><keyname>Thompson</keyname><forenames>John</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author><author><keyname>Xiao</keyname><forenames>Hailin</forenames></author><author><keyname>Zhao</keyname><forenames>Feng</forenames></author></authors><title>Aggregate Interference Modeling in Cognitive Radio Networks with Power
  and Contention Control</title><categories>cs.IT math.IT</categories><comments>24 pages, 8 figures, submitted to IEEE Trans. Communications in July
  2010</comments><journal-ref>Z. Chen, C.-X. Wang, S.A. Vorobyov, and et al, &quot;Aggregate
  interference modeling in cognitive radio networks with power and contention
  control,&quot; IEEE Trans. Communications, vol. 60, no. 2, pp. 456-468, Feb. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an interference model for cognitive radio (CR)
networks employing power control, contention control or hybrid power/contention
control schemes. For the first case, a power control scheme is proposed to
govern the transmission power of a CR node. For the second one, a contention
control scheme at the media access control (MAC) layer, based on carrier sense
multiple access with collision avoidance (CSMA/CA), is proposed to coordinate
the operation of CR nodes with transmission requests. The probability density
functions of the interference received at a primary receiver from a CR network
are first derived numerically for these two cases. For the hybrid case, where
power and contention controls are jointly adopted by a CR node to govern its
transmission, the interference is analyzed and compared with that of the first
two schemes by simulations. Then, the interference distributions under the
first two control schemes are fitted by log-normal distributions with greatly
reduced complexity. Moreover, the effect of a hidden primary receiver on the
interference experienced at the receiver is investigated. It is demonstrated
that both power and contention controls are effective approaches to alleviate
the interference caused by CR networks. Some in-depth analysis of the impact of
key parameters on the interference of CR networks is given via numerical
studies as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1047</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1047</id><created>2010-08-05</created><authors><author><keyname>Khabbazibasmenj</keyname><forenames>Arash</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Hassanien</keyname><forenames>Aboulnasr</forenames></author></authors><title>Robust Adaptive Beamforming Based on Steering Vector Estimation via
  Semidefinite Programming Relaxation</title><categories>cs.IT math.IT math.OC stat.AP</categories><comments>30 pages, 7 figures, Submitted to the IEEE Trans. Signal Processing
  in July 2010</comments><journal-ref>A. Khabbazibasmenj, S.A. Vorobyov, and A. Hassanien, &quot;Robust
  adaptive beamforming based on steering vector estimation with as little as
  possible prior information,&quot; IEEE Trans. Signal Processing, vol. 60, no. 6,
  pp. 2974-2987, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new approach to robust adaptive beamforming in the presence of
signal steering vector errors. Since the signal steering vector is known
imprecisely, its presumed (prior) value is used to find a more accurate
estimate of the actual steering vector, which then is used for obtaining the
optimal beamforming weight vector. The objective for finding such an estimate
of the actual signal steering vector is the maximization of the beamformer
output power, while the constraints are the normalization condition and the
requirement that the estimate of the steering vector does not converge to an
interference steering vector. Our objective and constraints are free of any
design parameters of non-unique choice. The resulting optimization problem is a
non-convex quadratically constrained quadratic program, which is NP hard in
general. However, for our problem we show that an efficient solution can be
found using the semi-definite relaxation technique. Moreover, the strong
duality holds for the proposed problem and can also be used for finding the
optimal solution efficiently and at low complexity. In some special cases, the
solution can be even found in closed-form. Our simulation results demonstrate
the superiority of the proposed method over other previously developed robust
adaptive beamforming methods for several frequently encountered types of signal
steering vector errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1048</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1048</id><created>2010-08-05</created><updated>2010-10-10</updated><authors><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Faster Shortest Path Algorithm for H-Minor Free Graphs with Negative
  Edge Weights</title><categories>cs.DM</categories><comments>Main change: corrected proof of the boundary vertex bound</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $H$ be a fixed graph and let $G$ be an $H$-minor free $n$-vertex graph
with integer edge weights and no negative weight cycles reachable from a given
vertex $s$. We present an algorithm that computes a shortest path tree in $G$
rooted at $s$ in $\tilde{O}(n^{4/3}\log L)$ time, where $L$ is the absolute
value of the smallest edge weight. The previous best bound was
$\tilde{O}(n^{\sqrt{11.5}-2}\log L) = O(n^{1.392}\log L)$. Our running time
matches an earlier bound for planar graphs by Henzinger et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1051</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1051</id><created>2010-08-05</created><authors><author><keyname>Aronov</keyname><forenames>Boris</forenames></author><author><keyname>Dulieu</keyname><forenames>Muriel</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author></authors><title>Witness Gabriel Graphs</title><categories>cs.CG</categories><comments>23 pages. EuroCG 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a generalization of the Gabriel graph, the witness Gabriel graph.
Given a set of vertices P and a set of witnesses W in the plane, there is an
edge ab between two points of P in the witness Gabriel graph GG-(P,W) if and
only if the closed disk with diameter ab does not contain any witness point
(besides possibly a and/or b). We study several properties of the witness
Gabriel graph, both as a proximity graph and as a new tool in graph drawing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1053</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1053</id><created>2010-08-05</created><authors><author><keyname>Aronov</keyname><forenames>Boris</forenames></author><author><keyname>Dulieu</keyname><forenames>Muriel</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author></authors><title>Witness (Delaunay) Graphs</title><categories>cs.CG</categories><comments>27 pages. JCCGG 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proximity graphs are used in several areas in which a neighborliness
relationship for input data sets is a useful tool in their analysis, and have
also received substantial attention from the graph drawing community, as they
are a natural way of implicitly representing graphs. However, as a tool for
graph representation, proximity graphs have some limitations that may be
overcome with suitable generalizations. We introduce a generalization, witness
graphs, that encompasses both the goal of more power and flexibility for graph
drawing issues and a wider spectrum for neighborhood analysis. We study in
detail two concrete examples, both related to Delaunay graphs, and consider as
well some problems on stabbing geometric objects and point set discrimination,
that can be naturally described in terms of witness graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1079</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1079</id><created>2010-08-05</created><authors><author><keyname>Nitinawarat</keyname><forenames>Sirin</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author></authors><title>Perfect Omniscience, Perfect Secrecy and Steiner Tree Packing</title><categories>cs.IT math.CO math.IT</categories><comments>accepted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider perfect secret key generation for a ``pairwise independent
network'' model in which every pair of terminals share a random binary string,
with the strings shared by distinct terminal pairs being mutually independent.
The terminals are then allowed to communicate interactively over a public
noiseless channel of unlimited capacity. All the terminals as well as an
eavesdropper observe this communication. The objective is to generate a perfect
secret key shared by a given set of terminals at the largest rate possible, and
concealed from the eavesdropper.
  First, we show how the notion of perfect omniscience plays a central role in
characterizing perfect secret key capacity. Second, a multigraph representation
of the underlying secrecy model leads us to an efficient algorithm for perfect
secret key generation based on maximal Steiner tree packing. This algorithm
attains capacity when all the terminals seek to share a key, and, in general,
attains at least half the capacity. Third, when a single ``helper'' terminal
assists the remaining ``user'' terminals in generating a perfect secret key, we
give necessary and sufficient conditions for the optimality of the algorithm;
also, a ``weak'' helper is shown to be sufficient for optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1096</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1096</id><created>2010-08-05</created><authors><author><keyname>Lu</keyname><forenames>Qiming</forenames></author><author><keyname>Korniss</keyname><forenames>G.</forenames></author><author><keyname>Szymanski</keyname><forenames>B. K.</forenames></author></authors><title>The Naming Game in Social Networks: Community Formation and Consensus
  Engineering</title><categories>physics.soc-ph cond-mat.stat-mech cs.MA</categories><comments>The original publication is available at
  http://www.springerlink.com/content/70370l311m1u0ng3/</comments><journal-ref>Journal of Economic Interaction and Coordination 4, 221-235 (2009)</journal-ref><doi>10.1007/s11403-009-0057-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the dynamics of the Naming Game [Baronchelli et al., (2006) J. Stat.
Mech.: Theory Exp. P06014] in empirical social networks. This stylized
agent-based model captures essential features of agreement dynamics in a
network of autonomous agents, corresponding to the development of shared
classification schemes in a network of artificial agents or opinion spreading
and social dynamics in social networks. Our study focuses on the impact that
communities in the underlying social graphs have on the outcome of the
agreement process. We find that networks with strong community structure hinder
the system from reaching global agreement; the evolution of the Naming Game in
these networks maintains clusters of coexisting opinions indefinitely. Further,
we investigate agent-based network strategies to facilitate convergence to
global consensus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1131</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1131</id><created>2010-08-06</created><authors><author><keyname>Preston</keyname><forenames>Chris</forenames></author></authors><title>Computing with Equations</title><categories>cs.PL</categories><comments>240 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intention of these notes is to give a mathematical account of how I
believe students could be taught to think about functional programming
languages and to explain how such languages work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1140</identifier>
 <datestamp>2012-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1140</id><created>2010-08-06</created><updated>2012-05-02</updated><authors><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>On Two Strong Converse Theorems for Stationary Discrete Memoryless
  Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1973, Arimoto proved the strong converse theorem for the discrete
memoryless channels stating that when transmission rate $R$ is above channel
capacity $C$, the error probability of decoding goes to one as the block length
$n$ of code word tends to infinity. He proved the theorem by deriving the
exponent function of error probability of correct decoding that is positive if
and only if $R&gt;C$. Subsequently, in 1979, Dueck and K\&quot;orner determined the
optimal exponent of correct decoding. Arimoto's bound has been said to be equal
to the bound of Dueck and K\&quot;orner. However its rigorous proof has not been
presented so far. In this paper we give a rigorous proof of the equivalence of
Arimoto's bound to that of Dueck and K\&quot;orner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1145</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1145</id><created>2010-08-06</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venu</forenames></author><author><keyname>Hanly</keyname><forenames>Stephen</forenames></author></authors><title>Linear Beamforming for the Spatially Correlated MISO broadcast channel</title><categories>cs.IT math.IT</categories><comments>Published in IEEE ISIT 2010, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A spatially correlated broadcast setting with M antennas at the base station
and M users (each with a single antenna) is considered. We assume that the
users have perfect channel information about their links and the base station
has only statistical information about each user's link. The base station
employs a linear beamforming strategy with one spatial eigen-mode allocated to
each user. The goal of this work is to understand the structure of the
beamforming vectors that maximize the ergodic sum-rate achieved by treating
interference as noise. In the M = 2 case, we first fix the beamforming vectors
and compute the ergodic sum-rate in closed-form as a function of the channel
statistics. We then show that the optimal beamforming vectors are the dominant
generalized eigenvectors of the covariance matrices of the two links. It is
difficult to obtain intuition on the structure of the optimal beamforming
vectors for M &gt; 2 due to the complicated nature of the sum-rate expression.
Nevertheless, in the case of asymptotic M, we show that the optimal beamforming
vectors have to satisfy a set of fixed-point equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1150</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1150</id><created>2010-08-06</created><authors><author><keyname>Gottschlich</keyname><forenames>Carsten</forenames></author><author><keyname>Hotz</keyname><forenames>Thomas</forenames></author><author><keyname>Lorenz</keyname><forenames>Robert</forenames></author><author><keyname>Bernhardt</keyname><forenames>Stefanie</forenames></author><author><keyname>Hantschel</keyname><forenames>Michael</forenames></author><author><keyname>Munk</keyname><forenames>Axel</forenames></author></authors><title>Modeling the growth of fingerprints improves matching for adolescents</title><categories>cs.CV stat.AP</categories><journal-ref>IEEE Transactions on Information Forensics and Security, vol. 6,
  no. 3, pp. 1165-1169, Sep. 2011</journal-ref><doi>10.1109/TIFS.2011.2143406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the effect of growth on the fingerprints of adolescents, based on
which we suggest a simple method to adjust for growth when trying to recover a
juvenile's fingerprint in a database years later. Based on longitudinal data
sets in juveniles' criminal records, we show that growth essentially leads to
an isotropic rescaling, so that we can use the strong correlation between
growth in stature and limbs to model the growth of fingerprints proportional to
stature growth as documented in growth charts. The proposed rescaling leads to
a 72% reduction of the distances between corresponding minutiae for the data
set analyzed. These findings were corroborated by several verification tests.
In an identification test on a database containing 3.25 million right index
fingers at the Federal Criminal Police Office of Germany, the identification
error rate of 20.8% was reduced to 2.1% by rescaling. The presented method is
of striking simplicity and can easily be integrated into existing automated
fingerprint identification systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1188</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1188</id><created>2010-08-06</created><authors><author><keyname>Zinovyev</keyname><forenames>Andrei</forenames></author></authors><title>Data visualization in political and social sciences</title><categories>cs.GR cs.CE cs.CY</categories><comments>To appear as a &quot;Data Visualization&quot; entry in SAGE &quot;International
  Encyclopedia of Political Science&quot; by Badie, B., Berg-Schlosser, D., Morlino,
  L. A. (Eds.) in 2011</comments><msc-class>00A66</msc-class><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The basic objective of data visualization is to provide an efficient
graphical display for summarizing and reasoning about quantitative information.
During the last decades, political science has accumulated a large corpus of
various kinds of data such as comprehensive factbooks and atlases,
characterizing all or most of existing states by multiple and objectively
assessed numerical indicators within certain time lapse. As a consequence,
there exists a continuous trend for political science to gradually become a
more quantitative scientific field and to use quantitative information in the
analysis and reasoning. It is believed that any objective analysis in political
science must be multidimensional and combine various sources of quantitative
information; however, human capabilities for perception of large massifs of
numerical information are limited. Hence, methods and approaches for
visualization of quantitative and qualitative data (and, especially
multivariate data) is an extremely important topic. Data visualization
approaches can be classified into several groups, starting from creating
informative charts and diagrams (statistical graphics and infographics) and
ending with advanced statistical methods for visualizing multidimensional
tables containing both quantitative and qualitative information. In this
article we provide a short review of existing methods of data visualization
methods with applications in political and social science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1191</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1191</id><created>2010-08-06</created><updated>2010-08-18</updated><authors><author><keyname>Karch</keyname><forenames>Daniel</forenames></author><author><keyname>Luxen</keyname><forenames>Dennis</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>Improved Fast Similarity Search in Dictionaries</title><categories>cs.IR cs.DS</categories><comments>Full version of a short paper accepted for Spire 2010, 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We engineer an algorithm to solve the approximate dictionary matching
problem. Given a list of words $\mathcal{W}$, maximum distance $d$ fixed at
preprocessing time and a query word $q$, we would like to retrieve all words
from $\mathcal{W}$ that can be transformed into $q$ with $d$ or less edit
operations. We present data structures that support fault tolerant queries by
generating an index. On top of that, we present a generalization of the method
that eases memory consumption and preprocessing time significantly. At the same
time, running times of queries are virtually unaffected. We are able to match
in lists of hundreds of thousands of words and beyond within microseconds for
reasonable distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1213</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1213</id><created>2010-08-03</created><updated>2010-12-12</updated><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>Classical Mathematics for a Constructive World</title><categories>cs.LO</categories><comments>v2: Final copy for publication</comments><journal-ref>Mathematical Structures in Computer Science (2011), 21: 861-882</journal-ref><doi>10.1017/S0960129511000132</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Interactive theorem provers based on dependent type theory have the
flexibility to support both constructive and classical reasoning. Constructive
reasoning is supported natively by dependent type theory and classical
reasoning is typically supported by adding additional non-constructive axioms.
However, there is another perspective that views constructive logic as an
extension of classical logic. This paper will illustrate how classical
reasoning can be supported in a practical manner inside dependent type theory
without additional axioms. We will see several examples of how classical
results can be applied to constructive mathematics. Finally, we will see how to
extend this perspective from logic to mathematics by representing classical
function spaces using a weak value monad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1221</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1221</id><created>2010-08-06</created><authors><author><keyname>Cheng</keyname><forenames>Qingfeng</forenames></author><author><keyname>Ma</keyname><forenames>Chuangui</forenames></author></authors><title>Security Weakness of Flexible Group Key Exchange with On-Demand
  Computation of Subgroup Keys</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In AFRICACRYPT 2010, Abdalla et al. first proposed a slight modification to
the computations steps of the BD protocol, called mBD+P. Then they extended
mBD+P protocol into mBD+S protocol. In this paper, we show that both of mBD+P
and mBD+S protocols are vulnerable to malicious insiders attack. Further, we
propose a simple countermeasure against this attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1224</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1224</id><created>2010-08-06</created><updated>2010-09-20</updated><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Lang</keyname><forenames>Robert J.</forenames></author></authors><title>Circle Packing for Origami Design Is Hard</title><categories>cs.CG cs.CC cs.DM</categories><comments>17 pages, 13 figures. An abstract was presented at the 5th
  International Conference on Origami in Science, Mathematics and Education
  (5OSME). Updated to fix a numerical typo related to Figure 13, and a new
  result</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that deciding whether a given set of circles can be packed into a
rectangle, an equilateral triangle, or a unit square are NP-hard problems,
settling the complexity of these natural packing problems. On the positive
side, we show that any set of circles of total area 1 can be packed into a
square of size 4/\sqrt{pi}=2.2567... These results are motivated by problems
arising in the context of origami design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1253</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1253</id><created>2010-08-06</created><authors><author><keyname>Romero</keyname><forenames>Daniel M.</forenames></author><author><keyname>Galuba</keyname><forenames>Wojciech</forenames></author><author><keyname>Asur</keyname><forenames>Sitaram</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Influence and Passivity in Social Media</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever-increasing amount of information flowing through Social Media forces
the members of these networks to compete for attention and influence by relying
on other people to spread their message. A large study of information
propagation within Twitter reveals that the majority of users act as passive
information consumers and do not forward the content to the network. Therefore,
in order for individuals to become influential they must not only obtain
attention and thus be popular, but also overcome user passivity. We propose an
algorithm that determines the influence and passivity of users based on their
information forwarding activity. An evaluation performed with a 2.5 million
user dataset shows that our influence measure is a good predictor of URL
clicks, outperforming several other measures that do not explicitly take user
passivity into account. We also explicitly demonstrate that high popularity
does not necessarily imply high influence and vice-versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1260</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1260</id><created>2010-08-06</created><authors><author><keyname>Scott</keyname><forenames>Alexander D.</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory B.</forenames></author></authors><title>Structure of random r-SAT below the pure literal threshold</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that there is a sharp density threshold for a random $r$-SAT
formula to be satisfiable, and a similar, smaller, threshold for it to be
satisfied by the pure literal rule. Also, above the satisfiability threshold,
where a random formula is with high probability (whp) unsatisfiable, the
unsatisfiability is whp due to a large &quot;minimal unsatisfiable subformula&quot;
(MUF).
  By contrast, we show that for the (rare) unsatisfiable formulae below the
pure literal threshold, the unsatisfiability is whp due to a unique MUF with
smallest possible &quot;excess&quot;, failing this whp due to a unique MUF with the next
larger excess, and so forth. In the same regime, we give a precise asymptotic
expansion for the probability that a formula is unsatisfiable, and efficient
algorithms for satisfying a formula or proving its unsatisfiability. It remains
open what happens between the pure literal threshold and the satisfiability
threshold. We prove analogous results for the $k$-core and $k$-colorability
thresholds for a random graph, or more generally a random $r$-uniform
hypergraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1270</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1270</id><created>2010-08-06</created><authors><author><keyname>McQuillan</keyname><forenames>Ian</forenames></author><author><keyname>Pighizzini</keyname><forenames>Giovanni</forenames></author></authors><title>Proceedings Twelfth Annual Workshop on Descriptional Complexity of
  Formal Systems</title><categories>cs.FL cs.CC cs.DM cs.IT cs.LO math.IT</categories><comments>These proceedings are dedicated to Chandra M. R. Kintala, who passed
  away on November 05, 2009, at the age of 61. We, the DCFS community, remember
  him as Chair of the IFIP Working Group 1.2 on Descriptional Complexity, as a
  co-initiator of the area of descriptional complexity with limited resources
  and as a co-founder of the workshops DCAGRS and DCFS. He was on the program
  committee for this DCFS2010 and did unfortunately not live to see the results
  of the submission and reviewing process</comments><proxy>EPTCS</proxy><acm-class>F.1.1;F.1.2;F.4.1;F.4.2;F.4.3</acm-class><journal-ref>EPTCS 31, 2010</journal-ref><doi>10.4204/EPTCS.31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 12th annual workshop, Descriptional Complexity of Formal Systems 2010, is
taking place in Saskatoon, Canada, on August 8-10, 2010. It is jointly
organized by the IFIP Working Group 1.2 on Descriptional Complexity and by the
Department of Computer Science at the University of Saskatchewan. This volume
contains the papers of the invited lectures and the accepted contributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1276</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1276</id><created>2010-08-06</created><updated>2011-03-02</updated><authors><author><keyname>Suri</keyname><forenames>Siddharth</forenames></author><author><keyname>Watts</keyname><forenames>Duncan J.</forenames></author></authors><title>Cooperation and Contagion in Web-Based, Networked Public Goods
  Experiments</title><categories>cs.GT physics.soc-ph</categories><doi>10.1371/journal.pone.0016836</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A longstanding idea in the literature on human cooperation is that
cooperation should be reinforced when conditional cooperators are more likely
to interact. In the context of social networks, this idea implies that
cooperation should fare better in highly clustered networks such as cliques
than in networks with low clustering such as random networks. To test this
hypothesis, we conducted a series of web-based experiments, in which 24
individuals played a local public goods game arranged on one of five network
topologies that varied between disconnected cliques and a random regular graph.
In contrast with previous theoretical work, we found that network topology had
no significant effect on average contributions. This result implies either that
individuals are not conditional cooperators, or else that cooperation does not
benefit from positive reinforcement between connected neighbors. We then tested
both of these possibilities in two subsequent series of experiments in which
artificial seed players were introduced, making either full or zero
contributions. First, we found that although players did generally behave like
conditional cooperators, they were as likely to decrease their contributions in
response to low contributing neighbors as they were to increase their
contributions in response to high contributing neighbors. Second, we found that
positive effects of cooperation were contagious only to direct neighbors in the
network. In total we report on 113 human subjects experiments, highlighting the
speed, flexibility, and cost-effectiveness of web-based experiments over those
conducted in physical labs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1284</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1284</id><created>2010-08-06</created><updated>2013-06-25</updated><authors><author><keyname>Cohn</keyname><forenames>Henry</forenames></author><author><keyname>Heninger</keyname><forenames>Nadia</forenames></author></authors><title>Ideal forms of Coppersmith's theorem and Guruswami-Sudan list decoding</title><categories>math.NT cs.CR cs.IT math.IT</categories><comments>29 pages, full version of paper (extended abstract appeared in
  Proceedings of ICS 2011)</comments><proxy>Henry Cohn</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a framework for solving polynomial equations with size constraints
on solutions. We obtain our results by showing how to apply a technique of
Coppersmith for finding small solutions of polynomial equations modulo integers
to analogous problems over polynomial rings, number fields, and function
fields. This gives us a unified view of several problems arising naturally in
cryptography, coding theory, and the study of lattices. We give (1) a
polynomial-time algorithm for finding small solutions of polynomial equations
modulo ideals over algebraic number fields, (2) a faster variant of the
Guruswami-Sudan algorithm for list decoding of Reed-Solomon codes, and (3) an
algorithm for list decoding of algebraic-geometric codes that handles both
single-point and multi-point codes. Coppersmith's algorithm uses lattice basis
reduction to find a short vector in a carefully constructed lattice; powerful
analogies from algebraic number theory allow us to identify the appropriate
analogue of a lattice in each application and provide efficient algorithms to
find a suitably short vector, thus allowing us to give completely parallel
proofs of the above theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1289</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1289</id><created>2010-08-06</created><authors><author><keyname>Perry</keyname><forenames>Ohad</forenames></author><author><keyname>Whitt</keyname><forenames>Ward</forenames></author></authors><title>An ODE for an Overloaded X Model Involving a Stochastic Averaging
  Principle</title><categories>math.PR cs.PF math.DS</categories><comments>55 pages (43 pages plus 12 page appendix), 14 figures</comments><msc-class>Primary: 60K25. Secondary: 60K30, 60F17, 90B15, 90B22, 37C75, 93D05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an ordinary differential equation (ODE) arising as the many-server
heavy-traffic fluid limit of a sequence of overloaded Markovian queueing models
with two customer classes and two service pools. The system, known as the X
model in the call-center literature, operates under the
fixed-queue-ratio-with-thresholds (FQR-T) control, which we proposed in a
recent paper as a way for one service system to help another in face of an
unanticipated overload. Each pool serves only its own class until a threshold
is exceeded; then one-way sharing is activated with all customer-server
assignments then driving the two queues toward a fixed ratio. For large
systems, that fixed ratio is achieved approximately. The ODE describes system
performance during an overload. The control is driven by a queue-difference
stochastic process, which operates in a faster time scale than the queueing
processes themselves, thus achieving a time-dependent steady state
instantaneously in the limit. As a result, for the ODE, the driving process is
replaced by its long-run average behavior at each instant of time; i.e., the
ODE involves a heavy-traffic averaging principle (AP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1309</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1309</id><created>2010-08-07</created><authors><author><keyname>Bineev</keyname><forenames>Osman</forenames></author></authors><title>Towards arrow-theoretic semantics of ontologies: conceptories</title><categories>cs.LO cs.AI math.CT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In context of efforts of composing category-theoretic and logical methods in
the area of knowledge representation we propose the notion of conceptory. We
consider intersection/union and other constructions in conceptories as
expressive alternative to category-theoretic (co)limits and show they have
features similar to (pro-, in-)jections. Then we briefly discuss approaches to
development of formal systems built on the base of conceptories and describe
possible application of such system to the specific ontology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1321</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1321</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>Contributions of PDM Systems in Organizational Technical Data Management</title><categories>cs.OH</categories><comments>In the proceedings of The First IEEE International Conference On
  Computer, Control &amp; Communication (IEEE-IC4 2007), 12-13 November 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Product Data Management (PDM) claims of producing desktop and web based
systems to maintain the organizational data to increase the quality of products
by improving the process of development, business process flows, change
management, product structure management, project tracking and resource
planning. Moreover PDM helps in reducing the cost and effort required in
engineering. This paper discusses PDM desktop and web based system, needed
information and important guidelines for PDM system development, functional
requirements, basic components in detail and some already implemented PDM
Sys-tems. In the end paper investigates and briefly concludes major currently
faced challenges to Product Data Management (PDM) community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1322</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1322</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Ganti</keyname><forenames>Sudhir Kumar</forenames></author><author><keyname>Kyhlb&#xe4;ck</keyname><forenames>Hans</forenames></author></authors><title>Design Artifact's, Design Principles, Problems, Goals and Importance</title><categories>cs.HC</categories><comments>In Proceedings of 4th International Statistical Conference May 9-11,
  Vol. 15, 57-68, ISBN 978-969-8858-04-9, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing human computer interaction interface is an important and a complex
task, but it could be simplified by decomposing task into subcomponents and
maintaining relationships among those subcomponents. Task decomposition is a
structured approach, applicable in both Software Engineering and Human Computer
Interaction (HCI) fields depending on specific processes and design artifacts.
Using design artifacts applications could be made for analysis and design by
making the hand draw sketches to provide high level of logical design based on
user requirements, usage scenarios and essential use cases. To design hand draw
sketches there are some strategies to be followed .i.e., planning, sequential
work flow, and levels of details. In this research paper we are presenting
design artifacts, goals, principles, guidelines and currently faced problems to
human computer interaction design community. Moreover in the end concluded with
assessed observations in a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1324</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1324</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>Statistical Trading Using Target Oriented Trading Agent</title><categories>cs.GT</categories><comments>In Proceedings of 4th International Statistical Conference May 9-11,
  Vol. 16, 355-358, ISBN 978-969-8858-04-9, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we briefly present our contributions toward Trading Agent
Competition (TAC); an international forum for promotion of research into the
trading agent problems. Moreover, we present some strategies proposed and used
in the development of our TAC Agent and resultant brief information after its
participation in a real time trading environment. In the end we conclude with
needed improvements and future recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1328</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1328</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>Semantic Oriented Agent based Approach towards Engineering Data
  Management, Web Information Retrieval and User System Communication Problems</title><categories>cs.AI</categories><comments>In the proceedings of 3rd International Conference for Internet
  Technology and Secured Transactions, Dublin Institute of Technology, ICITST
  08, June 23-28, pp 19-22 Dublin Ireland, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The four intensive problems to the software rose by the software industry
.i.e., User System Communication / Human Machine Interface, Meta Data
extraction, Information processing &amp; management and Data representation are
discussed in this research paper. To contribute in the field we have proposed
and described an intelligent semantic oriented agent based search engine
including the concepts of intelligent graphical user interface, natural
language based information processing, data management and data reconstruction
for the final user end information representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1330</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1330</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>Semantic Oriented Intelligent Electronic Learning</title><categories>cs.OH</categories><comments>In the proceedings of International Conference on Information and
  Communication Technologies (IC-ICT 08), Pakistan, 27 August 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research paper we describe semantic oriented information engineering
and knowledge management based solution towards E-Learning systems. We also try
to justify the importance of proposed solution with respect to the E-Learning
Approaches .i.e., Behavior, Objectivism, Cognitive and Construction. Moreover
we briefly describe E-Learning, information engineering, knowledge management
and some old and newly available technologies supporting development of
E-Learning Systems in this research paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1331</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1331</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>Web to Semantic Web &amp; Role of Ontology</title><categories>cs.OH</categories><comments>In the proceedings of National Conference on Information and
  Communication Technologies, (NCICT-2007), Paper ID 21, Session S32, pp
  100-102, Pakistan, 9th May 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research paper we are briefly presenting current major web problems
and introducing semantic web technologies with the claim of solving existing
web's problems. Furthermore we are describing Ontology as the main building
block of semantic web and focusing on its contributions to semantic web
progress and current limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1333</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1333</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>An Agent based Approach towards Metadata Extraction, Modelling and
  Information Retrieval over the Web</title><categories>cs.AI</categories><comments>In the proceedings of First International Workshop on Cultural
  Heritage on the Semantic Web in conjunction with the 6th International
  Semantic Web Conference and the 2nd Asian Semantic Web Conference 2007, (ISWC
  + ASWC 2007), P 117, 12-15 November 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web development is a challenging research area for its creativity and
complexity. The existing raised key challenge in web technology technologic
development is the presentation of data in machine read and process able format
to take advantage in knowledge based information extraction and maintenance.
Currently it is not possible to search and extract optimized results using full
text queries because there is no such mechanism exists which can fully extract
the semantic from full text queries and then look for particular knowledge
based information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1334</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1334</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>How Does Ontology Contribute in Semantic Web Development?</title><categories>cs.OH</categories><comments>In the proceedings of 6th CIIT Workshop on Research in Computing
  (CWRC 07), P 3, Pakistan, 27 October 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates and briefly describes the major currently existing
problems with World Wide Web .i.e., Information filtration and Security became
the main reasons of semantic web's invention. The semantic web claims of
providing the semantic based solutions towards current web problems. Semantic
web have introduced and relies on a main building block &quot;Ontology&quot; to provide
the information in machine processable semantic models and produce semantically
modelled knowledge representation systems. This paper also describes the role,
construction process and the contributions of ontology in providing some in
time proposed and implemented solutions. Furthermore paper concludes with the
currently existing limitations in Ontology and the areas which need
improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1335</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1335</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>Designing a Dynamic Components and Agent based Approach for Semantic
  Information Retrieval</title><categories>cs.IR</categories><comments>In the proceedings of 6th CIIT Workshop on Research in Computing,
  (CWRC 07) , P8, Pakistan 27 October, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper based on agent and semantic web technologies we propose an
approach .i.e., Semantic Oriented Agent Based Search (SOAS), to cope with
currently existing challenges of Meta data extraction, modeling and information
retrieval over the web. SOAS is designed by keeping four major requirements
.i.e., Automatic user request handling, Dynamic unstructured full text reading,
Analysing and modeling, Semantic query generation and optimized result
classifier. The architecture of SOAS is consisting of an agent called Personal
Agent (PA) and five dynamic components .i.e., Request Processing Unit (RPU),
Agent Locator (AL), Agent Communicator (AC), List Builder (LB) and Result
Generator (RG). Furthermore, in this paper we briefly discuss Semantic Web and
some already existing in time proposed and implemented semantic based
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1336</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1336</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>I-SOAS towards Product Data Management (PDM) based Application's
  Problems</title><categories>cs.OH</categories><comments>Presented at Doctoral Symposium on Research in Computer Science (DSCS
  08), IEEE Conference ID 14656, Pakistan, 02-03 August 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research paper we address the importance of Product Data Management
(PDM) with respect to the industrial contributional point of view and its major
objectives. Moreover we also present some currently available major challenges
to the Product Data Management based communities, and targeting those
challenges we discuss an already proposed conceptual architectural based
helpful approach and briefly describe how this approach can be helpful in
solving the PDM communities faced problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1337</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1337</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>PDM based I-SOAS Data Warehouse Design</title><categories>cs.DB</categories><comments>&quot;, In the proceedings of FIFTH International Conference on
  Statistical Sciences: Mathematics, Paper ID 125, ISBN 978-969-8858-04-9, Vol.
  17, 23-25 January 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research paper briefly describes the industrial contributions of Product
Data Management in any organization's technical and managerial data management.
Then focusing on some current major PDM based problems i.e. Static and
Unintelligent Search, Platform Independent System and Successful PDM System
Implementation, briefly presents a semantic based solution i.e. I-SOAS. Majorly
this research paper is about to present and discuss the contributions of I-SOAS
in any organization's technical and system data management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1338</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1338</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>Intelligent Human Machine Interface Design for Advanced Product Life
  Cycle Management Systems</title><categories>cs.HC</categories><comments>In International Conference on Frontiers of Information Technology,
  ACM - FIT09, Session 5: Computational Science/Artificial Intelligence, 16-18
  December, 2009</comments><journal-ref>ACM Special Interest Group on Artificial Intelligence (SIGART),
  2009</journal-ref><doi>10.1145/1838002.1838058</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Designing and implementing an intelligent and user friendly human machine
interface for any kind of software or hardware oriented application is always
be a challenging task for the designers and developers because it is very
difficult to understand the psychology of the user, nature of the work and best
suit of the environment. This research paper is basically about to propose an
intelligent, flexible and user friendly machine interface for Product Life
Cycle Management products or PDM Systems since studies show that usability and
human computer interaction issues are a major cause of acceptance problems
introducing or using such systems. Going into details of the proposition, we
present prototype implementations about theme based on design requirements,
designed designs and technologies involved for the development of human machine
interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1339</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1339</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Ganti</keyname><forenames>Sudhir</forenames></author></authors><title>Removal of Communication Gap</title><categories>cs.DB</categories><comments>In the 5th Virtual Conference of the EU-funded FP6 I*PROMS Network of
  Excellence on Innovative Production Machines and Systems, IPROMS 2009, 6-17
  July, 2009</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This research is about an online forum designed and developed to improve the
communication process between alumni, new, old and upcoming students. In this
research paper we present targeted problems, designed architecture, used
technologies in development and final end product in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1343</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1343</id><created>2010-08-07</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ge</keyname><forenames>Gennian</forenames></author><author><keyname>Ling</keyname><forenames>Alan C. H.</forenames></author></authors><title>Spectrum of Sizes for Perfect Deletion-Correcting Codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>23 pages</comments><journal-ref>SIAM Journal on Discrete Mathematics, vol. 24, no. 1, pp. 33-55,
  2010</journal-ref><doi>10.1137/090751311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One peculiarity with deletion-correcting codes is that perfect
$t$-deletion-correcting codes of the same length over the same alphabet can
have different numbers of codewords, because the balls of radius $t$ with
respect to the Levenshte\u{\i}n distance may be of different sizes. There is
interest, therefore, in determining all possible sizes of a perfect
$t$-deletion-correcting code, given the length $n$ and the alphabet size~$q$.
In this paper, we determine completely the spectrum of possible sizes for
perfect $q$-ary 1-deletion-correcting codes of length three for all $q$, and
perfect $q$-ary 2-deletion-correcting codes of length four for almost all $q$,
leaving only a small finite number of cases in doubt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1357</identifier>
 <datestamp>2011-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1357</id><created>2010-08-07</created><updated>2011-10-31</updated><authors><author><keyname>Kirkpatrick</keyname><forenames>Scott</forenames></author><author><keyname>Kulakovsky</keyname><forenames>Alex</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Pentland</keyname><forenames>Alex</forenames></author></authors><title>Social Networks and Spin Glasses</title><categories>cs.SI cs.CY</categories><comments>18 pages, 13 figures. To appear in Philosophical Magazine: Structure
  and Properties of Condensed Matter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The networks formed from the links between telephones observed in a month's
call detail records (CDRs) in the UK are analyzed, looking for the
characteristics thought to identify a communications network or a social
network. Some novel methods are employed. We find similarities to both types of
network. We conclude that, just as analogies to spin glasses have proved
fruitful for optimization of large scale practical problems, there will be
opportunities to exploit a statistical mechanics of the formation and dynamics
of social networks in today's electronically connected world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1360</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1360</id><created>2010-08-07</created><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author></authors><title>Coloring translates and homothets of a convex body</title><categories>cs.DM cs.CG math.MG</categories><comments>11 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain improved upper bounds and new lower bounds on the chromatic number
as a linear function of the clique number, for the intersection graphs (and
their complements) of finite families of translates and homothets of a convex
body in $\RR^n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1366</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1366</id><created>2010-08-07</created><updated>2011-02-10</updated><authors><author><keyname>Bowman</keyname><forenames>John C.</forenames></author><author><keyname>Roberts</keyname><forenames>Malcolm</forenames></author></authors><title>Efficient Dealiased Convolutions without Padding</title><categories>cs.CE physics.comp-ph</categories><comments>18 pages, 9 figures</comments><msc-class>65R99, 65T50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms are developed for calculating dealiased linear convolution sums
without the expense of conventional zero-padding or phase-shift techniques. For
one-dimensional in-place convolutions, the memory requirements are identical
with the zero-padding technique, with the important distinction that the
additional work memory need not be contiguous with the input data. This
decoupling of data and work arrays dramatically reduces the memory and
computation time required to evaluate higher-dimensional in-place convolutions.
The technique also allows one to dealias the higher-order convolutions that
arise from Fourier transforming cubic and higher powers. Implicitly dealiased
convolutions can be built on top of state-of-the-art fast Fourier transform
libraries: vectorized multidimensional implementations for the complex and
centered Hermitian (pseudospectral) cases have been implemented in the
open-source software FFTW++.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1371</identifier>
 <datestamp>2011-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1371</id><created>2010-08-07</created><updated>2011-04-25</updated><authors><author><keyname>Novakovic</keyname><forenames>Vedran</forenames></author><author><keyname>Singer</keyname><forenames>Sanja</forenames></author></authors><title>A GPU-based hyperbolic SVD algorithm</title><categories>cs.NA math.NA</categories><comments>Accepted for publication in BIT Numerical Mathematics</comments><msc-class>65F15 (Primary) 65Y05, 65Y10 (Secondary)</msc-class><acm-class>G.1.3; G.4</acm-class><journal-ref>BIT 51 (2011) 1009-1030</journal-ref><doi>10.1007/s10543-011-0333-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A one-sided Jacobi hyperbolic singular value decomposition (HSVD) algorithm,
using a massively parallel graphics processing unit (GPU), is developed. The
algorithm also serves as the final stage of solving a symmetric indefinite
eigenvalue problem. Numerical testing demonstrates the gains in speed and
accuracy over sequential and MPI-parallelized variants of similar Jacobi-type
HSVD algorithms. Finally, possibilities of hybrid CPU--GPU parallelism are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1372</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1372</id><created>2010-08-07</created><authors><author><keyname>Zehavi</keyname><forenames>Ephi</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Levanda</keyname><forenames>Ronny</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Weighted Max-Min Resource Allocation for Frequency Selective Channels</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss the computation of weighted max-min rate allocation
using joint TDM/FDM strategies under a PSD mask constraint. We show that the
weighted max-min solution allocates the rates according to a predetermined rate
ratio defined by the weights, a fact that is very valuable for
telecommunication service providers. Furthermore, we show that the problem can
be efficiently solved using linear programming. We also discuss the resource
allocation problem in the mixed services scenario where certain users have a
required rate, while the others have flexible rate requirements. The solution
is relevant to many communication systems that are limited by a power spectral
density mask constraint such as WiMax, Wi-Fi and UWB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1380</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1380</id><created>2010-08-08</created><authors><author><keyname>Banerjee</keyname><forenames>Soumya</forenames></author><author><keyname>Moses</keyname><forenames>Melanie</forenames></author></authors><title>Scale Invariance of Immune System Response Rates and Times: Perspectives
  on Immune System Architecture and Implications for Artificial Immune Systems</title><categories>q-bio.QM cs.DC math.OC</categories><comments>23 pages, 4 figures, Swarm Intelligence journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most biological rates and times decrease systematically with organism body
size. We use an ordinary differential equation (ODE) model of West Nile Virus
in birds to show that pathogen replication rates decline with host body size,
but natural immune system (NIS) response rates do not change systematically
with body size. This is surprising since the NIS has to search for small
quantities of pathogens through larger physical spaces in larger organisms, and
also respond by producing larger absolute quantities of antibody in larger
organisms. We call this scale-invariant detection and response. We hypothesize
that the NIS has evolved an architecture to efficiently neutralize pathogens.
We investigate a range of architectures using an Agent Based Model (ABM). We
find that a sub-modular NIS architecture, in which lymph node number and size
both increase sublinearly with body size, efficiently balances the tradeoff
between local pathogen detection and global response using antibodies. This
leads to nearly scale-invariant detection and response, consistent with
experimental data. Similar to the NIS, physical space and resources are also
important constraints on Artificial Immune Systems (AIS), especially
distributed systems applications used to connect low-powered sensors using
short-range wireless communication. We show that AIS problems, like distributed
robot control, will also require a sub-modular architecture to efficiently
balance the tradeoff between local search for a solution and global response or
proliferation of the solution between different components. This research has
wide applicability in other distributed systems AIS applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1387</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1387</id><created>2010-08-08</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Sole</keyname><forenames>Patrick</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Codes over Matrix Rings for Space-Time Coded Modulations</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that, for transmission over quasi-static MIMO fading channels
with n transmit antennas, diversity can be obtained by using an inner fully
diverse space-time block code while coding gain, derived from the determinant
criterion, comes from an appropriate outer code. When the inner code has a
cyclic algebra structure over a number field, as for perfect space-time codes,
an outer code can be designed via coset coding. More precisely, we take the
quotient of the algebra by a two-sided ideal which leads to a finite alphabet
for the outer code, with a cyclic algebra structure over a finite field or a
finite ring. We show that the determinant criterion induces various metrics on
the outer code, such as the Hamming and Bachoc distances. When n=2,
partitioning the 2x2 Golden code by using an ideal above the prime 2 leads to
consider codes over either M2(F_2) or M2(F_2[i]), both being non-commutative
alphabets. Matrix rings of higher dimension, suitable for 3x3 and 4x4 perfect
codes, give rise to more complex examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1393</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1393</id><created>2010-08-08</created><authors><author><keyname>Szabo</keyname><forenames>Zoltan</forenames></author></authors><title>Towards Nonstationary, Nonparametric Independent Process Analysis with
  Unknown Source Component Dimensions</title><categories>stat.ME cs.IT math.DS math.IT math.ST stat.TH</categories><comments>9 pages, 3 figures</comments><msc-class>37M10, 93E12, 62G08</msc-class><acm-class>G.3; I.2.6</acm-class><journal-ref>European Signal Processing Conference (EUSIPCO), 1718-1722, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to extend independent subspace analysis (ISA) to
the case of (i) nonparametric, not strictly stationary source dynamics and (ii)
unknown source component dimensions. We make use of functional autoregressive
(fAR) processes to model the temporal evolution of the hidden sources. An
extension of the ISA separation principle--which states that the ISA problem
can be solved by traditional independent component analysis (ICA) and
clustering of the ICA elements--is derived for the solution of the defined fAR
independent process analysis task (fAR-IPA): applying fAR identification we
reduce the problem to ISA. A local averaging approach, the Nadaraya-Watson
kernel regression technique is adapted to obtain strongly consistent fAR
estimation. We extend the Amari-index to different dimensional components and
illustrate the efficiency of the fAR-IPA approach by numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1394</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1394</id><created>2010-08-08</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Majeed</keyname><forenames>Saman</forenames></author><author><keyname>Dandekar</keyname><forenames>Thomas</forenames></author></authors><title>Towards Design and Implementation of a Language Technology based
  Information Processor for PDM Systems</title><categories>cs.IR cs.CL cs.SE</categories><journal-ref>IST Transactions of Information Technology- Theory and
  Applications, Vol. 1, No. 1 (2),ISSN 1913-8822, pp. 1-7, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Product Data Management (PDM) aims to provide 'Systems' contributing in
industries by electronically maintaining organizational data, improving data
repository system, facilitating with easy access to CAD and providing
additional information engineering and management modules to access, store,
integrate, secure, recover and manage information. Targeting one of the
unresolved issues i.e., provision of natural language based processor for the
implementation of an intelligent record search mechanism, an approach is
proposed and discussed in detail in this manuscript. Designing an intelligent
application capable of reading and analyzing user's structured and unstructured
natural language based text requests and then extracting desired concrete and
optimized results from knowledge base is still a challenging task for the
designers because it is still very difficult to completely extract Meta data
out of raw data. Residing within the limited scope of current research and
development; we present an approach capable of reading user's natural language
based input text, understanding the semantic and extracting results from
repositories. To evaluate the effectiveness of implemented prototyped version
of proposed approach, it is compared with some existing PDM Systems, in the end
the discussion is concluded with an abstract presentation of resultant
comparison amongst implemented prototype and some existing PDM Systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1398</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1398</id><created>2010-08-08</created><authors><author><keyname>Walder</keyname><forenames>Christian</forenames></author><author><keyname>Henao</keyname><forenames>Ricardo</forenames></author><author><keyname>M&#xf8;rup</keyname><forenames>Morten</forenames></author><author><keyname>Hansen</keyname><forenames>Lars Kai</forenames></author></authors><title>Semi-Supervised Kernel PCA</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present three generalisations of Kernel Principal Components Analysis
(KPCA) which incorporate knowledge of the class labels of a subset of the data
points. The first, MV-KPCA, penalises within class variances similar to Fisher
discriminant analysis. The second, LSKPCA is a hybrid of least squares
regression and kernel PCA. The final LR-KPCA is an iteratively reweighted
version of the previous which achieves a sigmoid loss function on the labeled
points. We provide a theoretical risk bound as well as illustrative experiments
on real and toy data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1417</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1417</id><created>2010-08-08</created><authors><author><keyname>Saha</keyname><forenames>Indranil</forenames></author><author><keyname>Misra</keyname><forenames>Janardan</forenames></author><author><keyname>Roy</keyname><forenames>Suman</forenames></author></authors><title>A Simplification of a Real-Time Verification Problem</title><categories>cs.LO cs.SE</categories><comments>32 Pages, 6 Figures. A preliminary version of this draft appeared in
  the proceedings of ATVA 2007</comments><msc-class>68Q60</msc-class><acm-class>D.2.4; C.2.2</acm-class><journal-ref>Proc. of Automated Technology for Verification and Analysis
  (ATVA'07), LNCS 4762, pp. 284-299, 2007</journal-ref><doi>10.1007/978-3-540-75596-8_21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the problem of real-time verification with dense dynamics using
timeout and calendar based models and simplify this to a finite state
verification problem. To overcome the complexity of verification of real-time
systems with dense dynamics, Dutertre and Sorea, proposed timeout and calender
based transition systems to model the behavior of real-time systems and
verified safety properties using k-induction in association with bounded model
checking. In this work, we introduce a specification formalism for these models
in terms of Timeout Transition Diagrams and capture their behavior in terms of
semantics of Timed Transition Systems. Further, we discuss a technique, which
reduces the problem of verification of qualitative temporal properties on
infinite state space of (a large fragment of) these timeout and calender based
transition systems into that on clockless finite state models through a
two-step process comprising of digitization and canonical finitary reduction.
This technique enables us to verify safety invariants for real-time systems
using finite state model-checking avoiding the complexity of infinite state
(bounded) model checking and scale up models without applying techniques from
induction based proof methodology. Moreover, we can verify liveness properties
for real-time systems, which is not possible by using induction with infinite
state model checkers. We present examples of Fischer's Protocol, Train-Gate
Controller, and TTA start-up algorithm to illustrate how such an approach can
be efficiently used for verifying safety, liveness, and timeliness properties
specified in LTL using finite state model checkers like SAL-smc and Spin. We
also demonstrate how advanced modeling concepts like inter-process scheduling,
priorities, interrupts, urgent and committed location can be specified as
extensions of the proposed specification formalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1427</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1427</id><created>2010-08-08</created><authors><author><keyname>Platonov</keyname><forenames>Anatoliy</forenames><affiliation>Warsaw University of Technology, Faculty of Electronics and Information Techniques, IES, Poland</affiliation></author></authors><title>Optimal Feedback Systems with Analogue Adaptive Transmitters</title><categories>cs.IT math.IT</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents original approach to concurrent optimization of the
transmitting and receiving parts of adaptive communication systems (CS) with
feedback channels. The results of research show a possibility and the way of
designing the systems transmitting the signals with a bit rate equal to the
capacity of the forward channel under given bit-error rate (BER). The results
of work can be used for design of different classes of high-efficient low
energy/size/cost CS, as well as allow further development and extension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1438</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1438</id><created>2010-08-08</created><authors><author><keyname>King</keyname><forenames>Ji</forenames></author></authors><title>Harmonic Analysis and Qualitative Uncertainty Principle</title><categories>cs.IT math-ph math.CA math.IT math.MP</categories><comments>108 pages,no figures</comments><msc-class>42Cxx(Primary), 94A12, 46N50 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the mathematical nature of qualitative uncertainty
principle (QUP), which plays an important role in mathematics, physics and
engineering fields. Consider a 3-tuple (K, H1, H2) that K: H1 -&gt; H2 is an
integral operator. Suppose a signal f in H1, {\Omega}1 and {\Omega}2 are
domains on which f, Kf define respectively. Does this signal f vanish if
|{\Sigma}(f)|&lt;|{\Omega}1|and|{\Sigma}(Kf)|&lt;|{\Omega}2|? The excesses and
deficiencies of integral kernel K({\omega}, t) are found to be greatly related
to this general formulation of QUP. The complete point theory of integral
kernel is so established to deal with the QUP. This theory addresses the
density and linear independence of integral kernels. Some algebraic and
geometric properties of complete points are presented. It is shown that the
satisfaction of QUP depends on the existence of some complete points. By
recognizing complete points of their corresponding integral kernels, the QUP
with Fourier transform, Wigner-Ville distribution, Gabor transform and wavelet
are studied. It is shown the QUP only holds for good behaved integral
operators. An investigation of full violation of QUP shows that L2 space is
large for high resolution harmonic analysis. And the invertible linear integral
transforms whose kernels are complete in L2 probably lead to the satisfaction
of QUP. It indicates the performance limitation of linear integral transforms
in harmonic analysis. Two possible ways bypassing uncertainty principle,
nonlinear method and sparse representation, are thus suggested. The notion of
operator family is developed and is applied to understand remarkable
performances of recent sparse representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1455</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1455</id><created>2010-08-09</created><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Diversity-Multiplexing Tradeoff of the Dynamic Decode-and-Forward
  Protocol on a MIMO Half-Duplex Relay Channel</title><categories>cs.IT math.IT</categories><comments>37 pages and 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diversity-multiplexing tradeoff of the dynamic decode-and-forward
protocol is characterized for the half-duplex three-terminal (m,k,n)-relay
channel where the source, relay and the destination terminals have m, k and n
antennas, respectively. It is obtained as a solution to a simple, two-variable,
convex optimization problem and this problem is solved in closed form for
special classes of relay channels, namely, the (1,k,1) relay channel, the
(n,1,n) relay channel and the (2,k,2) relay channel. Moreover, the tradeoff
curves for a certain class of relay channels, such as the (m,k,n&gt;k) channels,
are identical to those for the decode-and-forward protocol for the full duplex
channel while for other classes of channels they are marginally lower at high
multiplexing gains. Our results also show that for some classes of relay
channels and at low multiplexing gains the diversity orders of the dynamic
decode-and-forward protocol protocol are greater than those of the static
compress-and-forward protocol which in turn is known to be tradeoff optimal
over all {\em static} half duplex protocols. In general, the dynamic
decode-and-forward protocol has a performance that is comparable to that of the
static compress-and-forward protocol which, unlike the dynamic
decode-and-forward protocol, requires global channel state information at the
relay node. Its performance is also close to that of the decode-and-forward
protocol over the full-duplex relay channel thereby indicating that the
half-duplex constraint can be compensated for by the dynamic operation of the
relay wherein the relay switches from the receive to the transmit mode based on
the source-relay channel quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1459</identifier>
 <datestamp>2015-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1459</id><created>2010-08-09</created><updated>2015-01-21</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>Actor Model of Computation: Scalable Robust Information Systems</title><categories>cs.PL cs.DC</categories><comments>Relationship to Internet of Things. arXiv admin note: text overlap
  with arXiv:0812.4852, arXiv:0901.4934</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Actor model is a mathematical theory that treats &quot;Actors&quot; as the
universal primitives of concurrent digital computation. The model has been used
both as a framework for a theoretical understanding of concurrency, and as the
theoretical basis for several practical implementations of concurrent systems.
Unlike previous models of computation, the Actor model was inspired by physical
laws. It was also influenced by the programming languages Lisp, Simula 67 and
Smalltalk-72, as well as ideas for Petri Nets, capability-based systems and
packet switching. The advent of massive concurrency through client-cloud
computing and many-core computer architectures has galvanized interest in the
Actor model.
  Actor technology will see significant application for integrating all kinds
of digital information for individuals, groups, and organizations so their
information usefully links together. Information integration needs to make use
of the following information system principles:
  * Persistence. Information is collected and indexed.
  * Concurrency: Work proceeds interactively and concurrently, overlapping in
time.
  * Quasi-commutativity: Information can be used regardless of whether it
initiates new work or become relevant to ongoing work.
  * Sponsorship: Sponsors provide resources for computation, i.e., processing,
storage, and communications.
  * Pluralism: Information is heterogeneous, overlapping and often
inconsistent.
  * Provenance: The provenance of information is carefully tracked and recorded
  The Actor Model is intended to provide a foundation for inconsistency robust
information integration
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1480</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1480</id><created>2010-08-09</created><authors><author><keyname>Bartal</keyname><forenames>Yair</forenames></author><author><keyname>Gottlieb</keyname><forenames>Lee-Ad</forenames></author><author><keyname>Kopelowitz</keyname><forenames>Tsvi</forenames></author><author><keyname>Lewenstein</keyname><forenames>Moshe</forenames></author><author><keyname>Roditty</keyname><forenames>Liam</forenames></author></authors><title>Fast, precise and dynamic distance queries</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approximate distance oracle for a point set S with n points and
doubling dimension {\lambda}. For every {\epsilon}&gt;0, the oracle supports
(1+{\epsilon})-approximate distance queries in (universal) constant time,
occupies space [{\epsilon}^{-O({\lambda})} + 2^{O({\lambda} log {\lambda})}]n,
and can be constructed in [2^{O({\lambda})} log3 n + {\epsilon}^{-O({\lambda})}
+ 2^{O({\lambda} log {\lambda})}]n expected time. This improves upon the best
previously known constructions, presented by Har-Peled and Mendel. Furthermore,
the oracle can be made fully dynamic with expected O(1) query time and only
2^{O({\lambda})} log n + {\epsilon}^{-O({\lambda})} + 2^{O({\lambda} log
{\lambda})} update time. This is the first fully dynamic
(1+{\epsilon})-distance oracle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1484</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1484</id><created>2010-08-09</created><authors><author><keyname>Zhu</keyname><forenames>Ping</forenames></author><author><keyname>Wen</keyname><forenames>Qiaoyan</forenames></author></authors><title>A note on communicating between information systems based on including
  degrees</title><categories>cs.AI</categories><comments>4 pages</comments><journal-ref>International Journal of General Systems, 40(8): 837-840, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to study the communication between information systems, Gong and
Xiao [Z. Gong and Z. Xiao, Communicating between information systems based on
including degrees, International Journal of General Systems 39 (2010) 189--206]
proposed the concept of general relation mappings based on including degrees.
Some properties and the extension for fuzzy information systems of the general
relation mappings have been investigated there. In this paper, we point out by
counterexamples that several assertions (Lemma 3.1, Lemma 3.2, Theorem 4.1, and
Theorem 4.3) in the aforementioned work are not true in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1498</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1498</id><created>2010-08-09</created><authors><author><keyname>Gottlieb</keyname><forenames>Lee-Ad</forenames></author><author><keyname>Neylon</keyname><forenames>Tyler</forenames></author></authors><title>Matrix sparsification and the sparse null space problem</title><categories>cs.CC math.NA</categories><comments>A preliminary version appeared in Approx '10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the matrix problems sparse null space and matrix sparsification,
and show that they are equivalent. We then proceed to seek algorithms for these
problems: We prove the hardness of approximation of these problems, and also
give a powerful tool to extend algorithms and heuristics for sparse
approximation theory to these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1501</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1501</id><created>2010-08-06</created><authors><author><keyname>McCabe-Dansted</keyname><forenames>John C.</forenames></author></authors><title>Dodgson's Rule Approximations and Absurdity</title><categories>math.CO cs.GT</categories><comments>Expanded draft of paper presented at COMSOC 2008</comments><msc-class>91B12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the Dodgson rule, cloning the electorate can change the winner, which
Young (1977) considers an &quot;absurdity&quot;. Removing this absurdity results in a new
rule (Fishburn, 1977) for which we can compute the winner in polynomial time
(Rothe et al., 2003), unlike the traditional Dodgson rule. We call this rule DC
and introduce two new related rules (DR and D&amp;). Dodgson did not explicitly
propose the &quot;Dodgson rule&quot; (Tideman, 1987); we argue that DC and DR are better
realizations of the principle behind the Dodgson rule than the traditional
Dodgson rule. These rules, especially D&amp;, are also effective approximations to
the traditional Dodgson's rule. We show that, unlike the rules we have
considered previously, the DC, DR and D&amp; scores differ from the Dodgson score
by no more than a fixed amount given a fixed number of alternatives, and thus
these new rules converge to Dodgson under any reasonable assumption on voter
behaviour, including the Impartial Anonymous Culture assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1507</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1507</id><created>2010-08-09</created><updated>2011-04-13</updated><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author><author><keyname>Kuich</keyname><forenames>Werner</forenames></author></authors><title>Free iterative and iteration K-semialgebras</title><categories>cs.FL</categories><msc-class>68Q45, 68Q70, 08B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider algebras of rational power series over an alphabet $\Sigma$ with
coefficients in a commutative semiring $K$ and characterize them as the free
algebras in various classes of algebraic structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1516</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1516</id><created>2010-08-09</created><authors><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer</forenames></author><author><keyname>Ding</keyname><forenames>Jian</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author></authors><title>The Hitchhiker's Guide to Affiliation Networks: A Game-Theoretic
  Approach</title><categories>cs.GT cs.SI</categories><comments>15 pages; 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new class of game-theoretic models for network formation in
which strategies are not directly related to edge choices, but instead
correspond more generally to the exertion of social effort. The observed social
network is thus a byproduct of an expressive strategic interaction, which can
more naturally explain the emergence of complex social structures. Within this
framework, we present a natural network formation game in which agent utilities
are locally defined and that, despite its simplicity, produces a rich class of
equilibria that exhibit structural properties commonly observed in social
networks - such as triadic closure - that have proved elusive in most existing
models.
  Specifically, we consider a game in which players organize networking events
at a cost that grows with the number of attendees. An event's cost is assumed
by the organizer but the benefit accrues equally to all attendees: a link is
formed between any two players who see each other at more than a certain number
r of events per time period. The graph of connections so obtained is the social
network of the model.
  We analyze the Nash equilibria of this game when each player derives a
benefit a&gt;0 from all her neighbors in the network and when the costs are
linear, i.e., when the cost of an event with L invitees is b+cL, with b&gt;0 and
c&gt;0. For a/cr &gt; 1 and b sufficiently small, all Nash equilibria have the
complete graph as their social network; for a/cr &lt; 1 the Nash equilibria
correspond to a rich class of social networks, all of which have substantial
clustering in the sense that the clustering coefficient is bounded below by the
inverse of the average degree. Additionally, for any degree sequence with
finite mean, and not too many vertices of degree one or two, we can construct a
Nash equilibrium producing a social network with the given degree sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1555</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1555</id><created>2010-08-09</created><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author><author><keyname>Zivny</keyname><forenames>Stanislav</forenames></author></authors><title>The complexity of conservative finite-valued CSPs</title><categories>cs.CC</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of valued constraint satisfaction problems (VCSP). A
problem from VCSP is characterised by a \emph{constraint language}, a fixed set
of cost functions over a finite domain. An instance of the problem is specified
by a sum of cost functions from the language and the goal is to minimise the
sum. We consider the case of so-called \emph{conservative} languages; that is,
languages containing all unary cost functions, thus allowing arbitrary
restrictions on the domains of the variables. This problem has been studied by
Bulatov [LICS'03] for $\{0,\infty\}$-valued languages (i.e. CSP), by
Cohen~\etal\ (AIJ'06) for Boolean domains, by Deineko et al. (JACM'08) for
$\{0,1\}$-valued cost functions (i.e. Max-CSP), and by Takhanov (STACS'10) for
$\{0,\infty\}$-valued languages containing all finite-valued unary cost
functions (i.e. Min-Cost-Hom).
  We give an elementary proof of a complete complexity classification of
conservative finite-valued languages: we show that every conservative
finite-valued language is either tractable or NP-hard. This is the \emph{first}
dichotomy result for finite-valued VCSPs over non-Boolean domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1556</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1556</id><created>2010-08-09</created><updated>2010-11-20</updated><authors><author><keyname>&#xc1;sgeirsson</keyname><forenames>Eyj&#xf3;lfur Ingi</forenames></author><author><keyname>Mitra</keyname><forenames>Pradipta</forenames></author></authors><title>On a game theoretic approach to capacity maximization in wireless
  networks</title><categories>cs.DS cs.GT cs.NI</categories><comments>16 pages, 5 figures (to appear in INFOCOM 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the capacity problem (or, the single slot scheduling problem) in
wireless networks. Our goal is to maximize the number of successful connections
in arbitrary wireless networks where a transmission is successful only if the
signal-to-interference-plus-noise ratio at the receiver is greater than some
threshold. We study a game theoretic approach towards capacity maximization
introduced by Andrews and Dinitz (INFOCOM 2009) and Dinitz (INFOCOM 2010). We
prove vastly improved bounds for the game theoretic algorithm. In doing so, we
achieve the first distributed constant factor approximation algorithm for
capacity maximization for the uniform power assignment. When compared to the
optimum where links may use an arbitrary power assignment, we prove a $O(\log
\Delta)$ approximation, where $\Delta$ is the ratio between the largest and the
smallest link in the network. This is an exponential improvement of the
approximation factor compared to existing results for distributed algorithms.
All our results work for links located in any metric space. In addition, we
provide simulation studies clarifying the picture on distributed algorithms for
capacity maximization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1566</identifier>
 <datestamp>2012-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1566</id><created>2010-08-09</created><updated>2012-12-04</updated><authors><author><keyname>Zhu</keyname><forenames>Zhemin</forenames></author><author><keyname>Hiemstra</keyname><forenames>Djoerd</forenames></author><author><keyname>Apers</keyname><forenames>Peter</forenames></author><author><keyname>Wombacher</keyname><forenames>Andreas</forenames></author></authors><title>Separate Training for Conditional Random Fields Using Co-occurrence Rate
  Factorization</title><categories>cs.LG cs.AI</categories><comments>10pages</comments><report-no>TR-CTIT-12-29</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard training method of Conditional Random Fields (CRFs) is very slow
for large-scale applications. As an alternative, piecewise training divides the
full graph into pieces, trains them independently, and combines the learned
weights at test time. In this paper, we present \emph{separate} training for
undirected models based on the novel Co-occurrence Rate Factorization (CR-F).
Separate training is a local training method. In contrast to MEMMs, separate
training is unaffected by the label bias problem. Experiments show that
separate training (i) is unaffected by the label bias problem; (ii) reduces the
training time from weeks to seconds; and (iii) obtains competitive results to
the standard and piecewise training on linear-chain CRFs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1571</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1571</id><created>2010-08-09</created><authors><author><keyname>S</keyname><forenames>Ananth Narayan</forenames></author><author><keyname>Sharangi</keyname><forenames>Somsubhra</forenames></author><author><keyname>Fedorova</keyname><forenames>Alexandra</forenames></author></authors><title>Scaling Turbo Boost to a 1000 cores</title><categories>cs.PF cs.OS</categories><comments>7 pages, short paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Intel Core i7 processor code named Nehalem provides a feature named Turbo
Boost which opportunistically varies the frequencies of the processor's cores.
The frequency of a core is determined by core temperature, the number of active
cores, the estimated power consumption, the estimated current consumption, and
operating system frequency scaling requests. For a chip multi-processor(CMP)
that has a small number of physical cores and a small set of performance
states, deciding the Turbo Boost frequency to use on a given core might not be
difficult. However, we do not know the complexity of this decision making
process in the context of a large number of cores, scaling to the 100s, as
predicted by researchers in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1596</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1596</id><created>2010-08-09</created><authors><author><keyname>Kochanski</keyname><forenames>Greg</forenames></author><author><keyname>Rosner</keyname><forenames>Burton S.</forenames></author></authors><title>Bootstrap Markov chain Monte Carlo and optimal solutions for the Law of
  Categorical Judgment (Corrected)</title><categories>cs.NA</categories><msc-class>65C05</msc-class><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A novel procedure is described for accelerating the convergence of Markov
chain Monte Carlo computations. The algorithm uses an adaptive bootstrap
technique to generate candidate steps in the Markov Chain. It is efficient for
symmetric, convex probability distributions, similar to multivariate Gaussians,
and it can be used for Bayesian estimation or for obtaining maximum likelihood
solutions with confidence limits. As a test case, the Law of Categorical
Judgment (Corrected) was fitted with the algorithm to data sets from simulated
rating scale experiments. The correct parameters were recovered from
practical-sized data sets simulated for Full Signal Detection Theory and its
special cases of standard Signal Detection Theory and Complementary Signal
Detection Theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1608</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1608</id><created>2010-08-09</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Tan</keyname><forenames>Yin</forenames></author><author><keyname>Zhang</keyname><forenames>Xiande</forenames></author></authors><title>Universal Cycles for Minimum Coverings of Pairs by Triples, with
  Application to 2-Radius Sequences</title><categories>math.CO cs.DM</categories><comments>18 pages, to appear in Mathematics of Computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new ordering, extending the notion of universal cycles of Chung {\em et
al.} (1992), is proposed for the blocks of $k$-uniform set systems. Existence
of minimum coverings of pairs by triples that possess such an ordering is
established for all orders. Application to the construction of short 2-radius
sequences is given, with some new 2-radius sequences found through computer
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1610</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1610</id><created>2010-08-09</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author><author><keyname>Yeo</keyname><forenames>Sze Ling</forenames></author></authors><title>New Constant-Weight Codes from Propagation Rules</title><categories>cs.IT cs.DM math.IT</categories><comments>4 pages</comments><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 4, pp.
  1596-1599, 2010</journal-ref><doi>10.1109/TIT.2010.2040964</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes some simple propagation rules which give rise to new
binary constant-weight codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1611</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1611</id><created>2010-08-09</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Ling</keyname><forenames>Alan C. H.</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author></authors><title>Linear Size Optimal q-ary Constant-Weight Codes and Constant-Composition
  Codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>12 pages</comments><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 1, pp.
  140-151, 2010</journal-ref><doi>10.1109/TIT.2009.2034814</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optimal constant-composition or constant-weight code of weight $w$ has
linear size if and only if its distance $d$ is at least $2w-1$. When $d\geq
2w$, the determination of the exact size of such a constant-composition or
constant-weight code is trivial, but the case of $d=2w-1$ has been solved
previously only for binary and ternary constant-composition and constant-weight
codes, and for some sporadic instances.
  This paper provides a construction for quasicyclic optimal
constant-composition and constant-weight codes of weight $w$ and distance
$2w-1$ based on a new generalization of difference triangle sets. As a result,
the sizes of optimal constant-composition codes and optimal constant-weight
codes of weight $w$ and distance $2w-1$ are determined for all such codes of
sufficiently large lengths. This solves an open problem of Etzion.
  The sizes of optimal constant-composition codes of weight $w$ and distance
$2w-1$ are also determined for all $w\leq 6$, except in two cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1615</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1615</id><created>2010-08-09</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ling</keyname><forenames>Alan C. H.</forenames></author><author><keyname>Yin</keyname><forenames>Jianxing</forenames></author></authors><title>Optimal Partitioned Cyclic Difference Packings for Frequency Hopping and
  Code Synchronization</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal partitioned cyclic difference packings (PCDPs) are shown to give rise
to optimal frequency-hopping sequences and optimal comma-free codes. New
constructions for PCDPs, based on almost difference sets and cyclic difference
matrices, are given. These produce new infinite families of optimal PCDPs (and
hence optimal frequency-hopping sequences and optimal comma-free codes). The
existence problem for optimal PCDPs in ${\mathbb Z}_{3m}$, with $m$ base blocks
of size three, is also solved for all $m\not\equiv 8,16\pmod{24}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1616</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1616</id><created>2010-08-09</created><authors><author><keyname>Chakraborty</keyname><forenames>Tanmoy</forenames></author><author><keyname>Even-Dar</keyname><forenames>Eyal</forenames></author><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Mansour</keyname><forenames>Yishay</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Approximation Schemes for Sequential Posted Pricing in Multi-Unit
  Auctions</title><categories>cs.GT cs.DS</categories><comments>16 pages</comments><acm-class>F.2.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design algorithms for computing approximately revenue-maximizing {\em
sequential posted-pricing mechanisms (SPM)} in $K$-unit auctions, in a standard
Bayesian model. A seller has $K$ copies of an item to sell, and there are $n$
buyers, each interested in only one copy, who have some value for the item. The
seller must post a price for each buyer, the buyers arrive in a sequence
enforced by the seller, and a buyer buys the item if its value exceeds the
price posted to it. The seller does not know the values of the buyers, but have
Bayesian information about them. An SPM specifies the ordering of buyers and
the posted prices, and may be {\em adaptive} or {\em non-adaptive} in its
behavior.
  The goal is to design SPM in polynomial time to maximize expected revenue. We
compare against the expected revenue of optimal SPM, and provide a polynomial
time approximation scheme (PTAS) for both non-adaptive and adaptive SPMs. This
is achieved by two algorithms: an efficient algorithm that gives a
$(1-\frac{1}{\sqrt{2\pi K}})$-approximation (and hence a PTAS for sufficiently
large $K$), and another that is a PTAS for constant $K$. The first algorithm
yields a non-adaptive SPM that yields its approximation guarantees against an
optimal adaptive SPM -- this implies that the {\em adaptivity gap} in SPMs
vanishes as $K$ becomes larger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1617</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1617</id><created>2010-08-09</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Feng</keyname><forenames>Tao</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Wang</keyname><forenames>Huaxiong</forenames></author><author><keyname>Zhang</keyname><forenames>Liang Feng</forenames></author></authors><title>Query-Efficient Locally Decodable Codes of Subexponential Length</title><categories>cs.CC cs.DM cs.IT math.IT math.NT math.RA</categories><comments>to appear in Computational Complexity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop the algebraic theory behind the constructions of Yekhanin (2008)
and Efremenko (2009), in an attempt to understand the ``algebraic niceness''
phenomenon in $\mathbb{Z}_m$. We show that every integer $m = pq = 2^t -1$,
where $p$, $q$ and $t$ are prime, possesses the same good algebraic property as
$m=511$ that allows savings in query complexity. We identify 50 numbers of this
form by computer search, which together with 511, are then applied to gain
improvements on query complexity via Itoh and Suzuki's composition method. More
precisely, we construct a $3^{\lceil r/2\rceil}$-query LDC for every positive
integer $r&lt;104$ and a $\left\lfloor (3/4)^{51}\cdot 2^{r}\right\rfloor$-query
LDC for every integer $r\geq 104$, both of length $N_{r}$, improving the $2^r$
queries used by Efremenko (2009) and $3\cdot 2^{r-2}$ queries used by Itoh and
Suzuki (2010).
  We also obtain new efficient private information retrieval (PIR) schemes from
the new query-efficient LDCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1620</identifier>
 <datestamp>2012-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1620</id><created>2010-08-09</created><authors><author><keyname>Chattopadhyay</keyname><forenames>Ishanu</forenames></author></authors><title>GODDeS: Globally \epsilon-Optimal Routing Via Distributed
  Decision-theoretic Self-organization</title><categories>cs.NI math.OC</categories><comments>14 pages 6 figures : This is a preliminary pre-print. Full version
  has been submitted for review elsewhere</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces GODDeS: a fully distributed self-organizing
decision-theoretic routing algorithm designed to effectively exploit high
quality paths in lossy ad-hoc wireless environments, typically with a large
number of nodes. The routing problem is modeled as an optimal control problem
for a decentralized Markov Decision Process, with links characterized by
locally known packet drop probabilities that either remain constant on average
or change slowly. The equivalence of this optimization problem to that of
performance maximization of an explicitly constructed probabilistic automata
allows us to effectively apply the theory of quantitative measures of
probabilistic regular languages, and design a distributed highly efficient
solution approach that attempts to minimize source-to-sink drop probabilities
across the network. Theoretical results provide rigorous guarantees on global
performance, showing that the algorithm achieves near-global optimality, in
polynomial time. It is also argued that GODDeS is significantly
congestion-aware, and exploits multi-path routes optimally. Theoretical
development is supported by high-fidelity network simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1628</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1628</id><created>2010-08-10</created><updated>2011-03-07</updated><authors><author><keyname>Wong</keyname><forenames>Pui King</forenames></author><author><keyname>Yin</keyname><forenames>Dongjie</forenames></author><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author></authors><title>Performance Analysis of Markov Modulated 1-Persistent CSMA/CA Protocols
  with Exponential Backoff Scheduling</title><categories>cs.NI cs.PF</categories><comments>24 pages including 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a Markovian model of 1-persistent CSMA/CA protocols with
K-Exponential Backoff scheduling algorithms. The input buffer of each access
node is modeled as a Geo/G/1 queue, and the service time distribution of each
individual head-of-line packet is derived from the Markov chain of the
underlying scheduling algorithm. From the queuing model, we derive the
characteristic equation of network throughput and obtain the stable throughput
and bounded delay regions with respect to the retransmission factor. Our
results show that the stable throughput region of the exponential backoff
scheme exists even for an infinite population. Moreover, we find that the
bounded delay region of exponential backoff is only a sub-set of its stable
throughput region due to the large variance of the service time of input
packets caused by the capture effect. All analytical results presented in this
paper are verified by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1629</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1629</id><created>2010-08-10</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author><author><keyname>K</keyname><forenames>Chandra Sekaran</forenames></author></authors><title>Survey of Search and Replication Schemes in Unstructured P2P Networks</title><categories>cs.NI</categories><comments>39 Pages 5 Figures</comments><journal-ref>Network Protocols and Algorithms, ISSN 1943-3581, Vol. 2, No. 1,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  P2P computing lifts taxing issues in various areas of computer science. The
largely used decentralized unstructured P2P systems are ad hoc in nature and
present a number of research challenges. In this paper, we provide a
comprehensive theoretical survey of various state-of-the-art search and
replication schemes in unstructured P2P networks for file-sharing applications.
The classifications of search and replication techniques and their advantages
and disadvantages are briefly explained. Finally, the various issues on
searching and replication for unstructured P2P networks are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1643</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1643</id><created>2010-08-10</created><updated>2010-12-12</updated><authors><author><keyname>Philip</keyname><forenames>Ninan Sajeeth</forenames></author></authors><title>A Learning Algorithm based on High School Teaching Wisdom</title><categories>cs.AI cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A learning algorithm based on primary school teaching and learning is
presented. The methodology is to continuously evaluate a student and to give
them training on the examples for which they repeatedly fail, until, they can
correctly answer all types of questions. This incremental learning procedure
produces better learning curves by demanding the student to optimally dedicate
their learning time on the failed examples. When used in machine learning, the
algorithm is found to train a machine on a data with maximum variance in the
feature space so that the generalization ability of the network improves. The
algorithm has interesting applications in data mining, model evaluations and
rare objects discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1648</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1648</id><created>2010-08-10</created><authors><author><keyname>Cui</keyname><forenames>Bo</forenames><affiliation>The University of Western Ontario</affiliation></author><author><keyname>Gao</keyname><forenames>Yuan</forenames><affiliation>The University of Western Ontario</affiliation></author><author><keyname>Kari</keyname><forenames>Lila</forenames><affiliation>The University of Western Ontario</affiliation></author><author><keyname>Yu</keyname><forenames>Sheng</forenames><affiliation>The University of Western Ontario</affiliation></author></authors><title>State Complexity of Catenation Combined with Star and Reversal</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 58-67</journal-ref><doi>10.4204/EPTCS.31.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a continuation of our research work on state complexity of
combined operations. Motivated by applications, we study the state complexities
of two particular combined operations: catenation combined with star and
catenation combined with reversal. We show that the state complexities of both
of these combined operations are considerably less than the compositions of the
state complexities of their individual participating operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1649</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1649</id><created>2010-08-10</created><authors><author><keyname>Dassow</keyname><forenames>J&#xfc;rgen</forenames><affiliation>Otto-von-Guericke-Universit&#xe4;t Magdeburg, Fakult&#xe4;t f&#xfc;r Informatik</affiliation></author><author><keyname>Manea</keyname><forenames>Florin</forenames><affiliation>Otto-von-Guericke-Universit&#xe4;t Magdeburg, Fakult&#xe4;t f&#xfc;r Informatik</affiliation></author></authors><title>Accepting Hybrid Networks of Evolutionary Processors with Special
  Topologies and Small Communication</title><categories>cs.CC cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 68-77</journal-ref><doi>10.4204/EPTCS.31.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from the fact that complete Accepting Hybrid Networks of
Evolutionary Processors allow much communication between the nodes and are far
from network structures used in practice, we propose in this paper three
network topologies that restrict the communication: star networks, ring
networks, and grid networks. We show that ring-AHNEPs can simulate 2-tag
systems, thus we deduce the existence of a universal ring-AHNEP. For star
networks or grid networks, we show a more general result; that is, each
recursively enumerable language can be accepted efficiently by a star- or
grid-AHNEP. We also present bounds for the size of these star and grid
networks. As a consequence we get that each recursively enumerable can be
accepted by networks with at most 13 communication channels and by networks
where each node communicates with at most three other nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1650</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1650</id><created>2010-08-10</created><authors><author><keyname>&#xc9;sik</keyname><forenames>Zoltan</forenames><affiliation>University of Szeged</affiliation></author></authors><title>Representing Small Ordinals by Finite Automata</title><categories>cs.FL cs.DM</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><acm-class>F.4.3</acm-class><journal-ref>EPTCS 31, 2010, pp. 78-87</journal-ref><doi>10.4204/EPTCS.31.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that an ordinal is the order type of the lexicographic ordering
of a regular language if and only if it is less than omega^omega. We design a
polynomial time algorithm that constructs, for each well-ordered regular
language L with respect to the lexicographic ordering, given by a deterministic
finite automaton, the Cantor Normal Form of its order type. It follows that
there is a polynomial time algorithm to decide whether two deterministic finite
automata accepting well-ordered regular languages accept isomorphic languages.
We also give estimates on the size of the smallest automaton representing an
ordinal less than omega^omega, together with an algorithm that translates each
such ordinal to an automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1651</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1651</id><created>2010-08-10</created><authors><author><keyname>Freund</keyname><forenames>Rudolf</forenames></author><author><keyname>Kogler</keyname><forenames>Marian</forenames></author><author><keyname>Rogozhin</keyname><forenames>Yurii</forenames></author><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author></authors><title>Graph-Controlled Insertion-Deletion Systems</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 88-98</journal-ref><doi>10.4204/EPTCS.31.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we consider the operations of insertion and deletion working
in a graph-controlled manner. We show that like in the case of context-free
productions, the computational power is strictly increased when using a control
graph: computational completeness can be obtained by systems with insertion or
deletion rules involving at most two symbols in a contextual or in a
context-free manner and with the control graph having only four nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1652</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1652</id><created>2010-08-10</created><authors><author><keyname>Gao</keyname><forenames>Yuan</forenames><affiliation>The University of Western Ontario</affiliation></author><author><keyname>Salomaa</keyname><forenames>Kai</forenames><affiliation>Queen's University</affiliation></author><author><keyname>Yu</keyname><forenames>Sheng</forenames><affiliation>The University of Western Ontario</affiliation></author></authors><title>Transition Complexity of Incomplete DFAs</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 99-109</journal-ref><doi>10.4204/EPTCS.31.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the transition complexity of regular languages
based on the incomplete deterministic finite automata. A number of results on
Boolean operations have been obtained. It is shown that the transition
complexity results for union and complementation are very different from the
state complexity results for the same operations. However, for intersection,
the transition complexity result is similar to that of state complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1653</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1653</id><created>2010-08-10</created><authors><author><keyname>Holzer</keyname><forenames>Markus</forenames></author><author><keyname>Jakobi</keyname><forenames>Sebastian</forenames></author><author><keyname>Kutrib</keyname><forenames>Martin</forenames></author></authors><title>The Magic Number Problem for Subregular Language Families</title><categories>cs.FL cs.IT math.IT</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 110-119</journal-ref><doi>10.4204/EPTCS.31.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the magic number problem, that is, the question whether there
exists a minimal n-state nondeterministic finite automaton (NFA) whose
equivalent minimal deterministic finite automaton (DFA) has alpha states, for
all n and alpha satisfying n less or equal to alpha less or equal to exp(2,n).
A number alpha not satisfying this condition is called a magic number (for n).
It was shown in [11] that no magic numbers exist for general regular languages,
while in [5] trivial and non-trivial magic numbers for unary regular languages
were identified. We obtain similar results for automata accepting subregular
languages like, for example, combinational languages, star-free, prefix-,
suffix-, and infix-closed languages, and prefix-, suffix-, and infix-free
languages, showing that there are only trivial magic numbers, when they exist.
For finite languages we obtain some partial results showing that certain
numbers are non-magic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1654</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1654</id><created>2010-08-10</created><authors><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Rahman</keyname><forenames>Afroza</forenames></author></authors><title>Ciliate Gene Unscrambling with Fewer Templates</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 120-129</journal-ref><doi>10.4204/EPTCS.31.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the theoretical models proposed for the mechanism of gene unscrambling
in some species of ciliates is the template-guided recombination (TGR) system
by Prescott, Ehrenfeucht and Rozenberg which has been generalized by Daley and
McQuillan from a formal language theory perspective. In this paper, we propose
a refinement of this model that generates regular languages using the iterated
TGR system with a finite initial language and a finite set of templates, using
fewer templates and a smaller alphabet compared to that of the Daley-McQuillan
model. To achieve Turing completeness using only finite components, i.e., a
finite initial language and a finite set of templates, we also propose an
extension of the contextual template-guided recombination system (CTGR system)
by Daley and McQuillan, by adding an extra control called permitting contexts
on the usage of templates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1655</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1655</id><created>2010-08-10</created><authors><author><keyname>Kl&#xed;ma</keyname><forenames>Ond&#x159;ej</forenames><affiliation>Department of Mathematics and Statistics, Masaryk University Brno, Czech Republic</affiliation></author><author><keyname>Pol&#xe1;k</keyname><forenames>Libor</forenames><affiliation>Department of Mathematics and Statistics, Masaryk University Brno, Czech Republic</affiliation></author></authors><title>Descriptional Complexity of the Languages KaL: Automata, Monoids and
  Varieties</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><acm-class>F.4.3</acm-class><journal-ref>EPTCS 31, 2010, pp. 130-138</journal-ref><doi>10.4204/EPTCS.31.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first step when forming the polynomial hierarchies of languages is to
consider languages of the form KaL where K and L are over a finite alphabet A
and from a given variety V of languages, a being a letter from A. All such
KaL's generate the variety of languages BPol1(V).
  We estimate the numerical parameters of the language KaL in terms of their
values for K and L. These parameters include the state complexity of the
minimal complete DFA and the size of the syntactic monoids. We also estimate
the cardinality of the image of A* in the Schuetzenberger product of the
syntactic monoids of K and L. In these three cases we obtain the optimal
bounds.
  Finally, we also consider estimates for the cardinalities of free monoids in
the variety of monoids corresponding to BPol1(V) in terms of sizes of the free
monoids in the variety of monoids corresponding to V.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1656</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1656</id><created>2010-08-10</created><authors><author><keyname>Moreira</keyname><forenames>Nelma</forenames><affiliation>Universidade do Porto</affiliation></author><author><keyname>Nabais</keyname><forenames>Davide</forenames><affiliation>Universidade do Porto</affiliation></author><author><keyname>Reis</keyname><forenames>Rog&#xe9;rio</forenames><affiliation>Universidade do Porto</affiliation></author></authors><title>State Elimination Ordering Strategies: Some Experimental Results</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 139-148</journal-ref><doi>10.4204/EPTCS.31.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the problem of obtaining a short regular expression equivalent to a
given finite automaton has been intensively investigated. Algorithms for
converting finite automata to regular expressions have an exponential blow-up
in the worst-case. To overcome this, simple heuristic methods have been
proposed.
  In this paper we analyse some of the heuristics presented in the literature
and propose new ones. We also present some experimental comparative results
based on uniform random generated deterministic finite automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1657</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1657</id><created>2010-08-10</created><authors><author><keyname>Piao</keyname><forenames>Xiaoxue</forenames></author><author><keyname>Salomaa</keyname><forenames>Kai</forenames></author></authors><title>Operational State Complexity of Deterministic Unranked Tree Automata</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 149-158</journal-ref><doi>10.4204/EPTCS.31.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the state complexity of basic operations on tree languages
recognized by deterministic unranked tree automata. For the operations of union
and intersection the upper and lower bounds of both weakly and strongly
deterministic tree automata are obtained. For tree concatenation we establish a
tight upper bound that is of a different order than the known state complexity
of concatenation of regular string languages. We show that (n+1) (
(m+1)2^n-2^(n-1) )-1 vertical states are sufficient, and necessary in the worst
case, to recognize the concatenation of tree languages recognized by (strongly
or weakly) deterministic automata with, respectively, m and n vertical states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1658</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1658</id><created>2010-08-10</created><authors><author><keyname>Piao</keyname><forenames>Xiaoxue</forenames><affiliation>Queen's University</affiliation></author><author><keyname>Salomaa</keyname><forenames>Kai</forenames><affiliation>Queen's University</affiliation></author></authors><title>Transformations Between Different Types of Unranked Bottom-Up Tree
  Automata</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 159-168</journal-ref><doi>10.4204/EPTCS.31.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the representational state complexity of unranked tree automata.
The bottom-up computation of an unranked tree automaton may be either
deterministic or nondeterministic, and further variants arise depending on
whether the horizontal string languages defining the transitions are
represented by a DFA or an NFA. Also, we consider for unranked tree automata
the alternative syntactic definition of determinism introduced by Cristau et
al. (FCT'05, Lect. Notes Comput. Sci. 3623, pp. 68-79).
  We establish upper and lower bounds for the state complexity of conversions
between different types of unranked tree automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1659</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1659</id><created>2010-08-10</created><authors><author><keyname>Polley</keyname><forenames>Ronny</forenames><affiliation>Uni Halle</affiliation></author><author><keyname>Staiger</keyname><forenames>Ludwig</forenames><affiliation>Uni Halle</affiliation></author></authors><title>The Maximal Subword Complexity of Quasiperiodic Infinite Words</title><categories>cs.FL cs.DM cs.IT math.IT</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><acm-class>F.4.3, F.4.m, F.1.1</acm-class><journal-ref>EPTCS 31, 2010, pp. 169-176</journal-ref><doi>10.4204/EPTCS.31.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an exact estimate on the maximal subword complexity for
quasiperiodic infinite words. To this end we give a representation of the set
of finite and of infinite words having a certain quasiperiod q via a finite
language derived from q. It is shown that this language is a suffix code having
a bounded delay of decipherability. Our estimate of the subword complexity now
follows from this result, previously known results on the subword complexity
and elementary results on formal power series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1660</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1660</id><created>2010-08-10</created><authors><author><keyname>Truthe</keyname><forenames>Bianca</forenames><affiliation>Otto-von-Guericke-Universit&#xe4;t Magdeburg</affiliation></author></authors><title>On the Descriptional Complexity of Limited Propagating Lindenmayer
  Systems</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 177-188</journal-ref><doi>10.4204/EPTCS.31.20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the descriptional complexity of limited propagating
Lindenmayer systems and their deterministic and tabled variants with respect to
the number of rules and the number of symbols. We determine the decrease of
complexity when the generative capacity is increased. For incomparable
families, we give languages that can be described more efficiently in either of
these families than in the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1661</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1661</id><created>2010-08-10</created><authors><author><keyname>Han</keyname><forenames>Yo-Sub</forenames></author><author><keyname>Salomaa</keyname><forenames>Kai</forenames></author></authors><title>Nondeterministic State Complexity for Suffix-Free Regular Languages</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 189-196</journal-ref><doi>10.4204/EPTCS.31.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the nondeterministic state complexity of basic operations for
suffix-free regular languages. The nondeterministic state complexity of an
operation is the number of states that are necessary and sufficient in the
worst-case for a minimal nondeterministic finite-state automaton that accepts
the language obtained from the operation. We consider basic operations
(catenation, union, intersection, Kleene star, reversal and complementation)
and establish matching upper and lower bounds for each operation. In the case
of complementation the upper and lower bounds differ by an additive constant of
two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1662</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1662</id><created>2010-08-10</created><authors><author><keyname>Jir&#xe1;skov&#xe1;</keyname><forenames>Galina</forenames></author><author><keyname>Krausov&#xe1;</keyname><forenames>Monika</forenames></author></authors><title>Complexity in Prefix-Free Regular Languages</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 197-204</journal-ref><doi>10.4204/EPTCS.31.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine deterministic and nondeterministic state complexities of regular
operations on prefix-free languages. We strengthen several results by providing
witness languages over smaller alphabets, usually as small as possible. We next
provide the tight bounds on state complexity of symmetric difference, and
deterministic and nondeterministic state complexity of difference and cyclic
shift of prefix-free languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1663</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1663</id><created>2010-08-10</created><authors><author><keyname>Kasprzik</keyname><forenames>Anna</forenames><affiliation>University of Trier</affiliation></author></authors><title>Learning Residual Finite-State Automata Using Observation Tables</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 205-212</journal-ref><doi>10.4204/EPTCS.31.23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a two-step learner for RFSAs based on an observation table by using
an algorithm for minimal DFAs to build a table for the reversal of the language
in question and showing that we can derive the minimal RFSA from it after some
simple modifications. We compare the algorithm to two other table-based ones of
which one (by Bollig et al. 2009) infers a RFSA directly, and the other is
another two-step learner proposed by the author. We focus on the criterion of
query complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1664</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1664</id><created>2010-08-10</created><authors><author><keyname>Prusinkiewicz</keyname><forenames>Przemyslaw</forenames><affiliation>University of Calgary</affiliation></author><author><keyname>Shirmohammadi</keyname><forenames>Mitra</forenames><affiliation>University of Calgary</affiliation></author><author><keyname>Samavati</keyname><forenames>Faramarz</forenames><affiliation>University of Calgary</affiliation></author></authors><title>L-systems in Geometric Modeling</title><categories>cs.GR cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 3-14</journal-ref><doi>10.4204/EPTCS.31.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that parametric context-sensitive L-systems with affine geometry
interpretation provide a succinct description of some of the most fundamental
algorithms of geometric modeling of curves. Examples include the
Lane-Riesenfeld algorithm for generating B-splines, the de Casteljau algorithm
for generating Bezier curves, and their extensions to rational curves. Our
results generalize the previously reported geometric-modeling applications of
L-systems, which were limited to subdivision curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1665</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1665</id><created>2010-08-10</created><authors><author><keyname>Kappes</keyname><forenames>Martin</forenames></author><author><keyname>Malcher</keyname><forenames>Andreas</forenames></author><author><keyname>Wotschke</keyname><forenames>Detlef</forenames></author></authors><title>Remembering Chandra Kintala</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 15-26</journal-ref><doi>10.4204/EPTCS.31.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With this contribution we would like to remember Chandra M. R. Kintala who
passed away in November 2009. We will give short overviews of his CV and his
contributions to the field of theoretical and applied computer science and,
given the opportunity, will attempt to present the current state of limited
nondeterminism and limited resources for machines. Finally, we will briefly
touch on some research topics which hopefully will be addressed in the not so
distant future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1666</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1666</id><created>2010-08-10</created><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Li</keyname><forenames>Baiyu</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Ye</keyname><forenames>Yuli</forenames><affiliation>University of Toronto</affiliation></author></authors><title>On the Complexity of the Evaluation of Transient Extensions of Boolean
  Functions</title><categories>cs.CC cs.DM</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 27-37</journal-ref><doi>10.4204/EPTCS.31.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transient algebra is a multi-valued algebra for hazard detection in gate
circuits. Sequences of alternating 0's and 1's, called transients, represent
signal values, and gates are modeled by extensions of boolean functions to
transients. Formulas for computing the output transient of a gate from the
input transients are known for NOT, AND, OR} and XOR gates and their
complements, but, in general, even the problem of deciding whether the length
of the output transient exceeds a given bound is NP-complete. We propose a
method of evaluating extensions of general boolean functions. We introduce and
study a class of functions with the following property: Instead of evaluating
an extension of a boolean function on a given set of transients, it is possible
to get the same value by using transients derived from the given ones, but
having length at most 3. We prove that all functions of three variables, as
well as certain other functions, have this property, and can be efficiently
evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1667</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1667</id><created>2010-08-10</created><authors><author><keyname>Calude</keyname><forenames>Cristian</forenames><affiliation>University of Auckland</affiliation></author><author><keyname>Salomaa</keyname><forenames>Kai</forenames><affiliation>Queen's University</affiliation></author><author><keyname>Roblot</keyname><forenames>Tania</forenames><affiliation>University of Auckland</affiliation></author></authors><title>Finite-State Complexity and the Size of Transducers</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 31, 2010, pp. 38-47</journal-ref><doi>10.4204/EPTCS.31.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite-state complexity is a variant of algorithmic information theory
obtained by replacing Turing machines with finite transducers. We consider the
state-size of transducers needed for minimal descriptions of arbitrary strings
and, as our main result, we show that the state-size hierarchy with respect to
a standard encoding is infinite. We consider also hierarchies yielded by more
general computable encodings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1668</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1668</id><created>2010-08-10</created><authors><author><keyname>Charlier</keyname><forenames>Emilie</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Rigo</keyname><forenames>Michel</forenames></author><author><keyname>Waxweiler</keyname><forenames>Laurent</forenames></author></authors><title>State Complexity of Testing Divisibility</title><categories>cs.FL</categories><comments>In Proceedings DCFS 2010, arXiv:1008.1270</comments><proxy>EPTCS</proxy><acm-class>F.4.3</acm-class><journal-ref>EPTCS 31, 2010, pp. 48-57</journal-ref><doi>10.4204/EPTCS.31.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under some mild assumptions, we study the state complexity of the trim
minimal automaton accepting the greedy representations of the multiples of m &gt;=
2 for a wide class of linear numeration systems. As an example, the number of
states of the trim minimal automaton accepting the greedy representations of
the multiples of m in the Fibonacci system is exactly 2m^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1670</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1670</id><created>2010-08-10</created><authors><author><keyname>Headayetullah</keyname><forenames>Md.</forenames></author><author><keyname>Pradhan</keyname><forenames>G. K.</forenames></author></authors><title>Interoperability, Trust Based Information Sharing Protocol and Security:
  Digital Government Key Issues</title><categories>cs.CR</categories><report-no>1006.1199</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improved interoperability between public and private organizations is of key
significance to make digital government newest triumphant. Digital Government
interoperability, information sharing protocol and security are measured the
key issue for achieving a refined stage of digital government. Flawless
interoperability is essential to share the information between diverse and
merely dispersed organisations in several network environments by using
computer based tools. Digital government must ensure security for its
information systems, including computers and networks for providing better
service to the citizens. Governments around the world are increasingly
revolving to information sharing and integration for solving problems in
programs and policy areas. Evils of global worry such as syndrome discovery and
manage, terror campaign, immigration and border control, prohibited drug
trafficking, and more demand information sharing, harmonization and cooperation
amid government agencies within a country and across national borders. A number
of daunting challenges survive to the progress of an efficient information
sharing protocol. A secure and trusted information-sharing protocol is required
to enable users to interact and share information easily and perfectly across
many diverse networks and databases globally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1671</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1671</id><created>2010-08-10</created><authors><author><keyname>Hasan</keyname><forenames>K. M. Azharul</forenames></author><author><keyname>Hasan</keyname><forenames>Mohammad Sabbir</forenames></author></authors><title>A Parsing Scheme for Finding the Design Pattern and Reducing the
  Development Cost of Reusable Object Oriented Software</title><categories>cs.SE</categories><comments>15 pages, 5 figures</comments><msc-class>68N30</msc-class><acm-class>K.6.3</acm-class><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT), 2(3), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because of the importance of object oriented methodologies, the research in
developing new measure for object oriented system development is getting
increased focus. The most of the metrics need to find the interactions between
the objects and modules for developing necessary metric and an influential
software measure that is attracting the software developers, designers and
researchers. In this paper a new interactions are defined for object oriented
system. Using these interactions, a parser is developed to analyze the existing
architecture of the software. Within the design model, it is necessary for
design classes to collaborate with one another. However, collaboration should
be kept to an acceptable minimum i.e. better designing practice will introduce
low coupling. If a design model is highly coupled, the system is difficult to
implement, to test and to maintain overtime. In case of enhancing software, we
need to introduce or remove module and in that case coupling is the most
important factor to be considered because unnecessary coupling may make the
system unstable and may cause reduction in the system's performance. So
coupling is thought to be a desirable goal in software construction, leading to
better values for external software qualities such as maintainability,
reusability and so on. To test this hypothesis, a good measure of class
coupling is needed. In this paper, based on the developed tool called Design
Analyzer we propose a methodology to reuse an existing system with the
objective of enhancing an existing Object oriented system keeping the coupling
as low as possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1673</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1673</id><created>2010-08-10</created><updated>2010-08-28</updated><authors><author><keyname>Berka</keyname><forenames>Alex V</forenames></author></authors><title>Space and the Synchronic A-Ram</title><categories>cs.CL cs.PL</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space is a circuit oriented, spatial programming language designed to exploit
the massive parallelism available in a novel formal model of computation called
the Synchronic A-Ram, and physically related FPGA and reconfigurable
architectures. Space expresses variable grained MIMD parallelism, is modular,
strictly typed, and deterministic. Barring operations associated with memory
allocation and compilation, modules cannot access global variables, and are
referentially transparent. At a high level of abstraction, modules exhibit a
small, sequential state transition system, aiding verification. Space deals
with communication, scheduling, and resource contention issues in parallel
computing, by resolving them explicitly in an incremental manner, module by
module, whilst ascending the ladder of abstraction. Whilst the Synchronic A-Ram
model was inspired by linguistic considerations, it is also put forward as a
formal model for reconfigurable digital circuits. A programming environment has
been developed, that incorporates a simulator and compiler that transform Space
programs into Synchronic A-Ram machine code, consisting of only three bit-level
instructions, and a marking instruction. Space and the Synchronic A-Ram point
to novel routes out of the parallel computing crisis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1674</identifier>
 <datestamp>2011-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1674</id><created>2010-08-10</created><authors><author><keyname>Rumin</keyname><forenames>Michel</forenames></author></authors><title>Balanced distribution-energy inequalities and related entropy bounds</title><categories>math.FA cs.IT math.IT math.SP</categories><comments>21 pages</comments><msc-class>58J50, 47B06, 46E35, 35P20, 94A17</msc-class><journal-ref>Duke Math. J. Volume 160, Number 3 (2011), 567-597</journal-ref><doi>10.1215/00127094-1444305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $A$ be a self-adjoint operator acting over a space $X$ endowed with a
partition. We give lower bounds on the energy of a mixed state $\rho$ from its
distribution in the partition and the spectral density of $A$. These bounds
improve with the refinement of the partition, and generalize inequalities by
Li-Yau and Lieb--Thirring for the Laplacian in $\R^n$. They imply an
uncertainty principle, giving a lower bound on the sum of the spatial entropy
of $\rho$, as seen from $X$, and some spectral entropy, with respect to its
energy distribution. On $\R^n$, this yields lower bounds on the sum of the
entropy of the densities of $\rho$ and its Fourier transform. A general
log-Sobolev inequality is also shown. It holds on mixed states, without
Markovian or positivity assumption on $A$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1687</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1687</id><created>2010-08-10</created><authors><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author></authors><title>A Deterministic Polynomial-time Approximation Scheme for Counting
  Knapsack Solutions</title><categories>cs.DS</categories><comments>11 pages</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given n elements with nonnegative integer weights w1,..., wn and an integer
capacity C, we consider the counting version of the classic knapsack problem:
find the number of distinct subsets whose weights add up to at most the given
capacity. We give a deterministic algorithm that estimates the number of
solutions to within relative error 1+-eps in time polynomial in n and 1/eps
(fully polynomial approximation scheme). More precisely, our algorithm takes
time O(n^3 (1/eps) log (n/eps)). Our algorithm is based on dynamic programming.
Previously, randomized polynomial time approximation schemes were known first
by Morris and Sinclair via Markov chain Monte Carlo techniques, and
subsequently by Dyer via dynamic programming and rejection sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1695</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1695</id><created>2010-08-10</created><authors><author><keyname>Sheela</keyname><forenames>S. V.</forenames></author><author><keyname>Radhika</keyname><forenames>K. R.</forenames></author></authors><title>Biometric Authentication using Nonparametric Methods</title><categories>cs.CV</categories><comments>20 pages, 17 figures</comments><journal-ref>International Journal of Computer Science and Information
  Technology 2.3 (2010) 114-133</journal-ref><doi>10.5121/ijcsit.2010.2309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The physiological and behavioral trait is employed to develop biometric
authentication systems. The proposed work deals with the authentication of iris
and signature based on minimum variance criteria. The iris patterns are
preprocessed based on area of the connected components. The segmented image
used for authentication consists of the region with large variations in the
gray level values. The image region is split into quadtree components. The
components with minimum variance are determined from the training samples. Hu
moments are applied on the components. The summation of moment values
corresponding to minimum variance components are provided as input vector to
k-means and fuzzy k-means classifiers. The best performance was obtained for
MMU database consisting of 45 subjects. The number of subjects with zero False
Rejection Rate [FRR] was 44 and number of subjects with zero False Acceptance
Rate [FAR] was 45. This paper addresses the computational load reduction in
off-line signature verification based on minimal features using k-means, fuzzy
k-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and
FAR of 10% was achieved using k-nn classifier. The signature is a biometric,
where variations in a genuine case, is a natural expectation. In the genuine
signature, certain parts of signature vary from one instance to another. The
system aims to provide simple, fast and robust system using less number of
features when compared to state of art works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1700</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1700</id><created>2010-08-10</created><updated>2011-08-26</updated><authors><author><keyname>Manguoglu</keyname><forenames>Murat</forenames></author></authors><title>A domain decomposing parallel sparse linear system solver</title><categories>cs.NA cs.MS</categories><comments>To appear in Journal of Computational and Applied Mathematics</comments><msc-class>65F05, 65F10, 65Y05</msc-class><journal-ref>Journal of Computational and Applied Mathematics, Volume 236,
  Issue 3, 2011, Pages 319-325</journal-ref><doi>10.1016/j.cam.2011.07.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The solution of large sparse linear systems is often the most time-consuming
part of many science and engineering applications. Computational fluid
dynamics, circuit simulation, power network analysis, and material science are
just a few examples of the application areas in which large sparse linear
systems need to be solved effectively. In this paper we introduce a new
parallel hybrid sparse linear system solver for distributed memory
architectures that contains both direct and iterative components. We show that
by using our solver one can alleviate the drawbacks of direct and iterative
solvers, achieving better scalability than with direct solvers and more
robustness than with classical preconditioned iterative solvers. Comparisons to
well-known direct and iterative solvers on a parallel architecture are
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1710</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1710</id><created>2010-08-10</created><authors><author><keyname>Hermenegildo</keyname><forenames>Manuel</forenames></author><author><keyname>Schaub</keyname><forenames>Torsten</forenames></author></authors><title>Introduction to the 26th International Conference on Logic Programming
  Special Issue</title><categories>cs.AI cs.LO</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the preface to the 26th International Conference on Logic Programming
Special Issue
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1715</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1715</id><created>2010-08-10</created><updated>2011-11-24</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>The universality of iterated hashing over variable-length strings</title><categories>cs.DB cs.DS</categories><journal-ref>Discrete Applied Mathematics 160 (4-5), 604--617 (2012)</journal-ref><doi>10.1016/j.dam.2011.11.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterated hash functions process strings recursively, one character at a time.
At each iteration, they compute a new hash value from the preceding hash value
and the next character. We prove that iterated hashing can be pairwise
independent, but never 3-wise independent. We show that it can be almost
universal over strings much longer than the number of hash values; we bound the
maximal string length given the collision probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1723</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1723</id><created>2010-08-07</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Gerhard</keyname><forenames>Detlef</forenames></author></authors><title>Role of Ontology in Semantic Web Development</title><categories>cs.AI</categories><comments>In the proceedings of First International Workshop on Cultural
  Heritage on the Semantic Web in conjunction with the 6th International
  Semantic Web Conference and the 2nd Asian Semantic Web Conference 2007, (ISWC
  + ASWC 2007), P 119, 12-15 November 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  World Wide Web (WWW) is the most popular global information sharing and
communication system consisting of three standards .i.e., Uniform Resource
Identifier (URL), Hypertext Transfer Protocol (HTTP) and Hypertext Mark-up
Language (HTML). Information is provided in text, image, audio and video
formats over the web by using HTML which is considered to be unconventional in
defining and formalizing the meaning of the context...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1744</identifier>
 <datestamp>2011-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1744</id><created>2010-08-10</created><updated>2011-07-05</updated><authors><author><keyname>Kreitmeier</keyname><forenames>Wolfgang</forenames></author><author><keyname>Linder</keyname><forenames>Tamas</forenames></author></authors><title>High-resolution scalar quantization with R\'enyi entropy constraint</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory</comments><msc-class>28D20, 41A46, 62H30, 94A17, 94A29</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider optimal scalar quantization with $r$th power distortion and
constrained R\'enyi entropy of order $\alpha$. For sources with an absolutely
continuous distribution the high rate asymptotics of the quantizer distortion
has long been known for $\alpha=0$ (fixed-rate quantization) and $\al pha=1$
(entropy-constrained quantization). For a large class of absolutely continuous
source distributions we determine the sharp asymptotics of the optimal
quantization distortion for $\alpha\in [-\infty,0)\cup (0,1)$. The
achievability proof is based on finding (asymptotically) optimal quantizers via
the companding approach, and is thus constructive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1751</identifier>
 <datestamp>2014-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1751</id><created>2010-08-10</created><authors><author><keyname>Karra</keyname><forenames>Satish</forenames></author><author><keyname>Pr&#x16f;&#x161;a</keyname><forenames>V&#xed;t</forenames></author><author><keyname>Rajagopal</keyname><forenames>K. R.</forenames></author></authors><title>On Maxwell fluid with relaxation time and viscosity depending on the
  pressure</title><categories>cs.NA math-ph math.MP physics.flu-dyn</categories><comments>16 pages, 14 figures, submitted to International Journal of
  Non-Linear Mechanics</comments><msc-class>76A10</msc-class><journal-ref>Karra, Satish, V\'it Pr\r{u}\v{s}a, and K. R. Rajagopal. &quot;On
  Maxwell fluids with relaxation time and viscosity depending on the pressure.&quot;
  International Journal of Non-Linear Mechanics 46.6 (2011): 819-827</journal-ref><doi>10.1016/j.ijnonlinmec.2011.02.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a variant of the well known Maxwell model for viscoelastic fluids,
namely we consider the Maxwell fluid with viscosity and relaxation time
depending on the pressure. Such a model is relevant for example in modelling
behaviour of some polymers and geomaterials. Although it is experimentally
known that the material moduli of some viscoelastic fluids can depend on the
pressure, most of the studies concerning the motion of viscoelastic fluids do
not take such effects into account despite their possible practical
significance in technological applications. Using a generalized Maxwell model
with pressure dependent material moduli we solve a simple boundary value
problem and we demonstrate interesting non-classical features exhibited by the
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1756</identifier>
 <datestamp>2014-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1756</id><created>2010-08-10</created><authors><author><keyname>Bridges</keyname><forenames>Craig</forenames></author><author><keyname>Karra</keyname><forenames>Satish</forenames></author><author><keyname>Rajagopal</keyname><forenames>K. R.</forenames></author></authors><title>On Modeling the Response of Synovial Fluid: Unsteady Flow of a
  Shear-Thinning, Chemically-Reacting Fluid Mixture</title><categories>cs.NA math-ph math.MP physics.flu-dyn</categories><comments>25 pages, 11 figures, accepted in Computers &amp; Applications with
  Mathematics</comments><journal-ref>Bridges, Craig, Satish Karra, and K. R. Rajagopal. &quot;On modeling
  the response of the synovial fluid: Unsteady flow of a shear-thinning,
  chemically-reacting fluid mixture.&quot; Computers &amp; Mathematics with Applications
  60.8 (2010): 2333-2349</journal-ref><doi>10.1016/j.camwa.2010.08.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the flow of a shear-thinning, chemically-reacting fluid that could
be used to model the flow of the synovial fluid. The actual geometry where the
flow of the synovial fluid takes place is very complicated, and therefore the
governing equations are not amenable to simple mathematical analysis. In order
to understand the response of the model, we choose to study the flow in a
simple geometry. While the flow domain is not a geometry relevant to the flow
of the synovial fluid in the human body it yet provides a flow which can be
used to assess the efficacy of different models that have been proposed to
describe synovial fluids. We study the flow in the annular region between two
cylinders, one of which is undergoing unsteady oscillations about their common
axis, in order to understand the quintessential behavioral characteristics of
the synovial fluid. We use the three models suggested by Hron et al. [ J. Hron,
J. M\'{a}lek, P. Pust\v{e}jovsk\'{a}, K. R. Rajagopal, On concentration
dependent shear-thinning behavior in modeling of synovial fluid flow, Adv. in
Tribol. (In Press).] to study the problem, by appealing to a semi-inverse
method. The assumed structure for the velocity field automatically satisfies
the constraint of incompressibility, and the balance of linear momentum is
solved together with a convection-diffusion equation. The results are compared
to those associated with the Newtonian model. We also study the case in which
an external pressure gradient is applied along the axis of the cylindrical
annulus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1766</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1766</id><created>2010-08-10</created><updated>2013-11-30</updated><authors><author><keyname>Bennatan</keyname><forenames>Amir</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Calderbank</keyname><forenames>A. Robert</forenames></author></authors><title>Soft-Decoding-Based Strategies for Relay and Interference Channels:
  Analysis and Achievable Rates Using LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Accepted to the IEEE Transactions on Information Theory. This is a
  major revision of a paper originally submitted in August 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a rigorous mathematical analysis of two communication strategies:
soft decode-and-forward (soft-DF) for relay channels, and soft partial
interference-cancelation (soft-IC) for interference channels. Both strategies
involve soft estimation, which assists the decoding process. We consider LDPC
codes, not because of their practical benefits, but because of their analytic
tractability, which enables an asymptotic analysis similar to random coding
methods of information theory. Unlike some works on the closely-related
demodulate-and-forward, we assume non-memoryless, code-structure-aware
estimation. With soft-DF, we develop {\it simultaneous density evolution} to
bound the decoding error probability at the destination. This result applies to
erasure relay channels. In one variant of soft-DF, the relay applies Wyner-Ziv
coding to enhance its communication with the destination, borrowing from
compress-and-forward. To analyze soft-IC, we adapt existing techniques for
iterative multiuser detection, and focus on binary-input additive white
Gaussian noise (BIAWGN) interference channels. We prove that optimal
point-to-point codes are unsuitable for soft-IC, as well as for all strategies
that apply partial decoding to improve upon single-user detection (SUD) and
multiuser detection (MUD), including Han-Kobayashi (HK).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1767</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1767</id><created>2010-08-10</created><authors><author><keyname>Sarddar</keyname><forenames>Debabrata</forenames></author><author><keyname>Banerjee</keyname><forenames>Joydeep</forenames></author><author><keyname>Saha</keyname><forenames>Souvik Kumar</forenames></author><author><keyname>Jana</keyname><forenames>Tapas</forenames></author><author><keyname>Biswas</keyname><forenames>Utpal</forenames></author><author><keyname>Naskar</keyname><forenames>M. K.</forenames></author></authors><title>Minimization of Handoff latency by co-ordinate evaluation method using
  GPS based map</title><categories>cs.NI</categories><doi>10.5120/3039-4122</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handoff has become an essential criterion in mobile communication system,
specially in urban areas, owing to the limited coverage area of Access Points
(AP). Handover of calls between two Base Stations (BSs) is encountered
frequently and it is essentially required to minimize the delay of the process.
Many solutions attempting to improve this process have been proposed but only a
few use geo-location systems in the management of the handover. Here we propose
to minimize the handoff latency by minimizing the number of APs scanned by the
Mobile Node (MN) during each handoff procedure. We consider the whole
topographical area as a two dimensional plane. By GPS, we can note down the
co-ordinates of the MN at any instant. The average rate of change of its
latitudinal distance and longitudinal distance with a specific time period is
evaluated at the end of the given time period. With the knowledge of the given
parameter, it is possible to determine the latitude and longitude of the MN
after a particular instant of time. Hence, the direction of motion of the MN
can be determined, which in turns gives the AP towards which the MN is
headings. This reduces the number of APs to be scanned. Thus, on an overall
basis, the handoff latency can be reduced by almost half to one third of its
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1770</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1770</id><created>2010-08-10</created><updated>2010-08-11</updated><authors><author><keyname>Yazdani</keyname><forenames>A.</forenames></author><author><keyname>Jeffrey</keyname><forenames>P.</forenames></author></authors><title>A complex network approach to robustness and vulnerability of spatially
  organized water distribution networks</title><categories>physics.soc-ph cs.CE cs.SI math.CO</categories><comments>18 pages, 2 figures, A slightly different version of this work has
  been submitted to Water Distribution System Analysis Conference, WDSA2010,
  AZ, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, water distribution systems are regarded as large sparse planar
graphs with complex network characteristics and the relationship between
important topological features of the network (i.e. structural robustness and
loop redundancy) and system resilience, viewed as the antonym to structural
vulnerability, are assessed. Deterministic techniques from complex networks and
spectral graph theory are utilized to quantify well-connectedness and estimate
loop redundancy in the studied benchmark networks. By using graph connectivity
and expansion properties, system robustness against node/link failures and
isolation of the demand nodes from the source(s) are assessed and network
tolerance against random failures and targeted attacks on their bridges and cut
sets are analyzed. Among other measurements, two metrics of meshed-ness and
algebraic connectivity are proposed as candidates for quantification of
redundancy and robustness, respectively, in optimization design models. A brief
discussion on the scope and limitations of the provided measurements in the
analysis of operational reliability of water distribution systems is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1789</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1789</id><created>2010-08-10</created><authors><author><keyname>Ben-Sasson</keyname><forenames>Eli</forenames></author><author><keyname>Nordstr&#xf6;m</keyname><forenames>Jakob</forenames></author></authors><title>Understanding Space in Proof Complexity: Separations and Trade-offs via
  Substitutions</title><categories>cs.CC</categories><comments>This paper is a merged and updated version of the two ECCC technical
  reports TR09-034 and TR09-047, and it hence subsumes these two reports</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For current state-of-the-art DPLL SAT-solvers the two main bottlenecks are
the amounts of time and memory used. In proof complexity, these resources
correspond to the length and space of resolution proofs. There has been a long
line of research investigating these proof complexity measures, but while
strong results have been established for length, our understanding of space and
how it relates to length has remained quite poor. In particular, the question
whether resolution proofs can be optimized for length and space simultaneously,
or whether there are trade-offs between these two measures, has remained
essentially open.
  In this paper, we remedy this situation by proving a host of length-space
trade-off results for resolution. Our collection of trade-offs cover almost the
whole range of values for the space complexity of formulas, and most of the
trade-offs are superpolynomial or even exponential and essentially tight. Using
similar techniques, we show that these trade-offs in fact extend to the
exponentially stronger k-DNF resolution proof systems, which operate with
formulas in disjunctive normal form with terms of bounded arity k. We also
answer the open question whether the k-DNF resolution systems form a strict
hierarchy with respect to space in the affirmative.
  Our key technical contribution is the following, somewhat surprising,
theorem: Any CNF formula F can be transformed by simple variable substitution
into a new formula F' such that if F has the right properties, F' can be proven
in essentially the same length as F, whereas on the other hand the minimal
number of lines one needs to keep in memory simultaneously in any proof of F'
is lower-bounded by the minimal number of variables needed simultaneously in
any proof of F. Applying this theorem to so-called pebbling formulas defined in
terms of pebble games on directed acyclic graphs, we obtain our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1809</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1809</id><created>2010-08-10</created><authors><author><keyname>Drescher</keyname><forenames>Christian</forenames></author><author><keyname>Tifrea</keyname><forenames>Oana</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Symmetry-breaking Answer Set Solving</title><categories>cs.LO</categories><comments>Proceedings of ICLP'10 Workshop on Answer Set Programming and Other
  Computing Paradigm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of Answer Set Programming, this paper investigates
symmetry-breaking to eliminate symmetric parts of the search space and,
thereby, simplify the solution process. We propose a reduction of disjunctive
logic programs to a coloured digraph such that permutational symmetries can be
constructed from graph automorphisms. Symmetries are then broken by introducing
symmetry-breaking constraints. For this purpose, we formulate a preprocessor
that integrates a graph automorphism system. Experiments demonstrate its
computational impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1825</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1825</id><created>2010-08-10</created><authors><author><keyname>Miaji</keyname><forenames>Yaser</forenames></author><author><keyname>Hassan</keyname><forenames>Suhaidi</forenames></author></authors><title>Breaking the Legend: Maxmin Fairness notion is no longer effective</title><categories>cs.NI</categories><comments>8 Pages</comments><report-no>UUM-2010-1</report-no><msc-class>41-04</msc-class><acm-class>G.3</acm-class><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks(GRAPH-HOC) Vol.2, No.2, June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analytically propose an alternative approach to achieve
better fairness in scheduling mechanisms which could provide better quality of
service particularly for real time application. Our proposal oppose the
allocation of the bandwidth which adopted by all previous scheduling mechanism.
It rather adopt the opposition approach be proposing the notion of
Maxmin-charge which fairly distribute the congestion. Furthermore, analytical
proposition of novel mechanism named as Just Queueing is been demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1827</identifier>
 <datestamp>2012-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1827</id><created>2010-08-10</created><updated>2012-03-12</updated><authors><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Braverman</keyname><forenames>Mark</forenames></author></authors><title>Nash Equilibria in Perturbation Resilient Games</title><categories>cs.GT cs.DS</categories><comments>24 pages</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the fact that in many game-theoretic settings, the game analyzed
is only an approximation to the game being played, in this work we analyze
equilibrium computation for the broad and natural class of bimatrix games that
are stable to perturbations. We specifically focus on games with the property
that small changes in the payoff matrices do not cause the Nash equilibria of
the game to fluctuate wildly. For such games we show how one can compute
approximate Nash equilibria more efficiently than the general result of Lipton
et al. \cite{LMM03}, by an amount that depends on the degree of stability of
the game and that reduces to their bound in the worst case. Furthermore, we
show that for stable games the approximate equilibria found will be close in
variation distance to true equilibria, and moreover this holds even if we are
given as input only a perturbation of the actual underlying stable game.
  For uniformly-stable games, where the equilibria fluctuate at most
quasi-linearly in the extent of the perturbation, we get a particularly
dramatic improvement. Here, we achieve a fully quasi-polynomial-time
approximation scheme: that is, we can find $1/\poly(n)$-approximate equilibria
in quasi-polynomial time. This is in marked contrast to the general class of
bimatrix games for which finding such approximate equilibria is PPAD-hard. In
particular, under the (widely believed) assumption that PPAD is not contained
in quasi-polynomial time, our results imply that such uniformly stable games
are inherently easier for computation of approximate equilibria than general
bimatrix games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1828</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1828</id><created>2010-08-10</created><updated>2010-10-03</updated><authors><author><keyname>Ouyang</keyname><forenames>Wenzhuo</forenames></author><author><keyname>Murugesan</keyname><forenames>Sugumar</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Scheduling with Rate Adaptation under Incomplete Knowledge of
  Channel/Estimator Statistics</title><categories>cs.NI</categories><comments>48th Allerton Conference on Communication, Control, and Computing,
  Monticello, IL, Sept. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In time-varying wireless networks, the states of the communication channels
are subject to random variations, and hence need to be estimated for efficient
rate adaptation and scheduling. The estimation mechanism possesses inaccuracies
that need to be tackled in a probabilistic framework. In this work, we study
scheduling with rate adaptation in single-hop queueing networks under two
levels of channel uncertainty: when the channel estimates are inaccurate but
complete knowledge of the channel/estimator joint statistics is available at
the scheduler; and when the knowledge of the joint statistics is incomplete. In
the former case, we characterize the network stability region and show that a
maximum-weight type scheduling policy is throughput-optimal. In the latter
case, we propose a joint channel statistics learning - scheduling policy. With
an associated trade-off in average packet delay and convergence time, the
proposed policy has a stability region arbitrarily close to the stability
region of the network under full knowledge of channel/estimator joint
statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1842</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1842</id><created>2010-08-11</created><authors><author><keyname>Qureshi</keyname><forenames>Jalaluddin</forenames></author><author><keyname>Foh</keyname><forenames>Chuan Heng</forenames></author><author><keyname>Cai</keyname><forenames>Jianfei</forenames></author></authors><title>An Efficient Network Coding based Retransmission Algorithm for Wireless
  Multicasts</title><categories>cs.NI</categories><comments>5 pages, 5 figures</comments><doi>10.1109/PIMRC.2009.5449983</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retransmission based on packet acknowledgement (ACK/NAK) is a fundamental
error control technique employed in IEEE 802.11-2007 unicast network. However
the 802.11-2007 standard falls short of proposing a reliable MAC-level recovery
protocol for multicast frames. In this paper we propose a latency and bandwidth
efficient coding algorithm based on the principles of network coding for
retransmitting lost packets in a singlehop wireless multicast network and
demonstrate its effectiveness over previously proposed network coding based
retransmission algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1843</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1843</id><created>2010-08-11</created><updated>2010-10-27</updated><authors><author><keyname>Yan</keyname><forenames>Qiqi</forenames></author></authors><title>Mechanism Design via Correlation Gap</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For revenue and welfare maximization in single-dimensional Bayesian settings,
Chawla et al. (STOC10) recently showed that sequential posted-price mechanisms
(SPMs), though simple in form, can perform surprisingly well compared to the
optimal mechanisms. In this paper, we give a theoretical explanation of this
fact, based on a connection to the notion of correlation gap.
  Loosely speaking, for auction environments with matroid constraints, we can
relate the performance of a mechanism to the expectation of a monotone
submodular function over a random set. This random set corresponds to the
winner set for the optimal mechanism, which is highly correlated, and
corresponds to certain demand set for SPMs, which is independent. The notion of
correlation gap of Agrawal et al.\ (SODA10) quantifies how much we {}&quot;lose&quot; in
the expectation of the function by ignoring correlation in the random set, and
hence bounds our loss in using certain SPM instead of the optimal mechanism.
Furthermore, the correlation gap of a monotone and submodular function is known
to be small, and it follows that certain SPM can approximate the optimal
mechanism by a good constant factor.
  Exploiting this connection, we give tight analysis of a greedy-based SPM of
Chawla et al.\ for several environments. In particular, we show that it gives
an $e/(e-1)$-approximation for matroid environments, gives asymptotically a
$1/(1-1/\sqrt{2\pi k})$-approximation for the important sub-case of $k$-unit
auctions, and gives a $(p+1)$-approximation for environments with
$p$-independent set system constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1846</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1846</id><created>2010-08-11</created><updated>2010-08-15</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author><author><keyname>Delahaye</keyname><forenames>Jean-Paul</forenames></author></authors><title>An algorithmic information-theoretic approach to the behaviour of
  financial markets</title><categories>q-fin.TR cs.CE cs.IT math.IT</categories><comments>Forthcoming in the Journal of Economic Surveys, special issue on
  Nonlinearity, Complexity and Randomness. 25 pages. 7 figures. 9 tables.
  Latest version fixes the glitches on the tables related to the distribution
  from Turing machines (using 4 states as claimed, and not only 2 as before),
  added 2 new references and other minor changes. UK English version</comments><acm-class>E.4; H.1.1; J.1; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using frequency distributions of daily closing price time series of several
financial market indexes, we investigate whether the bias away from an
equiprobable sequence distribution found in the data, predicted by algorithmic
information theory, may account for some of the deviation of financial markets
from log-normal, and if so for how much of said deviation and over what
sequence lengths. We do so by comparing the distributions of binary sequences
from actual time series of financial markets and series built up from purely
algorithmic means. Our discussion is a starting point for a further
investigation of the market as a rule-based system with an 'algorithmic'
component, despite its apparent randomness, and the use of the theory of
algorithmic probability with new tools that can be applied to the study of the
market price phenomenon. The main discussion is cast in terms of assumptions
common to areas of economics in agreement with an algorithmic view of the
market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1848</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1848</id><created>2010-08-11</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames></author></authors><title>Enhancing QOS and QOE in IMS enabled next generation networks</title><categories>cs.NI</categories><report-no>International journal on applications of graph theory in wireless ad
  hoc networks and sensor networks (GRAPH-HOC) Vol.2, No.2, June 2010</report-no><doi>10.5121/jgraphoc.2010.2206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Managing network complexity, accommodating greater numbers of subscribers,
improving coverage to support data services (e.g. email, video, and music
downloads), keeping up to speed with fast-changing technology, and driving
maximum value from existing networks - all while reducing CapEX and OpEX and
ensuring Quality of Service (QoS) for the network and Quality of Experience
(QoE) for the user. These are just some of the pressing business issues faced
by mobileservice providers, summarized by the demand to &quot;achieve more, for
less.&quot; The ultimate goal of optimization techniques at the network and
application layer is to ensure End-user perceived QoS. The next generation
networks (NGN), a composite environment of proven telecommunications and
Internet-oriented mechanisms have become generally recognized as the
telecommunications environment of the future. However, the nature of the NGN
environment presents several complex issues regarding quality assurance that
have not existed in the legacy environments (e.g., multi-network, multi-vendor,
and multi-operator IP-based telecommunications environment, distributed
intelligence, third-party provisioning, fixed-wireless and mobile access,
etc.). In this Research Paper, a service aware policy-based approach to NGN
quality assurance is presented, taking into account both perceptual quality of
experience and technologydependant quality of service issues. The respective
procedures, entities, mechanisms, and profiles are discussed. The purpose of
the presented approach is in research, development, and discussion of pursuing
the end-to-end controllability of the quality of the multimedia NGN-based
communications in an environment that is best effort in its nature and promotes
end user's access agnosticism, service agility, and global mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1851</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1851</id><created>2010-08-11</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames></author><author><keyname>Jani</keyname><forenames>Dr. N. N.</forenames></author></authors><title>Design and Modeling Billing solution to Next Generation Networks</title><categories>cs.NI</categories><report-no>International Journal of Advanced Networking and Applications
  Volume: 01, Issue: 05, Pages: 290-294 (2010)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next generation networks (NGN) services are assumed to be a new revenue
stream for both network operators and service providers. New services
especially focused on a mobile telecommunications that would be used not only
as a communication de vice but also as a personal gateway to order or consume a
variety of services and products [1]. This type of advanced services can be
accomplished when the adaptability of the packet-networks (Internet) and the
quality of service of the circuit switched networks are combined into one
network [2]. New challenges appear in the billing of this heterogeneous multi
services network. Some examples of such a services and possible solutions about
charging and billing are examined in this paper. The first steps of
mathematical model for billing are also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1865</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1865</id><created>2010-08-11</created><authors><author><keyname>Ben-Shimon</keyname><forenames>Sonny</forenames></author><author><keyname>Ferber</keyname><forenames>Asaf</forenames></author><author><keyname>Hefetz</keyname><forenames>Dan</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author></authors><title>Hitting time results for Maker-Breaker games</title><categories>math.CO cs.DM math.PR</categories><comments>24 pages</comments><journal-ref>Proceedings of the 22nd ACM-SIAM Symposium on Discrete Algorithms
  (SODA'11), 900--912, 2011 and Random Structures and Algorithms, 41(1):23--46,
  2012</journal-ref><doi>10.1002/rsa.20392</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Maker-Breaker games played on the edge set of a random graph.
Specifically, we consider the random graph process and analyze the first time
in a typical random graph process that Maker starts having a winning strategy
for his final graph to admit some property $\mP$. We focus on three natural
properties for Maker's graph, namely being $k$-vertex-connected, admitting a
perfect matching, and being Hamiltonian. We prove the following optimal hitting
time results: with high probability Maker wins the $k$-vertex connectivity game
exactly at the time the random graph process first reaches minimum degree $2k$;
with high probability Maker wins the perfect matching game exactly at the time
the random graph process first reaches minimum degree $2$; with high
probability Maker wins the Hamiltonicity game exactly at the time the random
graph process first reaches minimum degree $4$. The latter two statements
settle conjectures of Stojakovi\'{c} and Szab\'{o}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1900</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1900</id><created>2010-08-11</created><authors><author><keyname>Khajeh-Hosseini</keyname><forenames>Ali</forenames></author><author><keyname>Greenwood</keyname><forenames>David</forenames></author><author><keyname>Smith</keyname><forenames>James W.</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author></authors><title>The Cloud Adoption Toolkit: Supporting Cloud Adoption Decisions in the
  Enterprise</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing promises a radical shift in the provisioning of computing
resource within the enterprise. This paper describes the challenges that
decision makers face when assessing the feasibility of the adoption of cloud
computing in their organisations, and describes our Cloud Adoption Toolkit,
which has been developed to support this process. The toolkit provides a
framework to support decision makers in identifying their concerns, and
matching these concerns to appropriate tools/techniques that can be used to
address them. Cost Modeling is the most mature tool in the toolkit, and this
paper shows its effectiveness by demonstrating how practitioners can use it to
examine the costs of deploying their IT systems on the cloud. The Cost Modeling
tool is evaluated using a case study of an organization that is considering the
migration of some of its IT systems to the cloud. The case study shows that
running systems on the cloud using a traditional &quot;always on&quot; approach can be
less cost effective, and the elastic nature of the cloud has to be used to
reduce costs. Therefore, decision makers have to be able to model the
variations in resource usage and their systems deployment options to obtain
accurate cost estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1902</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1902</id><created>2010-08-11</created><updated>2013-05-02</updated><authors><author><keyname>Sommer</keyname><forenames>Stefan</forenames></author><author><keyname>Lauze</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Nielsen</keyname><forenames>Mads</forenames></author></authors><title>Optimization over Geodesics for Exact Principal Geodesic Analysis</title><categories>cs.CG</categories><comments>Revised version to be published in Advances in Computational
  Mathematics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In fields ranging from computer vision to signal processing and statistics,
increasing computational power allows a move from classical linear models to
models that incorporate non-linear phenomena. This shift has created interest
in computational aspects of differential geometry, and solving optimization
problems that incorporate non-linear geometry constitutes an important
computational task. In this paper, we develop methods for numerically solving
optimization problems over spaces of geodesics using numerical integration of
Jacobi fields and second order derivatives of geodesic families. As an
important application of this optimization strategy, we compute exact Principal
Geodesic Analysis (PGA), a non-linear version of the PCA dimensionality
reduction procedure. By applying the exact PGA algorithm to synthetic data, we
exemplify the differences between the linearized and exact algorithms caused by
the non-linear geometry. In addition, we use the numerically integrated Jacobi
fields to determine sectional curvatures and provide upper bounds for
injectivity radii.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1906</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1906</id><created>2010-08-11</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Soboci&#x144;ski</keyname><forenames>Pawe&#x142;</forenames><affiliation>University of Southampton, United Kingdom</affiliation></author></authors><title>Proceedings Seventh Workshop on Structural Operational Semantics</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 32, 2010</journal-ref><doi>10.4204/EPTCS.32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural operational semantics (SOS) is a technique for defining
operational semantics for programming and specification languages. Because of
its intuitive appeal and flexibility, SOS has found considerable application in
the study of the semantics of concurrent processes. It is also a viable
alternative to denotational semantics in the static analysis of programs and in
proving compiler correctness. Recently it has been applied in emerging areas
such as probabilistic systems and systems biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1954</identifier>
 <datestamp>2012-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1954</id><created>2010-08-11</created><updated>2010-08-20</updated><authors><author><keyname>Touboul</keyname><forenames>Jonathan</forenames></author></authors><title>On the simulation of nonlinear bidimensional spiking neuron models</title><categories>cs.NA math.DS q-bio.NC</categories><doi>10.1162/NECO_a_00141</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bidimensional spiking models currently gather a lot of attention for their
simplicity and their ability to reproduce various spiking patterns of cortical
neurons, and are particularly used for large network simulations. These models
describe the dynamics of the membrane potential by a nonlinear differential
equation that blows up in finite time, coupled to a second equation for
adaptation. Spikes are emitted when the membrane potential blows up or reaches
a cutoff value. The precise simulation of the spike times and of the adaptation
variable is critical for it governs the spike pattern produced, and is hard to
compute accurately because of the exploding nature of the system at the spike
times. We thoroughly study the precision of fixed time-step integration schemes
for this type of models and demonstrate that these methods produce systematic
errors that are unbounded, as the cutoff value is increased, in the evaluation
of the two crucial quantities: the spike time and the value of the adaptation
variable at this time. Precise evaluation of these quantities therefore involve
very small time steps and long simulation times. In order to achieve a fixed
absolute precision in a reasonable computational time, we propose here a new
algorithm to simulate these systems based on a variable integration step method
that either integrates the original ordinary differential equation or the
equation of the orbits in the phase plane, and compare this algorithm with
fixed time-step Euler scheme and other more accurate simulation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1970</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1970</id><created>2010-08-11</created><authors><author><keyname>Hanawal</keyname><forenames>Manjesh Kumar</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>The Shannon Cipher System with a Guessing Wiretapper: General Sources</title><categories>cs.IT math.IT</categories><comments>24 pages, Submitted to IEEE Transactions on Information Theory</comments><report-no>TR-PME-2009-04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shannon cipher system is studied in the context of general sources using
a notion of computational secrecy introduced by Merhav &amp; Arikan. Bounds are
derived on limiting exponents of guessing moments for general sources. The
bounds are shown to be tight for iid, Markov, and unifilar sources, thus
recovering some known results. A close relationship between error exponents and
correct decoding exponents for fixed rate source compression on the one hand
and exponents for guessing moments on the other hand is established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1975</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1975</id><created>2010-08-11</created><updated>2010-11-05</updated><authors><author><keyname>Madry</keyname><forenames>Aleksander</forenames></author></authors><title>Fast Approximation Algorithms for Cut-based Problems in Undirected
  Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general method of designing fast approximation algorithms for
cut-based minimization problems in undirected graphs. In particular, we develop
a technique that given any such problem that can be approximated quickly on
trees, allows approximating it almost as quickly on general graphs while only
losing a poly-logarithmic factor in the approximation guarantee.
  To illustrate the applicability of our paradigm, we focus our attention on
the undirected sparsest cut problem with general demands and the balanced
separator problem. By a simple use of our framework, we obtain poly-logarithmic
approximation algorithms for these problems that run in time close to linear.
  The main tool behind our result is an efficient procedure that decomposes
general graphs into simpler ones while approximately preserving the cut-flow
structure. This decomposition is inspired by the cut-based graph decomposition
of R\&quot;acke that was developed in the context of oblivious routing schemes, as
well as, by the construction of the ultrasparsifiers due to Spielman and Teng
that was employed to preconditioning symmetric diagonally-dominant matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1977</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1977</id><created>2010-08-11</created><authors><author><keyname>Hanawal</keyname><forenames>Manjesh Kumar</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Guessing Revisited: A Large Deviations Approach</title><categories>cs.IT math.IT</categories><comments>16 pages, to appear in IEEE Transaction on Information Theory</comments><report-no>TR-PME-2008-08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of guessing a random string is revisited. A close relation
between guessing and compression is first established. Then it is shown that if
the sequence of distributions of the information spectrum satisfies the large
deviation property with a certain rate function, then the limiting guessing
exponent exists and is a scalar multiple of the Legendre-Fenchel dual of the
rate function. Other sufficient conditions related to certain continuity
properties of the information spectrum are briefly discussed. This approach
highlights the importance of the information spectrum in determining the
limiting guessing exponent. All known prior results are then re-derived as
example applications of our unifying approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.1986</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.1986</id><created>2010-08-11</created><authors><author><keyname>Yatskar</keyname><forenames>Mark</forenames></author><author><keyname>Pang</keyname><forenames>Bo</forenames></author><author><keyname>Danescu-Niculescu-Mizil</keyname><forenames>Cristian</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author></authors><title>For the sake of simplicity: Unsupervised extraction of lexical
  simplifications from Wikipedia</title><categories>cs.CL</categories><comments>4 pp; data available at
  http://www.cs.cornell.edu/home/llee/data/simple/</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of the NAACL, pp. 365-368, 2010. Short paper</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on work in progress on extracting lexical simplifications (e.g.,
&quot;collaborate&quot; -&gt; &quot;work together&quot;), focusing on utilizing edit histories in
Simple English Wikipedia for this task. We consider two main approaches: (1)
deriving simplification probabilities via an edit model that accounts for a
mixture of different operations, and (2) using metadata to focus on edits that
are more likely to be simplification operations. We find our methods to
outperform a reasonable baseline and yield many high-quality lexical
simplifications not included in an independently-created manually prepared
list.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2005</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2005</id><created>2010-08-11</created><updated>2011-11-05</updated><authors><author><keyname>Goyal</keyname><forenames>Amit</forenames></author><author><keyname>Bonchi</keyname><forenames>Francesco</forenames></author><author><keyname>Lakshmanan</keyname><forenames>Laks V. S.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Approximation Analysis of Influence Spread in Social Networks</title><categories>cs.DM cs.CC cs.SI</categories><comments>14 pages - double column, 2 tables, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of influence propagation in a social graph, we can identify
three orthogonal dimensions - the number of seed nodes activated at the
beginning (known as budget), the expected number of activated nodes at the end
of the propagation (known as expected spread or coverage), and the time taken
for the propagation. We can constrain one or two of these and try to optimize
the third. In their seminal paper, Kempe et al. constrained the budget, left
time unconstrained, and maximized the coverage: this problem is known as
Influence Maximization.
  In this paper, we study alternative optimization problems which are naturally
motivated by resource and time constraints on viral marketing campaigns. In the
first problem, termed Minimum Target Set Selection (or MINTSS for short), a
coverage threshold n is given and the task is to find the minimum size seed set
such that by activating it, at least n nodes are eventually activated in the
expected sense. In the second problem, termed MINTIME, a coverage threshold n
and a budget threshold k are given, and the task is to find a seed set of size
at most k such that by activating it, at least n nodes are activated, in the
minimum possible time. Both these problems are NP-hard, which motivates our
interest in their approximation.
  For MINTSS, we develop a simple greedy algorithm and show that it provides a
bicriteria approximation. We also establish a generic hardness result
suggesting that improving it is likely to be hard. For MINTIME, we show that
even bicriteria and tricriteria approximations are hard under several
conditions. However, if we allow the budget to be boosted by a logarithmic
factor and allow the coverage to fall short, then the problem can be solved
exactly in PTIME.
  Finally, we show the value of the approximation algorithms, by comparing them
against various heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2008</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2008</id><created>2010-08-11</created><updated>2011-02-23</updated><authors><author><keyname>Mao</keyname><forenames>Mark Z.</forenames></author><author><keyname>Gray</keyname><forenames>Robert M.</forenames></author><author><keyname>Linder</keyname><forenames>Tamas</forenames></author></authors><title>Rate-Constrained Simulation and Source Coding IID Sources</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory, 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Necessary conditions for asymptotically optimal sliding-block or stationary
codes for source coding and rate-constrained simulation of memoryless sources
are presented and used to motivate a design technique for trellis-encoded
source coding and rate-constrained simulation. The code structure has intuitive
similarities to classic random coding arguments as well as to ``fake process''
methods and alphabet-constrained methods. Experimental evidence shows that the
approach provides comparable or superior performance in comparison with
previously published methods on common examples, sometimes by significant
margins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2021</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2021</id><created>2010-08-11</created><authors><author><keyname>Een</keyname><forenames>Niklas</forenames></author><author><keyname>Mishchenko</keyname><forenames>Alan</forenames></author><author><keyname>Amla</keyname><forenames>Nina</forenames></author></authors><title>A Single-Instance Incremental SAT Formulation of Proof- and
  Counterexample-Based Abstraction</title><categories>cs.LO</categories><comments>Accepted for FMCAD 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient, combined formulation of two widely used
abstraction methods for bit-level verification: counterexample-based
abstraction (CBA) and proof-based abstraction (PBA). Unlike previous work, this
new method is formulated as a single, incremental SAT-problem, interleaving CBA
and PBA to develop the abstraction in a bottom-up fashion. It is argued that
the new method is simpler conceptually and implementation-wise than previous
approaches. As an added bonus, proof-logging is not required for the PBA part,
which allows for a wider set of SAT-solvers to be used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2028</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2028</id><created>2010-08-11</created><authors><author><keyname>Saria</keyname><forenames>Suchi</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author><author><keyname>Penn</keyname><forenames>Anna</forenames></author></authors><title>Discovering shared and individual latent structure in multiple time
  series</title><categories>stat.ML cs.AI stat.ME</categories><comments>Additional supplementary section in tex file</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a nonparametric Bayesian method for exploratory data
analysis and feature construction in continuous time series. Our method focuses
on understanding shared features in a set of time series that exhibit
significant individual variability. Our method builds on the framework of
latent Diricihlet allocation (LDA) and its extension to hierarchical Dirichlet
processes, which allows us to characterize each series as switching between
latent ``topics'', where each topic is characterized as a distribution over
``words'' that specify the series dynamics. However, unlike standard
applications of LDA, we discover the words as we learn the model. We apply this
model to the task of tracking the physiological signals of premature infants;
our model obtains clinically significant insights as well as useful features
for supervised learning tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2036</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2036</id><created>2010-08-11</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames></author></authors><title>Providing content based billing architecture over Next Generation
  Network</title><categories>cs.NI</categories><journal-ref>International Journal on Computer Engineering &amp; Information
  Technology March - May 2009, pp 118-124</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Communication marketplace has stressed that &quot;content is king&quot; ever
since the initial footsteps for Next Generation Networks like 3G, 3GPP, IP
Multimedia subsystem (IMS) services. However, many carriers and content
providers have struggled to drive revenue for content services, primarily due
to current limitations of certain types of desirable content offerings,
simplistic billing models, and the inability to support flexible pricing,
charging and settlement. Unlike wire line carriers, wireless carriers have a
limit to the volume of traffic they can carry, bounded by the finite wireless
spectrum. Event based services like calling, conferencing etc., only perceive
charge per event, while the Content based charging system attracts Mobile
Network Operators (MNOs) to maximize service delivery to customer and achieve
best ARPU. With the Next Generation Networks, the number of data related
services that can be offered, is increased significantly. The wireless carrier
will be able to move from offering wireless telecommunications services to
offering wireless telecommunication services plus a number of personalized
Value Added Services like news, games, video broadcasts, or multimedia
messaging service (MMS) through the network. The next generation Content Based
Billing systems allow the operators to maximize their revenues from such
services. These systems will enable operators to offer and bill for
application-based and content-based services, rather than for just bytes of
data. Therefore, the wireless business focus is no longer on infrastructure
build-outs but on customer retention and increased average revenue per customer
(ARPU). The mobile operator generates new revenues, strengthens brand value,
and differentiates its service to attract and retain customers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2063</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2063</id><created>2010-08-12</created><authors><author><keyname>Parand</keyname><forenames>K.</forenames></author><author><keyname>Dehghan</keyname><forenames>Mehdi</forenames></author><author><keyname>Rezaei</keyname><forenames>A. R.</forenames></author><author><keyname>Ghaderi</keyname><forenames>S. M.</forenames></author></authors><title>An approximation algorithm for the solution of the nonlinear Lane-Emden
  type equations arising in astrophysics using Hermite functions collocation
  method</title><categories>math-ph astro-ph.IM cs.NA math.MP math.NA</categories><comments>34 pages, 13 figures, Published in &quot;Computer Physics Communications&quot;</comments><msc-class>85-08, 74S25, 42C10</msc-class><journal-ref>Comput.Phys.Commun.181:1096-1108,2010</journal-ref><doi>10.1016/j.cpc.2010.02.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a collocation method for solving some well-known
classes of Lane-Emden type equations which are nonlinear ordinary differential
equations on the semi-infinite domain. They are categorized as singular initial
value problems. The proposed approach is based on a Hermite function
collocation (HFC) method. To illustrate the reliability of the method, some
special cases of the equations are solved as test examples. The new method
reduces the solution of a problem to the solution of a system of algebraic
equations. Hermite functions have prefect properties that make them useful to
achieve this goal. We compare the present work with some well-known results and
show that the new method is efficient and applicable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2066</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2066</id><created>2010-08-12</created><authors><author><keyname>Kostal</keyname><forenames>Lubomir</forenames></author><author><keyname>Lansky</keyname><forenames>Petr</forenames></author></authors><title>Information transfer with small-amplitude signals</title><categories>q-bio.NC cs.IT math.IT</categories><comments>5 pages, 1 figure; published in Physical Review E; this version
  improves Fig.1</comments><journal-ref>Phys. Rev. E 81, 050901(R) (2010)</journal-ref><doi>10.1103/PhysRevE.81.050901</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimality conditions of information transfer in systems with
memory in the low signal-to-noise ratio regime of vanishing input amplitude. We
find that the optimal mutual information is represented by a maximum-variance
of the signal time course, with correlation structure determined by the Fisher
information matrix. We provide illustration of the method on a simple
biologically-inspired model of electro-sensory neuron. Our general results
apply also to the study of information transfer in single neurons subject to
weak stimulation, with implications to the problem of coding efficiency in
biological systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2069</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2069</id><created>2010-08-12</created><authors><author><keyname>Kostal</keyname><forenames>Lubomir</forenames></author></authors><title>Information capacity in the weak-signal approximation</title><categories>cs.IT math.IT q-bio.NC</categories><comments>11 pages, 4 figures; accepted for publication in Physical Review E</comments><doi>10.1103/PhysRevE.82.026115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive an approximate expression for mutual information in a broad class
of discrete-time stationary channels with continuous input, under the
constraint of vanishing input amplitude or power. The approximation describes
the input by its covariance matrix, while the channel properties are described
by the Fisher information matrix. This separation of input and channel
properties allows us to analyze the optimality conditions in a convenient way.
We show that input correlations in memoryless channels do not affect channel
capacity since their effect decreases fast with vanishing input amplitude or
power. On the other hand, for channels with memory, properly matching the input
covariances to the dependence structure of the noise may lead to almost
noiseless information transfer, even for intermediate values of the noise
correlations. Since many model systems described in mathematical neuroscience
and biophysics operate in the high noise regime and weak-signal conditions, we
believe, that the described results are of potential interest also to
researchers in these areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2081</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2081</id><created>2010-08-12</created><updated>2011-09-07</updated><authors><author><keyname>Lapus</keyname><forenames>Raymond</forenames><affiliation>De La Salle University, Manila, Philippines</affiliation><affiliation>Mittweida University of Applied Sciences, Mittweida, Germany</affiliation></author><author><keyname>Simon</keyname><forenames>Frank</forenames><affiliation>Mittweida University of Applied Sciences, Mittweida, Germany</affiliation></author><author><keyname>Tittmann</keyname><forenames>Peter</forenames><affiliation>Mittweida University of Applied Sciences, Mittweida, Germany</affiliation></author></authors><title>Random Information Spread in Networks</title><categories>math.CO cs.DM cs.SI math.PR</categories><comments>17 pages, 1 figure</comments><msc-class>60J05 (Primary), 05C81 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E) be an undirected loopless graph with possible parallel edges and
s and t be two vertices of G. Assume that vertex s is labelled at the initial
time step and that every labelled vertex copies its labelling to neighbouring
vertices along edges with one labelled endpoint independently with probability
p in one time step. In this paper, we establish the equivalence between the
expected s-t first arrival time of the above spread process and the notion of
the stochastic shortest s-t path. Moreover, we give a short discussion of
analytical results on special graphs including the complete graph and s-t
series-parallel graphs. Finally, we propose some lower bounds for the expected
s-t first arrival time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2093</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2093</id><created>2010-08-12</created><authors><author><keyname>Fischer</keyname><forenames>Robert F. H.</forenames></author></authors><title>Notes on Lattice-Reduction-Aided MMSE Equalization</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last years, novel low-complexity approaches to the equalization of
MIMO channels have gained much attention. Thereby, methods based on lattice
basis reduction are of special interest, as they achieve the optimum diversity
order. In this paper, a tutorial overview on LRA equalization optimized
according to the MMSE criterion is given. It is proven that applying the
zero-forcing BLAST algorithm to a suitably augmented channel matrix (the
inverse of the square root of the correlation matrix of the data symbols times
the noise variance forms its lower part) results in the optimum solution. This
fact is already widely used but lacks a formal proof. It turns out that it is
more important to take the correlations of the data correctly into account than
what type of lattice reduction actually is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2108</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2108</id><created>2010-08-12</created><authors><author><keyname>F&#xe1;bregas</keyname><forenames>Ignacio</forenames><affiliation>Universidad Complutense de Madrid, Spain</affiliation></author><author><keyname>Escrig</keyname><forenames>David de Frutos</forenames><affiliation>Universidad Complutense de Madrid, Spain</affiliation></author><author><keyname>Palomino</keyname><forenames>Miguel</forenames><affiliation>Universidad Complutense de Madrid, Spain</affiliation></author></authors><title>Equational Characterization of Covariant-Contravariant Simulation and
  Conformance Simulation Semantics</title><categories>cs.LO cs.PL</categories><comments>In Proceedings SOS 2010, arXiv:1008.1906</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 32, 2010, pp. 1-14</journal-ref><doi>10.4204/EPTCS.32.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Covariant-contravariant simulation and conformance simulation generalize
plain simulation and try to capture the fact that it is not always the case
that &quot;the larger the number of behaviors, the better&quot;. We have previously
studied their logical characterizations and in this paper we present the
axiomatizations of the preorders defined by the new simulation relations and
their induced equivalences. The interest of our results lies in the fact that
the axiomatizations help us to know the new simulations better, understanding
in particular the role of the contravariant characteristics and their interplay
with the covariant ones; moreover, the axiomatizations provide us with a
powerful tool to (algebraically) prove results of the corresponding semantics.
But we also consider our results interesting from a metatheoretical point of
view: the fact that the covariant-contravariant simulation equivalence is
indeed ground axiomatizable when there is no action that exhibits both a
covariant and a contravariant behaviour, but becomes non-axiomatizable whenever
we have together actions of that kind and either covariant or contravariant
actions, offers us a new subtle example of the narrow border separating
axiomatizable and non-axiomatizable semantics. We expect that by studying these
examples we will be able to develop a general theory separating axiomatizable
and non-axiomatizable semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2109</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2109</id><created>2010-08-12</created><authors><author><keyname>Gazda</keyname><forenames>Maciej</forenames><affiliation>Vrije Universiteit, Amsterdam, Netherlands</affiliation></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames><affiliation>Vrije Universiteit, Amsterdam, Netherlands</affiliation></author></authors><title>Congruence from the Operator's Point of View: Compositionality
  Requirements on Process Semantics</title><categories>cs.LO</categories><comments>In Proceedings SOS 2010, arXiv:1008.1906</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 32, 2010, pp. 15-25</journal-ref><doi>10.4204/EPTCS.32.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the basic sanity properties of a behavioural semantics is that it
constitutes a congruence with respect to standard process operators. This issue
has been traditionally addressed by the development of rule formats for
transition system specifications that define process algebras. In this paper we
suggest a novel, orthogonal approach. Namely, we focus on a number of process
operators, and for each of them attempt to find the widest possible class of
congruences. To this end, we impose restrictions on sublanguages of
Hennessy-Milner logic, so that a semantics whose modal characterization
satisfies a given criterion is guaranteed to be a congruence with respect to
the operator in question. We investigate action prefix, alternative
composition, two restriction operators, and parallel composition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2110</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2110</id><created>2010-08-12</created><authors><author><keyname>Beohar</keyname><forenames>H.</forenames><affiliation>Eindhoven University of Technology, Netherlands</affiliation></author><author><keyname>Agut</keyname><forenames>D. E. Nadales</forenames><affiliation>Eindhoven University of Technology, Netherlands</affiliation></author><author><keyname>van Beek</keyname><forenames>D. A.</forenames><affiliation>Eindhoven University of Technology, Netherlands</affiliation></author><author><keyname>Cuijpers</keyname><forenames>P. J. L.</forenames><affiliation>Eindhoven University of Technology, Netherlands</affiliation></author></authors><title>Hierarchical states in the Compositional Interchange Format</title><categories>cs.LO cs.FL</categories><comments>In Proceedings SOS 2010, arXiv:1008.1906</comments><proxy>EPTCS</proxy><acm-class>F.3.2; F.4.3;</acm-class><journal-ref>EPTCS 32, 2010, pp. 42-56</journal-ref><doi>10.4204/EPTCS.32.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CIF is a language designed for two purposes, namely as a specification
language for hybrid systems and as an interchange format for allowing model
transformations between other languages for hybrid systems. To facilitate the
top-down development of a hybrid system and also to be able to express models
more succinctly in the CIF formalism, we need a mechanism for stepwise
refinement. In this paper, we add the notion of hierarchy to a subset of the
CIF language, which we call hCIF. The semantic domain of the CIF formalism is a
hybrid transition system, constructed using structural operational semantics.
The goal of this paper is to present a semantics for hierarchy in such a way
that only the SOS rules for atomic entities in hCIF are redesigned in
comparison to CIF. Furthermore, to be able to reuse existing tools like
simulators of the CIF language, a procedure to eliminate hierarchy from an
automaton is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2111</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2111</id><created>2010-08-12</created><authors><author><keyname>Heindel</keyname><forenames>Tobias</forenames><affiliation>Universt&#xe4;t Duisburg-Essen, Germany</affiliation></author></authors><title>Structural Decomposition of Reactions of Graph-Like Objects</title><categories>cs.LO</categories><comments>In Proceedings SOS 2010, arXiv:1008.1906</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 32, 2010, pp. 26-41</journal-ref><doi>10.4204/EPTCS.32.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by decomposition problems in rule-based formalisms in Computational
Systems Biology and recent work on compositionality in graph transformation,
this paper proposes to use arbitrary colimits to &quot;deconstruct&quot; models of
reactions in which states are represented as objects of adhesive categories.
The fundamental problem is the decomposition of complex reactions of large
states into simpler reactions of smaller states.
  The paper defines the local decomposition problem for transformations. To
solve this problem means to &quot;reconstruct&quot; a given transformation as the colimit
of &quot;smaller&quot; ones where the shape of the colimit and the decomposition of the
source object of the transformation are fixed in advance. The first result is
the soundness of colimit decomposition for arbitrary double pushout
transformations in any category, which roughly means that several &quot;local&quot;
transformations can be combined into a single &quot;global&quot; one. Moreover, a
solution for a certain class of local decomposition problems is given, which
generalizes and clarifies recent work on compositionality in graph
transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2112</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2112</id><created>2010-08-12</created><authors><author><keyname>Nakata</keyname><forenames>Keiko</forenames><affiliation>Institute of Cybernetics, Tallinn University of Technology, Estonia</affiliation></author><author><keyname>Uustalu</keyname><forenames>Tarmo</forenames><affiliation>Institute of Cybernetics, Tallinn University of Technology, Estonia</affiliation></author></authors><title>Resumptions, Weak Bisimilarity and Big-Step Semantics for While with
  Interactive I/O: An Exercise in Mixed Induction-Coinduction</title><categories>cs.LO cs.PL</categories><comments>In Proceedings SOS 2010, arXiv:1008.1906</comments><proxy>EPTCS</proxy><acm-class>F.3.2; F.1.2</acm-class><journal-ref>EPTCS 32, 2010, pp. 57-75</journal-ref><doi>10.4204/EPTCS.32.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We look at the operational semantics of languages with interactive I/O
through the glasses of constructive type theory. Following on from our earlier
work on coinductive trace-based semantics for While, we define several big-step
semantics for While with interactive I/O, based on resumptions and
termination-sensitive weak bisimilarity. These require nesting inductive
definitions in coinductive definitions, which is interesting both
mathematically and from the point-of-view of implementation in a proof
assistant.
  After first defining a basic semantics of statements in terms of resumptions
with explicit internal actions (delays), we introduce a semantics in terms of
delay-free resumptions that essentially removes finite sequences of delays on
the fly from those resumptions that are responsive. Finally, we also look at a
semantics in terms of delay-free resumptions supplemented with a silent
divergence option. This semantics hinges on decisions between convergence and
divergence and is only equivalent to the basic one classically.
  We have fully formalized our development in Coq.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2121</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2121</id><created>2010-08-12</created><updated>2011-07-08</updated><authors><author><keyname>Wittocx</keyname><forenames>Johan</forenames></author><author><keyname>Denecker</keyname><forenames>Marc</forenames></author><author><keyname>Bruynooghe</keyname><forenames>Maurice</forenames></author></authors><title>Constraint Propagation for First-Order Logic and Inductive Definitions</title><categories>cs.LO cs.AI</categories><comments>43 pages, 1 figure submitted to ACM Transactions on Computational
  Logic</comments><acm-class>I.2.4; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint propagation is one of the basic forms of inference in many
logic-based reasoning systems. In this paper, we investigate constraint
propagation for first-order logic (FO), a suitable language to express a wide
variety of constraints. We present an algorithm with polynomial-time data
complexity for constraint propagation in the context of an FO theory and a
finite structure. We show that constraint propagation in this manner can be
represented by a datalog program and that the algorithm can be executed
symbolically, i.e., independently of a structure. Next, we extend the algorithm
to FO(ID), the extension of FO with inductive definitions. Finally, we discuss
several applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2122</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2122</id><created>2010-08-12</created><authors><author><keyname>Ye</keyname><forenames>Chunxuan</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author></authors><title>Secret Key and Private Key Constructions for Simple Multiterminal Source
  Models</title><categories>cs.IT cs.CR math.IT</categories><comments>12 pages; 2 figures; The material in this paper was presented in part
  at the IEEE International Symposium on Information Theory, Adelaide,
  Australia, Sept. 2005, and at the Information Theory and Applications
  Workshop, San Diego, CA, Feb. 2006</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose an approach for constructing secret and private keys based on the
long-known Slepian-Wolf code, due to Wyner, for correlated sources connected by
a virtual additive noise channel. Our work is motivated by results of Csisz\'ar
and Narayan which highlight innate connections between secrecy generation by
multiple terminals that observe correlated source signals and Slepian-Wolf
near-lossless data compression. Explicit procedures for such constructions and
their substantiation are provided. The performance of low density parity check
channel codes in devising a new class of secret keys is examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2136</identifier>
 <datestamp>2010-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2136</id><created>2010-08-12</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Shepherd</keyname><forenames>F. Bruce</forenames></author><author><keyname>Weibel</keyname><forenames>Christophe</forenames></author></authors><title>Flow-Cut Gaps for Integer and Fractional Multiflows</title><categories>cs.DM cs.DS</categories><comments>24 pages, 10 figures. Results presented first at the Symposium on
  Discrete Algorithms (SoDA 2010)</comments><msc-class>05C21</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a routing problem consisting of a demand graph H and a supply graph
G. If the pair obeys the cut condition, then the flow-cut gap for this instance
is the minimum value C such that there is a feasible multiflow for H if each
edge of G is given capacity C. The flow-cut gap can be greater than 1 even when
G is the (series-parallel) graph K_{2,3}. In this paper we are primarily
interested in the &quot;integer&quot; flow-cut gap. What is the minimum value C such that
there is a feasible integer valued multiflow for H if each edge of G is given
capacity C? We conjecture that the integer flow-cut gap is quantitatively
related to the fractional flow-cut gap. This strengthens the well-known
conjecture that the flow-cut gap in planar and minor-free graphs is O(1) to
suggest that the integer flow-cut gap is O(1). We give several results on
non-trivial special classes of graphs supporting this conjecture and further
explore the &quot;primal&quot; method for understanding flow-cut gaps. Our results
include:
  - Let G be obtained by series-parallel operations starting from an edge st,
and consider orienting all edges in G in the direction from s to t. A demand is
compliant if its endpoints are joined by a directed path in the resulting
oriented graph. If the cut condition holds for a compliant instance and G+H is
Eulerian, then an integral routing of H exists.
  - The integer flow-cut gap in series-parallel graphs is 5. We also give an
explicit class of instances that shows via elementary calculations that the
flow-cut gap in series-parallel graphs is at least 2-o(1); this simplifies the
proof by Lee and Raghavendra.
  - The integer flow-cut gap in k-Outerplanar graphs is c^{O(k)} for some fixed
constant c.
  - A simple proof that the flow-cut gap is O(\log k^*) where k^* is the size
of a node-cover in H; this was previously shown by G\&quot;unl\&quot;uk via a more
intricate proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2147</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2147</id><created>2010-08-12</created><updated>2011-07-14</updated><authors><author><keyname>Kent</keyname><forenames>Adrian</forenames><affiliation>Centre for Quantum Information and Foundations, DAMTP, University of Cambridge and Perimeter Institute</affiliation></author><author><keyname>Munro</keyname><forenames>William J.</forenames><affiliation>NTT Basic Research Laboratories</affiliation></author><author><keyname>Spiller</keyname><forenames>Timothy P.</forenames><affiliation>Quantum Information Science, School of Physics and Astronomy, University of Leeds</affiliation></author></authors><title>Quantum Tagging: Authenticating Location via Quantum Information and
  Relativistic Signalling Constraints</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>Minor update re subsequent refs; typos fixed. To appear in Phys. Rev.
  A</comments><journal-ref>Phys. Rev. A 84, 012326 (2011)</journal-ref><doi>10.1103/PhysRevA.84.012326</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the task of {\it quantum tagging}, that is, authenticating the
classical location of a classical tagging device by sending and receiving
quantum signals from suitably located distant sites, in an environment
controlled by an adversary whose quantum information processing and
transmitting power is unbounded. We define simple security models for this task
and briefly discuss alternatives.
  We illustrate the pitfalls of naive quantum cryptographic reasoning in this
context by describing several protocols which at first sight appear
unconditionally secure but which, as we show, can in fact be broken by
teleportation-based attacks. We also describe some protocols which cannot be
broken by these specific attacks, but do not prove they are unconditionally
secure.
  We review the history of quantum tagging protocols, which we first discussed
in 2002 and described in a 2006 patent (for an insecure protocol). The
possibility has recently been reconsidered by other authors. All the more
recently discussed protocols of which we are aware were either previously
considered by us in 2002-3 or are variants of schemes then considered, and all
are provably insecure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2159</identifier>
 <datestamp>2012-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2159</id><created>2010-08-12</created><updated>2012-08-21</updated><authors><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Harvey</keyname><forenames>Nicholas J. A.</forenames></author></authors><title>Submodular Functions: Learnability, Structure, and Optimization</title><categories>cs.DS cs.DM cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Submodular functions are discrete functions that model laws of diminishing
returns and enjoy numerous algorithmic applications. They have been used in
many areas, including combinatorial optimization, machine learning, and
economics. In this work we study submodular functions from a learning theoretic
angle. We provide algorithms for learning submodular functions, as well as
lower bounds on their learnability. In doing so, we uncover several novel
structural results revealing ways in which submodular functions can be both
surprisingly structured and surprisingly unstructured. We provide several
concrete implications of our work in other domains including algorithmic game
theory and combinatorial optimization.
  At a technical level, this research combines ideas from many areas, including
learning theory (distributional learning and PAC-style analyses), combinatorics
and optimization (matroids and submodular functions), and pseudorandomness
(lossless expander graphs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2160</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2160</id><created>2010-08-12</created><authors><author><keyname>Harding</keyname><forenames>Peter J.</forenames></author><author><keyname>Gwynne</keyname><forenames>Steve M. V.</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author></authors><title>An early warning method for crush</title><categories>cs.MA</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fatal crush conditions occur in crowds with tragic frequency. Event
organisers and architects are often criticised for failing to consider the
causes and implications of crush, but the reality is that the prediction and
mitigation of such conditions offers a significant technical challenge. Full
treatment of physical force within crowd simulations is precise but
computationally expensive; the more common method of human interpretation of
results is computationally &quot;cheap&quot; but subjective and time-consuming. In this
paper we propose an alternative method for the analysis of crowd behaviour,
which uses information theory to measure crowd disorder. We show how this
technique may be easily incorporated into an existing simulation framework, and
validate it against an historical event. Our results show that this method
offers an effective and efficient route towards automatic detection of crush.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2170</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2170</id><created>2010-08-12</created><updated>2010-08-15</updated><authors><author><keyname>Rosgen</keyname><forenames>Bill</forenames></author><author><keyname>Stewart</keyname><forenames>Lorna</forenames></author></authors><title>The overlap number of a graph</title><categories>cs.DM</categories><comments>20 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An overlap representation is an assignment of sets to the vertices of a graph
in such a way that two vertices are adjacent if and only if the sets assigned
to them overlap. The overlap number of a graph is the minimum number of
elements needed to form such a representation. We find the overlap numbers of
cliques and complete bipartite graphs by relating the problem to previous
research in combinatorics. The overlap numbers of paths, cycles, and
caterpillars are also established. Finally, we show the NP-completeness of the
problems of extending an overlap representation and finding a minimum overlap
representation with limited containment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2181</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2181</id><created>2010-08-12</created><authors><author><keyname>Zinoviev</keyname><forenames>Dmitry</forenames></author><author><keyname>Duong</keyname><forenames>Vy</forenames></author></authors><title>A Game Theoretical Approach to Modeling Full-Duplex Information
  Dissemination</title><categories>cs.GT</categories><comments>6 pages, 3 figures. Presented at Summer Computer Simulation
  Conference (SCSC2010)</comments><journal-ref>Proc. SCSC2010, pp.358-363</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One major function of social networks (e.g., massive online social networks)
is the dissemination of information such as scientific knowledge, news, and
rumors. Information can be propagated by the users of the network via natural
connections in written, oral or electronic form. The information passing from a
sender to a receiver intrinsically involves both of them considering their
self-perceived knowledge, reputation, and popularity, which further determine
their decisions of whether or not to forward the information and whether or not
to provide feedback. To understand such human aspects of the information
dissemination, we propose a game theoretical model of the two-way full duplex
information forwarding and feedback mechanisms in a social network that take
into account the personalities of the communicating actors (including their
perceived knowledgeability, reputation, and desire for popularity) and the
global characteristics of the network. The model demonstrates how the emergence
of social networks can be explained in terms of maximizing game theoretical
utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2186</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2186</id><created>2010-08-12</created><authors><author><keyname>Goasdou&#xe9;</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LRI</affiliation></author><author><keyname>Karanasos</keyname><forenames>Konstantinos</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Leblay</keyname><forenames>Julien</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Manolescu</keyname><forenames>Ioana</forenames><affiliation>LRI, INRIA Saclay - Ile de France</affiliation></author></authors><title>RDFViewS: A Storage Tuning Wizard for RDF Applications</title><categories>cs.DB cs.AI</categories><proxy>ccsd</proxy><journal-ref>ACM International Conference on Information and Knowledge
  Management, Toronto : Canada (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the significant growth of RDF data used in numerous
applications has made its efficient and scalable manipulation an important
issue. In this paper, we present RDFViewS, a system capable of choosing the
most suitable views to materialize, in order to minimize the query response
time for a specific SPARQL query workload, while taking into account the view
maintenance cost and storage space constraints. Our system employs practical
algorithms and heuristics to navigate through the search space of potential
view configurations, and exploits the possibly available semantic information -
expressed via an RDF Schema - to ensure the completeness of the query
evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2205</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2205</id><created>2010-08-12</created><updated>2010-11-08</updated><authors><author><keyname>Gazis</keyname><forenames>P. R.</forenames><affiliation>Seti</affiliation></author><author><keyname>Levit</keyname><forenames>C.</forenames><affiliation>NASA/Ames</affiliation></author><author><keyname>Way</keyname><forenames>M. J.</forenames><affiliation>NASA/GISS</affiliation></author></authors><title>Viewpoints: A high-performance high-dimensional exploratory data
  analysis tool</title><categories>astro-ph.IM cs.GR physics.data-an</categories><comments>18 pages, 3 figures, PASP in press, this version corresponds more
  closely to that to be published</comments><doi>10.1086/657902</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Scientific data sets continue to increase in both size and complexity. In the
past, dedicated graphics systems at supercomputing centers were required to
visualize large data sets, but as the price of commodity graphics hardware has
dropped and its capability has increased, it is now possible, in principle, to
view large complex data sets on a single workstation. To do this in practice,
an investigator will need software that is written to take advantage of the
relevant graphics hardware. The Viewpoints visualization package described
herein is an example of such software. Viewpoints is an interactive tool for
exploratory visual analysis of large, high-dimensional (multivariate) data. It
leverages the capabilities of modern graphics boards (GPUs) to run on a single
workstation or laptop. Viewpoints is minimalist: it attempts to do a small set
of useful things very well (or at least very quickly) in comparison with
similar packages today. Its basic feature set includes linked scatter plots
with brushing, dynamic histograms, normalization and outlier detection/removal.
Viewpoints was originally designed for astrophysicists, but it has since been
used in a variety of fields that range from astronomy, quantum chemistry, fluid
dynamics, machine learning, bioinformatics, and finance to information
technology server log mining. In this article, we describe the Viewpoints
package and show examples of its usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2223</identifier>
 <datestamp>2010-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2223</id><created>2010-08-12</created><authors><author><keyname>Suciu</keyname><forenames>Alin</forenames></author><author><keyname>Carean</keyname><forenames>Tudor</forenames></author></authors><title>Benchmarking the True Random Number Generator of TPM Chips</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A TPM (trusted platform module) is a chip present mostly on newer
motherboards, and its primary function is to create, store and work with
cryptographic keys. This dedicated chip can serve to authenticate other devices
or to protect encryption keys used by various software applications. Among
other features, it comes with a True Random Number Generator (TRNG) that can be
used for cryptographic purposes. This random number generator consists of a
state machine that mixes unpredictable data with the output of a one way hash
function. According the specification it can be a good source of unpredictable
random numbers even without having to require a genuine source of hardware
entropy. However the specification recommends collecting entropy from any
internal sources available such as clock jitter or thermal noise in the chip
itself, a feature that was implemented by most manufacturers. This paper will
benchmark the random number generator of several TPM chips from two
perspectives: the quality of the random bit sequences generated, as well as the
output bit rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2247</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2247</id><created>2010-08-12</created><updated>2010-09-23</updated><authors><author><keyname>Kobayashi</keyname><forenames>Koji</forenames></author></authors><title>Symmetry and Uncountability of Computation</title><categories>cs.CC cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper talk about the complexity of computation by Turing Machine. I take
attention to the relation of symmetry and order structure of the data, and I
think about the limitation of computation time. First, I make general problem
named &quot;testing problem&quot;. And I get some condition of the P complete and NP
complete by using testing problem. Second, I make two problem &quot;orderly problem&quot;
and &quot;chaotic problem&quot;. Orderly problem have some order structure. And DTM can
limit some possible symbol effectly by using symmetry of each symbol. But
chaotic problem must treat some symbol as a set of symbol, so DTM cannot limit
some possible symbol. Orderly problem is P complete, and chaotic problem is NP
complete. Finally, I clear the computation time of orderly problem and chaotic
problem. And P != NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2249</identifier>
 <datestamp>2010-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2249</id><created>2010-08-13</created><authors><author><keyname>BK</keyname><forenames>Pradeepa</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>A Novel Association Policy for Web Browsing in a Multirate WLAN</title><categories>cs.NI</categories><comments>9 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain an association policy for STAs in an IEEE 802.11 WLAN by taking
into account explicitly two aspects of practical importance: (a) TCP-controlled
short file downloads interspersed with read times (motivated by web browsing),
and (b) different STAs associated with an AP at possibly different rates
(depending on distance from the AP). Our approach is based on two steps. First,
we consider an analytical model to obtain the aggregate AP throughput for long
TCP-controlled file downloads when STAs are associated at k different rates r1,
r2, : : :, rk; this extends earlier work in the literature. Second, we present
a 2-node closed queueing network model to approximate the expected
average-sized file download time for a user who shares the AP with other users
associated at a multiplicity of rates. These analytical results motivate the
proposed association policy, called the Estimated Delay based Association (EDA)
policy: Associate with the AP at which the expected file download time is the
least. Simulations indicate that for a web-browsing type traffic scenario, EDA
outperforms other policies that have been proposed earlier; the extent of
improvement ranges from 12.8% to 46.4% for a 9-AP network. To the best of our
knowledge, this is the first work that proposes an association policy tailored
specifically for web browsing. Apart from this, our analytical results could be
of independent interest
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2266</identifier>
 <datestamp>2010-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2266</id><created>2010-08-13</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Achievable Rates and Upper bounds for the Interference Relay Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, to appear in proceedings of Asilomar Conference
  on Signals, Systems, and Computers 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two user Gaussian interference channel with a full-duplex relay is
studied. By using genie aided approaches, two new upper bounds on the
achievable sum-rate in this setup are derived. These upper bounds are shown to
be tighter than previously known bounds under some conditions. Moreover, a
transmit strategy for this setup is proposed. This strategy utilizes the
following elements: Block Markov encoding combined with a Han-Kobayashi scheme
at the sources, decode and forward at the relay, and Willems' backward decoding
at the receivers. This scheme is shown to achieve within a finite gap our upper
bounds in certain cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2267</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2267</id><created>2010-08-13</created><updated>2010-10-21</updated><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Caron</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Kesidis</keyname><forenames>George</forenames></author></authors><title>Application Neutrality and a Paradox of Side Payments</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ongoing debate over net neutrality covers a broad set of issues related
to the regulation of public networks. In two ways, we extend an idealized
usage-priced game-theoretic framework based on a common linear demand-response
model. First, we study the impact of &quot;side payments&quot; among a plurality of
Internet service (access) providers and content providers. In the
non-monopolistic case, our analysis reveals an interesting &quot;paradox&quot; of side
payments in that overall revenues are reduced for those that receive them.
Second, assuming different application types (e.g., HTTP web traffic,
peer-to-peer file sharing, media streaming, interactive VoIP), we extend this
model to accommodate differential pricing among them in order to study the
issue of application neutrality. Revenues for neutral and non-neutral pricing
are compared for the case of two application types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2277</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2277</id><created>2010-08-13</created><authors><author><keyname>Pe&#xf1;a</keyname><forenames>Jose M.</forenames></author></authors><title>Faithfulness in Chain Graphs: The Gaussian Case</title><categories>stat.ML cs.AI math.ST stat.TH</categories><msc-class>62H05, 60E05, 68T30</msc-class><journal-ref>Proceedings of the 14th International Conference on Artificial
  Intelligence and Statistics (AISTATS 2011), 588-599</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with chain graphs under the classic
Lauritzen-Wermuth-Frydenberg interpretation. We prove that the regular Gaussian
distributions that factorize with respect to a chain graph $G$ with $d$
parameters have positive Lebesgue measure with respect to $\mathbb{R}^d$,
whereas those that factorize with respect to $G$ but are not faithful to it
have zero Lebesgue measure with respect to $\mathbb{R}^d$. This means that, in
the measure-theoretic sense described, almost all the regular Gaussian
distributions that factorize with respect to $G$ are faithful to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2297</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2297</id><created>2010-08-13</created><authors><author><keyname>Nam</keyname><forenames>Sung Sik</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Yang</keyname><forenames>Hong-Chuan</forenames></author></authors><title>An MGF-based Unified Framework to Determine the Joint Statistics of
  Partial Sums of Ordered Random Variables</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Order statistics find applications in various areas of communications and
signal processing. In this paper, we introduce an unified analytical framework
to determine the joint statistics of partial sums of ordered random variables
(RVs). With the proposed approach, we can systematically derive the joint
statistics of any partial sums of ordered statistics, in terms of the moment
generating function (MGF) and the probability density function (PDF). Our
MGF-based approach applies not only when all the K ordered RVs are involved but
also when only the Ks (Ks &lt; K) best RVs are considered. In addition, we present
the closed-form expressions for the exponential RV special case. These results
apply to the performance analysis of various wireless communication systems
over fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2300</identifier>
 <datestamp>2010-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2300</id><created>2010-08-13</created><authors><author><keyname>Bernecker</keyname><forenames>Thomas</forenames></author><author><keyname>Kriegel</keyname><forenames>Hans-Peter</forenames></author><author><keyname>Renz</keyname><forenames>Matthias</forenames></author><author><keyname>Verhein</keyname><forenames>Florian</forenames></author><author><keyname>Z&#xfc;fle</keyname><forenames>Andreas</forenames></author></authors><title>Probabilistic Frequent Pattern Growth for Itemset Mining in Uncertain
  Databases (Technical Report)</title><categories>cs.DB</categories><comments>Technical Report, 21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequent itemset mining in uncertain transaction databases semantically and
computationally differs from traditional techniques applied on standard
(certain) transaction databases. Uncertain transaction databases consist of
sets of existentially uncertain items. The uncertainty of items in transactions
makes traditional techniques inapplicable. In this paper, we tackle the problem
of finding probabilistic frequent itemsets based on possible world semantics.
In this context, an itemset X is called frequent if the probability that X
occurs in at least minSup transactions is above a given threshold. We make the
following contributions: We propose the first probabilistic FP-Growth algorithm
(ProFP-Growth) and associated probabilistic FP-Tree (ProFP-Tree), which we use
to mine all probabilistic frequent itemsets in uncertain transaction databases
without candidate generation. In addition, we propose an efficient technique to
compute the support probability distribution of an itemset in linear time using
the concept of generating functions. An extensive experimental section
evaluates the our proposed techniques and shows that our ProFP-Growth approach
is significantly faster than the current state-of-the-art algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2313</identifier>
 <datestamp>2014-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2313</id><created>2010-08-13</created><updated>2010-08-16</updated><authors><author><keyname>Parand</keyname><forenames>K.</forenames></author><author><keyname>Rezaei</keyname><forenames>A. R.</forenames></author><author><keyname>Taghavi</keyname><forenames>A.</forenames></author></authors><title>Lagrangian method for solving Lane-Emden type equation arising in
  astrophysics on semi-infinite domains</title><categories>math-ph astro-ph.IM cs.CE math.MP math.NA</categories><comments>16 pages, 1 figures; Published online in the journal of &quot;Acta
  Astronautica&quot;</comments><msc-class>85-08, 74S25, 42C10</msc-class><journal-ref>Acta Astronaut.67:673-680,2010</journal-ref><doi>10.1016/j.actaastro.2010.05.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a Lagrangian method for solving Lane-Emden equation
which is a nonlinear ordinary differential equation on semi-infinite interval.
This approach is based on a Modified generalized Laguerre functions Lagrangian
method. The method reduces the solution of this problem to the solution of a
system of algebraic equations. We also present the comparison of this work with
some well-known results and show that the present solution is acceptable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2322</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2322</id><created>2010-08-13</created><updated>2010-08-16</updated><authors><author><keyname>Parand</keyname><forenames>K.</forenames></author><author><keyname>Rezaei</keyname><forenames>A. R.</forenames></author><author><keyname>Ghaderi</keyname><forenames>S. M.</forenames></author></authors><title>An approximate solution of the MHD Falkner-Skan flow by Hermite
  functions pseudospectral method</title><categories>math-ph cs.CE math.MP math.NA physics.comp-ph physics.flu-dyn</categories><comments>15 pages, 4 figures; Published online in the journal of
  &quot;Communications in Nonlinear Science and Numerical Simulation&quot;</comments><msc-class>76M22, 33C45, 65L60</msc-class><journal-ref>Commun Nonlinear Sci Numer Simulat 16 (2011) 274-283</journal-ref><doi>10.1016/j.cnsns.2010.03.022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on a new approximation method, namely pseudospectral method, a solution
for the three order nonlinear ordinary differential laminar boundary layer
Falkner-Skan equation has been obtained on the semi-infinite domain. The
proposed approach is equipped by the orthogonal Hermite functions that have
perfect properties to achieve this goal. This method solves the problem on the
semi-infinite domain without truncating it to a finite domain and transforming
domain of the problem to a finite domain. In addition, this method reduces
solution of the problem to solution of a system of algebraic equations. We also
present the comparison of this work with numerical results and show that the
present method is applicable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2337</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2337</id><created>2010-08-13</created><updated>2010-08-16</updated><authors><author><keyname>Parand</keyname><forenames>K.</forenames></author><author><keyname>Rezaei</keyname><forenames>A. R.</forenames></author><author><keyname>Taghavi</keyname><forenames>A.</forenames></author></authors><title>Numerical approximations for population growth model by Rational
  Chebyshev and Hermite Functions collocation approach: A comparison</title><categories>math-ph cs.CE math.MP math.NA</categories><comments>18 pages, 5 figures; Published online in the journal of &quot;Mathematical
  Methods in the Applied Sciences&quot;</comments><msc-class>45D05, 65L60, 33C45</msc-class><doi>10.1002/mma.1318</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to compare rational Chebyshev (RC) and Hermite functions (HF)
collocation approach to solve the Volterra's model for population growth of a
species within a closed system. This model is a nonlinear integro-differential
equation where the integral term represents the effect of toxin. This approach
is based on orthogonal functions which will be defined. The collocation method
reduces the solution of this problem to the solution of a system of algebraic
equations. We also compare these methods with some other numerical results and
show that the present approach is applicable for solving nonlinear
integro-differential equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2345</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2345</id><created>2010-08-13</created><updated>2010-08-17</updated><authors><author><keyname>Orue</keyname><forenames>A. B.</forenames></author><author><keyname>Alvarez</keyname><forenames>G.</forenames></author><author><keyname>Guerra</keyname><forenames>A.</forenames></author><author><keyname>Pastor</keyname><forenames>G.</forenames></author><author><keyname>Romera</keyname><forenames>M.</forenames></author><author><keyname>Montoya</keyname><forenames>F.</forenames></author></authors><title>Trident, a new pseudo random number generator based on coupled chaotic
  maps</title><categories>cs.CR physics.comp-ph</categories><comments>4 figures, 10 pages. Submitted to the 3rd Int. Workshop on
  Computational Intelligence in Security for Information Systems (CISIS'10),
  Leon (Spain), November 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a new family of cryptographically secure pseudorandom
number generators, based on coupled chaotic maps, that will serve as keystream
in a stream cipher. The maps are a modification of a piecewise linear map, by
dynamic changing of the coefficient values and perturbing its lesser
significant bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2347</identifier>
 <datestamp>2010-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2347</id><created>2010-08-13</created><authors><author><keyname>Celik</keyname><forenames>Guner D.</forenames></author><author><keyname>Le</keyname><forenames>Long B.</forenames></author><author><keyname>Modiano</keyname><forenames>Eytan</forenames></author></authors><title>Scheduling in Parallel Queues with Randomly Varying Connectivity and
  Switchover Delay</title><categories>math.OC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dynamic server control problem for two parallel queues with
randomly varying connectivity and server switchover time between the queues. At
each time slot the server decides either to stay with the current queue or
switch to the other queue based on the current connectivity and the queue
length information. The introduction of switchover time is a new modeling
component of this problem, which makes the problem much more challenging. We
develop a novel approach to characterize the stability region of the system by
using state action frequencies, which are stationary solutions to a Markov
Decision Process (MDP) formulation of the corresponding saturated system. We
characterize the stability region explicitly in terms of the connectivity
parameters and develop a frame-based dynamic control (FBDC) policy that is
shown to be throughput-optimal. In fact, the FBDC policy provides a new
framework for developing throughput-optimal network control policies using
state action frequencies. Furthermore, we develop simple Myopic policies that
achieve more than 96% of the stability region. Finally, simulation results show
that the Myopic policies may achieve the full stability region and are more
delay efficient than the FBDC policy in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2348</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2348</id><created>2010-08-13</created><updated>2010-08-16</updated><authors><author><keyname>Parand</keyname><forenames>K.</forenames></author><author><keyname>Abbasbandy</keyname><forenames>S.</forenames></author><author><keyname>Kazem</keyname><forenames>S.</forenames></author><author><keyname>Rezaei</keyname><forenames>A. R.</forenames></author></authors><title>Comparison between two common collocation approaches based on radial
  basis functions for the case of heat transfer equations arising in porous
  medium</title><categories>math-ph cs.CE math.MP math.NA physics.comp-ph</categories><comments>23 pages, 4 figures; Published online in the journal of
  &quot;Communications in Nonlinear Science and Numerical Simulation&quot;</comments><msc-class>65L60, 34B15, 76A05</msc-class><doi>10.1016/j.cnsns.2010.07.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper two common collocation approaches based on radial basis
functions have been considered; one be computed through the integration process
(IRBF) and one be computed through the differentiation process (DRBF). We
investigated the two approaches on natural convection heat transfer equations
embedded in porous medium which are of great importance in the design of
canisters for nuclear wastes disposal. Numerical results show that the IRBF be
performed much better than the common DRBF, and show good accuracy and high
rate of convergence of IRBF process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2368</identifier>
 <datestamp>2011-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2368</id><created>2010-08-13</created><updated>2010-12-16</updated><authors><author><keyname>Couvreur</keyname><forenames>Alain</forenames></author></authors><title>Construction of Rational Surfaces Yielding Good Codes</title><categories>math.AG cs.IT math.IT math.NT</categories><comments>20 pages, 7 figures</comments><msc-class>94B27, 14J26, 11G25, 14C20</msc-class><journal-ref>Finite Fields and their Applications, Volume 17(5), 2011, Pages
  424-441</journal-ref><doi>10.1016/j.ffa.2011.02.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present article, we consider Algebraic Geometry codes on some rational
surfaces. The estimate of the minimum distance is translated into a point
counting problem on plane curves. This problem is solved by applying the upper
bound &quot;\`a la Weil&quot; of Aubry and Perret together with the bound of Homma and
Kim for plane curves. The parameters of several codes from rational surfaces
are computed. Among them, the codes defined by the evaluation of forms of
degree 3 on an elliptic quadric are studied. As far as we know, such codes have
never been treated before. Two other rational surfaces are studied and very
good codes are found on them. In particular, a [57,12,34] code over
$\mathbf{F}_7$ and a [91,18,53] code over $\mathbf{F}_9$ are discovered, these
codes beat the best known codes up to now.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2386</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2386</id><created>2010-08-13</created><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Huang</keyname><forenames>Howard</forenames></author></authors><title>Linear Precoding in Cooperative MIMO Cellular Networks with Limited
  Coordination Clusters</title><categories>cs.IT math.IT</categories><comments>13 pages, 5 figures</comments><journal-ref>IEEE J-SAC vol. 28, no. 9, pp. 1446-1454, Dec. 2010</journal-ref><doi>10.1109/JSAC.2010.101206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a cooperative multiple-antenna downlink cellular network, maximization of
a concave function of user rates is considered. A new linear precoding
technique called soft interference nulling (SIN) is proposed, which performs at
least as well as zero-forcing (ZF) beamforming. All base stations share channel
state information, but each user's message is only routed to those that
participate in the user's coordination cluster. SIN precoding is particularly
useful when clusters of limited sizes overlap in the network, in which case
traditional techniques such as dirty paper coding or ZF do not directly apply.
The SIN precoder is computed by solving a sequence of convex optimization
problems. SIN under partial network coordination can outperform ZF under full
network coordination at moderate SNRs. Under overlapping coordination clusters,
SIN precoding achieves considerably higher throughput compared to myopic ZF,
especially when the clusters are large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2390</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2390</id><created>2010-08-13</created><updated>2010-10-15</updated><authors><author><keyname>Dinh</keyname><forenames>Hang</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>The McEliece Cryptosystem Resists Quantum Fourier Sampling Attacks</title><categories>cs.CR cs.CC math.RT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum computers can break the RSA and El Gamal public-key cryptosystems,
since they can factor integers and extract discrete logarithms. If we believe
that quantum computers will someday become a reality, we would like to have
\emph{post-quantum} cryptosystems which can be implemented today with classical
computers, but which will remain secure even in the presence of quantum
attacks.
  In this article we show that the McEliece cryptosystem over
\emph{well-permuted, well-scrambled} linear codes resists precisely the attacks
to which the RSA and El Gamal cryptosystems are vulnerable---namely, those
based on generating and measuring coset states. This eliminates the approach of
strong Fourier sampling on which almost all known exponential speedups by
quantum algorithms are based. Specifically, we show that the natural case of
the Hidden Subgroup Problem to which the McEliece cryptosystem reduces cannot
be solved by strong Fourier sampling, or by any measurement of a coset state.
We start with recent negative results on quantum algorithms for Graph
Isomorphism, which are based on particular subgroups of size two, and extend
them to subgroups of arbitrary structure, including the automorphism groups of
linear codes. This allows us to obtain the first rigorous results on the
security of the McEliece cryptosystem in the face of quantum adversaries,
strengthening its candidacy for post-quantum cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2410</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2410</id><created>2010-08-13</created><authors><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author></authors><title>Removing the Barrier to Scalability in Parallel FMM</title><categories>cs.CE cs.NA physics.comp-ph</categories><comments>11 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fast Multipole Method (FMM) is well known to possess a bottleneck arising
from decreasing workload on higher levels of the FMM tree [Greengard and Gropp,
Comp. Math. Appl., 20(7), 1990]. We show that this potential bottleneck can be
eliminated by overlapping multipole and local expansion computations with
direct kernel evaluations on the finest level grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2412</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2412</id><created>2010-08-13</created><updated>2010-12-06</updated><authors><author><keyname>Sher</keyname><forenames>Gene I.</forenames></author></authors><title>Discover &amp; eXplore Neural Network (DXNN) Platform, a Modular TWEANN</title><categories>cs.NE cond-mat.dis-nn</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I present a novel type of Topology and Weight Evolving
Artificial Neural Network (TWEANN) system called Modular Discover &amp; eXplore
Neural Network (DXNN). Modular DXNN utilizes a hierarchical/modular topology
which allows for highly scalable and dynamically granular systems to evolve.
Among the novel features discussed in this paper is a simple and database
friendly encoding for hierarchical/modular NNs, a new selection method aimed at
producing highly compact and fit individuals within the population, a &quot;Targeted
Tunning&quot; system aimed at alleviating the curse of dimensionality, and a two
phase based neuroevolutionary approach which yields high population diversity
and removes the need for speciation algorithms. I will discuss DXNN's mutation
operators which are aimed at improving its efficiency, expandability, and
capabilities through a built in feature selection method that allows for the
evolved system to expand, discover, and explore new sensors and actuators.
Finally I will compare DXNN platform to other state of the art TWEANNs on a
control task to demonstrate its superior ability to produce highly compact
solutions faster than its competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2422</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2422</id><created>2010-08-14</created><updated>2012-01-30</updated><authors><author><keyname>Beame</keyname><forenames>Paul</forenames></author><author><keyname>Machmouchi</keyname><forenames>Widad</forenames></author></authors><title>The Quantum Query Complexity of AC0</title><categories>cs.CC quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any quantum algorithm deciding whether an input function $f$
from $[n]$ to $[n]$ is 2-to-1 or almost 2-to-1 requires $\Theta(n)$ queries to
$f$. The same lower bound holds for determining whether or not a function $f$
from $[2n-2]$ to $[n]$ is surjective. These results yield a nearly linear
$\Omega(n/\log n)$ lower bound on the quantum query complexity of $\cl{AC}^0$.
The best previous lower bound known for any $\cl{AC^0}$ function was the
$\Omega ((n/\log n)^{2/3})$ bound given by Aaronson and Shi's $\Omega(n^{2/3})$
lower bound for the element distinctness problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2425</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2425</id><created>2010-08-14</created><authors><author><keyname>Volkov</keyname><forenames>Mikhail V.</forenames></author><author><keyname>Goldberg</keyname><forenames>Svetlana V.</forenames></author><author><keyname>Kublanovsky</keyname><forenames>Stanislav I.</forenames></author></authors><title>A minimal nonfinitely based semigroup whose variety is polynomially
  recognizable</title><categories>math.GR cs.CC</categories><comments>16 pages, 3 figures</comments><msc-class>20M07, 68Q17</msc-class><journal-ref>J. Math. Sci. 177 (2011), 847-859</journal-ref><doi>10.1007/s10958-011-0512-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit a 6-element semigroup that has no finite identity basis but
nevertheless generates a variety whose finite membership problem admits a
polynomial algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2437</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2437</id><created>2010-08-14</created><authors><author><keyname>Horton</keyname><forenames>John J.</forenames></author></authors><title>Employer Expectations, Peer Effects and Productivity: Evidence from a
  Series of Field Experiments</title><categories>cs.HC cs.CY</categories><comments>30 pages</comments><acm-class>J.4; J.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports the results of a series of field experiments designed to
investigate how peer effects operate in a real work setting. Workers were hired
from an online labor market to perform an image-labeling task and, in some
cases, to evaluate the work product of other workers. These evaluations had
financial consequences for both the evaluating worker and the evaluated worker.
The experiments showed that on average, evaluating high-output work raised an
evaluator's subsequent productivity, with larger effects for evaluators that
are themselves highly productive. The content of the subject evaluations
themselves suggest one mechanism for peer effects: workers readily punished
other workers whose work product exhibited low output/effort. However,
non-compliance with employer expectations did not, by itself, trigger
punishment: workers would not punish non-complying workers so long as the
evaluated worker still exhibited high effort. A worker's willingness to punish
was strongly correlated with their own productivity, yet this relationship was
not the result of innate differences---productivity-reducing manipulations also
resulted in reduced punishment. Peer effects proved hard to stamp out: although
most workers complied with clearly communicated maximum expectations for
output, some workers still raised their production beyond the output ceiling
after evaluating highly productive yet non-complying work products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2440</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2440</id><created>2010-08-14</created><updated>2010-08-30</updated><authors><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author><author><keyname>Wang</keyname><forenames>Ming-wei</forenames></author></authors><title>Inverse Star, Borders, and Palstars</title><categories>cs.FL math.CO</categories><comments>revised to take into account Brzozowski article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A language L is closed if L = L*. We consider an operation on closed
languages, L-*, that is an inverse to Kleene closure. It is known that if L is
closed and regular, then L-* is also regular. We show that the analogous result
fails to hold for the context-free languages. Along the way we find a new
relationship between the unbordered words and the prime palstars of Knuth,
Morris, and Pratt. We use this relationship to enumerate the prime palstars,
and we prove that neither the language of all unbordered words nor the language
of all prime palstars is context-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2452</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2452</id><created>2010-08-14</created><authors><author><keyname>Syamsuddin</keyname><forenames>Irfan</forenames></author><author><keyname>Dillon</keyname><forenames>Tharam</forenames></author><author><keyname>Chang</keyname><forenames>Elizabeth</forenames></author><author><keyname>Han</keyname><forenames>Song</forenames></author></authors><title>A Survey of RFID Authentication Protocols Based on Hash-Chain Method</title><categories>cs.CR</categories><comments>Third ICCIT 2008 International Conference on Convergence and Hybrid
  Information Technology</comments><doi>10.1109/ICCIT.2008.314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security and privacy are the inherent problems in RFID communications. There
are several protocols have been proposed to overcome those problems. Hash chain
is commonly employed by the protocols to improve security and privacy for RFID
authentication. Although the protocols able to provide specific solution for
RFID security and privacy problems, they fail to provide integrated solution.
This article is a survey to closely observe those protocols in terms of its
focus and limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2458</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2458</id><created>2010-08-14</created><updated>2010-12-19</updated><authors><author><keyname>Gupta</keyname><forenames>Hari S.</forenames><affiliation>Indian Institute of Science, Bangalore, India</affiliation></author><author><keyname>D'Souza</keyname><forenames>Deepak</forenames><affiliation>Indian Institute of Science, Bangalore, India</affiliation></author><author><keyname>Komondoor</keyname><forenames>Raghavan</forenames><affiliation>Indian Institute of Science, Bangalore, India</affiliation></author><author><keyname>Rama</keyname><forenames>Girish M.</forenames><affiliation>Infosys Technologies Ltd., India</affiliation></author></authors><title>A Case Study in Matching Service Descriptions to Implementations in an
  Existing System</title><categories>cs.SE</categories><comments>20 pages, 19 pdf figures</comments><acm-class>D.2.7; D.2.13; K.6.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of companies are trying to migrate large monolithic software systems
to Service Oriented Architectures. A common approach to do this is to first
identify and describe desired services (i.e., create a model), and then to
locate portions of code within the existing system that implement the described
services. In this paper we describe a detailed case study we undertook to match
a model to an open-source business application. We describe the systematic
methodology we used, the results of the exercise, as well as several
observations that throw light on the nature of this problem. We also suggest
and validate heuristics that are likely to be useful in partially automating
the process of matching service descriptions to implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2514</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2514</id><created>2010-08-15</created><authors><author><keyname>de Cooman</keyname><forenames>Gert</forenames></author><author><keyname>Hermans</keyname><forenames>Filip</forenames></author><author><keyname>Antonucci</keyname><forenames>Alessandro</forenames></author><author><keyname>Zaffalon</keyname><forenames>Marco</forenames></author></authors><title>Epistemic irrelevance in credal nets: the case of imprecise Markov trees</title><categories>cs.AI math.PR stat.ML</categories><comments>29 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on credal nets, which are graphical models that generalise Bayesian
nets to imprecise probability. We replace the notion of strong independence
commonly used in credal nets with the weaker notion of epistemic irrelevance,
which is arguably more suited for a behavioural theory of probability. Focusing
on directed trees, we show how to combine the given local uncertainty models in
the nodes of the graph into a global model, and we use this to construct and
justify an exact message-passing algorithm that computes updated beliefs for a
variable in the tree. The algorithm, which is linear in the number of nodes, is
formulated entirely in terms of coherent lower previsions, and is shown to
satisfy a number of rationality requirements. We supply examples of the
algorithm's operation, and report an application to on-line character
recognition that illustrates the advantages of our approach for prediction. We
comment on the perspectives, opened by the availability, for the first time, of
a truly efficient algorithm based on epistemic irrelevance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2526</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2526</id><created>2010-08-15</created><authors><author><keyname>Natarajan</keyname><forenames>Lakshmi Prasad</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Low ML Decoding Complexity STBCs via Codes over GF(4)</title><categories>cs.IT math.IT</categories><comments>20 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give a new framework for constructing low ML decoding
complexity Space-Time Block Codes (STBCs) using codes over the finite field
$\mathbb{F}_4$. Almost all known low ML decoding complexity STBCs can be
obtained via this approach. New full-diversity STBCs with low ML decoding
complexity and cubic shaping property are constructed, via codes over
$\mathbb{F}_4$, for number of transmit antennas \mbox{$N=2^m$}, \mbox{$m \geq
1$}, and rates \mbox{$R&gt;1$} complex symbols per channel use. When \mbox{$R=N$},
the new STBCs are information-lossless as well. The new class of STBCs have the
least known ML decoding complexity among all the codes available in the
literature for a large set of \mbox{$(N,R)$} pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2529</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2529</id><created>2010-08-15</created><updated>2011-05-23</updated><authors><author><keyname>Hiai</keyname><forenames>F.</forenames></author><author><keyname>Mosonyi</keyname><forenames>M.</forenames></author><author><keyname>Petz</keyname><forenames>D.</forenames></author><author><keyname>Beny</keyname><forenames>C.</forenames></author></authors><title>Quantum f-divergences and error correction</title><categories>math-ph cs.IT math.IT math.MP quant-ph</categories><comments>v5: Extended analysis of the Chernoff and the Hoeffding distances in
  Section 6. The operator Holder and inverse Holder inequalities are derived in
  Appendix A as an application of the monotonicity under pinching</comments><report-no>Mittag-Leffler-2010fall</report-no><journal-ref>Reviews in Mathematical Physics, volume 23, issue 7, pp. 691 --
  747, (2011)</journal-ref><doi>10.1142/S0129055X11004412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum f-divergences are a quantum generalization of the classical notion of
f-divergences, and are a special case of Petz' quasi-entropies. Many well known
distinguishability measures of quantum states are given by, or derived from,
f-divergences; special examples include the quantum relative entropy, the Renyi
relative entropies, and the Chernoff and Hoeffding measures. Here we show that
the quantum f-divergences are monotonic under the dual of Schwarz maps whenever
the defining function is operator convex. This extends and unifies all
previously known monotonicity results. We also analyze the case where the
monotonicity inequality holds with equality, and extend Petz' reversibility
theorem for a large class of f-divergences and other distinguishability
measures. We apply our findings to the problem of quantum error correction, and
show that if a stochastic map preserves the pairwise distinguishability on a
set of states, as measured by a suitable f-divergence, then its action can be
reversed on that set by another stochastic map that can be constructed from the
original one in a canonical way. We also provide an integral representation for
operator convex functions on the positive half-line, which is the main
ingredient in extending previously known results on the monotonicity inequality
and the case of equality. We also consider some special cases where the
convexity of f is sufficient for the monotonicity, and obtain the inverse
Holder inequality for operators as an application. The presentation is
completely self-contained and requires only standard knowledge of matrix
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2542</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2542</id><created>2010-08-15</created><authors><author><keyname>Carlos</keyname><forenames>Oscar Sandoval</forenames></author></authors><title>Integration of Design Patterns and Mobile Applications in a Management
  System for Monitoring Maintenance Cathode Plates of Mining Company Quebrada
  Blanca SA</title><categories>cs.SE</categories><comments>10 Pages, 17 Figures; CISAISI 2009, CITIC 2010, JIISIC 2010</comments><journal-ref>CISAISI 2009, CITIC 2010, JIISIC 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document presents the integration of design patterns and mobile
applications, in the development of software management of plates (SIGEP) that
allows to support in the solutions to problematics that they appear in the
process of maintaining of plates copper cathodes of a Mining Company, in our
case for Quebrada Blanca S.A. (CMQB S.A.). These problematics mainly are
related to the little control over the tasks carried out in the maintaining to
the cathodic plates, and the lack of information that leads to this practice,
originates a deficient management and it does not allow to make opportune
decisions referring to these elements, and therefore it does to project and to
administer the life utility of the plates of cathodes, generating lifted costs
associated to this process. As the process of maintaining a cathode plates
constantly changing process, with respect to maintenance strategies in the
system design SIGEP recognizing the flexibility and reuse in the design of
system components, this achieved through design patterns used. The SIGEP
implementation of the system and the incorporation of a mobile application,
meant for CMQB S.A. increase control of the tasks carried out plates cathodes,
allowing the company to detailed information on the maintenance of these
elements, allowing among other things, identify cathode plates which are more
expensive, and therefore knowing what must be replaced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2555</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2555</id><created>2010-08-15</created><authors><author><keyname>Conway</keyname><forenames>Thomas C</forenames></author><author><keyname>Bromage</keyname><forenames>Andrew J</forenames></author></authors><title>Succinct Data Structures for Assembling Large Genomes</title><categories>q-bio.GN cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivation: Second generation sequencing technology makes it feasible for
many researches to obtain enough sequence reads to attempt the de novo assembly
of higher eukaryotes (including mammals). De novo assembly not only provides a
tool for understanding wide scale biological variation, but within human
bio-medicine, it offers a direct way of observing both large scale structural
variation and fine scale sequence variation. Unfortunately, improvements in the
computational feasibility for de novo assembly have not matched the
improvements in the gathering of sequence data. This is for two reasons: the
inherent computational complexity of the problem, and the in-practice memory
requirements of tools.
  Results: In this paper we use entropy compressed or succinct data structures
to create a practical representation of the de Bruijn assembly graph, which
requires at least a factor of 10 less storage than the kinds of structures used
by deployed methods. In particular we show that when stored succinctly, the de
Bruijn assembly graph for homo sapiens requires only 23 gigabytes of storage.
Moreover, because our representation is entropy compressed, in the presence of
sequencing errors it has better scaling behaviour asymptotically than
conventional approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2556</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2556</id><created>2010-08-15</created><authors><author><keyname>Krumme</keyname><forenames>Coco</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Pentland</keyname><forenames>Alex</forenames></author></authors><title>Patterns of Individual Shopping Behavior</title><categories>cs.CY</categories><comments>4 pages, 5 figures</comments><journal-ref>Krumme, C., Llorente, A., Cebrian, M., Pentland, A.(S.) &amp; Moro, E.
  The predictability of consumer visitation patterns. Sci. Rep. 3, 1645 (2013)</journal-ref><doi>10.1038/srep01645</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of economic theory is built on observations of aggregate, rather than
individual, behavior. Here, we present novel findings on human shopping
patterns at the resolution of a single purchase. Our results suggest that much
of our seemingly elective activity is actually driven by simple routines. While
the interleaving of shopping events creates randomness at the small scale, on
the whole consumer behavior is largely predictable. We also examine
income-dependent differences in how people shop, and find that wealthy
individuals are more likely to bundle shopping trips. These results validate
previous work on mobility from cell phone data, while describing the
unpredictability of behavior at higher resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2565</identifier>
 <datestamp>2011-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2565</id><created>2010-08-15</created><updated>2011-06-16</updated><authors><author><keyname>Gjoka</keyname><forenames>Minas</forenames></author><author><keyname>Butts</keyname><forenames>Carter T.</forenames></author><author><keyname>Kurant</keyname><forenames>Maciej</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>Multigraph Sampling of Online Social Networks</title><categories>cs.NI cs.DS cs.SI physics.data-an stat.ME</categories><comments>IEEE Journal on Selected Areas in Communications (JSAC), Special
  Issue on Measurement of Internet Topologies, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art techniques for probability sampling of users of online
social networks (OSNs) are based on random walks on a single social relation
(typically friendship). While powerful, these methods rely on the social graph
being fully connected. Furthermore, the mixing time of the sampling process
strongly depends on the characteristics of this graph. In this paper, we
observe that there often exist other relations between OSN users, such as
membership in the same group or participation in the same event. We propose to
exploit the graphs these relations induce, by performing a random walk on their
union multigraph. We design a computationally efficient way to perform
multigraph sampling by randomly selecting the graph on which to walk at each
iteration. We demonstrate the benefits of our approach through (i) simulation
in synthetic graphs, and (ii) measurements of Last.fm - an Internet website for
music with social networking features. More specifically, we show that
multigraph sampling can obtain a representative sample and faster convergence,
even when the individual graphs fail, i.e., are disconnected or highly
clustered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2571</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2571</id><created>2010-08-16</created><authors><author><keyname>Zhu</keyname><forenames>Jingge</forenames></author><author><keyname>Mo</keyname><forenames>Jianhua</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author></authors><title>Cooperative Secret Communication with Artificial Noise in Symmetric
  Interference Channel</title><categories>cs.IT math.IT</categories><comments>3 pages, 3 figures, to appear in IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the symmetric Gaussian interference channel where two users try
to enhance their secrecy rates in a cooperative manner. Artificial noise is
introduced along with useful information. We derive the power control and
artificial noise parameter for two kinds of optimal points, max-min point and
single user point. It is shown that there exists a critical value $P_c$ of the
power constraint, below which the max-min point is an optimal point on the
secrecy rate region, and above which time-sharing between single user points
achieves larger secrecy rate pairs. It is also shown that artificial noise can
help to enlarge the secrecy rate region, in particular on the single user
point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2574</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2574</id><created>2010-08-16</created><authors><author><keyname>Han</keyname><forenames>Jinyoung</forenames></author><author><keyname>Chung</keyname><forenames>Taejoong</forenames></author><author><keyname>Kim</keyname><forenames>Seungbae</forenames></author><author><keyname>Kim</keyname><forenames>Hyun-chul</forenames></author><author><keyname>Kwon</keyname><forenames>Ted &quot;Taekyoung&quot;</forenames></author><author><keyname>Choi</keyname><forenames>Yanghee</forenames></author></authors><title>An Empirical Study on Content Bundling in BitTorrent Swarming System</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the tremendous success of BitTorrent, its swarming system suffers
from a fundamental limitation: lower or no availability of unpopular contents.
Recently, Menasche et al. has shown that bundling is a promising solution to
mitigate this availability problem; it improves the availability and reduces
download times for unpopular contents by combining multiple files into a single
swarm. There also have been studies on bundling strategies and performance
issues in bundled swarms. In spite of the recent surge of interest in the
benefits of and strategies for bundling, there are still little empirical
grounding for understanding, describing, and modeling it. This is the first
empirical study that measures and analyzes how prevalent contents bundling is
in BitTorrent and how peers access the bundled contents, in comparison to the
other non-bundled (i.e., single-filed) ones. To our surprise, we found that
around 70% of BitTorrent swarms contain multiple files, which indicate that
bundling has become widespread for contents sharing. We also show that the
amount of bytes shared in bundled swarms is estimated to be around 85% out of
all the BitTorrent contents logged in our datasets. Inspired from our findings,
we raise and discuss three important research questions in the field of file
sharing systems as well as future contents-oriented networking: i) bundling
strategies, ii) bundling-aware sharing systems in BitTorrent, and iii)
implications on content-oriented networking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2579</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2579</id><created>2010-08-16</created><authors><author><keyname>Yahya</keyname><forenames>Keyvan</forenames></author><author><keyname>Biazar</keyname><forenames>Jafar</forenames></author><author><keyname>Azari</keyname><forenames>Hossein</forenames></author><author><keyname>Fard</keyname><forenames>Pouyan Rafiei</forenames></author></authors><title>Homotopy Perturbation Method for Image Restoration and Denoising</title><categories>cs.CV cs.NA math.AP math.NA</categories><comments>submitted for publication in ICCESSE 2010 : &quot;International Conference
  on Computer, Electrical, Systems, Science and Engineering&quot;, Amsterdam, The
  Netherlands</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The famous Perona-Malik (P-M) equation which was at first introduced for
image restoration has been solved via various numerical methods. In this paper
we will solve it for the first time via applying a new numerical method called
Homotopy Perturbation Method (HMP) and the correspondent approximated solutions
will be obtained for the P-M equation with regards to relevant error analysis.
Through implementation of our algorithm we will access some effective results
which are deserved to be considered as worthy as the other solutions issued by
the other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2581</identifier>
 <datestamp>2015-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2581</id><created>2010-08-16</created><updated>2015-12-15</updated><authors><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>The LASSO risk for gaussian matrices</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>43 pages, 5 figures (v3 rectifies some inconsistencies in the
  formulation of auxiliary lemmas)</comments><journal-ref>IEEE Transactions on Information Theory, Vol 587, Issue 4 pp.
  1997-2017, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning a coefficient vector x_0\in R^N from
noisy linear observation y=Ax_0+w \in R^n. In many contexts (ranging from model
selection to image processing) it is desirable to construct a sparse estimator
x'. In this case, a popular approach consists in solving an L1-penalized least
squares problem known as the LASSO or Basis Pursuit DeNoising (BPDN).
  For sequences of matrices A of increasing dimensions, with independent
gaussian entries, we prove that the normalized risk of the LASSO converges to a
limit, and we obtain an explicit expression for this limit. Our result is the
first rigorous derivation of an explicit formula for the asymptotic mean square
error of the LASSO for random instances. The proof technique is based on the
analysis of AMP, a recently developed efficient algorithm, that is inspired
from graphical models ideas.
  Simulations on real data matrices suggest that our results can be relevant in
a broad array of practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2588</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2588</id><created>2010-08-16</created><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author></authors><title>Fastest Mixing Markov Chain on Symmetric K-Partite Network</title><categories>cs.DM</categories><comments>19 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving fastest mixing Markov chain problem (i.e. finding transition
probabilities on the edges to minimize the second largest eigenvalue modulus of
the transition probability matrix) over networks with different topologies is
one of the primary areas of research in the context of computer science and one
of the well known networks in this issue is K-partite network. Here in this
work we present analytical solution for the problem of fastest mixing Markov
chain by means of stratification and semidefinite programming, for four
particular types of K-partite networks, namely Symmetric K-PPDR, Semi Symmetric
K-PPDR, Cycle K-PPDR and Semi Cycle K-PPDR networks. Our method in this paper
is based on convexity of fastest mixing Markov chain problem, and inductive
comparing of the characteristic polynomials initiated by slackness conditions
in order to find the optimal transition probabilities. The presented results
shows that a Symmetric K-PPDR network and its equivalent Semi Symmetric K-PPDR
network have the same SLEM despite the fact that Semi symmetric K-PPDR network
has less edges than its equivalent symmetric K-PPDR network and at the same
time symmetric K-PPDR network has better mixing rate per step than its
equivalent semi symmetric K-PPDR network at first few iterations. The same
results are true for Cycle K-PPDR and Semi Cycle K-PPDR networks. Also the
obtained optimal transition probabilities have been compared with the
transition probabilities obtained from Metropolis-Hasting method by comparing
mixing time improvements numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2590</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2590</id><created>2010-08-16</created><updated>2010-09-07</updated><authors><author><keyname>Zantema</keyname><forenames>Hans H</forenames><affiliation>Technische Universiteit Eindhoven, The Netherlands</affiliation></author></authors><title>Well-definedness of Streams by Transformation and Termination</title><categories>cs.LO cs.PL</categories><proxy>LMCS</proxy><acm-class>F.4.2, E.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  7, 2010) lmcs:1107</journal-ref><doi>10.2168/LMCS-6(3:21)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Streams are infinite sequences over a given data type. A stream specification
is a set of equations intended to define a stream. We propose a transformation
from such a stream specification to a term rewriting system (TRS) in such a way
that termination of the resulting TRS implies that the stream specification is
well-defined, that is, admits a unique solution. As a consequence, proving
well-definedness of several interesting stream specifications can be done fully
automatically using present powerful tools for proving TRS termination. In
order to increase the power of this approach, we investigate transformations
that preserve semantics and well-definedness. We give examples for which the
above mentioned technique applies for the ransformed specification while it
fails for the original one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2613</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2613</id><created>2010-08-16</created><authors><author><keyname>Kim</keyname><forenames>Y. H.</forenames></author></authors><title>Joint maximum likelihood estimation of carrier and sampling frequency
  offsets for OFDM systems</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Transactions on Broadcasting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In orthogonal-frequency division multiplexing (OFDM) systems, carrier and
sampling frequency offsets (CFO and SFO, respectively) can destroy the
orthogonality of the subcarriers and degrade system performance. In the
literature, Nguyen-Le, Le-Ngoc, and Ko proposed a simple maximum-likelihood
(ML) scheme using two long training symbols for estimating the initial CFO and
SFO of a recursive least-squares (RLS) estimation scheme. However, the results
of Nguyen-Le's ML estimation show poor performance relative to the Cramer-Rao
bound (CRB). In this paper, we extend Moose's CFO estimation algorithm to joint
ML estimation of CFO and SFO using two long training symbols. In particular, we
derive CRBs for the mean square errors (MSEs) of CFO and SFO estimation.
Simulation results show that the proposed ML scheme provides better performance
than Nguyen-Le's ML scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2626</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2626</id><created>2010-08-16</created><authors><author><keyname>Hoekx</keyname><forenames>Eveline</forenames></author><author><keyname>Bussche</keyname><forenames>Jan Van den</forenames></author></authors><title>Mining tree-query associations in graphs</title><categories>cs.DB cs.AI</categories><comments>Full version of two earlier conference papers presented at KDD 2005
  and ICDM 2006</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New applications of data mining, such as in biology, bioinformatics, or
sociology, are faced with large datasetsstructured as graphs. We introduce a
novel class of tree-shapedpatterns called tree queries, and present algorithms
for miningtree queries and tree-query associations in a large data graph. Novel
about our class of patterns is that they can containconstants, and can contain
existential nodes which are not counted when determining the number of
occurrences of the patternin the data graph. Our algorithms have a number of
provableoptimality properties, which are based on the theory of conjunctive
database queries. We propose a practical, database-oriented implementation in
SQL, and show that the approach works in practice through experiments on data
about food webs, protein interactions, and citation analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2638</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2638</id><created>2010-08-16</created><authors><author><keyname>Feder</keyname><forenames>Elie</forenames></author><author><keyname>Garber</keyname><forenames>David</forenames></author></authors><title>On the Orchard crossing number of complete bipartite graphs</title><categories>math.CO cs.DM</categories><comments>23 pages, 4 figures; Submitted</comments><msc-class>05C62</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute the Orchard crossing number, which is defined in a similar way to
the rectilinear crossing number, for the complete bipartite graphs K_{n,n}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2647</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2647</id><created>2010-08-16</created><authors><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Searching publications on software testing</title><categories>cs.SE</categories><comments>7 pages</comments><acm-class>D.2.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note concerns a search for publications in which the pragmatic concept
of a test as conducted in the practice of software testing is formalized, a
theory about software testing based on such a formalization is presented or it
is demonstrated on the basis of such a theory that there are solid grounds to
test software in cases where in principle other forms of analysis could be
used. This note reports on the way in which the search has been carried out and
the main outcomes of the search. The message of the note is that the
fundamentals of software testing are not yet complete in some respects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2688</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2688</id><created>2010-08-16</created><updated>2012-03-18</updated><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>A Dichotomy Theorem for the Approximate Counting of Complex-Weighted
  Bounded-Degree Boolean CSPs</title><categories>cs.CC</categories><comments>A4, 10pt, 20 pages. This revised version improves its preliminary
  version published under a slightly different title in the Proceedings of the
  4th International Conference on Combinatorial Optimization and Applications
  (COCOA 2010), Lecture Notes in Computer Science, Springer, Vol.6508 (Part I),
  pp.285--299, Kailua-Kona, Hawaii, USA, December 18--20, 2010</comments><journal-ref>(journal version) Theoretical Computer Science, Vol.447,
  pp.120-135, 2012</journal-ref><doi>10.1007/978-3-642-17458-2_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the computational complexity of approximately counting the total
weight of variable assignments for every complex-weighted Boolean constraint
satisfaction problem (or CSP) with any number of additional unary (i.e., arity
1) constraints, particularly, when degrees of input instances are bounded from
above by a fixed constant. All degree-1 counting CSPs are obviously solvable in
polynomial time. When the instance's degree is more than two, we present a
dichotomy theorem that classifies all counting CSPs admitting free unary
constraints into exactly two categories. This classification theorem extends,
to complex-weighted problems, an earlier result on the approximation complexity
of unweighted counting Boolean CSPs of bounded degree. The framework of the
proof of our theorem is based on a theory of signature developed from Valiant's
holographic algorithms that can efficiently solve seemingly intractable
counting CSPs. Despite the use of arbitrary complex weight, our proof of the
classification theorem is rather elementary and intuitive due to an extensive
use of a novel notion of limited T-constructibility. For the remaining degree-2
problems, in contrast, they are as hard to approximate as Holant problems,
which are a generalization of counting CSPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2715</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2715</id><created>2010-08-16</created><authors><author><keyname>Kosinska</keyname><forenames>Ilona Dominika</forenames></author><author><keyname>Technology</keyname><forenames>Wroclaw University of</forenames></author><author><keyname>Engineering</keyname><forenames>Institute of Biomedical</forenames></author><author><keyname>Instrumentation</keyname></author><author><keyname>27</keyname><forenames>Wybrzeze Wyspianskiego</forenames></author><author><keyname>Wroclaw</keyname><forenames>50-370</forenames></author><author><keyname>Poland</keyname></author></authors><title>The FEM approach to the 2D Poisson equation in 'meshes' optimized with
  the Metropolis algorithm</title><categories>cs.NA physics.comp-ph</categories><comments>22 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The presented article contains a 2D mesh generation routine optimized with
the Metropolis algorithm. The procedure enables to produce meshes with a
prescribed size h of elements. These finite element meshes can serve as
standard discrete patterns for the Finite Element Method (FEM). Appropriate
meshes together with the FEM approach constitute an effective tool to deal with
differential problems. Thus, having them both one can solve the 2D Poisson
problem. It can be done for different domains being either of a regular
(circle, square) or of a non--regular type. The proposed routine is even
capable to deal with non--convex shapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2729</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2729</id><created>2010-08-16</created><authors><author><keyname>Robinson</keyname><forenames>Michael</forenames></author></authors><title>Asynchronous logic circuits and sheaf obstructions</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article exhibits a particular encoding of logic circuits into a sheaf
formalism. The central result of this article is that there exists strictly
more information available to a circuit designer in this setting than exists in
static truth tables, but less than exists in event-level simulation. This
information is related to the timing behavior of the logic circuits, and
thereby provides a ``bridge'' between static logic analysis and detailed
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2743</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2743</id><created>2010-08-16</created><authors><author><keyname>Pendse</keyname><forenames>Gautam V.</forenames></author></authors><title>PMOG: The projected mixture of Gaussians model with application to blind
  source separation</title><categories>stat.ML cs.AI stat.ME</categories><comments>46 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the mixtures of Gaussians (MOG) model to the projected mixture of
Gaussians (PMOG) model. In the PMOG model, we assume that q dimensional input
data points z_i are projected by a q dimensional vector w into 1-D variables
u_i. The projected variables u_i are assumed to follow a 1-D MOG model. In the
PMOG model, we maximize the likelihood of observing u_i to find both the model
parameters for the 1-D MOG as well as the projection vector w. First, we derive
an EM algorithm for estimating the PMOG model. Next, we show how the PMOG model
can be applied to the problem of blind source separation (BSS). In contrast to
conventional BSS where an objective function based on an approximation to
differential entropy is minimized, PMOG based BSS simply minimizes the
differential entropy of projected sources by fitting a flexible MOG model in
the projected 1-D space while simultaneously optimizing the projection vector
w. The advantage of PMOG over conventional BSS algorithms is the more flexible
fitting of non-Gaussian source densities without assuming near-Gaussianity (as
in conventional BSS) and still retaining computational feasibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2748</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2748</id><created>2010-08-16</created><updated>2015-03-04</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>ActorScript(TM) extension of C sharp (TM), Java(TM), and Objective
  C(TM): iAdaptive(TM) concurrency for antiCloud(TM) privacy and security</title><categories>cs.PL cs.DC</categories><comments>Added explanation of facets of an Actor. Admin note: text overlap
  with arXiv:1008.1459</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ActorScript(TM) is a general purpose programming language for implementing
discretionary, adaptive concurrency that manages resources and demand.
  It is differentiated from previous languages by the following:
  - Universality
  *** Ability to specify what Actors can do
  *** Specify interface between hardware and software
  *** Everything in the language is accomplished using message passing
including the very definition of ActorScript itself
  *** Functional, Imperative, Logic, and Concurrent programming are integrated.
  *** Concurrency dynamically adapts to resources available and current load.
  *** Programs do not expose low-level implementation mechanisms such as
threads, tasks, locks, cores, etc.
  *** Messages can be directly communicated without requiring indirection
through brokers, channels, class hierarchies, mailboxes, pipes, ports, queues
etc.
  *** Variable races are eliminated.
  *** Binary XML and JSON are data types.
  *** Application binary interfaces are afforded so that no identifier symbol
need be looked up at runtime.
  - Safety and Security
  *** Programs are extension invariant, i.e., extending a program does not
change its meaning.
  *** Applications cannot directly harm each other.
  - Performance
  *** Impose no overhead on implementation of Actor systems
  *** Message passing has essentially same overhead as procedure calling and
looping.
  *** Allow execution to be dynamically adjusted for system load and capacity
(e.g. cores)
  *** Locality because execution is not bound by a sequential global memory
model
  *** Inherent concurrency because execution is not bound by communicating
sequential processes
  *** Minimize latency along critical paths
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2750</identifier>
 <datestamp>2013-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2750</id><created>2010-08-16</created><updated>2010-12-08</updated><authors><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Szczecinski</keyname><forenames>Leszek</forenames></author><author><keyname>Agrell</keyname><forenames>Erik</forenames></author></authors><title>On BICM receivers for TCM transmission</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications</comments><journal-ref>IEEE Trans. Commun., vol. 59, no. 10, pp. 2692-2702 , 2011</journal-ref><doi>10.1109/TCOMM.2011.091411.100505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent results have shown that the performance of bit-interleaved coded
modulation (BICM) using convolutional codes in nonfading channels can be
significantly improved when the interleaver takes a trivial form (BICM-T),
i.e., when it does not interleave the bits at all. In this paper, we give a
formal explanation for these results and show that BICM-T is in fact the
combination of a TCM transmitter and a BICM receiver. To predict the
performance of BICM-T, a new type of distance spectrum for convolutional codes
is introduced, analytical bounds based on this spectrum are developed, and
asymptotic approximations are also presented. It is shown that the minimum
distance of the code is not the relevant optimization criterion for BICM-T.
Optimal convolutional codes for different constrain lengths are tabulated and
asymptotic gains of about 2 dB are obtained. These gains are found to be the
same as those obtained by Ungerboeck's one-dimensional trellis coded modulation
(1D-TCM), and therefore, in nonfading channels, BICM-T is shown to be
asymptotically as good as 1D-TCM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2767</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2767</id><created>2010-08-16</created><authors><author><keyname>Groen</keyname><forenames>Derek</forenames><affiliation>Leiden</affiliation></author><author><keyname>Rieder</keyname><forenames>Steven</forenames><affiliation>Leiden</affiliation></author><author><keyname>Grosso</keyname><forenames>Paola</forenames><affiliation>Amsterdam</affiliation></author><author><keyname>de Laat</keyname><forenames>Cees</forenames><affiliation>Amsterdam</affiliation></author><author><keyname>Zwart</keyname><forenames>Simon Portegies</forenames><affiliation>Leiden</affiliation></author></authors><title>A Light-Weight Communication Library for Distributed Computing</title><categories>cs.DC</categories><comments>17 pages, 10 figures, published in Computational Science &amp; Discovery</comments><msc-class>68M14 (primary), 68M20, 85-08, 85A40 (secondary)</msc-class><acm-class>C.2.4; C.2.5</acm-class><journal-ref>Derek Groen et al 2010 Comput. Sci. Disc. 3 015002</journal-ref><doi>10.1088/1749-4699/3/1/015002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present MPWide, a platform independent communication library for
performing message passing between computers. Our library allows coupling of
several local MPI applications through a long distance network and is
specifically optimized for such communications. The implementation is
deliberately kept light-weight, platform independent and the library can be
installed and used without administrative privileges. The only requirements are
a C++ compiler and at least one open port to a wide area network on each site.
In this paper we present the library, describe the user interface, present
performance tests and apply MPWide in a large scale cosmological N-body
simulation on a network of two computers, one in Amsterdam and the other in
Tokyo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2798</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2798</id><created>2010-08-16</created><authors><author><keyname>Jindal</keyname><forenames>Apoorva</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Networked Computing in Wireless Sensor Networks for Structural Health
  Monitoring</title><categories>cs.NI</categories><doi>10.1117/12.880023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of distributed computation over a network of
wireless sensors. While this problem applies to many emerging applications, to
keep our discussion concrete we will focus on sensor networks used for
structural health monitoring. Within this context, the heaviest computation is
to determine the singular value decomposition (SVD) to extract mode shapes
(eigenvectors) of a structure. Compared to collecting raw vibration data and
performing SVD at a central location, computing SVD within the network can
result in significantly lower energy consumption and delay. Using recent
results on decomposing SVD, a well-known centralized operation, into
components, we seek to determine a near-optimal communication structure that
enables the distribution of this computation and the reassembly of the final
results, with the objective of minimizing energy consumption subject to a
computational delay constraint. We show that this reduces to a generalized
clustering problem; a cluster forms a unit on which a component of the overall
computation is performed. We establish that this problem is NP-hard. By
relaxing the delay constraint, we derive a lower bound to this problem. We then
propose an integer linear program (ILP) to solve the constrained problem
exactly as well as an approximate algorithm with a proven approximation ratio.
We further present a distributed version of the approximate algorithm. We
present both simulation and experimentation results to demonstrate the
effectiveness of these algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2799</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2799</id><created>2010-08-16</created><authors><author><keyname>Banerjee</keyname><forenames>Soumya</forenames></author><author><keyname>Moses</keyname><forenames>Melanie</forenames></author></authors><title>Immune System Inspired Strategies for Distributed Systems</title><categories>cs.DC math.OC q-bio.CB</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many components of the IS are constructed as modular units which do not need
to communicate with each other such that the number of components increases but
the size remains constant. However, a sub-modular IS architecture in which
lymph node number and size both increase sublinearly with body size is shown to
efficiently balance the requirements of communication and migration, consistent
with experimental data. We hypothesize that the IS architecture optimizes the
tradeoff between local search for pathogens and global response using
antibodies. Similar to natural immune systems, physical space and resource are
also important constraints on Artificial Immune Systems (AIS), especially
distributed systems applications used to connect low-powered sensors using
short-range wireless communication. AIS problems like distributed robot control
will also require a sub-modular architecture to efficiently balance the
tradeoff between local search for a solution and global response or
proliferation of the solution between different components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2814</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2814</id><created>2010-08-17</created><updated>2013-12-02</updated><authors><author><keyname>Ames</keyname><forenames>Brendan P. W.</forenames></author><author><keyname>Vavasis</keyname><forenames>Stephen A.</forenames></author></authors><title>Convex optimization for the planted k-disjoint-clique problem</title><categories>math.OC cs.DS cs.NA</categories><msc-class>90C25, 65K05, 68Q25, 62H30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the k-disjoint-clique problem. The input is an undirected graph G
in which the nodes represent data items, and edges indicate a similarity
between the corresponding items. The problem is to find within the graph k
disjoint cliques that cover the maximum number of nodes of G. This problem may
be understood as a general way to pose the classical `clustering' problem. In
clustering, one is given data items and a distance function, and one wishes to
partition the data into disjoint clusters of data items, such that the items in
each cluster are close to each other. Our formulation additionally allows
`noise' nodes to be present in the input data that are not part of any of the
cliques. The k-disjoint-clique problem is NP-hard, but we show that a convex
relaxation can solve it in polynomial time for input instances constructed in a
certain way. The input instances for which our algorithm finds the optimal
solution consist of k disjoint large cliques (called `planted cliques') that
are then obscured by noise edges and noise nodes inserted either at random or
by an adversary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2819</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2819</id><created>2010-08-17</created><authors><author><keyname>Inoue</keyname><forenames>Ayumu</forenames></author></authors><title>A symmetric motion picture of the twist-spun trefoil</title><categories>math.GT cs.GR</categories><comments>14 pages, 21 figures, and 5 movies</comments><msc-class>Primary 57Q45, Secondary 68U05, 68U07</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the aid of a computer, we provide a motion picture of the twist-spun
trefoil which exhibits the periodicity well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2824</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2824</id><created>2010-08-17</created><authors><author><keyname>Geetha</keyname><forenames>S.</forenames></author><author><keyname>Kamaraj</keyname><forenames>N.</forenames></author></authors><title>Optimized Image Steganalysis through Feature Selection using MBEGA</title><categories>cs.CR cs.MM</categories><comments>15 pages, IEEE NetCom 2009 Conference, IJCNC Journal</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.4
  (2010) 161-175</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature based steganalysis, an emerging branch in information forensics, aims
at identifying the presence of a covert communication by employing the
statistical features of the cover and stego image as clues/evidences. Due to
the large volumes of security audit data as well as complex and dynamic
properties of steganogram behaviours, optimizing the performance of
steganalysers becomes an important open problem. This paper is focussed at fine
tuning the performance of six promising steganalysers in this field, through
feature selection. We propose to employ Markov Blanket-Embedded Genetic
Algorithm (MBEGA) for stego sensitive feature selection process. In particular,
the embedded Markov blanket based memetic operators add or delete features (or
genes) from a genetic algorithm (GA) solution so as to quickly improve the
solution and fine-tune the search. Empirical results suggest that MBEGA is
effective and efficient in eliminating irrelevant and redundant features based
on both Markov blanket and predictive power in classifier model. Observations
show that the proposed method is superior in terms of number of selected
features, classification accuracy and computational cost than their existing
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2841</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2841</id><created>2010-08-17</created><authors><author><keyname>Mehta</keyname><forenames>S.</forenames></author><author><keyname>Kwak</keyname><forenames>K. S.</forenames></author></authors><title>Comparison of different Broadcast Schemes for Multi-Hop Wireless Sensor
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the performance of different broadcast schemes for
multihop sensor networks based on mathematical modeling. In near future many
applications will demand multicast (Broadcast) communication feature from the
sensor networks. This broadcast feature does not use virtual carrier sensing
but relies on physical carrier sensing to reduce collision. For this paper, we
analyze the different broadcast schemes for multihop wireless sensor networks
and also calculated the achievable throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2849</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2849</id><created>2010-08-17</created><updated>2010-09-06</updated><authors><author><keyname>Wassenberg</keyname><forenames>Jan</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>Faster Radix Sort via Virtual Memory and Write-Combining</title><categories>cs.DS cs.PF</categories><acm-class>D.3.4; C.1.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sorting algorithms are the deciding factor for the performance of common
operations such as removal of duplicates or database sort-merge joins. This
work focuses on 32-bit integer keys, optionally paired with a 32-bit value. We
present a fast radix sorting algorithm that builds upon a
microarchitecture-aware variant of counting sort. Taking advantage of virtual
memory and making use of write-combining yields a per-pass throughput
corresponding to at least 88 % of the system's peak memory bandwidth. Our
implementation outperforms Intel's recently published radix sort by a factor of
1.5. It also compares favorably to the reported performance of an algorithm for
Fermi GPUs when data-transfer overhead is included. These results indicate that
scalar, bandwidth-sensitive sorting algorithms remain competitive on current
architectures. Various other memory-intensive applications can benefit from the
techniques described herein.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2855</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2855</id><created>2010-08-17</created><authors><author><keyname>Dezfouli</keyname><forenames>Behnam</forenames></author><author><keyname>Radi</keyname><forenames>Marjan</forenames></author><author><keyname>Razak</keyname><forenames>Shukor Abd</forenames></author></authors><title>A Cross-Layer Approach for Minimizing Interference and Latency of Medium
  Access in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>17 pages, 16 figures</comments><acm-class>C.2.1; C.2.2</acm-class><journal-ref>International journal of Computer Networks &amp; Communications, vol.
  2, 2010, pp. 126-142</journal-ref><doi>10.5121/ijcnc.2010.2411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In low power wireless sensor networks, MAC protocols usually employ periodic
sleep/wake schedule to reduce idle listening time. Even though this mechanism
is simple and efficient, it results in high end-to-end latency and low
throughput. On the other hand, the previously proposed CSMA/CA-based MAC
protocols have tried to reduce inter-node interference at the cost of increased
latency and lower network capacity. In this paper we propose IAMAC, a CSMA/CA
sleep/wake MAC protocol that minimizes inter-node interference, while also
reduces per-hop delay through cross-layer interactions with the network layer.
Furthermore, we show that IAMAC can be integrated into the SP architecture to
perform its inter-layer interactions. Through simulation, we have extensively
evaluated the performance of IAMAC in terms of different performance metrics.
Simulation results confirm that IAMAC reduces energy consumption per node and
leads to higher network lifetime compared to S-MAC and Adaptive S-MAC, while it
also provides lower latency than S-MAC. Throughout our evaluations we have
considered IAMAC in conjunction with two error recovery methods, i.e., ARQ and
Seda. It is shown that using Seda as the error recovery mechanism of IAMAC
results in higher throughput and lifetime compared to ARQ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2857</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2857</id><created>2010-08-17</created><updated>2010-12-22</updated><authors><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author><author><keyname>Avestimehr</keyname><forenames>Amir Salman</forenames></author></authors><title>Bidirectional multi-pair network with a MIMO relay: Beamforming
  strategies and lack of duality</title><categories>cs.IT math.IT</categories><comments>Allerton 2010, updated the references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of a multi-user relay network, where multiple
single-antenna node pairs want to exchange information by using a multiple
antenna relay node. Due to the half-duplex constraint of the relay, the
exchange of information takes place in two steps. In the first step, the nodes
transmit their data to the relay, while in the second step, the relay is
broadcasting the data by using linear and non-linear precoding strategies. We
focus on the second step in this paper. We first consider the problem of
maximizing the overall rate achievable using linear and dirty-paper type
precoding strategies at the relay. Then, we consider minimizing the total power
at the relay subject to individual SINR constraints using the same strategies
at the relay. We show that the downlink-uplink duality does not hold for the
setup considered here, which is a somewhat surprising result. We also show that
the beamforming strategy which is optimal in the single-pair case performs very
well in the multi-pair case for practically relevant SNR. The results are
illustrated by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2873</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2873</id><created>2010-08-17</created><updated>2013-06-23</updated><authors><author><keyname>Gui</keyname><forenames>Guan</forenames></author><author><keyname>Wan</keyname><forenames>Qun</forenames></author><author><keyname>Adachi</keyname><forenames>Fumiyuki</forenames></author><author><keyname>Chen</keyname><forenames>Hongyang</forenames></author></authors><title>Compressive Channel Estimation for Two-way Relay Network in a
  Frequency-Selective Channel with Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>the paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-way relay network (TWRN) was introduced to realize high-data rate
transmission over the wireless frequency-selective channel. However, TWRC
requires the knowledge of channel state information (CSI) not only for coherent
data detection but also for the self-data removal. This is partial accomplished
by training sequence-based linear channel estimation. However, conventional
linear estimation techniques neglect anticipated sparsity of multipath channel.
Unlike the previous methods, we propose a compressive channel estimation method
which exploit the sparse structure and provide significant improvements in MSE
performance when compared with traditional LSbased linear channel probing
strategies. Simulation results confirm the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2897</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2897</id><created>2010-08-17</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Very Well-Covered Graphs of Girth at least Four and Local Maximum Stable
  Set Greedoids</title><categories>cs.DM math.CO</categories><comments>7 pages, 5 figures</comments><msc-class>05C69 (Primary) 52B40 (Secondary)</msc-class><acm-class>G.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A \textit{maximum stable set} in a graph $G$ is a stable set of maximum
cardinality. $S$ is a \textit{local maximum stable set} of $G$, and we write
$S\in\Psi(G)$, if $S$ is a maximum stable set of the subgraph induced by $S\cup
N(S)$, where $N(S)$ is the neighborhood of $S$. Nemhauser and Trotter Jr.
(1975), proved that any $S\in\Psi(G)$ is a subset of a maximum stable set of
$G$. In (Levit &amp; Mandrescu, 2002) we have shown that the family $\Psi(T)$ of a
forest $T$ forms a greedoid on its vertex set. The cases where $G$ is
bipartite, triangle-free, well-covered, while $\Psi(G)$ is a greedoid, were
analyzed in (Levit &amp; Mandrescu, 2002),(Levit &amp; Mandrescu, 2004),(Levit &amp;
Mandrescu, 2007), respectively. In this paper we demonstrate that if $G$ is a
very well-covered graph of girth $\geq4$, then the family $\Psi(G)$ is a
greedoid if and only if $G$ has a unique perfect matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2909</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2909</id><created>2010-08-17</created><authors><author><keyname>Andres</keyname><forenames>Bjoern</forenames></author><author><keyname>Koethe</keyname><forenames>Ullrich</forenames></author><author><keyname>Kroeger</keyname><forenames>Thorben</forenames></author><author><keyname>Hamprecht</keyname><forenames>Fred A.</forenames></author></authors><title>Runtime-Flexible Multi-dimensional Arrays and Views for C++98 and C++0x</title><categories>cs.DS cs.MS cs.PL cs.SE</categories><comments>Free source code available</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-dimensional arrays are among the most fundamental and most useful data
structures of all. In C++, excellent template libraries exist for arrays whose
dimension is fixed at runtime. Arrays whose dimension can change at runtime
have been implemented in C. However, a generic object-oriented C++
implementation of runtime-flexible arrays has so far been missing. In this
article, we discuss our new implementation called Marray, a package of class
templates that fills this gap. Marray is based on views as an underlying
concept. This concept brings some of the flexibility known from script
languages such as R and MATLAB to C++. Marray is free both for commercial and
non-commercial use and is publicly available from www.andres.sc/marray
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2928</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2928</id><created>2010-08-17</created><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author></authors><title>Minimum Entropy Combinatorial Optimization Problems</title><categories>cs.DS cs.DM</categories><journal-ref>Theory of Computing Systems, 51/1:4--21, 2012</journal-ref><doi>10.1007/s00224-011-9371-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey recent results on combinatorial optimization problems in which the
objective function is the entropy of a discrete distribution. These include the
minimum entropy set cover, minimum entropy orientation, and minimum entropy
coloring problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2952</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2952</id><created>2010-08-17</created><authors><author><keyname>Ritt</keyname><forenames>Marcus</forenames></author></authors><title>Motion planning with pull moves</title><categories>cs.CC</categories><comments>9 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that Sokoban is PSPACE-complete (Culberson 1998) and several
of its variants are NP-hard (Demaine et al. 2003). In this paper we prove the
NP-hardness of some variants of Sokoban where the warehouse keeper can only
pull boxes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2972</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2972</id><created>2010-08-17</created><authors><author><keyname>Sandryhaila</keyname><forenames>Aliaksei</forenames></author><author><keyname>Kovacevic</keyname><forenames>Jelena</forenames></author><author><keyname>Pueschel</keyname><forenames>Markus</forenames></author></authors><title>Algebraic Signal Processing Theory: Cooley-Tukey Type Algorithms for
  Polynomial Transforms Based on Induction</title><categories>cs.IT math.IT math.RA</categories><comments>19 pages. Submitted to SIAM Journal on Matrix Analysis and
  Applications</comments><journal-ref>SIAM J. Matrix Analysis and Appl. 32 (2) pp. 364-384, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A polynomial transform is the multiplication of an input vector $x\in\C^n$ by
a matrix $\PT_{b,\alpha}\in\C^{n\times n},$ whose $(k,\ell)$-th element is
defined as $p_\ell(\alpha_k)$ for polynomials $p_\ell(x)\in\C[x]$ from a list
$b=\{p_0(x),\dots,p_{n-1}(x)\}$ and sample points $\alpha_k\in\C$ from a list
$\alpha=\{\alpha_0,\dots,\alpha_{n-1}\}$. Such transforms find applications in
the areas of signal processing, data compression, and function interpolation.
Important examples include the discrete Fourier and cosine transforms. In this
paper we introduce a novel technique to derive fast algorithms for polynomial
transforms. The technique uses the relationship between polynomial transforms
and the representation theory of polynomial algebras. Specifically, we derive
algorithms by decomposing the regular modules of these algebras as a stepwise
induction. As an application, we derive novel $O(n\log{n})$ general-radix
algorithms for the discrete Fourier transform and the discrete cosine transform
of type 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2991</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2991</id><created>2010-08-17</created><updated>2010-09-14</updated><authors><author><keyname>Fousse</keyname><forenames>Laurent</forenames></author><author><keyname>Lafourcade</keyname><forenames>Pascal</forenames></author><author><keyname>Alnuaimi</keyname><forenames>Mohamed</forenames></author></authors><title>Benaloh's Dense Probabilistic Encryption Revisited</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1994, Josh Benaloh proposed a probabilistic homomorphic encryption scheme,
enhancing the poor expansion factor provided by Goldwasser and Micali's scheme.
Since then, numerous papers have taken advantage of Benaloh's homomorphic
encryption function, including voting schemes, computing multi-party trust
privately, non-interactive verifiable secret sharing, online poker... In this
paper we show that the original description of the scheme is incorrect,
possibly resulting in ambiguous decryption of ciphertexts. We give a corrected
description of the scheme and provide a complete proof of correctness. We also
compute the probability of failure of the original scheme. Finally we analyze
several applications using Benaloh's encryption scheme. We show in each case
the impact of a bad choice in the key generation phase of Benaloh's scheme. For
instance in the application of e-voting protocol, it can inverse the result of
an election, which is a non negligible consequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.2996</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.2996</id><created>2010-08-17</created><authors><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Sparsity-Cognizant Total Least-Squares for Perturbed Compressive
  Sampling</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, submitted to IEEE Transactions on Signal
  Processing</comments><journal-ref>IEEE.Trans.Signal.Processing 59 (2011) 2002-2016</journal-ref><doi>10.1109/TSP.2011.2109956</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving linear regression problems based on the total least-squares (TLS)
criterion has well-documented merits in various applications, where
perturbations appear both in the data vector as well as in the regression
matrix. However, existing TLS approaches do not account for sparsity possibly
present in the unknown vector of regression coefficients. On the other hand,
sparsity is the key attribute exploited by modern compressive sampling and
variable selection approaches to linear regression, which include noise in the
data, but do not account for perturbations in the regression matrix. The
present paper fills this gap by formulating and solving TLS optimization
problems under sparsity constraints. Near-optimum and reduced-complexity
suboptimum sparse (S-) TLS algorithms are developed to address the perturbed
compressive sampling (and the related dictionary learning) challenge, when
there is a mismatch between the true and adopted bases over which the unknown
vector is sparse. The novel S-TLS schemes also allow for perturbations in the
regression matrix of the least-absolute selection and shrinkage selection
operator (Lasso), and endow TLS approaches with ability to cope with sparse,
under-determined &quot;errors-in-variables&quot; models. Interesting generalizations can
further exploit prior knowledge on the perturbations to obtain novel weighted
and structured S-TLS solvers. Analysis and simulations demonstrate the
practical impact of S-TLS in calibrating the mismatch effects of contemporary
grid-based approaches to cognitive radio sensing, and robust
direction-of-arrival estimation using antenna arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3035</identifier>
 <datestamp>2012-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3035</id><created>2010-08-18</created><authors><author><keyname>Knabe</keyname><forenames>Frederic</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Achievable Rates in Two-user Interference Channels with Finite Inputs
  and (Very) Strong Interference</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, to appear in proceedings of Asilomar Conference
  on Signals, Systems, and Computers 2010</comments><doi>10.1109/ACSSC.2010.5757908</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For two-user interference channels, the capacity is known for the case where
interference is stronger than the desired signal. Moreover, it is known that if
the interference is above a certain level, it does not reduce the capacity at
all. To achieve this capacity, the channel inputs need to be Gaussian
distributed. However, Gaussian signals are continuous and unbounded. Thus, they
are not well suited for practical applications. In this paper, we investigate
the achievable rates if the channel inputs are restricted to finite
constellations. Moreover, we will show by numerical simulations that rotating
one of these input alphabets in the complex plane can increase the achievable
rate region. Finally, we show that the threshold at which the single-user rates
are achieved also depends on this rotation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3043</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3043</id><created>2010-08-18</created><updated>2012-01-17</updated><authors><author><keyname>Fornasier</keyname><forenames>Massimo</forenames></author><author><keyname>Schnass</keyname><forenames>Karin</forenames></author><author><keyname>Vybiral</keyname><forenames>Jan</forenames></author></authors><title>Learning Functions of Few Arbitrary Linear Parameters in High Dimensions</title><categories>math.NA cs.CC cs.LG stat.ML</categories><comments>31 pages, this version was accepted to Foundations of Computational
  Mathematics, the final publication will be available on
  http://www.springerlink.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let us assume that $f$ is a continuous function defined on the unit ball of
$\mathbb R^d$, of the form $f(x) = g (A x)$, where $A$ is a $k \times d$ matrix
and $g$ is a function of $k$ variables for $k \ll d$. We are given a budget $m
\in \mathbb N$ of possible point evaluations $f(x_i)$, $i=1,...,m$, of $f$,
which we are allowed to query in order to construct a uniform approximating
function. Under certain smoothness and variation assumptions on the function
$g$, and an {\it arbitrary} choice of the matrix $A$, we present in this paper
  1. a sampling choice of the points $\{x_i\}$ drawn at random for each
function approximation;
  2. algorithms (Algorithm 1 and Algorithm 2) for computing the approximating
function, whose complexity is at most polynomial in the dimension $d$ and in
the number $m$ of points.
  Due to the arbitrariness of $A$, the choice of the sampling points will be
according to suitable random distributions and our results hold with
overwhelming probability. Our approach uses tools taken from the {\it
compressed sensing} framework, recent Chernoff bounds for sums of
positive-semidefinite matrices, and classical stability bounds for invariant
subspaces of singular value decompositions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3056</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3056</id><created>2010-08-18</created><authors><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Pan</keyname><forenames>Guangming</forenames></author><author><keyname>Zeng</keyname><forenames>Yonghong</forenames></author></authors><title>On the Performance of Spectrum Sensing Algorithms using Multiple
  Antennas</title><categories>cs.IT math.IT stat.AP</categories><comments>IEEE GlobeCom 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, some spectrum sensing algorithms using multiple antennas,
such as the eigenvalue based detection (EBD), have attracted a lot of
attention. In this paper, we are interested in deriving the asymptotic
distributions of the test statistics of the EBD algorithms. Two EBD algorithms
using sample covariance matrices are considered: maximum eigenvalue detection
(MED) and condition number detection (CND). The earlier studies usually assume
that the number of antennas (K) and the number of samples (N) are both large,
thus random matrix theory (RMT) can be used to derive the asymptotic
distributions of the maximum and minimum eigenvalues of the sample covariance
matrices. While assuming the number of antennas being large simplifies the
derivations, in practice, the number of antennas equipped at a single secondary
user is usually small, say 2 or 3, and once designed, this antenna number is
fixed. Thus in this paper, our objective is to derive the asymptotic
distributions of the eigenvalues and condition numbers of the sample covariance
matrices for any fixed K but large N, from which the probability of detection
and probability of false alarm can be obtained. The proposed methodology can
also be used to analyze the performance of other EBD algorithms. Finally,
computer simulations are presented to validate the accuracy of the derived
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3091</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3091</id><created>2010-08-18</created><authors><author><keyname>Lagoutte</keyname><forenames>Aurelie</forenames></author></authors><title>2-FREE-FLOOD-IT is polynomial</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a discrete diffusion process introduced in some combinatorial games
called FLOODIT and MADVIRUS that can be played online and whose computational
complexity has been recently studied by Arthur et al (FUN'2010). The flooding
dynamics used in those games can be defined for any colored graph. It has been
shown in a first report (in french, hal-00509488 on HAL archive) that studying
this dynamics directly on general graph is a valuable approach to understand
its specificities and extract uncluttered key patterns or algorithms that can
be applied with success to particular cases like the square grid of FLOODIT or
the hexagonal grid of MADVIRUS, and many other classes of graphs. This report
is the translation from french to english of the section in the french report
showing that the variant of the problem called 2-FREE-FLOOD-IT can be solved
with a polynomial algorithm, answering a question raised in the previous study
of FLOODIT by Arthur et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3104</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3104</id><created>2010-08-18</created><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author><author><keyname>Zivny</keyname><forenames>Stanislav</forenames></author></authors><title>Generalising tractable VCSPs defined by symmetric tournament pair
  multimorphisms</title><categories>cs.CC</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study optimisation problems that can be formulated as valued constraint
satisfaction problems (VCSP). A problem from VCSP is characterised by a
\emph{constraint language}, a fixed set of cost functions taking finite and
infinite costs over a finite domain. An instance of the problem is specified by
a sum of cost functions from the language and the goal is to minimise the sum.
We are interested in \emph{tractable} constraint languages; that is, languages
that give rise to VCSP instances solvable in polynomial time. Cohen et al.
(AIJ'06) have shown that constraint languages that admit the MJN multimorphism
are tractable. Moreover, using a minimisation algorithm for submodular
functions, Cohen et al. (TCS'08) have shown that constraint languages that
admit an STP (symmetric tournament pair) multimorphism are tractable.
  We generalise these results by showing that languages admitting the MJN
multimorphism on a subdomain and an STP multimorphisms on the complement of the
subdomain are tractable. The algorithm is a reduction to the algorithm for
languages admitting an STP multimorphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3123</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3123</id><created>2010-08-18</created><authors><author><keyname>Gradwohl</keyname><forenames>Ronen</forenames></author><author><keyname>Livne</keyname><forenames>Noam</forenames></author><author><keyname>Rosen</keyname><forenames>Alon</forenames></author></authors><title>Sequential Rationality in Cryptographic Protocols</title><categories>cs.GT cs.CR</categories><comments>Extended abstract in FOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of the literature on rational cryptography focuses on analyzing the
strategic properties of cryptographic protocols. However, due to the presence
of computationally-bounded players and the asymptotic nature of cryptographic
security, a definition of sequential rationality for this setting has thus far
eluded researchers.
  We propose a new framework for overcoming these obstacles, and provide the
first definitions of computational solution concepts that guarantee sequential
rationality. We argue that natural computational variants of subgame perfection
are too strong for cryptographic protocols. As an alternative, we introduce a
weakening called threat-free Nash equilibrium that is more permissive but still
eliminates the undesirable ``empty threats'' of non-sequential solution
concepts.
  To demonstrate the applicability of our framework, we revisit the problem of
implementing a mediator for correlated equilibria (Dodis-Halevi-Rabin,
Crypto'00), and propose a variant of their protocol that is sequentially
rational for a non-trivial class of correlated equilibria. Our treatment
provides a better understanding of the conditions under which mediators in a
correlated equilibrium can be replaced by a stable protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3136</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3136</id><created>2010-08-18</created><authors><author><keyname>Jiang</keyname><forenames>C.</forenames></author><author><keyname>Wang</keyname><forenames>M.</forenames></author><author><keyname>Yang</keyname><forenames>C.</forenames></author></authors><title>MIMO Precoding Using Rotating Codebooks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next generation wireless communications rely on multiple input multiple
output (MIMO) techniques to achieve high data rates. Feedback of channel
information can be used in MIMO precoding to fully activate the strongest
channel modes and improve MIMO performance. Unfortunately, the bandwidth of the
control channel via which the feedback is conveyed is severely limited. An
important issue is how to improve the MIMO precoding performance with minimal
feedback. In this letter, we present a method that uses a rotating codebook
technique to effectively improve the precoding performance without the need of
increasing feedback overhead. The basic idea of the rotating codebook precoding
is to expend the effective precoding codebook size via rotating multiple
codebooks so that the number of feedback bits remains unchanged. Simulation
results are presented to show the performance gain of the proposed rotating
codebook precoding over the conventional precoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3146</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3146</id><created>2010-08-18</created><updated>2011-02-26</updated><authors><author><keyname>Fannjiang</keyname><forenames>Albert</forenames></author></authors><title>Exact Localization and Superresolution with Noisy Data and Random
  Illumination</title><categories>cs.IT math.IT math.PR physics.data-an physics.optics</categories><comments>28pages, 11 figures; fix minor errors of v1; add a new section on
  extended objects and a few figures</comments><doi>10.1088/0266-5611/27/6/065012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of exact localization of sparse (point or
extended) objects with noisy data. The crux of the proposed approach consists
of random illumination. Several recovery methods are analyzed: the Lasso, BPDN
and the One-Step Thresholding (OST). For independent random probes, it is shown
that both recovery methods can localize exactly $s=\cO(m)$, up to a logarithmic
factor, objects where $m$ is the number of data. Moreover, when the number of
random probes is large the Lasso with random illumination has a performance
guarantee for superresolution, beating the Rayleigh resolution limit. Numerical
evidence confirms the predictions and indicates that the performance of the
Lasso is superior to that of the OST for the proposed set-up with random
illumination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3147</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3147</id><created>2010-08-18</created><authors><author><keyname>Milazzo</keyname><forenames>Paolo</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Jim&#xe9;nez</keyname><forenames>Mario de J. P&#xe9;rez</forenames><affiliation>Universidad de Sevilla</affiliation></author></authors><title>Proceedings First Workshop on Applications of Membrane computing,
  Concurrency and Agent-based modelling in POPulation biology</title><categories>cs.CE cs.MA</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 33, 2010</journal-ref><doi>10.4204/EPTCS.33</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the first International Workshop
on Applications of Membrane Computing, Concurrency and Agent-based Modelling in
Population Biology (AMCA-POP 2010) held in Jena, Germany on August 25th, 2010
as a satellite event of the 11th Conference on Membrane Computing (CMC11).
  The aim of the workshop is to investigate whether formal modelling and
analysis techniques could be applied with profit to systems of interest for
population biology and ecology. The considered modelling notations include
membrane systems, Petri nets, agent-based notations, process calculi,
automata-based notations, rewriting systems and cellular automata. Such
notations enable the application of analysis techniques such as simulation,
model checking, abstract interpretation and type systems to study systems of
interest in disciplines such as population biology, ecosystem science,
epidemiology, genetics, sustainability science, evolution and other disciplines
in which population dynamics and interactions with the environment are studied.
Papers contain results and experiences in the modelling and analysis of systems
of interest in these fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3163</identifier>
 <datestamp>2014-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3163</id><created>2010-08-18</created><updated>2014-04-18</updated><authors><author><keyname>Boothby</keyname><forenames>Tomas</forenames></author><author><keyname>Henrich</keyname><forenames>Allison</forenames></author><author><keyname>Leaf</keyname><forenames>Alexander</forenames></author></authors><title>Minimal Diagrams of Free Knots</title><categories>math.CO cs.DM math.GT</categories><comments>Paper significantly changed: graph theoretical work removed to focus
  on knot theoretical results; 8 pages, 9 figures</comments><msc-class>57M27</msc-class><journal-ref>Journal of Knot Theory and Its Ramifications Vol. 23, No. 06
  (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manturov recently introduced the idea of a free knot, i.e. an equivalence
class of virtual knots where equivalence is generated by crossing change and
virtualization moves. He showed that if a free knot diagram is associated to a
graph that is irreducibly odd, then it is minimal with respect to the number of
classical crossings. Not all minimal diagrams of free knots are associated to
irreducibly odd graphs, however. We introduce a family of free knot diagrams
that arise from certain permutations that are minimal but not irreducibly odd.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3169</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3169</id><created>2010-08-18</created><updated>2010-11-26</updated><authors><author><keyname>Danescu-Niculescu-Mizil</keyname><forenames>Cristian</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author></authors><title>Don't 'have a clue'? Unsupervised co-learning of downward-entailing
  operators</title><categories>cs.CL</categories><comments>pp 1-6 are identical to the ACL 2010 published version; pp. 7-8 are
  the &quot;externally-available appendices&quot;. Revision contains an additional
  appendix correcting the origin of the term &quot;pseudo-polarity item&quot;</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of the ACL Short Papers, pp. 247-252, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers in textual entailment have begun to consider inferences involving
'downward-entailing operators', an interesting and important class of lexical
items that change the way inferences are made. Recent work proposed a method
for learning English downward-entailing operators that requires access to a
high-quality collection of 'negative polarity items' (NPIs). However, English
is one of the very few languages for which such a list exists. We propose the
first approach that can be applied to the many languages for which there is no
pre-existing high-precision database of NPIs. As a case study, we apply our
method to Romanian and show that our method yields good results. Also, we
perform a cross-linguistic analysis that suggests interesting connections to
some findings in linguistic typology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3171</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3171</id><created>2010-08-18</created><updated>2010-10-06</updated><authors><author><keyname>Sze</keyname><forenames>Tsz-Wo</forenames></author></authors><title>The Two Quadrillionth Bit of Pi is 0! Distributed Computation of Pi with
  Apache Hadoop</title><categories>cs.DC math.NT</categories><comments>9 pages, 2 figures, 3 tables</comments><msc-class>68Q85, 68M14, 11-04</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new record on computing specific bits of Pi, the mathematical
constant, and discuss performing such computations on Apache Hadoop clusters.
The specific bits represented in hexadecimal are 0E6C1294 AED40403 F56D2D76
4026265B CA98511D 0FCFFAA1 0F4D28B1 BB5392B8. These 256 bits end at the
2,000,000,000,000,252nd bit position, which doubles the position and quadruples
the precision of the previous known record. The position of the first bit is
1,999,999,999,999,997 and the value of the two quadrillionth bit is 0. The
computation is carried out by a MapReduce program called DistBbp. To
effectively utilize available cluster resources without monopolizing the whole
cluster, we develop an elastic computation framework that automatically
schedules computation slices, each a DistBbp job, as either map-side or
reduce-side computation based on changing cluster load condition. We have
calculated Pi at varying bit positions and precisions, and one of the largest
computations took 23 days of wall clock time and 503 years of CPU time on a
1000-node cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3172</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3172</id><created>2010-08-18</created><authors><author><keyname>Pickard</keyname><forenames>Galen</forenames></author><author><keyname>Rahwan</keyname><forenames>Iyad</forenames></author><author><keyname>Pan</keyname><forenames>Wei</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Crane</keyname><forenames>Riley</forenames></author><author><keyname>Madan</keyname><forenames>Anmol</forenames></author><author><keyname>Pentland</keyname><forenames>Alex</forenames></author></authors><title>Time Critical Social Mobilization: The DARPA Network Challenge Winning
  Strategy</title><categories>cs.CY</categories><comments>25 pages, 6 figures</comments><journal-ref>Science 28 October 2011: Vol. 334 no. 6055 pp. 509-512</journal-ref><doi>10.1126/science.1205869</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now commonplace to see the Web as a platform that can harness the
collective abilities of large numbers of people to accomplish tasks with
unprecedented speed, accuracy and scale. To push this idea to its limit, DARPA
launched its Network Challenge, which aimed to &quot;explore the roles the Internet
and social networking play in the timely communication, wide-area
team-building, and urgent mobilization required to solve broad-scope,
time-critical problems.&quot; The challenge required teams to provide coordinates of
ten red weather balloons placed at different locations in the continental
United States. This large-scale mobilization required the ability to spread
information about the tasks widely and quickly, and to incentivize individuals
to act. We report on the winning team's strategy, which utilized a novel
recursive incentive mechanism to find all balloons in under nine hours. We
analyze the theoretical properties of the mechanism, and present data about its
performance in the challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3187</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3187</id><created>2010-08-18</created><authors><author><keyname>Gopalan</keyname><forenames>Parikshit</forenames></author><author><keyname>Klivans</keyname><forenames>Adam</forenames></author><author><keyname>Meka</keyname><forenames>Raghu</forenames></author></authors><title>Polynomial-Time Approximation Schemes for Knapsack and Related Counting
  Problems using Branching Programs</title><categories>cs.DS cs.CC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a deterministic, polynomial-time algorithm for approximately counting
the number of {0,1}-solutions to any instance of the knapsack problem. On an
instance of length n with total weight W and accuracy parameter eps, our
algorithm produces a (1 + eps)-multiplicative approximation in time poly(n,log
W,1/eps). We also give algorithms with identical guarantees for general integer
knapsack, the multidimensional knapsack problem (with a constant number of
constraints) and for contingency tables (with a constant number of rows).
Previously, only randomized approximation schemes were known for these problems
due to work by Morris and Sinclair and work by Dyer.
  Our algorithms work by constructing small-width, read-once branching programs
for approximating the underlying solution space under a carefully chosen
distribution. As a byproduct of this approach, we obtain new query algorithms
for learning functions of k halfspaces with respect to the uniform distribution
on {0,1}^n. The running time of our algorithm is polynomial in the accuracy
parameter eps. Previously even for the case of k=2, only algorithms with an
exponential dependence on eps were known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3190</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3190</id><created>2010-08-18</created><authors><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Partitions and Coverings of Trees by Bounded-Degree Subtrees</title><categories>math.CO cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the following questions for a given tree $T$ and integer
$d\geq2$: (1) What is the minimum number of degree-$d$ subtrees that partition
$E(T)$? (2) What is the minimum number of degree-$d$ subtrees that cover
$E(T)$? We answer the first question by providing an explicit formula for the
minimum number of subtrees, and we describe a linear time algorithm that finds
the corresponding partition. For the second question, we present a polynomial
time algorithm that computes a minimum covering. We then establish a tight
bound on the number of subtrees in coverings of trees with given maximum degree
and pathwidth. Our results show that pathwidth is the right parameter to
consider when studying coverings of trees by degree-3 subtrees. We briefly
consider coverings of general graphs by connected subgraphs of bounded degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3193</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3193</id><created>2010-08-18</created><authors><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author><author><keyname>Liotta</keyname><forenames>Giuseppe</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Proximity Drawings of High-Degree Trees</title><categories>cs.CG cs.DS math.CO</categories><journal-ref>International J. of Computational Geometry and Applications
  23:213-230, 2013</journal-ref><doi>10.1142/S0218195913500088</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A drawing of a given (abstract) tree that is a minimum spanning tree of the
vertex set is considered aesthetically pleasing. However, such a drawing can
only exist if the tree has maximum degree at most 6. What can be said for trees
of higher degree? We approach this question by supposing that a partition or
covering of the tree by subtrees of bounded degree is given. Then we show that
if the partition or covering satisfies some natural properties, then there is a
drawing of the entire tree such that each of the given subtrees is drawn as a
minimum spanning tree of its vertex set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3196</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3196</id><created>2010-08-18</created><authors><author><keyname>Torrieri</keyname><forenames>Don</forenames></author><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Kwon</keyname><forenames>Hyuck</forenames></author></authors><title>Coded DS-CDMA Systems with Iterative Channel Estimation and no Pilot
  Symbols</title><categories>cs.IT math.IT</categories><comments>To appear, IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe direct-sequence code-division multiple-access
(DS-CDMA) systems with quadriphase-shift keying in which channel estimation,
coherent demodulation, and decoding are iteratively performed without the use
of any training or pilot symbols. An expectation-maximization
channel-estimation algorithm for the fading amplitude, phase, and the
interference power spectral density (PSD) due to the combined interference and
thermal noise is proposed for DS-CDMA systems with irregular repeat-accumulate
codes. After initial estimates of the fading amplitude, phase, and interference
PSD are obtained from the received symbols, subsequent values of these
parameters are iteratively updated by using the soft feedback from the channel
decoder. The updated estimates are combined with the received symbols and
iteratively passed to the decoder. The elimination of pilot symbols simplifies
the system design and allows either an enhanced information throughput, an
improved bit error rate, or greater spectral efficiency. The interference-PSD
estimation enables DS-CDMA systems to significantly suppress interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3199</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3199</id><created>2010-08-18</created><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Kwon</keyname><forenames>Hyuck</forenames></author></authors><title>General Auction-Theoretic Strategies for Distributed Partner Selection
  in Cooperative Wireless Networks</title><categories>cs.IT math.IT</categories><comments>13 pages, to appear, IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is unrealistic to assume that all nodes in an ad hoc wireless network
would be willing to participate in cooperative communication, especially if
their desired Quality-of- Service (QoS) is achievable via direct transmission.
An incentivebased auction mechanism is presented to induce cooperative behavior
in wireless networks with emphasis on users with asymmetrical channel fading
conditions. A single-object secondprice auction is studied for cooperative
partner selection in singlecarrier networks. In addition, a multiple-object
bundled auction is analyzed for the selection of multiple simultaneous partners
in a cooperative orthogonal frequency-division multiplexing (OFDM) setting. For
both cases, we characterize equilibrium outage probability performance, seller
revenue, and feedback bounds. The auction-based partner selection allows
winning bidders to achieve their desired QoS while compensating the seller who
assists them. At the local level sellers aim for revenue maximization, while
connections are drawn to min-max fairness at the network level. The proposed
strategies for partner selection in self-configuring cooperative wireless
networks are shown to be robust under conditions of uncertainty in the number
of users requesting cooperation, as well as minimal topology and channel link
information available to individual users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3208</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3208</id><created>2010-08-19</created><authors><author><keyname>Behsaz</keyname><forenames>Babak</forenames></author><author><keyname>Hatami</keyname><forenames>Pooya</forenames></author><author><keyname>Mahmoodian</keyname><forenames>Ebadollah S.</forenames></author></authors><title>On minimum vertex cover of generalized Petersen graphs</title><categories>cs.DM</categories><comments>11 pages, 1 figure,</comments><journal-ref>Australasian Journal of Combinatorics, Vol. 40 (2007) pp. 253-264</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For natural numbers $n$ and $k$ ($n &gt; 2k$), a generalized Petersen graph
$P(n,k)$, is defined by vertex set $\lbrace u_i,v_i\rbrace$ and edge set
$\lbrace u_iu_{i+1},u_iv_i,v_iv_{i+k}\rbrace$; where $i = 1,2,\dots,n$ and
subscripts are reduced modulo $n$. Here first, we characterize minimum vertex
covers in generalized Petersen graphs. Second, we present a lower bound and
some upper bounds for $\beta(P(n,k))$, the size of minimum vertex cover of
$P(n,k)$. Third, in some cases, we determine the exact values of
$\beta(P(n,k))$. Our conjecture is that $\beta(P(n,k)) \le n +
\lceil\frac{n}{5}\rceil$, for all $n$ and $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3216</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3216</id><created>2010-08-19</created><authors><author><keyname>Hatami</keyname><forenames>Pooya</forenames></author></authors><title>An approximation algorithm for the total cover problem</title><categories>cs.DS</categories><comments>5 pages, 1 figure</comments><journal-ref>Discussiones Mathematicae Graph Theory, Vol. 27, No.3 (2007) pp.
  553-560</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a $2$-approximation algorithm for the minimum total covering
number problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3217</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3217</id><created>2010-08-19</created><authors><author><keyname>Akbari</keyname><forenames>Saeed</forenames></author><author><keyname>Bolouki</keyname><forenames>Sadegh</forenames></author><author><keyname>Hatami</keyname><forenames>Pooya</forenames></author><author><keyname>Siami</keyname><forenames>Milad</forenames></author></authors><title>On The Signed Edge Domination Number of Graphs</title><categories>cs.DM</categories><journal-ref>Discrete Mathematics. Vol. 309, Issue 3 (2009) pp. 587-594</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\gamma'_s(G)$ be the signed edge domination number of G. In 2006, Xu
conjectured that: for any $2$-connected graph G of order $ n (n \geq 2),$
$\gamma'_s(G)\geq 1$. In this article we show that this conjecture is not true.
More precisely, we show that for any positive integer $m$, there exists an
$m$-connected graph $G$ such that $ \gamma'_s(G)\leq -\frac{m}{6}|V(G)|.$ Also
for every two natural numbers $m$ and $n$, we determine $\gamma'_s(K_{m,n})$,
where $K_{m,n}$ is the complete bipartite graph with part sizes $m$ and $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3222</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3222</id><created>2010-08-19</created><authors><author><keyname>Sloth</keyname><forenames>Christoffer</forenames></author><author><keyname>Wisniewski</keyname><forenames>Rafael</forenames></author></authors><title>Proofs for an Abstraction of Continuous Dynamical Systems Utilizing
  Lyapunov Functions</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report proofs are presented for a method for abstracting continuous
dynamical systems by timed automata. The method is based on partitioning the
state space of dynamical systems with invariant sets, which form cells
representing locations of the timed automata.
  To enable verification of the dynamical system based on the abstraction,
conditions for obtaining sound, complete, and refinable abstractions are set
up.
  It is proposed to partition the state space utilizing sub-level sets of
Lyapunov functions, since they are positive invariant sets. The existence of
sound abstractions for Morse-Smale systems and complete and refinable
abstractions for linear systems are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3253</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3253</id><created>2010-08-19</created><authors><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author><author><keyname>Leicher</keyname><forenames>Andreas</forenames></author><author><keyname>Shah</keyname><forenames>Yogendra</forenames></author><author><keyname>Cha</keyname><forenames>Inhyok</forenames></author></authors><title>Secure Operations on Tree-Formed Verification Data</title><categories>cs.CR</categories><comments>9 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define secure operations with tree-formed, protected verification data
registers. Functionality is conceptually added to Trusted Platform Modules
(TPMs) to handle Platform Configuration Registers (PCRs) which represent roots
of hash trees protecting the integrity of tree-formed Stored Measurement Logs
(SMLs). This enables verification and update of an inner node of an SML and
even attestation to its value with the same security level as for ordinary
PCRs. As an important application, it is shown how certification of SML
subtrees enables attestation of platform properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3282</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3282</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Khaled</keyname><forenames>Shah Mostafa</forenames></author><author><keyname>Farhan</keyname><forenames>Khalid</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Abdur</forenames></author><author><keyname>Rahman</keyname><forenames>Joy</forenames></author></authors><title>Modeling Spammer Behavior: Na\&quot;ive Bayes vs. Artificial Neural Networks</title><categories>cs.IR cs.AI</categories><comments>4 pages, 1 figure, 3 tables</comments><journal-ref>Proc. of IEEE ICIMT, Jeju Island, South Korea, December 16-18,
  2009, pp. 52-55</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Addressing the problem of spam emails in the Internet, this paper presents a
comparative study on Na\&quot;ive Bayes and Artificial Neural Networks (ANN) based
modeling of spammer behavior. Keyword-based spam email filtering techniques
fall short to model spammer behavior as the spammer constantly changes tactics
to circumvent these filters. The evasive tactics that the spammer uses are
themselves patterns that can be modeled to combat spam. It has been observed
that both Na\&quot;ive Bayes and ANN are best suitable for modeling spammer common
patterns. Experimental results demonstrate that both of them achieve a
promising detection rate of around 92%, which is considerably an improvement of
performance compared to the keyword-based contemporary filtering approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3287</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3287</id><created>2010-08-19</created><updated>2015-04-18</updated><authors><author><keyname>Wu</keyname><forenames>Haoyang</forenames></author></authors><title>A note on revelation principle from an energy perspective</title><categories>cs.GT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The revelation principle has been known in the economics society for decades.
In this paper, I will investigate it from an energy perspective, i.e.,
considering the energy consumed by agents and the designer in participating a
mechanism. The main result is that when the strategies of agents are actions
rather than messages, an additional energy condition should be added to make
the revelation principle hold in the real world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3288</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3288</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Begum</keyname><forenames>Zerina</forenames></author></authors><title>Reversible Logic Synthesis of Fault Tolerant Carry Skip BCD Adder</title><categories>cs.AR</categories><comments>9 pages, 7 figures, 5 tables</comments><journal-ref>Bangladesh Academy of Science Journal, Vol. 32, No. 2, pp.
  193-200, December 2008</journal-ref><doi>10.3329/jbas.v32i2.2431</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic is emerging as an important research area having its
application in diverse fields such as low power CMOS design, digital signal
processing, cryptography, quantum computing and optical information processing.
This paper presents a new 4*4 parity preserving reversible logic gate, IG. The
proposed parity preserving reversible gate can be used to synthesize any
arbitrary Boolean function. It allows any fault that affects no more than a
single signal readily detectable at the circuit's primary outputs. It is shown
that a fault tolerant reversible full adder circuit can be realized using only
two IGs. The proposed fault tolerant full adder (FTFA) is used to design other
arithmetic logic circuits for which it is used as the fundamental building
block. It has also been demonstrated that the proposed design offers less
hardware complexity and is efficient in terms of gate count, garbage outputs
and constant inputs than the existing counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3289</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3289</id><created>2010-08-19</created><authors><author><keyname>Moradi</keyname><forenames>Farnaz</forenames></author><author><keyname>Olovsson</keyname><forenames>Tomas</forenames></author><author><keyname>Tsigas</keyname><forenames>Philippas</forenames></author></authors><title>Analyzing the Social Structure and Dynamics of E-mail and Spam in
  Massive Backbone Internet Traffic</title><categories>cs.SI</categories><comments>15 pages, 20 figures, technical report</comments><report-no>Technical Report no. 2010-03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E-mail is probably the most popular application on the Internet, with
everyday business and personal communications dependent on it. Spam or
unsolicited e-mail has been estimated to cost businesses significant amounts of
money. However, our understanding of the network-level behavior of legitimate
e-mail traffic and how it differs from spam traffic is limited. In this study,
we have passively captured SMTP packets from a 10 Gbit/s Internet backbone link
to construct a social network of e-mail users based on their exchanged e-mails.
The focus of this paper is on the graph metrics indicating various structural
properties of e-mail networks and how they evolve over time. This study also
looks into the differences in the structural and temporal characteristics of
spam and non-spam networks. Our analysis on the collected data allows us to
show several differences between the behavior of spam and legitimate e-mail
traffic, which can help us to understand the behavior of spammers and give us
the knowledge to statistically model spam traffic on the network-level in order
to complement current spam detection techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3295</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3295</id><created>2010-08-19</created><updated>2011-01-14</updated><authors><author><keyname>Thakur</keyname><forenames>Mohit</forenames></author><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Optimal relay location and power allocation for low SNR broadcast relay
  channels</title><categories>cs.IT cs.NI math.IT</categories><comments>In Proceedings of INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the broadcast relay channel (BRC), where a single source
transmits to multiple destinations with the help of a relay, in the limit of a
large bandwidth. We address the problem of optimal relay positioning and power
allocations at source and relay, to maximize the multicast rate from source to
all destinations. To solve such a network planning problem, we develop a
three-faceted approach based on an underlying information theoretic model,
computational geometric aspects, and network optimization tools. Firstly,
assuming superposition coding and frequency division between the source and the
relay, the information theoretic framework yields a hypergraph model of the
wideband BRC, which captures the dependency of achievable rate-tuples on the
network topology. As the relay position varies, so does the set of hyperarcs
constituting the hypergraph, rendering the combinatorial nature of optimization
problem. We show that the convex hull C of all nodes in the 2-D plane can be
divided into disjoint regions corresponding to distinct hyperarcs sets. These
sets are obtained by superimposing all k-th order Voronoi tessellation of C. We
propose an easy and efficient algorithm to compute all hyperarc sets, and prove
they are polynomially bounded. Using the switched hypergraph approach, we model
the original problem as a continuous yet non-convex network optimization
program. Ultimately, availing on the techniques of geometric programming and
$p$-norm surrogate approximation, we derive a good convex approximation. We
provide a detailed characterization of the problem for collinearly located
destinations, and then give a generalization for arbitrarily located
destinations. Finally, we show strong gains for the optimal relay positioning
compared to seemingly interesting positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3301</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3301</id><created>2010-08-19</created><authors><author><keyname>Basuki</keyname><forenames>Thomas Anung</forenames><affiliation>UNU-IIST</affiliation></author><author><keyname>Cerone</keyname><forenames>Antonio</forenames><affiliation>UNU-IIST</affiliation></author><author><keyname>Barbuti</keyname><forenames>Roberto</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Maggiolo-Schettini</keyname><forenames>Andrea</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Milazzo</keyname><forenames>Paolo</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Rossi</keyname><forenames>Elisabetta</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author></authors><title>Modelling the Dynamics of an Aedes albopictus Population</title><categories>cs.CE cs.FL q-bio.PE</categories><comments>In Proceedings AMCA-POP 2010, arXiv:1008.3147</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 33, 2010, pp. 18-36</journal-ref><doi>10.4204/EPTCS.33.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a methodology for modelling population dynamics with formal means
of computer science. This allows unambiguous description of systems and
application of analysis tools such as simulators and model checkers. In
particular, the dynamics of a population of Aedes albopictus (a species of
mosquito) and its modelling with the Stochastic Calculus of Looping Sequences
(Stochastic CLS) are considered. The use of Stochastic CLS to model population
dynamics requires an extension which allows environmental events (such as
changes in the temperature and rainfalls) to be taken into account. A simulator
for the constructed model is developed via translation into the specification
language Maude, and used to compare the dynamics obtained from the model with
real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3303</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3303</id><created>2010-08-19</created><authors><author><keyname>Buti</keyname><forenames>Federico</forenames><affiliation>University of Camerino</affiliation></author><author><keyname>Corradini</keyname><forenames>Flavio</forenames><affiliation>University of Camerino</affiliation></author><author><keyname>Merelli</keyname><forenames>Emanuela</forenames><affiliation>University of Camerino</affiliation></author><author><keyname>Paschini</keyname><forenames>Elio</forenames><affiliation>CNR</affiliation></author><author><keyname>Penna</keyname><forenames>Pierluigi</forenames><affiliation>CNR</affiliation></author><author><keyname>Tesei</keyname><forenames>Luca</forenames><affiliation>University of Camerino</affiliation></author></authors><title>An Individual-based Probabilistic Model for Fish Stock Simulation</title><categories>cs.FL cs.MA q-bio.PE</categories><comments>In Proceedings AMCA-POP 2010, arXiv:1008.3147</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 33, 2010, pp. 37-55</journal-ref><doi>10.4204/EPTCS.33.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define an individual-based probabilistic model of a sole (Solea solea)
behaviour. The individual model is given in terms of an Extended Probabilistic
Discrete Timed Automaton (EPDTA), a new formalism that is introduced in the
paper and that is shown to be interpretable as a Markov decision process. A
given EPDTA model can be probabilistically model-checked by giving a suitable
translation into syntax accepted by existing model-checkers. In order to
simulate the dynamics of a given population of soles in different environmental
scenarios, an agent-based simulation environment is defined in which each agent
implements the behaviour of the given EPDTA model. By varying the probabilities
and the characteristic functions embedded in the EPDTA model it is possible to
represent different scenarios and to tune the model itself by comparing the
results of the simulations with real data about the sole stock in the North
Adriatic sea, available from the recent project SoleMon. The simulator is
presented and made available for its adaptation to other species.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3304</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3304</id><created>2010-08-19</created><authors><author><keyname>Besozzi</keyname><forenames>Daniela</forenames><affiliation>Universit&#xe0; degli Studi di Milano</affiliation></author><author><keyname>Cazzaniga</keyname><forenames>Paolo</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>Pescini</keyname><forenames>Dario</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>Mauri</keyname><forenames>Giancarlo</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author></authors><title>An Analysis on the Influence of Network Topologies on Local and Global
  Dynamics of Metapopulation Systems</title><categories>cs.CE q-bio.PE</categories><comments>In Proceedings AMCA-POP 2010, arXiv:1008.3147</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 33, 2010, pp. 1-17</journal-ref><doi>10.4204/EPTCS.33.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metapopulations are models of ecological systems, describing the interactions
and the behavior of populations that live in fragmented habitats. In this
paper, we present a model of metapopulations based on the multivolume
simulation algorithm tau-DPP, a stochastic class of membrane systems, that we
utilize to investigate the influence that different habitat topologies can have
on the local and global dynamics of metapopulations. In particular, we focus
our analysis on the migration rate of individuals among adjacent patches, and
on their capability of colonizing the empty patches in the habitat. We compare
the simulation results obtained for each habitat topology, and conclude the
paper with some proposals for other research issues concerning metapopulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3305</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3305</id><created>2010-08-19</created><authors><author><keyname>De Francesco</keyname><forenames>Nicoletta</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Lettieri</keyname><forenames>Giuseppe</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Martini</keyname><forenames>Luca</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author></authors><title>Celer: an Efficient Program for Genotype Elimination</title><categories>cs.DS cs.CE</categories><comments>In Proceedings AMCA-POP 2010, arXiv:1008.3147</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 33, 2010, pp. 56-70</journal-ref><doi>10.4204/EPTCS.33.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient program for checking Mendelian consistency
in a pedigree. Since pedigrees may contain incomplete and/or erroneous
information, geneticists need to pre-process them before performing linkage
analysis. Removing superfluous genotypes that do not respect the Mendelian
inheritance laws can speed up the linkage analysis. We have described in a
formal way the Mendelian consistency problem and algorithms known in
literature. The formalization helped to polish the algorithms and to find
efficient data structures. The performance of the tool has been tested on a
wide range of benchmarks. The results are promising if compared to other
programs that treat Mendelian consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3306</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3306</id><created>2010-08-19</created><authors><author><keyname>Kefalas</keyname><forenames>Petros</forenames><affiliation>CITY College</affiliation></author><author><keyname>Stamatopoulou</keyname><forenames>Ioanna</forenames><affiliation>CITY College</affiliation></author></authors><title>Modelling of Multi-Agent Systems: Experiences with Membrane Computing
  and Future Challenges</title><categories>cs.MA cs.FL</categories><comments>In Proceedings AMCA-POP 2010, arXiv:1008.3147</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 33, 2010, pp. 71-82</journal-ref><doi>10.4204/EPTCS.33.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal modelling of Multi-Agent Systems (MAS) is a challenging task due to
high complexity, interaction, parallelism and continuous change of roles and
organisation between agents. In this paper we record our research experience on
formal modelling of MAS. We review our research throughout the last decade, by
describing the problems we have encountered and the decisions we have made
towards resolving them and providing solutions. Much of this work involved
membrane computing and classes of P Systems, such as Tissue and Population P
Systems, targeted to the modelling of MAS whose dynamic structure is a
prominent characteristic. More particularly, social insects (such as colonies
of ants, bees, etc.), biology inspired swarms and systems with emergent
behaviour are indicative examples for which we developed formal MAS models.
Here, we aim to review our work and disseminate our findings to fellow
researchers who might face similar challenges and, furthermore, to discuss
important issues for advancing research on the application of membrane
computing in MAS modelling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3310</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3310</id><created>2010-08-19</created><updated>2010-10-06</updated><authors><author><keyname>Freij</keyname><forenames>Ragnar</forenames></author><author><keyname>W&#xe4;stlund</keyname><forenames>Johan</forenames></author></authors><title>Partially ordered secretaries</title><categories>math.OC cs.DS math.PR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The elements of a finite nonempty partially ordered set are exposed at
independent uniform times in $[0,1]$ to a selector who, at any given time, can
see the structure of the induced partial order on the exposed elements. The
selector's task is to choose online a maximal element. This generalizes the
classical linear order secretary problem, for which it is known that the
selector can succeed with probability $1/e$ and that this is best possible. We
describe a strategy for the general problem that achieves success probability
$1/e$ for an arbitrary partial order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3311</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3311</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammad Mahbubur</forenames></author><author><keyname>Begum</keyname><forenames>Zerina</forenames></author><author><keyname>Hafiz</keyname><forenames>Mohd. Zulfiquar</forenames></author></authors><title>Fault tolerant reversible logic synthesis: Carry look-ahead and
  carry-skip adders</title><categories>cs.AR</categories><comments>6 pages, 15 figures, 1 table</comments><journal-ref>IEEE International Conference on Advances in Computational Tools
  for Engineering Applications,pp. 396-401, 2009</journal-ref><doi>10.1109/ACTEA.2009.5227871</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Irreversible logic circuits dissipate heat for every bit of information that
is lost. Information is lost when the input vector cannot be recovered from its
corresponding output vector. Reversible logic circuit naturally takes care of
heating because it implements only the functions that have one-to-one mapping
between its input and output vectors. Therefore reversible logic design becomes
one of the promising research directions in low power dissipating circuit
design in the past few years and has found its application in low power CMOS
design, digital signal processing and nanotechnology. This paper presents the
efficient approaches for designing reversible fast adders that implement carry
look-ahead and carry-skip logic. The proposed 16-bit high speed reversible
adder will include IG gates for the realization of its basic building block.
The IG gate is universal in the sense that it can be used to synthesize any
arbitrary Boolean-functions. The IG gate is parity preserving, that is, the
parity of the inputs matches the parity of the outputs. It allows any fault
that affects no more than a single signal readily detectable at the circuit's
primary outputs. Therefore, the proposed high speed adders will have the
inherent opportunity of detecting errors in its output side. It has also been
demonstrated that the proposed design offers less hardware complexity and is
efficient in terms of gate count, garbage outputs and constant inputs than the
existing counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3314</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3314</id><created>2010-08-19</created><authors><author><keyname>De Bie</keyname><forenames>Tijl</forenames></author></authors><title>Maximum entropy models and subjective interestingness: an application to
  tiles in binary databases</title><categories>cs.AI</categories><comments>43 pages, submitted</comments><report-no>University of Bristol Tech. Rep. 125861</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has highlighted the practical benefits of subjective
interestingness measures, which quantify the novelty or unexpectedness of a
pattern when contrasted with any prior information of the data miner
(Silberschatz and Tuzhilin, 1995; Geng and Hamilton, 2006). A key challenge
here is the formalization of this prior information in a way that lends itself
to the definition of an interestingness subjective measure that is both
meaningful and practical.
  In this paper, we outline a general strategy of how this could be achieved,
before working out the details for a use case that is important in its own
right.
  Our general strategy is based on considering prior information as constraints
on a probabilistic model representing the uncertainty about the data. More
specifically, we represent the prior information by the maximum entropy
(MaxEnt) distribution subject to these constraints. We briefly outline various
measures that could subsequently be used to contrast patterns with this MaxEnt
model, thus quantifying their subjective interestingness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3320</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3320</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Rafiqul</forenames></author><author><keyname>Karim</keyname><forenames>Muhammad Rezaul</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Babu</keyname><forenames>Hafiz Md. Hasan</forenames></author></authors><title>Efficient Wrapper/TAM Co-Optimization for SOC Using Rectangle Packing</title><categories>cs.OH</categories><comments>4 pages, 6 figures, 2 tables</comments><journal-ref>10th International Symposium on Integrated Circuits, Devices and
  Systems, pp. 397-400, 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The testing time for a system-on-chip(SOC) largely depends on the design of
test wrappers and the test access mechanism(TAM).Wrapper/TAM co-optimization is
therefore necessary to minimize SOC testing time . In this paper, we propose an
efficient algorithm to construct wrappers that reduce testing time for cores.
We further propose a new approach for wrapper/TAM co-optimization based on
two-dimensional rectangle packing. This approach considers the diagonal length
of the rectangles to emphasize on both TAM widths required by a core and its
corresponding testing time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3321</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3321</id><created>2010-08-19</created><authors><author><keyname>Begum</keyname><forenames>Zerina</forenames></author><author><keyname>Khan</keyname><forenames>Mohammed Shafiul Alam</forenames></author><author><keyname>Hafiz</keyname><forenames>Mohd. Zulfiquar</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Shoyaib</keyname><forenames>Md.</forenames></author></authors><title>Software Development Standard and Software Engineering Practice: A Case
  Study of Bangladesh</title><categories>cs.SE</categories><comments>13 pages, 3 figures, 11 tables</comments><journal-ref>Bangladesh Academy of Science Journal, Vol. 32, No. 2, pp.
  201-210, December 2008</journal-ref><doi>10.3329/jbas.v32i2.2432</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improving software process to achieve high quality in a software development
organization is the key factor to success. Bangladeshi software firms have not
experienced much in this particular area in comparison to other countries. The
ISO 9001 and CMM standard has become a basic part of software development. The
main objectives of our study are: 1) To understand the software development
process uses by the software developer firms in Bangladesh 2) To identify the
development practices based on established quality standard and 3) To establish
a standardized and coherent process for the development of software for a
specific project. It is revealed from this research that software industries of
Bangladesh are lacking in target set for software process and improvement,
involvement of quality control activities, and standardize business expertise
practice. This paper investigates the Bangladeshi software industry in the
light of the above challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3328</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3328</id><created>2010-08-18</created><updated>2011-04-21</updated><authors><author><keyname>Akhter</keyname><forenames>Nasrin</forenames></author><author><keyname>Fatema</keyname><forenames>Kaniz</forenames></author><author><keyname>Ferdouse</keyname><forenames>Lilatul</forenames></author><author><keyname>Khandaker</keyname><forenames>Faria</forenames></author></authors><title>Implementation of the Trigonometric LMS Algorithm using Original Cordic
  Rotation</title><categories>cs.OH</categories><comments>12 pages, 5 figures, 1 table. Published in IJCNC;
  http://airccse.org/journal/cnc/0710ijcnc08.pdf,
  http://airccse.org/journal/ijc2010.html</comments><msc-class>68-04</msc-class><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol.2, No.4, July 2010, page. 84-95</journal-ref><doi>10.5121/ijcnc.2010.2408</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The LMS algorithm is one of the most successful adaptive filtering
algorithms. It uses the instantaneous value of the square of the error signal
as an estimate of the mean-square error (MSE). The LMS algorithm changes
(adapts) the filter tap weights so that the error signal is minimized in the
mean square sense. In Trigonometric LMS (TLMS) and Hyperbolic LMS (HLMS), two
new versions of LMS algorithms, same formulations are performed as in the LMS
algorithm with the exception that filter tap weights are now expressed using
trigonometric and hyperbolic formulations, in cases for TLMS and HLMS
respectively. Hence appears the CORDIC algorithm as it can efficiently perform
trigonometric, hyperbolic, linear and logarithmic functions. While
hardware-efficient algorithms often exist, the dominance of the software
systems has kept those algorithms out of the spotlight. Among these hardware-
efficient algorithms, CORDIC is an iterative solution for trigonometric and
other transcendental functions. Former researches worked on CORDIC algorithm to
observe the convergence behavior of Trigonometric LMS (TLMS) algorithm and
obtained a satisfactory result in the context of convergence performance of
TLMS algorithm. But revious researches directly used the CORDIC block output in
their simulation ignoring the internal step-by-step rotations of the CORDIC
processor. This gives rise to a need for verification of the convergence
performance of the TLMS algorithm to investigate if it actually performs
satisfactorily if implemented with step-by-step CORDIC rotation. This research
work has done this job. It focuses on the internal operations of the CORDIC
hardware, implements the Trigonometric LMS (TLMS) and Hyperbolic LMS (HLMS)
algorithms using actual CORDIC rotations. The obtained simulation results are
highly satisfactory and also it shows that convergence behavior of HLMS is much
better than TLMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3340</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3340</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammad Mahbubur</forenames></author><author><keyname>Begum</keyname><forenames>Zerina</forenames></author><author><keyname>Hafiz</keyname><forenames>Mohd. Zulfiquar</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author></authors><title>Synthesis of Fault Tolerant Reversible Logic Circuits</title><categories>cs.AR</categories><comments>4 pages, 9 figures, 7 tables</comments><journal-ref>IEEE International Conference on Testing and Diagnosis, 28-29
  April, 2009, Chengdu, China</journal-ref><doi>10.1109/CAS-ICTD.2009.4960883</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic is emerging as an important research area having its
application in diverse fields such as low power CMOS design, digital signal
processing, cryptography, quantum computing and optical information processing.
This paper presents a new 4*4 universal reversible logic gate, IG. It is a
parity preserving reversible logic gate, that is, the parity of the inputs
matches the parity of the outputs. The proposed parity preserving reversible
gate can be used to synthesize any arbitrary Boolean function. It allows any
fault that affects no more than a single signal readily detectable at the
circuit's primary outputs. Finally, it is shown how a fault tolerant reversible
full adder circuit can be realized using only two IGs. It has also been
demonstrated that the proposed design offers less hardware complexity and is
efficient in terms of gate count, garbage outputs and constant inputs than the
existing counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3344</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3344</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammad Mahbubur</forenames></author><author><keyname>begum</keyname><forenames>Zerina</forenames></author><author><keyname>Hafiz</keyname><forenames>Mohd. Zulfiquar</forenames></author></authors><title>Efficient Approaches for Designing Fault Tolerant Reversible Carry
  Look-Ahead and Carry-Skip Adders</title><categories>cs.AR</categories><comments>6 pages, 15 figures, 1 table</comments><journal-ref>MASAUM Journal of Basic and Applied Sciences (MJBAS), Vol. 1, No.
  3, pp.354-360, October 2009, ISSN 2076-0841</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combinational or Classical logic circuits dissipate heat for every bit of
information that is lost. Information is lost when the input vector cannot be
recovered from its corresponding output vector. Reversible logic circuit
implements only the functions having one-to-one mapping between its input and
output vectors and therefore naturally takes care of heating. Reversible logic
design becomes one of the promising research directions in low power
dissipating circuit design in the past few years and has found its application
in low power CMOS design, digital signal processing and nanotechnology. This
paper presents the efficient approaches for designing fault tolerant reversible
fast adders that implement carry look-ahead and carry-skip logic. The proposed
high speed reversible adders include MIG gates for the realization of its basic
building block. The MIG gate is universal and parity preserving. It allows any
fault that affects no more than a single signal readily detectable at the
circuit's primary outputs. It has also been demonstrated that the proposed
design offers less hardware complexity and is efficient in terms of gate count,
garbage outputs and constant inputs than the existing counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3346</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3346</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Ali</keyname><forenames>Md. Haider</forenames></author></authors><title>A Miniature-Based Image Retrieval System</title><categories>cs.CV</categories><comments>9 pages, 4 figures, 4 tables</comments><journal-ref>Dhaka University Journal of Science,Vol. 57, No. 2, pp. 187-191,
  July 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the rapid development of World Wide Web (WWW) and imaging technology,
more and more images are available in the Internet and stored in databases.
Searching the related images by the querying image is becoming tedious and
difficult. Most of the images on the web are compressed by methods based on
discrete cosine transform (DCT) including Joint Photographic Experts
Group(JPEG) and H.261. This paper presents an efficient content-based image
indexing technique for searching similar images using discrete cosine transform
features. Experimental results demonstrate its superiority with the existing
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3352</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3352</id><created>2010-08-19</created><authors><author><keyname>Islam</keyname><forenames>Md. Rafiqul</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Karim</keyname><forenames>Muhammad Rezaul</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Babu</keyname><forenames>Hafiz Md. Hasan</forenames></author></authors><title>Variable Block Carry Skip Logic using Reversible Gates</title><categories>cs.AR</categories><comments>4 pages, 7 figures, 3 tables</comments><journal-ref>Proc. of 10th International Symposium on Integrated Circuits,
  Devices and Systems, Nanyang Technological University, Suntec, Singapore, pp
  9-12, 8-10 September, 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible circuits have applications in digital signal processing, computer
graphics, quantum computation and cryptography. In this paper, a generalized
k*k reversible gate family is proposed and a 3*3 gate of the family is
discussed. Inverter, AND, OR, NAND, NOR, and EXOR gates can be realized by this
gate. Implementation of a full-adder circuit using two such 3*3 gates is given.
This full-adder circuit contains only two reversible gates and produces no
extra garbage outputs. The proposed full-adder circuit is efficient in terms of
gate count, garbage outputs and quantum cost. A 4-bit carry skip adder is
designed using this full-adder circuit and a variable block carry skip adder is
discussed. Necessary equations required to evaluate these adder are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3357</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3357</id><created>2010-08-19</created><authors><author><keyname>Babu</keyname><forenames>Hafiz Md. Hasaan</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Islam</keyname><forenames>Md. Rafiqul</forenames></author><author><keyname>Jamal</keyname><forenames>Lafifa</forenames></author><author><keyname>Ferdaus</keyname><forenames>Abu Ahmed</forenames></author><author><keyname>Karim</keyname><forenames>Muhammad Rezaul</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author></authors><title>Building Toffoli Network for Reversible Logic Synthesis Based on
  Swapping Bit Strings</title><categories>cs.AR</categories><comments>9 pages</comments><journal-ref>Dhaka University Journal of Science, Vol. 55, No. 2, pp. 153-156,
  2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have implemented and designed a sorting network for
reversible logic circuits synthesis in terms of n*n Toffoli gates. The
algorithm presented in this paper constructs a Toffoli Network based on
swapping bit strings. Reduction rules are then applied by simple template
matching and removing useless gates from the network. Random selection of bit
strings and reduction of control inputs are used to minimize both the number of
gates and gate width. The method produces near optimal results for up to
3-input 3-output circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3366</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3366</id><created>2010-08-19</created><authors><author><keyname>Frackiewicz</keyname><forenames>Piotr</forenames></author></authors><title>Quantum realization of extensive games</title><categories>cs.GT quant-ph</categories><comments>16 pages, 3 figures</comments><msc-class>91A18, 81P45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize a concept of classical finite extensive game to make it useful
for application of quantum objects. The generalization extends a quantum
realization scheme of static games to any finite extensive game. It represents
an extension of any classical finite extensive games to the quantum domain. In
addition our model is compatible with well-known quantum schemes of static
games. The paper is summed up by two examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3402</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3402</id><created>2010-08-19</created><updated>2010-11-05</updated><authors><author><keyname>Waber</keyname><forenames>Benjamin</forenames></author><author><keyname>Pollock</keyname><forenames>Ellen</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Crane</keyname><forenames>Riley</forenames></author><author><keyname>Danon</keyname><forenames>Leon</forenames></author><author><keyname>Pentland</keyname><forenames>Alex</forenames></author></authors><title>Modeling Corporate Epidemiology</title><categories>cs.CY cs.SI</categories><comments>3 pages, 5 figures. Presented at the 2010 Workshop on Information in
  Networks (WIN)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Corporate responses to illness is currently an ad-hoc, subjective process
that has little basis in data on how disease actually spreads at the workplace.
Additionally, many studies have shown that productivity is not an individual
factor but a social one: in any study on epidemic responses this social factor
has to be taken into account. The barrier to addressing this problem has been
the lack of data on the interaction and mobility patterns of people in the
workplace. We have created a wearable Sociometric Badge that senses
interactions between individuals using an infra-red (IR) transceiver and
proximity using a radio transmitter. Using the data from the Sociometric
Badges, we are able to simulate diseases spreading through face-to-face
interactions with realistic epidemiological parameters. In this paper we
construct a curve trading off productivity with epidemic potential. We are able
to take into account impacts on productivity that arise from social factors,
such as interaction diversity and density, which studies that take an
individual approach ignore. We also propose new organizational responses to
diseases that take into account behavioral patterns that are associated with a
more virulent disease spread. This is advantageous because it will allow
companies to decide appropriate responses based on the organizational context
of a disease outbreak.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3408</identifier>
 <datestamp>2012-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3408</id><created>2010-08-19</created><updated>2012-05-02</updated><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Honold</keyname><forenames>Thomas</forenames></author></authors><title>Good Random Matrices over Finite Fields</title><categories>cs.IT math.CO math.IT</categories><comments>25 pages, published</comments><journal-ref>Advances in Mathematics of Communications 6 (2012) 203-227</journal-ref><doi>10.3934/amc.2012.6.203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random matrix uniformly distributed over the set of all m-by-n matrices
over a finite field plays an important role in many branches of information
theory. In this paper a generalization of this random matrix, called k-good
random matrices, is studied. It is shown that a k-good random m-by-n matrix
with a distribution of minimum support size is uniformly distributed over a
maximum-rank-distance (MRD) code of minimum rank distance min{m,n}-k+1, and
vice versa. Further examples of k-good random matrices are derived from
homogeneous weights on matrix modules. Several applications of k-good random
matrices are given, establishing links with some well-known combinatorial
problems. Finally, the related combinatorial concept of a k-dense set of m-by-n
matrices is studied, identifying such sets as blocking sets with respect to
(m-k)-dimensional flats in a certain m-by-n matrix geometry and determining
their minimum size in special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3421</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3421</id><created>2010-08-19</created><authors><author><keyname>Li</keyname><forenames>Chih-ping</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Network Utility Maximization over Partially Observable Markovian
  Channels</title><categories>math.OC cs.NI</categories><comments>9 pages, 2 figures, submitted to IEEE INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a utility maximization problem over partially observable Markov
ON/OFF channels. In this network instantaneous channel states are never known,
and at most one user is selected for service in every slot according to the
partial channel information provided by past observations. Solving the utility
maximization problem directly is difficult because it involves solving
partially observable Markov decision processes. Instead, we construct an
approximate solution by optimizing the network utility only over a good
constrained network capacity region rendered by stationary policies. Using a
novel frame-based Lyapunov drift argument, we design a policy of admission
control and user selection that stabilizes the network with utility that can be
made arbitrarily close to the optimal in the constrained region. Equivalently,
we are dealing with a high-dimensional restless bandit problem with a general
functional objective over Markov ON/OFF restless bandits. Thus the network
control algorithm developed in this paper serves as a new approximation
methodology to attack such complex restless bandit problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3431</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3431</id><created>2010-08-19</created><authors><author><keyname>Dwarampudi</keyname><forenames>Venkatreddy</forenames></author><author><keyname>Dhillon</keyname><forenames>Shahbaz Singh</forenames></author><author><keyname>Shah</keyname><forenames>Jivitesh</forenames></author><author><keyname>Sebastian</keyname><forenames>Nikhil Joseph</forenames></author><author><keyname>Kanigicharla</keyname><forenames>Nitin</forenames></author></authors><title>Comparative study of the Pros and Cons of Programming languages Java,
  Scala, C++, Haskell, VB .NET, AspectJ, Perl, Ruby, PHP &amp; Scheme - a Team 11
  COMP6411-S10 Term Report</title><categories>cs.PL</categories><comments>28 pages, 2 tables</comments><acm-class>D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advent of numerous languages it is difficult to realize the edge of
one language in a particular scope over another one. We are making an effort,
realizing these few issues and comparing some main stream languages like Java,
Scala, C++, Haskell, VB .NET, AspectJ, Perl, Ruby, PHP and Scheme keeping in
mind some core issues in program development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3434</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3434</id><created>2010-08-20</created><authors><author><keyname>Al-Qahtani</keyname><forenames>Sultan S.</forenames></author><author><keyname>Pietrzynski</keyname><forenames>Pawel</forenames></author><author><keyname>Guzman</keyname><forenames>Luis F.</forenames></author><author><keyname>Arif</keyname><forenames>Rafik</forenames></author><author><keyname>Tevoedjre</keyname><forenames>Adrien</forenames></author></authors><title>Comparing Selected Criteria of Programming Languages Java, PHP, C++,
  Perl, Haskell, AspectJ, Ruby, COBOL, Bash Scripts and Scheme Revision 1.0 - a
  Team CPLgroup COMP6411-S10 Term Report</title><categories>cs.PL</categories><comments>10 pages</comments><acm-class>D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comparison of programming languages is a common topic of discussion among
software engineers. Few languages ever become sufficiently popular that they
are used by more than a few people or find their niche in research or
education; but professional programmers can easily use dozens of different
languages during their career. Multiple programming languages are designed,
specified, and implemented every year in order to keep up with the changing
programming paradigms, hardware evolution, etc. In this paper we present a
comparative study between ten programming languages: Haskell, Java, Perl, C++,
AspectJ, COBOL, Ruby, PHP, Bash Scripts, and Scheme; with respect of the
following criteria: Secure programming practices, web applications development,
web services design and composition, object oriented-based abstraction,
reflection, aspect-orientation, functional programming, declarative
programming, batch scripting, and user interface prototype design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3437</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3437</id><created>2010-08-20</created><authors><author><keyname>Charafeddine</keyname><forenames>Mohamad</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Paulraj</keyname><forenames>Arogyaswami</forenames></author></authors><title>Rate Region Frontiers for n-user Interference Channel with Interference
  as Noise</title><categories>cs.IT math.IT</categories><comments>6 pages, 6 figures</comments><journal-ref>Forty-Fifth Annual Allerton Conference, Allerton House, UIUC,
  Illinois, USA, September 26-28, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the achievable rate region frontiers for the n-user
interference channel when there is no cooperation at the transmit nor at the
receive side. The receiver is assumed to treat the interference as additive
thermal noise and does not employ multiuser detection. In this case, the rate
region frontier for the n-user interference channel is found to be the union of
n hyper-surface frontiers of dimension n-1, where each is characterized by
having one of the transmitters transmitting at full power. The paper also finds
the conditions determining the convexity or concavity of the frontiers for the
case of two-user interference channel, and discusses when a time sharing
approach should be employed with specific results pertaining to the two-user
symmetric channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3443</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3443</id><created>2010-08-20</created><authors><author><keyname>Alvarez-Hamelin</keyname><forenames>Jos&#xe9; Ignacio</forenames><affiliation>FIUBA, INTECIN</affiliation></author><author><keyname>Gast&#xf3;n</keyname><forenames>Beir&#xf3; Mariano</forenames><affiliation>FIUBA</affiliation></author><author><keyname>Busch</keyname><forenames>Jorge Rodolfo</forenames><affiliation>FIUBA</affiliation></author></authors><title>On weakly optimal partitions in modular networks</title><categories>cs.SI cond-mat.stat-mech physics.soc-ph</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modularity was introduced as a measure of goodness for the community
structure induced by a partition of the set of vertices in a graph. Then, it
also became an objective function used to find good partitions, with high
success. Nevertheless, some works have shown a scaling limit and certain
instabilities when finding communities with this criterion. Modularity has been
studied proposing several formalisms, as hamiltonians in a Potts model or
laplacians in spectral partitioning. In this paper we present a new
probabilistic formalism to analyze modularity, and from it we derive an
algorithm based on weakly optimal partitions. This algorithm obtains good
quality partitions and also scales to large graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3450</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3450</id><created>2010-08-20</created><updated>2012-11-22</updated><authors><author><keyname>Merrikh-Bayat</keyname><forenames>Farnood</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeed Bagheri</forenames></author><author><keyname>Afrakoti</keyname><forenames>Iman Esmaili Paeen</forenames></author></authors><title>Bottleneck of using single memristor as a synapse and its solution</title><categories>cs.NE</categories><comments>17 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now widely accepted that memristive devices are perfect candidates for
the emulation of biological synapses in neuromorphic systems. This is mainly
because of the fact that like the strength of synapse, memristance of the
memristive device can be tuned actively (e.g., by the application of volt- age
or current). In addition, it is also possible to fabricate very high density of
memristive devices (comparable to the number of synapses in real biological
system) through the nano-crossbar structures. However, in this paper we will
show that there are some problems associated with memristive synapses
(memristive devices which are playing the role of biological synapses). For
example, we show that the variation rate of the memristance of memristive
device depends completely on the current memristance of the device and
therefore it can change significantly with time during the learning phase. This
phenomenon can degrade the performance of learning methods like Spike
Timing-Dependent Plasticity (STDP) and cause the corresponding neuromorphic
systems to become unstable. Finally, at the end of this paper, we illustrate
that using two serially connected memristive devices with different polarities
as a synapse can somewhat fix the aforementioned problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3452</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3452</id><created>2010-08-20</created><updated>2010-09-02</updated><authors><author><keyname>Merrikh-Bayat</keyname><forenames>Farnood</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeed Bagheri</forenames></author></authors><title>Memristor-based Circuits for Performing Basic Arithmetic Operations</title><categories>cs.AR</categories><comments>5pages, 4 figures, Accepted in World Conference on Information
  Technology, turkey, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In almost all of the currently working circuits, especially in analog
circuits implementing signal processing applications, basic arithmetic
operations such as multiplication, addition, subtraction and division are
performed on values which are represented by voltages or currents. However, in
this paper, we propose a new and simple method for performing analog arithmetic
operations which in this scheme, signals are represented and stored through a
memristance of the newly found circuit element, i.e. memristor, instead of
voltage or current. Some of these operators such as divider and multiplier are
much simpler and faster than their equivalent voltage-based circuits and they
require less chip area. In addition, a new circuit is designed for programming
the memristance of the memristor with predetermined analog value. Presented
simulation results demonstrate the effectiveness and the accuracy of the
proposed circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3459</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3459</id><created>2010-08-20</created><authors><author><keyname>Dahan</keyname><forenames>Xavier</forenames></author><author><keyname>Kadri</keyname><forenames>Abdulilah</forenames></author><author><keyname>Schost</keyname><forenames>&#xc9;ric</forenames></author></authors><title>Bit-size estimates for triangular sets in positive dimension</title><categories>cs.SC</categories><comments>37 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give bit-size estimates for the coefficients appearing in triangular sets
describing positive-dimensional algebraic sets defined over Q. These estimates
are worst case upper bounds; they depend only on the degree and height of the
underlying algebraic sets. We illustrate the use of these results in the
context of a modular algorithm. This extends results by the first and last
author, which were confined to the case of dimension 0. Our strategy is to get
back to dimension 0 by evaluation and inter- polation techniques. Even though
the main tool (height theory) remains the same, new difficulties arise to
control the growth of the coefficients during the interpolation process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3503</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3503</id><created>2010-08-20</created><authors><author><keyname>Fink</keyname><forenames>Martin</forenames></author><author><keyname>Spoerhase</keyname><forenames>Joachim</forenames></author></authors><title>Maximum Betweenness Centrality: Approximability and Tractable Cases</title><categories>cs.DS</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Maximum Betweenness Centrality problem (MBC) can be defined as follows.
Given a graph find a $k$-element node set $C$ that maximizes the probability of
detecting communication between a pair of nodes $s$ and $t$ chosen uniformly at
random. It is assumed that the communication between $s$ and $t$ is realized
along a shortest $s$--$t$ path which is, again, selected uniformly at random.
The communication is detected if the communication path contains a node of $C$.
Recently, Dolev et al. (2009) showed that MBC is NP-hard and gave a
$(1-1/e)$-approximation using a greedy approach. We provide a reduction of MBC
to Maximum Coverage that simplifies the analysis of the algorithm of Dolev et
al. considerably. Our reduction allows us to obtain a new algorithm with the
same approximation ratio for a (generalized) budgeted version of MBC. We
provide tight examples showing that the analyses of both algorithms are best
possible. Moreover, we prove that MBC is APX-complete and provide an exact
polynomial-time algorithm for MBC on tree graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3505</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3505</id><created>2010-08-20</created><authors><author><keyname>Graham</keyname><forenames>Carl</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author></authors><title>Self-adaptive congestion control for multi-class intermittent
  connections in a communication network</title><categories>cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Markovian model of the evolution of intermittent connections of various
classes in a communication network is established and investigated. Any
connection evolves in a way which depends only on its class and the state of
the network, in particular as to the route it uses among a subset of the
network nodes. It can be either active (ON) when it is transmitting data along
its route, or idle (OFF). The congestion of a given node is defined as a
functional of the transmission rates of all ON connections going through it,
and causes losses and delays to these connections. In order to control this,
the ON connections self-adaptively vary their transmission rate in TCP-like
fashion. The connections interact through this feedback loop. A Markovian model
is provided by the states (OFF, or ON with some transmission rate) of the
connections. The number of connections in each class being potentially huge, a
mean-field limit result is proved with an appropriate scaling so as to reduce
the dimensionality. In the limit, the evolution of the states of the
connections can be represented by a non-linear system of stochastic
differential equations, of dimension the number of classes. Additionally, it is
shown that the corresponding stationary distribution can be expressed by the
solution of a fixed-point equation of finite dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3533</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3533</id><created>2010-08-20</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author></authors><title>A Novel Quantum Cost Efficient Reversible Full Adder Gate in
  Nanotechnology</title><categories>cs.AR</categories><comments>7 pages, 12 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic has become one of the promising research directions in low
power dissipating circuit design in the past few years and has found its
applications in low power CMOS design, cryptography, optical information
processing and nanotechnology. This paper presents a novel and quantum cost
efficient reversible full adder gate in nanotechnology. This gate can work
singly as a reversible full adder unit and requires only one clock cycle. The
proposed gate is a universal gate in the sense that it can be used to
synthesize any arbitrary Boolean functions. It has been demonstrated that the
hardware complexity offered by the proposed gate is less than the existing
counterparts. The proposed reversible full adder gate also adheres to the
theoretical minimum established by the researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3546</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3546</id><created>2010-08-20</created><authors><author><keyname>Paparrizos</keyname><forenames>Ioannis</forenames></author></authors><title>Homogeneous and Non Homogeneous Algorithms</title><categories>cs.DS cs.CC</categories><comments>This (full) paper was accepted for publication in the 13th
  Panhellenic Conference on Informatics (PCI 2009), 10-12 September 2009,
  Corfu, Greece (8 pages)</comments><acm-class>F.2.2; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by recent best case analyses for some sorting algorithms and based
on the type of complexity we partition the algorithms into two classes:
homogeneous and non homogeneous algorithms. Although both classes contain
algorithms with worst and best cases, homogeneous algorithms behave uniformly
on all instances. This partition clarifies in a completely mathematical way the
previously mentioned terms and reveals that in classifying an algorithm as
homogeneous or not best case analysis is equally important with worst case
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3551</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3551</id><created>2010-08-20</created><authors><author><keyname>Yang</keyname><forenames>Jian</forenames></author><author><keyname>Vee</keyname><forenames>Erik</forenames></author><author><keyname>Vassilvitskii</keyname><forenames>Sergei</forenames></author><author><keyname>Tomlin</keyname><forenames>John</forenames></author><author><keyname>Shanmugasundaram</keyname><forenames>Jayavel</forenames></author><author><keyname>Anastasakos</keyname><forenames>Tasos</forenames></author><author><keyname>Kennedy</keyname><forenames>Oliver</forenames></author></authors><title>Inventory Allocation for Online Graphical Display Advertising</title><categories>cs.CE</categories><report-no>YL-2010-004</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a multi-objective/goal programming model for the allocation of
inventory of graphical advertisements. The model considers two types of
campaigns: guaranteed delivery (GD), which are sold months in advance, and
non-guaranteed delivery (NGD), which are sold using real-time auctions. We
investigate various advertiser and publisher objectives such as (a) revenue
from the sale of impressions, clicks and conversions, (b) future revenue from
the sale of NGD inventory, and (c) &quot;fairness&quot; of allocation. While the first
two objectives are monetary, the third is not. This combination of demand types
and objectives leads to potentially many variations of our model, which we
delineate and evaluate. Our experimental results, which are based on
optimization runs using real data sets, demonstrate the effectiveness and
flexibility of the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3561</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3561</id><created>2010-08-20</created><authors><author><keyname>Naim</keyname><forenames>Rana</forenames></author><author><keyname>Nizam</keyname><forenames>Mohammad Fahim</forenames></author><author><keyname>Hanamasagar</keyname><forenames>Sheetal</forenames></author><author><keyname>Noureddine</keyname><forenames>Jalal</forenames></author><author><keyname>Miladinova</keyname><forenames>Marinela</forenames></author></authors><title>Comparative Studies of 10 Programming Languages within 10 Diverse
  Criteria - a Team 10 COMP6411-S10 Term Report</title><categories>cs.PL</categories><comments>126 pages</comments><acm-class>D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a survey on the programming languages: C++, JavaScript, AspectJ, C#,
Haskell, Java, PHP, Scala, Scheme, and BPEL. Our survey work involves a
comparative study of these ten programming languages with respect to the
following criteria: secure programming practices, web application development,
web service composition, OOP-based abstractions, reflection, aspect
orientation, functional programming, declarative programming, batch scripting,
and UI prototyping. We study these languages in the context of the above
mentioned criteria and the level of support they provide for each one of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3576</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3576</id><created>2010-08-20</created><authors><author><keyname>Karra</keyname><forenames>Satish</forenames></author><author><keyname>Rajagopal</keyname><forenames>K. R.</forenames></author></authors><title>Modeling the Non-linear Viscoelastic Response of High Temperature
  Polyimides</title><categories>cs.NA math-ph math.MP</categories><comments>16 pages, 4 figures, submitted to Mechanics of Materials</comments><msc-class>74D10</msc-class><doi>10.1016/j.mechmat.2010.09.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A constitutive model is developed to predict the viscoelastic response of
polyimide resins that are used in high temperature applications. This model is
based on a thermodynamic framework that uses the notion that the `natural
configuration' of a body evolves as the body undergoes a process and the
evolution is determined by maximizing the rate of entropy production in general
and the rate of dissipation within purely mechanical considerations. We
constitutively prescribe forms for the specific Helmholtz potential and the
rate of dissipation (which is the product of density, temperature and the rate
of entropy production), and the model is derived by maximizing the rate of
dissipation with the constraint of incompressibility, and the reduced energy
dissipation equation is also regarded as a constraint in that it is required to
be met in every process that the body undergoes. The efficacy of the model is
ascertained by comparing the predictions of the model with the experimental
data for PMR-15 and HFPE-II-52 polyimide resins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3585</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3585</id><created>2010-08-20</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Ultrametric and Generalized Ultrametric in Computational Logic and in
  Data Analysis</title><categories>cs.LO cs.LG stat.ML</categories><comments>19 pp., 5 figures, 3 tables</comments><msc-class>91C20, 62-07, 03-XX</msc-class><acm-class>I.5.3; F.4.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following a review of metric, ultrametric and generalized ultrametric, we
review their application in data analysis. We show how they allow us to explore
both geometry and topology of information, starting with measured data. Some
themes are then developed based on the use of metric, ultrametric and
generalized ultrametric in logic. In particular we study approximation chains
in an ultrametric or generalized ultrametric context. Our aim in this work is
to extend the scope of data analysis by facilitating reasoning based on the
data analysis; and to show how quantitative and qualitative data analysis can
be incorporated into logic programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3594</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3594</id><created>2010-08-20</created><updated>2011-07-25</updated><authors><author><keyname>Kelner</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Lee</keyname><forenames>James R.</forenames></author><author><keyname>Price</keyname><forenames>Gregory N.</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Metric uniformization and spectral bounds for graphs</title><categories>math.MG cs.DS math.DG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for proving upper bounds on the eigenvalues of the graph
Laplacian. A main step involves choosing an appropriate &quot;Riemannian&quot; metric to
uniformize the geometry of the graph. In many interesting cases, the existence
of such a metric is shown by examining the combinatorics of special types of
flows. This involves proving new inequalities on the crossing number of graphs.
  In particular, we use our method to show that for any positive integer k, the
kth smallest eigenvalue of the Laplacian on an n-vertex, bounded-degree planar
graph is O(k/n). This bound is asymptotically tight for every k, as it is
easily seen to be achieved for square planar grids. We also extend this
spectral result to graphs with bounded genus, and graphs which forbid fixed
minors. Previously, such spectral upper bounds were only known for the case
k=2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3596</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3596</id><created>2010-08-20</created><authors><author><keyname>Feng</keyname><forenames>Yong</forenames></author><author><keyname>Wu</keyname><forenames>Wenyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Jingzhong</forenames></author></authors><title>Exact Bivariate Polynomial Factorization in Q by Approximation of Roots</title><categories>math.AG cs.NA cs.SC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Factorization of polynomials is one of the foundations of symbolic
computation. Its applications arise in numerous branches of mathematics and
other sciences. However, the present advanced programming languages such as C++
and J++, do not support symbolic computation directly. Hence, it leads to
difficulties in applying factorization in engineering fields. In this paper, we
present an algorithm which use numerical method to obtain exact factors of a
bivariate polynomial with rational coefficients. Our method can be directly
implemented in efficient programming language such C++ together with the GNU
Multiple-Precision Library. In addition, the numerical computation part often
only requires double precision and is easily parallelizable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3597</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3597</id><created>2010-08-20</created><authors><author><keyname>Reznik</keyname><forenames>Yuriy A.</forenames></author></authors><title>Quantization of Discrete Probability Distributions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of quantization of discrete probability distributions,
arising in universal coding, as well as other applications. We show, that in
many situations this problem can be reduced to the covering problem for the
unit simplex. This setting yields precise asymptotic characterization in the
high-rate regime. We also describe a simple and asymptotically optimal
algorithm for solving this problem. Performance of this algorithm is studied
and compared with several known solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3608</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3608</id><created>2010-08-21</created><authors><author><keyname>Charafeddine</keyname><forenames>Mohamad</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Paulraj</keyname><forenames>Arogyaswami</forenames></author><author><keyname>Cioffi</keyname><forenames>John</forenames></author></authors><title>Crystallized Rates Region of the Interference Channel via Correlated
  Equilibrium with Interference as Noise</title><categories>cs.IT math.IT</categories><comments>6 pages, 9 figures, Proc. IEEE International Conference on
  Communications (ICC) 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Treating the interference as noise in the n-user interference channel, the
paper describes a novel approach to the rates region, composed by the
time-sharing convex hull of 2^n-1 corner points achieved through On/Off binary
power control. The resulting rates region is denoted crystallized rates region.
By treating the interference as noise, the n-user rates region frontiers has
been found in the literature to be the convex hull of n hyper-surfaces. The
rates region bounded by these hyper-surfaces is not necessarily convex, and
thereby a convex hull operation is imposed through the strategy of
time-sharing. This paper simplifies this rates region in the n-dimensional
space by having only an On/Off binary power control. This consequently leads to
2^n-1 corner points situated within the rates region. A time-sharing convex
hull is imposed onto those corner points, forming the crystallized rates
region. The paper focuses on game theoretic concepts to achieve that
crystallized convex hull via correlated equilibrium. In game theory, the
correlated equilibrium set is convex, and it consists of the time-sharing mixed
strategies of the Nash equilibriums. In addition, the paper considers a
mechanism design approach to carefully design a utility function, particularly
the Vickrey-Clarke-Groves auction utility, where the solution point is situated
on the correlated equilibrium set. Finally, the paper proposes a self learning
algorithm, namely the regret-matching algorithm, that converges to the solution
point on the correlated equilibrium set in a distributed fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3614</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3614</id><created>2010-08-21</created><authors><author><keyname>Koutsopoulos</keyname><forenames>Iordanis</forenames></author><author><keyname>Tassiulas</keyname><forenames>Leandros</forenames></author></authors><title>Control and Optimization Meet the Smart Power Grid - Scheduling of Power
  Demands for Optimal Energy Management</title><categories>cs.NI cs.SY</categories><comments>submitted to INFOCOM 2011; 9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The smart power grid aims at harnessing information and communication
technologies to enhance reliability and enforce sensible use of energy. Its
realization is geared by the fundamental goal of effective management of demand
load. In this work, we envision a scenario with real-time communication between
the operator and consumers. The grid operator controller receives requests for
power demands from consumers, with different power requirement, duration, and a
deadline by which it is to be completed. The objective is to devise a power
demand task scheduling policy that minimizes the grid operational cost over a
time horizon. The operational cost is a convex function of instantaneous power
consumption and reflects the fact that each additional unit of power needed to
serve demands is more expensive as demand load increases.First, we study the
off-line demand scheduling problem, where parameters are fixed and known. Next,
we devise a stochastic model for the case when demands are generated
continually and scheduling decisions are taken online and focus on long-term
average cost. We present two instances of power consumption control based on
observing current consumption. First, the controller may choose to serve a new
demand request upon arrival or to postpone it to the end of its deadline.
Second, the additional option exists to activate one of the postponed demands
when an active demand terminates. For both instances, the optimal policies are
threshold based. We derive a lower performance bound over all policies, which
is asymptotically tight as deadlines increase. We propose the Controlled
Release threshold policy and prove it is asymptotically optimal. The policy
activates a new demand request if the current power consumption is less than a
threshold, otherwise it is queued. Queued demands are scheduled when their
deadline expires or when the consumption drops below the threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3618</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3618</id><created>2010-08-21</created><authors><author><keyname>Zayyani</keyname><forenames>Hadi</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>Bayesian Hypothesis Testing for Sparse Representation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a Bayesian Hypothesis Testing Algorithm (BHTA) for
sparse representation. It uses the Bayesian framework to determine active atoms
in sparse representation of a signal.
  The Bayesian hypothesis testing based on three assumptions, determines the
active atoms from the correlations and leads to the activity measure as
proposed in Iterative Detection Estimation (IDE) algorithm. In fact, IDE uses
an arbitrary decreasing sequence of thresholds while the proposed algorithm is
based on a sequence which derived from hypothesis testing. So, Bayesian
hypothesis testing framework leads to an improved version of the IDE algorithm.
  The simulations show that Hard-version of our suggested algorithm achieves
one of the best results in terms of estimation accuracy among the algorithms
which have been implemented in our simulations, while it has the greatest
complexity in terms of simulation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3625</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3625</id><created>2010-08-21</created><authors><author><keyname>Naser</keyname><forenames>Mu'awya</forenames></author><author><keyname>Peris-Lopez</keyname><forenames>Pedro</forenames></author><author><keyname>Rafie</keyname><forenames>Mohammd</forenames></author><author><keyname>van der Lubbe</keyname><forenames>Jan</forenames></author></authors><title>Vulnerability Analysis of PAP for RFID Tags</title><categories>cs.CR</categories><comments>18 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the security of an RFID authentication protocol
proposed by Liu and Bailey [1], called Privacy and Authentication Protocol
(PAP), and show its vulnerabilities and faulty assumptions. PAP is a privacy
and authentication protocol designed for passive tags. The authors claim that
the protocol, being resistant to commonly assumed attacks, requires little
computation and provides privacy protection and authentication. Nevertheless,
we propose two traceability attacks and an impersonation attack, in which the
revealing of secret information (i.e., secret key and static identifier) shared
between the tag and the reader is unnecessary. Moreover, we review all basic
assumptions on which the design of the protocol resides, and show how many of
them are incorrect and are contrary to the common assumptions in RFID systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3629</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3629</id><created>2010-08-21</created><authors><author><keyname>Grissa</keyname><forenames>Dhouha</forenames></author><author><keyname>Guillaume</keyname><forenames>Sylvie</forenames></author><author><keyname>Nguifo</keyname><forenames>Engelbert Mephu</forenames></author></authors><title>Combining Clustering techniques and Formal Concept Analysis to
  characterize Interestingness Measures</title><categories>cs.IT math.IT</categories><comments>13 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal Concept Analysis &quot;FCA&quot; is a data analysis method which enables to
discover hidden knowledge existing in data. A kind of hidden knowledge
extracted from data is association rules. Different quality measures were
reported in the literature to extract only relevant association rules. Given a
dataset, the choice of a good quality measure remains a challenging task for a
user. Given a quality measures evaluation matrix according to semantic
properties, this paper describes how FCA can highlight quality measures with
similar behavior in order to help the user during his choice. The aim of this
article is the discovery of Interestingness Measures &quot;IM&quot; clusters, able to
validate those found due to the hierarchical and partitioning clustering
methods &quot;AHC&quot; and &quot;k-means&quot;. Then, based on the theoretical study of sixty one
interestingness measures according to nineteen properties, proposed in a recent
study, &quot;FCA&quot; describes several groups of measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3641</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3641</id><created>2010-08-21</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Capacity Limits of Multiuser Multiantenna Cognitive Networks</title><categories>cs.IT math.IT</categories><comments>32 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Unlike point-to-point cognitive radio, where the constraint imposed by the
primary rigidly curbs the secondary throughput, multiple secondary users have
the potential to more efficiently harvest the spectrum and share it among
themselves. This paper analyzes the sum throughput of a multiuser cognitive
radio system with multi-antenna base stations, either in the uplink or downlink
mode. The primary and secondary have $N$ and $n$ users, respectively, and their
base stations have $M$ and $m$ antennas, respectively. We show that an uplink
secondary throughput grows with $\frac{m}{N +1}\log n$ if the primary is a
downlink system, and grows with $\frac{m}{M +1}\log n$ if the primary is an
uplink system. These growth rates are shown to be optimal and can be obtained
with a simple threshold-based user selection rule. Furthermore, we show that
the secondary throughput can grow proportional to $\log n$ while simultaneously
pushing the interference on the primary down to zero, asymptotically.
Furthermore, we show that a downlink secondary throughput grows with $m\log
\log n$ in the presence of either an uplink or downlink primary system. In
addition, the interference on the primary can be made to go to zero
asymptotically while the secondary throughput increases proportionally to $\log
\log n$. Thus, unlike the point-to-point case, multiuser cognitive radios can
achieve non-trivial sum throughput despite stringent primary interference
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3651</identifier>
 <datestamp>2014-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3651</id><created>2010-08-21</created><updated>2011-05-27</updated><authors><author><keyname>Iouditski</keyname><forenames>Anatoli</forenames><affiliation>LJK</affiliation></author><author><keyname>Nemirovski</keyname><forenames>Arkadii S.</forenames><affiliation>ISyE</affiliation></author></authors><title>Accuracy guarantees for L1-recovery</title><categories>math.ST cs.SY math.OC stat.TH</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Information Theory 57, 12 (2011) 7818 - 7839</journal-ref><doi>10.1109/TIT.2011.2162569</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss two new methods of recovery of sparse signals from noisy
observation based on $\ell_1$- minimization. They are closely related to the
well-known techniques such as Lasso and Dantzig Selector. However, these
estimators come with efficiently verifiable guaranties of performance. By
optimizing these bounds with respect to the method parameters we are able to
construct the estimators which possess better statistical properties than the
commonly used ones. We also show how these techniques allow to provide
efficiently computable accuracy bounds for Lasso and Dantzig Selector. We link
our performance estimations to the well known results of Compressive Sensing
and justify our proposed approach with an oracle inequality which links the
properties of the recovery algorithms and the best estimation performance when
the signal support is known. We demonstrate how the estimates can be computed
using the Non-Euclidean Basis Pursuit algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3652</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3652</id><created>2010-08-21</created><authors><author><keyname>Naves</keyname><forenames>Guyslain</forenames></author></authors><title>On disjoint paths in acyclic planar graphs</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an algorithm with complexity $O(f(R)^{k^2} k^3 n)$ for the integer
multiflow problem on instances $(G,H,r,c)$ with $G$ an acyclic planar digraph
and $r+c$ Eulerian. Here, $f$ is a polynomial function, $n = |V(G)|$, $k =
|E(H)|$ and $R$ is the maximum request $\max_{h \in E(H)} r(h)$. When $k$ is
fixed, this gives a polynomial algorithm for the arc-disjoint paths problem
under the same hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3653</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3653</id><created>2010-08-21</created><authors><author><keyname>Naves</keyname><forenames>Guyslain</forenames></author><author><keyname>Weibel</keyname><forenames>Christophe</forenames></author></authors><title>Congestion in planar graphs with demands on faces</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an algorithm to route a multicommodity flow in a planar graph $G$
with congestion $O(\log k)$, where $k$ is the maximum number of terminals on
the boundary of a face, when each demand edge lie on a face of $G$. We also
show that our specific method cannot achieve a substantially better congestion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3654</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3654</id><created>2010-08-21</created><updated>2011-12-18</updated><authors><author><keyname>Raskutti</keyname><forenames>Garvesh</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Yu</keyname><forenames>Bin</forenames></author></authors><title>Minimax-optimal rates for sparse additive models over kernel classes via
  convex programming</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Lower bounds presented in part in Proceedings of the NIPS Conference,
  December 2009 Revised version December 2011: new Theorem 3, showing
  restrictiveness of global boundedness condition. Sharper version of Theorem
  1, with rates in both empirical and population norm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse additive models are families of $d$-variate functions that have the
additive decomposition $f^* = \sum_{j \in S} f^*_j$, where $S$ is an unknown
subset of cardinality $s \ll d$. In this paper, we consider the case where each
univariate component function $f^*_j$ lies in a reproducing kernel Hilbert
space (RKHS), and analyze a method for estimating the unknown function $f^*$
based on kernels combined with $\ell_1$-type convex regularization. Working
within a high-dimensional framework that allows both the dimension $d$ and
sparsity $s$ to increase with $n$, we derive convergence rates (upper bounds)
in the $L^2(\mathbb{P})$ and $L^2(\mathbb{P}_n)$ norms over the class
$\MyBigClass$ of sparse additive models with each univariate function $f^*_j$
in the unit ball of a univariate RKHS with bounded kernel function. We
complement our upper bounds by deriving minimax lower bounds on the
$L^2(\mathbb{P})$ error, thereby showing the optimality of our method. Thus, we
obtain optimal minimax rates for many interesting classes of sparse additive
models, including polynomials, splines, and Sobolev classes. We also show that
if, in contrast to our univariate conditions, the multivariate function class
is assumed to be globally bounded, then much faster estimation rates are
possible for any sparsity $s = \Omega(\sqrt{n})$, showing that global
boundedness is a significant restriction in the high-dimensional setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3667</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3667</id><created>2010-08-21</created><authors><author><keyname>Chattopadhyay</keyname><forenames>Ishanu</forenames></author><author><keyname>Wen</keyname><forenames>Yicheng</forenames></author><author><keyname>Ray</keyname><forenames>Asok</forenames></author></authors><title>Pattern Classification In Symbolic Streams via Semantic Annihilation of
  Information</title><categories>cs.SC cs.CL cs.IT math.IT</categories><comments>15 pages, 7 figures (Under Review Elsewhere: Journal Reference Will
  Be Provided When Available )</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a technique for pattern classification in symbolic streams via
selective erasure of observed symbols, in cases where the patterns of interest
are represented as Probabilistic Finite State Automata (PFSA). We define an
additive abelian group for a slightly restricted subset of probabilistic finite
state automata (PFSA), and the group sum is used to formulate pattern-specific
semantic annihilators. The annihilators attempt to identify pre-specified
patterns via removal of essentially all inter-symbol correlations from observed
sequences, thereby turning them into symbolic white noise. Thus a perfect
annihilation corresponds to a perfect pattern match. This approach of
classification via information annihilation is shown to be strictly
advantageous, with theoretical guarantees, for a large class of PFSA models.
The results are supported by simulation experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3672</identifier>
 <datestamp>2012-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3672</id><created>2010-08-21</created><updated>2012-10-10</updated><authors><author><keyname>Kapralov</keyname><forenames>Michael</forenames></author><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>Prediction strategies without loss</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a sequence of bits where we are trying to predict the next bit from
the previous bits. Assume we are allowed to say 'predict 0' or 'predict 1', and
our payoff is +1 if the prediction is correct and -1 otherwise. We will say
that at each point in time the loss of an algorithm is the number of wrong
predictions minus the number of right predictions so far. In this paper we are
interested in algorithms that have essentially zero (expected) loss over any
string at any point in time and yet have small regret with respect to always
predicting 0 or always predicting 1. For a sequence of length $T$ our algorithm
has regret $14\epsilon T $ and loss $2\sqrt{T}e^{-\epsilon^2 T} $ in
expectation for all strings. We show that the tradeoff between loss and regret
is optimal up to constant factors.
  Our techniques extend to the general setting of $N$ experts, where the
related problem of trading off regret to the best expert for regret to the
`special' expert has been studied by Even-Dar et al. (COLT'07). We obtain
essentially zero loss with respect to the special expert and optimal
loss/regret tradeoff, improving upon the results of Even-Dar et al and settling
the main question left open in their paper.
  The strong loss bounds of the algorithm have some surprising consequences. A
simple iterative application of our algorithm gives essentially optimal regret
bounds at multiple time scales, bounds with respect to $k$-shifting optima as
well as regret bounds with respect to higher norms of the input sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3681</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3681</id><created>2010-08-22</created><authors><author><keyname>Kumar</keyname><forenames>Rajender</forenames></author><author><keyname>Singh</keyname><forenames>Brahmjit</forenames></author></authors><title>EVM as generic QoS trigger for heterogeneous wieless overlay network</title><categories>cs.NI cs.PF</categories><comments>12 pages, 7 figures, IJWMN 2010 august issue vol. 2, no.3</comments><journal-ref>International Journal on Wireless and Mobile Networks, August 2010
  Issue volume 2, number 3, AIRCCS</journal-ref><doi>10.5121/ijwmn.2010.2315</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fourth Generation (4G) Wireless System will integrate heterogeneous wireless
overlay systems i.e. interworking of WLAN/ GSM/ CDMA/ WiMAX/ LTE/ etc with
guaranteed Quality of Service (QoS) and Experience (QoE).QoS(E) vary from
network to network and is application sensitive. User needs an optimal mobility
solution while roaming in Overlaid wireless environment i.e. user could
seamlessly transfer his session/ call to a best available network bearing
guaranteed Quality of Experience. And If this Seamless transfer of session is
executed between two networks having different access standards then it is
called Vertical Handover (VHO). Contemporary VHO decision algorithms are based
on generic QoS metrics viz. SNR, bandwidth, jitter, BER and delay. In this
paper, Error Vector Magnitude (EVM) is proposed to be a generic QoS trigger for
VHO execution. EVM is defined as the deviation of inphase/ quadrature (I/Q)
values from ideal signal states and thus provides a measure of signal quality.
In 4G Interoperable environment, OFDM is the leading Modulation scheme (more
prone to multi-path fading). EVM (modulation error) properly characterises the
wireless link/ channel for accurate VHO decision. EVM depends on the inherent
transmission impairments viz. frequency offset, phase noise,
non-linear-impairment, skewness etc. for a given wireless link. Paper provides
an insight to the analytical aspect of EVM &amp; measures EVM (%) for key
management subframes like association/re-association/disassociation/ probe
request/response frames. EVM relation is explored for different possible
NAV-Network Allocation Vectors (frame duration). Finally EVM is compared with
SNR, BER and investigation concludes EVM as a promising QoS trigger for OFDM
based emerging wireless standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3691</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3691</id><created>2010-08-22</created><updated>2011-08-06</updated><authors><author><keyname>Hajiabolhassan</keyname><forenames>Hossein</forenames></author><author><keyname>Moazami</keyname><forenames>Farokhlagha</forenames></author></authors><title>Some New Bounds For Cover-Free Families Through Biclique Cover</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $(r,w;d)$ cover-free family $(CFF)$ is a family of subsets of a finite set
such that the intersection of any $r$ members of the family contains at least
$d$ elements that are not in the union of any other $w$ members. The minimum
number of elements for which there exists an $(r,w;d)-CFF$ with $t$ blocks is
denoted by $N((r,w;d),t)$.
  In this paper, we show that the value of $N((r,w;d),t)$ is equal to the
$d$-biclique covering number of the bipartite graph $I_t(r,w)$ whose vertices
are all $w$- and $r$-subsets of a $t$-element set, where a $w$-subset is
adjacent to an $r$-subset if their intersection is empty. Next, we introduce
some new bounds for $N((r,w;d),t)$. For instance, we show that for $r\geq w$
and $r\geq 2$
  $$ N((r,w;1),t) \geq c{{r+w\choose w+1}+{r+w-1 \choose w+1}+ 3 {r+w-4 \choose
w-2} \over \log r} \log (t-w+1),$$ where $c$ is a constant satisfies the
well-known bound $N((r,1;1),t)\geq c\frac{r^2}{\log r}\log t$. Also, we
determine the exact value of $N((r,w;d),t)$ for some values of $d$. Finally, we
show that $N((1,1;d),4d-1)=4d-1$ whenever there exists a Hadamard matrix of
order 4d.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3694</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3694</id><created>2010-08-22</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Islam</keyname><forenames>Md. Rafiqul</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author><author><keyname>karim</keyname><forenames>Muhammad Rezaul</forenames></author></authors><title>Sorting Network for Reversible Logic Synthesis</title><categories>cs.AR</categories><comments>4 pages, 8 figures, 2 tables</comments><journal-ref>International Conference for Upcoming Engineers, Windsor
  University, Ontario, Canada, May 20-21, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have introduced an algorithm to implement a sorting network
for reversible logic synthesis based on swapping bit strings. The algorithm
first constructs a network in terms of n*n Toffoli gates read from left to
right. The number of gates in the circuit produced by our algorithm is then
reduced by template matching and removing useless gates from the network. We
have also compared the efficiency of the proposed method with the existing
ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3705</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3705</id><created>2010-08-22</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Techniques for Enhanced Physical-Layer Security</title><categories>cs.NI cs.IT math.IT</categories><comments>Pre-print, IEEE Global Telecommunications Conference (GLOBECOM'10),
  Miami, FL, Dec. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information-theoretic security--widely accepted as the strictest notion of
security--relies on channel coding techniques that exploit the inherent
randomness of propagation channels to strengthen the security of communications
systems. Within this paradigm, we explore strategies to improve secure
connectivity in a wireless network. We first consider the intrinsically secure
communications graph (iS-graph), a convenient representation of the links that
can be established with information-theoretic security on a large-scale
network. We then propose and characterize two techniques--sectorized
transmission and eavesdropper neutralization--which are shown to dramatically
enhance the connectivity of the iS-graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3725</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3725</id><created>2010-08-22</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author><author><keyname>Baker</keyname><forenames>David F.</forenames></author><author><keyname>Lawal</keyname><forenames>Ola</forenames></author></authors><title>Evaluating Financial Model Performance: An Empirical Analysis of Some
  North Sea Investments</title><categories>cs.CY</categories><comments>11 Pages, 1 Table, 5 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 87-98
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifty North Sea oil &amp; gas investment transactions were analysed using
traditional spreadsheet based financial modelling methods. The purpose of the
analysis was to determine if there was a statistically significant relationship
between the price paid for an oil &amp; gas asset and the actual or expected
financial return over the asset's economically useful life. Several interesting
and statistically significant relationships were found which reveal useful
information about financial modelling performance, the premia paid to acquire
North Sea assets, the contribution oil and gas price uncertainty has on
estimates of future financial returns and the median financial return of these
North Sea Investments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3730</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3730</id><created>2010-08-22</created><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Poisoned Feedback: The Impact of Malicious Users in Closed-Loop
  Multiuser MIMO Systems</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures, 2010</comments><journal-ref>35th International Conference on Acoustics, Speech, and Signal
  Processing 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate channel state information (CSI) at the transmitter is critical for
maximizing spectral efficiency on the downlink of multi-antenna networks. In
this work we analyze a novel form of physical layer attacks on such closed-loop
wireless networks. Specifically, this paper considers the impact of
deliberately inaccurate feedback by malicious users in a multiuser multicast
system. Numerical results demonstrate the significant degradation in
performance of closed-loop transmission schemes due to intentional feedback of
false CSI by adversarial users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3741</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3741</id><created>2010-08-22</created><updated>2012-03-04</updated><authors><author><keyname>Yang</keyname><forenames>Wei</forenames></author><author><keyname>Sun</keyname><forenames>Wanlu</forenames></author><author><keyname>Li</keyname><forenames>Lihua</forenames></author></authors><title>Reliable Multicasting for Device-to-Device Radio Underlaying Cellular
  Networks</title><categories>cs.MM cs.NI</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes Leader in Charge (LiC), a reliable multicast architecture
for device-to-device (D2D) radio underlaying cellular networks. The
multicast-requesting user equipments (UEs) in close proximity form a D2D
cluster to receive the multicast packets through cooperation. In addition to
receiving the multicast packets from the eNB, UEs share what they received from
the multicast on short-range links among UEs, namely the D2D links, to exploit
the wireless resources a more efficient way. Consequently, we show that
utilizing the D2D links in cellular networks increases the throughput of a
multicast session by means of simulation. We also discuss some practical issues
facing the integration of LiC into the current cellular networks. In
particular, we propose efficient delay control mechanism to reduce the average
and maximum delay experienced by LiC users, which is further confirmed by the
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3742</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3742</id><created>2010-08-22</created><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author></authors><title>Optimally Training a Cascade Classifier</title><categories>cs.CV</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cascade classifiers are widely used in real-time object detection. Different
from conventional classifiers that are designed for a low overall
classification error rate, a classifier in each node of the cascade is required
to achieve an extremely high detection rate and moderate false positive rate.
Although there are a few reported methods addressing this requirement in the
context of object detection, there is no a principled feature selection method
that explicitly takes into account this asymmetric node learning objective. We
provide such an algorithm here. We show a special case of the biased minimax
probability machine has the same formulation as the linear asymmetric
classifier (LAC) of \cite{wu2005linear}. We then design a new boosting
algorithm that directly optimizes the cost function of LAC. The resulting
totally-corrective boosting algorithm is implemented by the column generation
technique in convex optimization. Experimental results on object detection
verify the effectiveness of the proposed boosting algorithm as a node
classifier in cascade object detection, and show performance better than that
of the current state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3743</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3743</id><created>2010-08-22</created><authors><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author><author><keyname>Kolahi</keyname><forenames>Solmaz</forenames></author><author><keyname>Lakshmanan</keyname><forenames>Laks V. S.</forenames></author></authors><title>Data Cleaning and Query Answering with Matching Dependencies and
  Matching Functions</title><categories>cs.DB</categories><comments>14 pages, double column</comments><acm-class>H.2; H.2.0; H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching dependencies were recently introduced as declarative rules for data
cleaning and entity resolution. Enforcing a matching dependency on a database
instance identifies the values of some attributes for two tuples, provided that
the values of some other attributes are sufficiently similar. Assuming the
existence of matching functions for making two attributes values equal, we
formally introduce the process of cleaning an instance using matching
dependencies, as a chase-like procedure. We show that matching functions
naturally introduce a lattice structure on attribute domains, and a partial
order of semantic domination between instances. Using the latter, we define the
semantics of clean query answering in terms of certain/possible answers as the
greatest lower bound/least upper bound of all possible answers obtained from
the clean instances. We show that clean query answering is intractable in some
cases. Then we study queries that behave monotonically wrt semantic domination
order, and show that we can provide an under/over approximation for clean
answers to monotone queries. Moreover, non-monotone positive queries can be
relaxed into monotone queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3746</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3746</id><created>2010-08-23</created><updated>2010-09-09</updated><authors><author><keyname>Shinzato</keyname><forenames>Takashi</forenames></author><author><keyname>Yasuda</keyname><forenames>Muneki</forenames></author></authors><title>Belief Propagation Algorithm for Portfolio Optimization Problems</title><categories>q-fin.PM cond-mat.stat-mech cs.LG math.OC q-fin.RM</categories><comments>5 pages, 2 figures, to submit to EPL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The typical behavior of optimal solutions to portfolio optimization problems
with absolute deviation and expected shortfall models using replica analysis
was pioneeringly estimated by S. Ciliberti and M. M\'ezard [Eur. Phys. B. 57,
175 (2007)]; however, they have not yet developed an approximate derivation
method for finding the optimal portfolio with respect to a given return set. In
this study, an approximation algorithm based on belief propagation for the
portfolio optimization problem is presented using the Bethe free energy
formalism, and the consistency of the numerical experimental results of the
proposed algorithm with those of replica analysis is confirmed. Furthermore,
the conjecture of H. Konno and H. Yamazaki, that the optimal solutions with the
absolute deviation model and with the mean-variance model have the same typical
behavior, is verified using replica analysis and the belief propagation
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3751</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3751</id><created>2010-08-23</created><authors><author><keyname>Das</keyname><forenames>Sudipto</forenames></author><author><keyname>Agrawal</keyname><forenames>Divyakant</forenames></author><author><keyname>Abbadi</keyname><forenames>Amr El</forenames></author></authors><title>ElasTraS: An Elastic Transactional Data Store in the Cloud</title><categories>cs.DB</categories><comments>5 Pages, In Proc. of USENIX HotCloud 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last couple of years, &quot;Cloud Computing&quot; or &quot;Elastic Computing&quot; has
emerged as a compelling and successful paradigm for internet scale computing.
One of the major contributing factors to this success is the elasticity of
resources. In spite of the elasticity provided by the infrastructure and the
scalable design of the applications, the elephant (or the underlying database),
which drives most of these web-based applications, is not very elastic and
scalable, and hence limits scalability. In this paper, we propose ElasTraS
which addresses this issue of scalability and elasticity of the data store in a
cloud computing environment to leverage from the elastic nature of the
underlying infrastructure, while providing scalable transactional data access.
This paper aims at providing the design of a system in progress, highlighting
the major design choices, analyzing the different guarantees provided by the
system, and identifying several important challenges for the research community
striving for computing in the cloud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3758</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3758</id><created>2010-08-23</created><authors><author><keyname>Hakiri</keyname><forenames>Akram</forenames><affiliation>LAAS</affiliation></author><author><keyname>Berthou</keyname><forenames>Pascal</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gayraud</keyname><forenames>Thierry</forenames><affiliation>LAAS</affiliation></author></authors><title>Survey study of the QoS Management in Distributed Interactive Simulation
  Through Dead Reckoning Algorithms</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dead Reckoning mechanism allows reducing the network utilization considerably
when used in Distributed Interactive Simulation Applications. However, this
technique often ignores available contextual information that may be
influential to the state of an entity, sacrificing remote predictive accuracy
in favor of low computational complexity. The remainder of this paper focuses
on the analysis of the Dead Reckoning Algorithms. Some contributions are
expected and overviews of the major bandwidth reduction techniques currently
investigated are discussed. A novel extension of Dead Reckoning based on ANFIS
systems is suggested to increase the network availability and fulfilling the
required QoS in such applications. The model shows it primary benefits
regarding the other research contributions, especially in the decision making
of the behavior of simulated entities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3759</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3759</id><created>2010-08-23</created><authors><author><keyname>Hakiri</keyname><forenames>Akram</forenames><affiliation>LAAS</affiliation></author><author><keyname>Berthou</keyname><forenames>Pascal</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gayraud</keyname><forenames>Thierry</forenames><affiliation>LAAS</affiliation></author></authors><title>Addressing the Challenge of Distributed Interactive Simulation With Data
  Distribution Service</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-Time availability of information is of most importance in large scale
distributed interactive simulation in network-centric communication.
Information generated from multiple federates must be distributed and made
available to interested parties and providing the required QoS for consistent
communication. The remainder of this paper discuss design alternative for
realizing high performance distributed interactive simulation (DIS) application
using the OMG Data Distribution Service (DDS), which is a QoS enabled
publish/subscribe platform standard for time-critical, data-centric and large
scale distributed networks. The considered application, in the civil domain, is
used for remote education in driving schools. An experimental design evaluates
the bandwidth and the latency performance of DDS and a comparison with the High
Level Architecture performance is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3760</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3760</id><created>2010-08-23</created><authors><author><keyname>Chattopadhyay</keyname><forenames>Ishanu</forenames></author><author><keyname>Cascone</keyname><forenames>Anthony</forenames></author><author><keyname>Ray</keyname><forenames>Asok</forenames></author></authors><title>Formal-language-theoretic Optimal Path Planning For Accommodation of
  Amortized Uncertainties and Dynamic Effects</title><categories>cs.RO cs.SY math.OC</categories><comments>Submitted for review for possible publication elsewhere; journal
  reference will be added when available</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a globally-optimal approach to robotic path planning under
uncertainty, based on the theory of quantitative measures of formal languages.
A significant generalization to the language-measure-theoretic path planning
algorithm $\nustar$ is presented that explicitly accounts for average dynamic
uncertainties and estimation errors in plan execution. The notion of the
navigation automaton is generalized to include probabilistic uncontrollable
transitions, which account for uncertainties by modeling and planning for
probabilistic deviations from the computed policy in the course of execution.
The planning problem is solved by casting it in the form of a performance
maximization problem for probabilistic finite state automata. In essence we
solve the following optimization problem: Compute the navigation policy which
maximizes the probability of reaching the goal, while simultaneously minimizing
the probability of hitting an obstacle. Key novelties of the proposed approach
include the modeling of uncertainties using the concept of uncontrollable
transitions, and the solution of the ensuing optimization problem using a
highly efficient search-free combinatorial approach to maximize quantitative
measures of probabilistic regular languages. Applicability of the algorithm in
various models of robot navigation has been shown with experimental validation
on a two-wheeled mobile robotic platform (SEGWAY RMP 200) in a laboratory
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3773</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3773</id><created>2010-08-23</created><authors><author><keyname>Althaus</keyname><forenames>Ernst</forenames></author><author><keyname>Hachenberger</keyname><forenames>Peter</forenames></author></authors><title>Fully Automatic Trunk Packing with Free Placements</title><categories>cs.DS cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm to compute the volume of a trunk according to the
SAE J1100 standard. Our new algorithm uses state-of-the-art methods from
computational geometry and from combinatorial optimization. It finds better
solutions than previous approaches for small trunks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3775</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3775</id><created>2010-08-23</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Litvak</keyname><forenames>Nelly</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Nemirovsky</keyname><forenames>Danil A.</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Smirnova</keyname><forenames>Elena</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Sokol</keyname><forenames>Marina</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Monte Carlo Methods for Top-k Personalized PageRank Lists and Name
  Disambiguation</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a problem of quick detection of top-k Personalized PageRank lists.
This problem has a number of important applications such as finding local cuts
in large graphs, estimation of similarity distance and name disambiguation. In
particular, we apply our results to construct efficient algorithms for the
person name disambiguation problem. We argue that when finding top-k
Personalized PageRank lists two observations are important. Firstly, it is
crucial that we detect fast the top-k most important neighbours of a node,
while the exact order in the top-k list as well as the exact values of PageRank
are by far not so crucial. Secondly, a little number of wrong elements in top-k
lists do not really degrade the quality of top-k lists, but it can lead to
significant computational saving. Based on these two key observations we
propose Monte Carlo methods for fast detection of top-k Personalized PageRank
lists. We provide performance evaluation of the proposed methods and supply
stopping criteria. Then, we apply the methods to the person name disambiguation
problem. The developed algorithm for the person name disambiguation problem has
achieved the second place in the WePS 2010 competition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3776</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3776</id><created>2010-08-23</created><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author><author><keyname>Pasupathy</keyname><forenames>Subbarayan</forenames></author></authors><title>Green Modulations in Energy-Constrained Wireless Sensor Networks</title><categories>cs.IT math.IT</categories><comments>24 pages, 5 Figures, accepted for publication in IET Communications
  Journal 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the unique characteristics of sensor devices, finding the
energy-efficient modulation with a low-complexity implementation (refereed to
as green modulation) poses significant challenges in the physical layer design
of Wireless Sensor Networks (WSNs). Toward this goal, we present an in-depth
analysis on the energy efficiency of various modulation schemes using realistic
models in the IEEE 802.15.4 standard to find the optimum distance-based scheme
in a WSN over Rayleigh and Rician fading channels with path-loss. We describe a
proactive system model according to a flexible duty-cycling mechanism utilized
in practical sensor apparatus. The present analysis includes the effect of the
channel bandwidth and the active mode duration on the energy consumption of
popular modulation designs. Path-loss exponent and DC-DC converter efficiency
are also taken into consideration. In considering the energy efficiency and
complexity, it is demonstrated that among various sinusoidal carrier-based
modulations, the optimized Non-Coherent M-ary Frequency Shift Keying (NC-MFSK)
is the most energy-efficient scheme in sparse WSNs for each value of the
path-loss exponent, where the optimization is performed over the modulation
parameters. In addition, we show that the On-Off Keying (OOK) displays a
significant energy saving as compared to the optimized NC-MFSK in dense WSNs
with small values of path-loss exponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3786</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3786</id><created>2010-08-23</created><authors><author><keyname>Raffinot</keyname><forenames>Mathieu</forenames></author></authors><title>Consecutive ones property testing: cut or swap</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let C be a finite set of $N elements and R = {R_1,R_2, ..,R_m} a family of M
subsets of C. The family R verifies the consecutive ones property if there
exists a permutation P of C such that each R_i in R is an interval of P. There
already exist several algorithms to test this property in sum_{i=1}^m |R_i|
time, all being involved. We present a simpler algorithm, based on a new
partitioning scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3788</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3788</id><created>2010-08-23</created><updated>2010-09-24</updated><authors><author><keyname>Li</keyname><forenames>Quan-Lin</forenames></author></authors><title>Doubly Exponential Solution for Randomized Load Balancing Models with
  General Service Times</title><categories>cs.DM cs.IT cs.NI cs.PF math.IT</categories><comments>40 pages, 4 figures</comments><msc-class>68M07, 68M11</msc-class><acm-class>C.2.1; C.2.4; C.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we provide a novel and simple approach to study the
supermarket model with general service times. This approach is based on the
supplementary variable method used in analyzing stochastic models extensively.
We organize an infinite-size system of integral-differential equations by means
of the density dependent jump Markov process, and obtain a close-form solution:
doubly exponential structure, for the fixed point satisfying the system of
nonlinear equations, which is always a key in the study of supermarket models.
The fixed point is decomposited into two groups of information under a product
form: the arrival information and the service information. based on this, we
indicate two important observations: the fixed point for the supermarket model
is different from the tail of stationary queue length distribution for the
ordinary M/G/1 queue, and the doubly exponential solution to the fixed point
can extensively exist even if the service time distribution is heavy-tailed.
Furthermore, we analyze the exponential convergence of the current location of
the supermarket model to its fixed point, and study the Lipschitz condition in
the Kurtz Theorem under general service times. Based on these analysis, one can
gain a new understanding how workload probing can help in load balancing jobs
with general service times such as heavy-tailed service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3795</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3795</id><created>2010-08-23</created><authors><author><keyname>Kelsey</keyname><forenames>T W</forenames></author><author><keyname>Wallace</keyname><forenames>W H B</forenames></author></authors><title>Machine Science in Biomedicine: Practicalities, Pitfalls and Potential</title><categories>cs.IR cs.CE physics.data-an physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Science, or Data-driven Research, is a new and interesting scientific
methodology that uses advanced computational techniques to identify, retrieve,
classify and analyse data in order to generate hypotheses and develop models.
In this paper we describe three recent biomedical Machine Science studies, and
use these to assess the current state of the art with specific emphasis on data
mining, data assessment, costs, limitations, skills and tool support.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3798</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3798</id><created>2010-08-23</created><authors><author><keyname>Kelsey</keyname><forenames>Thomas W</forenames></author><author><keyname>Caserta</keyname><forenames>Benedicta</forenames></author><author><keyname>Castillo</keyname><forenames>Luis</forenames></author><author><keyname>Wallace</keyname><forenames>W Hamish B</forenames></author><author><keyname>Gonz&#xe1;lvez</keyname><forenames>Francisco C&#xf3;ppola</forenames></author></authors><title>Proliferating cell nuclear antigen (PCNA) allows the automatic
  identification of follicles in microscopic images of human ovarian tissue</title><categories>cs.CV</categories><journal-ref>Pathology and Laboratory Medicine International 2010:2; 99-105</journal-ref><doi>10.2147/PLMI.S11116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human ovarian reserve is defined by the population of nongrowing follicles
(NGFs) in the ovary. Direct estimation of ovarian reserve involves the
identification of NGFs in prepared ovarian tissue. Previous studies involving
human tissue have used hematoxylin and eosin (HE) stain, with NGF populations
estimated by human examination either of tissue under a microscope, or of
images taken of this tissue. In this study we replaced HE with proliferating
cell nuclear antigen (PCNA), and automated the identification and enumeration
of NGFs that appear in the resulting microscopic images. We compared the
automated estimates to those obtained by human experts, with the &quot;gold
standard&quot; taken to be the average of the conservative and liberal estimates by
three human experts. The automated estimates were within 10% of the &quot;gold
standard&quot;, for images at both 100x and 200x magnifications. Automated analysis
took longer than human analysis for several hundred images, not allowing for
breaks from analysis needed by humans. Our results both replicate and improve
on those of previous studies involving rodent ovaries, and demonstrate the
viability of large-scale studies of human ovarian reserve using a combination
of immunohistochemistry and computational image analysis techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3800</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3800</id><created>2010-08-23</created><authors><author><keyname>Standish</keyname><forenames>Russell K.</forenames></author></authors><title>Network Complexity of Foodwebs</title><categories>nlin.AO cs.IT cs.SI math.IT</categories><journal-ref>in Proceedings of Artficial Life XII, Fellerman et al. (eds), (MIT
  Press) p337-343 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work, I have developed an information theoretic complexity
measure of networks. When applied to several real world food webs, there is a
distinct difference in complexity between the real food web, and randomised
control networks obtained by shuffling the network links. One hypothesis is
that this complexity surplus represents information captured by the
evolutionary process that generated the network. In this paper, I test this
idea by applying the same complexity measure to several well-known artificial
life models that exhibit ecological networks: Tierra, EcoLab and Webworld.
Contrary to what was found in real networks, the artificial life generated
foodwebs had little information difference between itself and randomly shuffled
versions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3813</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3813</id><created>2010-08-23</created><updated>2012-05-18</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>The Approximate Capacity of the Gaussian N-Relay Diamond Network</title><categories>cs.IT math.IT</categories><comments>23 pages, to appear in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 59, pp. 845 - 859 ,
  February 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Gaussian &quot;diamond&quot; or parallel relay network, in which a
source node transmits a message to a destination node with the help of N
relays. Even for the symmetric setting, in which the channel gains to the
relays are identical and the channel gains from the relays are identical, the
capacity of this channel is unknown in general. The best known capacity
approximation is up to an additive gap of order N bits and up to a
multiplicative gap of order N^2, with both gaps independent of the channel
gains.
  In this paper, we approximate the capacity of the symmetric Gaussian N-relay
diamond network up to an additive gap of 1.8 bits and up to a multiplicative
gap of a factor 14. Both gaps are independent of the channel gains and, unlike
the best previously known result, are also independent of the number of relays
N in the network. Achievability is based on bursty amplify-and-forward, showing
that this simple scheme is uniformly approximately optimal, both in the
low-rate as well as in the high-rate regimes. The upper bound on capacity is
based on a careful evaluation of the cut-set bound. We also present
approximation results for the asymmetric Gaussian N-relay diamond network. In
particular, we show that bursty amplify-and-forward combined with optimal relay
selection achieves a rate within a factor O(log^4(N)) of capacity with
pre-constant in the order notation independent of the channel gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3829</identifier>
 <datestamp>2013-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3829</id><created>2010-08-23</created><updated>2011-11-22</updated><authors><author><keyname>Nehama</keyname><forenames>Ilan</forenames></author></authors><title>Approximate Judgement Aggregation</title><categories>cs.GT cs.AI cs.LG</categories><doi>10.1007/s10472-013-9358-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze judgement aggregation problems in which a group of
agents independently votes on a set of complex propositions that has some
interdependency constraint between them(e.g., transitivity when describing
preferences). We consider the issue of judgement aggregation from the
perspective of approximation. That is, we generalize the previous results by
studying approximate judgement aggregation. We relax the main two constraints
assumed in the current literature, Consistency and Independence and consider
mechanisms that only approximately satisfy these constraints, that is, satisfy
them up to a small portion of the inputs. The main question we raise is whether
the relaxation of these notions significantly alters the class of satisfying
aggregation mechanisms. The recent works for preference aggregation of Kalai,
Mossel, and Keller fit into this framework. The main result of this paper is
that, as in the case of preference aggregation, in the case of a subclass of a
natural class of aggregation problems termed `truth-functional agendas', the
set of satisfying aggregation mechanisms does not extend non-trivially when
relaxing the constraints. Our proof techniques involve Boolean Fourier
transform and analysis of voter influences for voting protocols. The question
we raise for Approximate Aggregation can be stated in terms of Property
Testing. For instance, as a corollary from our result we get a generalization
of the classic result for property testing of linearity of Boolean functions.
  An updated version (RePEc:huj:dispap:dp574R) is available at
http://www.ratio.huji.ac.il/dp_files/dp574R.pdf
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3845</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3845</id><created>2010-07-15</created><updated>2010-11-30</updated><authors><author><keyname>Srinivasan</keyname><forenames>S.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author></authors><title>A stabilized mixed formulation for unsteady Brinkman equation based on
  the method of horizontal lines</title><categories>cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a stabilized mixed formulation for unsteady
Brinkman equation. The formulation is systematically derived based on the
variational multiscale formalism and the method of horizontal lines. The
derivation does not need the assumption that the fine-scale variables do not
depend on the time, which is the case with the conventional derivation of
multiscale stabilized formulations for transient mixed problems. An expression
for the stabilization parameter is obtained in terms of a bubble function, and
appropriate bubble functions for various finite elements are also presented.
Under the proposed formulation, equal-order interpolation for the velocity and
pressure (which is computationally the most convenient) is stable.
Representative numerical results are presented to illustrate the performance of
the proposed formulation. Spatial and temporal convergence studies are also
performed, and the proposed formulation performed well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3863</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3863</id><created>2010-08-23</created><authors><author><keyname>Rodr&#xed;guez-Artalejo</keyname><forenames>Mario</forenames></author><author><keyname>Romero-D&#xed;az</keyname><forenames>Carlos A.</forenames></author></authors><title>A Generic Scheme for Qualified Logic Programming</title><categories>cs.LO cs.PL</categories><comments>23 pages, extended version with full proofs of Quantitative Logic
  Programming Revisited, in J. Garrigue and M. Hermenegildo (Eds.), FLOPS 2008,
  LNCS 4989, pp. 272-288, 2008. Springer-Verlag Berlin Heidelberg 2008</comments><report-no>SIC-1-08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncertainty in Logic Programming has been investigated since about 25 years,
publishing papers dealing with various approaches to semantics and different
applications. This report is intended as a first step towards the investigation
of qualified computations in Constraint Functional Logic Programming, including
uncertain computations as a particular case. We revise an early proposal,
namely van Emden's Quantitative Logic Programming, and we improve it in two
ways. Firstly, we generalize van Emden's QLP to a generic scheme QLP(D)
parameterized by any given Qualification Domain D, which must be a lattice
satisfying certain natural axioms. We present several interesting instances for
D, one of which corresponds to van Emden's QLP. Secondly, we generalize van
Emden's results by providing stronger ones, concerning both semantics and goal
solving. We present Qualified SLD Resolution over D, a sound and strongly
complete goal solving procedure for QLP(D), which is applicable to open goals
and can be efficiently implemented using CLP technology over any constraint
domain CD able to deal with qualification constraints over D. We have developed
a prototype implementation of some instances of the QLP(D) scheme (including
van Emden's QLP) on top of the CFLP system TOY.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3867</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3867</id><created>2010-08-23</created><authors><author><keyname>Caballero</keyname><forenames>Rafael</forenames></author><author><keyname>Rodr&#xed;guez-Artalejo</keyname><forenames>Mario</forenames></author><author><keyname>Romero-D&#xed;az</keyname><forenames>Carlos A.</forenames></author></authors><title>Similarity-based Reasoning in Qualified Logic Programming</title><categories>cs.LO cs.PL</categories><comments>10 pages, 2 figures, revised edition of Similarity-based Reasoning in
  Qualified Logic Programming, in PPDP '08: Proceedings of the 10th
  international ACM SIGPLAN conference on Principles and Practice of
  Declarative Programming. ACM, Valencia, Spain, 185-194. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity-based Logic Programming (briefly, SLP ) has been proposed to
enhance the LP paradigm with a kind of approximate reasoning which supports
flexible information retrieval applications. This approach uses a fuzzy
similarity relation R between symbols in the program's signature, while keeping
the syntax for program clauses as in classical LP. Another recent proposal is
the QLP(D) scheme for Qualified Logic Programming, an extension of the LP
paradigm which supports approximate reasoning and more. This approach uses
annotated program clauses and a parametrically given domain D whose elements
qualify logical assertions by measuring their closeness to various users'
expectations. In this paper we propose a more expressive scheme SQLP(R,D) which
subsumes both SLP and QLP(D) as particular cases. We also show that SQLP(R,D)
programs can be transformed into semantically equivalent QLP(D) programs. As a
consequence, existing QLP(D) implementations can be used to give efficient
support for similarity-based reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3879</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3879</id><created>2010-08-23</created><authors><author><keyname>Moinard</keyname><forenames>Yves</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>A formalism for causal explanations with an Answer Set Programming
  translation</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>4th International Conference on Knowledge Science, Engineering \&amp;
  Management (KSEM 2010), Belfast : United Kingdom (2010)</journal-ref><doi>10.1007/978-3-642-15280-1_56</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the practicality for a user of using Answer Set Programming (ASP)
for representing logical formalisms. Our example is a formalism aiming at
capturing causal explanations from causal information. We show the naturalness
and relative efficiency of this translation job. We are interested in the ease
for writing an ASP program. Limitations of the earlier systems made that in
practice, the ``declarative aspect'' was more theoretical than practical. We
show how recent improvements in working ASP systems facilitate the translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3889</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3889</id><created>2010-08-23</created><authors><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Flatland</keyname><forenames>Robin</forenames></author></authors><title>Connectivity of Graphs Induced by Directional Antennas</title><categories>cs.CG</categories><comments>8 pages, 10 figures</comments><acm-class>C.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of finding an orientation and a minimum
radius for directional antennas of a fixed angle placed at the points of a
planar set S, that induce a strongly connected communication graph. We consider
problem instances in which antenna angles are fixed at 90 and 180 degrees, and
establish upper and lower bounds for the minimum radius necessary to guarantee
strong connectivity. In the case of 90-degree angles, we establish a lower
bound of 2 and an upper bound of 7. In the case of 180-degree angles, we
establish a lower bound of sqrt(3) and an upper bound of 1+sqrt(3). Underlying
our results is the assumption that the unit disk graph for S is connected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3895</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3895</id><created>2010-08-23</created><authors><author><keyname>Cie&#x15b;li&#x144;ski</keyname><forenames>Jan L.</forenames></author><author><keyname>Ratkiewicz</keyname><forenames>Bogus&#x142;aw</forenames></author></authors><title>Discrete gradient algorithms of high order for one-dimensional systems</title><categories>physics.comp-ph cs.NA math.NA</categories><comments>22 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to increase the order of one-dimensional discrete gradient
numerical integrator without losing its advantages, such as exceptional
stability, exact conservation of the energy integral and exact preservation of
the trajectories in the phase space. The accuracy of our integrators is higher
by several orders of magnitude as compared with the standard discrete gradient
scheme (modified midpoint rule) and, what is more, our schemes have very high
accuracy even for large time steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3926</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3926</id><created>2010-08-23</created><authors><author><keyname>Karrer</keyname><forenames>Brian</forenames></author><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>Stochastic blockmodels and community structure in networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.data-an</categories><comments>11 pages, 3 figures</comments><journal-ref>Phys. Rev. E 83, 016107 (2011)</journal-ref><doi>10.1103/PhysRevE.83.016107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic blockmodels have been proposed as a tool for detecting community
structure in networks as well as for generating synthetic networks for use as
benchmarks. Most blockmodels, however, ignore variation in vertex degree,
making them unsuitable for applications to real-world networks, which typically
display broad degree distributions that can significantly distort the results.
Here we demonstrate how the generalization of blockmodels to incorporate this
missing element leads to an improved objective function for community detection
in complex networks. We also propose a heuristic algorithm for community
detection using this objective function or its non-degree-corrected counterpart
and show that the degree-corrected version dramatically outperforms the
uncorrected one in both real-world and synthetic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3932</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3932</id><created>2010-08-23</created><updated>2010-09-13</updated><authors><author><keyname>He</keyname><forenames>Miao</forenames></author><author><keyname>Murugesan</keyname><forenames>Sugumar</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author></authors><title>Multiple Timescale Dispatch and Scheduling for Stochastic Reliability in
  Smart Grids with Wind Generation Integration</title><categories>cs.SY cs.PF</categories><comments>Submitted to IEEE Infocom 2011. Contains 10 pages and 4 figures.
  Replaces the previous arXiv submission (dated Aug-23-2010) with the same
  title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrating volatile renewable energy resources into the bulk power grid is
challenging, due to the reliability requirement that at each instant the load
and generation in the system remain balanced. In this study, we tackle this
challenge for smart grid with integrated wind generation, by leveraging
multi-timescale dispatch and scheduling. Specifically, we consider smart grids
with two classes of energy users - traditional energy users and opportunistic
energy users (e.g., smart meters or smart appliances), and investigate pricing
and dispatch at two timescales, via day-ahead scheduling and realtime
scheduling. In day-ahead scheduling, with the statistical information on wind
generation and energy demands, we characterize the optimal procurement of the
energy supply and the day-ahead retail price for the traditional energy users;
in realtime scheduling, with the realization of wind generation and the load of
traditional energy users, we optimize real-time prices to manage the
opportunistic energy users so as to achieve systemwide reliability. More
specifically, when the opportunistic users are non-persistent, i.e., a subset
of them leave the power market when the real-time price is not acceptable, we
obtain closedform solutions to the two-level scheduling problem. For the
persistent case, we treat the scheduling problem as a multitimescale Markov
decision process. We show that it can be recast, explicitly, as a classic
Markov decision process with continuous state and action spaces, the solution
to which can be found via standard techniques. We conclude that the proposed
multi-scale dispatch and scheduling with real-time pricing can effectively
address the volatility and uncertainty of wind generation and energy demand,
and has the potential to improve the penetration of renewable energy into smart
grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3938</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3938</id><created>2010-08-23</created><authors><author><keyname>Kale</keyname><forenames>Satyen</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>Combinatorial Approximation Algorithms for MaxCut using Random Walks</title><categories>cs.DS cs.DM</categories><comments>28 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first combinatorial approximation algorithm for Maxcut that beats
the trivial 0.5 factor by a constant. The main partitioning procedure is very
intuitive, natural, and easily described. It essentially performs a number of
random walks and aggregates the information to provide the partition. We can
control the running time to get an approximation factor-running time tradeoff.
We show that for any constant b &gt; 1.5, there is an O(n^{b}) algorithm that
outputs a (0.5+delta)-approximation for Maxcut, where delta = delta(b) is some
positive constant.
  One of the components of our algorithm is a weak local graph partitioning
procedure that may be of independent interest. Given a starting vertex $i$ and
a conductance parameter phi, unless a random walk of length ell = O(log n)
starting from i mixes rapidly (in terms of phi and ell), we can find a cut of
conductance at most phi close to the vertex. The work done per vertex found in
the cut is sublinear in n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3940</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3940</id><created>2010-08-23</created><authors><author><keyname>Gatsis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Power Control with Imperfect Exchanges and Applications to Spectrum
  Sharing</title><categories>cs.NI</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2011.2143709</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In various applications, the effect of errors in gradient-based iterations is
of particular importance when seeking saddle points of the Lagrangian function
associated with constrained convex optimization problems. Of particular
interest here are problems arising in power control applications, where network
utility is maximized subject to minimum signal-to-interference-plus-noise ratio
(SINR) constraints, maximum interference constraints, maximum received power
constraints, or simultaneous minimum and maximum SINR constraints. Especially
when the gradient iterations are executed in a disributed fashion, imperfect
exchanges among the link nodes may result in erroneous gradient vectors. In
order to assess and cope with such errors, two running averages (ergodic
sequences) are formed from the iterates generated by the perturbed saddle point
method, each with complementary strengths. Under the assumptions of problem
convexity and error boundedness, bounds on the constraint violation and the
suboptimality per iteration index are derived. The two types of running
averages are tested on a spectrum sharing problem with minimum and maximum SINR
constraints, as well as maximum interference constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3977</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3977</id><created>2010-08-24</created><authors><author><keyname>Morris</keyname><forenames>Tom</forenames></author><author><keyname>Mietchen</keyname><forenames>Daniel</forenames></author></authors><title>Collaborative Structuring of Knowledge by Experts and the Public</title><categories>cs.DL cs.SI</categories><comments>A contribution to OKCON 2010 (cf. http://okfn.org/okcon/).
  Contextualized on-wiki at
  http://en.citizendium.org/wiki/Open_Knowledge_Conference/Program/Collaborative_Structuring_of_Knowledge_by_Experts_and_the_Public.
  Available online at http://ceur-ws.org/Vol-575/paper5.pdf, Also at:
  http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-575/</comments><journal-ref>Proceedings of the 5th Open Knowledge Conference (London, UK,
  April 24, 2010), pp. 29-41</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  There is much debate on how public participation and expertise can be brought
together in collaborative knowledge environments. One of the experiments
addressing the issue directly is Citizendium. In seeking to harvest the
strengths (and avoiding the major pitfalls) of both user-generated wiki
projects and traditional expert-approved reference works, it is a wiki to which
anybody can contribute using their real names, while those with specific
expertise are given a special role in assessing the quality of content. Upon
fulfillment of a set of criteria like factual and linguistic accuracy, lack of
bias, and readability by non-specialists, these entries are forked into two
versions: a stable (and thus citable) approved &quot;cluster&quot; (an article with
subpages providing supplementary information) and a draft version, the latter
to allow for further development and updates. We provide an overview of how
Citizendium is structured and what it offers to the open knowledge communities,
particularly to those engaged in education and research. Special attention will
be paid to the structures and processes put in place to provide for transparent
governance, to encourage collaboration, to resolve disputes in a civil manner
and by taking into account expert opinions, and to facilitate navigation of the
site and contextualization of its contents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.3998</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.3998</id><created>2010-08-24</created><authors><author><keyname>El-Samadony</keyname><forenames>Ahmed</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author></authors><title>Cognitive Radio Transmission Strategies for Primary Erasure Channels</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in cognitive radio systems is that the cognitive radio
is ignorant of the primary channel state and the interference it inflicts on
the primary license holder. In this paper we assume that the primary
transmitter sends packets across an erasure channel and the primary receiver
employs ACK/NAK feedback (ARQ) to retransmit erased packets. The cognitive
radio can eavesdrop on the primary's ARQs. Assuming the primary channel states
follow a Markov chain, this feedback gives the cognitive radio an indication of
the primary link quality. Based on the ACK/NACK received, we devise optimal
transmission strategies for the cognitive radio so as to maximize a weighted
sum of primary and secondary throughput. The actual weight used during network
operation is determined by the degree of protection afforded to the primary
link. We study a two-state model where we characterize a scheme that spans the
boundary of the primary-secondary rate region. Moreover, we study a three-state
model where we derive the optimal strategy using dynamic programming. We also
show via simulations that our optimal strategies achieve gains over the simple
greedy algorithm for a range of primary channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4000</identifier>
 <datestamp>2011-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4000</id><created>2010-08-24</created><authors><author><keyname>Zhou</keyname><forenames>Tianyi</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Wu</keyname><forenames>Xindong</forenames></author></authors><title>NESVM: a Fast Gradient Method for Support Vector Machines</title><categories>cs.LG stat.ML</categories><comments>10 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Support vector machines (SVMs) are invaluable tools for many practical
applications in artificial intelligence, e.g., classification and event
recognition. However, popular SVM solvers are not sufficiently efficient for
applications with a great deal of samples as well as a large number of
features. In this paper, thus, we present NESVM, a fast gradient SVM solver
that can optimize various SVM models, e.g., classical SVM, linear programming
SVM and least square SVM. Compared against SVM-Perf
\cite{SVM_Perf}\cite{PerfML} (its convergence rate in solving the dual SVM is
upper bounded by $\mathcal O(1/\sqrt{k})$, wherein $k$ is the number of
iterations.) and Pegasos \cite{Pegasos} (online SVM that converges at rate
$\mathcal O(1/k)$ for the primal SVM), NESVM achieves the optimal convergence
rate at $\mathcal O(1/k^{2})$ and a linear time complexity. In particular,
NESVM smoothes the non-differentiable hinge loss and $\ell_1$-norm in the
primal SVM. Then the optimal gradient method without any line search is adopted
to solve the optimization. In each iteration round, the current gradient and
historical gradients are combined to determine the descent direction, while the
Lipschitz constant determines the step size. Only two matrix-vector
multiplications are required in each iteration round. Therefore, NESVM is more
efficient than existing SVM solvers. In addition, NESVM is available for both
linear and nonlinear kernels. We also propose &quot;homotopy NESVM&quot; to accelerate
NESVM by dynamically decreasing the smooth parameter and using the continuation
method. Our experiments on census income categorization, indoor/outdoor scene
classification, event recognition and scene recognition suggest the efficiency
and the effectiveness of NESVM. The MATLAB code of NESVM will be available on
our website for further assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4035</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4035</id><created>2010-08-24</created><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author></authors><title>A dichotomy theorem for conservative general-valued CSPs</title><categories>cs.CC</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of valued constraint satisfaction problems (VCSP). A
problem from VCSP is characterised by a \emph{constraint language}, a fixed set
of cost functions over a finite domain. An instance of the problem is specified
by a sum of cost functions from the language and the goal is to minimise the
sum. We consider the case of so-called \emph{conservative} languages; that is,
languages containing all unary cost functions, thus allowing arbitrary
restrictions on the domains of the variables. We prove a Schaefer-like
dichotomy theorem for this case: if all cost functions in the language satisfy
a certain condition (specified by a complementary combination of \emph{STP and
MJN multimorphisms}) then any instance can be solved in polynomial time by the
algorithm of Kolmogorov and Zivny (arXiv:1008.3104v1), otherwise the language
is NP-hard. This generalises recent results of Takhanov (STACS'10) who
considered $\{0,\infty\}$-valued languages containing additionally all
finite-valued unary cost functions, and Kolmogorov and Zivny
(arXiv:1008.1555v1) who considered \emph{finite-valued} conservative languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4039</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4039</id><created>2010-08-24</created><authors><author><keyname>Balakrishnan</keyname><forenames>R.</forenames></author><author><keyname>Sridharan</keyname><forenames>N.</forenames></author><author><keyname>Iyer</keyname><forenames>K. V.</forenames></author></authors><title>A sharp lower bound for the Wiener index of a graph</title><categories>cs.DM math.CO</categories><comments>Accepted for publication in Ars Combinatoria</comments><journal-ref>Ars Combinatoria,v.XCVII,Oct. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a simple connected undirected graph G, the Wiener index W(G) of G is
defined as half the sum of the distances over all pairs of vertices of G. In
practice, G corresponds to what is known as the molecular graph of an organic
compound. We obtain a sharp lower bound for W(G) of an arbitrary graph in terms
of the order, size and diameter of G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4049</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4049</id><created>2010-08-24</created><updated>2010-08-25</updated><authors><author><keyname>Curran</keyname><forenames>Kevin</forenames></author><author><keyname>Yuan</keyname><forenames>Peng</forenames></author><author><keyname>Coyle</keyname><forenames>Damian</forenames></author></authors><title>Discriminating between Nasal and Mouth Breathing</title><categories>cs.NE</categories><comments>Hi, I just wish to withdraw this paper from the site until further
  notice. Thanks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recommendation to change breathing patterns from the mouth to the nose
can have a significantly positive impact upon the general well being of the
individual. We classify nasal and mouth breathing by using an acoustic sensor
and intelligent signal processing techniques. The overall purpose is to
investigate the possibility of identifying the differences in patterns between
nasal and mouth breathing in order to integrate this information into a
decision support system which will form the basis of a patient monitoring and
motivational feedback system to recommend the change from mouth to nasal
breathing. Our findings show that the breath pattern can be discriminated in
certain places of the body both by visual spectrum analysis and with a Back
Propagation neural network classifier. The sound file recoded from the sensor
placed on the hollow in the neck shows the most promising accuracy which is as
high as 90%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4063</identifier>
 <datestamp>2014-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4063</id><created>2010-08-24</created><updated>2014-07-24</updated><authors><author><keyname>Zinovyev</keyname><forenames>A.</forenames></author><author><keyname>Gorban</keyname><forenames>A. N.</forenames></author></authors><title>Nonlinear Quality of Life Index</title><categories>cs.NE stat.AP</categories><comments>9 pages, 1 figure, 1 table with data for 171 countries. In this case
  study we use only publicly available data taken from GAPMINDER online data
  base for 2005</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present details of the analysis of the nonlinear quality of life index for
171 countries. This index is based on four indicators: GDP per capita by
Purchasing Power Parities, Life expectancy at birth, Infant mortality rate, and
Tuberculosis incidence. We analyze the structure of the data in order to find
the optimal and independent on expert's opinion way to map several numerical
indicators from a multidimensional space onto the one-dimensional space of the
quality of life. In the 4D space we found a principal curve that goes &quot;through
the middle&quot; of the dataset and project the data points on this curve. The order
along this principal curve gives us the ranking of countries. Projection onto
the principal curve provides a solution to the classical problem of
unsupervised ranking of objects. It allows us to find the independent on
expert's opinion way to project several numerical indicators from a
multidimensional space onto the one-dimensional space of the index values. This
projection is, in some sense, optimal and preserves as much information as
possible. For computation we used ViDaExpert, a tool for visualization and
analysis of multidimensional vectorial data (arXiv:1406.5550).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4067</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4067</id><created>2010-08-24</created><authors><author><keyname>Moser</keyname><forenames>Robin A.</forenames></author><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author></authors><title>A Full Derandomization of Schoening's k-SAT Algorithm</title><categories>cs.DS cs.DM</categories><comments>11 pages</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schoening in 1999 presented a simple randomized algorithm for k-SAT with
running time O(a^n * poly(n)) for a = 2(k-1)/k. We give a deterministic version
of this algorithm running in time O((a+epsilon)^n * poly(n)), where epsilon &gt; 0
can be made arbitrarily small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4071</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4071</id><created>2010-08-24</created><authors><author><keyname>Cooper</keyname><forenames>Martin C.</forenames></author><author><keyname>Zivny</keyname><forenames>Stanislav</forenames></author></authors><title>Hybrid tractability of soft constraint problems</title><categories>cs.AI cs.DS</categories><comments>A full version of a CP'10 paper, 26 pages</comments><journal-ref>Artificial Intelligence 175(9-10) 1555-1569 (2011)</journal-ref><doi>10.1016/j.artint.2011.02.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The constraint satisfaction problem (CSP) is a central generic problem in
computer science and artificial intelligence: it provides a common framework
for many theoretical problems as well as for many real-life applications. Soft
constraint problems are a generalisation of the CSP which allow the user to
model optimisation problems. Considerable effort has been made in identifying
properties which ensure tractability in such problems. In this work, we
initiate the study of hybrid tractability of soft constraint problems; that is,
properties which guarantee tractability of the given soft constraint problem,
but which do not depend only on the underlying structure of the instance (such
as being tree-structured) or only on the types of soft constraints in the
instance (such as submodularity). We present several novel hybrid classes of
soft constraint problems, which include a machine scheduling problem,
constraint problems of arbitrary arities with no overlapping nogoods, and the
SoftAllDiff constraint with arbitrary unary soft constraints. An important tool
in our investigation will be the notion of forbidden substructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4099</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4099</id><created>2010-08-24</created><authors><author><keyname>Bania</keyname><forenames>Piotr</forenames></author></authors><title>Security Mitigations for Return-Oriented Programming Attacks</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the discovery of new exploit techniques, new protection mechanisms are
needed as well. Mitigations like DEP (Data Execution Prevention) or ASLR
(Address Space Layout Randomization) created a significantly more difficult
environment for vulnerability exploitation. Attackers, however, have recently
developed new exploitation methods which are capable of bypassing the operating
system's security protection mechanisms. In this paper we present a short
summary of novel and known mitigation techniques against return-oriented
programming (ROP) attacks. The techniques described in this article are related
mostly to x86-32 processors and Microsoft Windows operating systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4104</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4104</id><created>2010-08-24</created><updated>2011-01-10</updated><authors><author><keyname>Plaumann</keyname><forenames>Daniel</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author><author><keyname>Vinzant</keyname><forenames>Cynthia</forenames></author></authors><title>Quartic Curves and Their Bitangents</title><categories>math.AG cs.SC</categories><comments>26 pages, 3 figures, added references, fixed theorems 4.3 and 7.8,
  other minor changes</comments><msc-class>Primary: 14H45, Secondary: 13P15, 14H50, 14Q05</msc-class><journal-ref>Journal of Symbolic Computation 46 (2011) 712-733</journal-ref><doi>10.1016/j.jsc.2011.01.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A smooth quartic curve in the complex projective plane has 36 inequivalent
representations as a symmetric determinant of linear forms and 63
representations as a sum of three squares. These correspond to Cayley octads
and Steiner complexes respectively. We present exact algorithms for computing
these objects from the 28 bitangents. This expresses Vinnikov quartics as
spectrahedra and positive quartics as Gram matrices. We explore the geometry of
Gram spectrahedra and we find equations for the variety of Cayley octads.
Interwoven is an exposition of much of the 19th century theory of plane
quartics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4115</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4115</id><created>2010-08-24</created><authors><author><keyname>Zhang</keyname><forenames>Weituo</forenames></author><author><keyname>Lim</keyname><forenames>Chjan C.</forenames></author></authors><title>Noise in Naming Games, partial synchronization and community detection
  in social networks</title><categories>cs.MA cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Naming Games (NG) are agent-based models for agreement dynamics, peer
pressure and herding in social networks, and protocol selection in autonomous
ad-hoc sensor networks. By introducing a small noise term to the NG, the
resulting Markov Chain model called Noisy Naming Games (NNG) are ergodic, in
which all partial consensus states are recurrent. By using Gibbs-Markov
equivalence we show how to get the NNG's stationary distribution in terms of
the local specification of a related Markov Random Field (MRF). By ordering the
partially-synchronized states according to their Gibbs energy, taken here to be
a good measure of social tension, this method offers an enhanced method for
community-detection in social interaction data. We show how the lowest Gibbs
energy multi-name states separate and display the hidden community structures
within a social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4135</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4135</id><created>2010-08-24</created><updated>2010-08-26</updated><authors><author><keyname>Madhok</keyname><forenames>Vaibhav</forenames></author><author><keyname>Datta</keyname><forenames>Animesh</forenames></author></authors><title>Interpreting quantum discord through quantum state merging</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, no figures. See http://arxiv.org/abs/1008.3205 for similar
  results. Typos fixed, references and acknowledgements updated. End note added</comments><journal-ref>Phys. Rev. A, 83, 032323 (2011)</journal-ref><doi>10.1103/PhysRevA.83.032323</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an operational interpretation of quantum discord based on the
quantum state merging protocol. Quantum discord is the markup in the cost of
quantum communication in the process of quantum state merging, if one discards
relevant prior information. Our interpretation has an intuitive explanation
based on the strong subadditivity of von Neumann entropy. We use our result to
provide operational interpretations of other quantities like the local purity
and quantum deficit. Finally, we discuss in brief some instances where our
interpretation is valid in the single copy scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4153</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4153</id><created>2010-08-24</created><authors><author><keyname>Hodtani</keyname><forenames>Ghosheh Abed</forenames></author></authors><title>Improvement of the Han-Kobayashi Rate Region for General Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans.on Information theory, on June 27</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Allowing the input auxiliary random variables to be correlated and using the
binning scheme, the Han- Kobayashi (HK) rate region for general interference
channel is improved. The obtained new achievable rate region (i) is shown to
encompass the HK region and its simplified description, i.e., Chong-Motani-Garg
(CMG) region,considering a detailed and favorable comparison between different
versions of the regions, and (ii) has an interesting and easy interpretation:
as expected, any rate in our region has generally two additional terms in
comparison with the HK region (one due to the input correlation and the other
as a result of the binning scheme).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4157</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4157</id><created>2010-08-24</created><authors><author><keyname>Hodtani</keyname><forenames>Ghosheh Abed</forenames></author></authors><title>A New Achievable Rate Region for the Cognitive Radio Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory, on July 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering a general input distribution, using Gel'fand-Pinsker full binning
scheme and the Han- Kobayashi (HK) jointly decoding strategy, we obtain a new
achievable rate region for the cognitive radio channel (CRC) and then derive a
simplified description for the region, by a combination of Cover superposition
coding, binning scheme and the HK decoding technique. Our rate region (i) has
an interesting interpretation, i.e., any rate in the region, as expected, has
generally three additional terms in comparison with the KH region for the
interference channel (IC): one term due to the input correlation, the other
term due to binning scheme and the third term due to the interference dependent
on the inputs, (ii) is really a generalization of the HK region for the IC to
the CRC by the use of binning scheme, and as a result of this generalization we
see that different versions of our region for the CRC are reduced to different
versions of the previous results for the IC, and (iii) is a generalized and
improved version of previous results ,i.g., the Devroye-Mitran-Tarokh (DMT)
region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4161</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4161</id><created>2010-08-24</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Percolation and Connectivity in the Intrinsically Secure Communications
  Graph</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to exchange secret information is critical to many commercial,
governmental, and military networks. The intrinsically secure communications
graph (iS-graph) is a random graph which describes the connections that can be
securely established over a large-scale network, by exploiting the physical
properties of the wireless medium. This paper aims to characterize the global
properties of the iS-graph in terms of: (i) percolation on the infinite plane,
and (ii) full connectivity on a finite region. First, for the Poisson iS-graph
defined on the infinite plane, the existence of a phase transition is proven,
whereby an unbounded component of connected nodes suddenly arises as the
density of legitimate nodes is increased. This shows that long-range secure
communication is still possible in the presence of eavesdroppers. Second, full
connectivity on a finite region of the Poisson iS-graph is considered. The
exact asymptotic behavior of full connectivity in the limit of a large density
of legitimate nodes is characterized. Then, simple, explicit expressions are
derived in order to closely approximate the probability of full connectivity
for a finite density of legitimate nodes. The results help clarify how the
presence of eavesdroppers can compromise long-range secure communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4166</identifier>
 <datestamp>2011-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4166</id><created>2010-08-24</created><authors><author><keyname>Singer</keyname><forenames>Sanja</forenames></author><author><keyname>Singer</keyname><forenames>Sasa</forenames></author><author><keyname>Novakovic</keyname><forenames>Vedran</forenames></author><author><keyname>Davidovic</keyname><forenames>Davor</forenames></author><author><keyname>Bokulic</keyname><forenames>Kresimir</forenames></author><author><keyname>Uscumlic</keyname><forenames>Aleksandar</forenames></author></authors><title>Three-Level Parallel J-Jacobi Algorithms for Hermitian Matrices</title><categories>cs.NA math.NA</categories><comments>Submitted for publication</comments><msc-class>65F15 (Primary) 65Y05, 65Y20, 46C20, 68W10 (Secondary)</msc-class><acm-class>G.1.3; G.4</acm-class><doi>10.1016/j.amc.2011.11.067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes several efficient parallel implementations of the
one-sided hyperbolic Jacobi-type algorithm for computing eigenvalues and
eigenvectors of Hermitian matrices. By appropriate blocking of the algorithms
an almost ideal load balancing between all available processors/cores is
obtained. A similar blocking technique can be used to exploit local cache
memory of each processor to further speed up the process. Due to diversity of
modern computer architectures, each of the algorithms described here may be the
method of choice for a particular hardware and a given matrix size. All
proposed block algorithms compute the eigenvalues with relative accuracy
similar to the original non-blocked Jacobi algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4174</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4174</id><created>2010-08-24</created><authors><author><keyname>Grossman</keyname><forenames>Thomas A.</forenames></author><author><keyname>Ozluk</keyname><forenames>Ozgur</forenames></author></authors><title>Spreadsheets Grow Up: Three Spreadsheet Engineering Methodologies for
  Large Financial Planning Models</title><categories>cs.SE</categories><comments>14 pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 1-15
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many large financial planning models are written in a spreadsheet programming
language (usually Microsoft Excel) and deployed as a spreadsheet application.
Three groups, FAST Alliance, Operis Group, and BPM Analytics (under the name
&quot;Spreadsheet Standards Review Board&quot;) have independently promulgated
standardized processes for efficiently building such models. These spreadsheet
engineering methodologies provide detailed guidance on design, construction
process, and quality control. We summarize and compare these methodologies.
They share many design practices, and standardized, mechanistic procedures to
construct spreadsheets. We learned that a written book or standards document is
by itself insufficient to understand a methodology. These methodologies
represent a professionalization of spreadsheet programming, and can provide a
means to debug a spreadsheet that contains errors. We find credible the
assertion that these spreadsheet engineering methodologies provide enhanced
productivity, accuracy and maintainability for large financial planning models
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4177</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4177</id><created>2010-08-24</created><updated>2011-08-23</updated><authors><author><keyname>Nguyen</keyname><forenames>Dung Viet</forenames></author><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Marcellin</keyname><forenames>Michael W.</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author></authors><title>LDPC Codes from Latin Squares Free of Small Trapping Sets</title><categories>cs.IT math.IT</categories><comments>This is a 21 page paper. It contains 18 figures and 4 tables. This
  paper was submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the construction of low-density parity-check
(LDPC) codes with low error floors. Two main contributions are made. First, a
new class of structured LDPC codes is introduced. The parity check matrices of
these codes are arrays of permutation matrices which are obtained from Latin
squares and form a finite field under some matrix operations. Second, a method
to construct LDPC codes with low error floors on the binary symmetric channel
(BSC) is presented. Codes are constructed so that their Tanner graphs are free
of certain small trapping sets. These trapping sets are selected from the
Trapping Set Ontology for the Gallager A/B decoder. They are selected based on
their relative harmfulness for a given decoding algorithm. We evaluate the
relative harmfulness of different trapping sets for the sum product algorithm
(SPA) by using the topological relations among them and by analyzing the
decoding failures on one trapping set in the presence or absence of other
trapping sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4182</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4182</id><created>2010-08-24</created><updated>2011-01-03</updated><authors><author><keyname>Travers</keyname><forenames>Nicholas F.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>Exact Synchronization for Finite-State Sources</title><categories>nlin.CD cs.IT math.DS math.IT stat.ML</categories><comments>9 pages, 6 figures; now includes analytical calculation of the
  synchronization rate; updates and corrections added</comments><doi>10.1007/s10955-011-0342-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze how an observer synchronizes to the internal state of a
finite-state information source, using the epsilon-machine causal
representation. Here, we treat the case of exact synchronization, when it is
possible for the observer to synchronize completely after a finite number of
observations. The more difficult case of strictly asymptotic synchronization is
treated in a sequel. In both cases, we find that an observer, on average, will
synchronize to the source state exponentially fast and that, as a result, the
average accuracy in an observer's predictions of the source output approaches
its optimal level exponentially fast as well. Additionally, we show here how to
analytically calculate the synchronization rate for exact epsilon-machines and
provide an efficient polynomial-time algorithm to test epsilon-machines for
exactness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4184</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4184</id><created>2010-08-24</created><authors><author><keyname>Sun</keyname><forenames>Ke</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author><author><keyname>Wang</keyname><forenames>Yongliang</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Direct Data Domain STAP using Sparse Representation of Clutter Spectrum</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, submitted to Elsevier,Signal Processing,
  August,2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space-time adaptive processing (STAP) is an effective tool for detecting a
moving target in the airborne radar system. Due to the fast-changing clutter
scenario and/or non side-looking configuration, the stationarity of the
training data is destroyed such that the statistical-based methods suffer
performance degradation. Direct data domain (D3) methods avoid non-stationary
training data and can effectively suppress the clutter within the test cell.
However, this benefit comes at the cost of a reduced system degree of freedom
(DOF), which results in performance loss. In this paper, by exploiting the
intrinsic sparsity of the spectral distribution, a new direct data domain
approach using sparse representation (D3SR) is proposed, which seeks to
estimate the high-resolution space-time spectrum with only the test cell. The
simulation of both side-looking and non side-looking cases has illustrated the
effectiveness of the D3SR spectrum estimation using focal underdetermined
system solution (FOCUSS) and norm minimization. Then the clutter covariance
matrix (CCM) and the corresponding adaptive filter can be effectively obtained.
Since D3SR maintains the full system DOF, it can achieve better performance of
output signal-clutter-ratio (SCR) and minimum detectable velocity (MDV) than
current D3 methods, e.g., direct data domain least squares (D3LS). Thus D3SR is
more effective against the range-dependent clutter and interference in the
non-stationary clutter scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4185</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4185</id><created>2010-08-24</created><authors><author><keyname>Sun</keyname><forenames>Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Airborne Radar STAP using Sparse Recovery of Clutter Spectrum</title><categories>cs.IT math.IT</categories><comments>28 pages, 11 figures, Submitted to the IEEE Transactions on Aerospace
  and Electronic Systems in April,2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space-time adaptive processing (STAP) is an effective tool for detecting a
moving target in spaceborne or airborne radar systems. Statistical-based STAP
methods generally need sufficient statistically independent and identically
distributed (IID) training data to estimate the clutter characteristics.
However, most actual clutter scenarios appear only locally stationary and lack
sufficient IID training data. In this paper, by exploiting the intrinsic
sparsity of the clutter distribution in the angle-Doppler domain, a new STAP
algorithm called SR-STAP is proposed, which uses the technique of sparse
recovery to estimate the clutter space-time spectrum. Joint sparse recovery
with several training samples is also used to improve the estimation
performance. Finally, an effective clutter covariance matrix (CCM) estimate and
the corresponding STAP filter are designed based on the estimated clutter
spectrum. Both the Mountaintop data and simulated experiments have illustrated
the fast convergence rate of this approach. Moreover, SR-STAP is less dependent
on prior knowledge, so it is more robust to the mismatch in the prior knowledge
than knowledge-based STAP methods. Due to these advantages, SR-STAP has great
potential for application in actual clutter scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4188</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4188</id><created>2010-08-24</created><authors><author><keyname>L&#xe4;mmel</keyname><forenames>Ralf</forenames></author><author><keyname>Zaytsev</keyname><forenames>Vadim</forenames></author></authors><title>Recovering Grammar Relationships for the Java Language Specification</title><categories>cs.PL</categories><journal-ref>Software Quality Journal, 19:2, pages 333-378. Springer, 2011</journal-ref><doi>10.1007/s11219-010-9116-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grammar convergence is a method that helps discovering relationships between
different grammars of the same language or different language versions. The key
element of the method is the operational, transformation-based representation
of those relationships. Given input grammars for convergence, they are
transformed until they are structurally equal. The transformations are composed
from primitive operators; properties of these operators and the composed chains
provide quantitative and qualitative insight into the relationships between the
grammars at hand. We describe a refined method for grammar convergence, and we
use it in a major study, where we recover the relationships between all the
grammars that occur in the different versions of the Java Language
Specification (JLS). The relationships are represented as grammar
transformation chains that capture all accidental or intended differences
between the JLS grammars. This method is mechanized and driven by nominal and
structural differences between pairs of grammars that are subject to
asymmetric, binary convergence steps. We present the underlying operator suite
for grammar transformation in detail, and we illustrate the suite with many
examples of transformations on the JLS grammars. We also describe the
extraction effort, which was needed to make the JLS grammars amenable to
automated processing. We include substantial metadata about the convergence
process for the JLS so that the effort becomes reproducible and transparent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4206</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4206</id><created>2010-08-25</created><authors><author><keyname>Tabassum</keyname><forenames>Mirza Rehenuma</forenames></author><author><keyname>Gias</keyname><forenames>Alim Ul</forenames></author><author><keyname>Kamal</keyname><forenames>Md. Mostafa</forenames></author><author><keyname>Muctadir</keyname><forenames>Hossain Muhammad</forenames></author><author><keyname>Ibrahim</keyname><forenames>Muhammad</forenames></author><author><keyname>Shakir</keyname><forenames>Asif Khan</forenames></author><author><keyname>Imran</keyname><forenames>Asif</forenames></author><author><keyname>Islamm</keyname><forenames>Saiful</forenames></author><author><keyname>Rabbani</keyname><forenames>Md. Golam</forenames></author><author><keyname>Khaled</keyname><forenames>Shah Mostafa</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Begum</keyname><forenames>Zerina</forenames></author></authors><title>Comparative Study of Statistical Skin Detection Algorithms for
  Sub-Continental Human Images</title><categories>cs.CV</categories><comments>8 pages</comments><journal-ref>Information Technology Journal, Vol. 9, No. 4, pp. 811-817, 2010</journal-ref><doi>10.3923/itj.2010.811.817</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object detection has been a focus of research in human-computer interaction.
Skin area detection has been a key to different recognitions like face
recognition, human motion detection, pornographic and nude image prediction,
etc. Most of the research done in the fields of skin detection has been trained
and tested on human images of African, Mongolian and Anglo-Saxon ethnic
origins. Although there are several intensity invariant approaches to skin
detection, the skin color of Indian sub-continentals have not been focused
separately. The approach of this research is to make a comparative study
between three image segmentation approaches using Indian sub-continental human
images, to optimize the detection criteria, and to find some efficient
parameters to detect the skin area from these images. The experiments observed
that HSV color model based approach to Indian sub-continental skin detection is
more suitable with considerable success rate of 91.1% true positives and 88.1%
true negatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4210</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4210</id><created>2010-08-25</created><updated>2011-04-16</updated><authors><author><keyname>Mehrabian</keyname><forenames>Abbas</forenames></author></authors><title>Cops and Robber Game with a Fast Robber on Interval, Chordal, and Planar
  Graphs</title><categories>math.CO cs.DM</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variant of the Cops and Robber game, introduced by Fomin,
Golovach, Kratochvil, in which the robber has unbounded speed, i.e. can take
any path from her vertex in her turn, but she is not allowed to pass through a
vertex occupied by a cop. We study this game on interval graphs, chordal
graphs, planar graphs, and hypercube graphs. Let c_{\infty}(G) denote the
number of cops needed to capture the robber in graph G in this variant. We show
that if G is an interval graph, then c_{\infty}(G) = O(sqrt(|V(G)|)), and we
give a polynomial-time 3-approximation algorithm for finding c_{\infty}(G) in
interval graphs. We prove that for every n there exists an n-vertex chordal
graph G with c_{\infty}(G) = Omega(n / \log n). Let tw(G) and Delta(G) denote
the treewidth and the maximum degree of G, respectively. We prove that for
every G, tw(G) + 1 \leq (Delta(G) + 1) c_{\infty}(G). Using this lower bound
for c_{\infty}(G), we show two things. The first is that if G is a planar graph
(or more generally, if G does not have a fixed apex graph as a minor), then
c_{\infty}(G) = Theta(tw(G)). This immediately leads to an O(1)-approximation
algorithm for computing c_{\infty} for planar graphs. The second is that if G
is the m-hypercube graph, then there exist constants eta1, eta2&gt;0 such that
(eta1) 2^m / (m sqrt(m)) \leq c_{\infty}(G) \leq (eta2) 2^m / m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4220</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4220</id><created>2010-08-25</created><updated>2010-11-12</updated><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt, LIENS</affiliation></author></authors><title>Structured sparsity-inducing norms through submodular functions</title><categories>cs.LG math.OC stat.ML</categories><proxy>ccsd</proxy><journal-ref>NIPS, Canada (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse methods for supervised learning aim at finding good linear predictors
from as few variables as possible, i.e., with small cardinality of their
supports. This combinatorial selection problem is often turned into a convex
optimization problem by replacing the cardinality function by its convex
envelope (tightest convex lower bound), in this case the L1-norm. In this
paper, we investigate more general set-functions than the cardinality, that may
incorporate prior knowledge or structural constraints which are common in many
applications: namely, we show that for nondecreasing submodular set-functions,
the corresponding convex envelope can be obtained from its \lova extension, a
common tool in submodular analysis. This defines a family of polyhedral norms,
for which we provide generic algorithmic tools (subgradients and proximal
operators) and theoretical results (conditions for support recovery or
high-dimensional inference). By selecting specific submodular functions, we can
give a new interpretation to known norms, such as those based on
rank-statistics or grouped norms with potentially overlapping groups; we also
define new norms, in particular ones that can be used as non-factorial priors
for supervised learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4221</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4221</id><created>2010-08-25</created><authors><author><keyname>Fu</keyname><forenames>Hua</forenames></author><author><keyname>Kam</keyname><forenames>Pooi Yuen</forenames></author></authors><title>Performance of Optimum and Suboptimum Combining Diversity Reception for
  Binary DPSK over Independent, Nonidentical Rayleigh Fading Channels</title><categories>cs.IT math.IT</categories><comments>ICC'05</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the error performance analysis of binary
differential phase shift keying with differential detection over the
nonselective, Rayleigh fading channel with combining diversity reception. Space
antenna diversity reception is assumed. The diversity branches are independent,
but have nonidentically distributed statistics. The fading process in each
branch is assumed to have an arbitrary Doppler spectrum with arbitrary Doppler
bandwidth. Both optimum diversity reception and suboptimum diversity reception
are considered. Results available previously apply only to the case of first
and second-order diversity. Our results are more general in that the order of
diversity is arbitrary. Moreover, the bit error probability (BEP) result is
obtained in an exact, closed-form expression which shows the behavior of the
BEP as an explict function of the one-bit-interval fading correlation
coefficient at the matched filter output, the mean signal-to-noise ratio per
bit per branch and the order of diversity. A simple, more easily computable
Chernoff bound to the BEP of the optimum diversity detector is also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4232</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4232</id><created>2010-08-25</created><authors><author><keyname>V'yugin</keyname><forenames>Vladimir V.</forenames></author></authors><title>Online Learning in Case of Unbounded Losses Using the Follow Perturbed
  Leader Algorithm</title><categories>cs.LG</categories><comments>31 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the sequential prediction problem with expert advice is
considered for the case where losses of experts suffered at each step cannot be
bounded in advance. We present some modification of Kalai and Vempala algorithm
of following the perturbed leader where weights depend on past losses of the
experts. New notions of a volume and a scaled fluctuation of a game are
introduced. We present a probabilistic algorithm protected from unrestrictedly
large one-step losses. This algorithm has the optimal performance in the case
when the scaled fluctuations of one-step losses of experts of the pool tend to
zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4244</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4244</id><created>2010-08-25</created><authors><author><keyname>Ahn</keyname><forenames>Hee-Kap</forenames></author><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Matou&#x161;ek</keyname><forenames>Jir&#xed;</forenames></author><author><keyname>Vigneron</keyname><forenames>Antoine</forenames></author></authors><title>Reachability by Paths of Bounded Curvature in a Convex Polygon</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $B$ be a point robot moving in the plane, whose path is constrained to
forward motions with curvature at most one, and let $P$ be a convex polygon
with $n$ vertices. Given a starting configuration (a location and a direction
of travel) for $B$ inside $P$, we characterize the region of all points of $P$
that can be reached by $B$, and show that it has complexity $O(n)$. We give an
$O(n^2)$ time algorithm to compute this region. We show that a point is
reachable only if it can be reached by a path of type CCSCS, where C denotes a
unit circle arc and S denotes a line segment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4249</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4249</id><created>2010-08-25</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Islam</keyname><forenames>Md. Rafiqul</forenames></author></authors><title>Machine Learning Approaches for Modeling Spammer Behavior</title><categories>cs.IR cs.AI</categories><comments>12 pages, 3 figures, 5 tables, Submitted to AIRS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam is commonly known as unsolicited or unwanted email messages in the
Internet causing potential threat to Internet Security. Users spend a valuable
amount of time deleting spam emails. More importantly, ever increasing spam
emails occupy server storage space and consume network bandwidth. Keyword-based
spam email filtering strategies will eventually be less successful to model
spammer behavior as the spammer constantly changes their tricks to circumvent
these filters. The evasive tactics that the spammer uses are patterns and these
patterns can be modeled to combat spam. This paper investigates the
possibilities of modeling spammer behavioral patterns by well-known
classification algorithms such as Na\&quot;ive Bayesian classifier (Na\&quot;ive Bayes),
Decision Tree Induction (DTI) and Support Vector Machines (SVMs). Preliminary
experimental results demonstrate a promising detection rate of around 92%,
which is considerably an enhancement of performance compared to similar spammer
behavior modeling research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4250</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4250</id><created>2010-08-25</created><updated>2010-09-10</updated><authors><author><keyname>Cao</keyname><forenames>Yixin</forenames></author><author><keyname>Chen</keyname><forenames>Jianer</forenames></author></authors><title>Cluster Editing: Kernelization based on Edge Cuts</title><categories>cs.DS</categories><doi>10.1007/978-3-642-17493-3_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernelization algorithms for the {\sc cluster editing} problem have been a
popular topic in the recent research in parameterized computation. Thus far
most kernelization algorithms for this problem are based on the concept of {\it
critical cliques}. In this paper, we present new observations and new
techniques for the study of kernelization algorithms for the {\sc cluster
editing} problem. Our techniques are based on the study of the relationship
between {\sc cluster editing} and graph edge-cuts. As an application, we
present an ${\cal O}(n^2)$-time algorithm that constructs a $2k$ kernel for the
{\it weighted} version of the {\sc cluster editing} problem. Our result meets
the best kernel size for the unweighted version for the {\sc cluster editing}
problem, and significantly improves the previous best kernel of quadratic size
for the weighted version of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4257</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4257</id><created>2010-08-25</created><authors><author><keyname>Matta</keyname><forenames>Nada</forenames><affiliation>UTT</affiliation></author><author><keyname>Castillo</keyname><forenames>Oswaldo</forenames><affiliation>UTT</affiliation></author></authors><title>Learning from Profession Knowledge: Application on Knitting</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>5th International Conference on Signal-Image Technology and
  Internet based Systems, Marakesh : Morocco (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge Management is a global process in companies. It includes all the
processes that allow capitalization, sharing and evolution of the Knowledge
Capital of the firm, generally recognized as a critical resource of the
organization. Several approaches have been defined to capitalize knowledge but
few of them study how to learn from this knowledge. We present in this paper an
approach that helps to enhance learning from profession knowledge in an
organisation. We apply our approach on knitting industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4264</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4264</id><created>2010-08-25</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author><author><keyname>Walid</keyname><forenames>Anwar I.</forenames></author></authors><title>Network Protection Design Using Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>ITW2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link and node failures are two common fundamental problems that affect
operational networks. Protection of communication networks against such
failures is essential for maintaining network reliability and performance.
Network protection codes (NPC) are proposed to protect operational networks
against link and node failures. Furthermore, encoding and decoding operations
of such codes are well developed over binary and finite fields. Finding network
topologies, practical scenarios, and limits on graphs applicable for NPC are of
interest. In this paper, we establish limits on network protection design. We
investigate several network graphs where NPC can be deployed using network
coding. Furthermore, we construct graphs with minimum number of edges suitable
for network protection codes deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4268</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4268</id><created>2010-08-25</created><authors><author><keyname>Jeet</keyname><forenames>Kawal</forenames></author><author><keyname>Mago</keyname><forenames>Vijay Kumar</forenames></author><author><keyname>Prasad</keyname><forenames>Bhanu</forenames></author><author><keyname>Minhas</keyname><forenames>Rajinder Singh</forenames></author></authors><title>An Influence Diagram-Based Approach for Estimating Staff Training in
  Software Industry</title><categories>cs.SE cs.AI</categories><comments>16 Pages, 7 Figures, 2 Tables</comments><journal-ref>Journal of Intelligent Systems, Vol 18 (4). 2009. pp 267-283</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The successful completion of a software development process depends on the
analytical capability and foresightedness of the project manager. For the
project manager, the main intriguing task is to manage the risk factors as they
adversely influence the completion deadline. One such key risk factor is staff
training. The risk of this factor can be avoided by pre-judging the amount of
training required by the staff. So, a procedure is required to help the project
manager make this decision. This paper presents a system that uses influence
diagrams to implement the risk model to aid decision making. The system also
considers the cost of conducting the training, based on various risk factors
such as, (i) Lack of experience with project software; (ii) Newly appointed
staff; (iii) Staff not well versed with the required quality standards; and
(iv) Lack of experience with project environment. The system provides estimated
requirement details for staff training at the beginning of a software
development project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4296</identifier>
 <datestamp>2011-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4296</id><created>2010-08-25</created><authors><author><keyname>Aldroubi</keyname><forenames>Akram</forenames></author><author><keyname>Sun</keyname><forenames>Qiyu</forenames></author><author><keyname>Wang</keyname><forenames>Haichao</forenames></author></authors><title>Uncertainty Principles and Balian-Low type Theorems in Principal
  Shift-Invariant Spaces</title><categories>math.FA cs.IT math.IT</categories><report-no>Volume 30, Issue 3, May 2011, Pages 337-347</report-no><journal-ref>Applied and Computational Harmonic Analysis, 2011</journal-ref><doi>10.1016/j.acha.2010.09.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the time-frequency localization of the generator
of a principal shift-invariant space on the real line which has additional
shift-invariance. We prove that if a principal shift-invariant space on the
real line is translation-invariant then any of its orthonormal (or Riesz)
generators is non-integrable. However, for any $n\ge2$, there exist principal
shift-invariant spaces on the real line that are also $\nZ$-invariant with an
integrable orthonormal (or a Riesz) generator $\phi$, but $\phi$ satisfies
$\int_{\mathbb R} |\phi(x)|^2 |x|^{1+\epsilon} dx=\infty$ for any $\epsilon&gt;0$
and its Fourier transform $\hat\phi$ cannot decay as fast as $ (1+|\xi|)^{-r}$
for any $r&gt;1/2$. Examples are constructed to demonstrate that the above decay
properties for the orthormal generator in the time domain and in the frequency
domain are optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4310</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4310</id><created>2010-08-25</created><authors><author><keyname>Matta</keyname><forenames>Nada</forenames><affiliation>UTT</affiliation></author><author><keyname>Sidoumou</keyname><forenames>Karima</forenames><affiliation>UTT</affiliation></author><author><keyname>Ninova</keyname><forenames>Goritsa</forenames><affiliation>UTT, LIPN</affiliation></author><author><keyname>Atifi</keyname><forenames>Hassan</forenames><affiliation>UTT</affiliation></author></authors><title>Mod\'elisation d'une analyse pragma-linguistique d'un forum de
  discussion</title><categories>cs.AI cs.IR</categories><proxy>ccsd</proxy><journal-ref>Intelligence collective et organisation des connaissances (ISKO),
  Lyon : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper, a modelling of an expertise in pragmatics. We
follow knowledge engineering techniques and observe the expert when he analyses
a social discussion forum. Then a number of models are defined. These models
emphasises the process followed by the expert and a number of criteria used in
his analysis. Results can be used as guides that help to understand and
annotate discussion forum. We aim at modelling other pragmatics analysis in
order to complete the base of guides; criteria, process, etc. of discussion
analysis
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4326</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4326</id><created>2010-08-25</created><authors><author><keyname>Gent</keyname><forenames>Ian</forenames></author><author><keyname>Kotthoff</keyname><forenames>Lars</forenames></author><author><keyname>Miguel</keyname><forenames>Ian</forenames></author><author><keyname>Nightingale</keyname><forenames>Peter</forenames></author></authors><title>Machine learning for constraint solver design -- A case study for the
  alldifferent constraint</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint solvers are complex pieces of software which require many design
decisions to be made by the implementer based on limited information. These
decisions affect the performance of the finished solver significantly. Once a
design decision has been made, it cannot easily be reversed, although a
different decision may be more appropriate for a particular problem.
  We investigate using machine learning to make these decisions automatically
depending on the problem to solve. We use the alldifferent constraint as a case
study. Our system is capable of making non-trivial, multi-level decisions that
improve over always making a default choice and can be implemented as part of a
general-purpose constraint solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4328</identifier>
 <datestamp>2010-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4328</id><created>2010-08-25</created><authors><author><keyname>Kotthoff</keyname><forenames>Lars</forenames></author><author><keyname>Moore</keyname><forenames>Neil C. A.</forenames></author></authors><title>Distributed solving through model splitting</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint problems can be trivially solved in parallel by exploring
different branches of the search tree concurrently. Previous approaches have
focused on implementing this functionality in the solver, more or less
transparently to the user. We propose a new approach, which modifies the
constraint model of the problem. An existing model is split into new models
with added constraints that partition the search space. Optionally, additional
constraints are imposed that rule out the search already done. The advantages
of our approach are that it can be implemented easily, computations can be
stopped and restarted, moved to different machines and indeed solved on
machines which are not able to communicate with each other at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4331</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4331</id><created>2010-08-22</created><updated>2010-08-25</updated><authors><author><keyname>Small</keyname><forenames>Alex</forenames></author></authors><title>Geometric construction of voting methods that protect voters' first
  choices</title><categories>cs.GT math.CO</categories><comments>Updated to correct references, include table of contents for
  convenience of reader</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the possibility of designing an election method that eliminates
the incentives for a voter to rank any other candidate equal to or ahead of his
or her sincere favorite. We refer to these methods as satisfying the ``Strong
Favorite Betrayal Criterion&quot; (SFBC). Methods satisfying our strategic criteria
can be classified into four categories, according to their geometrical
properties. We prove that two categories of methods are highly restricted and
closely related to positional methods (point systems) that give equal points to
a voter's first and second choices. The third category is tightly restricted,
but if criteria are relaxed slightly a variety of interesting methods can be
identified. Finally, we show that methods in the fourth category are largely
irrelevant to public elections. Interestingly, most of these methods for
satisfying the SFBC do so only ``weakly,&quot; in that these methods make no
meaningful distinction between the first and second place on the ballot.
However, when we relax our conditions and allow (but do not require) equal
rankings for first place, a wider range of voting methods are possible, and
these methods do indeed make meaningful distinctions between first and second
place.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4348</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4348</id><created>2010-08-25</created><authors><author><keyname>Meng</keyname><forenames>Jia</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Collaborative Spectrum Sensing from Sparse Observations in Cognitive
  Radio Networks</title><categories>cs.IT math.IT</categories><comments>12 pages, 11 figures</comments><journal-ref>IEEE Journal on Selected Areas in Communications 29(2), 327-337,
  2011</journal-ref><doi>10.1109/JSAC.2011.110206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing, which aims at detecting spectrum holes, is the precondition
for the implementation of cognitive radio (CR). Collaborative spectrum sensing
among the cognitive radio nodes is expected to improve the ability of checking
complete spectrum usage. Due to hardware limitations, each cognitive radio node
can only sense a relatively narrow band of radio spectrum. Consequently, the
available channel sensing information is far from being sufficient for
precisely recognizing the wide range of unoccupied channels. Aiming at breaking
this bottleneck, we propose to apply matrix completion and joint sparsity
recovery to reduce sensing and transmitting requirements and improve sensing
results. Specifically, equipped with a frequency selective filter, each
cognitive radio node senses linear combinations of multiple channel information
and reports them to the fusion center, where occupied channels are then decoded
from the reports by using novel matrix completion and joint sparsity recovery
algorithms. As a result, the number of reports sent from the CRs to the fusion
center is significantly reduced. We propose two decoding approaches, one based
on matrix completion and the other based on joint sparsity recovery, both of
which allow exact recovery from incomplete reports. The numerical results
validate the effectiveness and robustness of our approaches. In particular, in
small-scale networks, the matrix completion approach achieves exact channel
detection with a number of samples no more than 50% of the number of channels
in the network, while joint sparsity recovery achieves similar performance in
large-scale networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4365</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4365</id><created>2010-08-25</created><authors><author><keyname>Kinable</keyname><forenames>Joris</forenames></author><author><keyname>Kostakis</keyname><forenames>Orestis</forenames></author></authors><title>Malware Classification based on Call Graph Clustering</title><categories>cs.CR</categories><comments>This research has been supported by TEKES - the Finnish Funding
  Agency for Technology and Innovation as part of its ICT SHOK Future Internet
  research programme, grant 40212/09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Each day, anti-virus companies receive tens of thousands samples of
potentially harmful executables. Many of the malicious samples are variations
of previously encountered malware, created by their authors to evade
pattern-based detection. Dealing with these large amounts of data requires
robust, automatic detection approaches. This paper studies malware
classification based on call graph clustering. By representing malware samples
as call graphs, it is possible to abstract certain variations away, and enable
the detection of structural similarities between samples. The ability to
cluster similar samples together will make more generic detection techniques
possible, thereby targeting the commonalities of the samples within a cluster.
To compare call graphs mutually, we compute pairwise graph similarity scores
via graph matchings which approximately minimize the graph edit distance. Next,
to facilitate the discovery of similar malware samples, we employ several
clustering algorithms, including k-medoids and DBSCAN. Clustering experiments
are conducted on a collection of real malware samples, and the results are
evaluated against manual classifications provided by human malware analysts.
Experiments show that it is indeed possible to accurately detect malware
families via call graph clustering. We anticipate that in the future, call
graphs can be used to analyse the emergence of new malware families, and
ultimately to automate implementation of generic detection schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4370</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4370</id><created>2010-08-25</created><authors><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Fourier Domain Decoding Algorithm of Non-Binary LDPC codes for Parallel
  Implementation</title><categories>cs.IT cs.AR math.IT</categories><comments>To appear in IEICE Trans. Fundamentals, vol.E93-A, no.11 November
  2010</comments><doi>10.1587/transfun.E93.A.1949</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For decoding non-binary low-density parity check (LDPC) codes,
logarithm-domain sum-product (Log-SP) algorithms were proposed for reducing
quantization effects of SP algorithm in conjunction with FFT. Since FFT is not
applicable in the logarithm domain, the computations required at check nodes in
the Log-SP algorithms are computationally intensive. What is worth, check nodes
usually have higher degree than variable nodes. As a result, most of the time
for decoding is used for check node computations, which leads to a bottleneck
effect. In this paper, we propose a Log-SP algorithm in the Fourier domain.
With this algorithm, the role of variable nodes and check nodes are switched.
The intensive computations are spread over lower-degree variable nodes, which
can be efficiently calculated in parallel. Furthermore, we develop a fast
calculation method for the estimated bits and syndromes in the Fourier domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4401</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4401</id><created>2010-08-25</created><updated>2010-08-27</updated><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>Nordstr&#xf6;m</keyname><forenames>Jakob</forenames></author><author><keyname>Xie</keyname><forenames>Ning</forenames></author></authors><title>Separations of Matroid Freeness Properties</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Properties of Boolean functions on the hypercube invariant with respect to
linear transformations of the domain are among the most well-studied properties
in the context of property testing. In this paper, we study the fundamental
class of linear-invariant properties called matroid freeness properties. These
properties have been conjectured to essentially coincide with all testable
linear-invariant properties, and a recent sequence of works has established
testability for increasingly larger subclasses. One question left open,
however, is whether the infinitely many syntactically different properties
recently shown testable in fact correspond to new, semantically distinct ones.
This is a crucial issue since it has also been shown that there exist
subclasses of these properties for which an infinite set of syntactically
different representations collapse into one of a small, finite set of
properties, all previously known to be testable.
  An important question is therefore to understand the semantics of matroid
freeness properties, and in particular when two syntactically different
properties are truly distinct. We shed light on this problem by developing a
method for determining the relation between two matroid freeness properties P
and Q. Furthermore, we show that there is a natural subclass of matroid
freeness properties such that for any two properties P and Q from this
subclass, a strong dichotomy must hold: either P is contained in Q or the two
properties are &quot;well separated.&quot; As an application of this method, we exhibit
new, infinite hierarchies of testable matroid freeness properties such that at
each level of the hierarchy, there are functions that are far from all
functions lying in lower levels of the hierarchy. Our key technical tool is an
apparently new notion of maps between linear matroids, called matroid
homomorphisms, that might be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4406</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4406</id><created>2010-08-25</created><authors><author><keyname>Fu</keyname><forenames>Fangwen</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Structural Solutions to Dynamic Scheduling for Multimedia Transmission
  in Unknown Wireless Environments</title><categories>cs.MM cs.LG cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a systematic solution to the problem of scheduling
delay-sensitive media data for transmission over time-varying wireless
channels. We first formulate the dynamic scheduling problem as a Markov
decision process (MDP) that explicitly considers the users' heterogeneous
multimedia data characteristics (e.g. delay deadlines, distortion impacts and
dependencies etc.) and time-varying channel conditions, which are not
simultaneously considered in state-of-the-art packet scheduling algorithms.
This formulation allows us to perform foresighted decisions to schedule
multiple data units for transmission at each time in order to optimize the
long-term utilities of the multimedia applications. The heterogeneity of the
media data enables us to express the transmission priorities between the
different data units as a priority graph, which is a directed acyclic graph
(DAG). This priority graph provides us with an elegant structure to decompose
the multi-data unit foresighted decision at each time into multiple single-data
unit foresighted decisions which can be performed sequentially, from the high
priority data units to the low priority data units, thereby significantly
reducing the computation complexity. When the statistical knowledge of the
multimedia data characteristics and channel conditions is unknown a priori, we
develop a low-complexity online learning algorithm to update the value
functions which capture the impact of the current decision on the future
utility. The simulation results show that the proposed solution significantly
outperforms existing state-of-the-art scheduling solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4413</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4413</id><created>2010-08-25</created><authors><author><keyname>Wang</keyname><forenames>Shanshan</forenames></author><author><keyname>Sagduyu</keyname><forenames>Yalin E.</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author><author><keyname>Li</keyname><forenames>Jason H.</forenames></author></authors><title>Spectrum Shaping via Network Coding in Cognitive Radio Networks</title><categories>cs.NI</categories><comments>A shorter version of this report has been submitted to INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a cognitive radio network where primary users (PUs) employ
network coding for data transmissions. We view network coding as a spectrum
shaper, in the sense that it increases spectrum availability to secondary users
(SUs) and offers more structure of spectrum holes that improves the
predictability of the primary spectrum. With this spectrum shaping effect of
network coding, each SU can carry out adaptive channel sensing by dynamically
updating the list of the PU channels predicted to be idle while giving priority
to these channels when sensing. This dynamic spectrum access approach with
network coding improves how SUs detect and utilize temporal spectrum holes over
PU channels. Our results show that compared to the existing approaches based on
retransmission, both PUs and SUs can achieve higher stable throughput, thanks
to the spectrum shaping effect of network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4416</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4416</id><created>2010-08-25</created><updated>2010-11-15</updated><authors><author><keyname>Sun</keyname><forenames>Ke</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author><author><keyname>Lapierre</keyname><forenames>Fabian</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Registration-based Compensation using Sparse Representation in
  Conformal-array STAP</title><categories>cs.IT math.IT</categories><comments>21 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space-time adaptive processing (STAP) is a well-known technique in detecting
slow-moving targets in the presence of a clutter-spreading environment. When
considering the STAP system deployed with conformal radar array (CFA), the
training data are range-dependent, which results in poor detection performance
of traditional statistical-based algorithms. Current registration-based
compensation (RBC) is implemented based on a sub-snapshot spectrum using
temporal smoothing. In this case, the estimation accuracy of the configuration
parameters and the clutter power distribution is limited. In this paper, the
technique of sparse representation is introduced into the spectral estimation,
and a new compensation method is proposed, namely RBC with sparse
representation (SR-RBC). This method first converts the clutter spectral
estimation into an ill-posed problem with the constraint of sparsity. Then, the
technique of sparse representation, like iterative reweighted least squares
(IRLS), is utilized to solve this problem. Then, the transform matrix is
designed so that the processed training data behaves nearly stationary with the
test cell. Because the configuration parameters and the clutter spectral
response are obtained with full-snapshot using sparse representation, SR-RBC
provides more accurate clutter spectral estimation, and the transformed
training data are more stationary so that better signal-clutter-ratio (SCR)
improvement is expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4420</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4420</id><created>2010-08-25</created><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Gray</keyname><forenames>Chris</forenames></author><author><keyname>Kroeller</keyname><forenames>Alexander</forenames></author></authors><title>Evacuation of rectilinear polygons</title><categories>cs.DS cs.CC cs.CG</categories><comments>15 pages, 7 figures; to appear in COCOA 2010</comments><acm-class>F.2.2</acm-class><doi>10.1007/978-3-642-17458-2_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of creating fast evacuation plans for buildings
that are modeled as grid polygons, possibly containing exponentially many
cells. We study this problem in two contexts: the ``confluent'' context in
which the routes to exits remain fixed over time, and the ``non-confluent''
context in which routes may change. Confluent evacuation plans are simpler to
carry out, as they allocate contiguous regions to exits; non-confluent
allocation can possibly create faster evacuation plans. We give results on the
hardness of creating the evacuation plans and strongly polynomial algorithms
for finding confluent evacuation plans when the building has two exits. We also
give a pseudo-polynomial time algorithm for non-confluent evacuation plans.
Finally, we show that the worst-case bound between confluent and non-confluent
plans is 2-2/(k+1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4446</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4446</id><created>2010-08-26</created><authors><author><keyname>Islam</keyname><forenames>Md. Rafiqul</forenames></author><author><keyname>Karim</keyname><forenames>Muhammad Rezaul</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Babu</keyname><forenames>Hafiz Md. Hasan</forenames></author></authors><title>Wrapper/TAM Co-Optimization and Test Scheduling for SOCs Using Rectangle
  Bin Packing Considering Diagonal Length of Rectangles</title><categories>cs.OH</categories><comments>6 pages, 8 figures, 5 tables</comments><journal-ref>Proc. of 7th International Conference on Computer and Information
  Technology, pp. 580-585, 26-28 December, 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an integrated framework for SOC test automation. This
framework is based on a new approach for Wrapper/TAM co-optimization based on
rectangle packing considering the diagonal length of the rectangles to
emphasize on both TAM widths required by a core and its corresponding testing
time. In this paper, we propose an efficient algorithm to construct wrappers
that reduce testing time for cores. We then use rectangle packing to develop an
integrated scheduling algorithm that incorporates power constraints in the test
schedule. The test power consumption is important to consider since exceeding
the system's power limit might damage the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4448</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4448</id><created>2010-08-26</created><authors><author><keyname>Babu</keyname><forenames>Hafiz Md. Hasan</forenames></author><author><keyname>Islam</keyname><forenames>Md. Rafiqul</forenames></author><author><keyname>Karim</keyname><forenames>Muhammad Rezaul</forenames></author><author><keyname>Mahmud</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author></authors><title>Wrapper/TAM Co-Optimization and constrained Test Scheduling for SOCs
  Using Rectangle Bin Packing</title><categories>cs.OH</categories><comments>10 pages, 7 figures, 5 tables</comments><journal-ref>Dhaka University Journal of Science, Vol. 55, No. 2, pp. 147-152,
  2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an integrated framework for SOC test automation. This
framework is based on a new approach for Wrapper/TAM co-optimization based on
rectangle packing considering the diagonal length of the rectangles to
emphasize on both TAM widths required by a core and its corresponding testing
time .In this paper, an efficient algorithm has been proposed to construct
wrappers that reduce testing time for cores. Rectangle packing has been used to
develop an integrated scheduling algorithm that incorporates power constraints
in the test schedule. The test power consumption is important to consider since
exceeding the system's power limit might damage the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4463</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4463</id><created>2010-08-26</created><authors><author><keyname>Tinnirello</keyname><forenames>I.</forenames></author><author><keyname>Giarr&#xe9;</keyname><forenames>L.</forenames></author><author><keyname>Neglia</keyname><forenames>G.</forenames></author></authors><title>MAC design for WiFi infrastructure networks: a game-theoretic approach</title><categories>cs.GT math.OC</categories><comments>under review on IEEE Transaction on wireless communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In WiFi networks, mobile nodes compete for accessing a shared channel by
means of a random access protocol called Distributed Coordination Function
(DCF). Although this protocol is in principle fair, since all the stations have
the same probability to transmit on the channel, it has been shown that unfair
behaviors may emerge in actual networking scenarios because of non-standard
configurations of the nodes. Due to the proliferation of open source drivers
and programmable cards, enabling an easy customization of the channel access
policies, we propose a game-theoretic analysis of random access schemes.
Assuming that each node is rational and implements a best response strategy, we
show that efficient equilibria conditions can be reached when stations are
interested in both uploading and downloading traffic. More interesting, these
equilibria are reached when all the stations play the same strategy, thus
guaranteeing a fair resource sharing. When stations are interested in upload
traffic only, we also propose a mechanism design, based on an artificial
dropping of layer-2 acknowledgments, to force desired equilibria. Finally, we
propose and evaluate some simple DCF extensions for practically implementing
our theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4474</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4474</id><created>2010-08-26</created><authors><author><keyname>Quintana</keyname><forenames>M. Borges</forenames></author><author><keyname>Trenard</keyname><forenames>M. A. Borges</forenames></author><author><keyname>Marquez-Corbella</keyname><forenames>I.</forenames></author><author><keyname>Martinez-Moro</keyname><forenames>E.</forenames></author></authors><title>An Algebraic View to Gradient Descent Decoding</title><categories>cs.IT math.CO math.IT</categories><journal-ref>Information Theory Workshop, Dublin 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are two gradient descent decoding procedures for binary codes proposed
independently by Liebler and by Ashikhmin and Barg. Liebler in his paper
mentions that both algorithms have the same philosophy but in fact they are
rather different. The purpose of this communication is to show that both
algorithms can be seen as two ways of understanding the reduction process
algebraic monoid structure related to the code. The main tool used for showing
this is the Gr\&quot;obner representation of the monoid associated to the linear
code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4532</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4532</id><created>2010-08-26</created><authors><author><keyname>Koolen</keyname><forenames>Wouter M.</forenames></author><author><keyname>van Erven</keyname><forenames>Tim</forenames></author></authors><title>Switching between Hidden Markov Models using Fixed Share</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In prediction with expert advice the goal is to design online prediction
algorithms that achieve small regret (additional loss on the whole data)
compared to a reference scheme. In the simplest such scheme one compares to the
loss of the best expert in hindsight. A more ambitious goal is to split the
data into segments and compare to the best expert on each segment. This is
appropriate if the nature of the data changes between segments. The standard
fixed-share algorithm is fast and achieves small regret compared to this
scheme.
  Fixed share treats the experts as black boxes: there are no assumptions about
how they generate their predictions. But if the experts are learning, the
following question arises: should the experts learn from all data or only from
data in their own segment? The original algorithm naturally addresses the first
case. Here we consider the second option, which is more appropriate exactly
when the nature of the data changes between segments. In general extending
fixed share to this second case will slow it down by a factor of T on T
outcomes. We show, however, that no such slowdown is necessary if the experts
are hidden Markov models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4535</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4535</id><created>2010-08-26</created><updated>2011-05-29</updated><authors><author><keyname>Bourgain</keyname><forenames>Jean</forenames></author><author><keyname>Dilworth</keyname><forenames>S. J.</forenames></author><author><keyname>Ford</keyname><forenames>Kevin</forenames></author><author><keyname>Konyagin</keyname><forenames>Sergei</forenames></author><author><keyname>Kutzarova</keyname><forenames>Denka</forenames></author></authors><title>Explicit constructions of RIP matrices and related problems</title><categories>math.NT cs.IT math.IT</categories><comments>v3. Minor corrections</comments><msc-class>11T23 (Primary), 11B13 (Secondary), 11B30, 41A46, 94A12, 94B60</msc-class><journal-ref>Duke Math. Journal 159 (2011), 145-185</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new explicit construction of $n\times N$ matrices satisfying the
Restricted Isometry Property (RIP). Namely, for some c&gt;0, large N and any n
satisfying N^{1-c} &lt; n &lt; N, we construct RIP matrices of order k^{1/2+c}. This
overcomes the natural barrier k=O(n^{1/2}) for proofs based on small coherence,
which are used in all previous explicit constructions of RIP matrices. Key
ingredients in our proof are new estimates for sumsets in product sets and for
exponential sums with the products of sets possessing special additive
structure. We also give a construction of sets of n complex numbers whose k-th
moments are uniformly small for 1\le k\le N (Turan's power sum problem), which
improves upon known explicit constructions when (\log N)^{1+o(1)} \le n\le
(\log N)^{4+o(1)}. This latter construction produces elementary explicit
examples of n by N matrices that satisfy RIP and whose columns constitute a new
spherical code; for those problems the parameters closely match those of
existing constructions in the range (\log N)^{1+o(1)} \le n\le (\log
N)^{5/2+o(1)}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4551</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4551</id><created>2010-08-26</created><authors><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>Deterministic Consensus Algorithm with Linear Per-Bit Complexity</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, building on the deterministic multi-valued one-to-many
Byzantine agreement (broadcast) algorithm in our recent technical report [2],
we introduce a deterministic multi-valued all-to-all Byzantine agreement
algorithm (consensus), with linear complexity per bit agreed upon. The
discussion in this note is not self-contained, and relies heavily on the
material in [2] - please refer to [2] for the necessary background.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4563</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4563</id><created>2010-08-26</created><updated>2011-02-07</updated><authors><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author><author><keyname>Medvedev</keyname><forenames>Paul</forenames></author><author><keyname>Milanic</keyname><forenames>Martin</forenames></author></authors><title>Shortest paths between shortest paths and independent sets</title><categories>cs.CC cs.DM</categories><doi>10.1007/978-3-642-19222-7_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study problems of reconfiguration of shortest paths in graphs. We prove
that the shortest reconfiguration sequence can be exponential in the size of
the graph and that it is NP-hard to compute the shortest reconfiguration
sequence even when we know that the sequence has polynomial length. Moreover,
we also study reconfiguration of independent sets in three different models and
analyze relationships between these models, observing that shortest path
reconfiguration is a special case of independent set reconfiguration in perfect
graphs, under any of the three models. Finally, we give polynomial results for
restricted classes of graphs (even-hole-free and $P_4$-free graphs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4564</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4564</id><created>2010-08-26</created><authors><author><keyname>Qu</keyname><forenames>Yan-Qin</forenames></author><author><keyname>Xu</keyname><forenames>Xiu-Lian</forenames></author><author><keyname>Guan</keyname><forenames>Shan</forenames></author><author><keyname>Li</keyname><forenames>Kai-Jun</forenames></author><author><keyname>Pan</keyname><forenames>Si-Jun</forenames></author><author><keyname>Gu</keyname><forenames>Chang-Gui</forenames></author><author><keyname>Jiang</keyname><forenames>Yu-Mei</forenames></author><author><keyname>He</keyname><forenames>Da-Ren</forenames></author></authors><title>Study on some interconnecting bilayer networks</title><categories>physics.soc-ph cs.SI</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a model, in which some nodes (called interconnecting nodes) in two
networks merge and play the roles in both the networks. The model analytic and
simulation discussions show a monotonically increasing dependence of
interconnecting node topological position difference and a monotonically
decreasing dependence of the interconnecting node number on function difference
of both networks. The dependence function details do not influence the
qualitative relationship. This online manuscript presents the details of the
model simulation and analytic discussion, as well as the empirical
investigations performed in eight real world bilayer networks. The analytic and
simulation results with different dependence function forms show rather good
agreement with the empirical conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4565</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4565</id><created>2010-08-26</created><authors><author><keyname>Rost</keyname><forenames>P.</forenames></author><author><keyname>Fettweis</keyname><forenames>G.</forenames></author></authors><title>On the Transmission-Computation-Energy Tradeoff in Wireless and Fixed
  Networks</title><categories>cs.IT math.IT</categories><comments>Accepted for publication Green Communications Workshop, colocated
  with 2010 IEEE GLOBECOM</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a framework for the analysis of the
transmission-computation-energy tradeoff in wireless and fixed networks is
introduced. The analysis of this tradeoff considers both the transmission
energy as well as the energy consumed at the receiver to process the received
signal. While previous work considers linear decoder complexity, which is only
achieved by uncoded transmission, this paper claims that the average processing
(or computation) energy per symbol depends exponentially on the information
rate of the source message. The introduced framework is parametrized in a way
that it reflects properties of fixed and wireless networks alike.
  The analysis of this paper shows that exponential complexity and therefore
stronger codes are preferable at low data rates while linear complexity and
therefore uncoded transmission becomes preferable at high data rates. The more
the computation energy is emphasized (such as in fixed networks), the less hops
are optimal and the lower is the benefit of multi-hopping. On the other hand,
the higher the information rate of the single-hop network, the higher the
benefits of multi-hopping. Both conclusions are underlined by analytical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4571</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4571</id><created>2010-08-26</created><authors><author><keyname>Thomas</keyname><forenames>Michael W.</forenames></author><author><keyname>Schnetter</keyname><forenames>Erik</forenames></author></authors><title>Simulation Factory: Taming Application Configuration and Workflow on
  High-End Resources</title><categories>cs.DC physics.comp-ph</categories><comments>10 pages, accepted by CBHPC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational Science on large high performance computing resources is
hampered by the complexity of these systems. Much of this complexity is due to
low-level details on these resources that are exposed to the application and
the end user. This includes (but is not limited to) mechanisms for remote
access, configuring and building applications from source code, and managing
simulations and their output files via batch queue systems. These challenges
multiply in a modern research environment, where a research collaboration spans
multiple groups, often in loosely defined international collaborations, where
there is a constant influx of new students into multi-year projects, and where
simulations are performed on several different resources. The Simulation
Factory addresses these challenges by significantly simplifying remote access,
building executables, and managing simulations. By abstracting out the
low-level differences between different resources, it offers a uniform
interface to these resources. At the same time, it can enforce certain
standards for performing simulations that encapsulate best practices from
experienced users. Furthermore, SimFactory's automation avoids many possible
user errors that can in the worst case render month-long simulations worthless.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4627</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4627</id><created>2010-08-26</created><authors><author><keyname>Gardezi</keyname><forenames>Jaffer</forenames></author><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author><author><keyname>Kiringa</keyname><forenames>Iluju</forenames></author></authors><title>Matching Dependencies with Arbitrary Attribute Values: Semantics, Query
  Answering and Integrity Constraints</title><categories>cs.DB</categories><comments>13 pages, double column, 2 figures</comments><acm-class>H.2; H.2.0; H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching dependencies (MDs) were introduced to specify the identification or
matching of certain attribute values in pairs of database tuples when some
similarity conditions are satisfied. Their enforcement can be seen as a natural
generalization of entity resolution. In what we call the &quot;pure case&quot; of MDs,
any value from the underlying data domain can be used for the value in common
that does the matching. We investigate the semantics and properties of data
cleaning through the enforcement of matching dependencies for the pure case. We
characterize the intended clean instances and also the &quot;clean answers&quot; to
queries as those that are invariant under the cleaning process. The complexity
of computing clean instances and clean answers to queries is investigated.
Tractable and intractable cases depending on the MDs and queries are
identified. Finally, we establish connections with database &quot;repairs&quot; under
integrity constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4629</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4629</id><created>2010-08-26</created><authors><author><keyname>&#xc7;elik</keyname><forenames>G&#xfc;ner D.</forenames></author><author><keyname>Modiano</keyname><forenames>Eytan</forenames></author></authors><title>Dynamic Vehicle Routing for Data Gathering in Wireless Networks</title><categories>math.OC cs.NI</categories><comments>19 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dynamic vehicle routing problem in wireless networks where
messages arriving randomly in time and space are collected by a mobile receiver
(vehicle or a collector). The collector is responsible for receiving these
messages via wireless communication by dynamically adjusting its position in
the network. Our goal is to utilize a combination of wireless transmission and
controlled mobility to improve the delay performance in such networks. We show
that the necessary and sufficient condition for the stability of such a system
(in the bounded average number of messages sense) is given by {\rho}&lt;1 where
{\rho} is the average system load. We derive fundamental lower bounds for the
delay in the system and develop policies that are stable for all loads {\rho}&lt;1
and that have asymptotically optimal delay scaling. Furthermore, we extend our
analysis to the case of multiple collectors in the network. We show that the
combination of mobility and wireless transmission results in a delay scaling of
{\Theta}(1/(1- {\rho})) with the system load {\rho} that is a factor of
{\Theta}(1/(1- {\rho})) smaller than the delay scaling in the corresponding
system where the collector visits each message location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4654</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4654</id><created>2010-08-27</created><authors><author><keyname>Koolen</keyname><forenames>Wouter M.</forenames></author><author><keyname>van Erven</keyname><forenames>Tim</forenames></author></authors><title>Freezing and Sleeping: Tracking Experts that Learn by Evolving Past
  Posteriors</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A problem posed by Freund is how to efficiently track a small pool of experts
out of a much larger set. This problem was solved when Bousquet and Warmuth
introduced their mixing past posteriors (MPP) algorithm in 2001.
  In Freund's problem the experts would normally be considered black boxes.
However, in this paper we re-examine Freund's problem in case the experts have
internal structure that enables them to learn. In this case the problem has two
possible interpretations: should the experts learn from all data or only from
the subsequence on which they are being tracked? The MPP algorithm solves the
first case. Our contribution is to generalise MPP to address the second option.
The results we obtain apply to any expert structure that can be formalised
using (expert) hidden Markov models. Curiously enough, for our interpretation
there are \emph{two} natural reference schemes: freezing and sleeping. For each
scheme, we provide an efficient prediction strategy and prove the relevant loss
bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4658</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4658</id><created>2010-08-27</created><updated>2010-09-09</updated><authors><author><keyname>Biatov</keyname><forenames>Konstantin</forenames></author></authors><title>A high speed unsupervised speaker retrieval using vector quantization
  and second-order statistics</title><categories>cs.IR cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an effective unsupervised method for query-by-example
speaker retrieval. We suppose that only one speaker is in each audio file or in
audio segment. The audio data are modeled using a common universal codebook.
The codebook is based on bag-of-frames (BOF). The features corresponding to the
audio frames are extracted from all audio files. These features are grouped
into clusters using the K-means algorithm. The individual audio files are
modeled by the normalized distribution of the numbers of cluster bins
corresponding to this file. In the first level the k-nearest to the query files
are retrieved using vector space representation. In the second level the
second-order statistical measure is applied to obtained k-nearest files to find
the final result of the retrieval. The described method is evaluated on the
subset of Ester corpus of French broadcast news.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4662</identifier>
 <datestamp>2012-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4662</id><created>2010-08-27</created><updated>2010-09-29</updated><authors><author><keyname>Tsibidis</keyname><forenames>George D</forenames></author><author><keyname>Burroughs</keyname><forenames>Nigel J</forenames></author><author><keyname>Gaze</keyname><forenames>William</forenames></author><author><keyname>Wellington</keyname><forenames>Elizabeth M H</forenames></author></authors><title>Automated Acanthamoeba polyphaga detection and computation of Salmonella
  typhimurium concentration in spatio-temporal images</title><categories>q-bio.QM cs.CV q-bio.PE</categories><comments>25 pages</comments><journal-ref>Micron (2011), 42, 911-920</journal-ref><doi>10.1016/j.micron.2011.06.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactions between bacteria and protozoa is an increasing area of interest,
however there are a few systems that allow extensive observation of the
interactions. We examined a surface system consisting of non nutrient agar with
a uniform bacterial lawn that extended over the agar surface, and a spatially
localised central population of amoebae. The amoeba fed on bacteria and
migrated over the plate. Automated image analysis techniques were used to
locate and count amoebae, cysts and bacteria coverage in a series of spatial
images. Most algorithms were based on intensity thresholding, or a modification
of this idea with probabilistic models. Our strategy was two tiered, we
performed an automated analysis for object classification and bacteria counting
followed by user intervention/reclassification using custom written Graphical
User Interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4668</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4668</id><created>2010-08-27</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author></authors><title>BSSSN: Bit String Swapping Sorting Network for Reversible Logic
  Synthesis</title><categories>cs.AR</categories><comments>8 pages, 11 figures, 2 tables</comments><journal-ref>Journal of Computer Science (IBAIS University), Vol. 1, No. 1, pp.
  94-99, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have introduced the notion of UselessGate and
ReverseOperation. We have also given an algorithm to implement a sorting
network for reversible logic synthesis based on swapping bit strings. The
network is constructed in terms of n*n Toffoli Gates read from left to right
and it has shown that there will be no more gates than the number of swappings
the algorithm requires. The gate complexity of the network is O(n2). The number
of gates in the network can be further reduced by template reduction technique
and removing UselessGate from the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4669</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4669</id><created>2010-08-27</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Amin</keyname><forenames>Md. Iftekharul</forenames></author></authors><title>An Architecture of Active Learning SVMs with Relevance Feedback for
  Classifying E-mail</title><categories>cs.IR cs.LG</categories><comments>7 pages, 2 figures</comments><journal-ref>Journal of Computer Science (IBAIS University), Vol. 1, No. 1, pp.
  15-18, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have proposed an architecture of active learning SVMs with
relevance feedback (RF)for classifying e-mail. This architecture combines both
active learning strategies where instead of using a randomly selected training
set, the learner has access to a pool of unlabeled instances and can request
the labels of some number of them and relevance feedback where if any mail
misclassified then the next set of support vectors will be different from the
present set otherwise the next set will not change. Our proposed architecture
will ensure that a legitimate e-mail will not be dropped in the event of
overflowing mailbox. The proposed architecture also exhibits dynamic updating
characteristics making life as difficult for the spammer as possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4705</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4705</id><created>2010-08-27</created><authors><author><keyname>Boero</keyname><forenames>Riccardo</forenames></author><author><keyname>Bravo</keyname><forenames>Giangiacomo</forenames></author><author><keyname>Squazzoni</keyname><forenames>Flaminio</forenames></author></authors><title>Trust and Partner Selection in Social Networks: An Experimentally
  Grounded Model</title><categories>physics.soc-ph cs.SI</categories><comments>23 pages, 4 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an experimentally grounded model on the relevance of
partner selection for the emergence of trust and cooperation among individuals.
By combining experimental evidence and network simulation, our model
investigates the link of interaction outcome and social structure formation and
shows that dynamic networks lead to positive outcomes when cooperators have the
capability of creating more links and isolating free-riders. By emphasizing the
self-reinforcing dynamics of interaction outcome and structure formation, our
results cast the argument about the relevance of interaction continuity for
cooperation in new light and provide insights to guide the design of new lab
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4733</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4733</id><created>2010-08-27</created><updated>2010-09-03</updated><authors><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Gelfand-Pinsker coding achieves the interference-free capacity</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author as there exist
  counter-examples</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a discrete memoryless channel with non-causal state information available
only at the encoder, it is well-known that Gelfand-Pinsker coding achieves its
capacity. In this paper, we analyze Gelfand-Pinsker coding scheme and capacity
to bring out further understandings. We show that Gelfand-Pinsker capacity is
equal to the interference-free capacity. Thus the capacity of a channel with
non-causal state information available only at the encoder is the same as if
the state information is also available at the decoder. Furthermore, the
capacity-achieving conditional input distributions in these two cases are the
same. This lets us connect the studied channel with state to the multiple
access channel (MAC) with correlated sources and show that under certain
conditions, the receiver can decode both the message and the state information.
This dual decoding can be obtained in particular if the state sequences come
from a known codebook with rate satisfying a simple constraint. In such a case,
we can modify Gelfand-Pinsker coding by pre-building multiple codebooks of
input sequences $X^n$, each codebook is for a given state sequence $S^n$, upon
generating the auxiliary $U^n$ sequences. The modified Gelfand-Pinsker coding
scheme achieves the capacity of the MAC with degraded message set and still
allows for decoding of just the message at any state information rate. We then
revisit dirty-paper coding for the Gaussian channel to verify our analysis and
modified coding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4747</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4747</id><created>2010-08-27</created><updated>2010-11-01</updated><authors><author><keyname>Fujiwara</keyname><forenames>Yuichiro</forenames></author><author><keyname>Clark</keyname><forenames>David</forenames></author><author><keyname>Vandendriessche</keyname><forenames>Peter</forenames></author><author><keyname>De Boeck</keyname><forenames>Maarten</forenames></author><author><keyname>Tonchev</keyname><forenames>Vladimir D.</forenames></author></authors><title>Entanglement-assisted quantum low-density parity-check codes</title><categories>cs.IT math.CO math.IT quant-ph</categories><comments>20 pages, 5 figures. Final version appearing in Physical Review A</comments><msc-class>94B (primary), 51E (secondary)</msc-class><journal-ref>Phys. Rev. A 82, 042338 (2010)</journal-ref><doi>10.1103/PhysRevA.82.042338</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a general method for constructing entanglement-assisted
quantum low-density parity-check (LDPC) codes, which is based on combinatorial
design theory. Explicit constructions are given for entanglement-assisted
quantum error-correcting codes (EAQECCs) with many desirable properties. These
properties include the requirement of only one initial entanglement bit, high
error correction performance, high rates, and low decoding complexity. The
proposed method produces infinitely many new codes with a wide variety of
parameters and entanglement requirements. Our framework encompasses various
codes including the previously known entanglement-assisted quantum LDPC codes
having the best error correction performance and many new codes with better
block error rates in simulations over the depolarizing channel. We also
determine important parameters of several well-known classes of quantum and
classical LDPC codes for previously unsettled cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4754</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4754</id><created>2010-08-26</created><authors><author><keyname>Ding</keyname><forenames>Jie</forenames></author><author><keyname>Hillston</keyname><forenames>Jane</forenames></author></authors><title>Fundamental Results on Fluid Approximations of Stochastic Process
  Algebra Models</title><categories>cs.LO cs.NA math.DS</categories><comments>Manuscript, 87 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to avoid the state space explosion problem encountered in the
quantitative analysis of large scale PEPA models, a fluid approximation
approach has recently been proposed, which results in a set of ordinary
differential equations (ODEs) to approximate the underlying continuous time
Markov chain (CTMC). This paper presents a mapping semantics from PEPA to ODEs
based on a numerical representation scheme, which extends the class of PEPA
models that can be subjected to fluid approximation. Furthermore, we have
established the fundamental characteristics of the derived ODEs, such as the
existence, uniqueness, boundedness and nonnegativeness of the solution. The
convergence of the solution as time tends to infinity for several classes of
PEPA models, has been proved under some mild conditions. For general PEPA
models, the convergence is proved under a particular condition, which has been
revealed to relate to some famous constants of Markov chains such as the
spectral gap and the Log-Sobolev constant. This thesis has established the
consistency between the fluid approximation and the underlying CTMCs for PEPA,
i.e. the limit of the solution is consistent with the equilibrium probability
distribution corresponding to a family of underlying density dependent CTMCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4776</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4776</id><created>2010-08-27</created><authors><author><keyname>Gutfraind</keyname><forenames>Alexander</forenames></author></authors><title>Targeting by Transnational Terrorist Groups</title><categories>cs.GT nlin.AO physics.soc-ph</categories><report-no>LA-UR 10-05689</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many successful terrorist groups operate across international borders where
different countries host different stages of terrorist operations. Often the
recruits for the group come from one country or countries, while the targets of
the operations are in another. Stopping such attacks is difficult because
intervention in any region or route might merely shift the terrorists
elsewhere. Here we propose a model of transnational terrorism based on the
theory of activity networks. The model represents attacks on different
countries as paths in a network. The group is assumed to prefer paths of lowest
cost (or risk) and maximal yield from attacks. The parameters of the model are
computed for the Islamist-Salafi terrorist movement based on open source data
and then used for estimation of risks of future attacks. The central finding is
that the USA has an enduring appeal as a target, due to lack of other nations
of matching geopolitical weight or openness. It is also shown that countries in
Africa and Asia that have been overlooked as terrorist bases may become highly
significant threats in the future. The model quantifies the dilemmas facing
countries in the effort to cut such networks, and points to a limitation of
deterrence against transnational terrorists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4815</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4815</id><created>2010-08-27</created><authors><author><keyname>Costa</keyname><forenames>Alberto</forenames></author><author><keyname>Roda</keyname><forenames>Fabio</forenames></author></authors><title>Recommender Systems by means of Information Retrieval</title><categories>cs.IR</categories><doi>10.1145/1988688.1988755</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we present a method for reformulating the Recommender Systems
problem in an Information Retrieval one. In our tests we have a dataset of
users who give ratings for some movies; we hide some values from the dataset,
and we try to predict them again using its remaining portion (the so-called
&quot;leave-n-out approach&quot;). In order to use an Information Retrieval algorithm, we
reformulate this Recommender Systems problem in this way: a user corresponds to
a document, a movie corresponds to a term, the active user (whose rating we
want to predict) plays the role of the query, and the ratings are used as
weigths, in place of the weighting schema of the original IR algorithm. The
output is the ranking list of the documents (&quot;users&quot;) relevant for the query
(&quot;active user&quot;). We use the ratings of these users, weighted according to the
rank, to predict the rating of the active user. We carry out the comparison by
means of a typical metric, namely the accuracy of the predictions returned by
the algorithm, and we compare this to the real ratings from users. In our first
tests, we use two different Information Retrieval algorithms: LSPR, a recently
proposed model based on Discrete Fourier Transform, and a simple vector space
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4820</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4820</id><created>2010-08-27</created><authors><author><keyname>Aperjis</keyname><forenames>Christina</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Wu</keyname><forenames>Fang</forenames></author></authors><title>Human Speed-Accuracy Tradeoffs in Search</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When foraging for information, users face a tradeoff between the accuracy and
value of the acquired information and the time spent collecting it, a problem
which also surfaces when seeking answers to a question posed to a large
community. We empirically study how people behave when facing these conflicting
objectives using data from Yahoo Answers, a community driven
question-and-answer site. We first study how users behave when trying to
maximize the amount of acquired information while minimizing the waiting time.
We find that users are willing to wait longer for an additional answer if they
have received a small number of answers. We then assume that users make a
sequence of decisions, deciding to wait for an additional answer as long as the
quality of the current answer exceeds some threshold. The resulting probability
distribution for the number of answers that a question gets is an inverse
Gaussian, a fact that is validated by our data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4825</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4825</id><created>2010-08-27</created><updated>2014-08-12</updated><authors><author><keyname>Kjos-Hanssen</keyname><forenames>Bj&#xf8;rn</forenames></author><author><keyname>Stephan</keyname><forenames>Frank</forenames></author><author><keyname>Teutsch</keyname><forenames>Jason R.</forenames></author></authors><title>Arithmetic complexity via effective names for random sequences</title><categories>math.LO cs.CC</categories><msc-class>03D32, 68Q30</msc-class><acm-class>F.1</acm-class><journal-ref>ACM Transactions on Computational Logic 13, no. 3 (July 2012),
  Art. 24, 18 pp</journal-ref><doi>10.1145/2287718.2287724</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate enumerability properties for classes of sets which permit
recursive, lexicographically increasing approximations, or left-r.e. sets. In
addition to pinpointing the complexity of left-r.e. Martin-L\&quot;{o}f, computably,
Schnorr, and Kurtz random sets, weakly 1-generics and their complementary
classes, we find that there exist characterizations of the third and fourth
levels of the arithmetic hierarchy purely in terms of these notions.
  More generally, there exists an equivalence between arithmetic complexity and
existence of numberings for classes of left-r.e. sets with shift-persistent
elements. While some classes (such as Martin-L\&quot;{o}f randoms and Kurtz
non-randoms) have left-r.e. numberings, there is no canonical, or acceptable,
left-r.e. numbering for any class of left-r.e. randoms.
  Finally, we note some fundamental differences between left-r.e. numberings
for sets and reals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4831</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4831</id><created>2010-08-28</created><updated>2012-06-21</updated><authors><author><keyname>Knuth</keyname><forenames>Kevin H.</forenames></author><author><keyname>Skilling</keyname><forenames>John</forenames></author></authors><title>Foundations of Inference</title><categories>math.PR cs.AI math.LO math.ST physics.data-an stat.TH</categories><comments>This updated version of the paper has been published in the journal
  Axioms (please see journal reference). 28 pages, 9 figures</comments><journal-ref>Axioms 2012, 1(1):38-73</journal-ref><doi>10.3390/axioms1010038</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple and clear foundation for finite inference that unites and
significantly extends the approaches of Kolmogorov and Cox. Our approach is
based on quantifying lattices of logical statements in a way that satisfies
general lattice symmetries. With other applications such as measure theory in
mind, our derivations assume minimal symmetries, relying on neither negation
nor continuity nor differentiability. Each relevant symmetry corresponds to an
axiom of quantification, and these axioms are used to derive a unique set of
quantifying rules that form the familiar probability calculus. We also derive a
unique quantification of divergence, entropy and information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4844</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4844</id><created>2010-08-28</created><updated>2014-09-20</updated><authors><author><keyname>Zamponi</keyname><forenames>Francesco</forenames></author></authors><title>Mean field theory of spin glasses</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC</categories><comments>Lecture notes, 73 pages, 16 figures, improved version with respect to
  v4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These lecture notes focus on the mean field theory of spin glasses, with
particular emphasis on the presence of a very large number of metastable states
in these systems. This phenomenon, and some of its physical consequences, will
be discussed in details for fully-connected models and for models defined on
random lattices. This will be done using the replica and cavity methods.
  These notes have been prepared for a course of the PhD program in Statistical
Mechanics at SISSA, Trieste and at the University of Rome &quot;Sapienza&quot;. Part of
the material is reprinted from other lecture notes, and when this is done a
reference is obviously provided to the original.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4870</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4870</id><created>2010-08-28</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Celiker</keyname><forenames>Fatih</forenames></author><author><keyname>Kingravi</keyname><forenames>Hassan A.</forenames></author></authors><title>On Euclidean Norm Approximations</title><categories>cs.NA cs.CV</categories><comments>9 pages, 1 figure, Pattern Recognition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Euclidean norm calculations arise frequently in scientific and engineering
applications. Several approximations for this norm with differing complexity
and accuracy have been proposed in the literature. Earlier approaches were
based on minimizing the maximum error. Recently, Seol and Cheun proposed an
approximation based on minimizing the average error. In this paper, we first
examine these approximations in detail, show that they fit into a single
mathematical formulation, and compare their average and maximum errors. We then
show that the maximum errors given by Seol and Cheun are significantly
optimistic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4873</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4873</id><created>2010-08-28</created><authors><author><keyname>Al-Omari</keyname><forenames>Saleh Ali K.</forenames></author><author><keyname>Sumari</keyname><forenames>Putra</forenames></author></authors><title>Spiking Neurons with ASNN Based-Methods for the Neural Block Cipher</title><categories>cs.CR cs.NE</categories><comments>11 pages, 4 Figures, International journal of computer science &amp;
  information Technology</comments><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT) Vol.2, No.4, August 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Problem statement: This paper examines Artificial Spiking Neural Network
(ASNN) which inter-connects group of artificial neurons that uses a
mathematical model with the aid of block cipher. The aim of undertaken this
research is to come up with a block cipher where by the keys are randomly
generated by ASNN which can then have any variable block length. This will show
the private key is kept and do not have to be exchange to the other side of the
communication channel so it present a more secure procedure of key scheduling.
The process enables for a faster change in encryption keys and a network level
encryption to be implemented at a high speed without the headache of
factorization. Approach: The block cipher is converted in public cryptosystem
and had a low level of vulnerability to attack from brute, and moreover can
able to defend against linear attacks since the Artificial Neural Networks
(ANN) architecture convey non-linearity to the encryption/decryption
procedures. Result: In this paper is present to use the Spiking Neural Networks
(SNNs) with spiking neurons as its basic unit. The timing for the SNNs is
considered and the output is encoded in 1's and 0's depending on the occurrence
or not occurrence of spikes as well as the spiking neural networks use a sign
function as activation function, and present the weights and the filter
coefficients to be adjust, having more degrees of freedom than the classical
neural networks. Conclusion: In conclusion therefore, encryption algorithm can
be deployed in communication and security applications where data transfers are
most crucial. So this paper, the neural block cipher proposed where the keys
are generated by the SNN and the seed is considered the public key which
generates the both keys on both sides In future therefore a new research will
be conducted on the Spiking Neural Network (SNN) impacts on communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4874</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4874</id><created>2010-08-28</created><updated>2011-06-20</updated><authors><author><keyname>Barash</keyname><forenames>L. Yu.</forenames></author></authors><title>Applying dissipative dynamical systems to pseudorandom number
  generation: Equidistribution property and statistical independence of bits at
  distances up to logarithm of mesh size</title><categories>physics.comp-ph cs.MS</categories><comments>6 pages, 3 figures, 3 tables</comments><journal-ref>EPL 95, 10003 (2011)</journal-ref><doi>10.1209/0295-5075/95/10003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The behavior of a family of dissipative dynamical systems representing
transformations of two-dimensional torus is studied on a discrete lattice and
compared with that of conservative hyperbolic automorphisms of the torus.
Applying dissipative dynamical systems to generation of pseudorandom numbers is
shown to be advantageous and equidistribution of probabilities for the
sequences of bits can be achieved. A new algorithm for generating uniform
pseudorandom numbers is proposed. The theory of the generator, which includes
proofs of periodic properties and of statistical independence of bits at
distances up to logarithm of mesh size, is presented. Extensive statistical
testing using available test packages demonstrates excellent results, while the
speed of the generator is comparable to other modern generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4889</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4889</id><created>2010-08-28</created><authors><author><keyname>Bansal</keyname><forenames>Nikhil</forenames></author><author><keyname>Pruhs</keyname><forenames>Kirk</forenames></author></authors><title>The Geometry of Scheduling</title><categories>cs.DS</categories><comments>Conference version in FOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following general scheduling problem: The input consists of n
jobs, each with an arbitrary release time, size, and a monotone function
specifying the cost incurred when the job is completed at a particular time.
The objective is to find a preemptive schedule of minimum aggregate cost. This
problem formulation is general enough to include many natural scheduling
objectives, such as weighted flow, weighted tardiness, and sum of flow squared.
Our main result is a randomized polynomial-time algorithm with an approximation
ratio O(log log nP), where P is the maximum job size. We also give an O(1)
approximation in the special case when all jobs have identical release times.
The main idea is to reduce this scheduling problem to a particular geometric
set-cover problem which is then solved using the local ratio technique and
Varadarajan's quasi-uniform sampling technique. This general algorithmic
approach improves the best known approximation ratios by at least an
exponential factor (and much more in some cases) for essentially all of the
nontrivial common special cases of this problem. Our geometric interpretation
of scheduling may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4895</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4895</id><created>2010-08-28</created><updated>2011-04-03</updated><authors><author><keyname>Huang</keyname><forenames>Longbo</forenames></author><author><keyname>Moeller</keyname><forenames>Scott</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author></authors><title>LIFO-Backpressure Achieves Near Optimal Utility-Delay Tradeoff</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been considerable recent work developing a new stochastic network
utility maximization framework using Backpressure algorithms, also known as
MaxWeight. A key open problem has been the development of utility-optimal
algorithms that are also delay efficient. In this paper, we show that the
Backpressure algorithm, when combined with the LIFO queueing discipline (called
LIFO-Backpressure), is able to achieve a utility that is within $O(1/V)$ of the
optimal value, while maintaining an average delay of $O([\log(V)]^2)$ for all
but a tiny fraction of the network traffic. This result holds for general
stochastic network optimization problems and general Markovian dynamics.
Remarkably, the performance of LIFO-Backpressure can be achieved by simply
changing the queueing discipline; it requires no other modifications of the
original Backpressure algorithm. We validate the results through empirical
measurements from a sensor network testbed, which show good match between
theory and practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4896</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4896</id><created>2010-08-28</created><updated>2011-10-16</updated><authors><author><keyname>Urgaonkar</keyname><forenames>Rahul</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Optimal Routing with Mutual Information Accumulation in Wireless
  Networks</title><categories>math.OC cs.IT cs.NI math.IT</categories><comments>Full version of JSAC Special Issue on Cooperative Networking:
  Challenges and Applications paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate optimal routing and scheduling strategies for multi-hop
wireless networks with rateless codes. Rateless codes allow each node of the
network to accumulate mutual information from every packet transmission. This
enables a significant performance gain over conventional shortest path routing.
Further, it outperforms cooperative communication techniques that are based on
energy accumulation. However, it requires complex and combinatorial networking
decisions concerning which nodes participate in transmission, and which decode
ordering to use. We formulate three problems of interest in this setting: (i)
minimum delay routing, (ii) minimum energy routing subject to delay constraint,
and (iii) minimum delay broadcast. All of these are hard combinatorial
optimization problems and we make use of several structural properties of their
optimal solutions to simplify the problems and derive optimal greedy
algorithms. Although the reduced problems still have exponential complexity,
unlike prior works on such problems, our greedy algorithms are simple to use
and do not require solving any linear programs. Further, using the insight
obtained from the optimal solution to a line network, we propose two simple
heuristics that can be implemented in polynomial time and in a distributed
fashion and compare them with the optimal solution. Simulations suggest that
both heuristics perform very close to the optimal solution over random network
topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4898</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4898</id><created>2010-08-28</created><authors><author><keyname>Gobjuka</keyname><forenames>Hassan</forenames></author><author><keyname>Ahmat</keyname><forenames>Kamal</forenames></author></authors><title>WiNV: A Framework for Web-based Interactive Scalable Network
  Visualization</title><categories>cs.NI cs.SE</categories><comments>The IEEE INFOCOM 2010, San Diego, California</comments><journal-ref>The IEEE INFOCOM 2010, San Diego, California, March 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we introduce WiNV - A framework for web-based interactive
scalable network visualization. WiNV enables a new class of rich and scalable
interactive cross-platform capabilities for visualizing large-scale networks
natively in a user's browser. Extensive experiments show that our system can
visualize networks that consist of tens of thousands of nodes while maintaining
fast, high-quality interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4900</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4900</id><created>2010-08-28</created><authors><author><keyname>Ahmat</keyname><forenames>Kamal A.</forenames></author><author><keyname>Gobjuka</keyname><forenames>Hassan</forenames></author></authors><title>Managing Clouds in Cloud Platforms</title><categories>cs.DC cs.NI</categories><comments>NSDI '10: 7th USENIX Symposium on Networked Systems Design and
  Implementation, San Jose, California</comments><journal-ref>NSDI '10: 7th USENIX Symposium on Networked Systems Design and
  Implementation, San Jose, California, April 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Managing cloud services is a fundamental challenge in todays virtualized
environments. These challenges equally face both providers and consumers of
cloud services. The issue becomes even more challenging in virtualized
environments that support mobile clouds. Cloud computing platforms such as
Amazon EC2 provide customers with flexible, on demand resources at low cost.
However, they fail to provide seamless infrastructure management and monitoring
capabilities that many customers may need. For instance, Amazon EC2 doesn't
fully support cloud services automated discovery and it requires a private set
of authentication credentials. Salesforce.com, on the other hand, do not
provide monitoring access to their underlying systems. Moreover, these systems
fail to provide infrastructure monitoring of heterogenous and legacy systems
that don't support agents. In this work, we explore how to build a cloud
management system that combines heterogeneous management of virtual resources
with comprehensive management of physical devices. We propose an initial
prototype for automated cloud management and monitoring framework. Our ultimate
goal is to develop a framework that have the capability of automatically
tracking configuration and relationships while providing full event management,
measuring performance and testing thresholds, and measuring availability
consistently. Armed with such a framework, operators can make better decisions
quickly and more efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4904</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4904</id><created>2010-08-29</created><authors><author><keyname>Moghaddam</keyname><forenames>Saeed</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>Spatio-Temporal Modeling of Wireless Users Internet Access Patterns
  Using Self-Organizing Maps</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User online behavior and interests will play a central role in future mobile
networks. We introduce a systematic method for large-scale multi-dimensional
analysis of online activity for thousands of mobile users across 79 buildings
over a variety of web domains. We propose a modeling approach based on
self-organizing maps (SOM) for discovering, organizing and visualizing
different mobile users' trends from billions of WLAN records. We find
surprisingly that users' trends based on domains and locations can be
accurately modeled using a self-organizing map with clearly distinct
characteristics. We also find many non-trivial correlations between different
types of web domains and locations. Based on our analysis, we introduce a
mixture model as an initial step towards realistic simulation of wireless
network usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4916</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4916</id><created>2010-08-29</created><updated>2011-01-27</updated><authors><author><keyname>Eisenstat</keyname><forenames>David</forenames></author></authors><title>Random road networks: the quadtree model</title><categories>cs.DM cs.SI</categories><comments>ANALCO '11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What does a typical road network look like? Existing generative models tend
to focus on one aspect to the exclusion of others. We introduce the
general-purpose \emph{quadtree model} and analyze its shortest paths and
maximum flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4929</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4929</id><created>2010-08-29</created><authors><author><keyname>Kaifosh</keyname><forenames>Patrick</forenames></author></authors><title>User interfaces and data entry with real time inverse arithmetic coding</title><categories>cs.HC</categories><comments>12 pages, 4 figures</comments><acm-class>H.5.2; K.4.2; K.8.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces real time inverse arithmetic coding and user interfaces
based thereupon. The main idea is that information-efficient data entry can be
achieved by ensuring that each input's associated display space and ease of
selection are at all times related to the input's probability of being
selected. As with data entry based on inverse arithmetic coding, the layout
initially depends on the probabilities of the possible inputs; however, real
time inverse arithmetic coding differs in that the user's actions are
interpreted not to navigate this probability distribution but rather to modify
it according to a learned update rule, which approximates the conditioning of
the probability distribution on the user's actions. Potential applications of
real time inverse arithmetic coding include text entry, file browsing,
integrated multi-program user interfaces, assistive technologies for users with
movement disabilities, and ergonomic input methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4931</identifier>
 <datestamp>2014-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4931</id><created>2010-08-29</created><authors><author><keyname>Wu</keyname><forenames>Wenji</forenames></author><author><keyname>DeMar</keyname><forenames>Phil</forenames></author><author><keyname>Crawford</keyname><forenames>Matt</forenames></author></authors><title>Sorting Reordered Packets with Interrupt Coalescing</title><categories>cs.NI</categories><journal-ref>Comput.Net.53:2646-2662,2009</journal-ref><doi>10.1016/j.comnet.2009.05.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  TCP performs poorly in networks with serious packet reordering. Processing
reordered packets in the TCP layer is costly and inefficient, involving
interaction of the sender and receiver. Motivated by the interrupt coalescing
mechanism that delivers packets upward for protocol processing in blocks, we
propose a new strategy, Sorting Reordered Packets with Interrupt Coalescing
(SRPIC), to reduce packet reordering in the receiver. SRPIC works in the
network device driver; it makes use of the interrupt coalescing mechanism to
sort the reordered packets belonging to the same TCP stream in a block of
packets before delivering them upward; each sorted block is internally ordered.
Experiments have proven the effectiveness of SRPIC against forward-path
reordering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4938</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4938</id><created>2010-08-29</created><authors><author><keyname>Hong</keyname><forenames>Yoojin</forenames></author><author><keyname>Ko</keyname><forenames>Kyung Dae</forenames></author><author><keyname>Bhardwaj</keyname><forenames>Gaurav</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenhai</forenames></author><author><keyname>van Rossum</keyname><forenames>Damian B.</forenames></author><author><keyname>Patterson</keyname><forenames>Randen L.</forenames></author></authors><title>Towards Solving the Inverse Protein Folding Problem</title><categories>q-bio.QM cs.SC</categories><comments>22 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurately assigning folds for divergent protein sequences is a major
obstacle to structural studies and underlies the inverse protein folding
problem. Herein, we outline our theories for fold-recognition in the
&quot;twilight-zone&quot; of sequence similarity (&lt;25% identity). Our analyses
demonstrate that structural sequence profiles built using Position-Specific
Scoring Matrices (PSSMs) significantly outperform multiple popular
homology-modeling algorithms for relating and predicting structures given only
their amino acid sequences. Importantly, structural sequence profiles
reconstitute SCOP fold classifications in control and test datasets. Results
from our experiments suggest that structural sequence profiles can be used to
rapidly annotate protein folds at proteomic scales. We propose that encoding
the entire Protein DataBank (~1070 folds) into structural sequence profiles
would extract interoperable information capable of improving most if not all
methods of structural modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4941</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4941</id><created>2010-08-29</created><authors><author><keyname>Durham</keyname><forenames>Joseph W.</forenames></author><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Pairwise Optimal Discrete Coverage Control for Gossiping Robots</title><categories>cs.RO math.OC</categories><comments>Expanded version of paper appearing in CDC 2010. 8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose distributed algorithms to automatically deploy a group of robotic
agents and provide coverage of a discretized environment represented by a
graph. The classic Lloyd approach to coverage optimization involves separate
centering and partitioning steps and converges to the set of centroidal Voronoi
partitions. In this work we present a novel graph coverage algorithm which
achieves better performance without this separation while requiring only
pairwise ``gossip'' communication between agents. Our new algorithm provably
converges to an element of the set of pairwise-optimal partitions, a subset of
the set of centroidal Voronoi partitions. We illustrate that this new
equilibrium set represents a significant performance improvement through
numerical comparisons to existing Lloyd-type methods. Finally, we discuss ways
to efficiently do the necessary computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4957</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4957</id><created>2010-08-29</created><authors><author><keyname>Liang</keyname><forenames>X. San</forenames></author></authors><title>Remarkable evolutionary laws of absolute and relative entropies with
  dynamical systems</title><categories>nlin.CD cs.IT math.IT physics.ao-ph physics.flu-dyn</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of entropy is derived with respect to dynamical systems. For a
stochastic system, its relative entropy $D$ evolves in accordance with the
second law of thermodynamics; its absolute entropy $H$ may also be so, provided
that the stochastic perturbation is additive and the flow of the vector field
is nondivergent. For a deterministic system, $dH/dt$ is equal to the
mathematical expectation of the divergence of the flow (a result obtained
before), and, remarkably, $dD/dt = 0$. That is to say, relative entropy is
always conserved. So, for a nonlinear system, though the trajectories of the
state variables, say $\ve x$, may appear chaotic in the phase space, say
$\Omega$, those of the density function $\rho(\ve x)$ in the new ``phase
space'' $L^1(\Omega)$ are not; the corresponding Lyapunov exponent is always
zero. This result is expected to have important implications for the ensemble
predictions in many applied fields, and may help to analyze chaotic data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4966</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4966</id><created>2010-08-29</created><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames></author><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Multiple source, single sink maximum flow in a planar graph</title><categories>cs.DM cs.DS</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an $O(n^{1.5}\log n)$ time algorithm for finding the maximum flow in
a directed planar graph with multiple sources and a single sink. The techniques
generalize to a subquadratic time algorithm for bounded genus graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4973</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4973</id><created>2010-08-29</created><authors><author><keyname>Malakar</keyname><forenames>N. K.</forenames></author><author><keyname>Knuth</keyname><forenames>K. H.</forenames></author></authors><title>Entropy-Based Search Algorithm for Experimental Design</title><categories>stat.ML cs.LG physics.comp-ph physics.data-an</categories><comments>8 pages, 3 figures. To appear in the proceedings of MaxEnt 2010, held
  in Chamonix, France</comments><doi>10.1063/1.3573612</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The scientific method relies on the iterated processes of inference and
inquiry. The inference phase consists of selecting the most probable models
based on the available data; whereas the inquiry phase consists of using what
is known about the models to select the most relevant experiment. Optimizing
inquiry involves searching the parameterized space of experiments to select the
experiment that promises, on average, to be maximally informative. In the case
where it is important to learn about each of the model parameters, the
relevance of an experiment is quantified by Shannon entropy of the distribution
of experimental outcomes predicted by a probable set of models. If the set of
potential experiments is described by many parameters, we must search this
high-dimensional entropy space. Brute force search methods will be slow and
computationally expensive. We present an entropy-based search algorithm, called
nested entropy sampling, to select the most informative experiment for
efficient experimental design. This algorithm is inspired by Skilling's nested
sampling algorithm used in inference and borrows the concept of a rising
threshold while a set of experiment samples are maintained. We demonstrate that
this algorithm not only selects highly relevant experiments, but also is more
efficient than brute force search. Such entropic search techniques promise to
greatly benefit autonomous experimental design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4974</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4974</id><created>2010-08-29</created><authors><author><keyname>Lakoba</keyname><forenames>Taras I.</forenames></author></authors><title>Stability analysis of the split-step Fourier method on the background of
  a soliton of the nonlinear Schr\&quot;odinger equation</title><categories>cs.NA math.NA nlin.PS</categories><comments>28 pages, 5 figures This is the original manuscript submitted to the
  journal Numerical methods for PDEs. A revised version, in whose title the
  word &quot;Stability&quot; is changed to &quot;Instability&quot;, is scheduled to appear in that
  journal at the end of 2010</comments><msc-class>65M12, 65M70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a numerical instability that occurs in the well-known split-step
Fourier method on the background of a soliton. This instability is found to be
very sensitive to small changes of the parameters of both the numerical grid
and the soliton, unlike the instability of most finite-difference schemes. % on
the background of a monochromatic wave, considered earlier in the literature.
Moreover, the principle of ``frozen coefficients&quot;, in which variable
coefficients are treated as ``locally constant&quot; for the purpose of stability
analysis, is strongly violated for the instability of the split-step method on
the soliton background. Our analysis explains all these features. It is enabled
by the fact that the period of oscillations of the unstable Fourier modes is
much smaller than the width of the soliton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.4990</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.4990</id><created>2010-08-29</created><updated>2010-12-02</updated><authors><author><keyname>Obermeyer</keyname><forenames>Karl J.</forenames></author><author><keyname>Ganguli</keyname><forenames>Anurag</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Multi-Agent Deployment for Visibility Coverage in Polygonal Environments
  with Holes</title><categories>cs.RO cs.DC cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a distributed algorithm for a group of robotic agents
with omnidirectional vision to deploy into nonconvex polygonal environments
with holes. Agents begin deployment from a common point, possess no prior
knowledge of the environment, and operate only under line-of-sight sensing and
communication. The objective of the deployment is for the agents to achieve
full visibility coverage of the environment while maintaining line-of-sight
connectivity with each other. This is achieved by incrementally partitioning
the environment into distinct regions, each completely visible from some agent.
Proofs are given of (i) convergence, (ii) upper bounds on the time and number
of agents required, and (iii) bounds on the memory and communication
complexity. Simulation results and description of robust extensions are also
included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5000</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5000</id><created>2010-08-30</created><updated>2010-12-29</updated><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author><author><keyname>Wu</keyname><forenames>Jian-Liang</forenames></author></authors><title>Structural properties of 1-planar graphs and an application to acyclic
  edge coloring</title><categories>cs.DM math.CO</categories><comments>Please cite this published article as: X. Zhang, G. Liu, J.-L. Wu.
  Structural properties of 1-planar graphs and an application to acyclic edge
  coloring. Scientia Sinica Mathematica, 2010, 40, 1025--1032</comments><msc-class>05C10, 05C15, 05C75</msc-class><journal-ref>Scientia Sinica Mathematica, 2010, 40, 1025--1032</journal-ref><doi>10.1360/012009-678</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is called 1-planar if it can be drawn on the plane so that each edge
is crossed by at most one other edge. In this paper, we establish a local
property of 1-planar graphs which describes the structure in the neighborhood
of small vertices (i.e. vertices of degree no more than seven). Meanwhile, some
new classes of light graphs in 1-planar graphs with the bounded degree are
found. Therefore, two open problems presented by Fabrici and Madaras [The
structure of 1-planar graphs, Discrete Mathematics, 307, (2007), 854-865] are
solved. Furthermore, we prove that each 1-planar graph $G$ with maximum degree
$\Delta(G)$ is acyclically edge $L$-choosable where
$L=\max\{2\Delta(G)-2,\Delta(G)+83\}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5015</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5015</id><created>2010-08-30</created><authors><author><keyname>Xiong</keyname><forenames>Hu</forenames></author><author><keyname>Hu</keyname><forenames>Jianbin</forenames></author><author><keyname>Yang</keyname><forenames>Tao</forenames></author><author><keyname>Xin</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Zhong</forenames></author></authors><title>Efficient Privacy-Preserving Authentication Protocol for Vehicular
  Communications with Trustworthy</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an efficient and trustworthy conditional
privacy-preserving communication protocol for VANETs based on proxy
re-signature. The proposed protocol is characterized by the Trusted Authority
(TA) designating the Roadside Units (RSUs) to translate signatures computed by
the On-Board Units (OBUs) into one that are valid with respect to TA's public
key. In addition, the proposed protocol offers both a priori and a posteriori
countermeasures: it can not only provide fast anonymous authentication and
privacy tracking, but guarantees message trustworthiness for vehicle-to-vehicle
(V2V) communications. Furthermore, it reduces the communication overhead and
offers fast message authentication and, low storage requirements. We use
extensive analysis to demonstrate the merits of the proposed protocol and to
contrast it with previously proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5022</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5022</id><created>2010-08-30</created><authors><author><keyname>Rogers</keyname><forenames>Caroline</forenames></author></authors><title>Quantum Measurements Cannot be Proved to be Random</title><categories>quant-ph cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that it is impossible to prove that the outcome of a quantum
measurement is random.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5029</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5029</id><created>2010-08-30</created><authors><author><keyname>Drescher</keyname><forenames>Christian</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Reformulation of Global Constraints in Answer Set Programming</title><categories>cs.LO</categories><comments>Proceedings of AAAI'10 Workshop on Abstraction, Reformulation, and
  Approximation. AAAI Technical Report, WS-10-08, pages 14-19, AAAI Press, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that global constraints on finite domains like all-different can be
reformulated into answer set programs on which we achieve arc, bound or range
consistency. These reformulations offer a number of other advantages beyond
providing the power of global propagators to answer set programming. For
example, they provide other constraints with access to the state of the
propagator by sharing variables. Such sharing can be used to improve
propagation between constraints. Experiments with these encodings demonstrate
their promise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5033</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5033</id><created>2010-08-30</created><authors><author><keyname>Drescher</keyname><forenames>Christian</forenames></author></authors><title>Symmetry Breaking for Answer Set Programming</title><categories>cs.LO</categories><comments>Diploma thesis. Vienna University of Technology, August 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of answer set programming, this work investigates symmetry
detection and symmetry breaking to eliminate symmetric parts of the search
space and, thereby, simplify the solution process. We contribute a reduction of
symmetry detection to a graph automorphism problem which allows to extract
symmetries of a logic program from the symmetries of the constructed coloured
graph. We also propose an encoding of symmetry-breaking constraints in terms of
permutation cycles and use only generators in this process which implicitly
represent symmetries and always with exponential compression. These ideas are
formulated as preprocessing and implemented in a completely automated flow that
first detects symmetries from a given answer set program, adds
symmetry-breaking constraints, and can be applied to any existing answer set
solver. We demonstrate computational impact on benchmarks versus direct
application of the solver.
  Furthermore, we explore symmetry breaking for answer set programming in two
domains: first, constraint answer set programming as a novel approach to
represent and solve constraint satisfaction problems, and second, distributed
nonmonotonic multi-context systems. In particular, we formulate a
translation-based approach to constraint answer set solving which allows for
the application of our symmetry detection and symmetry breaking methods. To
compare their performance with a-priori symmetry breaking techniques, we also
contribute a decomposition of the global value precedence constraint that
enforces domain consistency on the original constraint via the unit-propagation
of an answer set solver. We evaluate both options in an empirical analysis. In
the context of distributed nonmonotonic multi-context system, we develop an
algorithm for distributed symmetry detection and also carry over
symmetry-breaking constraints for distributed answer set programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5035</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5035</id><created>2010-08-30</created><authors><author><keyname>Preobrazhenskii</keyname><forenames>Sergei N.</forenames><affiliation>Lomonosov Moscow State University</affiliation></author></authors><title>Recovering Fourier coefficients of modular forms and factoring of
  integers</title><categories>math.NT cs.CR math.NA</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that if a function defined on the segment [-1,1] has sufficiently
good approximation by partial sums of the Legendre polynomial expansion, then,
given the function's Fourier coefficients $c_n$ for some subset of
$n\in[n_1,n_2]$, one may approximately recover them for all $n\in[n_1,n_2]$. As
an application, a new approach to factoring of integers is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5057</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5057</id><created>2010-08-30</created><authors><author><keyname>Ukkonen</keyname><forenames>Antti</forenames></author></authors><title>Approximate Top-k Retrieval from Hidden Relations</title><categories>cs.DB cs.IR</categories><report-no>TKK-ICS-R36</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the evaluation of approximate top-k queries from relations with
a-priori unknown values. Such relations can arise for example in the context of
expensive predicates, or cloud-based data sources. The task is to find an
approximate top-k set that is close to the exact one while keeping the total
processing cost low. The cost of a query is the sum of the costs of the entries
that are read from the hidden relation. A novel aspect of this work is that we
consider prior information about the values in the hidden matrix. We propose an
algorithm that uses regression models at query time to assess whether a row of
the matrix can enter the top-k set given that only a subset of its values are
known. The regression models are trained with existing data that follows the
same distribution as the relation subjected to the query. To evaluate the
algorithm and to compare it with a method proposed previously in literature, we
conduct experiments using data from a context sensitive Wikipedia search
engine. The results indicate that the proposed method outperforms the baseline
algorithms in terms of the cost while maintaining a high accuracy of the
returned results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5073</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5073</id><created>2010-08-30</created><authors><author><keyname>Barcenas</keyname><forenames>Everardo</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Geneves</keyname><forenames>Pierre</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Layaida</keyname><forenames>Nabil</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Schmitt</keyname><forenames>Alan</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>On the Count of Trees</title><categories>cs.DB</categories><proxy>ccsd</proxy><report-no>RR-7251</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regular tree grammars and regular path expressions constitute core constructs
widely used in programming languages and type systems. Nevertheless, there has
been little research so far on frameworks for reasoning about path expressions
where node cardinality constraints occur along a path in a tree. We present a
logic capable of expressing deep counting along paths which may include
arbitrary recursive forward and backward navigation. The counting extensions
can be seen as a generalization of graded modalities that count immediate
successor nodes. While the combination of graded modalities, nominals, and
inverse modalities yields undecidable logics over graphs, we show that these
features can be combined in a decidable tree logic whose main features can be
decided in exponential time. Our logic being closed under negation, it may be
used to decide typical problems on XPath queries such as satisfiability, type
checking with relation to regular types, containment, or equivalence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5078</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5078</id><created>2010-08-30</created><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>Prediction by Compression</title><categories>cs.IT cs.AI cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that text compression can be achieved by predicting the next
symbol in the stream of text data based on the history seen up to the current
symbol. The better the prediction the more skewed the conditional probability
distribution of the next symbol and the shorter the codeword that needs to be
assigned to represent this next symbol. What about the opposite direction ?
suppose we have a black box that can compress text stream. Can it be used to
predict the next symbol in the stream ? We introduce a criterion based on the
length of the compressed data and use it to predict the next symbol. We examine
empirically the prediction error rate and its dependency on some compression
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5080</identifier>
 <datestamp>2010-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5080</id><created>2010-08-30</created><authors><author><keyname>D'Alfonso</keyname><forenames>Lisi</forenames></author><author><keyname>Jeronimo</keyname><forenames>Gabriella</forenames></author><author><keyname>Ollivier</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Sedoglavic</keyname><forenames>Alexandre</forenames></author><author><keyname>Solern&#xf3;</keyname><forenames>Pablo</forenames></author></authors><title>A Geometric Index Reduction Method for Implicit Systems of Differential
  Algebraic Equations</title><categories>math.CA cs.SC</categories><msc-class>12H05, 34A09, 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the index reduction problem for the class of
quasi-regular DAE systems. It is shown that any of these systems can be
transformed to a generically equivalent first order DAE system consisting of a
single purely algebraic (polynomial) equation plus an under-determined ODE
(that is, a semi-explicit DAE system of differentiation index 1) in as many
variables as the order of the input system. This can be done by means of a
Kronecker-type algorithm with bounded complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5090</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5090</id><created>2010-08-30</created><authors><author><keyname>Dinuzzo</keyname><forenames>Francesco</forenames></author></authors><title>Fixed-point and coordinate descent algorithms for regularized kernel
  methods</title><categories>cs.LG math.OC stat.CO stat.ML</categories><doi>10.1109/TNN.2011.2164096</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study two general classes of optimization algorithms for
kernel methods with convex loss function and quadratic norm regularization, and
analyze their convergence. The first approach, based on fixed-point iterations,
is simple to implement and analyze, and can be easily parallelized. The second,
based on coordinate descent, exploits the structure of additively separable
loss functions to compute solutions of line searches in closed form. Instances
of these general classes of algorithms are already incorporated into state of
the art machine learning software for large scale problems. We start from a
solution characterization of the regularized problem, obtained using
sub-differential calculus and resolvents of monotone operators, that holds for
general convex loss functions regardless of differentiability. The two
methodologies described in the paper can be regarded as instances of non-linear
Jacobi and Gauss-Seidel algorithms, and are both well-suited to solve large
scale problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5093</identifier>
 <datestamp>2012-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5093</id><created>2010-08-30</created><authors><author><keyname>Choi</keyname><forenames>Byung-Soo</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author></authors><title>An $\Theta(\sqrt{n})$-depth Quantum Adder on a 2D NTC Quantum Computer
  Architecture</title><categories>quant-ph cs.AR</categories><doi>10.1145/2287696.2287707</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose an adder for the 2D NTC architecture, designed to
match the architectural constraints of many quantum computing technologies. The
chosen architecture allows the layout of logical qubits in two dimensions and
the concurrent execution of one- and two-qubit gates with nearest-neighbor
interaction only. The proposed adder works in three phases. In the first phase,
the first column generates the summation output and the other columns do the
carry-lookahead operations. In the second phase, these intermediate values are
propagated from column to column, preparing for computation of the final carry
for each register position. In the last phase, each column, except the first
one, generates the summation output using this column-level carry. The depth
and the number of qubits of the proposed adder are $\Theta(\sqrt{n})$ and O(n),
respectively. The proposed adder executes faster than the adders designed for
the 1D NTC architecture when the length of the input registers $n$ is larger
than 58.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5105</identifier>
 <datestamp>2012-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5105</id><created>2010-08-30</created><updated>2011-05-21</updated><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>Indexability, concentration, and VC theory</title><categories>cs.DS cs.LG</categories><comments>17 pages, final submission to J. Discrete Algorithms (an expanded,
  improved and corrected version of the SISAP'2010 invited paper, this e-print,
  v3)</comments><msc-class>68P10, 68P20, 68Q87</msc-class><acm-class>H.3.3</acm-class><journal-ref>J. Discrete Algorithms 13 (2012), pp. 2-18</journal-ref><doi>10.1016/j.jda.2011.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Degrading performance of indexing schemes for exact similarity search in high
dimensions has long since been linked to histograms of distributions of
distances and other 1-Lipschitz functions getting concentrated. We discuss this
observation in the framework of the phenomenon of concentration of measure on
the structures of high dimension and the Vapnik-Chervonenkis theory of
statistical learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5133</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5133</id><created>2010-08-22</created><updated>2010-09-02</updated><authors><author><keyname>Merrikh-Bayat</keyname><forenames>Farnood</forenames></author><author><keyname>Bagheri-Shouraki</keyname><forenames>Saeed</forenames></author><author><keyname>Rohani</keyname><forenames>Ali</forenames></author></authors><title>Memristor Crossbar-based Hardware Implementation of IDS Method</title><categories>cs.LG cs.AI cs.AR</categories><comments>16 pages, 13 figures, Submitted to IEEE Transaction on Fuzzy Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ink Drop Spread (IDS) is the engine of Active Learning Method (ALM), which is
the methodology of soft computing. IDS, as a pattern-based processing unit,
extracts useful information from a system subjected to modeling. In spite of
its excellent potential in solving problems such as classification and modeling
compared to other soft computing tools, finding its simple and fast hardware
implementation is still a challenge. This paper describes a new hardware
implementation of IDS method based on the memristor crossbar structure. In
addition of simplicity, being completely real-time, having low latency and the
ability to continue working after the occurrence of power breakdown are some of
the advantages of our proposed circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5161</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5161</id><created>2010-08-30</created><updated>2010-10-04</updated><authors><author><keyname>Burger</keyname><forenames>John Robert</forenames></author></authors><title>Artificial Brain Based on Credible Neural Circuits in a Human Brain</title><categories>cs.AI q-bio.NC</categories><comments>14 pages 12 figures corrected Fig. 3 &amp; edited</comments><acm-class>I.2.0; I.2.6; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neurons are individually translated into simple gates to plan a brain based
on human psychology and intelligence. State machines, assumed previously
learned in subconscious associative memory are shown to enable equation solving
and rudimentary thinking using nanoprocessing within short term memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5163</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5163</id><created>2010-08-30</created><authors><author><keyname>McFee</keyname><forenames>Brian</forenames></author><author><keyname>Lanckriet</keyname><forenames>Gert</forenames></author></authors><title>Learning Multi-modal Similarity</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications involving multi-media data, the definition of similarity
between items is integral to several key tasks, e.g., nearest-neighbor
retrieval, classification, and recommendation. Data in such regimes typically
exhibits multiple modalities, such as acoustic and visual content of video.
Integrating such heterogeneous data to form a holistic similarity space is
therefore a key challenge to be overcome in many real-world applications.
  We present a novel multiple kernel learning technique for integrating
heterogeneous data into a single, unified similarity space. Our algorithm
learns an optimal ensemble of kernel transfor- mations which conform to
measurements of human perceptual similarity, as expressed by relative
comparisons. To cope with the ubiquitous problems of subjectivity and
inconsistency in multi- media similarity, we develop graph-based techniques to
filter similarity measurements, resulting in a simplified and robust training
procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5166</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5166</id><created>2010-08-30</created><authors><author><keyname>Navlakha</keyname><forenames>Saket</forenames></author><author><keyname>Kingsford</keyname><forenames>Carl</forenames></author></authors><title>Network Archaeology: Uncovering Ancient Networks from Present-day
  Interactions</title><categories>q-bio.MN cs.SI</categories><comments>16 pages, 10 figures</comments><acm-class>G.2.2; G.3; H.2.8</acm-class><doi>10.1371/journal.pcbi.1001119</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often questions arise about old or extinct networks. What proteins interacted
in a long-extinct ancestor species of yeast? Who were the central players in
the Last.fm social network 3 years ago? Our ability to answer such questions
has been limited by the unavailability of past versions of networks. To
overcome these limitations, we propose several algorithms for reconstructing a
network's history of growth given only the network as it exists today and a
generative model by which the network is believed to have evolved. Our
likelihood-based method finds a probable previous state of the network by
reversing the forward growth model. This approach retains node identities so
that the history of individual nodes can be tracked. We apply these algorithms
to uncover older, non-extant biological and social networks believed to have
grown via several models, including duplication-mutation with complementarity,
forest fire, and preferential attachment. Through experiments on both synthetic
and real-world data, we find that our algorithms can estimate node arrival
times, identify anchor nodes from which new nodes copy links, and can reveal
significant features of networks that have long since disappeared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5170</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5170</id><created>2010-08-30</created><authors><author><keyname>Amer</keyname><forenames>Abdelsalam</forenames></author><author><keyname>Gebali</keyname><forenames>Fayez</forenames></author></authors><title>General Model for Single and Multiple Channels WLANs with Quality of
  Service Support</title><categories>cs.NI</categories><comments>19 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop an intergraded model for request mechanism and data
transmission in the uplink phase in the presence of channel noise. This model
supports quality of service. The wireless channel is prone to many impairments.
Thus, certain techniques have to be developed to deliver data to the receiver.
We calculated the performance parameters for single and multichannel wireless
networks, like the requests throughput, data throughput and the requests
acceptance probability and data acceptance probability. The proposed model is
general model since it can be applied to different wireless networks such as
IEEE802.11a, IEEE802.16e, CDMA operated networks and Hiperlan\2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5188</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5188</id><created>2010-08-30</created><updated>2011-12-11</updated><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Li</keyname><forenames>Hanxi</forenames></author><author><keyname>Barnes</keyname><forenames>Nick</forenames></author></authors><title>Totally Corrective Boosting for Regularized Risk Minimization</title><categories>cs.AI</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consideration of the primal and dual problems together leads to important new
insights into the characteristics of boosting algorithms. In this work, we
propose a general framework that can be used to design new boosting algorithms.
A wide variety of machine learning problems essentially minimize a regularized
risk functional. We show that the proposed boosting framework, termed CGBoost,
can accommodate various loss functions and different regularizers in a
totally-corrective optimization fashion. We show that, by solving the primal
rather than the dual, a large body of totally-corrective boosting algorithms
can actually be efficiently solved and no sophisticated convex optimization
solvers are needed. We also demonstrate that some boosting algorithms like
AdaBoost can be interpreted in our framework--even their optimization is not
totally corrective. We empirically show that various boosting algorithms based
on the proposed framework perform similarly on the UCIrvine machine learning
datasets [1] that we have used in the experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5189</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5189</id><created>2010-08-30</created><authors><author><keyname>Balafoutis</keyname><forenames>Thanasis</forenames></author><author><keyname>Paparrizou</keyname><forenames>Anastasia</forenames></author><author><keyname>Stergiou</keyname><forenames>Kostas</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Improving the Performance of maxRPC</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Max Restricted Path Consistency (maxRPC) is a local consistency for binary
constraints that can achieve considerably stronger pruning than arc
consistency. However, existing maxRRC algorithms suffer from overheads and
redundancies as they can repeatedly perform many constraint checks without
triggering any value deletions. In this paper we propose techniques that can
boost the performance of maxRPC algorithms. These include the combined use of
two data structures to avoid many redundant constraint checks, and heuristics
for the efficient ordering and execution of certain operations. Based on these,
we propose two closely related algorithms. The first one which is a maxRPC
algorithm with optimal O(end^3) time complexity, displays good performance when
used stand-alone, but is expensive to apply during search. The second one
approximates maxRPC and has O(en^2d^4) time complexity, but a restricted
version with O(end^4) complexity can be very efficient when used during search.
Both algorithms have O(ed) space complexity. Experimental results demonstrate
that the resulting methods constantly outperform previous algorithms for
maxRPC, often by large margins, and constitute a more than viable alternative
to arc consistency on many problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5196</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5196</id><created>2010-08-30</created><updated>2011-08-21</updated><authors><author><keyname>Zhu</keyname><forenames>Yan</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>The Degrees of Freedom of MIMO Interference Channels without State
  Information at Transmitters</title><categories>cs.IT math.IT</categories><comments>second revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper fully determines the degree-of-freedom (DoF) region of two-user
interference channels with arbitrary number of transmit and receive antennas
and isotropic fading, where the channel state information is available to the
receivers but not to the transmitters. The result characterizes the capacity
region to the first order of the logarithm of the signal-to-noise ratio (SNR)
in the high-SNR regime. The DoF region is achieved using random Gaussian
codebooks independent of the channel states. Hence the DoF gain due to
beamforming and interference alignment is completely lost in absence of channel
state information at the transmitters (CSIT).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5204</identifier>
 <datestamp>2011-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5204</id><created>2010-08-30</created><updated>2011-06-30</updated><authors><author><keyname>Lin</keyname><forenames>Qihang</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Pena</keyname><forenames>Javier</forenames></author></authors><title>A Smoothing Stochastic Gradient Method for Composite Optimization</title><categories>math.OC cs.LG</categories><comments>working paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the unconstrained optimization problem whose objective function
is composed of a smooth and a non-smooth conponents where the smooth component
is the expectation a random function. This type of problem arises in some
interesting applications in machine learning. We propose a stochastic gradient
descent algorithm for this class of optimization problem. When the non-smooth
component has a particular structure, we propose another stochastic gradient
descent algorithm by incorporating a smoothing method into our first algorithm.
The proofs of the convergence rates of these two algorithms are given and we
show the numerical performance of our algorithm by applying them to regularized
linear regression problems with different sets of synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5209</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5209</id><created>2010-08-30</created><authors><author><keyname>Mairal</keyname><forenames>Julien</forenames><affiliation>INRIA Rocquencourt, LIENS</affiliation></author><author><keyname>Jenatton</keyname><forenames>Rodolphe</forenames><affiliation>INRIA Rocquencourt, LIENS</affiliation></author><author><keyname>Obozinski</keyname><forenames>Guillaume</forenames><affiliation>INRIA Rocquencourt, LIENS</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt, LIENS</affiliation></author></authors><title>Network Flow Algorithms for Structured Sparsity</title><categories>cs.LG stat.ML</categories><comments>accepted for publication in Adv. Neural Information Processing
  Systems, 2010</comments><proxy>ccsd</proxy><report-no>RR-7372</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of learning problems that involve a structured
sparsity-inducing norm defined as the sum of $\ell_\infty$-norms over groups of
variables. Whereas a lot of effort has been put in developing fast optimization
methods when the groups are disjoint or embedded in a specific hierarchical
structure, we address here the case of general overlapping groups. To this end,
we show that the corresponding optimization problem is related to network flow
optimization. More precisely, the proximal problem associated with the norm we
consider is dual to a quadratic min-cost flow problem. We propose an efficient
procedure which computes its solution exactly in polynomial time. Our algorithm
scales up to millions of variables, and opens up a whole new range of
applications for structured sparse models. We present several experiments on
image and video data, demonstrating the applicability and scalability of our
approach for various problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5217</identifier>
 <datestamp>2012-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5217</id><created>2010-08-31</created><updated>2012-02-23</updated><authors><author><keyname>Seferoglu</keyname><forenames>Hulya</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>K. K.</forenames></author></authors><title>Intra- and Inter-Session Network Coding in Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we are interested in improving the performance of constructive
network coding schemes in lossy wireless environments.We propose I2NC - a
cross-layer approach that combines inter-session and intra-session network
coding and has two strengths. First, the error-correcting capabilities of
intra-session network coding make our scheme resilient to loss. Second,
redundancy allows intermediate nodes to operate without knowledge of the
decoding buffers of their neighbors. Based only on the knowledge of the loss
rates on the direct and overhearing links, intermediate nodes can make
decisions for both intra-session (i.e., how much redundancy to add in each
flow) and inter-session (i.e., what percentage of flows to code together)
coding. Our approach is grounded on a network utility maximization (NUM)
formulation of the problem. We propose two practical schemes, I2NC-state and
I2NC-stateless, which mimic the structure of the NUM optimal solution. We also
address the interaction of our approach with the transport layer. We
demonstrate the benefits of our schemes through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5231</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5231</id><created>2010-08-31</created><updated>2011-08-05</updated><authors><author><keyname>Slavakis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Yamada</keyname><forenames>Isao</forenames></author></authors><title>The adaptive projected subgradient method constrained by families of
  quasi-nonexpansive mappings and its application to online learning</title><categories>math.OC cs.IT cs.LG math.IT</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many online, i.e., time-adaptive, inverse problems in signal processing and
machine learning fall under the wide umbrella of the asymptotic minimization of
a sequence of non-negative, convex, and continuous functions. To incorporate
a-priori knowledge into the design, the asymptotic minimization task is usually
constrained on a fixed closed convex set, which is dictated by the available
a-priori information. To increase versatility towards the usage of the
available information, the present manuscript extends the Adaptive Projected
Subgradient Method (APSM) by introducing an algorithmic scheme which
incorporates a-priori knowledge in the design via a sequence of strongly
attracting quasi-nonexpansive mappings in a real Hilbert space. In such a way,
the benefits offered to online learning tasks by the proposed method unfold in
two ways: 1) the rich class of quasi-nonexpansive mappings provides a plethora
of ways to cast a-priori knowledge, and 2) by introducing a sequence of such
mappings, the proposed scheme is able to capture the time-varying nature of
a-priori information. The convergence properties of the algorithm are studied,
several special cases of the method with wide applicability are shown, and the
potential of the proposed scheme is demonstrated by considering an increasingly
important, nowadays, online sparse system/signal recovery task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5248</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5248</id><created>2010-08-31</created><updated>2012-06-19</updated><authors><author><keyname>Zhang</keyname><forenames>Shaoquan</forenames></author><author><keyname>Shao</keyname><forenames>Ziyu</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Jiang</keyname><forenames>Libin</forenames></author></authors><title>Optimal Distributed P2P Streaming under Node Degree Bounds</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of maximizing the broadcast rate in peer-to-peer (P2P)
systems under \emph{node degree bounds}, i.e., the number of neighbors a node
can simultaneously connect to is upper-bounded. The problem is critical for
supporting high-quality video streaming in P2P systems, and is challenging due
to its combinatorial nature. In this paper, we address this problem by
providing the first distributed solution that achieves near-optimal broadcast
rate under arbitrary node degree bounds, and over arbitrary overlay graph. It
runs on individual nodes and utilizes only the measurement from their one-hop
neighbors, making the solution easy to implement and adaptable to peer churn
and network dynamics. Our solution consists of two distributed algorithms
proposed in this paper that can be of independent interests: a network-coding
based broadcasting algorithm that optimizes the broadcast rate given a
topology, and a Markov-chain guided topology hopping algorithm that optimizes
the topology. Our distributed broadcasting algorithm achieves the optimal
broadcast rate over arbitrary P2P topology, while previously proposed
distributed algorithms obtain optimality only for P2P complete graphs. We prove
the optimality of our solution and its convergence to a neighborhood around the
optimal equilibrium under noisy measurements or without time-scale separation
assumptions. We demonstrate the effectiveness of our solution in simulations
using uplink bandwidth statistics of Internet hosts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5254</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5254</id><created>2010-08-31</created><updated>2013-06-23</updated><authors><author><keyname>Gui</keyname><forenames>Guan</forenames></author><author><keyname>Wan</keyname><forenames>Qun</forenames></author><author><keyname>Peng</keyname><forenames>Wei</forenames></author><author><keyname>Adachi</keyname><forenames>Fumiyuki</forenames></author></authors><title>Sparse Channel Estimation for Amplify-and-Forward Two-way Relay Network
  with Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>the paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Amplify-and-forward two-way relay network (AFTWRN) was introduced to realize
high-data rate transmission over the wireless frequency-selective channel.
However, AFTWRC requires the knowledge of channel state information (CSI) not
only for coherent data detection but also for the selfdata removal. This is
partial accomplished by training sequence-based linear channel estimation.
However, conventional linear estimation techniques neglect anticipated sparsity
of multipath channel and thus lead to low spectral efficiency which is scarce
in the field of wireless communication. Unlike the previous methods, we propose
a sparse channel estimation method which can exploit the sparse structure and
hence provide significant improvements in MSE performance when compared with
traditional LS-based linear channel probing strategies in AF-TWRN. Simulation
results confirm the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5274</identifier>
 <datestamp>2011-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5274</id><created>2010-08-31</created><updated>2011-07-01</updated><authors><author><keyname>Takeda</keyname><forenames>Koujin</forenames></author><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>Statistical mechanical assessment of a reconstruction limit of
  compressed sensing: Toward theoretical analysis of correlated signals</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>6 pages, 3 figures</comments><journal-ref>Europhys. Lett. 95 (2011) 18006</journal-ref><doi>10.1209/0295-5075/95/18006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a scheme for exploring the reconstruction limit of compressed
sensing by minimizing the general cost function under the random measurement
constraints for generic correlated signal sources. Our scheme is based on the
statistical mechanical replica method for dealing with random systems. As a
simple but non-trivial example, we apply the scheme to a sparse autoregressive
model, where the first differences in the input signals of the correlated time
series are sparse, and evaluate the critical compression rate for a perfect
reconstruction. The results are in good agreement with a numerical experiment
for a signal reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5287</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5287</id><created>2010-08-31</created><authors><author><keyname>Chaudhari</keyname><forenames>Dipak</forenames></author><author><keyname>Damani</keyname><forenames>Om P.</forenames></author><author><keyname>Laxman</keyname><forenames>Srivatsan</forenames></author></authors><title>Lexical Co-occurrence, Statistical Significance, and Word Association</title><categories>cs.CL cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lexical co-occurrence is an important cue for detecting word associations. We
present a theoretical framework for discovering statistically significant
lexical co-occurrences from a given corpus. In contrast with the prevalent
practice of giving weightage to unigram frequencies, we focus only on the
documents containing both the terms (of a candidate bigram). We detect biases
in span distributions of associated words, while being agnostic to variations
in global unigram frequencies. Our framework has the fidelity to distinguish
different classes of lexical co-occurrences, based on strengths of the document
and corpuslevel cues of co-occurrence in the data. We perform extensive
experiments on benchmark data sets to study the performance of various
co-occurrence measures that are currently known in literature. We find that a
relatively obscure measure called Ochiai, and a newly introduced measure CSA
capture the notion of lexical co-occurrence best, followed next by LLR, Dice,
and TTest, while another popular measure, PMI, suprisingly, performs poorly in
the context of lexical co-occurrence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5288</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5288</id><created>2010-08-31</created><authors><author><keyname>Akerblom</keyname><forenames>Nikolas</forenames></author><author><keyname>Cornelissen</keyname><forenames>Gunther</forenames></author></authors><title>Relative entropy as a measure of inhomogeneity in general relativity</title><categories>gr-qc cs.IT hep-th math-ph math.IT math.MP</categories><comments>15 pages, 7 figures</comments><report-no>NIKHEF 2010-025</report-no><journal-ref>J.Math.Phys.53:012502,2012</journal-ref><doi>10.1063/1.3675440</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of relative volume entropy for two spacetimes with
preferred compact spacelike foliations. This is accomplished by applying the
notion of Kullback-Leibler divergence to the volume elements induced on
spacelike slices. The resulting quantity gives a lower bound on the number of
bits which are necessary to describe one metric given the other. For
illustration, we study some examples, in particular gravitational waves, and
conclude that the relative volume entropy is a suitable device for quantitative
comparison of the inhomogeneity of two spacetimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5296</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5296</id><created>2010-08-31</created><updated>2012-01-17</updated><authors><author><keyname>Abyaneh</keyname><forenames>Mohammad Reza Sohizadeh</forenames></author></authors><title>Passive Cryptanalysis of Unconditionally Secure Authentication Protocol
  for RFID Systems</title><categories>cs.CR</categories><comments>This paper is withdrwan due to duplication in DBLP site</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Alomair et al. proposed the first UnConditionally Secure mutual
authentication protocol for low-cost RFID systems(UCS-RFID). The security of
the UCS-RFID relies on five dynamic secret keys which are updated at every
protocol run using a fresh random number (nonce) secretly transmitted from a
reader to tags. Our results show that, at the highest security level of the
protocol (security parameter= 256), inferring a nonce is feasible with the
probability of 0.99 by eavesdropping(observing) about 90 runs of the protocol.
Finding a nonce enable a passive attacker to recover all five secret keys of
the protocol. To do so, we propose a three-phase probabilistic approach in this
paper. Our attack recovers the secret keys with a probability that increases by
accessing to more protocol runs. We also show that tracing a tag using this
protocol is also possible even with less runs of the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5325</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5325</id><created>2010-08-31</created><updated>2011-03-21</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos</forenames></author></authors><title>Inference with Multivariate Heavy-Tails in Linear Models</title><categories>cs.LG cs.IT math.IT</categories><comments>In Neural Information Processing System (NIPS) 2010, Dec. 2010,
  Vancouver, Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heavy-tailed distributions naturally occur in many real life problems.
Unfortunately, it is typically not possible to compute inference in closed-form
in graphical models which involve such heavy-tailed distributions.
  In this work, we propose a novel simple linear graphical model for
independent latent random variables, called linear characteristic model (LCM),
defined in the characteristic function domain. Using stable distributions, a
heavy-tailed family of distributions which is a generalization of Cauchy,
L\'evy and Gaussian distributions, we show for the first time, how to compute
both exact and approximate inference in such a linear multivariate graphical
model. LCMs are not limited to stable distributions, in fact LCMs are always
defined for any random variables (discrete, continuous or a mixture of both).
  We provide a realistic problem from the field of computer networks to
demonstrate the applicability of our construction. Other potential application
is iterative decoding of linear channels with non-Gaussian noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5332</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5332</id><created>2010-08-31</created><updated>2010-09-14</updated><authors><author><keyname>Klein</keyname><forenames>Philip N.</forenames></author><author><keyname>Mozes</keyname><forenames>Shay</forenames></author></authors><title>Multiple-source single-sink maximum flow in directed planar graphs in
  $O(n^{1.5} \log n)$ time</title><categories>cs.DS cs.DM</categories><comments>13 pages, 2 figures. Corrected spelling in one citation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an $O(n^{1.5} \log n)$ algorithm that, given a directed planar graph
with arc capacities, a set of source nodes and a single sink node, finds a
maximum flow from the sources to the sink . This is the first subquadratic-time
strongly polynomial algorithm for the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5340</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5340</id><created>2010-08-28</created><authors><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Yuan</keyname><forenames>Zhou</forenames></author><author><keyname>Song</keyname><forenames>Ju Bin</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>Dynamic Interference Minimization Routing Game for On-Demand Cognitive
  Pilot Channel</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a distributed dynamic routing algorithm for
secondary users (SUs) to minimize their interference with the primary users
(PUs) in multi-hop cognitive radio (CR) networks. We use the medial axis with a
relaxation factor as a reference path which is contingent on the states of the
PUs. Along the axis, we construct a hierarchical structure for multiple sources
to reach cognitive pilot channel (CPC) base stations. We use a temporal and
spatial dynamic non-cooperative game to model the interactions among SUs as
well as their influences from PUs in the multi-hop structure of the network. A
multi-stage fictitious play learning is used for distributed routing in
multi-hop CR networks. We obtain a set of mixed (behavioral) Nash equilibrium
strategies of the dynamic game in closed form by backward induction. The
proposed algorithm minimizes the overall interference and the average packet
delay along the routing path from SU nodes to CPC base stations in an optimal
and distributed manner
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5356</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5356</id><created>2010-08-31</created><authors><author><keyname>Bansal</keyname><forenames>Nikhil</forenames></author><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Mestre</keyname><forenames>Julian</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Rudra</keyname><forenames>Atri</forenames></author></authors><title>When LP is the Cure for Your Matching Woes: Improved Bounds for
  Stochastic Matchings</title><categories>cs.DS</categories><comments>26 pages, preliminary version appears in ESA 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a random graph model where each possible edge $e$ is present
independently with some probability $p_e$. Given these probabilities, we want
to build a large/heavy matching in the randomly generated graph. However, the
only way we can find out whether an edge is present or not is to query it, and
if the edge is indeed present in the graph, we are forced to add it to our
matching. Further, each vertex $i$ is allowed to be queried at most $t_i$
times. How should we adaptively query the edges to maximize the expected weight
of the matching? We consider several matching problems in this general
framework (some of which arise in kidney exchanges and online dating, and
others arise in modeling online advertisements); we give LP-rounding based
constant-factor approximation algorithms for these problems. Our main results
are the following:
  We give a 4 approximation for weighted stochastic matching on general graphs,
and a 3 approximation on bipartite graphs. This answers an open question from
[Chen etal ICALP 09]. Combining our LP-rounding algorithm with the natural
greedy algorithm, we give an improved 3.46 approximation for unweighted
stochastic matching on general graphs.
  We introduce a generalization of the stochastic online matching problem
[Feldman etal FOCS 09] that also models preference-uncertainty and timeouts of
buyers, and give a constant factor approximation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5357</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5357</id><created>2010-08-31</created><authors><author><keyname>Mindolin</keyname><forenames>Denis</forenames></author><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author></authors><title>Preference Elicitation in Prioritized Skyline Queries</title><categories>cs.DB</categories><acm-class>H.2.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preference queries incorporate the notion of binary preference relation into
relational database querying. Instead of returning all the answers, such
queries return only the best answers, according to a given preference relation.
Preference queries are a fast growing area of database research. Skyline
queries constitute one of the most thoroughly studied classes of preference
queries. A well known limitation of skyline queries is that skyline preference
relations assign the same importance to all attributes. In this work, we study
p-skyline queries that generalize skyline queries by allowing varying attribute
importance in preference relations. We perform an in-depth study of the
properties of p-skyline preference relations. In particular,we study the
problems of containment and minimal extension. We apply the obtained results to
the central problem of the paper: eliciting relative importance of attributes.
Relative importance is implicit in the constructed p-skyline preference
relation. The elicitation is based on user-selected sets of superior (positive)
and inferior (negative) examples. We show that the computational complexity of
elicitation depends on whether inferior examples are involved. If they are not,
elicitation can be achieved in polynomial time. Otherwise, it is NP-complete.
Our experiments show that the proposed elicitation algorithm has high accuracy
and good scalability
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5367</identifier>
 <datestamp>2012-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5367</id><created>2010-08-31</created><updated>2012-04-20</updated><authors><author><keyname>Ren</keyname><forenames>Shaolei</forenames></author><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>User Subscription, Revenue Maximization, and Competition in
  Communications Markets</title><categories>cs.GT</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An updated version of this paper (but with a different title) can be found at
arXiv:1204.4262
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5372</identifier>
 <datestamp>2012-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5372</id><created>2010-08-31</created><updated>2012-05-11</updated><authors><author><keyname>Lu</keyname><forenames>Zhaosong</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author></authors><title>Penalty Decomposition Methods for $L0$-Norm Minimization</title><categories>math.OC cs.CV cs.IT cs.LG cs.NA math.IT stat.ME</categories><comments>This paper has been withdrawn by the author because an updated
  version has been resubmitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider general l0-norm minimization problems, that is, the
problems with l0-norm appearing in either objective function or constraint. In
particular, we first reformulate the l0-norm constrained problem as an
equivalent rank minimization problem and then apply the penalty decomposition
(PD) method proposed in [33] to solve the latter problem. By utilizing the
special structures, we then transform all matrix operations of this method to
vector operations and obtain a PD method that only involves vector operations.
Under some suitable assumptions, we establish that any accumulation point of
the sequence generated by the PD method satisfies a first-order optimality
condition that is generally stronger than one natural optimality condition. We
further extend the PD method to solve the problem with the l0-norm appearing in
objective function. Finally, we test the performance of our PD methods by
applying them to compressed sensing, sparse logistic regression and sparse
inverse covariance selection. The computational results demonstrate that our
methods generally outperform the existing methods in terms of solution quality
and/or speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5373</identifier>
 <datestamp>2012-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5373</id><created>2010-08-31</created><updated>2012-05-29</updated><authors><author><keyname>Lu</keyname><forenames>Zhaosong</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author></authors><title>Penalty Decomposition Methods for Rank Minimization</title><categories>math.OC cs.LG cs.NA cs.SY q-fin.CP q-fin.ST</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider general rank minimization problems with rank
appearing in either objective function or constraint. We first establish that a
class of special rank minimization problems has closed-form solutions. Using
this result, we then propose penalty decomposition methods for general rank
minimization problems in which each subproblem is solved by a block coordinate
descend method. Under some suitable assumptions, we show that any accumulation
point of the sequence generated by the penalty decomposition methods satisfies
the first-order optimality conditions of a nonlinear reformulation of the
problems. Finally, we test the performance of our methods by applying them to
the matrix completion and nearest low-rank correlation matrix problems. The
computational results demonstrate that our methods are generally comparable or
superior to the existing methods in terms of solution quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5380</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5380</id><created>2010-08-31</created><updated>2011-08-27</updated><authors><author><keyname>Kent</keyname><forenames>Adrian</forenames><affiliation>Centre for Quantum Information and Foundations, DAMTP, University of Cambridge and Perimeter Institute</affiliation></author></authors><title>Quantum Tagging for Tags Containing Secret Classical Data</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>Title changed for clarity. Refs updated. Published version</comments><journal-ref>Phys. Rev. A 84, 022335 (2011)</journal-ref><doi>10.1103/PhysRevA.84.022335</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various authors have considered schemes for {\it quantum tagging}, that is,
authenticating the classical location of a classical tagging device by sending
and receiving quantum signals from suitably located distant sites, in an
environment controlled by an adversary whose quantum information processing and
transmitting power is potentially unbounded. This task raises some interesting
new questions about cryptographic security assumptions, as relatively subtle
details in the security model can dramatically affect the security attainable.
We consider here the case in which the tag is cryptographically secure, and
show how to implement tagging securely within this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5386</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5386</id><created>2010-08-31</created><authors><author><keyname>Silva</keyname><forenames>Ricardo</forenames></author><author><keyname>Blundell</keyname><forenames>Charles</forenames></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames></author></authors><title>Mixed Cumulative Distribution Networks</title><categories>stat.ML cs.LG</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directed acyclic graphs (DAGs) are a popular framework to express
multivariate probability distributions. Acyclic directed mixed graphs (ADMGs)
are generalizations of DAGs that can succinctly capture much richer sets of
conditional independencies, and are especially useful in modeling the effects
of latent variables implicitly. Unfortunately there are currently no good
parameterizations of general ADMGs. In this paper, we apply recent work on
cumulative distribution networks and copulas to propose one one general
construction for ADMG models. We consider a simple parameter estimation
approach, and report some encouraging experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5387</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5387</id><created>2010-08-31</created><authors><author><keyname>Dashti</keyname><forenames>Hesam T.</forenames></author><author><keyname>Ardalan</keyname><forenames>Adel</forenames></author><author><keyname>Siahpirani</keyname><forenames>Alireza F.</forenames></author><author><keyname>Tonejc</keyname><forenames>Jernej</forenames></author><author><keyname>Uilecan</keyname><forenames>Ioan V.</forenames></author><author><keyname>Simas</keyname><forenames>Tiago</forenames></author><author><keyname>Miranda</keyname><forenames>Bruno</forenames></author><author><keyname>Ribeiro</keyname><forenames>Rita</forenames></author><author><keyname>Wang</keyname><forenames>Liya</forenames></author><author><keyname>Assadi</keyname><forenames>Amir H.</forenames></author></authors><title>Pattern Recognition in Collective Cognitive Systems: Hybrid
  Human-Machine Learning (HHML) By Heterogeneous Ensembles</title><categories>cs.AI astro-ph.CO q-bio.QM</categories><comments>International Conference on Artificial Intelligence, WorldComp 2010</comments><acm-class>I.2.6; J.2; J.3</acm-class><journal-ref>IC-AI CSREA Press (2010) , p. 183-188</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The ubiquitous role of the cyber-infrastructures, such as the WWW, provides
myriad opportunities for machine learning and its broad spectrum of application
domains taking advantage of digital communication. Pattern classification and
feature extraction are among the first applications of machine learning that
have received extensive attention. The most remarkable achievements have
addressed data sets of moderate-to-large size. The 'data deluge' in the last
decade or two has posed new challenges for AI researchers to design new,
effective and accurate algorithms for similar tasks using ultra-massive data
sets and complex (natural or synthetic) dynamical systems. We propose a novel
principled approach to feature extraction in hybrid architectures comprised of
humans and machines in networked communication, who collaborate to solve a
pre-assigned pattern recognition (feature extraction) task. There are two
practical considerations addressed below: (1) Human experts, such as plant
biologists or astronomers, often use their visual perception and other implicit
prior knowledge or expertise without any obvious constraints to search for the
significant features, whereas machines are limited to a pre-programmed set of
criteria to work with; (2) in a team collaboration of collective problem
solving, the human experts have diverse abilities that are complementary, and
they learn from each other to succeed in cognitively complex tasks in ways that
are still impossible imitate by machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5390</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5390</id><created>2010-08-31</created><authors><author><keyname>Dashti</keyname><forenames>Hesam T.</forenames></author><author><keyname>Tonejc</keyname><forenames>Jernej</forenames></author><author><keyname>Ardalan</keyname><forenames>Adel</forenames></author><author><keyname>Siahpirani</keyname><forenames>Alireza F.</forenames></author><author><keyname>Guettes</keyname><forenames>Sabrina</forenames></author><author><keyname>Sharif</keyname><forenames>Zohreh</forenames></author><author><keyname>Wang</keyname><forenames>Liya</forenames></author><author><keyname>Assadi</keyname><forenames>Amir H.</forenames></author></authors><title>Applications of Machine Learning Methods to Quantifying Phenotypic
  Traits that Distinguish the Wild Type from the Mutant Arabidopsis Thaliana
  Seedlings during Root Gravitropism</title><categories>q-bio.QM cs.CE cs.LG q-bio.GN</categories><comments>International Conference on Bioinformatics and Computational Biology,
  WorldComp 2010</comments><acm-class>J.3; I.5.3; I.2.9</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Post-genomic research deals with challenging problems in screening genomes of
organisms for particular functions or potential for being the targets of
genetic engineering for desirable biological features. 'Phenotyping' of wild
type and mutants is a time-consuming and costly effort by many individuals.
This article is a preliminary progress report in research on large-scale
automation of phenotyping steps (imaging, informatics and data analysis) needed
to study plant gene-proteins networks that influence growth and development of
plants. Our results undermine the significance of phenotypic traits that are
implicit in patterns of dynamics in plant root response to sudden changes of
its environmental conditions, such as sudden re-orientation of the root tip
against the gravity vector. Including dynamic features besides the common
morphological ones has paid off in design of robust and accurate machine
learning methods to automate a typical phenotyping scenario, i.e. to
distinguish the wild type from the mutants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5391</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5391</id><created>2010-08-31</created><updated>2013-12-15</updated><authors><author><keyname>Dashti</keyname><forenames>Hesam T.</forenames></author><author><keyname>Siahpirani</keyname><forenames>Alireza F.</forenames></author><author><keyname>Wang</keyname><forenames>Liya</forenames></author><author><keyname>Kloc</keyname><forenames>Mary</forenames></author><author><keyname>Assadi</keyname><forenames>Amir H.</forenames></author></authors><title>Parallel Evolutionary Computation in Very Large Scale Eigenvalue
  Problems</title><categories>cs.DC cs.NA</categories><comments>Proceedings of the 2008 International Conference on Scientific
  Computing, CSC 2008</comments><acm-class>A.0; D.1.3; I.2.8</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The history of research on eigenvalue problems is rich with many outstanding
contributions. Nonetheless, the rapidly increasing size of data sets requires
new algorithms for old problems in the context of extremely large matrix
dimensions. This paper reports on a new method for finding eigenvalues of very
large matrices by a synthesis of evolutionary computation, parallel
programming, and empirical stochastic search. The direct design of our method
has the added advantage that it could be adapted to extend many algorithmic
variants of solutions of generalized eigenvalue problems to improve the
accuracy of our algorithms. The preliminary evaluation results are encouraging
and demonstrate the method's efficiency and practicality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1008.5393</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1008.5393</id><created>2010-08-31</created><updated>2010-09-15</updated><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>Increased Capacity per Unit-Cost by Oversampling</title><categories>cs.IT math.IT</categories><comments>27 pages, 2 figures. To be presented at the IEEE 26-th Convention of
  Electrical and Electronics Engineers in Israel, November 17-20, 2010, Eilat,
  Israel. Corrected minor typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is demonstrated that doubling the sampling rate recovers some of the loss
in capacity incurred on the bandlimited Gaussian channel with a one-bit output
quantizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0026</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0026</id><created>2010-08-31</created><authors><author><keyname>Panagopoulos</keyname><forenames>Dimitrios</forenames></author></authors><title>A secret sharing scheme using groups</title><categories>cs.CR math.GR</categories><comments>4 pages</comments><msc-class>20F10, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a secret sharing scheme based on the word problem in groups is
introduced. The security of the scheme and possible variations are discussed in
section 2. The article concludes with the suggestion of two categories of
platform groups for the implementation of the scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0033</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0033</id><created>2010-08-31</created><authors><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Yang</keyname><forenames>Xiaowei</forenames></author><author><keyname>Xia</keyname><forenames>Yong</forenames></author></authors><title>NetFence: Preventing Internet Denial of Service from Inside Out</title><categories>cs.NI</categories><comments>The original paper is published in SIGCOMM 2010</comments><report-no>Technical Report 2010-01</report-no><acm-class>C.2.1; C.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denial of Service (DoS) attacks frequently happen on the Internet, paralyzing
Internet services and causing millions of dollars of financial loss. This work
presents NetFence, a scalable DoS-resistant network architecture. NetFence uses
a novel mechanism, secure congestion policing feedback, to enable robust
congestion policing inside the network. Bottleneck routers update the feedback
in packet headers to signal congestion, and access routers use it to police
senders' traffic. Targeted DoS victims can use the secure congestion policing
feedback as capability tokens to suppress unwanted traffic. When compromised
senders and receivers organize into pairs to congest a network link, NetFence
provably guarantees a legitimate sender its fair share of network resources
without keeping per-host state at the congested link. We use a Linux
implementation, ns-2 simulations, and theoretical analysis to show that
NetFence is an effective and scalable DoS solution: it reduces the amount of
state maintained by a congested router from per-host to at most per-(Autonomous
System).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0045</identifier>
 <datestamp>2015-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0045</id><created>2010-08-31</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author><author><keyname>Mumford</keyname><forenames>Elena</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author></authors><title>Optimal 3D Angular Resolution for Low-Degree Graphs</title><categories>cs.CG</categories><comments>18 pages, 10 figures. Extended version of paper to appear in Proc.
  18th Int. Symp. Graph Drawing, Konstanz, Germany, 2010</comments><acm-class>F.2.2</acm-class><journal-ref>J. Graph Algorithms &amp; Applications 17(3): 173-200, 2013</journal-ref><doi>10.7155/jgaa.00290</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every graph of maximum degree three can be drawn in three
dimensions with at most two bends per edge, and with 120-degree angles between
any two edge segments meeting at a vertex or a bend. We show that every graph
of maximum degree four can be drawn in three dimensions with at most three
bends per edge, and with 109.5-degree angles, i.e., the angular resolution of
the diamond lattice, between any two edge segments meeting at a vertex or bend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0050</identifier>
 <datestamp>2012-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0050</id><created>2010-08-31</created><authors><author><keyname>Li</keyname><forenames>Boyu</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Golden Coded Multiple Beamforming</title><categories>cs.IT math.IT</categories><comments>accepted to conference</comments><doi>10.1109/GLOCOM.2010.5683719</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Golden Code is a full-rate full-diversity space-time code, which achieves
maximum coding gain for Multiple-Input Multiple-Output (MIMO) systems with two
transmit and two receive antennas. Since four information symbols taken from an
M-QAM constellation are selected to construct one Golden Code codeword, a
maximum likelihood decoder using sphere decoding has the worst-case complexity
of O(M^4), when the Channel State Information (CSI) is available at the
receiver. Previously, this worst-case complexity was reduced to O(M^(2.5))
without performance degradation. When the CSI is known by the transmitter as
well as the receiver, beamforming techniques that employ singular value
decomposition are commonly used in MIMO systems. In the absence of channel
coding, when a single symbol is transmitted, these systems achieve the full
diversity order provided by the channel. Whereas this property is lost when
multiple symbols are simultaneously transmitted. However, uncoded multiple
beamforming can achieve the full diversity order by adding a properly designed
constellation precoder. For 2 \times 2 Fully Precoded Multiple Beamforming
(FPMB), the general worst-case decoding complexity is O(M). In this paper,
Golden Coded Multiple Beamforming (GCMB) is proposed, which transmits the
Golden Code through 2 \times 2 multiple beamforming. GCMB achieves the full
diversity order and its performance is similar to general MIMO systems using
the Golden Code and FPMB, whereas the worst-case decoding complexity of
O(sqrt(M)) is much lower. The extension of GCMB to larger dimensions is also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0051</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0051</id><created>2010-08-31</created><updated>2010-09-02</updated><authors><author><keyname>Yahya</keyname><forenames>Keyvan</forenames></author><author><keyname>Biazar</keyname><forenames>Jafar</forenames></author><author><keyname>Azari</keyname><forenames>Hossein</forenames></author><author><keyname>Fard</keyname><forenames>Pouyan Rafiei</forenames></author></authors><title>Variational Iteration Method for Image Restoration</title><categories>math.NA cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The famous Perona-Malik (P-M) equation which was at first introduced for
image restoration has been solved via various numerical methods. In this paper
we will solve it for the first time via applying a new numerical method called
the Variational Iteration Method (VIM) and the correspondent approximated
solutions will be obtained for the P-M equation with regards to relevant error
analysis. Through implementation of our algorithm we will access some effective
results which are deserved to be considered as worthy as the other solutions
issued by the other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0056</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0056</id><created>2010-08-31</created><authors><author><keyname>Sharma</keyname><forenames>Gokarna</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author></authors><title>A Competitive Analysis for Balanced Transactional Memory Workloads</title><categories>cs.DC</categories><comments>18 pages, In submission for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider transactional memory contention management in the context of
balanced workloads, where if a transaction is writing, the number of write
operations it performs is a constant fraction of its total reads and writes. We
explore the theoretical performance boundaries of contention management in
balanced workloads from the worst-case perspective by presenting and analyzing
two new contention management algorithms. The first algorithm Clairvoyant is
O(\surd s)-competitive, where s is the number of shared resources. This
algorithm depends on explicitly knowing the conflict graph. The second
algorithm Non-Clairvoyant is O(\surd s \cdot log n)-competitive, with high
probability, which is only a O(log n) factor worse, but does not require
knowledge of the conflict graph, where n is the number of transactions. Both of
these algorithms are greedy. We also prove that the performance of Clairvoyant
is tight since there is no contention management algorithm that is better than
O((\surd s)^(1-\epsilon))-competitive for any constant \epsilon &gt; 0, unless
NP\subseteq ZPP. To our knowledge, these results are significant improvements
over the best previously known O(s) competitive ratio bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0068</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0068</id><created>2010-08-31</created><authors><author><keyname>Yang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Lihua</forenames></author><author><keyname>Wu</keyname><forenames>Gang</forenames></author><author><keyname>Wang</keyname><forenames>Haifeng</forenames></author><author><keyname>Wang</keyname><forenames>Ying</forenames></author></authors><title>Joint Uplink and Downlink Relay Selection in Cooperative Cellular
  Networks</title><categories>cs.IT math.IT</categories><comments>Accepted by VTC-2010FALL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider relay selection technique in a cooperative cellular network where
user terminals act as mobile relays to help the communications between base
station (BS) and mobile station (MS). A novel relay selection scheme, called
Joint Uplink and Downlink Relay Selection (JUDRS), is proposed in this paper.
Specifically, we generalize JUDRS in two key aspects: (i) relay is selected
jointly for uplink and downlink, so that the relay selection overhead can be
reduced, and (ii) we consider to minimize the weighted total energy consumption
of MS, relay and BS by taking into account channel quality and traffic load
condition of uplink and downlink. Information theoretic analysis of the
diversity-multiplexing tradeoff demonstrates that the proposed scheme achieves
full spatial diversity in the quantity of cooperating terminals in this
network. And numerical results are provided to further confirm a significant
energy efficiency gain of the proposed algorithm comparing to the previous best
worse channel selection and best harmonic mean selection algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0072</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0072</id><created>2010-08-31</created><authors><author><keyname>Yang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Lihua</forenames></author><author><keyname>Wu</keyname><forenames>Gang</forenames></author><author><keyname>Wang</keyname><forenames>Haifeng</forenames></author></authors><title>Joint Relay Selection and Link Adaptation for Distributed Beamforming in
  Regenerative Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>Accepted by 2010 International Symposium on Information Theory and
  its Applications (ISITA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relay selection enhances the performance of the cooperative networks by
selecting the links with higher capacity. Meanwhile link adaptation improves
the spectral efficiency of wireless data-centric networks through adapting the
modulation and coding schemes (MCS) to the current link condition. In this
paper, relay selection is combined with link adaptation for distributed
beamforming in a two-hop regenerative cooperative system. A novel signaling
mechanism and related optimal algorithms are proposed for joint relay selection
and link adaptation. In the proposed scheme, there is no need to feedback the
relay selection results to each relay. Instead, by broadcasting the link
adaptation results from the destination, each relay will automatically
understand whether it is selected or not. The lower and upper bounds of the
throughput of the proposed scheme are derived. The analysis and simulation
results indicate that the proposed scheme provides synergistic gains compared
to the pure relay selection and link adaptation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0074</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0074</id><created>2010-08-31</created><updated>2012-03-04</updated><authors><author><keyname>Yang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Lihua</forenames></author><author><keyname>Wang</keyname><forenames>Ying</forenames></author><author><keyname>Sun</keyname><forenames>Wanlu</forenames></author></authors><title>Energy-Efficient Transmission Schemes in Cooperative Cellular Systems</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-efficient communication is an important requirement for mobile
devices, as the battery technology has not kept up with the growing
requirements stemming from ubiquitous multimedia applications. This paper
considers energy-efficient transmission schemes in cooperative cellular systems
with unbalanced traffic between uplink and downlink. Theoretically, we derive
the optimal transmission data rate, which minimizes the total energy
consumption of battery-powered terminals per information bit. The
energy-efficient cooperation regions are then investigated to illustrate the
effects of relay locations on the energy-efficiency of the systems, and the
optimal relay location is found for maximum energy-efficiency. Finally,
numerical results are provided to demonstrate the tradeoff between
energy-efficiency and spectral efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0077</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0077</id><created>2010-08-31</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Not only a lack of right definitions: Arguments for a shift in
  information-processing paradigm</title><categories>cs.AI q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Consciousness and Machine Intelligence are not simply new buzzwords
that occupy our imagination. Over the last decades, we witness an unprecedented
rise in attempts to create machines with human-like features and capabilities.
However, despite widespread sympathy and abundant funding, progress in these
enterprises is far from being satisfactory. The reasons for this are twofold:
First, the notions of cognition and intelligence (usually borrowed from human
behavior studies) are notoriously blurred and ill-defined, and second, the
basic concepts underpinning the whole discourse are by themselves either
undefined or defined very vaguely. That leads to improper and inadequate
research goals determination, which I will illustrate with some examples drawn
from recent documents issued by DARPA and the European Commission. On the other
hand, I would like to propose some remedies that, I hope, would improve the
current state-of-the-art disgrace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0078</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0078</id><created>2010-08-31</created><authors><author><keyname>Yang</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Lihua</forenames></author><author><keyname>Sun</keyname><forenames>Wanlu</forenames></author></authors><title>Energy-Efficient Relay Selection and Optimal Relay Location in
  Cooperative Cellular Networks with Asymmetric Traffic</title><categories>cs.IT math.IT</categories><comments>To appear in Journal of China Universities of Posts and
  Telecommunications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-efficient communication is an important requirement for mobile relay
networks due to the limited battery power of user terminals. This paper
considers energy-efficient relaying schemes through selection of mobile relays
in cooperative cellular systems with asymmetric traffic. The total energy
consumption per information bit of the battery-powered terminals, i.e., the
mobile station (MS) and the relay, is derived in theory. In the Joint Uplink
and Downlink Relay Selection (JUDRS) scheme we proposed, the relay which
minimizes the total energy consumption is selected. Additionally, the
energy-efficient cooperation regions are investigated, and the optimal relay
location is found for cooperative cellular systems with asymmetric traffic. The
results reveal that the MS-relay and the relay-base station (BS) channels have
different influence over relay selection decisions for optimal
energy-efficiency. Information theoretic analysis of the diversity-multiplexing
tradeoff (DMT) demonstrates that the proposed scheme achieves full spatial
diversity in the quantity of cooperating terminals in this network. Finally,
numerical results further confirm a significant energy efficiency gain of the
proposed algorithm comparing to the previous best worse channel selection and
best harmonic mean selection algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0088</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0088</id><created>2010-09-01</created><authors><author><keyname>Chambers</keyname><forenames>Erin W.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author></authors><title>Drawing Graphs in the Plane with a Prescribed Outer Face and Polynomial
  Area</title><categories>cs.CG</categories><comments>13 pages, 5 figures. This is an extended version of a paper to appear
  in Proc. 18th Int. Symp. Graph Drawing, 2010</comments><acm-class>F.2.2</acm-class><journal-ref>J. Graph Algorithms and Applications 16(2):243-259, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the classic graph drawing problem of drawing a planar graph using
straight-line edges with a prescribed convex polygon as the outer face. Unlike
previous algorithms for this problem, which may produce drawings with
exponential area, our method produces drawings with polynomial area. In
addition, we allow for collinear points on the boundary, provided such vertices
do not create overlapping edges. Thus, we solve an open problem of Duncan et
al., which, when combined with their work, implies that we can produce a planar
straight-line drawing of a combinatorially-embedded genus-g graph with the
graph's canonical polygonal schema drawn as a convex polygonal external face.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0108</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0108</id><created>2010-09-01</created><authors><author><keyname>Shaukat</keyname><forenames>Arslan</forenames></author><author><keyname>Chen</keyname><forenames>Ke</forenames></author></authors><title>Emotional State Categorization from Speech: Machine vs. Human</title><categories>cs.CL cs.AI cs.HC</categories><comments>14 pages, 15 figures, 12 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents our investigations on emotional state categorization from
speech signals with a psychologically inspired computational model against
human performance under the same experimental setup. Based on psychological
studies, we propose a multistage categorization strategy which allows
establishing an automatic categorization model flexibly for a given emotional
speech categorization task. We apply the strategy to the Serbian Emotional
Speech Corpus (GEES) and the Danish Emotional Speech Corpus (DES), where human
performance was reported in previous psychological studies. Our work is the
first attempt to apply machine learning to the GEES corpus where the human
recognition rates were only available prior to our study. Unlike the previous
work on the DES corpus, our work focuses on a comparison to human performance
under the same experimental settings. Our studies suggest that
psychology-inspired systems yield behaviours that, to a great extent, resemble
what humans perceived and their performance is close to that of humans under
the same experimental setup. Furthermore, our work also uncovers some
differences between machine and humans in terms of emotional state recognition
from speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0117</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0117</id><created>2010-09-01</created><authors><author><keyname>Shaukat</keyname><forenames>Arslan</forenames></author><author><keyname>Chen</keyname><forenames>Ke</forenames></author></authors><title>Exploring Language-Independent Emotional Acoustic Features via Feature
  Selection</title><categories>cs.LG</categories><comments>15 pages, 2 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel feature selection strategy to discover
language-independent acoustic features that tend to be responsible for emotions
regardless of languages, linguistics and other factors. Experimental results
suggest that the language-independent feature subset discovered yields the
performance comparable to the full feature set on various emotional speech
corpora.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0119</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0119</id><created>2010-09-01</created><authors><author><keyname>Menezes</keyname><forenames>Telmo</forenames></author><author><keyname>Roth</keyname><forenames>Camille</forenames></author><author><keyname>Cointet</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Precursors and Laggards: An Analysis of Semantic Temporal Relationships
  on a Blog Network</title><categories>cs.SI physics.soc-ph</categories><journal-ref>IEEE SocialCom Intl Conf on Social Computing, Minneapolis,
  Minnesota, Aug 2010</journal-ref><doi>10.1109/SocialCom.2010.26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the hypothesis that it is possible to obtain information about the
dynamics of a blog network by analysing the temporal relationships between
blogs at a semantic level, and that this type of analysis adds to the knowledge
that can be extracted by studying the network only at the structural level of
URL links. We present an algorithm to automatically detect fine-grained
discussion topics, characterized by n-grams and time intervals. We then propose
a probabilistic model to estimate the temporal relationships that blogs have
with one another. We define the precursor score of blog A in relation to blog B
as the probability that A enters a new topic before B, discounting the effect
created by asymmetric posting rates. Network-level metrics of precursor and
laggard behavior are derived from these dyadic precursor score estimations.
This model is used to analyze a network of French political blogs. The scores
are compared to traditional link degree metrics. We obtain insights into the
dynamics of topic participation on this network, as well as the relationship
between precursor/laggard and linking behaviors. We validate and analyze
results with the help of an expert on the French blogosphere. Finally, we
propose possible applications to the improvement of search engine ranking
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0143</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0143</id><created>2010-09-01</created><updated>2011-07-08</updated><authors><author><keyname>Chassaing</keyname><forenames>Philippe</forenames><affiliation>IECN</affiliation></author><author><keyname>Mairesse</keyname><forenames>Jean</forenames><affiliation>LIAFA</affiliation></author></authors><title>A non-ergodic probabilistic cellular automaton with a unique invariant
  measure</title><categories>cs.FL cs.DM math.PR</categories><comments>To appear in Stochastic Processes and their Applications</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit a Probabilistic Cellular Automaton (PCA) on the integers with an
alphabet and a neighborhood of size 2 which is non-ergodic although it has a
unique invariant measure. This answers by the negative an old open question on
whether uniqueness of the invariant measure implies ergodicity for a PCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0146</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0146</id><created>2010-09-01</created><authors><author><keyname>Chappelon</keyname><forenames>Jonathan</forenames><affiliation>LMPA</affiliation></author><author><keyname>Matsuura</keyname><forenames>Akihiro</forenames></author></authors><title>On generalized Frame-Stewart numbers</title><categories>math.NT cs.DM</categories><comments>13 pages, 3 figures</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the multi-peg Tower of Hanoi problem with $k \ge 4$ pegs, so far the best
solution is obtained by the Stewart's algorithm based on the the following
recurrence relation: $S_k(n) = \min_{1 \le t \le n} \{2 \cdot S_k(n-t) +
S_{k-1}(t) \}$, $S_3(n) = 2^n - 1$. In this paper, we generalize this
recurrence relation to $G_k(n) = \min_{1 \le t \le n} \{p_k \cdot G_k(n-t) +
q_k \cdot G_{k-1}(t) \}$, $G_3(n) = p_3 \cdot G_3(n-1) + q_3$, for two
sequences of arbitrary positive integers $(p_i)_{i \ge 3}$ and $(q_i)_{i \ge
3}$ and we show that the sequence of differences $(G_k(n)-G_k(n-1))_{n \ge 1}$
consists of numbers of the form $(\prod_{i=3}^{k}q_i) \cdot
(\prod_{i=3}^{k}{p_i}^{\alpha_i})$, with $\alpha_i \ge 0$ for all $i$, lined in
the increasing order. We also apply this result to analyze recurrence relations
for the Tower of Hanoi problems on several graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0148</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0148</id><created>2010-09-01</created><updated>2011-07-30</updated><authors><author><keyname>Gao</keyname><forenames>Xiao-Shan</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Yuan</keyname><forenames>Chun-Ming</forenames></author></authors><title>Intersection Theory in Differential Algebraic Geometry: Generic
  Intersections and the Differential Chow Form</title><categories>math.AG cs.SC</categories><comments>Although essentially the same, the new version contains many
  modifications</comments><msc-class>Primary 12H05, 14C05, Secondary 14C17, 14Q99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an intersection theory for generic differential polynomials is
presented. The intersection of an irreducible differential variety of dimension
$d$ and order $h$ with a generic differential hypersurface of order $s$ is
shown to be an irreducible variety of dimension $d-1$ and order $h+s$. As a
consequence, the dimension conjecture for generic differential polynomials is
proved. Based on the intersection theory, the Chow form for an irreducible
differential variety is defined and most of the properties of the Chow form in
the algebraic case are established for its differential counterpart.
Furthermore, the generalized differential Chow form is defined and its
properties are proved. As an application of the generalized differential Chow
form, the differential resultant of $n+1$ generic differential polynomials in
$n$ variables is defined and properties similar to that of the Macaulay
resultant for multivariate polynomials are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0152</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0152</id><created>2010-09-01</created><authors><author><keyname>Eden</keyname><forenames>Amnon H.</forenames></author><author><keyname>Gasparis</keyname><forenames>Epameinondas</forenames></author></authors><title>Three Controlled Experiments in Software Engineering with the Two-Tier
  Programming Toolkit: Final Report</title><categories>cs.SE</categories><comments>School of Computer Science &amp; Electronic Engineering, University of
  Essex (5 Jan. 2010); ISSN 1744-8050</comments><report-no>Technical Report CES-496</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Three controlled experiments testing the benefits that Java programmers gain
from using the Two-Tier Programming Toolkit have recently been concluded. The
first experiment offers statistically significant evidence (p-value: 0.02) that
programmers who undertook only minimal (1-hour) training in using the current
prototype exhibit 76% productivity gains in key tasks in software development
and maintenance. The second experiment shows that the use of the TTP Toolkit is
likely (p-value: 0.10) to almost triple the accuracy of programmers performing
tasks associated with software quality. The third experiment shows that the TTP
Toolkit does not offer significant productivity gains in performing very short
(under 10 min.) tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0193</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0193</id><created>2010-09-01</created><authors><author><keyname>Decreusefond</keyname><forenames>Laurent</forenames><affiliation>LTCI</affiliation></author><author><keyname>Martins</keyname><forenames>Philippe</forenames><affiliation>LTCI</affiliation></author><author><keyname>Vu</keyname><forenames>Than-Tung</forenames><affiliation>LTCI</affiliation></author></authors><title>An analytical model for evaluating outage and handover probability of
  cellular wireless networks</title><categories>math.PR cs.NI cs.PF</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider stochastic cellular networks where base stations locations form a
homogenous Poisson point process and each mobile is attached to the base
station that provides the best mean signal power. The mobile is in outage if
the SINR falls below some threshold. The handover decision has to be made if
the mobile is in outage for some time slots. The outage probability and the
handover probability is evaluated in taking into account the effect of path
loss, shadowing, Rayleigh fast fading, frequency factor reuse and conventional
beamforming. The main assumption is that the Rayleigh fast fading changes each
time slot while other network components remain static during the period of
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0216</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0216</id><created>2010-09-01</created><updated>2011-07-08</updated><authors><author><keyname>Belmonte</keyname><forenames>R&#xe9;my</forenames></author><author><keyname>Vatshelle</keyname><forenames>Martin</forenames></author></authors><title>On graph classes with logarithmic boolean-width</title><categories>cs.DM cs.DS</categories><comments>16 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boolean-width is a recently introduced graph parameter. Many problems are
fixed parameter tractable when parametrized by boolean-width, for instance
&quot;Minimum Weighted Dominating Set&quot; (MWDS) problem can be solved in $O^*(2^{3k})$
time given a boolean-decomposition of width $k$, hence for all graph classes
where a boolean-decomposition of width $O(\log n)$ can be found in polynomial
time, MWDS can be solved in polynomial time. We study graph classes having
boolean-width $O(\log n)$ and problems solvable in $O^*(2^{O(k)})$, combining
these two results to design polynomial algorithms. We show that for trapezoid
graphs, circular permutation graphs, convex graphs, Dilworth-$k$ graphs,
circular arc graphs and complements of $k$-degenerate graphs,
boolean-decompositions of width $O(\log n)$ can be found in polynomial time. We
also show that circular $k$-trapezoid graphs have boolean-width $O(\log n)$,
and find such a decomposition if a circular $k$-trapezoid intersection model is
given. For many of the graph classes we also prove that they contain graphs of
boolean-width $\Theta(\log n)$.
  Further we apply the results from \cite{boolw2} to give a new polynomial time
algorithm solving all vertex partitioning problems introduced by Proskurowski
and Telle \cite{TP97}. This extends previous results by Kratochv\'il, Manuel
and Miller \cite{KMM95} showing that a large subset of the vertex partitioning
problems are polynomial solvable on interval graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0240</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0240</id><created>2010-09-01</created><updated>2012-02-25</updated><authors><author><keyname>Pan</keyname><forenames>Wei</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Dong</keyname><forenames>Wen</forenames></author><author><keyname>Kim</keyname><forenames>Taemie</forenames></author><author><keyname>Fowler</keyname><forenames>James</forenames></author><author><keyname>Pentland</keyname><forenames>Alex</forenames></author></authors><title>Modeling Dynamical Influence in Human Interaction Patterns</title><categories>cs.SI physics.soc-ph</categories><comments>Signal Processing Magazine March 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How can we model influence between individuals in a social system, even when
the network of interactions is unknown? In this article, we review the
literature on the &quot;influence model,&quot; which utilizes independent time series to
estimate how much the state of one actor affects the state of another actor in
the system. We extend this model to incorporate dynamical parameters that allow
us to infer how influence changes over time, and we provide three examples of
how this model can be applied to simulated and real data. The results show that
the model can recover known estimates of influence, it generates results that
are consistent with other measures of social networks, and it allows us to
uncover important shifts in the way states may be transmitted between actors at
different points in time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0246</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0246</id><created>2010-09-01</created><authors><author><keyname>Mulmuley</keyname><forenames>Ketan</forenames></author></authors><title>Explicit Proofs and The Flip</title><categories>cs.CC</categories><comments>32 pages</comments><msc-class>97P70</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a formal strategy of geometric complexity theory (GCT)
to resolve the {\em self referential paradox} in the $P$ vs. $NP$ and related
problems. The strategy, called the {\em flip}, is to go for {\em explicit
proofs} of these problems. By an explicit proof we mean a proof that constructs
proof certificates of hardness that are easy to verify, construct and decode.
The main result in this paper says that (1) any proof of the arithmetic
implication of the $P$ vs. $NP$ conjecture is close to an explicit proof in the
sense that it can be transformed into an explicit proof by proving in addition
that arithmetic circuit identity testing can be derandomized in a blackbox
fashion, and (2) stronger forms of these arithmetic hardness and
derandomization conjectures together imply a polynomial time algorithm for a
formidable explicit construction problem in algebraic geometry. This may
explain why these conjectures, which look so elementary at the surface, have
turned out to be so hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0255</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0255</id><created>2010-09-01</created><authors><author><keyname>Rizzolo</keyname><forenames>Flavio</forenames></author><author><keyname>Kiringa</keyname><forenames>Iluju</forenames></author><author><keyname>Pottinger</keyname><forenames>Rachel</forenames></author><author><keyname>Wong</keyname><forenames>Kwok</forenames></author></authors><title>The Conceptual Integration Modeling Framework: Abstracting from the
  Multidimensional Model</title><categories>cs.DB</categories><comments>Technical report, 18 pages</comments><acm-class>H.2.1; H.2.3; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data warehouses are overwhelmingly built through a bottom-up process, which
starts with the identification of sources, continues with the extraction and
transformation of data from these sources, and then loads the data into a set
of data marts according to desired multidimensional relational schemas. End
user business intelligence tools are added on top of the materialized
multidimensional schemas to drive decision making in an organization.
Unfortunately, this bottom-up approach is costly both in terms of the skilled
users needed and the sheer size of the warehouses. This paper proposes a
top-down framework in which data warehousing is driven by a conceptual model.
The framework offers both design time and run time environments. At design
time, a business user first uses the conceptual modeling language as a
multidimensional object model to specify what business information is needed;
then she maps the conceptual model to a pre-existing logical multidimensional
representation. At run time, a system will transform the user conceptual model
together with the mappings into views over the logical multidimensional
representation. We focus on how the user can conceptually abstract from an
existing data warehouse, and on how this conceptual model can be mapped to the
logical multidimensional representation. We also give an indication of what
query language is used over the conceptual model. Finally, we argue that our
framework is a step along the way to allowing automatic generation of the data
warehouse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0267</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0267</id><created>2010-09-01</created><updated>2010-09-10</updated><authors><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Fragkiskos</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author></authors><title>Sustaining the Internet with Hyperbolic Mapping</title><categories>cs.NI cond-mat.dis-nn cond-mat.stat-mech cs.SI physics.soc-ph</categories><journal-ref>Nature Communications, v.1, p.62, 2010</journal-ref><doi>10.1038/ncomms1063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet infrastructure is severely stressed. Rapidly growing overheads
associated with the primary function of the Internet---routing information
packets between any two computers in the world---cause concerns among Internet
experts that the existing Internet routing architecture may not sustain even
another decade. Here we present a method to map the Internet to a hyperbolic
space. Guided with the constructed map, which we release with this paper,
Internet routing exhibits scaling properties close to theoretically best
possible, thus resolving serious scaling limitations that the Internet faces
today. Besides this immediate practical viability, our network mapping method
can provide a different perspective on the community structure in complex
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0278</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0278</id><created>2010-09-01</created><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Mitrokotsa</keyname><forenames>Aikaterini</forenames></author><author><keyname>Vaudenay</keyname><forenames>Serge</forenames></author></authors><title>Expected loss analysis of thresholded authentication protocols in noisy
  conditions</title><categories>cs.CR cs.NI</categories><comments>17 pages, 2 figures; draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of authentication protocols have been proposed recently, where at
least some part of the authentication is performed during a phase, lasting $n$
rounds, with no error correction. This requires assigning an acceptable
threshold for the number of detected errors. This paper describes a framework
enabling an expected loss analysis for all the protocols in this family.
Furthermore, computationally simple methods to obtain nearly optimal value of
the threshold, as well as for the number of rounds is suggested. Finally, a
method to adaptively select both the number of rounds and the threshold is
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0282</identifier>
 <datestamp>2012-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0282</id><created>2010-09-01</created><updated>2012-09-18</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Empirical processes, typical sequences and coordinated actions in
  standard Borel spaces</title><categories>cs.IT math.IT</categories><comments>14 pages, 3 pdf figures; accepted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new notion of typical sequences on a wide class of
abstract alphabets (so-called standard Borel spaces), which is based on
approximations of memoryless sources by empirical distributions uniformly over
a class of measurable &quot;test functions.&quot; In the finite-alphabet case, we can
take all uniformly bounded functions and recover the usual notion of strong
typicality (or typicality under the total variation distance). For a general
alphabet, however, this function class turns out to be too large, and must be
restricted. With this in mind, we define typicality with respect to any
Glivenko-Cantelli function class (i.e., a function class that admits a Uniform
Law of Large Numbers) and demonstrate its power by giving simple derivations of
the fundamental limits on the achievable rates in several source coding
scenarios, in which the relevant operational criteria pertain to reproducing
empirical averages of a general-alphabet stationary memoryless source with
respect to a suitable function class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0289</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0289</id><created>2010-09-01</created><updated>2010-10-14</updated><authors><author><keyname>S&#xe1;nchez-Moreno</keyname><forenames>P.</forenames></author><author><keyname>Manzano</keyname><forenames>D.</forenames></author><author><keyname>Dehesa</keyname><forenames>J. S.</forenames></author></authors><title>Direct spreading measures of Laguerre polynomials</title><categories>math-ph cs.IT math.IT math.MP quant-ph</categories><comments>15 pages, 5 figures, accepted in Journal of Computational and Applied
  Mathematics</comments><journal-ref>Journal of Computational and Applied Mathematics, 235 (2011) 1129</journal-ref><doi>10.1016/j.cam.2010.07.022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The direct spreading measures of the Laguerre polynomials, which quantify the
distribution of its Rakhmanov probability density along the positive real line
in various complementary and qualitatively different ways, are investigated.
These measures include the familiar root-mean-square or standard deviation and
the information-theoretic lengths of Fisher, Renyi and Shannon types. The
Fisher length is explicitly given. The Renyi length of order q (such that 2q is
a natural number) is also found in terms of the polynomials parameters by means
of two error-free computing approaches; one makes use of the Lauricella
functions, which is based on the Srivastava-Niukkanen linearization relation of
Laguerre polynomials, and another one which utilizes the multivariate Bell
polynomials of Combinatorics. The Shannon length cannot be exactly calculated
because of its logarithmic-functional form, but its asymptotics is provided and
sharp bounds are obtained by use of an information-theoretic optimization
procedure. Finally, all these spreading measures are mutually compared and
computationally analyzed; in particular, it is found that the apparent
quasi-linear relation between the Shannon length and the standard deviation
becomes rigorously linear only asymptotically (i.e. for n&gt;&gt;1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0300</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0300</id><created>2010-08-31</created><authors><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Slinko</keyname><forenames>Arkadii</forenames></author></authors><title>Rationalizations of Condorcet-Consistent Rules via Distances of Hamming
  Type</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main idea of the {\em distance rationalizability} approach to view the
voters' preferences as an imperfect approximation to some kind of consensus is
deeply rooted in social choice literature. It allows one to define
(&quot;rationalize&quot;) voting rules via a consensus class of elections and a distance:
a candidate is said to be an election winner if she is ranked first in one of
the nearest (with respect to the given distance) consensus elections. It is
known that many classic voting rules can be distance rationalized. In this
paper, we provide new results on distance rationalizability of several
Condorcet-consistent voting rules. In particular, we distance rationalize
Young's rule and Maximin rule using distances similar to the Hamming distance.
We show that the claim that Young's rule can be rationalized by the Condorcet
consensus class and the Hamming distance is incorrect; in fact, these consensus
class and distance yield a new rule which has not been studied before. We prove
that, similarly to Young's rule, this new rule has a computationally hard
winner determination problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0304</identifier>
 <datestamp>2011-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0304</id><created>2010-09-01</created><updated>2011-10-24</updated><authors><author><keyname>Huang</keyname><forenames>Yu-Chih</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Joint Source-Channel Coding with Correlated Interference</title><categories>cs.IT math.IT</categories><comments>31 pages, 15 figures, corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the joint source-channel coding problem of transmitting a
discrete-time analog source over an additive white Gaussian noise (AWGN)
channel with interference known at transmitter.We consider the case when the
source and the interference are correlated. We first derive an outer bound on
the achievable distortion and then, we propose two joint source-channel coding
schemes. The first scheme is the superposition of the uncoded signal and a
digital part which is the concatenation of a Wyner-Ziv encoder and a dirty
paper encoder. In the second scheme, the digital part is replaced by the hybrid
digital and analog scheme proposed by Wilson et al. When the channel
signal-tonoise ratio (SNR) is perfectly known at the transmitter, both proposed
schemes are shown to provide identical performance which is substantially
better than that of existing schemes. In the presence of an SNR mismatch, both
proposed schemes are shown to be capable of graceful enhancement and graceful
degradation. Interestingly, unlike the case when the source and interference
are independent, neither of the two schemes outperforms the other universally.
As an application of the proposed schemes, we provide both inner and outer
bounds on the distortion region for the generalized cognitive radio channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0305</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0305</id><created>2010-09-01</created><authors><author><keyname>Rabah</keyname><forenames>Sleiman</forenames></author><author><keyname>Li</keyname><forenames>Jiang</forenames></author><author><keyname>Liu</keyname><forenames>Mingzhi</forenames></author><author><keyname>Lai</keyname><forenames>Yuanwei</forenames></author></authors><title>Comparative Studies of 10 Programming Languages within 10 Diverse
  Criteria -- a Team 7 COMP6411-S10 Term Report</title><categories>cs.PL</categories><comments>139 pages, programming languages comparison tables</comments><acm-class>D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many programming languages in the world today.Each language has
their advantage and disavantage. In this paper, we will discuss ten programming
languages: C++, C#, Java, Groovy, JavaScript, PHP, Schalar, Scheme, Haskell and
AspectJ. We summarize and compare these ten languages on ten different
criterion. For example, Default more secure programming practices, Web
applications development, OO-based abstraction and etc. At the end, we will
give our conclusion that which languages are suitable and which are not for
using in some cases. We will also provide evidence and our analysis on why some
language are better than other or have advantages over the other on some
criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0306</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0306</id><created>2010-09-01</created><authors><author><keyname>Liu</keyname><forenames>Jun</forenames></author><author><keyname>Ye</keyname><forenames>Jieping</forenames></author></authors><title>Fast Overlapping Group Lasso</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The group Lasso is an extension of the Lasso for feature selection on
(predefined) non-overlapping groups of features. The non-overlapping group
structure limits its applicability in practice. There have been several recent
attempts to study a more general formulation, where groups of features are
given, potentially with overlaps between the groups. The resulting optimization
is, however, much more challenging to solve due to the group overlaps. In this
paper, we consider the efficient optimization of the overlapping group Lasso
penalized problem. We reveal several key properties of the proximal operator
associated with the overlapping group Lasso, and compute the proximal operator
by solving the smooth and convex dual problem, which allows the use of the
gradient descent type of algorithms for the optimization. We have performed
empirical evaluations using the breast cancer gene expression data set, which
consists of 8,141 genes organized into (overlapping) gene sets. Experimental
results demonstrate the efficiency and effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0309</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0309</id><created>2010-09-01</created><authors><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>A Complexity View of Markets with Social Influence</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, inspired by the work of Megiddo on the formation of
preferences and strategic analysis, we consider an early market model studied
in the field of economic theory, in which each trader's utility may be
influenced by the bundles of goods obtained by her social neighbors. The goal
of this paper is to understand and characterize the impact of social influence
on the complexity of computing and approximating market equilibria.
  We present complexity-theoretic and algorithmic results for approximating
market equilibria in this model with focus on two concrete influence models
based on the traditional linear utility functions. Recall that an Arrow-Debreu
market equilibrium in a conventional exchange market with linear utility
functions can be computed in polynomial time by convex programming. Our
complexity results show that even a bounded-degree, planar influence network
can significantly increase the difficulty of equilibrium computation even in
markets with only a constant number of goods. Our algorithmic results suggest
that finding an approximate equilibrium in markets with hierarchical influence
networks might be easier than that in markets with arbitrary neighborhood
structures. By demonstrating a simple market with a constant number of goods
and a bounded-degree, planar influence graph whose equilibrium is PPAD-hard to
approximate, we also provide a counterexample to a common belief, which we
refer to as the myth of a constant number of goods, that equilibria in markets
with a constant number of goods are easy to compute or easy to approximate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0343</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0343</id><created>2010-09-02</created><authors><author><keyname>DeVos</keyname><forenames>Matt</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>Edge Growth in Graph Cubes</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for every connected graph $G$ of diameter $\ge 3$, the graph
$G^3$ has average degree $\ge 7/4 \delta(G)$. We also provide an example
showing that this bound is best possible. This resolves a question of Hegarty
\cite{PH}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0347</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0347</id><created>2010-09-02</created><authors><author><keyname>Schutt</keyname><forenames>Andreas</forenames></author><author><keyname>Feydy</keyname><forenames>Thibaut</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author><author><keyname>Wallace</keyname><forenames>Mark G.</forenames></author></authors><title>Solving the Resource Constrained Project Scheduling Problem with
  Generalized Precedences by Lazy Clause Generation</title><categories>cs.AI</categories><comments>37 pages, 3 figures, 16 tables</comments><acm-class>G.1.6, F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The technical report presents a generic exact solution approach for
minimizing the project duration of the resource-constrained project scheduling
problem with generalized precedences (Rcpsp/max). The approach uses lazy clause
generation, i.e., a hybrid of finite domain and Boolean satisfiability solving,
in order to apply nogood learning and conflict-driven search on the solution
generation. Our experiments show the benefit of lazy clause generation for
finding an optimal solutions and proving its optimality in comparison to other
state-of-the-art exact and non-exact methods. The method is highly robust: it
matched or bettered the best known results on all of the 2340 instances we
examined except 3, according to the currently available data on the PSPLib. Of
the 631 open instances in this set it closed 573 and improved the bounds of 51
of the remaining 58 instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0358</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0358</id><created>2010-09-02</created><authors><author><keyname>Feder</keyname><forenames>Tom&#xe1;s</forenames></author><author><keyname>Hell</keyname><forenames>Pavol</forenames></author><author><keyname>Schell</keyname><forenames>David G.</forenames></author><author><keyname>Stacho</keyname><forenames>Juraj</forenames></author></authors><title>Dichotomy for tree-structured trigraph list homomorphism problems</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trigraph list homomorphism problems (also known as list matrix partition
problems) have generated recent interest, partly because there are concrete
problems that are not known to be polynomial time solvable or NP-complete. Thus
while digraph list homomorphism problems enjoy dichotomy (each problem is
NP-complete or polynomial time solvable), such dichotomy is not necessarily
expected for trigraph list homomorphism problems. However, in this paper, we
identify a large class of trigraphs for which list homomorphism problems do
exhibit a dichotomy. They consist of trigraphs with a tree-like structure, and,
in particular, include all trigraphs whose underlying graphs are trees. In
fact, we show that for these tree-like trigraphs, the trigraph list
homomorphism problem is polynomially equivalent to a related digraph list
homomorphism problem. We also describe a few examples illustrating that our
conditions defining tree-like trigraphs are not unnatural, as relaxing them may
lead to harder problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0368</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0368</id><created>2010-09-02</created><authors><author><keyname>Rawat</keyname><forenames>Sandeep Singh</forenames></author><author><keyname>Rajamani</keyname><forenames>Lakshmi</forenames></author></authors><title>Discovering potential user browsing behaviors using custom-built apriori
  algorithm</title><categories>cs.DB</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the organizations put information on the web because they want it to
be seen by the world. Their goal is to have visitors come to the site, feel
comfortable and stay a while and try to know completely about the running
organization. As educational system increasingly requires data mining, the
opportunity arises to mine the resulting large amounts of student information
for hidden useful information (patterns like rule, clustering, and
classification, etc). The education domain offers ground for many interesting
and challenging data mining applications like astronomy, chemistry,
engineering, climate studies, geology, oceanography, ecology, physics, biology,
health sciences and computer science. Collecting the interesting patterns using
the required interestingness measures, which help us in discovering the
sophisticated patterns that are ultimately used for developing the site. We
study the application of data mining to educational log data collected from
Guru Nanak Institute of Technology, Ibrahimpatnam, India. We have proposed a
custom-built apriori algorithm to find the effective pattern analysis. Finally,
analyzing web logs for usage and access trends can not only provide important
information to web site developers and administrators, but also help in
creating adaptive web sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0373</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0373</id><created>2010-09-02</created><authors><author><keyname>Ilyevsky</keyname><forenames>V. I.</forenames></author></authors><title>The concept of an order and its application for research of the
  deterministic chains of symbols</title><categories>cs.IT math.IT physics.bio-ph</categories><comments>23 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work is dedicated to searching parameters, alternative to
entropy, applicable for description of highly organized systems. The general
concept has been offered, in which the system complexity and order are
functions of the order establishment rules. The concept of order poles has been
introduced. The concept is being applied to definition of the order parameter
(OP) for non-random sequences with equal number of zeros and ones. Properties
of the OP are being studied. Definition of the OP is being compared to
classical definition of amount of information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0377</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0377</id><created>2010-09-02</created><authors><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author><author><keyname>Naik</keyname><forenames>Siddharth</forenames></author></authors><title>A Unified Mechanism Design Framework for Networked Systems</title><categories>cs.GT cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mechanisms such as auctions and pricing schemes are utilized to design
strategic (noncooperative) games for networked systems. Although the
participating players are selfish, these mechanisms ensure that the game
outcome is optimal with respect to a global criterion (e.g. maximizing a social
welfare function), preference-compatible, and strategy-proof, i.e. players have
no reason to deceive the designer. The mechanism designer achieves these
objectives by introducing specific rules and incentives to the players; in this
case by adding resource prices to their utilities. In auction-based mechanisms,
the mechanism designer explicitly allocates the resources based on bids of the
participants in addition to setting prices. Alternatively, pricing mechanisms
enforce global objectives only by charging the players for the resources they
have utilized. In either setting, the player preferences represented by utility
functions may be coupled or decoupled, i.e. they depend on other player's
actions or only on player's own actions, respectively. The unified framework
and its information structures are illustrated through multiple example
resource allocation problems from wireless and wired networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0384</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0384</id><created>2010-09-02</created><authors><author><keyname>Sembiring</keyname><forenames>Rahmat Widia</forenames></author><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author><author><keyname>Embong</keyname><forenames>Abdullah</forenames></author></authors><title>Clustering high dimensional data using subspace and projected clustering
  algorithms</title><categories>cs.DB</categories><comments>9 pages, 6 figures</comments><msc-class>68-02</msc-class><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT) Vol.2, No.4, August 2010, p.162-170</journal-ref><doi>10.5121/ijcsit.2010.2414</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Problem statement: Clustering has a number of techniques that have been
developed in statistics, pattern recognition, data mining, and other fields.
Subspace clustering enumerates clusters of objects in all subspaces of a
dataset. It tends to produce many over lapping clusters. Approach: Subspace
clustering and projected clustering are research areas for clustering in high
dimensional spaces. In this research we experiment three clustering oriented
algorithms, PROCLUS, P3C and STATPC. Results: In general, PROCLUS performs
better in terms of time of calculation and produced the least number of
un-clustered data while STATPC outperforms PROCLUS and P3C in the accuracy of
both cluster points and relevant attributes found. Conclusions/Recommendations:
In this study, we analyze in detail the properties of different data clustering
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0386</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0386</id><created>2010-09-02</created><authors><author><keyname>Al-Bahadili</keyname><forenames>Hussein</forenames></author><author><keyname>Kaabneh</keyname><forenames>Khalid</forenames></author></authors><title>Analyzing the performance of probabilistic algorithm in noisy manets</title><categories>cs.NI cs.PF</categories><comments>13 Pages, 13 Figures, Journal</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN),
  Vol.2, No.3, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic broadcast has been widely used as a flooding optimization
mechanism to alleviate the effect of broadcast storm problem (BSP) in mobile ad
hoc networks (MANETs). Many research studies have been carried-out to develop
and evaluate the performance of this mechanism in an error-free (noiseless)
environment. In reality, wireless communication channels in MANETs are an
error-prone and suffer from high packet-loss due to presence of noise, i.e.,
noisy environment. In this paper, we propose a simulation model that can be
used to evaluate the performance of probabilistic broadcast for flooding in
noisy environment. In the proposed model, the noise-level is represented by a
generic name, probability of reception (pc) (0&lt;=pc&lt;=1), where pc=1 for
noiseless and &lt;1 for noisy environment. The effect of noise is determined
randomly by generating a random number \zeta (0&lt;=\zeta&lt;1); if \zeta&lt;=pc means
the packet is successfully delivered to the receiving node, otherwise,
unsuccessful delivery occurs. The proposed model is implemented on a MANET
simulator, namely, MANSim. The effect of noise on the performance of
probabilistic algorithm was investigated in four scenarios. The main
conclusions of these scenarios are: the performance of probabilistic algorithm
suffers in presence of noise. However, this suffering is less in high density
networks, or if the nodes characterized by high retransmission probability or
large radio transmission range. The nodes' speed has no or insignificant effect
on the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0389</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0389</id><created>2010-09-02</created><authors><author><keyname>Al-Bahadili</keyname><forenames>Hussein</forenames></author><author><keyname>Jaradat</keyname><forenames>Rami</forenames></author></authors><title>Performance Evaluation of an OMPR Algorithm for Route Discovery in Noisy
  MANETs</title><categories>cs.NI cs.PF</categories><comments>12 Pages, 8 Figures, 1 Table, Journal</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol. 2, No. 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been revealed in the literature that pure multipoint relaying (MPR)
algorithms demonstrate both simplicity and outstanding performance, as compared
to other flooding algorithms in wireless networks. One drawback of pure MPR
algorithms is that the selected forwarding set may not represent the optimum
selection. In addition, little efforts have been carried-out to investigate the
performance of such algorithms in noisy mobile ad hoc networks (MANETs)
suffering from high packet-loss and node mobility. In this paper, we develop
and evaluate the performance of an optimal MPR (OMPR) algorithm for route
discovery in noisy MANETs. The main feature of this new algorithm is that it
calculates all possible sets of multipoint relays (MPRs) and then selects the
set with minimum number of nodes. The algorithm demonstrates an excellent
performance when it is compared with other route discovery algorithms as it
achieves the highest cost-effective reachability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0390</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0390</id><created>2010-09-02</created><updated>2010-09-09</updated><authors><author><keyname>Nawaz</keyname><forenames>Khalid</forenames></author><author><keyname>Buchmann</keyname><forenames>Alejandro P.</forenames></author></authors><title>Acdmcp: An adaptive and completely distributed multi-hop clustering
  protocol for wireless sensor networks</title><categories>cs.NI cs.DC</categories><acm-class>C.2.1</acm-class><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN),
  ISSN:0975-3834, 0975-4679, Academy &amp; Industry Research Collaboration Center
  (AIRCC), August 2010</journal-ref><doi>10.5121/ijwmn.2010.2302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering is a very popular network structuring technique which mainly
addresses the issue of scalability in large scale Wireless Sensor Networks.
Additionally, it has been shown to improve the energy efficiency and prolong
the life of the network. The suggested protocols mostly base their clustering
criteria on some grouping attribute(s) of the nodes. One important attribute
that is largely ignored by most of the existing multi-hop clustering protocols
is the reliability of the communication links between the nodes. In this paper,
we suggest an adaptive and completely distributed multi-hop clustering protocol
that incorporates different notions of reliability of the communication links,
among other things, into a composite metric and uses it in all phases of the
clustering process. The joining criteria for the nodes, which lie at one hop
from the elected cluster heads, to a particular cluster not only consider the
reliability of their communication link with their cluster head but also other
important attributes. The nodes that lie outside the communication range of
cluster heads become cluster members transitively through existing cluster
members utilizing the end-to-end notion of link reliability, between the nodes
and the cluster heads, along with other important attributes. Similarly,
inter-cluster communication paths are selected using a set of criteria that
includes the end-to-end communication link reliability with the sink node along
with other important node and network attributes. We believe that incorporating
link reliability in all phases of clustering process results in an efficient
multi-hop communication hierarchy that has the potential of bringing down the
total communication costs in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0396</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0396</id><created>2010-09-02</created><updated>2012-03-14</updated><authors><author><keyname>Karahanoglu</keyname><forenames>Nazim Burak</forenames></author><author><keyname>Erdogan</keyname><forenames>Hakan</forenames></author></authors><title>A* Orthogonal Matching Pursuit: Best-First Search for Compressed Sensing
  Signal Recovery</title><categories>cs.IT math.IT</categories><comments>accepted for publication in Digital Signal Processing</comments><journal-ref>Digital Signal Processing, Volume 22, Issue 4, 2012, Pages 555-568</journal-ref><doi>10.1016/j.dsp.2012.03.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a developing field aiming at reconstruction of sparse
signals acquired in reduced dimensions, which make the recovery process
under-determined. The required solution is the one with minimum $\ell_0$ norm
due to sparsity, however it is not practical to solve the $\ell_0$ minimization
problem. Commonly used techniques include $\ell_1$ minimization, such as Basis
Pursuit (BP) and greedy pursuit algorithms such as Orthogonal Matching Pursuit
(OMP) and Subspace Pursuit (SP). This manuscript proposes a novel semi-greedy
recovery approach, namely A* Orthogonal Matching Pursuit (A*OMP). A*OMP
performs A* search to look for the sparsest solution on a tree whose paths grow
similar to the Orthogonal Matching Pursuit (OMP) algorithm. Paths on the tree
are evaluated according to a cost function, which should compensate for
different path lengths. For this purpose, three different auxiliary structures
are defined, including novel dynamic ones. A*OMP also incorporates pruning
techniques which enable practical applications of the algorithm. Moreover, the
adjustable search parameters provide means for a complexity-accuracy trade-off.
We demonstrate the reconstruction ability of the proposed scheme on both
synthetically generated data and images using Gaussian and Bernoulli
observation matrices, where A*OMP yields less reconstruction error and higher
exact recovery frequency than BP, OMP and SP. Results also indicate that novel
dynamic cost functions provide improved results as compared to a conventional
choice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0397</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0397</id><created>2010-09-02</created><authors><author><keyname>oueslati</keyname><forenames>wided</forenames></author><author><keyname>akaichi</keyname><forenames>jalel</forenames></author></authors><title>Mobile Information Collectors' Trajectory Data Warehouse Design</title><categories>cs.DB</categories><comments>20 pages, 9 figures</comments><journal-ref>international journal of managing information technology august
  2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  To analyze complex phenomena which involve moving objects, Trajectory Data
Warehouse (TDW) seems to be an answer for many recent decision problems related
to various professions (physicians, commercial representatives, transporters,
ecologists ...) concerned with mobility. This work aims to make trajectories as
a first class concept in the trajectory data conceptual model and to design a
TDW, in which data resulting from mobile information collectors' trajectory are
gathered. These data will be analyzed, according to trajectory characteristics,
for decision making purposes, such as new products commercialization, new
commerce implementation, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0402</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0402</id><created>2010-09-02</created><authors><author><keyname>Kayri</keyname><forenames>Murat</forenames></author><author><keyname>Cakir</keyname><forenames>Ozlem</forenames></author></authors><title>An Applied Study on Educational Use of Facebook as a Web 2.0 Tool: The
  Sample Lesson of Computer Networks and Communication</title><categories>cs.SI</categories><comments>11 pages</comments><doi>10.5121/ijcsit.2010.2405</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main aim of the research was to examine educational use of Facebook. The
Computer Networks and Communication lesson was taken as the sample and the
attitudes of the students included in the study group towards Facebook were
measured in a semi-experimental setup. The students on Facebook platform were
examined for about three months and they continued their education
interactively in that virtual environment. After the-three-month-education
period, observations for the students were reported and the attitudes of the
students towards Facebook were measured by three different measurement tools.
As a result, the attitudes of the students towards educational use of Facebook
and their views were heterogeneous. When the average values of the group were
examined, it was reported that the attitudes towards educational use of
Facebook was above a moderate level. Therefore, it might be suggested that
social networks in virtual environments provide continuity in life long
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0407</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0407</id><created>2010-09-02</created><authors><author><keyname>Balafoutis</keyname><forenames>Thanasis</forenames></author><author><keyname>Paparrizou</keyname><forenames>Anastasia</forenames></author><author><keyname>Stergiou</keyname><forenames>Kostas</forenames></author></authors><title>Experimental Evaluation of Branching Schemes for the CSP</title><categories>cs.AI</categories><comments>To appear in the 3rd workshop on techniques for implementing
  constraint programming systems (TRICS workshop at the 16th CP Conference),
  St. Andrews, Scotland 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search strategy of a CP solver is determined by the variable and value
ordering heuristics it employs and by the branching scheme it follows. Although
the effects of variable and value ordering heuristics on search effort have
been widely studied, the effects of different branching schemes have received
less attention. In this paper we study this effect through an experimental
evaluation that includes standard branching schemes such as 2-way, d-way, and
dichotomic domain splitting, as well as variations of set branching where
branching is performed on sets of values. We also propose and evaluate a
generic approach to set branching where the partition of a domain into sets is
created using the scores assigned to values by a value ordering heuristic, and
a clustering algorithm from machine learning. Experimental results demonstrate
that although exponential differences between branching schemes, as predicted
in theory between 2-way and d-way branching, are not very common, still the
choice of branching scheme can make quite a difference on certain classes of
problems. Set branching methods are very competitive with 2-way branching and
outperform it on some problem classes. A statistical analysis of the results
reveals that our generic clustering-based set branching method is the best
among the methods compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0416</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0416</id><created>2010-09-02</created><authors><author><keyname>Iwama</keyname><forenames>Kazuo</forenames></author><author><keyname>Nishimura</keyname><forenames>Harumichi</forenames></author><author><keyname>Raymond</keyname><forenames>Rudy</forenames></author><author><keyname>Teruyama</keyname><forenames>Junichi</forenames></author></authors><title>Quantum Counterfeit Coin Problems</title><categories>quant-ph cs.CC cs.DM</categories><comments>18 pages</comments><journal-ref>Theor. Comput. Sci. 456 (2012) 51-64</journal-ref><doi>10.1016/j.tcs.2012.05.039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The counterfeit coin problem requires us to find all false coins from a given
bunch of coins using a balance scale. We assume that the balance scale gives us
only ``balanced'' or ``tilted'' information and that we know the number k of
false coins in advance. The balance scale can be modeled by a certain type of
oracle and its query complexity is a measure for the cost of weighing
algorithms (the number of weighings). In this paper, we study the quantum query
complexity for this problem. Let Q(k,N) be the quantum query complexity of
finding all k false coins from the N given coins. We show that for any k and N
such that k &lt; N/2, Q(k,N)=O(k^{1/4}), contrasting with the classical query
complexity, \Omega(k\log(N/k)), that depends on N. So our quantum algorithm
achieves a quartic speed-up for this problem. We do not have a matching lower
bound, but we show some evidence that the upper bound is tight: any algorithm,
including our algorithm, that satisfies certain properties needs
\Omega(k^{1/4}) queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0425</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0425</id><created>2010-09-02</created><authors><author><keyname>Liu</keyname><forenames>Yuan</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Li</keyname><forenames>Bin</forenames></author><author><keyname>Shen</keyname><forenames>Hui</forenames></author></authors><title>Optimization Framework and Graph-Based Approach for Relay-Assisted
  Bidirectional OFDMA Cellular Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>27 pages, 8 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a relay-assisted bidirectional cellular network where
the base station (BS) communicates with each mobile station (MS) using OFDMA
for both uplink and downlink. The goal is to improve the overall system
performance by exploring the full potential of the network in various
dimensions including user, subcarrier, relay, and bidirectional traffic. In
this work, we first introduce a novel three-time-slot time-division duplexing
(TDD) transmission protocol. This protocol unifies direct transmission, one-way
relaying and network-coded two-way relaying between the BS and each MS. Using
the proposed three-time-slot TDD protocol, we then propose an optimization
framework for resource allocation to achieve the following gains: cooperative
diversity (via relay selection), network coding gain (via bidirectional
transmission mode selection), and multiuser diversity (via subcarrier
assignment). We formulate the problem as a combinatorial optimization problem,
which is NP-complete. To make it more tractable, we adopt a graph-based
approach. We first establish the equivalence between the original problem and a
maximum weighted clique problem in graph theory. A metaheuristic algorithm
based on any colony optimization (ACO) is then employed to find the solution in
polynomial time. Simulation results demonstrate that the proposed protocol
together with the ACO algorithm significantly enhances the system total
throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0433</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0433</id><created>2010-09-02</created><authors><author><keyname>Dixit</keyname><forenames>Dipa</forenames></author><author><keyname>Gadge</keyname><forenames>Jayant</forenames></author></authors><title>Automatic Recommendation for Online Users Using Web Usage Mining</title><categories>cs.IR cs.HC</categories><comments>10 PAGES Paper of web usage mining;
  http://airccse.org/journal/ijmit/jmit_current10.html)</comments><journal-ref>IJMIT Journal August 2010, Volume 2, Number 3</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A real world challenging task of the web master of an organization is to
match the needs of user and keep their attention in their web site. So, only
option is to capture the intuition of the user and provide them with the
recommendation list. Most specifically, an online navigation behavior grows
with each passing day, thus extracting information intelligently from it is a
difficult issue. Web master should use web usage mining method to capture
intuition. A WUM is designed to operate on web server logs which contain user's
navigation. Hence, recommendation system using WUM can be used to forecast the
navigation pattern of user and recommend those to user in a form of
recommendation list. In this paper, we propose a two tier architecture for
capturing users intuition in the form of recommendation list containing pages
visited by user and pages visited by other user's having similar usage profile.
The practical implementation of proposed architecture and algorithm shows that
accuracy of user intuition capturing is improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0448</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0448</id><created>2010-09-02</created><updated>2010-09-03</updated><authors><author><keyname>Sunny</keyname><forenames>Albert</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author><author><keyname>Aggarwal</keyname><forenames>Saurabh</forenames></author></authors><title>Delay Modelling for a Single-hop Wireless Mesh Network under Light
  Aggregate Traffic</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of modelling the average delay in an
IEEE 802.11 DCF wireless mesh network with a single root node under light
traffic. We derive expression for mean delay for a co-located wireless mesh
network, when packet generation is homogeneous Poisson process with rate
\lambda. We also show how our analysis can be extended for non-homogeneous
Poisson packet generation. We model mean delay by decoupling queues into
independent M/M/1 queues. Extensive simulations are conducted to verify the
analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0451</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0451</id><created>2010-09-02</created><authors><author><keyname>Tenc&#xe9;</keyname><forenames>Fabien</forenames><affiliation>LISYC</affiliation></author><author><keyname>Buche</keyname><forenames>C&#xe9;dric</forenames><affiliation>LISYC</affiliation></author><author><keyname>De Loor</keyname><forenames>Pierre</forenames><affiliation>LISYC</affiliation></author><author><keyname>Marc</keyname><forenames>Olivier</forenames><affiliation>LISYC</affiliation></author></authors><title>The Challenge of Believability in Video Games: Definitions, Agents
  Models and Imitation Learning</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>GAMEON-ASIA'2010, France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of creating believable agents (virtual
characters) in video games. We consider only one meaning of believability,
``giving the feeling of being controlled by a player'', and outline the problem
of its evaluation. We present several models for agents in games which can
produce believable behaviours, both from industry and research. For high level
of believability, learning and especially imitation learning seems to be the
way to go. We make a quick overview of different approaches to make video
games' agents learn from players. To conclude we propose a two-step method to
develop new models for believable agents. First we must find the criteria for
believability for our application and define an evaluation method. Then the
model and the learning algorithm can be designed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0471</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0471</id><created>2010-09-02</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Sanchez</keyname><forenames>Juan R.</forenames></author></authors><title>Complexity and Stochastic Synchronization in Coupled Map Lattices and
  Cellular Automata</title><categories>nlin.CD cs.IT math.IT physics.comp-ph</categories><comments>21 pages, 13 figures, 1 table; Chapter to appear in the Free Book
  &quot;Stochastic Control&quot;, Ed. Sciyo.com, Setember 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays the question `what is complexity?' is a challenge to be answered.
This question is triggering a great quantity of works in the frontier of
physics, biology, mathematics and computer science. Even more when this century
has been told to be the century of Complexity. Although there seems to be no
urgency to answer the above question, many different proposals that have been
developed to this respect can be found in the literature. In this context,
several articles concerning statistical complexity and stochastic processes are
collected in this chapter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0498</identifier>
 <datestamp>2014-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0498</id><created>2010-09-02</created><updated>2014-01-02</updated><authors><author><keyname>Haddouchi</keyname><forenames>Faouzi</forenames></author></authors><title>One side invertibility for implicit hyperbolic systems with delays</title><categories>math.OC cs.SY</categories><comments>Paper presented at the conference&quot; The 3rd International IEEE
  Scientific Conference on Physics and Control (PhysCon 2007), September
  3rd-7th 2007 at the University of Potsdam, Germany. Abstract available at
  http://opus.kobv.de/ubp/volltexte/2007/1522/ ; Full paper available at IPACS
  Electronic library http://lib.physcon.ru/</comments><msc-class>93C15, 93C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with left invertibility problem of implicit hyperbolic
systems with delays in infinite dimensional Hilbert spaces. From a
decomposition procedure, invertibility for this class of systems is shown to be
equivalent to the left invertibility of a subsystem without delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0499</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0499</id><created>2010-09-02</created><authors><author><keyname>Seldin</keyname><forenames>Yevgeny</forenames></author></authors><title>A PAC-Bayesian Analysis of Graph Clustering and Pairwise Clustering</title><categories>cs.LG cs.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate weighted graph clustering as a prediction problem: given a
subset of edge weights we analyze the ability of graph clustering to predict
the remaining edge weights. This formulation enables practical and theoretical
comparison of different approaches to graph clustering as well as comparison of
graph clustering with other possible ways to model the graph. We adapt the
PAC-Bayesian analysis of co-clustering (Seldin and Tishby, 2008; Seldin, 2009)
to derive a PAC-Bayesian generalization bound for graph clustering. The bound
shows that graph clustering should optimize a trade-off between empirical data
fit and the mutual information that clusters preserve on the graph nodes. A
similar trade-off derived from information-theoretic considerations was already
shown to produce state-of-the-art results in practice (Slonim et al., 2005;
Yom-Tov and Slonim, 2009). This paper supports the empirical evidence by
providing a better theoretical foundation, suggesting formal generalization
guarantees, and offering a more accurate way to deal with finite sample issues.
We derive a bound minimization algorithm and show that it provides good results
in real-life problems and that the derived PAC-Bayesian bound is reasonably
tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0501</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0501</id><created>2010-09-02</created><authors><author><keyname>Tenc&#xe9;</keyname><forenames>Fabien</forenames><affiliation>LISYC</affiliation></author><author><keyname>Buche</keyname><forenames>C&#xe9;dric</forenames><affiliation>LISYC</affiliation></author></authors><title>Automatable Evaluation Method Oriented toward Behaviour Believability
  for Video Games</title><categories>cs.AI</categories><comments>GAME-ON 2008, France (2008)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classic evaluation methods of believable agents are time-consuming because
they involve many human to judge agents. They are well suited to validate work
on new believable behaviours models. However, during the implementation,
numerous experiments can help to improve agents' believability. We propose a
method which aim at assessing how much an agent's behaviour looks like humans'
behaviours. By representing behaviours with vectors, we can store data computed
for humans and then evaluate as many agents as needed without further need of
humans. We present a test experiment which shows that even a simple evaluation
following our method can reveal differences between quite believable agents and
humans. This method seems promising although, as shown in our experiment,
results' analysis can be difficult.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0513</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0513</id><created>2010-09-02</created><updated>2010-09-03</updated><authors><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Wang</keyname><forenames>Jinlong</forenames></author><author><keyname>Zhu</keyname><forenames>Xiaodan</forenames></author></authors><title>Dynamically generated cyclic dominance in spatial prisoner's dilemma
  games</title><categories>physics.soc-ph cond-mat.stat-mech cs.GT</categories><comments>7 pages, 6 figures, accepted for publication in Physical Review E</comments><journal-ref>Physical Review E 82 (2010) 036110</journal-ref><doi>10.1103/PhysRevE.82.036110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have studied the impact of time-dependent learning capacities of players
in the framework of spatial prisoner's dilemma game. In our model, this
capacity of players may decrease or increase in time after strategy adoption
according to a step-like function. We investigated both possibilities
separately and observed significantly different mechanisms that form the
stationary pattern of the system. The time decreasing learning activity helps
cooperator domains to recover the possible intrude of defectors hence supports
cooperation. In the other case the temporary restrained learning activity
generates a cyclic dominance between defector and cooperator strategies, which
helps to maintain the diversity of strategies via propagating waves. The
results are robust and remain valid by changing payoff values, interaction
graphs or functions characterizing time-dependence of learning activity. Our
observations suggest that dynamically generated mechanisms may offer
alternative ways to keep cooperators alive even at very larger temptation to
defect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0516</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0516</id><created>2010-09-02</created><updated>2011-02-21</updated><authors><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author></authors><title>A Tractable Approach to Coverage and Rate in Cellular Networks</title><categories>cs.IT cs.NI math.IT math.PR</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular networks are usually modeled by placing the base stations on a grid,
with mobile users either randomly scattered or placed deterministically. These
models have been used extensively but suffer from being both highly idealized
and not very tractable, so complex system-level simulations are used to
evaluate coverage/outage probability and rate. More tractable models have long
been desirable. We develop new general models for the multi-cell
signal-to-interference-plus-noise ratio (SINR) using stochastic geometry. Under
very general assumptions, the resulting expressions for the downlink SINR CCDF
(equivalent to the coverage probability) involve quickly computable integrals,
and in some practical special cases can be simplified to common integrals
(e.g., the Q-function) or even to simple closed-form expressions. We also
derive the mean rate, and then the coverage gain (and mean rate loss) from
static frequency reuse. We compare our coverage predictions to the grid model
and an actual base station deployment, and observe that the proposed model is
pessimistic (a lower bound on coverage) whereas the grid model is optimistic,
and that both are about equally accurate. In addition to being more tractable,
the proposed model may better capture the increasingly opportunistic and dense
placement of base stations in future networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0550</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0550</id><created>2010-09-02</created><authors><author><keyname>David-Tabibi</keyname><forenames>Omid</forenames></author><author><keyname>Koppel</keyname><forenames>Moshe</forenames></author><author><keyname>Netanyahu</keyname><forenames>Nathan S.</forenames></author></authors><title>Optimizing Selective Search in Chess</title><categories>cs.AI cs.NE</categories><journal-ref>Proceedings of the International Conference on Machine Learning
  (ICML) Workshop on Machine Learning and Games, Haifa, Israel, June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a novel method for automatically tuning the search
parameters of a chess program using genetic algorithms. Our results show that a
large set of parameter values can be learned automatically, such that the
resulting performance is comparable with that of manually tuned parameters of
top tournament-playing chess programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0556</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0556</id><created>2010-09-02</created><authors><author><keyname>Gutfraind</keyname><forenames>Alexander</forenames></author><author><keyname>Hagberg</keyname><forenames>Aric A.</forenames></author><author><keyname>Izraelevitz</keyname><forenames>David</forenames></author><author><keyname>Pan</keyname><forenames>Feng</forenames></author></authors><title>Interdiction of a Markovian Evader</title><categories>math.OC cs.DS</categories><comments>Submitted to INFORMS Computing Society Conference (ICS2011)</comments><report-no>LA-UR-08-06551</report-no><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shortest path network interdiction is a combinatorial optimization problem on
an activity network arising in a number of important security-related
applications. It is classically formulated as a bilevel maximin problem
representing an &quot;interdictor&quot; and an &quot;evader&quot;. The evader tries to move from a
source node to the target node along a path of the least cost while the
interdictor attempts to frustrate this motion by cutting edges or nodes. The
interdiction objective is to find the optimal set of edges to cut given that
there is a finite interdiction budget and the interdictor must move first. We
reformulate the interdiction problem for stochastic evaders by introducing a
model in which the evader follows a Markovian random walk guided by the
least-cost path to the target. This model can represent incomplete knowledge
about the evader, and the resulting model is a nonlinear 0-1 optimization
problem. We then introduce an optimization heuristic based on betweenness
centrality that can rapidly find high-quality interdiction solutions by
providing a global view of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0558</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0558</id><created>2010-09-02</created><updated>2011-09-22</updated><authors><author><keyname>Dong</keyname><forenames>Daoyi</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Sliding Mode Control of Two-Level Quantum Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>29 pages, 4 figures, accepted by Automatica</comments><journal-ref>Automatica 48 (2012) 725-735</journal-ref><doi>10.1016/j.automatica.2012.02.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a robust control method based on sliding mode design for
two-level quantum systems with bounded uncertainties. An eigenstate of the
two-level quantum system is identified as a sliding mode. The objective is to
design a control law to steer the system's state into the sliding mode domain
and then maintain it in that domain when bounded uncertainties exist in the
system Hamiltonian. We propose a controller design method using the Lyapunov
methodology and periodic projective measurements. In particular, we give
conditions for designing such a control law, which can guarantee the desired
robustness in the presence of the uncertainties. The sliding mode control
method has potential applications to quantum information processing with
uncertainties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0569</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0569</id><created>2010-09-02</created><updated>2012-09-05</updated><authors><author><keyname>Srivastava</keyname><forenames>Rahul</forenames></author><author><keyname>Koksal</keyname><forenames>Can Emre</forenames></author></authors><title>Basic Performance Limits and Tradeoffs in Energy Harvesting Sensor Nodes
  with Finite Data and Energy Storage</title><categories>cs.NI</categories><comments>A shorter version of this paper will appear in the IEEE/ACM
  Transactions on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As many sensor network applications require deployment in remote and
hard-to-reach areas, it is critical to ensure that such networks are capable of
operating unattended for long durations. Consequently, the concept of using
nodes with energy replenishment capabilities has been gaining popularity.
However, new techniques and protocols must be developed to maximize the
performance of sensor networks with energy replenishment. Here, we analyze
limits of the performance of sensor nodes with limited energy, being
replenished at a variable rate. We provide a simple localized energy management
scheme that achieves a performance close to that with an unlimited energy
source, and at the same time keeps the probability of complete battery
discharge low. Based on the insights developed, we address the problem of
energy management for energy-replenishing nodes with finite battery and finite
data buffer capacities. To this end, we give an energy management scheme that
achieves the optimal utility asymptotically while keeping both the battery
discharge and data loss probabilities low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0571</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0571</id><created>2010-09-02</created><updated>2011-11-20</updated><authors><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Bartlett</keyname><forenames>Peter L.</forenames></author><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Information-theoretic lower bounds on the oracle complexity of
  stochastic convex optimization</title><categories>stat.ML cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relative to the large literature on upper bounds on complexity of convex
optimization, lesser attention has been paid to the fundamental hardness of
these problems. Given the extensive use of convex optimization in machine
learning and statistics, gaining an understanding of these complexity-theoretic
issues is important. In this paper, we study the complexity of stochastic
convex optimization in an oracle model of computation. We improve upon known
results and obtain tight minimax complexity estimates for various function
classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0572</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0572</id><created>2010-09-02</created><updated>2010-09-20</updated><authors><author><keyname>Zhou</keyname><forenames>Zhiheng</forenames></author><author><keyname>Zhou</keyname><forenames>Liang</forenames></author><author><keyname>Wang</keyname><forenames>Xing</forenames></author><author><keyname>Tan</keyname><forenames>Yuanquan</forenames></author></authors><title>Encoded packet-Assisted Rescue Approach to Reliable Unicast in Wireless
  Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>9 pages, 8 figures, submitted to IEEE ICC 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently, network coding technique has emerged as a promising approach that
supports reliable transmission over wireless loss channels. In existing
protocols where users have no interest in considering the encoded packets they
had in coding or decoding operations, this rule is expensive and inefficient.
This paper studies the impact of encoded packets in the reliable unicast
network coding via some theoretical analysis. Using our approach, receivers do
not only store the encoded packets they overheard, but also report these
information to their neighbors, such that users enable to take account of
encoded packets in their coding decisions as well as decoding operations.
Moreover, we propose a redistribution algorithm to maximize the coding
opportunities, which achieves better retransmission efficiency. Finally,
theoretical analysis and simulation results for a wheel network illustrate the
improvement in retransmissions efficiency due to the encoded packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0574</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0574</id><created>2010-09-02</created><updated>2011-03-07</updated><authors><author><keyname>Peterson</keyname><forenames>G. J.</forenames></author><author><keyname>Press&#xe9;</keyname><forenames>S.</forenames></author><author><keyname>Dill</keyname><forenames>K. A.</forenames></author></authors><title>Nonuniversal power law scaling in the probability distribution of
  scientific citations</title><categories>physics.soc-ph cond-mat.stat-mech cs.DL physics.data-an</categories><comments>7 pages, 3 figures, 2 tables</comments><journal-ref>PNAS 107 (2010) 16023-16027</journal-ref><doi>10.1073/pnas.1010757107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a model for the distribution of scientific citations. The model
involves a dual mechanism: in the direct mechanism, the author of a new paper
finds an old paper A and cites it. In the indirect mechanism, the author of a
new paper finds an old paper A only via the reference list of a newer
intermediary paper B, which has previously cited A. By comparison to citation
databases, we find that papers having few citations are cited mainly by the
direct mechanism. Papers already having many citations ('classics') are cited
mainly by the indirect mechanism. The indirect mechanism gives a power-law
tail. The 'tipping point' at which a paper becomes a classic is about 21
citations for papers published in the Institute for Scientific Information
(ISI) Web of Science database in 1981, 29 for Physical Review D papers
published from 1975-1994, and 39 for all publications from a list of high
h-index chemists assembled in 2007. The power-law exponent is not universal.
Individuals who are highly cited have a systematically smaller exponent than
individuals who are less cited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0579</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0579</id><created>2010-09-02</created><authors><author><keyname>Duncan</keyname><forenames>Christian A.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author></authors><title>Lombardi Drawings of Graphs</title><categories>cs.CG</categories><comments>Expanded version of paper appearing in the 18th International
  Symposium on Graph Drawing (GD 2010). 13 pages, 7 figures</comments><msc-class>05C10, 68R10</msc-class><acm-class>G.2.2; F.2.2</acm-class><journal-ref>J. Graph Algorithms and Applications 16(1):85-108, 2012 (special
  issue for GD 2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of Lombardi graph drawings, named after the American
abstract artist Mark Lombardi. In these drawings, edges are represented as
circular arcs rather than as line segments or polylines, and the vertices have
perfect angular resolution: the edges are equally spaced around each vertex. We
describe algorithms for finding Lombardi drawings of regular graphs, graphs of
bounded degeneracy, and certain families of planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0580</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0580</id><created>2010-09-02</created><updated>2010-10-25</updated><authors><author><keyname>Yakubo</keyname><forenames>Kousuke</forenames></author><author><keyname>Korosak</keyname><forenames>Dean</forenames></author></authors><title>Scale-free networks embedded in fractal space</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>11 pages, 10 figures</comments><doi>10.1103/PhysRevE.83.066111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The impact of inhomogeneous arrangement of nodes in space on network
organization cannot be neglected in most of real-world scale-free networks.
Here, we wish to suggest a model for a geographical network with nodes embedded
in a fractal space in which we can tune the network heterogeneity by varying
the strength of the spatial embedding. When the nodes in such networks have
power-law distributed intrinsic weights, the networks are scale-free with the
degree distribution exponent decreasing with increasing fractal dimension if
the spatial embedding is strong enough, while the weakly embedded networks are
still scale-free but the degree exponent is equal to $\gamma=2$ regardless of
the fractal dimension. We show that this phenomenon is related to the
transition from a non-compact to compact phase of the network and that this
transition is related to the divergence of the edge length fluctuations. We
test our analytically derived predictions on the real-world example of networks
describing the soil porous architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0581</identifier>
 <datestamp>2015-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0581</id><created>2010-09-03</created><updated>2015-09-10</updated><authors><author><keyname>Duncan</keyname><forenames>Christian A.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author></authors><title>Drawing Trees with Perfect Angular Resolution and Polynomial Area</title><categories>cs.CG</categories><comments>30 pages, 17 figures</comments><msc-class>05C10, 68R10</msc-class><acm-class>G.2.2; F.2.2</acm-class><journal-ref>Discrete Comput. Geom. 49 (2): 157-182, 2013</journal-ref><doi>10.1007/s00454-012-9472-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study methods for drawing trees with perfect angular resolution, i.e.,
with angles at each node v equal to 2{\pi}/d(v). We show:
  1. Any unordered tree has a crossing-free straight-line drawing with perfect
angular resolution and polynomial area.
  2. There are ordered trees that require exponential area for any
crossing-free straight-line drawing having perfect angular resolution.
  3. Any ordered tree has a crossing-free Lombardi-style drawing (where each
edge is represented by a circular arc) with perfect angular resolution and
polynomial area. Thus, our results explore what is achievable with
straight-line drawings and what more is achievable with Lombardi-style
drawings, with respect to drawings of trees with perfect angular resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0585</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0585</id><created>2010-09-03</created><authors><author><keyname>Samundiswary</keyname><forenames>P.</forenames></author><author><keyname>Sathian</keyname><forenames>D.</forenames></author><author><keyname>Dananjayan</keyname><forenames>P.</forenames></author></authors><title>Secured Greedy Perimeter Stateless Routing for Wireless Sensor Networks</title><categories>cs.NI</categories><comments>12 pages, 16 figures</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing(
  IJASUC ) Vol.1, No.2, June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks are collections of large number of sensor nodes. The
sensor nodes are featured with limited energy, computation and transmission
power. Each node in the network coordinates with every other node in forwarding
their packets to reach the destination. Since these nodes operate in a
physically insecure environment; they are vulnerable to different types of
attacks such as selective forwarding and sinkhole. These attacks can inject
malicious packets by compromising the node. Geographical routing protocols of
wireless sensor networks have been developed without considering the security
aspects against these attacks. In this paper, a secure routing protocol named
secured greedy perimeter stateless routing protocol (S-GPSR) is proposed for
mobile sensor networks by incorporating trust based mechanism in the existing
greedy perimeter stateless routing protocol (GPSR). Simulation results prove
that S-GPSR outperforms the GPSR by reducing the overhead and improving the
delivery ratio of the networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0605</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0605</id><created>2010-09-03</created><updated>2011-01-15</updated><authors><author><keyname>Dorard</keyname><forenames>Louis</forenames></author><author><keyname>Shawe-Taylor</keyname><forenames>John</forenames></author></authors><title>Gaussian Process Bandits for Tree Search: Theory and Application to
  Planning in Discounted MDPs</title><categories>cs.LG cs.AI</categories><comments>Second draft. Tried to follow the JMLR formatting guidelines. Made
  corrections to the section on planning in MDPs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We motivate and analyse a new Tree Search algorithm, GPTS, based on recent
theoretical advances in the use of Gaussian Processes for Bandit problems. We
consider tree paths as arms and we assume the target/reward function is drawn
from a GP distribution. The posterior mean and variance, after observing data,
are used to define confidence intervals for the function values, and we
sequentially play arms with highest upper confidence bounds. We give an
efficient implementation of GPTS and we adapt previous regret bounds by
determining the decay rate of the eigenvalues of the kernel matrix on the whole
set of tree paths. We consider two kernels in the feature space of binary
vectors indexed by the nodes of the tree: linear and Gaussian. The regret grows
in square root of the number of iterations T, up to a logarithmic factor, with
a constant that improves with bigger Gaussian kernel widths. We focus on
practical values of T, smaller than the number of arms. Finally, we apply GPTS
to Open Loop Planning in discounted Markov Decision Processes by modelling the
reward as a discounted sum of independent Gaussian Processes. We report similar
regret bounds to those of the OLOP algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0606</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0606</id><created>2010-09-03</created><authors><author><keyname>Zhang</keyname><forenames>Zhongzhi</forenames></author><author><keyname>Gao</keyname><forenames>Shuyang</forenames></author><author><keyname>Xie</keyname><forenames>Wenlei</forenames></author></authors><title>Impact of degree heterogeneity on the behavior of trapping in Koch
  networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>Definitive version accepted for publication in Chaos</comments><journal-ref>Chaos, 2010, 20:043112</journal-ref><doi>10.1063/1.3493406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work shows that the mean first-passage time (MFPT) for random walks
to a given hub node (node with maximum degree) in uncorrelated random
scale-free networks is closely related to the exponent $\gamma$ of power-law
degree distribution $P(k)\sim k^{-\gamma}$, which describes the extent of
heterogeneity of scale-free network structure. However, extensive empirical
research indicates that real networked systems also display ubiquitous degree
correlations. In this paper, we address the trapping issue on the Koch
networks, which is a special random walk with one trap fixed at a hub node. The
Koch networks are power-law with the characteristic exponent $\gamma$ in the
range between 2 and 3, they are either assortative or disassortative. We
calculate exactly the MFPT that is the average of first-passage time from all
other nodes to the trap. The obtained explicit solution shows that in large
networks the MFPT varies lineally with node number $N$, which is obviously
independent of $\gamma$ and is sharp contrast to the scaling behavior of MFPT
observed for uncorrelated random scale-free networks, where $\gamma$ influences
qualitatively the MFPT of trapping problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0619</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0619</id><created>2010-09-03</created><authors><author><keyname>Nordio</keyname><forenames>Alessandro</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author></authors><title>Field Reconstruction in Sensor Networks with Coverage Holes and Packet
  Losses</title><categories>cs.NI</categories><doi>10.1109/TSP.2011.2146778</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environmental monitoring is often performed through a wireless sensor
network, whose nodes are randomly deployed over the geographical region of
interest. Sensors sample a physical phenomenon (the so-called field) and send
their measurements to a {\em sink} node, which is in charge of reconstructing
the field from such irregular samples. In this work, we focus on scenarios of
practical interest where the sensor deployment is unfeasible in certain areas
of the geographical region, e.g., due to terrain asperities, and the delivery
of sensor measurements to the sink may fail due to fading or to transmission
collisions among sensors simultaneously accessing the wireless medium. Under
these conditions, we carry out an asymptotic analysis and evaluate the quality
of the estimation of a d-dimensional field when the sink uses linear filtering
as a reconstruction technique. Specifically, given the matrix representing the
sampling system, V, we derive both the moments and an expression of the
limiting spectral distribution of VV*, as the size of V goes to infinity and
its aspect ratio has a finite limit bounded away from zero. By using such
asymptotic results, we approximate the mean square error on the estimated field
through the eta-transform of VV*, and derive the sensor network performance
under the conditions described above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0623</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0623</id><created>2010-09-03</created><updated>2010-09-28</updated><authors><author><keyname>Sakthivel</keyname><forenames>S.</forenames></author><author><keyname>Lakshmipathi</keyname><forenames>R.</forenames></author></authors><title>Weighted Attribute Fusion Model for Face Recognition</title><categories>cs.CV</categories><comments>Keywords - Face Recognition, Feature Fusion Method, Parallel Method,
  PCA, DCT, Histogram Matching</comments><journal-ref>International Journal of Computer Science and Information
  Security,Vol. 8, No. 3, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recognizing a face based on its attributes is an easy task for a human to
perform as it is a cognitive process. In recent years, Face Recognition is
achieved with different kinds of facial features which were used separately or
in a combined manner. Currently, Feature fusion methods and parallel methods
are the facial features used and performed by integrating multiple feature sets
at different levels. However, this integration and the combinational methods do
not guarantee better result. Hence to achieve better results, the feature
fusion model with multiple weighted facial attribute set is selected. For this
feature model, face images from predefined data set has been taken from
Olivetti Research Laboratory (ORL) and applied on different methods like
Principal Component Analysis (PCA) based Eigen feature extraction technique,
Discrete Cosine Transformation (DCT) based feature extraction technique,
Histogram Based Feature Extraction technique and Simple Intensity based
features. The extracted feature set obtained from these methods were compared
and tested for accuracy. In this work we have developed a model which will use
the above set of feature extraction techniques with different levels of weights
to attain better accuracy. The results show that the selection of optimum
weight for a particular feature will lead to improvement in recognition rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0626</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0626</id><created>2010-09-03</created><authors><author><keyname>Dietz</keyname><forenames>Chris</forenames></author><author><keyname>van der Laan</keyname><forenames>Dinard</forenames></author><author><keyname>Ridder</keyname><forenames>Ad</forenames></author></authors><title>Approximate results for a generalized secretary problem</title><categories>math.PR cs.GT</categories><comments>15 pages, 2 figures</comments><msc-class>60C05, 90C39</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A version of the classical secretary problem is studied, in which one is
interested in selecting one of the b best out of a group of n differently
ranked persons who are presented one by one in a random order. It is assumed
that b is a preassigned (natural) number. It is known, already for a long time,
that for the optimal policy one needs to compute b position thresholds, for
instance via backwards induction. In this paper we study approximate policies,
that use just a single or a double position threshold, albeit in conjunction
with a level rank. We give exact and asymptotic (as n tends to infinity)
results, which show that the double-level policy is an extremely accurate
approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0630</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0630</id><created>2010-09-03</created><authors><author><keyname>Sharma</keyname><forenames>Kalpana</forenames></author><author><keyname>Rathor</keyname><forenames>Anurag S.</forenames></author><author><keyname>Biradar</keyname><forenames>S. R.</forenames></author><author><keyname>Ghose</keyname><forenames>M. K</forenames></author></authors><title>Power-efficient Routing &amp; Increased Yield Approach For WSNs</title><categories>cs.NI</categories><comments>7 pages,6 figures, International Journal on Computer Science and
  Engineering Vol. 02, No. 03, 2010, 573-579</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sensor nodes in a Wireless Sensor Network are generally constrained with
limited power supply. Efficient power management is a must for any sensor
network to keep the sensor nodes in the network to be operational for a longer
period of time this increasing the lifetime of the sensor network. Hierarchy
based routing enables the sensor networks to be deployed in larger areas. In
this paper we present a hierarchical cluster based routing protocol which
improves the scalability as the data travels from one cluster level to another
covering a greater amount of distance and increases the lifetime of the
wireless sensor network by distributing the power dissipation load evenly among
all the sensor nodes within the network. Also the time delay in case of
critical data to be received by the Base Station has also been lowered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0638</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0638</id><created>2010-09-03</created><authors><author><keyname>Evans</keyname><forenames>T. S.</forenames></author></authors><title>Clique Graphs and Overlapping Communities</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>23 pages plus 16 additional pages in appendices</comments><report-no>Imperial/TP/10/TSE/02</report-no><journal-ref>J. Stat. Mech. (2010) P12037</journal-ref><doi>10.1088/1742-5468/2010/12/P12037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown how to construct a clique graph in which properties of cliques of
a fixed order in a given graph are represented by vertices in a weighted graph.
Various definitions and motivations for these weights are given. The detection
of communities or clusters is used to illustrate how a clique graph may be
exploited. In particular a benchmark network is shown where clique graphs find
the overlapping communities accurately while vertex partition methods fail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0655</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0655</id><created>2010-09-03</created><authors><author><keyname>Stoianov</keyname><forenames>Nikolai</forenames></author><author><keyname>Aleksandrova</keyname><forenames>Veselina</forenames></author></authors><title>The E-net model for the Risk Analysis and Assessment System for the
  Information Security of Communication and Information Systems (&quot;Defining&quot;
  Subsystem)</title><categories>cs.CR</categories><comments>Acknowledgment: The work presented in this paper has been performed
  in the framework of the EU Project INDECT (Intelligent information system
  supporting observation, searching and detection for security of citizens in
  urban environment) - grant agreement number: 218086</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents one suggestion that comprises the authors' experience in
development and implementation of systems for information security in the
Automated Information Systems of the Bulgarian Armed Forces. The architecture
of risk analysis and assessment system for the communication and information
system's information security (CIS IS) has been presented. E-net model of
&quot;Defining&quot; Subsystem as a tool that allows to examine the subsystems is
proposed as well. Such approach can be applied successfully for communication
and information systems in the business field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0670</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0670</id><created>2010-09-03</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Watkins</keyname><forenames>Jennifer H.</forenames></author></authors><title>Grammar-Based Geodesics in Semantic Networks</title><categories>cs.DS</categories><comments>First draft written in 2007</comments><report-no>LA-UR-07-4042</report-no><journal-ref>Knowledge-Based Systems, 23(8), pp. 844-855, December 2010</journal-ref><doi>10.1016/j.knosys.2010.05.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A geodesic is the shortest path between two vertices in a connected network.
The geodesic is the kernel of various network metrics including radius,
diameter, eccentricity, closeness, and betweenness. These metrics are the
foundation of much network research and thus, have been studied extensively in
the domain of single-relational networks (both in their directed and undirected
forms). However, geodesics for single-relational networks do not translate
directly to multi-relational, or semantic networks, where vertices are
connected to one another by any number of edge labels. Here, a more
sophisticated method for calculating a geodesic is necessary. This article
presents a technique for calculating geodesics in semantic networks with a
focus on semantic networks represented according to the Resource Description
Framework (RDF). In this framework, a discrete &quot;walker&quot; utilizes an abstract
path description called a grammar to determine which paths to include in its
geodesic calculation. The grammar-based model forms a general framework for
studying geodesic metrics in semantic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0673</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0673</id><created>2010-09-03</created><authors><author><keyname>Ihlemann</keyname><forenames>Carsten</forenames></author><author><keyname>Sofronie-Stokkermans</keyname><forenames>Viorica</forenames></author></authors><title>System Description: H-PILoT (Version 1.9)</title><categories>cs.LO cs.SC cs.SE</categories><comments>43 pages; A version of this system description appeared as AVACS
  technical report Nr. 61 (SFB/TR 14) http://www.avacs.org</comments><report-no>AVACS technical report Nr. 61 (SFB/TR 14)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This system description provides an overview of H-PILoT (Hierarchical Proving
by Instantiation in Local Theory extensions), a program for hierarchical
reasoning in extensions of logical theories. H-PILoT reduces deduction problems
in the theory extension to deduction problems in the base theory. Specialized
provers and standard SMT solvers can be used for testing the satisfiability of
the formulae obtained after the reduction. For a certain type of theory
extension (namely for local theory extensions) this hierarchical reduction is
sound and complete and -- if the formulae obtained this way belong to a
fragment decidable in the base theory -- H-PILoT provides a decision procedure
for testing satisfiability of ground formulae, and can also be used for model
generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0679</identifier>
 <datestamp>2012-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0679</id><created>2010-09-02</created><updated>2012-05-23</updated><authors><author><keyname>Owhadi</keyname><forenames>Houman</forenames></author><author><keyname>Scovel</keyname><forenames>Clint</forenames></author><author><keyname>Sullivan</keyname><forenames>Timothy John</forenames></author><author><keyname>McKerns</keyname><forenames>Mike</forenames></author><author><keyname>Ortiz</keyname><forenames>Michael</forenames></author></authors><title>Optimal Uncertainty Quantification</title><categories>math.PR cs.IT math.IT math.ST physics.data-an stat.TH</categories><comments>90 pages. Accepted for publication in SIAM Review (Expository
  Research Papers). See SIAM Review for higher quality figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a rigorous framework for Uncertainty Quantification (UQ) in which
the UQ objectives and the assumptions/information set are brought to the
forefront. This framework, which we call \emph{Optimal Uncertainty
Quantification} (OUQ), is based on the observation that, given a set of
assumptions and information about the problem, there exist optimal bounds on
uncertainties: these are obtained as values of well-defined optimization
problems corresponding to extremizing probabilities of failure, or of
deviations, subject to the constraints imposed by the scenarios compatible with
the assumptions and information. In particular, this framework does not
implicitly impose inappropriate assumptions, nor does it repudiate relevant
information. Although OUQ optimization problems are extremely large, we show
that under general conditions they have finite-dimensional reductions. As an
application, we develop \emph{Optimal Concentration Inequalities} (OCI) of
Hoeffding and McDiarmid type. Surprisingly, these results show that
uncertainties in input parameters, which propagate to output uncertainties in
the classical sensitivity analysis paradigm, may fail to do so if the transfer
functions (or probability distributions) are imperfectly known. We show how,
for hierarchical structures, this phenomenon may lead to the non-propagation of
uncertainties or information across scales. In addition, a general algorithmic
framework is developed for OUQ and is tested on the Caltech surrogate model for
hypervelocity impact and on the seismic safety assessment of truss structures,
suggesting the feasibility of the framework for important complex systems. The
introduction of this paper provides both an overview of the paper and a
self-contained mini-tutorial about basic concepts and issues of UQ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0682</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0682</id><created>2010-09-03</created><authors><author><keyname>Kendziorra</keyname><forenames>Andreas</forenames></author><author><keyname>Schmidt</keyname><forenames>Stefan E.</forenames></author></authors><title>Network coding with modular lattices</title><categories>cs.IT math.IT</categories><comments>26 pages, 1 figure</comments><msc-class>06C05, 68P30, 94B65, 05A15, 20K27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [1], K\&quot;otter and Kschischang presented a new model for error correcting
codes in network coding. The alphabet in this model is the subspace lattice of
a given vector space, a code is a subset of this lattice and the used metric on
this alphabet is the map d: (U, V) \longmapsto dim(U + V) - dim(U \bigcap V).
In this paper we generalize this model to arbitrary modular lattices, i.e. we
consider codes, which are subsets of modular lattices. The used metric in this
general case is the map d: (x, y) \longmapsto h(x \bigvee y) - h(x \bigwedge
y), where h is the height function of the lattice. We apply this model to
submodule lattices. Moreover, we show a method to compute the size of spheres
in certain modular lattices and present a sphere packing bound, a sphere
covering bound, and a singleton bound for codes, which are subsets of modular
lattices.
  [1] R. K\&quot;otter, F.R. Kschischang: Coding for errors and erasures in random
network coding, IEEE Trans. Inf. Theory, Vol. 54, No. 8, 2008
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0706</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0706</id><created>2010-09-03</created><authors><author><keyname>Daneshgar</keyname><forenames>Amir</forenames></author><author><keyname>Javadi</keyname><forenames>Ramin</forenames></author></authors><title>On Complexity of Isoperimetric Problems on Trees</title><categories>cs.CC math.CO</categories><msc-class>05C85, 68Q25, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is aimed to investigate some computational aspects of different
isoperimetric problems on weighted trees. In this regard, we consider different
connectivity parameters called {\it minimum normalized cuts}/{\it isoperimteric
numbers} defined through taking minimum of the maximum or the mean of the
normalized outgoing flows from a set of subdomains of vertices, where these
subdomains constitute a {\it partition}/{\it subpartition}. Following the main
result of [A. Daneshgar, {\it et. al.}, {\it On the isoperimetric spectrum of
graphs and its approximations}, JCTB, (2010)], it is known that the
isoperimetric number and the minimum normalized cut both can be described as
$\{0,1\}$-optimization programs, where the latter one does {\it not} admit a
relaxation to the reals. We show that the decision problem for the case of
taking $k$-partitions and the maximum (called the max normalized cut problem
{\rm NCP}$^M$) as well as the other two decision problems for the mean version
(referred to as {\rm IPP}$^m$ and {\rm NCP}$^m$) are $NP$-complete problems. On
the other hand, we show that the decision problem for the case of taking
$k$-subpartitions and the maximum (called the max isoperimetric problem {\rm
IPP}$^M$) can be solved in {\it linear time} for any weighted tree and any $k
\geq 2$. Based on this fact, we provide polynomial time $O(k)$-approximation
algorithms for all different versions of $k$th isoperimetric numbers
considered. Moreover, when the number of partitions/subpartitions, $k$, is a
fixed constant, as an extension of a result of B. Mohar (1989) for the case
$k=2$ (usually referred to as the Cheeger constant), we prove that max and mean
isoperimetric numbers of weighted trees as well as their max normalized cut can
be computed in polynomial time. We also prove some hardness results for the
case of simple unweighted graphs and trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0744</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0744</id><created>2010-09-03</created><updated>2011-02-10</updated><authors><author><keyname>Krahmer</keyname><forenames>Felix</forenames></author><author><keyname>Ward</keyname><forenames>Rachel</forenames></author></authors><title>New and improved Johnson-Lindenstrauss embeddings via the Restricted
  Isometry Property</title><categories>cs.IT math.IT math.NA math.PR</categories><comments>11 pages, no figures</comments><msc-class>41, 60, 65, 94</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an m by N matrix Phi with the Restricted Isometry Property of order
k and level delta, that is, the norm of any k-sparse vector in R^N is preserved
to within a multiplicative factor of 1 +- delta under application of Phi. We
show that by randomizing the column signs of such a matrix Phi, the resulting
map with high probability embeds any fixed set of p = O(e^k) points in R^N into
R^m without distorting the norm of any point in the set by more than a factor
of 1 +- delta. Consequently, matrices with the Restricted Isometry Property and
with randomized column signs provide optimal Johnson-Lindenstrauss embeddings
up to logarithmic factors in N. In particular, our results improve the best
known bounds on the necessary embedding dimension m for a wide class of
structured random matrices; for partial Fourier and partial Hadamard matrices,
we improve the recent bound m = O(delta^(-4) log(p) log^4(N)) appearing in
Ailon and Liberty to m = O(delta^(-2) log(p) log^4(N)), which is optimal up to
the logarithmic factors in N. Our results also have a direct application in the
area of compressed sensing for redundant dictionaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0769</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0769</id><created>2010-09-03</created><authors><author><keyname>Du</keyname><forenames>Songzi</forenames></author><author><keyname>Livne</keyname><forenames>Yair</forenames></author></authors><title>Chaos and Unraveling in Matching Markets</title><categories>q-fin.TR cs.GT math.PR</categories><comments>39 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study how information perturbations can destabilize two-sided matching
markets. In our model, agents arrive on the market over two periods, while
agents in the first period do not know the types of those arriving later.
Agents already present in the market may match early or wait for the small
group of new entrants. Despite the lack of discounting or risk aversion, this
perturbation creates incentives to match early and leave the market before the
new agents arrive. These incentives do not disappear as the market gets large.
Moreover, we identify a new adverse phenomenon in this setting: as markets get
large the probability of \emph{chaos} -- where no early matching scheme for
existing agents is robust to pairwise deviations -- approaches 1. These results
are independent of the distribution of agents' types and robust to asymmetries
between the two sides of the market. Our findings thus suggest that matching
markets are extremely sensitive to institutional details and uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0783</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0783</id><created>2010-09-03</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author><author><keyname>Trott</keyname><forenames>Lowell</forenames></author></authors><title>Extended h-Index Parameterized Data Structures for Computing Dynamic
  Subgraph Statistics</title><categories>cs.DS</categories><journal-ref>Theor. Comput. Sci. 447: 44-52, 2012</journal-ref><doi>10.1016/j.tcs.2011.11.034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present techniques for maintaining subgraph frequencies in a dynamic
graph, using data structures that are parameterized in terms of h, the h-index
of the graph. Our methods extend previous results of Eppstein and Spiro for
maintaining statistics for undirected subgraphs of size three to directed
subgraphs and to subgraphs of size four. For the directed case, we provide a
data structure to maintain counts for all 3-vertex induced subgraphs in O(h)
amortized time per update. For the undirected case, we maintain the counts of
size-four subgraphs in O(h^2) amortized time per update. These extensions
enable a number of new applications in Bioinformatics and Social Networking
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0794</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0794</id><created>2010-09-03</created><authors><author><keyname>Wang</keyname><forenames>Charlie C. L.</forenames></author><author><keyname>Chen</keyname><forenames>Yong</forenames></author></authors><title>Layered Depth-Normal Images: a Sparse Implicit Representation of Solid
  Models</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel implicit representation of solid models. With
this representation, every solid model can be effectively presented by three
layered depth-normal images (LDNIs) that are perpendicular to three orthogonal
axes respectively. The layered depth-normal images for a solid model, whose
boundary is presented by a polygonal mesh, can be generated efficiently with
help of the graphics hardware accelerated sampling. Based on this implicit
representation - LDNIs, solid modeling operations including the Boolean
operations and the offsetting operation have been developed. A contouring
algorithm is also introduced in this paper to generate thin structure and sharp
feature preserved mesh surfaces from the layered depth-normal images.
Comparisons between LDNIs and other implicit representation of solid models are
given at the end of the paper to demonstrate the advantages of LDNIs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0797</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0797</id><created>2010-09-03</created><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author><author><keyname>Dini</keyname><forenames>Paolo</forenames></author></authors><title>Towards Autopoietic Computing</title><categories>cs.OH</categories><comments>10 Pages, 3 figures</comments><doi>10.1007/978-3-642-14859-0_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key challenge in modern computing is to develop systems that address
complex, dynamic problems in a scalable and efficient way, because the
increasing complexity of software makes designing and maintaining efficient and
flexible systems increasingly difficult. Biological systems are thought to
possess robust, scalable processing paradigms that can automatically manage
complex, dynamic problem spaces, possessing several properties that may be
useful in computer systems. The biological properties of self-organisation,
self-replication, self-management, and scalability are addressed in an
interesting way by autopoiesis, a descriptive theory of the cell founded on the
concept of a system's circular organisation to define its boundary with its
environment. In this paper, therefore, we review the main concepts of
autopoiesis and then discuss how they could be related to fundamental concepts
and theories of computation. The paper is conceptual in nature and the emphasis
is on the review of other people's work in this area as part of a longer-term
strategy to develop a formal theory of autopoietic computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0806</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0806</id><created>2010-09-04</created><authors><author><keyname>Philip</keyname><forenames>Geevarghese</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>A Quartic Kernel for Pathwidth-One Vertex Deletion</title><categories>cs.DS</categories><comments>Full version of an extended abstract accepted for publication in the
  proceedings of WG 2010. 18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pathwidth of a graph is a measure of how path-like the graph is. Given a
graph G and an integer k, the problem of finding whether there exist at most k
vertices in G whose deletion results in a graph of pathwidth at most one is NP-
complete. We initiate the study of the parameterized complexity of this
problem, parameterized by k. We show that the problem has a quartic
vertex-kernel: We show that, given an input instance (G = (V, E), k); |V| = n,
we can construct, in polynomial time, an instance (G', k') such that (i) (G, k)
is a YES instance if and only if (G', k') is a YES instance, (ii) G' has
O(k^{4}) vertices, and (iii) k' \leq k. We also give a fixed parameter
tractable (FPT) algorithm for the problem that runs in O(7^{k} k \cdot n^{2})
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0817</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0817</id><created>2010-09-04</created><authors><author><keyname>Blech</keyname><forenames>Jan Olaf</forenames></author><author><keyname>Hattendorf</keyname><forenames>Anton</forenames></author><author><keyname>Huang</keyname><forenames>Jia</forenames></author></authors><title>Towards a Property Preserving Transformation from IEC 61131-3 to BIP</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on a transformation from Sequential Function Charts of the IEC
61131-3 standard to BIP. Our presentation features a description of formal
syntax and semantics representation of the involved languages and
transformation rules. Furthermore, we present a formalism for describing
invariants of IEC 61131-3 systems and establish a notion of invariant
preservation between the two languages. For a subset of our transformation
rules we sketch a proof showing invariant preservation during the
transformation of IEC 61131-3 to BIP and vice versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0827</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0827</id><created>2010-09-04</created><authors><author><keyname>khataeimaragheh</keyname><forenames>Hamed</forenames></author><author><keyname>Rashidi</keyname><forenames>Hassan</forenames></author></authors><title>A Novel Watermarking Scheme for Detecting and Recovering Distortions in
  Database Tables</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel fragile watermarking scheme is proposed to detect,
localize and recover malicious modifications in relational databases. In the
proposed scheme, all tuples in the database are first securely divided into
groups. Then watermarks are embedded and verified group-by-group independently.
By using the embedded watermark, we are able to detect and localize the
modification made to the database and even we recover the true data from the
database modified locations. Our experimental results show that this scheme is
so qualified; i.e. distortion detection and true data recovery both are
performed successfully.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0842</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0842</id><created>2010-09-04</created><updated>2010-09-26</updated><authors><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author></authors><title>Empirical study and modeling of human behaviour dynamics of comments on
  Blog posts</title><categories>cs.SI cs.HC physics.soc-ph</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  On-line communities offer a great opportunity to investigate human dynamics,
because much information about individuals is registered in databases. In this
paper, based on data statistics of online comments on Blog posts, we first
present an empirical study of a comment arrival-time interval distribution. We
find that people interested in some subjects gradually disappear and the
interval distribution is a power law. According to this feature, we propose a
model with gradually decaying interest. We give a rigorous analysis on the
model by non-homogeneous Poisson processes and obtain an analytic expression of
the interval distribution. Our analysis indicates that the time interval
between two consecutive events follows the power-law distribution with a
tunable exponent, which can be controlled by the model parameters and is in
interval (1,+{\infty}). The analytical result agrees with the empirical results
well, obeying an approximately power-law form. Our model provides a theoretical
basis for human behaviour dynamics of comments on Blog posts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0844</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0844</id><created>2010-09-04</created><authors><author><keyname>Kabiraj</keyname><forenames>Sajal</forenames></author><author><keyname>Topkar</keyname><forenames>Vinay</forenames></author><author><keyname>Walke</keyname><forenames>R. C.</forenames></author></authors><title>Going Green: A Holistic Approach to Transform Business</title><categories>cs.CY cs.GL</categories><comments>10 pages</comments><journal-ref>International Journal of Managing Information Technology (IJMIT)
  Vol.2, No.3, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years environmental and energy conservation issues have taken the
central theme in the global business arena. The reality of rising energy cost
and their impact on international affairs coupled with the different kinds of
environmental issues has shifted the social and economic consciousness of the
business community. Hence, the business community is now in search of an
eco-friendly business model. This paper highlights the concept of green
business and their needs in the current global scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0854</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0854</id><created>2010-09-04</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Kingravi</keyname><forenames>Hassan</forenames></author><author><keyname>Celiker</keyname><forenames>Fatih</forenames></author></authors><title>Fast Color Space Transformations Using Minimax Approximations</title><categories>cs.CV</categories><acm-class>G.1.2; I.4.m</acm-class><journal-ref>IET Image Processing 4 (2010) 70-80</journal-ref><doi>10.1049/iet-ipr.2008.0172</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Color space transformations are frequently used in image processing,
graphics, and visualization applications. In many cases, these transformations
are complex nonlinear functions, which prohibits their use in time-critical
applications. In this paper, we present a new approach called Minimax
Approximations for Color-space Transformations (MACT).We demonstrate MACT on
three commonly used color space transformations. Extensive experiments on a
large and diverse image set and comparisons with well-known multidimensional
lookup table interpolation methods show that MACT achieves an excellent balance
among four criteria: ease of implementation, memory usage, accuracy, and
computational speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0861</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0861</id><created>2010-09-04</created><authors><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Talwalkar</keyname><forenames>Ameet</forenames></author></authors><title>On the Estimation of Coherence</title><categories>stat.ML cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-rank matrix approximations are often used to help scale standard machine
learning algorithms to large-scale problems. Recently, matrix coherence has
been used to characterize the ability to extract global information from a
subset of matrix entries in the context of these low-rank approximations and
other sampling-based algorithms, e.g., matrix com- pletion, robust PCA. Since
coherence is defined in terms of the singular vectors of a matrix and is
expensive to compute, the practical significance of these results largely
hinges on the following question: Can we efficiently and accurately estimate
the coherence of a matrix? In this paper we address this question. We propose a
novel algorithm for estimating coherence from a small number of columns,
formally analyze its behavior, and derive a new coherence-based matrix
approximation bound based on this analysis. We then present extensive
experimental results on synthetic and real datasets that corroborate our
worst-case theoretical analysis, yet provide strong support for the use of our
proposed algorithm whenever low-rank approximation is being considered. Our
algorithm efficiently and accurately estimates matrix coherence across a wide
range of datasets, and these coherence estimates are excellent predictors of
the effectiveness of sampling-based matrix approximation on a case-by-case
basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0862</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0862</id><created>2010-09-04</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Dragus</keyname><forenames>Andrei</forenames></author><author><keyname>Sambotin</keyname><forenames>Ana-Delia</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Brief Announcement: Decentralized Construction of Multicast Trees
  Embedded into P2P Overlay Networks based on Virtual Geometric Coordinates</title><categories>cs.DC cs.DS</categories><comments>ISBN: 978-1-60558-888-9</comments><msc-class>68M14, 68W15</msc-class><acm-class>C.2.1; C.2.4</acm-class><journal-ref>Proceedings of the 29th Annual ACM SIGACT-SIGOPS Symposium on
  Principles of Distributed Computing (PODC), pp. 283-284, Zurich, Switzerland,
  25-28 July, 2010</journal-ref><doi>10.1145/1835698.1835766</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of efficiently constructing in a fully
distributed manner multicast trees which are embedded into P2P overlays using
virtual geometric node coordinates. We consider two objectives: to minimize the
number of messages required for constructing a multicast tree by using the
geometric properties of the P2P overlay, and to construct stable multicast
trees when the lifetime durations of the peers are known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0870</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0870</id><created>2010-09-04</created><updated>2012-09-06</updated><authors><author><keyname>Tan</keyname><forenames>Bo</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Online Advertisement, Optimization and Stochastic Networks</title><categories>cs.DS cs.PF cs.SY math.OC</categories><comments>32 pages (single-column, double-spaced), 8 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a stochastic model to describe how search service
providers charge client companies based on users' queries for the keywords
related to these companies' ads by using certain advertisement assignment
strategies. We formulate an optimization problem to maximize the long-term
average revenue for the service provider under each client's long-term average
budget constraint, and design an online algorithm which captures the stochastic
properties of users' queries and click-through behaviors. We solve the
optimization problem by making connections to scheduling problems in wireless
networks, queueing theory and stochastic networks. Unlike prior models, we do
not assume that the number of query arrivals is known. Due to the stochastic
nature of the arrival process considered here, either temporary &quot;free&quot; service,
i.e., service above the specified budget or under-utilization of the budget is
unavoidable. We prove that our online algorithm can achieve a revenue that is
within $O(\epsilon)$ of the optimal revenue while ensuring that the overdraft
or underdraft is $O(1/\epsilon)$, where $\epsilon$ can be arbitrarily small.
With a view towards practice, we can show that one can always operate strictly
under the budget. In addition, we extend our results to a click-through rate
maximization model, and also show how our algorithm can be modified to handle
non-stationary query arrival processes and clients with short-term contracts.
  Our algorithm allows us to quantify the effect of errors in click-through
rate estimation on the achieved revenue. We also show that in the long run, an
expected overdraft level of $\Omega(\log(1/\epsilon))$ is unavoidable (a
universal lower bound) under any stationary ad assignment algorithm which
achieves a long-term average revenue within $O(\epsilon)$ of the offline
optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0881</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0881</id><created>2010-09-04</created><updated>2011-10-03</updated><authors><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author><author><keyname>Glineur</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>A Multilevel Approach For Nonnegative Matrix Factorization</title><categories>math.OC cs.NA math.NA</categories><comments>23 pages, 10 figures. Section 6 added discussing limitations of the
  method. Accepted in Journal of Computational and Applied Mathematics</comments><journal-ref>Journal of Computational and Applied Mathematics 236 (7), pp.
  1708-1723, 2012</journal-ref><doi>10.1016/j.cam.2011.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonnegative Matrix Factorization (NMF) is the problem of approximating a
nonnegative matrix with the product of two low-rank nonnegative matrices and
has been shown to be particularly useful in many applications, e.g., in text
mining, image processing, computational biology, etc. In this paper, we explain
how algorithms for NMF can be embedded into the framework of multilevel methods
in order to accelerate their convergence. This technique can be applied in
situations where data admit a good approximate representation in a lower
dimensional space through linear transformations preserving nonnegativity. A
simple multilevel strategy is described and is experimentally shown to speed up
significantly three popular NMF algorithms (alternating nonnegative least
squares, multiplicative updates and hierarchical alternating least squares) on
several standard image datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0884</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0884</id><created>2010-09-04</created><authors><author><keyname>Wen</keyname><forenames>Han Xiao</forenames></author></authors><title>Knowledge Recognition Algorithm enables P = NP</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a knowledge recognition algorithm (KRA) that is both a
Turing machine algorithm and an Oracle Turing machine algorithm. By definition
KRA is a non-deterministic language recognition algorithm. Simultaneously it
can be implemented as a deterministic Turing machine algorithm. KRA applies
mirrored perceptual-conceptual languages to learn member-class relations
between the two languages iteratively and retrieve information through
deductive and reductive recognition from one language to another. The novelty
of KRA is that the conventional concept of relation is adjusted. The
computation therefore becomes efficient bidirectional string mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0892</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0892</id><created>2010-09-05</created><updated>2010-09-16</updated><authors><author><keyname>Zheng</keyname><forenames>Yongbin</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Hartley</keyname><forenames>Richard</forenames></author><author><keyname>Huang</keyname><forenames>Xinsheng</forenames></author></authors><title>Effective Pedestrian Detection Using Center-symmetric Local
  Binary/Trinary Patterns</title><categories>cs.CV</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurately detecting pedestrians in images plays a critically important role
in many computer vision applications. Extraction of effective features is the
key to this task. Promising features should be discriminative, robust to
various variations and easy to compute. In this work, we present novel
features, termed dense center-symmetric local binary patterns (CS-LBP) and
pyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for
pedestrian detection. The standard LBP proposed by Ojala et al. \cite{c4}
mainly captures the texture information. The proposed CS-LBP feature, in
contrast, captures the gradient information and some texture information.
Moreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to
implement and computationally efficient, which is desirable for real-time
applications. Experiments on the INRIA pedestrian dataset show that the dense
CS-LBP feature with linear supporct vector machines (SVMs) is comparable with
the histograms of oriented gradients (HOG) feature with linear SVMs, and the
pyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and
the start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection
kernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP
feature and the PHOG feature could significantly improve the detection
performance-producing state-of-the-art accuracy on the INRIA pedestrian
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0896</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0896</id><created>2010-09-05</created><authors><author><keyname>Merrikh-Bayat</keyname><forenames>Farnood</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeed Bagheri</forenames></author></authors><title>Memristor Crossbar-based Hardware Implementation of Fuzzy Membership
  Functions</title><categories>cs.NE cs.AI cs.AR</categories><comments>5 pages, 5 figures, Submitted to ICCAE 2011 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In May 1, 2008, researchers at Hewlett Packard (HP) announced the first
physical realization of a fundamental circuit element called memristor that
attracted so much interest worldwide. This newly found element can easily be
combined with crossbar interconnect technology which this new structure has
opened a new field in designing configurable or programmable electronic
systems. These systems in return can have applications in signal processing and
artificial intelligence. In this paper, based on the simple memristor crossbar
structure, we propose new and simple circuits for hardware implementation of
fuzzy membership functions. In our proposed circuits, these fuzzy membership
functions can have any shapes and resolutions. In addition, these circuits can
be used as a basis in the construction of evolutionary systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0906</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0906</id><created>2010-09-05</created><authors><author><keyname>Ben-Haim</keyname><forenames>Zvika</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Near-Oracle Performance of Greedy Block-Sparse Estimation Techniques
  from Noisy Measurements</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>15 pages, 2 figures. Submitted to IEEE J. Selected Topics in Signal
  Processing</comments><doi>10.1109/JSTSP.2011.2160250</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the ability of greedy algorithms to estimate a block
sparse parameter vector from noisy measurements. In particular, block sparse
versions of the orthogonal matching pursuit and thresholding algorithms are
analyzed under both adversarial and Gaussian noise models. In the adversarial
setting, it is shown that estimation accuracy comes within a constant factor of
the noise power. Under Gaussian noise, the Cramer-Rao bound is derived, and it
is shown that the greedy techniques come close to this bound at high SNR. The
guarantees are numerically compared with the actual performance of block and
non-block algorithms, highlighting the advantages of block sparse techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0909</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0909</id><created>2010-09-05</created><updated>2011-10-18</updated><authors><author><keyname>Kirkpatrick</keyname><forenames>Bonnie</forenames></author><author><keyname>Reshef</keyname><forenames>Yakir</forenames></author><author><keyname>Finucane</keyname><forenames>Hilary</forenames></author><author><keyname>Jiang</keyname><forenames>Haitao</forenames></author><author><keyname>Zhu</keyname><forenames>Binhai</forenames></author><author><keyname>Karp</keyname><forenames>Richard M.</forenames></author></authors><title>Comparing Pedigree Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pedigree graphs, or family trees, are typically constructed by an expensive
process of examining genealogical records to determine which pairs of
individuals are parent and child. New methods to automate this process take as
input genetic data from a set of extant individuals and reconstruct ancestral
individuals. There is a great need to evaluate the quality of these methods by
comparing the estimated pedigree to the true pedigree.
  In this paper, we consider two main pedigree comparison problems. The first
is the pedigree isomorphism problem, for which we present a linear-time
algorithm for leaf-labeled pedigrees. The second is the pedigree edit distance
problem, for which we present 1) several algorithms that are fast and exact in
various special cases, and 2) a general, randomized heuristic algorithm.
  In the negative direction, we first prove that the pedigree isomorphism
problem is as hard as the general graph isomorphism problem, and that the
sub-pedigree isomorphism problem is NP-hard. We then show that the pedigree
edit distance problem is APX-hard in general and NP-hard on leaf-labeled
pedigrees.
  We use simulated pedigrees to compare our edit-distance algorithms to each
other as well as to a branch-and-bound algorithm that always finds an optimal
solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0915</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0915</id><created>2010-09-05</created><authors><author><keyname>J&#xe4;ntschi</keyname><forenames>Lorentz</forenames></author><author><keyname>Bolboac{\ba}</keyname><forenames>Sorana D.</forenames></author><author><keyname>B&#x103;lan</keyname><forenames>Mugur C.</forenames></author><author><keyname>Sestra&#x15f;</keyname><forenames>Radu E.</forenames></author></authors><title>Results of Evolution Supervised by Genetic Algorithms</title><categories>cs.NE</categories><comments>6 pages, 1 Table, 2 figures</comments><msc-class>78M32</msc-class><acm-class>I.6.4; J.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A series of results of evolution supervised by genetic algorithms with
interest to agricultural and horticultural fields are reviewed. New obtained
original results from the use of genetic algorithms on structure-activity
relationships are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0919</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0919</id><created>2010-09-05</created><authors><author><keyname>BK</keyname><forenames>Pradeepa</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>Aggregate AP Throughputs for Long File Transfers in a WLAN controlled by
  Inhomogeneous TCP Connections</title><categories>cs.NI</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance analysis of long file TCP controlled transfers in a WLAN in
infrastructure mode is available in the present literature with one of the main
assumptions being equal window size for all TCP connections. In this paper, we
extend the analysis to TCP-controlled long file uploads and downloads with
different TCP windows. Our approach is based on simple Markov chain given in
the paper [1], [2] with arbitrary window sizes. We presented simulation results
to show the accuracy of the analytical model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0921</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0921</id><created>2010-09-05</created><updated>2010-09-15</updated><authors><author><keyname>Zhou</keyname><forenames>Zhiheng</forenames></author><author><keyname>Zhou</keyname><forenames>Liang</forenames></author><author><keyname>Tan</keyname><forenames>Yuanquan</forenames></author><author><keyname>Wang</keyname><forenames>Xing</forenames></author></authors><title>An Efficient Retransmission Based on Network Coding with Unicast Flows</title><categories>cs.IT cs.NI math.IT</categories><comments>14 pages, 6 figures, submitted to IEEE WCNC2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently, network coding technique has emerged as a promising approach that
supports reliable transmission over wireless loss channels. In existing
protocols where users have no interest in considering the encoded packets they
had in coding or decoding operations, this rule is expensive and inef-ficient.
This paper studies the impact of encoded packets in the reliable unicast
network coding via some theoretical analysis. Using our approach, receivers do
not only store the encoded packets they overheard, but also report these
information to their neighbors, such that users enable to take account of
encoded packets in their coding decisions as well as decoding operations.
Moreover, we propose a redistribution algorithm to maximize the coding
opportunities, which achieves better retransmission efficiency. Finally,
theoretical analysis and simulation results for a wheel network illustrate the
improve-ment in retransmissions efficiency due to the encoded packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0923</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0923</id><created>2010-09-05</created><authors><author><keyname>Adl</keyname><forenames>Ammar</forenames></author><author><keyname>Badr</keyname><forenames>Amr</forenames></author><author><keyname>Farag</keyname><forenames>Ibrahim</forenames></author></authors><title>A Note on the Membrane Computer</title><categories>cs.OH</categories><journal-ref>COMPUTING AND INFORMATION SYSTEMS JOURNAL, Issue2, May 2010, P 1-7</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the emergent membrane computing (P Systems) concepts, some
efforts are carried out introducing simulation models, some are software
oriented, and others are hardware, yet all are applied with the current vision
of the conventional computers, based on &quot;Von Neumann architecture&quot;, which is a
sequential design in its essence. We think that these models will need &quot;as a
consequent result&quot; to a new architecture exposing a true parallel design, in
this paper; we try to investigate and introduce a global view for how it would
be like to have such architecture. The main goal is to point out to this
direction broadly, suggesting that it might be useful considering some aspects,
like the need for a new definition of an operating system and its programs,
which will eventually lead to a higher scope: the membrane computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0929</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0929</id><created>2010-09-05</created><authors><author><keyname>Chueh</keyname><forenames>Hao-En</forenames></author></authors><title>Mining Target-Oriented Sequential Patterns with Time-Intervals</title><categories>cs.DB</categories><comments>11 pages, 9 tables</comments><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT) Vol.2, No.4, August 2010</journal-ref><doi>10.5121/ijcsit.2010.2410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A target-oriented sequential pattern is a sequential pattern with a concerned
itemset in the end of pattern. A time-interval sequential pattern is a
sequential pattern with time-intervals between every pair of successive
itemsets. In this paper we present an algorithm to discover target-oriented
sequential pattern with time-intervals. To this end, the original sequences are
reversed so that the last itemsets can be arranged in front of the sequences.
The contrasts between reversed sequences and the concerned itemset are then
used to exclude the irrelevant sequences. Clustering analysis is used with
typical sequential pattern mining algorithm to extract the sequential patterns
with time-intervals between successive itemsets. Finally, the discovered
time-interval sequential patterns are reversed again to the original order for
searching the target patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0932</identifier>
 <datestamp>2013-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0932</id><created>2010-09-05</created><updated>2013-01-13</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Huang</keyname><forenames>Yu-Jui</forenames></author></authors><title>On the Multi-Dimensional Controller and Stopper Games</title><categories>math.OC cs.SY math.PR q-fin.GN</categories><comments>Key words: Controller-stopper games, weak dynamic programming
  principle, viscosity solutions, robust optimal stopping, stopping strategies.
  35 pages. Final version. To appear in the SIAM Journal on Control and
  Optimization</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a zero-sum stochastic differential controller-and-stopper game in
which the state process is a controlled diffusion evolving in a
multi-dimensional Euclidean space. In this game, the controller affects both
the drift and the volatility terms of the state process. Under appropriate
conditions, we show that the game has a value and the value function is the
unique viscosity solution to an obstacle problem for a Hamilton-Jacobi-Bellman
equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0938</identifier>
 <datestamp>2013-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0938</id><created>2010-09-05</created><updated>2011-12-16</updated><authors><author><keyname>Garc&#xed;a-Risue&#xf1;o</keyname><forenames>Pablo</forenames></author><author><keyname>Echenique</keyname><forenames>Pablo</forenames></author></authors><title>Linearly scaling direct method for accurately inverting sparse banded
  matrices</title><categories>physics.comp-ph cs.NA</categories><comments>24 pages, 5 figures, submitted to J. Comp. Phys</comments><journal-ref>Journal of Physics A: Mathematical and Theoretical 45 (2012)
  065204</journal-ref><doi>10.1088/1751-8113/45/6/065204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many problems in Computational Physics and Chemistry, one finds a special
kind of sparse matrices, termed &quot;banded matrices&quot;. These matrices, which are
defined as having non-zero entries only within a given distance from the main
diagonal, need often to be inverted in order to solve the associated linear
system of equations. In this work, we introduce a new O(n) algorithm for
solving such a system, being n X n the size of the matrix. We produce the
analytical recursive expressions that allow to directly obtain the solution, as
well as the pseudocode for its computer implementation. Moreover, we review the
different options for possibly parallelizing the method, we describe the
extension to deal with matrices that are banded plus a small number of non-zero
entries outside the band, and we use the same ideas to produce a method for
obtaining the full inverse matrix. Finally, we show that the New Algorithm is
competitive, both in accuracy and in numerical efficiency, when compared to a
standard method based in Gaussian elimination. We do this using sets of large
random banded matrices, as well as the ones that appear when one tries to solve
the 1D Poisson equation by finite differences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0957</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0957</id><created>2010-09-05</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author></authors><title>Distance Measures for Reduced Ordering Based Vector Filters</title><categories>cs.CV</categories><acm-class>I.4.3</acm-class><journal-ref>IET Image Processing 3 (2009) 249-260</journal-ref><doi>10.1049/iet-ipr.2009.0056</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reduced ordering based vector filters have proved successful in removing
long-tailed noise from color images while preserving edges and fine image
details. These filters commonly utilize variants of the Minkowski distance to
order the color vectors with the aim of distinguishing between noisy and
noise-free vectors. In this paper, we review various alternative distance
measures and evaluate their performance on a large and diverse set of images
using several effectiveness and efficiency criteria. The results demonstrate
that there are in fact strong alternatives to the popular Minkowski metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0958</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0958</id><created>2010-09-05</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author></authors><title>Real-Time Implementation of Order-Statistics Based Directional Filters</title><categories>cs.CV</categories><acm-class>I.4.3</acm-class><journal-ref>IET Image Processing 3 (2009) 1-9</journal-ref><doi>10.1049/iet-ipr:20080080</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vector filters based on order-statistics have proved successful in removing
impulsive noise from color images while preserving edges and fine image
details. Among these filters, the ones that involve the cosine distance
function (directional filters) have particularly high computational
requirements, which limits their use in time critical applications. In this
paper, we introduce two methods to speed up these filters. Experiments on a
diverse set of color images show that the proposed methods provide substantial
computational gains without significant loss of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0959</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0959</id><created>2010-09-05</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Kingravi</keyname><forenames>Hassan A.</forenames></author><author><keyname>Lukac</keyname><forenames>Rastislav</forenames></author><author><keyname>Celiker</keyname><forenames>Fatih</forenames></author></authors><title>Cost-Effective Implementation of Order-Statistics Based Vector Filters
  Using Minimax Approximations</title><categories>cs.CV</categories><acm-class>I.4.3</acm-class><journal-ref>Journal of the Optical Society of America A 26 (2009) 1518-1524</journal-ref><doi>10.1364/JOSAA.26.001518</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vector operators based on robust order statistics have proved successful in
digital multichannel imaging applications, particularly color image filtering
and enhancement, in dealing with impulsive noise while preserving edges and
fine image details. These operators often have very high computational
requirements which limits their use in time-critical applications. This paper
introduces techniques to speed up vector filters using the minimax
approximation theory. Extensive experiments on a large and diverse set of color
images show that proposed approximations achieve an excellent balance among
ease of implementation, accuracy, and computational speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0961</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0961</id><created>2010-09-05</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Kingravi</keyname><forenames>Hassan A.</forenames></author><author><keyname>Uddin</keyname><forenames>Bakhtiyar</forenames></author><author><keyname>Aslandogan</keyname><forenames>Y. Alp</forenames></author></authors><title>A Fast Switching Filter for Impulsive Noise Removal from Color Images</title><categories>cs.CV</categories><acm-class>I.4.3</acm-class><journal-ref>Journal of Imaging Science and Technology 51 (2007) 155-165</journal-ref><doi>10.2352/J.ImagingSci.Technol.(2007)51:2(155)</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a fast switching filter for impulsive noise removal
from color images. The filter exploits the HSL color space, and is based on the
peer group concept, which allows for the fast detection of noise in a
neighborhood without resorting to pairwise distance computations between each
pixel. Experiments on large set of diverse images demonstrate that the proposed
approach is not only extremely fast, but also gives excellent results in
comparison to various state-of-the-art filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0962</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0962</id><created>2010-09-05</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Kingravi</keyname><forenames>Hassan A.</forenames></author><author><keyname>Aslandogan</keyname><forenames>Y. Alp</forenames></author></authors><title>Nonlinear Vector Filtering for Impulsive Noise Removal from Color Images</title><categories>cs.CV</categories><acm-class>I.4.3</acm-class><journal-ref>Journal of Electronic Imaging 16 (2007) 033008</journal-ref><doi>10.1117/1.2772639</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a comprehensive survey of 48 filters for impulsive noise
removal from color images is presented. The filters are formulated using a
uniform notation and categorized into 8 families. The performance of these
filters is compared on a large set of images that cover a variety of domains
using three effectiveness and one efficiency criteria. In order to ensure a
fair efficiency comparison, a fast and accurate approximation for the inverse
cosine function is introduced. In addition, commonly used distance measures
(Minkowski, angular, and directional-distance) are analyzed and evaluated.
Finally, suggestions are provided on how to choose a filter given certain
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.0971</identifier>
 <datestamp>2014-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.0971</id><created>2010-09-06</created><authors><author><keyname>Kumar</keyname><forenames>B. Kiran</forenames><affiliation>Department of M.C.A., Kakatiya Institute of Technology &amp; Science, A.P., INDIA</affiliation></author><author><keyname>Bhaskar</keyname><forenames>A.</forenames><affiliation>Department of M.C.A., Kakatiya Institute of Technology &amp; Science, A.P., INDIA</affiliation></author></authors><title>ETP-Mine: An Efficient Method for Mining Transitional Patterns</title><categories>cs.DB</categories><comments>11 pages</comments><journal-ref>International Journal of Database Management Systems (IJDMS) ISSN
  : 0975-5705, August,2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Transaction database contains a set of transactions along with items and
their associated timestamps. Transitional patterns are the patterns which
specify the dynamic behavior of frequent patterns in a transaction database. To
discover transitional patterns and their significant milestones, first we have
to extract all frequent patterns and their supports using any frequent pattern
generation algorithm. These frequent patterns are used in the generation of
transitional patterns. The existing algorithm (TP-Mine) generates frequent
patterns, some of which cannot be used in generation of transitional patterns.
In this paper, we propose a modification to the existing algorithm, which
prunes the candidate items to be used in the generation of frequent patterns.
This method drastically reduces the number of frequent patterns which are used
in discovering transitional patterns. Extensive simulation test is done to
evaluate the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1013</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1013</id><created>2010-09-06</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Iyatomi</keyname><forenames>Hitoshi</forenames></author><author><keyname>Stoecker</keyname><forenames>William V.</forenames></author><author><keyname>Moss</keyname><forenames>Randy H.</forenames></author><author><keyname>Rabinovitz</keyname><forenames>Harold S.</forenames></author><author><keyname>Argenziano</keyname><forenames>Giuseppe</forenames></author><author><keyname>Soyer</keyname><forenames>H. Peter</forenames></author></authors><title>Automatic Detection of Blue-White Veil and Related Structures in
  Dermoscopy Images</title><categories>cs.CV</categories><acm-class>I.4.7; I.4.9</acm-class><journal-ref>Computerized Medical Imaging and Graphics 32 (2008) 670-677</journal-ref><doi>10.1016/j.compmedimag.2008.08.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dermoscopy is a non-invasive skin imaging technique, which permits
visualization of features of pigmented melanocytic neoplasms that are not
discernable by examination with the naked eye. One of the most important
features for the diagnosis of melanoma in dermoscopy images is the blue-white
veil (irregular, structureless areas of confluent blue pigmentation with an
overlying white &quot;ground-glass&quot; film). In this article, we present a machine
learning approach to the detection of blue-white veil and related structures in
dermoscopy images. The method involves contextual pixel classification using a
decision tree classifier. The percentage of blue-white areas detected in a
lesion combined with a simple shape descriptor yielded a sensitivity of 69.35%
and a specificity of 89.97% on a set of 545 dermoscopy images. The sensitivity
rises to 78.20% for detection of blue veil in those cases where it is a primary
feature for melanoma recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1020</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1020</id><created>2010-09-06</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Schaefer</keyname><forenames>Gerald</forenames></author><author><keyname>Iyatomi</keyname><forenames>Hitoshi</forenames></author><author><keyname>Stoecker</keyname><forenames>William V.</forenames></author><author><keyname>Malters</keyname><forenames>Joseph M.</forenames></author><author><keyname>Grichnik</keyname><forenames>James M.</forenames></author></authors><title>An Improved Objective Evaluation Measure for Border Detection in
  Dermoscopy Images</title><categories>cs.CV</categories><acm-class>I.4.6</acm-class><journal-ref>Skin Research and Technology 15 (2009) 444-450</journal-ref><doi>10.1111/j.1600-0846.2009.00387.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Dermoscopy is one of the major imaging modalities used in the
diagnosis of melanoma and other pigmented skin lesions. Due to the difficulty
and subjectivity of human interpretation, dermoscopy image analysis has become
an important research area. One of the most important steps in dermoscopy image
analysis is the automated detection of lesion borders. Although numerous
methods have been developed for the detection of lesion borders, very few
studies were comprehensive in the evaluation of their results. Methods: In this
paper, we evaluate five recent border detection methods on a set of 90
dermoscopy images using three sets of dermatologist-drawn borders as the
ground-truth. In contrast to previous work, we utilize an objective measure,
the Normalized Probabilistic Rand Index, which takes into account the
variations in the ground-truth images. Conclusion: The results demonstrate that
the differences between four of the evaluated border detection methods are in
fact smaller than those predicted by the commonly used XOR measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1031</identifier>
 <datestamp>2013-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1031</id><created>2010-09-06</created><updated>2013-03-12</updated><authors><author><keyname>Migda&#x142;</keyname><forenames>Piotr</forenames></author></authors><title>A mathematical model of the Mafia game</title><categories>math.PR cs.GT physics.soc-ph</categories><comments>12 pages, 4 figures; after corrections</comments><msc-class>60J10 (Primary) 60J28 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Mafia (also called Werewolf) is a party game. The participants are divided
into two competing groups: citizens and a mafia. The objective is to eliminate
the opponent group. The game consists of two consecutive phases (day and night)
and a certain set of actions (e.g. lynching during day). The mafia members have
additional powers (knowing each other, killing during night) whereas the
citizens are more numerous.
  We propose a simple mathematical model of the game, which is essentially a
pure death process with discrete time. We find the closed-form solutions for
the mafia winning-chance, w(n,m), as well as for the evolution of the game.
Moreover, we investigate the discrete properties of results, as well as their
continuous-time approximations.
  It turns out that a relatively small number of the mafia members, i.e.
proportional to the square root of the total number of players, gives equal
winning-chance for both groups. Furthermore, the game strongly depends on the
parity of the total number of players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1038</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1038</id><created>2010-09-06</created><authors><author><keyname>Bania</keyname><forenames>Piotr</forenames></author></authors><title>JIT Spraying and Mitigations</title><categories>cs.CR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the discovery of new exploit techniques, novel protection mechanisms are
needed as well. Mitigations like DEP (Data Execution Prevention) or ASLR
(Address Space Layout Randomization) created a significantly more difficult
environment for exploitation. Attackers, however, have recently researched new
exploitation methods which are capable of bypassing the operating system's
memory mitigations. One of the newest and most popular exploitation techniques
to bypass both of the aforementioned security protections is JIT memory
spraying, introduced by Dion Blazakis. In this article we will present a short
overview of the JIT spraying technique and also novel mitigation methods
against this innovative class of attacks. An anti-JIT spraying library was
created as part of our shellcode execution prevention system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1076</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1076</id><created>2010-09-06</created><updated>2010-09-09</updated><authors><author><keyname>jerome</keyname><forenames>leroux</forenames><affiliation>LABRI, CNRS</affiliation></author></authors><title>The General Vector Addition System Reachability Problem by Presburger
  Inductive Invariants</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  9, 2010) lmcs:1024</journal-ref><doi>10.2168/LMCS-6(3:22)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reachability problem for Vector Addition Systems (VASs) is a central
problem of net theory. The general problem is known to be decidable by
algorithms exclusively based on the classical
Kosaraju-Lambert-Mayr-Sacerdote-Tenney decomposition. This decomposition is
used in this paper to prove that the Parikh images of languages recognized by
VASs are semi-pseudo-linear; a class that extends the semi-linear sets, a.k.a.
the sets definable in Presburger arithmetic. We provide an application of this
result; we prove that a final configuration is not reachable from an initial
one if and only if there exists a semi-linear inductive invariant that contains
the initial configuration but not the final one. Since we can decide if a
Presburger formula denotes an inductive invariant, we deduce that there exist
checkable certificates of non-reachability. In particular, there exists a
simple algorithm for deciding the general VAS reachability problem based on two
semi-algorithms. A first one that tries to prove the reachability by
enumerating finite sequences of actions and a second one that tries to prove
the non-reachability by enumerating Presburger formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1114</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1114</id><created>2010-08-22</created><updated>2010-11-04</updated><authors><author><keyname>Fontanari</keyname><forenames>Jose F.</forenames></author></authors><title>Social interaction as a heuristic for combinatorial optimization
  problems</title><categories>cs.DS physics.comp-ph</categories><journal-ref>Phys. Rev. E 82, 056118 (2010)</journal-ref><doi>10.1103/PhysRevE.82.056118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the performance of a variant of Axelrod's model for
dissemination of culture - the Adaptive Culture Heuristic (ACH) - on solving an
NP-Complete optimization problem, namely, the classification of binary input
patterns of size $F$ by a Boolean Binary Perceptron. In this heuristic, $N$
agents, characterized by binary strings of length $F$ which represent possible
solutions to the optimization problem, are fixed at the sites of a square
lattice and interact with their nearest neighbors only. The interactions are
such that the agents' strings (or cultures) become more similar to the low-cost
strings of their neighbors resulting in the dissemination of these strings
across the lattice. Eventually the dynamics freezes into a homogeneous
absorbing configuration in which all agents exhibit identical solutions to the
optimization problem. We find through extensive simulations that the
probability of finding the optimal solution is a function of the reduced
variable $F/N^{1/4}$ so that the number of agents must increase with the fourth
power of the problem size, $N \propto F^ 4$, to guarantee a fixed probability
of success. In this case, we find that the relaxation time to reach an
absorbing configuration scales with $F^ 6$ which can be interpreted as the
overall computational cost of the ACH to find an optimal set of weights for a
Boolean Binary Perceptron, given a fixed probability of success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1117</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1117</id><created>2010-09-06</created><updated>2010-09-24</updated><authors><author><keyname>Tolone</keyname><forenames>Elsa</forenames><affiliation>LIGM</affiliation></author><author><keyname>Voyatzi</keyname><forenames>Stavroula</forenames><affiliation>LIGM</affiliation></author><author><keyname>Lecl&#xe8;re</keyname><forenames>Christian</forenames><affiliation>LIGM</affiliation></author></authors><title>Constructions d\'efinitoires des tables du Lexique-Grammaire</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>29\`eme Colloque international sur le Lexique et la Grammaire
  (LGC'10), Belgrade : Serbie (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lexicon-Grammar tables are a very rich syntactic lexicon for the French
language. This linguistic database is nevertheless not directly suitable for
use by computer programs, as it is incomplete and lacks consistency. Tables are
defined on the basis of features which are not explicitly recorded in the
lexicon. These features are only described in literature. Our aim is to define
for each tables these essential properties to make them usable in various
Natural Language Processing (NLP) applications, such as parsing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1121</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1121</id><created>2010-09-06</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames></author><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author></authors><title>Analyzing Web 2.0 Integration with Next Generation Networks for Services
  Rendering</title><categories>cs.NI</categories><report-no>International Conferences, NeCoM 2010, India, July 23-25, 2010,
  ISBN: 978-3-642-14492-9</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Next Generation Networks (NGN) aims to integrate for IP-based telecom
infrastructures and provide most advance &amp; high speed emerging value added
services. NGN capable to provide higher innovative services, these services
will able to integrate communication and Web service into a single platform. IP
Multimedia Subsystem, a NGN leading technology, enables a variety of
NGN-compliant communications services to interoperate while being accessed
through different kinds of access networks, preferably broadband. IMS-NGN
services essential by both consumer and corporate users are by now used to
access services, even communications services through the web and web-based
communities and social networks, It is key for success of IMS-based services to
be provided with efficient web access, so users can benefit from those new
services by using web-based applications and user interfaces, not only NGN-IMS
User Equipments and SIP protocol. Many Service are under planning which
provided only under convergence of IMS &amp; Web 2.0. Convergence between Web 2.0
and NGN-IMS creates and serves new invented innovative, entertainment and
information appealing as well as user centric services and applications. These
services merge features from WWW and Communication worlds. On the one hand,
interactivity, ubiquity, social orientation, user participation and content
generation, etc. are relevant characteristics coming from Web 2.0 services.
Parallel IMS enables services including multimedia telephony, media sharing
(video-audio), instant messaging with presence and context, online directory,
etc. all of them applicable to mobile, fixed or convergent telecom networks.
With this paper, this paper brings out the benefits of adopting web 2.0
technologies for telecom services. As the services are today mainly driven by
the user's needs, and proposed the concept of unique customizable service
interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1122</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1122</id><created>2010-09-06</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames></author><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author></authors><title>Design &amp; Deploy Web 2.0 enable services over Next Generation Network
  Platform</title><categories>cs.NI</categories><journal-ref>International Journal of Database Management Systems (IJDMS)
  Vol.2, No.3, August 2010</journal-ref><doi>10.5121/ijdms.2010.2305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Next Generation Networks (NGN) aims to integrate for IP-based telecom
infrastructures and provide most advance &amp; high speed emerging value added
services. NGN capable to provide higher innovative services, these services
will able to integrate communication and Web service into a single platform. IP
Multimedia Subsystem, a NGN leading technology, enables a variety of
NGN-compliant communications services to interoperate while being accessed
through different kinds of access networks, preferably broadband. IMS-NGN
services essential by both consumer and corporate users are by now used to
access services, even communications services through the web and web-based
communities and social networks, It is key for success of IMS-based services to
be provided with efficient web access, so users can benefit from those new
services by using web-based applications and user interfaces, not only NGN-IMS
User Equipments and SIP protocol. Many Service are under planning which
provided only under convergence of IMS &amp; Web 2.0. Convergence between Web 2.0
and NGN-IMS creates and serves new invented innovative, entertainment and
information appealing as well as user centric services and applications. These
services merge features from WWW and Communication worlds. On the one hand,
interactivity, ubiquity, social orientation, user participation and content
generation, etc. are relevant characteristics coming from Web 2.0 services.
Parallel IMS enables services including multimedia telephony, media sharing
(video-audio), instant messaging with presence and context, online directory,
etc. all of them applicable to mobile, fixed or convergent telecom networks.
With this paper, this paper brings out the benefits of adopting web 2.0
technologies for telecom services. As the services are today mainly driven by
the user's needs, and proposed the concept of unique customizable service
interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1128</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1128</id><created>2010-09-06</created><updated>2012-03-14</updated><authors><author><keyname>Mota</keyname><forenames>Jo&#xe3;o F. C.</forenames></author><author><keyname>Xavier</keyname><forenames>Jo&#xe3;o M. F.</forenames></author><author><keyname>Aguiar</keyname><forenames>Pedro M. Q.</forenames></author><author><keyname>P&#xfc;schel</keyname><forenames>Markus</forenames></author></authors><title>Distributed Basis Pursuit</title><categories>math.OC cs.IT cs.SY math.IT</categories><comments>Preprint of the journal version of the paper; IEEE Transactions on
  Signal Processing, Vol. 60, Issue 4, April, 2012</comments><doi>10.1109/TSP.2011.2182347</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We propose a distributed algorithm for solving the optimization problem Basis
Pursuit (BP). BP finds the least L1-norm solution of the underdetermined linear
system Ax = b and is used, for example, in compressed sensing for
reconstruction. Our algorithm solves BP on a distributed platform such as a
sensor network, and is designed to minimize the communication between nodes.
The algorithm only requires the network to be connected, has no notion of a
central processing node, and no node has access to the entire matrix A at any
time. We consider two scenarios in which either the columns or the rows of A
are distributed among the compute nodes. Our algorithm, named D-ADMM, is a
decentralized implementation of the alternating direction method of
multipliers. We show through numerical simulation that our algorithm requires
considerably less communications between the nodes than the state-of-the-art
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1132</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1132</id><created>2010-09-06</created><updated>2010-09-28</updated><authors><author><keyname>Altshuler</keyname><forenames>Yaniv</forenames></author><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Elovici</keyname><forenames>Yuval</forenames></author></authors><title>Efficient Collaborative Application Monitoring Scheme for Mobile
  Networks</title><categories>cs.MA cs.CR cs.DC</categories><comments>19 pages (single colmun) + 9 pages (appendix and references)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New operating systems for mobile devices allow their users to download
millions of applications created by various individual programmers, some of
which may be malicious or flawed. In order to detect that an application is
malicious, monitoring its operation in a real environment for a significant
period of time is often required. Mobile devices have limited computation and
power resources and thus are limited in their monitoring capabilities. In this
paper we propose an efficient collaborative monitoring scheme that harnesses
the collective resources of many mobile devices, &quot;vaccinating&quot; them against
potentially unsafe applications. We suggest a new local information flooding
algorithm called &quot;TTL Probabilistic Propagation&quot; (TPP). The algorithm
periodically monitors one or more application and reports its conclusions to a
small number of other mobile devices, who then propagate this information
onwards. The algorithm is analyzed, and is shown to outperform existing state
of the art information propagation algorithms, in terms of convergence time as
well as network overhead. The maximal &quot;load&quot; of the algorithm (the fastest
arrival rate of new suspicious applications, that can still guarantee complete
monitoring), is analytically calculated and shown to be significantly superior
compared to any non-collaborative approach. Finally, we show both analytically
and experimentally using real world network data that implementing the proposed
algorithm significantly reduces the number of infected mobile devices. In
addition, we analytically prove that the algorithm is tolerant to several types
of Byzantine attacks where some adversarial agents may generate false
information, or abuse the algorithm in other ways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1137</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1137</id><created>2010-09-06</created><authors><author><keyname>KASAI</keyname><forenames>Kenta</forenames></author><author><keyname>AWANO</keyname><forenames>Tomoharu</forenames></author><author><keyname>DECLERCQ</keyname><forenames>David</forenames></author><author><keyname>POULLIAT</keyname><forenames>Charly</forenames></author><author><keyname>SAKANIWA</keyname><forenames>Kohichi</forenames></author></authors><title>Weight Distributions of Multi-Edge type LDPC Codes</title><categories>cs.IT math.IT</categories><comments>To appear in IEICE Trans. Fundamentals, vol.E93-A, no.11 November
  2010</comments><doi>10.1587/transfun.E93.A.1942</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multi-edge type LDPC codes, introduced by Richardson and Urbanke, present
the general class of structured LDPC codes. In this paper, we derive the
average weight distributions of the multi-edge type LDPC code ensembles.
Furthermore, we investigate the asymptotic exponential growth rate of the
average weight distributions and investigate the connection to the stability
condition of the density evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1166</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1166</id><created>2010-09-06</created><updated>2013-02-02</updated><authors><author><keyname>Spivak</keyname><forenames>David I.</forenames></author></authors><title>Functorial Data Migration</title><categories>cs.DB math.CT</categories><comments>30 pages</comments><msc-class>18A99, 94A99, 68P15</msc-class><acm-class>H.2.1; H.5.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we present a simple database definition language: that of
categories and functors. A database schema is a small category and an instance
is a set-valued functor on it. We show that morphisms of schemas induce three
&quot;data migration functors&quot;, which translate instances from one schema to the
other in canonical ways. These functors parameterize projections, unions, and
joins over all tables simultaneously and can be used in place of conjunctive
and disjunctive queries. We also show how to connect a database and a
functional programming language by introducing a functorial connection between
the schema and the category of types for that language. We begin the paper with
a multitude of examples to motivate the definitions, and near the end we
provide a dictionary whereby one can translate database concepts into
category-theoretic concepts and vice-versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1170</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1170</id><created>2010-09-06</created><authors><author><keyname>Mahamad</keyname><forenames>Saipunidzam</forenames></author><author><keyname>Ibrahim</keyname><forenames>Mohammad Noor</forenames></author><author><keyname>Taib</keyname><forenames>Shakirah Mohd</forenames></author></authors><title>M-Learning: A New Paradigm of Learning Mathematics in Malaysia</title><categories>cs.MM cs.CY cs.MS</categories><comments>Wireless technology, teaching mathematics, flexible learning,
  m-Learning</comments><report-no>0810ijcsit07</report-no><acm-class>K.3.1</acm-class><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT) Vol 2 No 4 (2010) pp 76-86</journal-ref><doi>10.5121/ijcsit.2010.2407</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  M-Learning is a new learning paradigm of the new social structure with mobile
and wireless technologies.Smart school is one of the four flagship applications
for Multimedia Super Corridor (MSC) under Malaysian government initiative to
improve education standard in the country. With the advances of mobile devices
technologies, mobile learning could help the government in realizing the
initiative. This paper discusses the prospect of implementing mobile learning
for primary school students. It indicates significant and challenges and
analysis of user perceptions on potential mobile applications through a survey
done in primary school context. The authors propose the m-Learning for
mathematics by allowing the extension of technology in the traditional
classroom in term of learning and teaching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1174</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1174</id><created>2010-09-06</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Parameterized Complexity Results in Symmetry Breaking</title><categories>cs.AI cs.CC</categories><comments>Invited talk at IPEC 2010, 5th International Symposium on
  Parameterized and Exact Computation, December 13-15, 2010, Chennai, India
  http://www.imsc.res.in/ipec</comments><acm-class>I.2.3</acm-class><doi>10.1007/978-3-642-17493-3_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry is a common feature of many combinatorial problems. Unfortunately
eliminating all symmetry from a problem is often computationally intractable.
This paper argues that recent parameterized complexity results provide insight
into that intractability and help identify special cases in which symmetry can
be dealt with more tractably
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1193</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1193</id><created>2010-09-07</created><updated>2010-09-08</updated><authors><author><keyname>Razaghi</keyname><forenames>Peyman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Coarse Network Coding: A Simple Relay Strategy to Resolve Interference</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reminiscent of the parity function in network coding for the butterfly
network, it is shown that forwarding an even/odd indicator bit for a scalar
quantization of a relay observation recovers 1 bit of information at the two
destinations in a noiseless interference channel where interference is treated
as noise. Based on this observation, a coding strategy is proposed to improve
the rate of both users at the same time using a relay node in an interference
channel. In this strategy, the relay observes a linear combination of the two
source signals, and broadcasts a common message to the two destinations over a
shared out-of-band link of rate R0 bits per channel use. The relay message
consists of the bin index of a structured binning scheme obtained from a
2^R0-way partition of the squared lattice in the complex plane. We show that
such scalar quantization-binning relay strategy asymptotically achieves the
cut-set bound in an interference channel with a common out-of-band relay link
of limited rate, improving the sum rate by two bits for every bit relayed,
asymptotically at high signal to noise ratios (SNR) and when interference is
treated as noise. We then use low-density parity-check (LDPC) codes along with
bit-interleaved coded-modulation (BICM) as a practical coding scheme for the
proposed strategy. We consider matched and mismatched scenarios, depending on
whether the input alphabet of the interference signal is known or unknown to
the decoder, respectively. For the matched scenario, we show the proposed
strategy results in significant gains in SNR. For the mismatched scenario, we
show that the proposed strategy results in rate improvements that, without the
relay, cannot be achieved by merely increasing transmit powers. Finally, we use
generalized mutual information analysis to characterize the theoretical
performance of the mismatched scenario and validate our simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1194</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1194</id><created>2010-09-07</created><authors><author><keyname>Babulal</keyname><forenames>Kanojia Sindhuben</forenames></author><author><keyname>Tewari</keyname><forenames>Rajiv Ranjan</forenames></author></authors><title>E2XLRADR (Energy Efficient Cross Layer Routing Algorithm with Dynamic
  Retransmission for Wireless Sensor Networks)</title><categories>cs.NI</categories><journal-ref>http://airccse.org/journal/jwmn/0203ijwmn12.pdf. International
  Journal of Wireless &amp; Mobile Networks ( IJWMN ), Vol.2, No.3, August 2010</journal-ref><doi>10.5121/ijwmn.2010.2312</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main focus of this article is to achieve prolonged network lifetime with
overall energy efficiency in wireless sensor networks through controlled
utilization of limited energy. Major percentage of energy in wireless sensor
network is consumed during routing from source to destination, retransmission
of data on packet loss. For improvement, cross layered algorithm is proposed
for routing and retransmission scheme. Simulation and results shows that this
approach can save the overall energy consumption
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1208</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1208</id><created>2010-09-07</created><updated>2012-10-01</updated><authors><author><keyname>B&#xc3;&#xb6;hler</keyname><forenames>Elmar</forenames><affiliation>Universit&#xe4;t W&#xfc;rzburg</affiliation></author><author><keyname>Creignou</keyname><forenames>Nadia</forenames><affiliation>Universit&#xe9; de la M&#xe9;diterran&#xe9;e, Marseille</affiliation></author><author><keyname>Galota</keyname><forenames>Matthias</forenames><affiliation>Elektrobit</affiliation></author><author><keyname>Reith</keyname><forenames>Steffen</forenames><affiliation>Hochschule RheinMain, Wiesbaden</affiliation></author><author><keyname>Schnoor</keyname><forenames>Henning</forenames><affiliation>Christian-Albrechts-Universit&#xe4;t zu Kiel</affiliation></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames><affiliation>Leibniz Universit&#xe4;t Hannover</affiliation></author></authors><title>Complexity classifications for different equivalence and audit problems
  for Boolean circuits</title><categories>cs.CC</categories><comments>25 pages, 1 figure</comments><proxy>LMCS</proxy><acm-class>F.2.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (September
  30, 2012) lmcs:1172</journal-ref><doi>10.2168/LMCS-8(3:31)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Boolean circuits as a representation of Boolean functions and
consider different equivalence, audit, and enumeration problems. For a number
of restricted sets of gate types (bases) we obtain efficient algorithms, while
for all other gate types we show these problems are at least NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1225</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1225</id><created>2010-09-07</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>A family of sequences with large size and good correlation property
  arising from $M$-ary Sidelnikov sequences of period $q^d-1$</title><categories>cs.IT math.IT</categories><comments>No comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $q$ be any prime power and let $d$ be a positive integer greater than 1.
In this paper, we construct a family of $M$-ary sequences of period $q-1$ from
a given $M$-ary, with $M|q-1$, Sidelikov sequence of period $q^d-1$. Under mild
restrictions on $d$, we show that the maximum correlation magnitude of the
family is upper bounded by $(2d -1) \sqrt { q }+1$ and the asymptotic size, as
$q\rightarrow \infty$, of that is $\frac{ (M-1)q^{d-1}}{d }$. This extends the
pioneering work of Yu and Gong for $d=2$ case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1254</identifier>
 <datestamp>2012-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1254</id><created>2010-09-07</created><updated>2012-08-28</updated><authors><author><keyname>Gatzianas</keyname><forenames>Marios</forenames></author><author><keyname>Georgiadis</keyname><forenames>Leonidas</forenames></author><author><keyname>Tassiulas</keyname><forenames>Leandros</forenames></author></authors><title>Multiuser broadcast erasure channel with feedback - capacity and
  algorithms</title><categories>cs.IT cs.DM math.IT</categories><comments>54 pages, 3 figures, 3 tables, submitted to IEEE Transactions on
  Information Theory. Updated version to match reviewer comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the $N$-user broadcast erasure channel with $N$ unicast sessions
(one for each user) where receiver feedback is regularly sent to the
transmitter in the form of ACK/NACK messages. We first provide a generic outer
bound to the capacity of this system; we then propose a virtual-queue-based
inter-session mixing coding algorithm, determine its rate region and show that
it achieves capacity under certain conditions on channel statistics, assuming
that instantaneous feedback is known to all users. Removing this assumption
results in a rate region that asymptotically differs from the outer bound by 1
bit as $L\to \infty$, where $L$ is the number of bits per packet (packet
length). For the case of arbitrary channel statistics, we present a
modification of the previous algorithm whose rate region is identical to the
outer bound for N=3, when instant feedback is known to all users, and differs
from the bound by 1 bit as $L\to \infty$, when the 3 users know only their own
ACK. The proposed algorithms do not require any prior knowledge of channel
statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1305</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1305</id><created>2010-09-07</created><authors><author><keyname>Mishali</keyname><forenames>Moshe</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Wideband Spectrum Sensing at Sub-Nyquist Rates</title><categories>cs.AR cs.IT math.IT</categories><comments>12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a mixed analog-digital spectrum sensing method that is especially
suited to the typical wideband setting of cognitive radio (CR). The advantages
of our system with respect to current architectures are threefold. First, our
analog front-end is fixed and does not involve scanning hardware. Second, both
the analog-to-digital conversion (ADC) and the digital signal processing (DSP)
rates are substantially below Nyquist. Finally, the sensing resources are
shared with the reception path of the CR, so that the lowrate streaming samples
can be used for communication purposes of the device, besides the sensing
functionality they provide. Combining these advantages leads to a real time map
of the spectrum with minimal use of mobile resources. Our approach is based on
the modulated wideband converter (MWC) system, which samples sparse wideband
inputs at sub-Nyquist rates. We report on results of hardware experiments,
conducted on an MWC prototype circuit, which affirm fast and accurate spectrum
sensing in parallel to CR communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1315</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1315</id><created>2010-09-07</created><updated>2010-09-23</updated><authors><author><keyname>Keszegh</keyname><forenames>Bal&#xe1;zs</forenames></author><author><keyname>Pach</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Drawing planar graphs of bounded degree with few slopes</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We settle a problem of Dujmovi\'c, Eppstein, Suderman, and Wood by showing
that there exists a function $f$ with the property that every planar graph $G$
with maximum degree $d$ admits a drawing with noncrossing straight-line edges,
using at most $f(d)$ different slopes. If we allow the edges to be represented
by polygonal paths with {\em one} bend, then 2d slopes suffice. Allowing {\em
two} bends per edge, every planar graph with maximum degree $d\ge 3$ can be
drawn using segments of at most $\lceil d/2\rceil$ different slopes. There is
only one exception: the graph formed by the edges of an octahedron is
4-regular, yet it requires 3 slopes. These bounds cannot be improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1317</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1317</id><created>2010-07-28</created><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Gautier</keyname><forenames>Thierry</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Pernet</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Saunders</keyname><forenames>B. David</forenames><affiliation>CIS</affiliation></author></authors><title>LinBox founding scope allocation, parallel building blocks, and separate
  compilation</title><categories>cs.SE cs.MS cs.SC</categories><proxy>ccsd</proxy><journal-ref>The Third International Congress on Mathematical Software, Kobe :
  Japan (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To maximize efficiency in time and space, allocations and deallocations, in
the exact linear algebra library \linbox, must always occur in the founding
scope. This provides a simple lightweight allocation model. We present this
model and its usage for the rebinding of matrices between different coefficient
domains. We also present automatic tools to speed-up the compilation of
template libraries and a software abstraction layer for the introduction of
transparent parallelism at the algorithmic level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1341</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1341</id><created>2010-09-07</created><authors><author><keyname>Allen</keyname><forenames>Gabrielle</forenames></author><author><keyname>Goodale</keyname><forenames>Tom</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Frank</forenames></author><author><keyname>Rideout</keyname><forenames>David</forenames></author><author><keyname>Schnetter</keyname><forenames>Erik</forenames></author><author><keyname>Seidel</keyname><forenames>Eric L.</forenames></author></authors><title>Component Specification in the Cactus Framework: The Cactus
  Configuration Language</title><categories>cs.DC cs.PL</categories><comments>10 pages</comments><doi>10.1109/GRID.2010.5698008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Component frameworks are complex systems that rely on many layers of
abstraction to function properly. One essential requirement is a consistent
means of describing each individual component and how it relates to both other
components and the whole framework. As component frameworks are designed to be
flexible by nature, the description method should be simultaneously powerful,
lead to efficient code, and be easy to use, so that new users can quickly adapt
their own code to work with the framework. In this paper, we discuss the Cactus
Configuration Language (CCL) which is used to describe components (&quot;thorns'')
in the Cactus Framework. The CCL provides a description language for the
variables, parameters, functions, scheduling and compilation of a component and
includes concepts such as interface and implementation which allow thorns
providing the same capabilities to be easily interchanged. We include several
application examples which illustrate how community toolkits use the CCL and
Cactus and identify needed additions to the language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1342</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1342</id><created>2010-09-07</created><authors><author><keyname>Seidel</keyname><forenames>Eric L.</forenames></author><author><keyname>Allen</keyname><forenames>Gabrielle</forenames></author><author><keyname>Brandt</keyname><forenames>Steven</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Frank</forenames></author><author><keyname>Schnetter</keyname><forenames>Erik</forenames></author></authors><title>Simplifying Complex Software Assembly: The Component Retrieval Language
  and Implementation</title><categories>cs.PL cs.SE</categories><comments>8 pages, 5 figures, TeraGrid 2010</comments><acm-class>D.2.7; D.3.2</acm-class><doi>10.1145/1838574.1838592</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assembling simulation software along with the associated tools and utilities
is a challenging endeavor, particularly when the components are distributed
across multiple source code versioning systems. It is problematic for
researchers compiling and running the software across many different
supercomputers, as well as for novices in a field who are often presented with
a bewildering list of software to collect and install. In this paper, we
describe a language (CRL) for specifying software components with the details
needed to obtain them from source code repositories. The language supports
public and private access. We describe a tool called GetComponents which
implements CRL and can be used to assemble software. We demonstrate the tool
for application scenarios with the Cactus Framework on the NSF TeraGrid
resources. The tool itself is distributed with an open source license and
freely available from our web page.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1344</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1344</id><created>2010-09-07</created><authors><author><keyname>Toka</keyname><forenames>Laszlo</forenames></author><author><keyname>Dell'Amico</keyname><forenames>Matteo</forenames></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames></author></authors><title>On Scheduling and Redundancy for P2P Backup</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An online backup system should be quick and reliable in both saving and
restoring users' data. To do so in a peer-to-peer implementation, data transfer
scheduling and the amount of redundancy must be chosen wisely. We formalize the
problem of exchanging multiple pieces of data with intermittently available
peers, and we show that random scheduling completes transfers nearly optimally
in terms of duration as long as the system is sufficiently large. Moreover, we
propose an adaptive redundancy scheme that improves performance and decreases
resource usage while keeping the risks of data loss low. Extensive simulations
show that our techniques are effective in a realistic trace-driven scenario
with heterogeneous bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1362</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1362</id><created>2010-09-06</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Iyatomi</keyname><forenames>Hitoshi</forenames></author><author><keyname>Schaefer</keyname><forenames>Gerald</forenames></author><author><keyname>Stoecker</keyname><forenames>William V.</forenames></author></authors><title>Approximate Lesion Localization in Dermoscopy Images</title><categories>cs.CV</categories><acm-class>I.4.6</acm-class><journal-ref>Skin Research and Technology 15 (2009) 314-322</journal-ref><doi>10.1111/j.1600-0846.2009.00357.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Dermoscopy is one of the major imaging modalities used in the
diagnosis of melanoma and other pigmented skin lesions. Due to the difficulty
and subjectivity of human interpretation, automated analysis of dermoscopy
images has become an important research area. Border detection is often the
first step in this analysis. Methods: In this article, we present an
approximate lesion localization method that serves as a preprocessing step for
detecting borders in dermoscopy images. In this method, first the black frame
around the image is removed using an iterative algorithm. The approximate
location of the lesion is then determined using an ensemble of thresholding
algorithms. Results: The method is tested on a set of 428 dermoscopy images.
The localization error is quantified by a metric that uses dermatologist
determined borders as the ground truth. Conclusion: The results demonstrate
that the method presented here achieves both fast and accurate localization of
lesions in dermoscopy images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1373</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1373</id><created>2010-09-07</created><authors><author><keyname>Kawamura</keyname><forenames>Akitoshi</forenames></author></authors><title>Generalized Semimagic Squares for Digital Halftoning</title><categories>cs.CG math.CO</categories><comments>6 pages, 6 figures</comments><msc-class>68U10, 65D18, 97A20</msc-class><acm-class>I.4.1; F.2.2; G.2.1</acm-class><journal-ref>Theory of Computing Systems 49(3):632-638, 2011</journal-ref><doi>10.1007/s00224-010-9290-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Completing Aronov et al.'s study on zero-discrepancy matrices for digital
halftoning, we determine all (m, n, k, l) for which it is possible to put mn
consecutive integers on an m-by-n board (with wrap-around) so that each k-by-l
region holds the same sum. For one of the cases where this is impossible, we
give a heuristic method to find a matrix with small discrepancy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1381</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1381</id><created>2010-09-07</created><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Liedloff</keyname><forenames>Mathieu</forenames></author></authors><title>A Branch-and-Reduce Algorithm for Finding a Minimum Independent
  Dominating Set</title><categories>cs.DS</categories><comments>Full version. A preliminary version appeared in the proceedings of WG
  2006</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An independent dominating set D of a graph G = (V,E) is a subset of vertices
such that every vertex in V \ D has at least one neighbor in D and D is an
independent set, i.e. no two vertices of D are adjacent in G. Finding a minimum
independent dominating set in a graph is an NP-hard problem. Whereas it is hard
to cope with this problem using parameterized and approximation algorithms,
there is a simple exact O(1.4423^n)-time algorithm solving the problem by
enumerating all maximal independent sets. In this paper we improve the latter
result, providing the first non trivial algorithm computing a minimum
independent dominating set of a graph in time O(1.3569^n). Furthermore, we give
a lower bound of \Omega(1.3247^n) on the worst-case running time of this
algorithm, showing that the running time analysis is almost tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1404</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1404</id><created>2010-09-07</created><authors><author><keyname>Lemon</keyname><forenames>Thomas</forenames></author><author><keyname>Ferguson</keyname><forenames>Ewen</forenames></author></authors><title>A Practical Approach to Managing Spreadsheet Risk in a Global Business</title><categories>cs.SE cs.CY</categories><comments>8 pages, 1 diagram; ISBN 978-1-905404-50-6</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 15-22</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets are used extensively within today's organisations. Although
spreadsheets have many benefits, they can also present a significant risk
exposure, requiring appropriate management. Protiviti has worked with a number
of organisations, ranging in size up to huge multi-nationals, to help them
build appropriate spreadsheet governance frameworks, including the design and
implementation of policies, minimum design standards, control processes,
training and awareness programmes and the consideration and implementation of
spreadsheet management tools. This paper presents a case-study explaining the
practical and pragmatic approach that was recently taken to control spreadsheet
risk at one of Protiviti's clients - a global energy firm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1407</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1407</id><created>2010-09-07</created><authors><author><keyname>Dewhurst</keyname><forenames>Sebastian</forenames></author></authors><title>Transforming Critical Spreadsheets into Web Applications at Zurich
  Financial</title><categories>cs.SE cs.CY</categories><comments>10 pages, 6 colour figures; ISBN 978-1-905404-50-6</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 23-32</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the insurance industry, spreadsheets have emerged as an invaluable tool to
for product pricing, because it is relatively straightforward to create and
maintain complex pricing models using Excel. In fact, Excel is often preferred
to &quot;hard-code&quot; whenever there are frequent changes to the calculations and
business logic which under-pin the pricing of an insurance product. However,
problems arise as soon as spreadsheets are deployed to end-users: version
control, security of intellectual property, and ensuring correct usage are
obvious issues; frequently, integration with other systems is also a
requirement. Zurich Financial Services Group is a leading financial services
provider; several possible solutions to these problems have been evaluated, and
EASA has been selected as the preferred technology. Other spreadsheet
collaboration approaches which were considered include Excel Services, and/or
custom-built software; however, EASA has provided clear benefits over these
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1412</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1412</id><created>2010-09-07</created><authors><author><keyname>O'Beirne</keyname><forenames>Patrick</forenames></author></authors><title>Spreadsheet Refactoring</title><categories>cs.SE</categories><comments>14 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 24-32
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Refactoring is a change made to the internal structure of software to make it
easier to understand and cheaper to modify without changing its observable
behaviour. A database refactoring is a small change to the database schema
which improves its design without changing its semantics. This paper presents
example 'spreadsheet refactorings', derived from the above and taking into
account the unique characteristics of spreadsheet formulas and VBA code. The
techniques are constrained by the tightly coupled data and code in
spreadsheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1419</identifier>
 <datestamp>2011-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1419</id><created>2010-09-07</created><updated>2011-09-15</updated><authors><author><keyname>Socolar</keyname><forenames>Joshua E. S.</forenames></author><author><keyname>Taylor</keyname><forenames>Joan M.</forenames></author></authors><title>Forcing nonperiodicity with a single tile</title><categories>math.CO cs.CG math.MG</categories><comments>18 pages, 10 figures. This article has been substantially revised and
  accepted for publication in the Mathematical Intelligencer and is scheduled
  to appear in Vol 33. Citations to and quotations from this work should
  reference that publication. If you cite this work, please check that the
  published form contains precisely the material to which you intend to refer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An aperiodic prototile is a shape for which infinitely many copies can be
arranged to fill Euclidean space completely with no overlaps, but not in a
periodic pattern. Tiling theorists refer to such a prototile as an &quot;einstein&quot;
(a German pun on &quot;one stone&quot;). The possible existence of an einstein has been
pondered ever since Berger's discovery of large set of prototiles that in
combination can tile the plane only in a nonperiodic way. In this article we
review and clarify some features of a prototile we recently introduced that is
an einstein according to a reasonable definition. [This abstract does not
appear in the published article.]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1446</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1446</id><created>2010-09-07</created><authors><author><keyname>Brahma</keyname><forenames>Aseem</forenames></author><author><keyname>Das</keyname><forenames>Sanmay</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Comparing Prediction Market Structures, With an Application to Market
  Making</title><categories>q-fin.TR cs.AI cs.CE</categories><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring sufficient liquidity is one of the key challenges for designers of
prediction markets. Various market making algorithms have been proposed in the
literature and deployed in practice, but there has been little effort to
evaluate their benefits and disadvantages in a systematic manner. We introduce
a novel experimental design for comparing market structures in live trading
that ensures fair comparison between two different microstructures with the
same trading population. Participants trade on outcomes related to a
two-dimensional random walk that they observe on their computer screens. They
can simultaneously trade in two markets, corresponding to the independent
horizontal and vertical random walks. We use this experimental design to
compare the popular inventory-based logarithmic market scoring rule (LMSR)
market maker and a new information based Bayesian market maker (BMM). Our
experiments reveal that BMM can offer significant benefits in terms of price
stability and expected loss when controlling for liquidity; the caveat is that,
unlike LMSR, BMM does not guarantee bounded loss. Our investigation also
elucidates some general properties of market makers in prediction markets. In
particular, there is an inherent tradeoff between adaptability to market shocks
and convergence during market equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1460</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1460</id><created>2010-09-08</created><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Truong</keyname><forenames>Kien T.</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Two-Way Transmission Capacity of Wireless Ad-hoc Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transmission capacity of an ad-hoc network is the maximum density of
active transmitters per unit area, given an outage constraint at each receiver
for a fixed rate of transmission. Most prior work on finding the transmission
capacity of ad-hoc networks has focused only on one-way communication where a
source communicates with a destination and no data is sent from the destination
to the source. In practice, however, two-way or bidirectional data transmission
is required to support control functions like packet acknowledgements and
channel feedback. This paper extends the concept of transmission capacity to
two-way wireless ad-hoc networks by incorporating the concept of a two-way
outage with different rate requirements in both directions. Tight upper and
lower bounds on the two-way transmission capacity are derived for frequency
division duplexing. The derived bounds are used to derive the optimal solution
for bidirectional bandwidth allocation that maximizes the two-way transmission
capacity, which is shown to perform better than allocating bandwidth
proportional to the desired rate in both directions. Using the proposed two-way
transmission capacity framework, a lower bound on the two-way transmission
capacity with transmit beamforming using limited feedback is derived as a
function of bandwidth, and bits allocated for feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1466</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1466</id><created>2010-09-08</created><authors><author><keyname>Salah</keyname><forenames>Alkim Almila Akdag</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Development of the Journal Environment of Leonardo</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present animations based on the aggregated journal-journal citations of
Leonardo during the period 1974-2008. Leonardo is mainly cited by journals
outside the arts domain for cultural reasons, for example, in neuropsychology
and physics. Articles in Leonardo itself cite a large number of journals, but
with a focus on the arts. Animations at this level of aggregation enable us to
show the history of the journal from a network perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1478</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1478</id><created>2010-09-08</created><authors><author><keyname>Devi</keyname><forenames>A. Saradha</forenames></author><author><keyname>Priyadharsini</keyname><forenames>S. Suja</forenames></author><author><keyname>Athinarayanan</keyname><forenames>S.</forenames></author></authors><title>A Block Based Scheme for Enhancing Low Luminated Images</title><categories>cs.MM</categories><comments>13 pages, 5 figures, 2 national conferences</comments><journal-ref>International Journal of Multimedia &amp; Its Applications(IJMA),
  Vol.2, No.3, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the background detection in images in poor lighting can be done
by the use of morphological filters. Lately contrast image enhancement
technique is used to detect the background in image which uses Weber's Law. The
proposed technique is more effective one in which the background detection in
image can be done in color images. The given image obtained in this method is
very effective one. More enhancement can be obtained while comparing the
results. In this technique compressed domain enhancement has been used for
better result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1498</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1498</id><created>2010-09-08</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Mancini</keyname><forenames>Hector</forenames></author><author><keyname>Calbet</keyname><forenames>Xavier</forenames></author></authors><title>A Statistical Measure of Complexity</title><categories>nlin.AO cs.IT math.IT physics.data-an</categories><comments>23 pages, 5 figures, 2 tables; Chapter to appear in the e-Book
  &quot;Recent Advances in Generalized Information Measures and Statistics&quot;,
  Kowalski, Rossignoli &amp; Curado (Eds.), Ed. Bentham Science, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, a statistical measure of complexity is introduced and some
of its properties are discussed. Also, some straightforward applications are
shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1512</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1512</id><created>2010-09-08</created><authors><author><keyname>Bachoc</keyname><forenames>Christine</forenames><affiliation>IMB</affiliation></author></authors><title>Applications of semidefinite programming to coding theory</title><categories>cs.IT math.IT</categories><comments>5 pages; ITW 2010, Dublib : Ireland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey recent generalizations and improvements of the linear programming
method that involve semidefinite programming. A general framework using group
representations and tools from graph theory is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1513</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1513</id><created>2010-09-08</created><updated>2011-04-08</updated><authors><author><keyname>Urfalioglu</keyname><forenames>Onay</forenames></author><author><keyname>Arikan</keyname><forenames>Orhan</forenames></author></authors><title>Artificial Neural Networks, Symmetries and Differential Evolution</title><categories>cs.NE</categories><comments>technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuroevolution is an active and growing research field, especially in times
of increasingly parallel computing architectures. Learning methods for
Artificial Neural Networks (ANN) can be divided into two groups. Neuroevolution
is mainly based on Monte-Carlo techniques and belongs to the group of global
search methods, whereas other methods such as backpropagation belong to the
group of local search methods. ANN's comprise important symmetry properties,
which can influence Monte-Carlo methods. On the other hand, local search
methods are generally unaffected by these symmetries. In the literature,
dealing with the symmetries is generally reported as being not effective or
even yielding inferior results. In this paper, we introduce the so called
Minimum Global Optimum Proximity principle derived from theoretical
considerations for effective symmetry breaking, applied to offline supervised
learning. Using Differential Evolution (DE), which is a popular and robust
evolutionary global optimization method, we experimentally show significant
global search efficiency improvements by symmetry breaking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1526</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1526</id><created>2010-09-08</created><authors><author><keyname>Srivastava</keyname><forenames>Dhruv</forenames></author><author><keyname>Ranjan</keyname><forenames>Dr. Priya</forenames></author></authors><title>An Application-oriented Model for Wireless Sensor Networks integrated
  with Telecom Infra</title><categories>cs.NI</categories><comments>8 pages, 9 figures</comments><report-no>15125</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to propose a significant way of remote access and real time
monitoring of a particular geographic area by integrating wireless sensor
clouds with existing Telecom infrastructure and applications built around them
through a gateway. This utility is very potent for environment monitoring in
harsh and inaccessible places like mines, nuclear reactors, etc. We demonstrate
a scaled down version of multi-hop network of wireless sensor nodes and its
integration with existing telecom network infrastructure via a gateway. The
kind of results achieved like temperature monitoring etc. gives a glimpse of an
enormous step ahead in mine safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1533</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1533</id><created>2010-09-08</created><authors><author><keyname>Rosenblum</keyname><forenames>Kevin</forenames></author><author><keyname>Zelnik-Manor</keyname><forenames>Lihi</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Sensing Matrix Optimization for Block-Sparse Decoding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has demonstrated that using a carefully designed sensing matrix
rather than a random one, can improve the performance of compressed sensing. In
particular, a well-designed sensing matrix can reduce the coherence between the
atoms of the equivalent dictionary, and as a consequence, reduce the
reconstruction error. In some applications, the signals of interest can be well
approximated by a union of a small number of subspaces (e.g., face recognition
and motion segmentation). This implies the existence of a dictionary which
leads to block-sparse representations. In this work, we propose a framework for
sensing matrix design that improves the ability of block-sparse approximation
techniques to reconstruct and classify signals. This method is based on
minimizing a weighted sum of the inter-block coherence and the sub-block
coherence of the equivalent dictionary. Our experiments show that the proposed
algorithm significantly improves signal recovery and classification ability of
the Block-OMP algorithm compared to sensing matrix optimization methods that do
not employ block structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1544</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1544</id><created>2010-09-08</created><authors><author><keyname>Mir</keyname><forenames>Darakhshan</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Nikolov</keyname><forenames>Aleksandar</forenames></author><author><keyname>Wright</keyname><forenames>Rebecca N.</forenames></author></authors><title>Pan-private Algorithms: When Memory Does Not Help</title><categories>cs.CR cs.DS</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider updates arriving online in which the $t$th input is $(i_t,d_t)$,
where $i_t$'s are thought of as IDs of users. Informally, a randomized function
$f$ is {\em differentially private} with respect to the IDs if the probability
distribution induced by $f$ is not much different from that induced by it on an
input in which occurrences of an ID $j$ are replaced with some other ID $k$
Recently, this notion was extended to {\em pan-privacy} where the computation
of $f$ retains differential privacy, even if the internal memory of the
algorithm is exposed to the adversary (say by a malicious break-in or by fiat
by the government). This is a strong notion of privacy, and surprisingly, for
basic counting tasks such as distinct counts, heavy hitters and others, Dwork
et al~\cite{dwork-pan} present pan-private algorithms with reasonable accuracy.
The pan-private algorithms are nontrivial, and rely on sampling. We reexamine
these basic counting tasks and show improved bounds. In particular, we estimate
the distinct count $\Dt$ to within $(1\pm \eps)\Dt \pm O(\polylog m)$, where
$m$ is the number of elements in the universe. This uses suitably noisy
statistics on sketches known in the streaming literature. We also present the
first known lower bounds for pan-privacy with respect to a single intrusion.
Our lower bounds show that, even if allowed to work with unbounded memory,
pan-private algorithms for distinct counts can not be significantly more
accurate than our algorithms. Our lower bound uses noisy decoding. For heavy
hitter counts, we present a pan private streaming algorithm that is accurate to
within $O(k)$ in worst case; previously known bound for this problem is
arbitrarily worse. An interesting aspect of our pan-private algorithms is that,
they deliberately use very small (polylogarithmic) space and tend to be
streaming algorithms, even though using more space is not forbidden.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1560</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1560</id><created>2010-09-08</created><authors><author><keyname>Earl</keyname><forenames>Christopher</forenames></author><author><keyname>Might</keyname><forenames>Matthew</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>Stack-Summarizing Control-Flow Analysis of Higher-Order Programs</title><categories>cs.PL</categories><acm-class>F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two sinks drain precision from higher-order flow analyses: (1) merging of
argument values upon procedure call and (2) merging of return values upon
procedure return. To combat the loss of precision, these two sinks have been
addressed independently. In the case of procedure calls, abstract garbage
collection reduces argument merging; while in the case of procedure returns,
context-free approaches eliminate return value merging. It is natural to expect
a combined analysis could enjoy the mutually beneficial interaction between the
two approaches. The central contribution of this work is a direct product of
abstract garbage collection with context-free analysis. The central challenge
to overcome is the conflict between the core constraint of a pushdown system
and the needs of garbage collection: a pushdown system can only see the top of
the stack, yet garbage collection needs to see the entire stack during a
collection. To make the direct product computable, we develop &quot;stack
summaries,&quot; a method for tracking stack properties at each control state in a
pushdown analysis of higher-order programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1575</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1575</id><created>2010-09-08</created><authors><author><keyname>Fert&#xe9;</keyname><forenames>Julien</forenames></author><author><keyname>Pilaud</keyname><forenames>Vincent</forenames></author><author><keyname>Pocchiola</keyname><forenames>Michel</forenames></author></authors><title>On the number of simple arrangements of five double pseudolines</title><categories>cs.CG math.CO</categories><comments>24 pages, 16 figures, 6 tables</comments><msc-class>52C30, 52A10, 68-04, 68R05</msc-class><journal-ref>Discrete Comput. Geom., 45(2):279-302, 2011</journal-ref><doi>10.1007/s00454-010-9298-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an incremental algorithm to enumerate the isomorphism classes of
double pseudoline arrangements. The correction of our algorithm is based on the
connectedness under mutations of the spaces of one-extensions of double
pseudoline arrangements, proved in this paper. Counting results derived from an
implementation of our algorithm are also reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1596</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1596</id><created>2010-09-08</created><updated>2011-05-04</updated><authors><author><keyname>Mandayam</keyname><forenames>Prabha</forenames></author><author><keyname>Wehner</keyname><forenames>Stephanie</forenames></author></authors><title>Achieving the physical limits of the bounded-storage model</title><categories>quant-ph cs.CR</categories><comments>10 pages (revtex), 2 figures, v2: published version, minor changes</comments><journal-ref>Phys. Rev. A 83, 022329 (2011)</journal-ref><doi>10.1103/PhysRevA.83.022329</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure two-party cryptography is possible if the adversary's quantum storage
device suffers imperfections. For example, security can be achieved if the
adversary can store strictly less then half of the qubits transmitted during
the protocol. This special case is known as the bounded-storage model, and it
has long been an open question whether security can still be achieved if the
adversary's storage were any larger. Here, we answer this question positively
and demonstrate a two-party protocol which is secure as long as the adversary
cannot store even a small fraction of the transmitted pulses. We also show that
security can be extended to a larger class of noisy quantum memories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1604</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1604</id><created>2010-09-08</created><authors><author><keyname>Ko</keyname><forenames>JeongGil</forenames></author><author><keyname>Mishra</keyname><forenames>Amitabh</forenames></author></authors><title>DynaChanAl: Dynamic Channel Allocation with Minimal End-to-end Delay for
  Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With recent advances in wireless communication, networking, and low power
sensor technology, wireless sensor network (WSN) systems have begun to take
significant roles in various applications ranging from environmental sensing to
mobile healthcare sensing. While some WSN applications only require a lim- ited
amount of bandwidth, new emerging applications operate with a notice- ably
large amount of data transfers. One way to deal with such applications is to
maximize the available capacity by utilizing the use of multiple wireless
channels. This work proposes DynaChannAl, a distributed dynamic wireless
channel algorithm with the goal of effectively distributing nodes on multiple
wireless channels in WSN systems. Specifically, DynaChannAl targets applica-
tions where mobile nodes connect to a pre-existing wireless backbone and takes
the expected end-to-end queuing delay as its core metric. We use the link qual-
ity indicator (LQI) values provided by IEEE 802.15.4 radios white-list
potential links with good link quality and evaluate such links with the
aggregated packet transmission latency at each hop. Our approach is useful for
applications that require minimal end-to-end delay (i.e., healthcare
applications). DynaChannAl is a light weight and highly adoptable scheme that
can be easily incorporated with various pre-developed components and
pre-deployed applications. We eval- uate DynaChannAl in on a 45 node WSN
testbed. As the first study to consider end-to-end latency as the core metric
for channel allocation in WSN systems, the experimental results indicate that
DynaChannAl successfully distributes multi- ple (mobile) source nodes on
different wireless channels and enables the nodes to select wireless channel
and links that can minimize the end-to-end latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1605</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1605</id><created>2010-09-08</created><authors><author><keyname>Pilaud</keyname><forenames>Vincent</forenames></author></authors><title>Multitriangulations, pseudotriangulations and some problems of
  realization of polytopes</title><categories>math.CO cs.CG math.MG</categories><comments>PhD thesis; 312 pages, 129 figures; included summaries in french and
  spanish</comments><msc-class>52B05, 52B11, 05C62, 05C35, 68-04, 68R05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis explores two specific topics of discrete geometry, the
multitriangulations and the polytopal realizations of products, whose
connection is the problem of finding polytopal realizations of a given
combinatorial structure.
  A k-triangulation is a maximal set of chords of the convex n-gon such that no
k+1 of them mutually cross. We propose a combinatorial and geometric study of
multitriangulations based on their stars, which play the same role as triangles
of triangulations. This study leads to interpret multitriangulations by duality
as pseudoline arrangements with contact points covering a given support. We
exploit finally these results to discuss some open problems on
multitriangulations, in particular the question of the polytopal realization of
their flip graphs.
  We study secondly the polytopality of Cartesian products. We investigate the
existence of polytopal realizations of cartesian products of graphs, and we
study the minimal dimension that can have a polytope whose k-skeleton is that
of a product of simplices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1635</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1635</id><created>2010-09-08</created><authors><author><keyname>Laumann</keyname><forenames>C. R.</forenames></author><author><keyname>Moessner</keyname><forenames>R.</forenames></author><author><keyname>Scardicchio</keyname><forenames>A.</forenames></author><author><keyname>Sondhi</keyname><forenames>S. L.</forenames></author></authors><title>Statistical mechanics of classical and quantum computational complexity</title><categories>cond-mat.stat-mech cs.CC quant-ph</categories><comments>25 pages, 8 figures. Lecture notes for lectures given by R. Moessner
  at the Les Houches School on &quot;Modern theories of correlated electron
  systems&quot;, May 11-29, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quest for quantum computers is motivated by their potential for solving
problems that defy existing, classical, computers. The theory of computational
complexity, one of the crown jewels of computer science, provides a rigorous
framework for classifying the hardness of problems according to the
computational resources, most notably time, needed to solve them. Its extension
to quantum computers allows the relative power of quantum computers to be
analyzed. This framework identifies families of problems which are likely hard
for classical computers (``NP-complete'') and those which are likely hard for
quantum computers (``QMA-complete'') by indirect methods. That is, they
identify problems of comparable worst-case difficulty without directly
determining the individual hardness of any given instance. Statistical
mechanical methods can be used to complement this classification by directly
extracting information about particular families of instances---typically those
that involve optimization---by studying random ensembles of them. These pose
unusual and interesting (quantum) statistical mechanical questions and the
results shed light on the difficulty of problems for large classes of
algorithms as well as providing a window on the contrast between typical and
worst case complexity. In these lecture notes we present an introduction to
this set of ideas with older work on classical satisfiability and recent work
on quantum satisfiability as primary examples. We also touch on the connection
of computational hardness with the physical notion of glassiness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1685</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1685</id><created>2010-09-09</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author><author><keyname>Sekaran</keyname><forenames>K Chandra</forenames></author></authors><title>Protocols for Bio-Inspired Resource Discovery and Erasure Coded
  Replication in P2P Networks</title><categories>cs.NI</categories><comments>11 pages, 6 figures, INFOCOMP</comments><journal-ref>INFOCOMP Journal of Computer Science, ISSN 1807-4545, Vol. 9, No.
  2, pp. 08-20, June, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient resource discovery and availability improvement are very important
issues in unstructured P2P networks. In this paper, a bio-inspired resource
discovery scheme inspired by the principle of elephants migration is proposed.
A replication scheme based on Q-learning and erasure codes is also introduced.
Simulation results show that the proposed schemes significantly increases query
success rate and availability, and reduces the network traffic as the resources
are effectively distributed to well-performing nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1686</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1686</id><created>2010-09-09</created><updated>2010-09-21</updated><authors><author><keyname>Sridharan</keyname><forenames>Ajay</forenames><affiliation>University of Victoria</affiliation></author><author><keyname>Gao</keyname><forenames>Yong</forenames><affiliation>University of British Columbia</affiliation></author><author><keyname>Wu</keyname><forenames>Kui</forenames><affiliation>University of Victoria</affiliation></author><author><keyname>Nastos</keyname><forenames>James</forenames><affiliation>University of British Columbia</affiliation></author></authors><title>Statistical Behavior of Embeddedness and Communities of Overlapping
  Cliques in Online Social Networks</title><categories>cs.SI physics.soc-ph</categories><acm-class>H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Degree distribution of nodes, especially a power law degree distribution, has
been regarded as one of the most significant structural characteristics of
social and information networks. Node degree, however, only discloses the
first-order structure of a network. Higher-order structures such as the edge
embeddedness and the size of communities may play more important roles in many
online social networks. In this paper, we provide empirical evidence on the
existence of rich higherorder structural characteristics in online social
networks, develop mathematical models to interpret and model these
characteristics, and discuss their various applications in practice. In
particular, 1) We show that the embeddedness distribution of social links in
many social networks has interesting and rich behavior that cannot be captured
by well-known network models. We also provide empirical results showing a clear
correlation between the embeddedness distribution and the average number of
messages communicated between pairs of social network nodes. 2) We formally
prove that random k-tree, a recent model for complex networks, has a power law
embeddedness distribution, and show empirically that the random k-tree model
can be used to capture the rich behavior of higherorder structures we observed
in real-world social networks. 3) Going beyond the embeddedness, we show that a
variant of the random k-tree model can be used to capture the power law
distribution of the size of communities of overlapping cliques discovered
recently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1690</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1690</id><created>2010-09-09</created><updated>2010-10-04</updated><authors><author><keyname>Truyen</keyname><forenames>Tran The</forenames></author><author><keyname>Phung</keyname><forenames>Dinh Q.</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Probabilistic Models over Ordered Partitions with Application in
  Learning to Rank</title><categories>cs.IR stat.ML</categories><comments>19 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the general problem of modelling and learning rank data
with ties. We propose a probabilistic generative model, that models the process
as permutations over partitions. This results in super-exponential
combinatorial state space with unknown numbers of partitions and unknown
ordering among them. We approach the problem from the discrete choice theory,
where subsets are chosen in a stagewise manner, reducing the state space per
each stage significantly. Further, we show that with suitable parameterisation,
we can still learn the models in linear time. We evaluate the proposed models
on the problem of learning to rank with the data from the recently held Yahoo!
challenge, and demonstrate that the models are competitive against well-known
rivals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1691</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1691</id><created>2010-09-09</created><authors><author><keyname>Tao</keyname><forenames>L.</forenames></author><author><keyname>Ramakrishna</keyname><forenames>M.</forenames></author></authors><title>Multi-scale turbulence modeling and maximum information principle. Part
  1</title><categories>physics.flu-dyn cs.IT math.IT</categories><msc-class>76F02, 76F05, 76F55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss averaged turbulence modeling of multi-scales of length for an
incompressible Newtonian fluid, with the help of the maximum information
principle. We suppose that there exists a function basis to decompose the
turbulent fluctuations in a flow of our concern into the components associated
with various spatial scales and that there is a probability density function
$\pdf$ of these fluctuation components. The unbiased form for $\pdf$ is
determined and the turbulence model is closed, with the multi-scale
correlations up to the fourth order, through maximizing the information under
the constraints of equality and inequality for that flow. Due to the
computational difficulty to maximize the information, a closely related but
simple alternative objective is sought, like the determinant or the trace of
the second order correlations of the turbulent flow. Some preliminary results
and implications from the application to homogeneous turbulence are presented.
Some issues yet to be resolved are indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1697</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1697</id><created>2010-09-09</created><authors><author><keyname>Titov</keyname><forenames>Oleg</forenames></author></authors><title>One method of storing information</title><categories>cs.DS</categories><comments>12 pages, article in russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formulate the problem as follows. Split a file into n pieces so that it can
be restored without any m parts (1&lt;=m&lt;=n). Such problems are called problems
secret sharing. There exists a set of methods for solving such problems, but
they all require a fairly large number of calculations applied to the problem
posed above. The proposed method does not require calculations, and requires
only the operations of the division of the file into equal (nearly equal) parts
and gluing them in a certain order in one or more files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1708</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1708</id><created>2010-09-09</created><authors><author><keyname>Violaris</keyname><forenames>George C.</forenames><affiliation>Computer Science Department, University of Nicosia Cyprus</affiliation></author><author><keyname>Mavromoustakis</keyname><forenames>Constandinos X.</forenames><affiliation>Computer Science Department, University of Nicosia Cyprus</affiliation></author></authors><title>On the Performance Evaluation and Analysis of the Hybridised Bittorrent
  Protocol with Partial Mobility Characteristics</title><categories>cs.PF</categories><comments>The Fourth International Conference on Mobile Ubiquitous Computing,
  Systems, Services and Technologies
  http://www.iaria.org/conferences2010/ProgramUBICOMM10.html UBICOMM 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Engaging mobility with file sharing is considered very promising in today's
run Anywhere, Anytime, Anything (3As) environments. The Bittorrent file sharing
protocol can be rarely combined with the mobility scenario framework since
resources are not available due to the dynamically changing topology network.
As a result, mobility in P2P-oriented file sharing platforms, degrades the
end-to-end efficiency and the system's performance. This work proposes a new
hybridized model, which takes into account the mobility characteristics of the
combined Bittorrent protocol in a centralized manner enabling partial mobility
characteristics, where the clients of the network use a distinct technique to
differentiate between mobile and static nodes. Many parameters were taken into
consideration like the round trip delays, the diffusion process, and the
seeding techniques, targeting the maximization of the average throughput in the
clustered swarms containing mobile peers. Partial mobility characteristics are
set in a peer-tracker and peer-peer communication enhancement schema with
partial mobility, allowing an optimistic approach to attain high availability
and throughput response as simulation results show.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1716</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1716</id><created>2010-09-09</created><authors><author><keyname>Mavromoustakis</keyname><forenames>Constandinos X.</forenames><affiliation>Department of Computer Science, University of Nicosia</affiliation></author></authors><title>On the Impact of Caching and a Model for Storage-Capacity Measurements
  for Energy Conservation in Asymmetrical Wireless Devices</title><categories>cs.NI</categories><comments>IEEE Communication Society (COMSOC), 16th International Conference on
  Software, Telecommunications and Computer Networks (SoftCOM 2008), September
  25 &amp; 26 2008, &quot;Dubrovnik&quot;, September 27, Split and Dubrovnik, pp. 243-247</comments><doi>10.1109/SOFTCOM.2008.4669488</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic and channel-data rate combined with the stream oriented methodology
can provide a scheme for offering optimized and guaranteed QoS. In this work a
stream oriented modeled scheme is proposed based on each node's self-scheduling
energy management. This scheme is taking into account the overall packet loss
in order to form the optimal effective -for the end-to-end connection-
throughput response. The scheme also -quantitatively- takes into account the
asymmetrical nature of wireless links and the caching activity that is used for
data revocation in the ad-hoc based connectivity scenario. Through the designed
middleware and the architectural layering and through experimental simulation,
the proposed energy-aware management scheme is thoroughly evaluated in order to
meet the parameters' values where the optimal throughput response for each
device/user is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1720</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1720</id><created>2010-09-09</created><authors><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author></authors><title>Is there a physically universal cellular automaton or Hamiltonian?</title><categories>quant-ph cs.AI</categories><comments>27 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that both quantum and classical cellular automata (CA) exist that
are computationally universal in the sense that they can simulate, after
appropriate initialization, any quantum or classical computation, respectively.
Here we introduce a different notion of universality: a CA is called physically
universal if every transformation on any finite region can be (approximately)
implemented by the autonomous time evolution of the system after the complement
of the region has been initialized in an appropriate way. We pose the question
of whether physically universal CAs exist. Such CAs would provide a model of
the world where the boundary between a physical system and its controller can
be consistently shifted, in analogy to the Heisenberg cut for the quantum
measurement problem. We propose to study the thermodynamic cost of computation
and control within such a model because implementing a cyclic process on a
microsystem may require a non-cyclic process for its controller, whereas
implementing a cyclic process on system and controller may require the
implementation of a non-cyclic process on a &quot;meta&quot;-controller, and so on.
Physically universal CAs avoid this infinite hierarchy of controllers and the
cost of implementing cycles on a subsystem can be described by mixing
properties of the CA dynamics. We define a physical prior on the CA
configurations by applying the dynamics to an initial state where half of the
CA is in the maximum entropy state and half of it is in the all-zero state
(thus reflecting the fact that life requires non-equilibrium states like the
boundary between a hold and a cold reservoir). As opposed to Solomonoff's
prior, our prior does not only account for the Kolmogorov complexity but also
for the cost of isolating the system during the state preparation if the
preparation process is not robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1731</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1731</id><created>2010-09-09</created><updated>2010-09-21</updated><authors><author><keyname>Barigozzi</keyname><forenames>Matteo</forenames></author><author><keyname>Fagiolo</keyname><forenames>Giorgio</forenames></author><author><keyname>Mangioni</keyname><forenames>Giuseppe</forenames></author></authors><title>Identifying the Community Structure of the International-Trade Multi
  Network</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.physa.2011.02.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the community structure of the multi-network of commodity-specific
trade relations among world countries over the 1992-2003 period. We compare
structures across commodities and time by means of the normalized mutual
information index (NMI). We also compare them with exogenous community
structures induced by geographical distances and regional trade agreements. We
find that commodity-specific community structures are very heterogeneous and
much more fragmented than that characterizing the aggregate ITN. This shows
that the aggregate properties of the ITN may result (and be very different)
from the aggregation of very diverse commodity-specific layers of the multi
network. We also show that commodity-specific community structures, especially
those related to the chemical sector, are becoming more and more similar to the
aggregate one. Finally, our findings suggest that geographical distance is much
more correlated with the observed community structure than RTAs. This result
strengthens previous findings from the empirical literature on trade.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1756</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1756</id><created>2010-09-09</created><authors><author><keyname>Varma</keyname><forenames>Girish</forenames></author></authors><title>Conductance and Eigenvalue</title><categories>cs.DM</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We show the following. \begin{theorem} Let $M$ be an finite-state ergodic
time-reversible Markov chain with transition matrix $P$ and conductance $\phi$.
Let $\lambda \in (0,1)$ be an eigenvalue of $P$. Then, $$\phi^2 + \lambda^2
\leq 1$$ \end{theorem} This strengthens the well-known~\cite{HLW,Dod84, AM85,
Alo86, JS89} inequality $\lambda \leq 1- \phi^2/2$. We obtain our result by a
slight variation in the proof method in \cite{JS89, HLW}; the same method was
used earlier in \cite{RS06} to obtain the same inequality for random walks on
regular undirected graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1759</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1759</id><created>2010-09-09</created><authors><author><keyname>Klinc</keyname><forenames>Demijan</forenames></author><author><keyname>Hazay</keyname><forenames>Carmit</forenames></author><author><keyname>Jagmohan</keyname><forenames>Ashish</forenames></author><author><keyname>Krawczyk</keyname><forenames>Hugo</forenames></author><author><keyname>Rabin</keyname><forenames>Tal</forenames></author></authors><title>On Compression of Data Encrypted with Block Ciphers</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates compression of data encrypted with block ciphers,
such as the Advanced Encryption Standard (AES). It is shown that such data can
be feasibly compressed without knowledge of the secret key. Block ciphers
operating in various chaining modes are considered and it is shown how
compression can be achieved without compromising security of the encryption
scheme. Further, it is shown that there exists a fundamental limitation to the
practical compressibility of block ciphers when no chaining is used between
blocks. Some performance results for practical code constructions used to
compress binary sources are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1796</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1796</id><created>2010-09-09</created><authors><author><keyname>Kamaraju</keyname><forenames>M.</forenames></author><author><keyname>Kishore</keyname><forenames>K. Lal</forenames></author><author><keyname>Tilak</keyname><forenames>A. V. N.</forenames></author></authors><title>Power optimized programmable embedded controller</title><categories>cs.AR</categories><comments>11 pages,11 figures,International Journal Publication</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC),Vol.2, No.4, July 2010</journal-ref><doi>10.5121/ijcnc.2010.2409</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now a days, power has become a primary consideration in hardware design, and
is critical in computer systems especially for portable devices with high
performance and more functionality. Clock-gating is the most common technique
used for reducing processor's power. In this work clock gating technique is
applied to optimize the power of fully programmable Embedded Controller (PEC)
employing RISC architecture. The CPU designed supports i) smart instruction
set, ii) I/O port, UART iii) on-chip clocking to provide a range of frequencies
, iv) RISC as well as controller concepts. The whole design is captured using
VHDL and is implemented on FPGA chip using Xilinx .The architecture and clock
gating technique together is found to reduce the power consumption by 33.33% of
total power consumed by this chip.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1833</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1833</id><created>2010-09-09</created><updated>2010-11-18</updated><authors><author><keyname>H&#xe4;nggi</keyname><forenames>Esther</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Device-Independent Quantum Key Distribution with Commuting Measurements</title><categories>quant-ph cs.CR</categories><comments>26 pages. See also the related work arXiv:1009.1567</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider quantum key distribution in the device-independent scenario,
i.e., where the legitimate parties do not know (or trust) the exact
specification of their apparatus. We show how secure key distribution can be
realized against the most general attacks by a quantum adversary under the
condition that measurements on different subsystems by the honest parties
commute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1861</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1861</id><created>2010-09-09</created><updated>2010-12-13</updated><authors><author><keyname>Lovas</keyname><forenames>William</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Pfenning</keyname><forenames>Frank</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>Refinement Types for Logical Frameworks and Their Interpretation as
  Proof Irrelevance</title><categories>cs.PL cs.LO</categories><proxy>LMCS</proxy><acm-class>cs.LO</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  5, 2010) lmcs:1063</journal-ref><doi>10.2168/LMCS-6(4:5)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Refinement types sharpen systems of simple and dependent types by offering
expressive means to more precisely classify well-typed terms. We present a
system of refinement types for LF in the style of recent formulations where
only canonical forms are well-typed. Both the usual LF rules and the rules for
type refinements are bidirectional, leading to a straightforward proof of
decidability of typechecking even in the presence of intersection types.
Because we insist on canonical forms, structural rules for subtyping can now be
derived rather than being assumed as primitive. We illustrate the expressive
power of our system with examples and validate its design by demonstrating a
precise correspondence with traditional presentations of subtyping. Proof
irrelevance provides a mechanism for selectively hiding the identities of terms
in type theories. We show that LF refinement types can be interpreted as
predicates using proof irrelevance, establishing a uniform relationship between
two previously studied concepts in type theory. The interpretation and its
correctness proof are surprisingly complex, lending support to the claim that
refinement types are a fundamental construct rather than just a convenient
surface syntax for certain uses of proof irrelevance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1866</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1866</id><created>2010-09-09</created><updated>2013-12-13</updated><authors><author><keyname>de Berg</keyname><forenames>Mark</forenames></author><author><keyname>Onak</keyname><forenames>Krzysztof</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>Fat Polygonal Partitions with Applications to Visualization and
  Embeddings</title><categories>cs.CG</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{T}$ be a rooted and weighted tree, where the weight of any node
is equal to the sum of the weights of its children. The popular Treemap
algorithm visualizes such a tree as a hierarchical partition of a square into
rectangles, where the area of the rectangle corresponding to any node in
$\mathcal{T}$ is equal to the weight of that node. The aspect ratio of the
rectangles in such a rectangular partition necessarily depends on the weights
and can become arbitrarily high.
  We introduce a new hierarchical partition scheme, called a polygonal
partition, which uses convex polygons rather than just rectangles. We present
two methods for constructing polygonal partitions, both having guarantees on
the worst-case aspect ratio of the constructed polygons; in particular, both
methods guarantee a bound on the aspect ratio that is independent of the
weights of the nodes.
  We also consider rectangular partitions with slack, where the areas of the
rectangles may differ slightly from the weights of the corresponding nodes. We
show that this makes it possible to obtain partitions with constant aspect
ratio. This result generalizes to hyper-rectangular partitions in
$\mathbb{R}^d$. We use these partitions with slack for embedding ultrametrics
into $d$-dimensional Euclidean space: we give a $\mathop{\rm
polylog}(\Delta)$-approximation algorithm for embedding $n$-point ultrametrics
into $\mathbb{R}^d$ with minimum distortion, where $\Delta$ denotes the spread
of the metric, i.e., the ratio between the largest and the smallest distance
between two points. The previously best-known approximation ratio for this
problem was polynomial in $n$. This is the first algorithm for embedding a
non-trivial family of weighted-graph metrics into a space of constant dimension
that achieves polylogarithmic approximation ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1889</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1889</id><created>2010-09-09</created><updated>2010-09-18</updated><authors><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Rathi</keyname><forenames>Yogesh</forenames></author><author><keyname>Dolui</keyname><forenames>Sudipto</forenames></author></authors><title>Spatially regularized compressed sensing of diffusion MRI data</title><categories>cs.IT math.IT physics.med-ph</categories><comments>10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper introduces a method for substantial reduction of the number
of diffusion encoding gradients required for reliable reconstruction of HARDI
signals. The method exploits the theory of compressed sensing (CS), which
establishes conditions on which a signal of interest can be recovered from its
under-sampled measurements, provided that the signal admits a sparse
representation in the domain of a linear transform. In the case at hand, the
latter is defined to be spherical ridgelet transformation, which excels in
sparsifying HARDI signals. What makes the resulting reconstruction procedure
even more accurate is a combination of the sparsity constraints in the
diffusion domain with additional constraints imposed on the estimated diffusion
field in the spatial domain. Accordingly, the present paper describes a novel
way to combine the diffusion- and spatial-domain constraints to achieve a
maximal reduction in the number of diffusion measurements, while sacrificing
little in terms of reconstruction accuracy. Finally, details are provided on a
particularly efficient numerical scheme which can be used to solve the
aforementioned reconstruction problem by means of standard and readily
available estimation tools. The paper is concluded with experimental results
which support the practical value of the proposed reconstruction methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1904</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1904</id><created>2010-09-09</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Tamassia</keyname><forenames>Roberto</forenames></author></authors><title>Privacy-Preserving Data-Oblivious Geometric Algorithms for Geographic
  Data</title><categories>cs.CG cs.DS</categories><comments>19 pages, 5 figures. Extended version of a paper to appear in Proc.
  18th ACM SIGSPATIAL Int. Conf. Advances in Geographic Information Systems
  (ACM GIS 2010), San Jose, California</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give efficient data-oblivious algorithms for several fundamental geometric
problems that are relevant to geographic information systems, including planar
convex hulls and all-nearest neighbors. Our methods are &quot;data-oblivious&quot; in
that they don't perform any data-dependent operations, with the exception of
operations performed inside low-level blackbox circuits having a constant
number of inputs and outputs. Thus, an adversary who observes the control flow
of one of our algorithms, but who cannot see the inputs and outputs to the
blackbox circuits, cannot learn anything about the input or output. This
behavior makes our methods applicable to secure multiparty computation (SMC)
protocols for geographic data used in location-based services. In SMC
protocols, multiple parties wish to perform a computation on their combined
data without revealing individual data to the other parties. For instance, our
methods can be used to solve a problem posed by Du and Atallah, where Alice has
a set, A, of m private points in the plane, Bob has another set, B, of n
private points in the plane, and Alice and Bob want to jointly compute the
convex hull of A u B without disclosing any more information than what can be
derived from the answer. In particular, neither Alice nor Bob want to reveal
any of their respective points that are in the interior of the convex hull of A
u B.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1976</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1976</id><created>2010-09-10</created><authors><author><keyname>Caballero</keyname><forenames>Rafael</forenames></author><author><keyname>Rodr&#xed;guez-Artalejo</keyname><forenames>Mario</forenames></author><author><keyname>Romero-D&#xed;az</keyname><forenames>Carlos A.</forenames></author></authors><title>A Transformation-based Implementation for CLP with Qualification and
  Proximity</title><categories>cs.LO cs.PL</categories><comments>49 pages, 5 figures, 1 table, preliminary version of an article of
  the same title, published as Technical Report SIC-4-10, Universidad
  Complutense, Departamento de Sistemas Inform\'aticos y Computaci\'on, Madrid,
  Spain</comments><report-no>SIC-4-10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncertainty in logic programming has been widely investigated in the last
decades, leading to multiple extensions of the classical LP paradigm. However,
few of these are designed as extensions of the well-established and powerful
CLP scheme for Constraint Logic Programming. In a previous work we have
proposed the SQCLP (proximity-based qualified constraint logic programming)
scheme as a quite expressive extension of CLP with support for qualification
values and proximity relations as generalizations of uncertainty values and
similarity relations, respectively. In this paper we provide a transformation
technique for transforming SQCLP programs and goals into semantically
equivalent CLP programs and goals, and a practical Prolog-based implementation
of some particularly useful instances of the SQCLP scheme. We also illustrate,
by showing some simple-and working-examples, how the prototype can be
effectively used as a tool for solving problems where qualification values and
proximity relations play a key role. Intended use of SQCLP includes flexible
information retrieval applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1977</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1977</id><created>2010-09-10</created><updated>2011-01-14</updated><authors><author><keyname>Rodr&#xed;guez-Artalejo</keyname><forenames>Mario</forenames></author><author><keyname>Romero-D&#xed;az</keyname><forenames>Carlos A.</forenames></author></authors><title>Fixpoint &amp; Proof-theoretic Semantics for CLP with Qualification and
  Proximity</title><categories>cs.LO cs.PL</categories><comments>47 pages, 2 figures, extended version with full proofs of A
  Declarative Semantics for CLP with Qualification and Proximity
  (arXiv:1007.3629). Theory and Practice of Logic Programming, 26th Int'l.
  Conference on Logic Programming (ICLP'10) Special Issue, 10(4-6):627-642,
  2010. Revised definition 2.10, theorem 2.1 &amp; proposition 2.2, results
  unchanged</comments><report-no>SIC-1-10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncertainty in Logic Programming has been investigated during the last
decades, dealing with various extensions of the classical LP paradigm and
different applications. Existing proposals rely on different approaches, such
as clause annotations based on uncertain truth values, qualification values as
a generalization of uncertain truth values, and unification based on proximity
relations. On the other hand, the CLP scheme has established itself as a
powerful extension of LP that supports efficient computation over specialized
domains while keeping a clean declarative semantics. In this report we propose
a new scheme SQCLP designed as an extension of CLP that supports qualification
values and proximity relations. We show that several previous proposals can be
viewed as particular cases of the new scheme, obtained by partial
instantiation. We present a declarative semantics for SQCLP that is based on
observables, providing fixpoint and proof-theoretical characterizations of
least program models as well as an implementation-independent notion of goal
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1983</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1983</id><created>2010-09-10</created><authors><author><keyname>Geetha</keyname><forenames>P.</forenames></author><author><keyname>Narayanan</keyname><forenames>Vasumathi</forenames></author></authors><title>Evolutionary Computational Method of Facial Expression Analysis for
  Content-based Video Retrieval using 2-Dimensional Cellular Automata</title><categories>cs.CV</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-2-issue-2-August-2010</comments><journal-ref>Journal of Computer Science and Engineering, Volume 2, Issue 2,
  p30-39, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Deterministic Cellular Automata (DCA) based video shot
classification and retrieval is proposed. The deterministic 2D Cellular
automata model captures the human facial expressions, both spontaneous and
posed. The determinism stems from the fact that the facial muscle actions are
standardized by the encodings of Facial Action Coding System (FACS) and Action
Units (AUs). Based on these encodings, we generate the set of evolutionary
update rules of the DCA for each facial expression. We consider a
Person-Independent Facial Expression Space (PIFES) to analyze the facial
expressions based on Partitioned 2D-Cellular Automata which capture the
dynamics of facial expressions and classify the shots based on it. Target video
shot is retrieved by comparing the similar expression is obtained for the query
frame's face with respect to the key faces expressions in the database video.
Consecutive key face expressions in the database that are highly similar to the
query frame's face, then the key faces are used to generate the set of
retrieved video shots from the database. A concrete example of its application
which realizes an affective interaction between the computer and the user is
proposed. In the affective interaction, the computer can recognize the facial
expression of any given video shot. This interaction endows the computer with
certain ability to adapt to the user's feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.1990</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.1990</id><created>2010-09-10</created><authors><author><keyname>Thomas</keyname><forenames>Michael</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>Complexity of Non-Monotonic Logics</title><categories>cs.CC cs.AI cs.LO</categories><comments>To appear in Bulletin of the EATCS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past few decades, non-monotonic reasoning has developed to be one of
the most important topics in computational logic and artificial intelligence.
Different ways to introduce non-monotonic aspects to classical logic have been
considered, e.g., extension with default rules, extension with modal belief
operators, or modification of the semantics. In this survey we consider a
logical formalism from each of the above possibilities, namely Reiter's default
logic, Moore's autoepistemic logic and McCarthy's circumscription.
Additionally, we consider abduction, where one is not interested in inferences
from a given knowledge base but in computing possible explanations for an
observation with respect to a given knowledge base.
  Complexity results for different reasoning tasks for propositional variants
of these logics have been studied already in the nineties. In recent years,
however, a renewed interest in complexity issues can be observed. One current
focal approach is to consider parameterized problems and identify reasonable
parameters that allow for FPT algorithms. In another approach, the emphasis
lies on identifying fragments, i.e., restriction of the logical language, that
allow more efficient algorithms for the most important reasoning tasks. In this
survey we focus on this second aspect. We describe complexity results for
fragments of logical languages obtained by either restricting the allowed set
of operators (e.g., forbidding negations one might consider only monotone
formulae) or by considering only formulae in conjunctive normal form but with
generalized clause types.
  The algorithmic problems we consider are suitable variants of satisfiability
and implication in each of the logics, but also counting problems, where one is
not only interested in the existence of certain objects (e.g., models of a
formula) but asks for their number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2000</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2000</id><created>2010-09-10</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>Home Automation</title><categories>cs.OH</categories><comments>In the proceedings of 9th National Research Conference on Management
  and Computer Sciences, SZABIST Institute of Science and Technology, Pakistan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I briefly discuss the importance of home automation system.
Going in to the details I briefly present a real time designed and implemented
software and hardware oriented house automation research project, capable of
automating house's electricity and providing a security system to detect the
presence of unexpected behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2002</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2002</id><created>2010-09-10</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>Aero Fighter - 2D Gaming</title><categories>cs.OH</categories><comments>In the proceedings of 9th National Research Conference on Management
  and Computer Sciences, SZABIST Institute of Science and Technology, Pakistan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing and developing quality based computer game is always a challenging
task for developers. In this paper I briefly discuss aero fighting war game
based on simple 2D gaming concepts and developed in C &amp; C++ programming
languages, using old bitmapping concepts. Going into the details of the game
development, I discuss the designed strategies, flow of game and implemented
prototype version of game, especially for beginners of game programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2003</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2003</id><created>2010-09-10</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>AI 3D Cybug Gaming</title><categories>cs.AI</categories><comments>In the proceedings of 9th National Research Conference on Management
  and Computer Sciences, SZABIST Institute of Science and Technology, Pakistan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short paper I briefly discuss 3D war Game based on artificial
intelligence concepts called AI WAR. Going in to the details, I present the
importance of CAICL language and how this language is used in AI WAR. Moreover
I also present a designed and implemented 3D War Cybug for AI WAR using CAICL
and discus the implemented strategy to defeat its enemies during the game life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2009</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2009</id><created>2010-09-10</created><authors><author><keyname>Truyen</keyname><forenames>Tran The</forenames></author><author><keyname>Phung</keyname><forenames>Dinh Q.</forenames></author><author><keyname>Bui</keyname><forenames>Hung H.</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Hierarchical Semi-Markov Conditional Random Fields for Recursive
  Sequential Data</title><categories>stat.ML cs.AI</categories><comments>56 pages, short version presented at NIPS'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the hierarchical hidden Markov models (HHMM), we present the
hierarchical semi-Markov conditional random field (HSCRF), a generalisation of
embedded undirectedMarkov chains tomodel complex hierarchical, nestedMarkov
processes. It is parameterised in a discriminative framework and has polynomial
time algorithms for learning and inference. Importantly, we consider
partiallysupervised learning and propose algorithms for generalised
partially-supervised learning and constrained inference. We demonstrate the
HSCRF in two applications: (i) recognising human activities of daily living
(ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. We show
that the HSCRF is capable of learning rich hierarchical models with reasonable
accuracy in both fully and partially observed data cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2021</identifier>
 <datestamp>2011-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2021</id><created>2010-09-10</created><updated>2011-09-29</updated><authors><author><keyname>Meliou</keyname><forenames>Alexandra</forenames></author><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Moore</keyname><forenames>Katherine F.</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>The Complexity of Causality and Responsibility for Query Answers and
  non-Answers</title><categories>cs.DB cs.AI</categories><comments>15 pages, 12 figures, PVLDB 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An answer to a query has a well-defined lineage expression (alternatively
called how-provenance) that explains how the answer was derived. Recent work
has also shown how to compute the lineage of a non-answer to a query. However,
the cause of an answer or non-answer is a more subtle notion and consists, in
general, of only a fragment of the lineage. In this paper, we adapt Halpern,
Pearl, and Chockler's recent definitions of causality and responsibility to
define the causes of answers and non-answers to queries, and their degree of
responsibility. Responsibility captures the notion of degree of causality and
serves to rank potentially many causes by their relative contributions to the
effect. Then, we study the complexity of computing causes and responsibilities
for conjunctive queries. It is known that computing causes is NP-complete in
general. Our first main result shows that all causes to conjunctive queries can
be computed by a relational query which may involve negation. Thus, causality
can be computed in PTIME, and very efficiently so. Next, we study computing
responsibility. Here, we prove that the complexity depends on the conjunctive
query and demonstrate a dichotomy between PTIME and NP-complete cases. For the
PTIME cases, we give a non-trivial algorithm, consisting of a reduction to the
max-flow computation problem. Finally, we prove that, even when it is in PTIME,
responsibility is complete for LOGSPACE, implying that, unlike causality, it
cannot be computed by a relational query.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2032</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2032</id><created>2010-09-10</created><authors><author><keyname>Haimovich</keyname><forenames>Hernan</forenames></author><author><keyname>Braslavsky</keyname><forenames>Julio H.</forenames></author></authors><title>Feedback stabilisation of switched systems via iterative approximate
  eigenvector assignment</title><categories>cs.SY math.OC</categories><comments>Extended version of a paper to appear in the 49th IEEE Conference on
  Decision and Control, Atlanta, Georgia, USA, 2010</comments><msc-class>37N35, 93C30, 93C55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents and implements an iterative feedback design algorithm for
stabilisation of discrete-time switched systems under arbitrary switching
regimes. The algorithm seeks state feedback gains so that the closed-loop
switching system admits a common quadratic Lyapunov function (CQLF) and hence
is uniformly globally exponentially stable. Although the feedback design
problem considered can be solved directly via linear matrix inequalities
(LMIs), direct application of LMIs for feedback design does not provide
information on closed-loop system structure. In contrast, the feedback matrices
computed by the proposed algorithm assign closed-loop structure approximating
that required to satisfy Lie-algebraic conditions that guarantee existence of a
CQLF. The main contribution of the paper is to provide, for single-input
systems, a numerical implementation of the algorithm based on iterative
approximate common eigenvector assignment, and to establish cases where such
algorithm is guaranteed to succeed. We include pseudocode and a few numerical
examples to illustrate advantages and limitations of the proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2041</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2041</id><created>2010-09-10</created><authors><author><keyname>Belle</keyname><forenames>Vaishak</forenames></author><author><keyname>Lakemeyer</keyname><forenames>Gerhard</forenames></author></authors><title>Multi-Agent Only-Knowing Revisited</title><categories>cs.AI</categories><comments>Appears in Principles of Knowledge Representation and Reasoning 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Levesque introduced the notion of only-knowing to precisely capture the
beliefs of a knowledge base. He also showed how only-knowing can be used to
formalize non-monotonic behavior within a monotonic logic. Despite its appeal,
all attempts to extend only-knowing to the many agent case have undesirable
properties. A belief model by Halpern and Lakemeyer, for instance, appeals to
proof-theoretic constructs in the semantics and needs to axiomatize validity as
part of the logic. It is also not clear how to generalize their ideas to a
first-order case. In this paper, we propose a new account of multi-agent
only-knowing which, for the first time, has a natural possible-world semantics
for a quantified language with equality. We then provide, for the propositional
fragment, a sound and complete axiomatization that faithfully lifts Levesque's
proof theory to the many agent case. We also discuss comparisons to the earlier
approach by Halpern and Lakemeyer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2054</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2054</id><created>2010-09-10</created><updated>2010-09-13</updated><authors><author><keyname>Yang</keyname><forenames>Bo</forenames></author><author><keyname>Liu</keyname><forenames>Jiming</forenames></author></authors><title>Multiplex Structures: Patterns of Complexity in Real-World Networks</title><categories>cs.SI cs.AI physics.soc-ph</categories><comments>48 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex network theory aims to model and analyze complex systems that consist
of multiple and interdependent components. Among all studies on complex
networks, topological structure analysis is of the most fundamental importance,
as it represents a natural route to understand the dynamics, as well as to
synthesize or optimize the functions, of networks. A broad spectrum of network
structural patterns have been respectively reported in the past decade, such as
communities, multipartites, hubs, authorities, outliers, bow ties, and others.
Here, we show that most individual real-world networks demonstrate multiplex
structures. That is, a multitude of known or even unknown (hidden) patterns can
simultaneously situate in the same network, and moreover they may be overlapped
and nested with each other to collaboratively form a heterogeneous, nested or
hierarchical organization, in which different connective phenomena can be
observed at different granular levels. In addition, we show that the multiplex
structures hidden in exploratory networks can be well defined as well as
effectively recognized within an unified framework consisting of a set of
proposed concepts, models, and algorithms. Our findings provide a strong
evidence that most real-world complex systems are driven by a combination of
heterogeneous mechanisms that may collaboratively shape their ubiquitous
multiplex structures as we observe currently. This work also contributes a
mathematical tool for analyzing different sources of networks from a new
perspective of unveiling multiplex structures, which will be beneficial to
multiple disciplines including sociology, economics and computer science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2077</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2077</id><created>2010-09-10</created><authors><author><keyname>Yang</keyname><forenames>Yang</forenames></author><author><keyname>Zhang</keyname><forenames>Yifu</forenames></author><author><keyname>Xiong</keyname><forenames>Zixiang</forenames></author></authors><title>A new sufficient condition for sum-rate tightness in quadratic Gaussian
  multiterminal source coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the quadratic Gaussian multiterminal (MT) source coding
problem and provides a new sufficient condition for the Berger-Tung sum-rate
bound to be tight. The converse proof utilizes a set of virtual remote sources
given which the MT sources are block independent with a maximum block size of
two. The given MT source coding problem is then related to a set of
two-terminal problems with matrix-distortion constraints, for which a new lower
bound on the sum-rate is given. Finally, a convex optimization problem is
formulated and a sufficient condition derived for the optimal BT scheme to
satisfy the subgradient based Karush-Kuhn-Tucker condition. The set of sum-rate
tightness problems defined by our new sufficient condition subsumes all
previously known tight cases, and opens new direction for a more general
partial solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2084</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2084</id><created>2010-09-10</created><authors><author><keyname>Mas</keyname><forenames>Massimiliano Dal</forenames></author></authors><title>Ontology Temporal Evolution for Multi-Entity Bayesian Networks under
  Exogenous and Endogenous Semantic Updating</title><categories>cs.AI cs.LO</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a challenge for any Knowledge Base reasoning to manage ubiquitous
uncertain ontology as well as uncertain updating times, while achieving
acceptable service levels at minimum computational cost. This paper proposes an
application-independent merging ontologies for any open interaction system. A
solution that uses Multi-Entity Bayesan Networks with SWRL rules, and a Java
program is presented to dynamically monitor Exogenous and Endogenous temporal
evolution on updating merging ontologies on a probabilistic framework for the
Semantic Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2107</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2107</id><created>2010-09-10</created><authors><author><keyname>Meredith</keyname><forenames>L. G.</forenames></author><author><keyname>Snyder</keyname><forenames>David F.</forenames></author></authors><title>Knots as processes: a new kind of invariant</title><categories>math.GT cs.LO</categories><msc-class>57M27, 68Q85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit an encoding of knots into processes in the {\pi}-calculus such
that knots are ambient isotopic if and only their encodings are weakly
bisimilar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2109</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2109</id><created>2010-09-10</created><updated>2010-09-27</updated><authors><author><keyname>Argyriou</keyname><forenames>Evmorfia N.</forenames></author><author><keyname>Bekos</keyname><forenames>Michael A.</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>Maximizing the Total Resolution of Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major factor affecting the readability of a graph drawing is its
resolution. In the graph drawing literature, the resolution of a drawing is
either measured based on the angles formed by consecutive edges incident to a
common node (angular resolution) or by the angles formed at edge crossings
(crossing resolution). In this paper, we evaluate both by introducing the
notion of &quot;total resolution&quot;, that is, the minimum of the angular and crossing
resolution. To the best of our knowledge, this is the first time where the
problem of maximizing the total resolution of a drawing is studied.
  The main contribution of the paper consists of drawings of asymptotically
optimal total resolution for complete graphs (circular drawings) and for
complete bipartite graphs (2-layered drawings). In addition, we present and
experimentally evaluate a force-directed based algorithm that constructs
drawings of large total resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2118</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2118</id><created>2010-09-10</created><updated>2011-05-15</updated><authors><author><keyname>Negahban</keyname><forenames>Sahand</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Restricted strong convexity and weighted matrix completion: Optimal
  bounds with noise</title><categories>cs.IT math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the matrix completion problem under a form of row/column weighted
entrywise sampling, including the case of uniform entrywise sampling as a
special case. We analyze the associated random observation operator, and prove
that with high probability, it satisfies a form of restricted strong convexity
with respect to weighted Frobenius norm. Using this property, we obtain as
corollaries a number of error bounds on matrix completion in the weighted
Frobenius norm under noisy sampling and for both exact and near low-rank
matrices. Our results are based on measures of the &quot;spikiness&quot; and
&quot;low-rankness&quot; of matrices that are less restrictive than the incoherence
conditions imposed in previous work. Our technique involves an $M$-estimator
that includes controls on both the rank and spikiness of the solution, and we
establish non-asymptotic error bounds in weighted Frobenius norm for recovering
matrices lying with $\ell_q$-&quot;balls&quot; of bounded spikiness. Using
information-theoretic methods, we show that no algorithm can achieve better
estimates (up to a logarithmic factor) over these same sets, showing that our
conditions on matrices and associated rates are essentially optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2142</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2142</id><created>2010-09-11</created><authors><author><keyname>Christ</keyname><forenames>Tobias</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author><author><keyname>Stojakovi&#x107;</keyname><forenames>Milo&#x161;</forenames></author></authors><title>Consistent digital line segments</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel and general approach for digitalization of line segments
in the plane that satisfies a set of axioms naturally arising from Euclidean
axioms. In particular, we show how to derive such a system of digital segments
from any total order on the integers. As a consequence, using a well-chosen
total order, we manage to define a system of digital segments such that all
digital segments are, in Hausdorff metric, optimally close to their
corresponding Euclidean segments, thus giving an explicit construction that
resolves the main question of Chun et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2160</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2160</id><created>2010-09-11</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tirsa</keyname><forenames>Eliana-Dina</forenames></author></authors><title>Clustering, Encoding and Diameter Computation Algorithms for
  Multidimensional Data</title><categories>cs.DS cs.CG</categories><comments>ISBN: 978-973-662-574-9</comments><msc-class>65D18, 68W32</msc-class><acm-class>H.3.3; I.3.5</acm-class><journal-ref>Proceedings of the IEEE International Conference on Automation,
  Quality and Testing, Robotics (THETA 17) (AQTR) - Student Forum, Cluj-Napoca,
  Romania, 28-30 May, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present novel algorithms for several multidimensional data
processing problems. We consider problems related to the computation of
restricted clusters and of the diameter of a set of points using a new distance
function. We also consider two string (1D data) processing problems, regarding
an optimal encoding method and the computation of the number of occurrences of
a substring within a string generated by a grammar. The algorithms have been
thoroughly analyzed from a theoretical point of view and some of them have also
been evaluated experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2178</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2178</id><created>2010-09-11</created><authors><author><keyname>Lu</keyname><forenames>Lunjin</forenames></author><author><keyname>Cleary</keyname><forenames>John G.</forenames></author></authors><title>Simplifying Negative Goals Using Typed Existence Properties</title><categories>cs.PL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for extracting positive information from negative goals is proposed.
It makes use of typed existence properties between arguments of a predicate to
rewrite negative goals in a logic program. A typed existence property is a
generalization of functional dependencies in that an input value maps to a
fixed number of output values. Types are used to specify the domains of the
input and output values. An implementation of the simplification method is
presented and its complexity is analyzed. A key algorithm of the implementation
checks if an atom in a negative goal can be extracted using a given typed
existence property. A digraph links an atom to the quantified variables
occurring in the atom and is used to quickly retrieve atoms in the negative
goal that may become extractable after some other atom is extracted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2189</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2189</id><created>2010-09-11</created><authors><author><keyname>Crary</keyname><forenames>Karl</forenames></author><author><keyname>Miculan</keyname><forenames>Marino</forenames></author></authors><title>Proceedings 5th International Workshop on Logical Frameworks and
  Meta-languages: Theory and Practice</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 34, 2010</journal-ref><doi>10.4204/EPTCS.34</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Type theories, logical frameworks and meta-languages form a common foundation
for designing, implementing, and reasoning about formal languages and their
semantics. They are central to the design of modern programming languages,
certified software, and domain specific logics. More generally, they continue
to influence applications in many areas in mathematics, logic and computer
science.
  The Logical Frameworks and Meta-languages: Theory and Practice workshop aims
to bring together designers, implementers, and practitioners working on these
areas, and in particular about: the automation and implementation of the
meta-theory of programming languages and related calculi; the design of proof
assistants, automated theorem provers, and formal digital libraries building
upon logical framework technology; theoretical and practical issues concerning
the encoding of variable binding and fresh name generation, especially the
representation of, and reasoning about, datatypes defined from binding
signatures; case studies of meta-programming, and the mechanization of the
(meta) theory of descriptions of programming languages and other calculi.
  This volume contains the final and revised versions of the papers presented
at LFMTP 2010, which was held on July 14, 2010 in Edinburgh (UK). LFMTP 2010
was part of the Federated Logic Conference (FLoC 2010), and affilated with LICS
2010.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2199</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2199</id><created>2010-09-11</created><updated>2011-07-26</updated><authors><author><keyname>Miller</keyname><forenames>Ezra</forenames></author></authors><title>Affine stratifications from finite mis\`ere quotients</title><categories>math.CO cs.GT math.AC</categories><comments>8 pages; v2: updated references, particularly concerning mesoprimary
  decomposition and counterexample to affine stratification conjecture</comments><msc-class>Primary: 20M14, 20M15, 20M30, 91A46, 91A05, 52B20, Secondary: 05E40,
  20M25, 13F99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a morphism from an affine semigroup Q to an arbitrary commutative
monoid, it is shown that every fiber possesses an affine stratification: a
partition into a finite disjoint union of translates of normal affine
semigroups. The proof rests on mesoprimary decomposition of monoid congruences
[arXiv:1107.4699] and a novel list of equivalent conditions characterizing the
existence of an affine stratification. The motivating consequence of the main
result is a special case of a conjecture due to Guo and the author
[arXiv:0908.3473, arXiv:1105.5420] on the existence of affine stratifications
for (the set of winning positions of) any lattice game. The special case proved
here assumes that the lattice game has finite mis\'ere quotient, in the sense
of Plambeck and Siegel [arXiv:math/0501315, arXiv:math/0609825v5].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2204</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2204</id><created>2010-09-11</created><authors><author><keyname>Brunelle</keyname><forenames>Justin F.</forenames></author><author><keyname>Levinstein</keyname><forenames>Irwin B.</forenames></author><author><keyname>Boonthum</keyname><forenames>Chutima</forenames></author></authors><title>MiBoard: Metacognitive Training Through Gaming in iSTART</title><categories>cs.GT</categories><comments>VMASC Capstone Conference, April 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MiBoard (Multiplayer Interactive Board Game) is an online, turn-based board
game, which is a supplement of the iSTART (Interactive Strategy Training for
Active Reading and Thinking) application. MiBoard is developed to test the
hypothesis that integrating game characteristics (point rewards, game-like
interaction, and peer feedback) into the iSTART trainer will significantly
improve its effectiveness on students' learning. It was shown by M. Rowe that a
physical board game did in fact enhance students' performance. MiBoard is a
computer-based version of Rowe's board game that eliminates constraints on
locality while retaining the crucial practice components that were the game's
objective. MiBoard gives incentives for participation and provides a more
enjoyable and social practice environment compared to the online individual
practice component of the original trainer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2205</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2205</id><created>2010-09-11</created><authors><author><keyname>Brunelle</keyname><forenames>Justin F.</forenames></author><author><keyname>Dempsey</keyname><forenames>Kyle B.</forenames></author><author><keyname>Jackson</keyname><forenames>G. Tanner</forenames></author><author><keyname>Boonthum</keyname><forenames>Chutima</forenames></author><author><keyname>Levinstein</keyname><forenames>Irwin B.</forenames></author><author><keyname>McNamara</keyname><forenames>Danielle S.</forenames></author></authors><title>MiBoard: iSTART Metacognitive Training through Gaming</title><categories>cs.GT</categories><comments>SCiP Conference, November 19th 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MiBoard (Multiplayer Interactive Board Game) is an online, turn-based board
game, which is a supplement of the iSTART (Interactive Strategy Training for
Active Reading and Thinking) application. MiBoard is developed to test the
hypothesis that integrating game characteristics (point rewards, game-like
interaction, and peer feedback) into the iSTART trainer will significantly
improve its effectiveness on students' learning. It was shown by M. Rowe that a
physical board game did in fact enhance students' performance. MiBoard is a
computer-based version of Rowe's board game that eliminates constraints on
locality while retaining the crucial practice components that were the game's
objective. MiBoard gives incentives for participation and provides a more
enjoyable and social practice environment compared to the online individual
practice component of the original trainer
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2206</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2206</id><created>2010-09-11</created><authors><author><keyname>Dempsey</keyname><forenames>Kyle B.</forenames></author><author><keyname>Brunelle</keyname><forenames>Justin F.</forenames></author><author><keyname>Jackson</keyname><forenames>G. Tanner</forenames></author><author><keyname>Boonthum</keyname><forenames>Chutima</forenames></author><author><keyname>Levinstein</keyname><forenames>Irwin B.</forenames></author><author><keyname>McNamara</keyname><forenames>Danielle S.</forenames></author></authors><title>MiBoard: Multiplayer Interactive Board Game</title><categories>cs.CY</categories><comments>14th International Conference on Artificial Intelligence in Education
  (AIED), 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Serious games have recently emerged as an avenue for curriculum delivery.
Serious games incorporate motivation and entertainment while providing pointed
curriculum for the user. This paper presents a serious game, called MiBoard,
currently being developed from the iSTART Intelligent Tutoring System. MiBoard
incorporates a multiplayer interaction that iSTART was previously unable to
provide. This multiplayer interaction produces a wide variation across game
trials, while also increasing the repeat playability for users. This paper
presents a demonstration of the MiBoard system and the expectations for its
application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2207</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2207</id><created>2010-09-11</created><authors><author><keyname>Dempsey</keyname><forenames>Kyle B</forenames></author><author><keyname>Jackson</keyname><forenames>G. Tanner</forenames></author><author><keyname>Brunelle</keyname><forenames>Justin F.</forenames></author><author><keyname>Rowe</keyname><forenames>Michael</forenames></author><author><keyname>McNamara</keyname><forenames>Danielle S.</forenames></author></authors><title>MiBoard: A Digital Game from a Physical World</title><categories>cs.GT</categories><journal-ref>FLAIRS-23, May 22-23 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing user engagement is constant challenge for Intelligent Tutoring
Systems researchers. A current trend in the ITS field is to increase engagement
of proven learning systems by integrating them within games, or adding in game
like components. Incorporating proven learning methods within a game based
environment is expected to add to the overall experience without detracting
from the original goals, however, the current study demonstrates two important
issues with regard to ITS design. First, effective designs from the physical
world do not always translate into the digital world. Second, games do not
necessarily improve engagement, and in some cases, they may have the opposite
effect. The current study discusses the development and a brief assessment of
MiBoard a multiplayer collaborative online board game designed to closely
emulate a previously developed physical board game, iSTART: The Board Game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2208</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2208</id><created>2010-09-11</created><authors><author><keyname>Brunelle</keyname><forenames>Justin F.</forenames></author><author><keyname>Jackson</keyname><forenames>G. Tanner</forenames></author><author><keyname>Dempsey</keyname><forenames>Kyle</forenames></author><author><keyname>Boonthum</keyname><forenames>Chutima</forenames></author><author><keyname>Levinstein</keyname><forenames>Irwin B.</forenames></author><author><keyname>McNamara</keyname><forenames>Danielle S.</forenames></author></authors><title>Gamed-based iSTART Practice: From MiBoard to Self-Explanation Showdown</title><categories>cs.GT</categories><journal-ref>FLAIRS-23, May 22-23 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MiBoard (Multiplayer Interactive Board Game) is an online, turnbased board
game that was developed to assess the integration of game characteristics
(point rewards, game-like interaction, and peer feedback) and how that might
affect student engagement and learning efficacy. This online board game was
designed to fit within the Extended Practice module of iSTART (Interactive
Strategy Training for Active Reading and Thinking). Unfortunately, preliminary
research shows that MiBoard actually reduces engagement and does not benefit
the quality of student self-explanations when compared to the original Extended
Practice module. Consequently the MiBoard framework has been revamped to create
Self-Explanation Showdown, a faster-paced, less analytically oriented game that
adds competition to the creation of self-explanations. Students are evaluated
on the quality of their self-explanations using the same assessment algorithms
from iSTART Extended Practice module (this includes both word-based and
LSA-based assessments). The technical issues involved in development of MiBoard
and Self- Explanation Showdown are described. The lessons learned from the
MiBoard experience are also discussed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2211</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2211</id><created>2010-09-11</created><authors><author><keyname>Wu</keyname><forenames>Xiaodi</forenames></author></authors><title>Parallelized Solution to Semidefinite Programmings in Quantum Complexity
  Theory</title><categories>quant-ph cs.CC</categories><comments>22 pages. Comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an equilibrium value based framework for solving
SDPs via the multiplicative weight update method which is different from the
one in Kale's thesis \cite{Kale07}. One of the main advantages of the new
framework is that we can guarantee the convertibility from approximate to exact
feasibility in a much more general class of SDPs than previous result. Another
advantage is the design of the oracle which is necessary for applying the
multiplicative weight update method is much simplified in general cases. This
leads to an alternative and easier solutions to the SDPs used in the previous
results \class{QIP(2)}$\subseteq$\class{PSPACE} \cite{JainUW09} and
\class{QMAM}=\class{PSPACE} \cite{JainJUW09}. Furthermore, we provide a generic
form of SDPs which can be solved in the similar way. By parallelizing every
step in our solution, we are able to solve a class of SDPs in \class{NC}.
Although our motivation is from quantum computing, our result will also apply
directly to any SDP which satisfies our conditions. In addition to the new
framework for solving SDPs, we also provide a novel framework which improves
the range of equilibrium value problems that can be solved via the
multiplicative weight update method. Before this work we are only able to
calculate the equilibrium value where one of the two convex sets needs to be
the set of density operators. Our work demonstrates that in the case when one
set is the set of density operators with further linear constraints, we are
still able to approximate the equilibrium value to high precision via the
multiplicative weight update method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2216</identifier>
 <datestamp>2014-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2216</id><created>2010-09-12</created><updated>2014-10-20</updated><authors><author><keyname>Aggarwal</keyname><forenames>Amol</forenames></author></authors><title>On Unit Distances in a Convex Polygon</title><categories>cs.CG</categories><comments>7 pages, no figures</comments><journal-ref>Discrete Mathematics 338, 88-92 (2015)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1959, Erd\H{o}s and Moser asked for the maximum number of unit distances
that may be formed among the vertices of a convex $n$-gon; until now, the best
known upper bound has been $2\pi n \log_2 n + O(n)$, achieved by F\&quot;uredi in
1990. In this paper, we examine two properties that any convex polygon must
satisfy and use them to prove several new facts related to the question posed
by Erd\H{o}s and Moser. In particular, we improve on F\&quot;uredi's result, and
instead obtain a bound of $n \log_2 n + O(n)$; we exhibit a class of `cycles'
formed by unit distances that are forbidden in convex polygons; and we provide
a lower bound that shows the limitations of our methods. The second result
addresses a question asked by Fishburn and Reeds regarding the possible
configurations of vertices that form a convex polygon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2218</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2218</id><created>2010-09-12</created><updated>2010-09-15</updated><authors><author><keyname>Aggarwal</keyname><forenames>Amol</forenames></author></authors><title>On Isosceles Triangles and Related Problems in a Convex Polygon</title><categories>cs.CG cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given any convex $n$-gon, in this article, we: (i) prove that its vertices
can form at most $n^2/2 + \Theta(n\log n)$ isosceles trianges with two sides of
unit length and show that this bound is optimal in the first order, (ii)
conjecture that its vertices can form at most $3n^2/4 + o(n^2)$ isosceles
triangles and prove this conjecture for a special group of convex $n$-gons,
(iii) prove that its vertices can form at most $\lfloor n/k \rfloor$ regular
$k$-gons for any integer $k\ge 4$ and that this bound is optimal, and (iv)
provide a short proof that the sum of all the distances between its vertices is
at least $(n-1)/2$ and at most $\lfloor n/2 \rfloor \lceil n/2 \rceil(1/2)$ as
long as the convex $n$-gon has unit perimeter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2221</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2221</id><created>2010-09-12</created><updated>2010-09-14</updated><authors><author><keyname>Ben-Haim</keyname><forenames>Zvika</forenames></author><author><keyname>Michaeli</keyname><forenames>Tomer</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Performance Bounds and Design Criteria for Estimating Finite Rate of
  Innovation Signals</title><categories>cs.IT math.IT</categories><comments>23 pages, 4 figures. Submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of estimating finite rate of
innovation (FRI) signals from noisy measurements, and specifically analyze the
interaction between FRI techniques and the underlying sampling methods. We
first obtain a fundamental limit on the estimation accuracy attainable
regardless of the sampling method. Next, we provide a bound on the performance
achievable using any specific sampling approach. Essential differences between
the noisy and noise-free cases arise from this analysis. In particular, we
identify settings in which noise-free recovery techniques deteriorate
substantially under slight noise levels, thus quantifying the numerical
instability inherent in such methods. This instability, which is only present
in some families of FRI signals, is shown to be related to a specific type of
structure, which can be characterized by viewing the signal model as a union of
subspaces. Finally, we develop a methodology for choosing the optimal sampling
kernels based on a generalization of the Karhunen--Lo\`eve transform. The
results are illustrated for several types of time-delay estimation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2230</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2230</id><created>2010-09-12</created><updated>2011-12-12</updated><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Nain</keyname><forenames>Philippe</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Shwartz</keyname><forenames>Adam</forenames><affiliation>EE-Technion</affiliation></author><author><keyname>Xu</keyname><forenames>Yuedong</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Predicting the Impact of Measures Against P2P Networks on the Transient
  Behaviors</title><categories>cs.NI</categories><comments>IEEE Infocom (2011)</comments><proxy>ccsd</proxy><doi>10.1109/INFCOM.2011.5934931</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper has two objectives. The first is to study rigorously the transient
behavior of some P2P networks whenever information is replicated and
disseminated according to epidemic-like dynamics. The second is to use the
insight gained from the previous analysis in order to predict how efficient are
measures taken against peer-to-peer (P2P) networks. We first introduce a
stochastic model which extends a classical epidemic model and characterize the
P2P swarm behavior in presence of free riding peers. We then study a second
model in which a peer initiates a contact with another peer chosen randomly. In
both cases the network is shown to exhibit a phase transition: a small change
in the parameters causes a large change in the behavior of the network. We
show, in particular, how the phase transition affects measures that content
provider networks may take against P2P networks that distribute non-authorized
music or books, and what is the efficiency of counter-measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2231</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2231</id><created>2010-09-12</created><updated>2010-09-16</updated><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>Symbolic landforms created by ancient earthworks near Lake Titicaca</title><categories>physics.geo-ph cs.GR</categories><comments>Keywords: Satellite maps, Landforms, Artificial landforms,
  Geo-glyphs, Image processing, Archaeology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interesting landforms created by an ancient network of earthworks are shown,
using Google satellite imagery enhanced by an image processing. This network
covers a large part of the land near the Titicaca Lake. Satellite images
clearly display the slopes of hills criss-crossed with terrace walls and the
surfaces of the plains covered with raised fields, indicating that this was
once a highly productive agricultural place for the south central Andes. Some
of the landforms are rather remarkable, having a clear symbolic function. Among
them, there are structures which seem to represent birds, where ponds are their
eyes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2242</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2242</id><created>2010-09-12</created><authors><author><keyname>Houshmand</keyname><forenames>Monireh</forenames></author><author><keyname>Hosseini-Khayat</keyname><forenames>Saied</forenames></author></authors><title>Minimal-memory realization of pearl-necklace encoders of general quantum
  convolutional codes</title><categories>quant-ph cs.DS</categories><comments>16 pages, 5 figures; extends paper arXiv:1004.5179v1</comments><doi>10.1103/PhysRevA.83.022308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum convolutional codes, like their classical counterparts, promise to
offer higher error correction performance than block codes of equivalent
encoding complexity, and are expected to find important applications in
reliable quantum communication where a continuous stream of qubits is
transmitted. Grassl and Roetteler devised an algorithm to encode a quantum
convolutional code with a &quot;pearl-necklace encoder.&quot; Despite their theoretical
significance as a neat way of representing quantum convolutional codes, they
are not well-suited to practical realization. In fact, there is no
straightforward way to implement any given pearl-necklace structure. This paper
closes the gap between theoretical representation and practical implementation.
In our previous work, we presented an efficient algorithm for finding a
minimal-memory realization of a pearl-necklace encoder for
Calderbank-Shor-Steane (CSS) convolutional codes. This work extends our
previous work and presents an algorithm for turning a pearl-necklace encoder
for a general (non-CSS) quantum convolutional code into a realizable quantum
convolutional encoder. We show that a minimal-memory realization depends on the
commutativity relations between the gate strings in the pearl-necklace encoder.
We find a realization by means of a weighted graph which details the
non-commutative paths through the pearl-necklace. The weight of the longest
path in this graph is equal to the minimal amount of memory needed to implement
the encoder. The algorithm has a polynomial-time complexity in the number of
gate strings in the pearl-necklace encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2252</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2252</id><created>2010-09-12</created><authors><author><keyname>Hasan</keyname><forenames>Masud</forenames></author><author><keyname>Hossain</keyname><forenames>Mohammad Monoar</forenames></author><author><keyname>L&#xf3;pez-Ortiz</keyname><forenames>Alejandro</forenames></author><author><keyname>Nusrat</keyname><forenames>Sabrina</forenames></author><author><keyname>Quader</keyname><forenames>Saad Altaful</forenames></author><author><keyname>Rahman</keyname><forenames>Nabila</forenames></author></authors><title>Some New Equiprojective Polyhedra</title><categories>cs.CG cs.DM</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A convex polyhedron $P$ is $k$-equiprojective if all of its orthogonal
projections, i.e., shadows, except those parallel to the faces of $P$ are
$k$-gon for some fixed value of $k$. Since 1968, it is an open problem to
construct all equiprojective polyhedra. Recently, Hasan and Lubiw [CGTA
40(2):148-155, 2008] have given a characterization of equiprojective polyhedra.
Based on their characterization, in this paper we discover some new
equiprojective polyhedra by cutting and gluing existing polyhedra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2259</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2259</id><created>2010-09-12</created><authors><author><keyname>Mironov</keyname><forenames>Andrew M.</forenames></author></authors><title>Theory of processes</title><categories>cs.LO</categories><comments>290 pages</comments><msc-class>68Q60</msc-class><acm-class>D.2.4; C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The book gives a detailed exposition of basic concepts and results of a
theory of processes. The presentation of theoretical concepts and results is
accompanied with illustrations of their application to solving various problems
of verification of processes. Along with well-known results there are presented
author's results related to verification of processes with message passing, and
there are given examples of an application of these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2270</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2270</id><created>2010-09-12</created><authors><author><keyname>Caroprese</keyname><forenames>L.</forenames></author><author><keyname>Truszczynski</keyname><forenames>M.</forenames></author></authors><title>Active Integrity Constraints and Revision Programming</title><categories>cs.DB</categories><comments>48 pages, 3 figures</comments><msc-class>68P15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study active integrity constraints and revision programming, two
formalisms designed to describe integrity constraints on databases and to
specify policies on preferred ways to enforce them. Unlike other more commonly
accepted approaches, these two formalisms attempt to provide a declarative
solution to the problem. However, the original semantics of founded repairs for
active integrity constraints and justified revisions for revision programs
differ. Our main goal is to establish a comprehensive framework of semantics
for active integrity constraints, to find a parallel framework for revision
programs, and to relate the two. By doing so, we demonstrate that the two
formalisms proposed independently of each other and based on different
intuitions when viewed within a broader semantic framework turn out to be
notational variants of each other. That lends support to the adequacy of the
semantics we develop for each of the formalisms as the foundation for a
declarative approach to the problem of database update and repair. In the paper
we also study computational properties of the semantics we consider and
establish results concerned with the concept of the minimality of change and
the invariance under the shifting transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2274</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2274</id><created>2010-09-12</created><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Robust Beamforming for Security in MIMO Wiretap Channels with Imperfect
  CSI</title><categories>cs.IT math.IT</categories><comments>10 pages, 5 figures; to appear, IEEE Transactions on Signal
  Processing, 2010</comments><doi>10.1109/TSP.2010.2078810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate methods for reducing the likelihood that a
message transmitted between two multiantenna nodes is intercepted by an
undetected eavesdropper. In particular, we focus on the judicious transmission
of artificial interference to mask the desired signal at the time it is
broadcast. Unlike previous work that assumes some prior knowledge of the
eavesdropper's channel and focuses on maximizing secrecy capacity, we consider
the case where no information regarding the eavesdropper is available, and we
use signal-to-interference-plus-noise-ratio (SINR) as our performance metric.
Specifically, we focus on the problem of maximizing the amount of power
available to broadcast a jamming signal intended to hide the desired signal
from a potential eavesdropper, while maintaining a prespecified SINR at the
desired receiver. The jamming signal is designed to be orthogonal to the
information signal when it reaches the desired receiver, assuming both the
receiver and the eavesdropper employ optimal beamformers and possess exact
channel state information (CSI). In practice, the assumption of perfect CSI at
the transmitter is often difficult to justify. Therefore, we also study the
resulting performance degradation due to the presence of imperfect CSI, and we
present robust beamforming schemes that recover a large fraction of the
performance in the perfect CSI case. Numerical simulations verify our
analytical performance predictions, and illustrate the benefit of the robust
beamforming schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2275</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2275</id><created>2010-09-12</created><authors><author><keyname>Le</keyname><forenames>Anh</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Faloutsos</keyname><forenames>Michalis</forenames></author></authors><title>PhishDef: URL Names Say It All</title><categories>cs.CR cs.LG cs.NI</categories><comments>9 pages, submitted to IEEE INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phishing is an increasingly sophisticated method to steal personal user
information using sites that pretend to be legitimate. In this paper, we take
the following steps to identify phishing URLs. First, we carefully select
lexical features of the URLs that are resistant to obfuscation techniques used
by attackers. Second, we evaluate the classification accuracy when using only
lexical features, both automatically and hand-selected, vs. when using
additional features. We show that lexical features are sufficient for all
practical purposes. Third, we thoroughly compare several classification
algorithms, and we propose to use an online method (AROW) that is able to
overcome noisy training data. Based on the insights gained from our analysis,
we propose PhishDef, a phishing detection system that uses only URL names and
combines the above three elements. PhishDef is a highly accurate method (when
compared to state-of-the-art approaches over real datasets), lightweight (thus
appropriate for online and client-side deployment), proactive (based on online
classification rather than blacklists), and resilient to training data
inaccuracies (thus enabling the use of large noisy training data).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2282</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2282</id><created>2010-09-12</created><authors><author><keyname>Luo</keyname><forenames>Jun</forenames></author></authors><title>SNAP: SNowbAll multi-tree Pushing for Peer-to-Peer Media Streaming</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the respective advantages of the two complimentary techniques for
peer-to-peer media streaming (namely tree-based push and mesh-based pull),
there is a strong trend of combining them into a hybrid streaming system.
Backed by recently proposed mechanisms to identify stable peers, such a hybrid
system usually consists of backbone trees formed by the stable peers and other
overlay structures in the second tier to accommodate the remaining peers. In
this paper, we embrace the hybrid push-pull structure for peer-to-peer media
streaming. Our protocol is dominated by a multi-tree push mechanism to minimize
the delay in the backbone and is complemented by other overlay structures to
cope with peer dynamics. What mainly distinguishes our multi-tree pushing from
the conventional ones is an unbalanced tree design guided by the so called
snow-ball streaming, which has a provable minimum delay and can be smoothly
&quot;melded&quot; with virtually any other existing overlay structures lying in the
second tier. We design algorithms to construct and maintain our SNowbAll
multi-tree Pushing (SNAP) overlay, and we also illustrate how to smoothly weld
the SNAP backbone with the second tier. Finally, we perform simulations in
ns-2; the results indicate that our approach outperforms a recently proposed
hybrid streaming system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2287</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2287</id><created>2010-09-12</created><authors><author><keyname>Privman</keyname><forenames>Vladimir</forenames></author><author><keyname>Halamek</keyname><forenames>Jan</forenames></author><author><keyname>Arugula</keyname><forenames>Mary A.</forenames></author><author><keyname>Melnikov</keyname><forenames>Dmitriy</forenames></author><author><keyname>Bocharova</keyname><forenames>Vera</forenames></author><author><keyname>Katz</keyname><forenames>Evgeny</forenames></author></authors><title>Biochemical Filter with Sigmoidal Response: Increasing the Complexity of
  Biomolecular Logic</title><categories>physics.bio-ph cond-mat.soft cs.OH physics.chem-ph q-bio.MN</categories><comments>24 pages, PDF</comments><journal-ref>J. Phys. Chem. B 114, 14103-14109 (2010)</journal-ref><doi>10.1021/jp108693m</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first realization of a designed, rather than natural, biochemical filter
process is reported and analyzed as a promising network component for
increasing the complexity of biomolecular logic systems. Key challenge in
biochemical logic research has been achieving scalability for complex network
designs. Various logic gates have been realized, but a &quot;toolbox&quot; of analog
elements for interconnectivity and signal processing has remained elusive.
Filters are important as network elements that allow control of noise in signal
transmission and conversion. We report a versatile biochemical filtering
mechanism designed to have sigmoidal response in combination with
signal-conversion process. Horseradish peroxidase-catalyzed oxidation of
chromogenic electron donor by hydrogen peroxide, was altered by adding
ascorbate, allowing to selectively suppress the output signal, modifying the
response from convex to sigmoidal. A kinetic model was developed for evaluation
of the quality of filtering. The results offer improved capabilities for design
of scalable biomolecular information processing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2305</identifier>
 <datestamp>2013-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2305</id><created>2010-09-13</created><updated>2013-02-11</updated><authors><author><keyname>Shi</keyname><forenames>Xiangqiong</forenames></author><author><keyname>Schonfeld</keyname><forenames>Dan</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>Message Error Analysis of Loopy Belief Propagation for the Sum-Product
  Algorithm</title><categories>cs.IT math.IT</categories><comments>36 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Belief propagation is known to perform extremely well in many practical
statistical inference and learning problems using graphical models, even in the
presence of multiple loops. The iterative use of belief propagation algorithm
on loopy graphs is referred to as Loopy Belief Propagation (LBP). Various
sufficient conditions for convergence of LBP have been presented; however,
general necessary conditions for its convergence to a unique fixed point remain
unknown. Because the approximation of beliefs to true marginal probabilities
has been shown to relate to the convergence of LBP, several methods have been
explored whose aim is to obtain distance bounds on beliefs when LBP fails to
converge. In this paper, we derive uniform and non-uniform error bounds on
messages, which are tighter than existing ones in literature, and use these
bounds to derive sufficient conditions for the convergence of LBP in terms of
the sum-product algorithm. We subsequently use these bounds to study the
dynamic behavior of the sum-product algorithm, and analyze the relation between
convergence of LBP and sparsity and walk-summability of graphical models. We
finally use the bounds derived to investigate the accuracy of LBP, as well as
the scheduling priority in asynchronous LBP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2307</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2307</id><created>2010-09-13</created><updated>2011-05-10</updated><authors><author><keyname>Huang</keyname><forenames>Hao</forenames></author><author><keyname>Lee</keyname><forenames>Choongbum</forenames></author></authors><title>Quasi-randomness of graph balanced cut properties</title><categories>math.CO cs.DM</categories><comments>20 pages, 1 figures</comments><msc-class>05C80</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Quasi-random graphs can be informally described as graphs whose edge
distribution closely resembles that of a truly random graph of the same edge
density. Recently, Shapira and Yuster proved the following result on
quasi-randomness of graphs. Let $k \ge 2$ be a fixed integer,
$\alpha_1,...,\alpha_k$ be positive reals satisfying $\sum_{i} \alpha_i = 1$
and $(\alpha_1,..., \alpha_k) \neq (1/k,...,1/k)$, and $G$ be a graph on $n$
vertices. If for every partition of the vertices of $G$ into sets $V_1,...,
V_k$ of size $\alpha_1 n,..., \alpha_k n$, the number of complete graphs on $k$
vertices which have exactly one vertex in each of these sets is similar to what
we would expect in a random graph, then the graph is quasi-random. However, the
method of quasi-random hypergraphs they used did not provide enough information
to resolve the case $(1/k,..., 1/k)$ for graphs. In their work, Shapira and
Yuster asked whether this case also forces the graph to be quasi-random. Janson
also posed the same question in his study of quasi-randomness under the
framework of graph limits. In this paper, we positively answer their question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2314</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2314</id><created>2010-09-13</created><authors><author><keyname>Prasad</keyname><forenames>Ajay</forenames></author><author><keyname>Chaurasia</keyname><forenames>Sandeep</forenames></author><author><keyname>Singh</keyname><forenames>Arjun</forenames></author><author><keyname>Gour</keyname><forenames>Deepak</forenames></author></authors><title>Mapping Cloud Computing onto Useful e-Governance</title><categories>cs.DC</categories><journal-ref>&quot;Mapping Cloud Computing onto Useful e-Governance&quot;; International
  Journal of Computer Science and Information Security (IJCSIS), Vol. 8, No. 5,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the services viewed in context to grid and cloud computing are mostly
confined to services that are available for intellectual purposes. The grid or
cloud computing are large scale distributed systems. The essence of large scale
distribution can only be realized if the services are rendered to common man.
The only organization which has exposure to almost every single resident is the
respective governments in every country. As the size of population increases so
the need for a larger purview arises. The problem of having a large purview can
be solved by means of large scale grid for online services. The government
services can be rendered through fully customized Service-oriented Clouds. In
this paper we are presenting tight similarities between generic government
functioning and the service oriented grid/cloud approach. Also, we will discuss
the major issues in establishing services oriented grids for governmental
organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2322</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2322</id><created>2010-09-13</created><authors><author><keyname>Chan</keyname><forenames>Joseph Wun-Tat</forenames></author><author><keyname>Chin</keyname><forenames>Francis Y. L.</forenames></author><author><keyname>Han</keyname><forenames>Xin</forenames></author><author><keyname>Lam</keyname><forenames>Ka-Cheong</forenames></author><author><keyname>Ting</keyname><forenames>Hing-Fung</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author></authors><title>Deterministic Online Call Control in Cellular Networks and Triangle-Free
  Cellular Networks</title><categories>cs.DS</categories><comments>12 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Wireless Communication Networks based on Frequency Division Multiplexing (FDM
in short) plays an important role in the field of communications, in which each
request can be satisfied by assigning a frequency. To avoid interference, each
assigned frequency must be different to the neighboring assigned frequencies.
Since frequency is a scarce resource, the main problem in wireless networks is
how to fully utilize the given bandwidth of frequencies. In this paper, we
consider the online call control problem. Given a fixed bandwidth of
frequencies and a sequence of communication requests arrive over time, each
request must be either satisfied immediately after its arrival by assigning an
available frequency, or rejected. The objective of call control problem is to
maximize the number of accepted requests. We study the asymptotic performance
of this problem, i.e., the number of requests in the sequence and the bandwidth
of frequencies are very large. In this paper, we give a 7/3-competitive
algorithm for call control problem in cellular network, improving the previous
2.5-competitive result. Moreover, we investigate the triangle-free cellular
network, propose a 9/4-competitive algorithm and prove that the lower bound of
competitive ratio is at least 5/3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2363</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2363</id><created>2010-09-13</created><updated>2010-10-16</updated><authors><author><keyname>Husfeldt</keyname><forenames>Thore</forenames></author><author><keyname>Taslaman</keyname><forenames>Nina</forenames></author></authors><title>The Exponential Time Complexity of Computing the Probability That a
  Graph is Connected</title><categories>cs.CC</categories><comments>To appear in 5th International Symposium on Parameterized and Exact
  Computation (IPEC 2010), December 13-15, 2010, Chennai, India, Springer LNCS,
  2010</comments><doi>10.1007/978-3-642-17493-3_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for every probability p with 0 &lt; p &lt; 1, computation of
all-terminal graph reliability with edge failure probability p requires time
exponential in Omega(m/ log^2 m) for simple graphs of m edges under the
Exponential Time Hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2368</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2368</id><created>2010-09-13</created><authors><author><keyname>Chowdhury</keyname><forenames>Mostafa Zaman</forenames></author><author><keyname>Jang</keyname><forenames>Yeong Min</forenames></author><author><keyname>Haas</keyname><forenames>Zygmunt J.</forenames></author></authors><title>Network evolution and QOS provisioning for integrated
  femtocell/macrocell networks</title><categories>cs.NI cs.MM</categories><comments>16 pages, 10 figures, Published in International Journal of Wireless
  &amp; Mobile Networks (IJWMN)</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN),
  Vol.2, No.3, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrated femtocell/macrocell networks, comprising a conventional cellular
network overlaid with femtocells, offer an economically appealing way to
improve coverage, quality of service, and access network capacity. The key
element to successful femtocells/macrocell integration lies in its
self-organizing capability. Provisioning of quality of service is the main
technical challenge of the femtocell/macrocell integrated networks, while the
main administrative challenge is the choice of the proper evolutionary path
from the existing macrocellular networks to the integrated network. In this
article, we introduce three integrated network architectures which, while
increasing the access capacity, they also reduce the deployment and operational
costs. Then, we discuss a number of technical issues, which are key to making
such integration a reality, and we offer possible approaches to their solution.
These issues include efficient frequency and interference management, quality
of service provisioning of the xDSL-based backhaul networks, and intelligent
handover control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2370</identifier>
 <datestamp>2012-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2370</id><created>2010-09-13</created><updated>2012-05-28</updated><authors><author><keyname>Andriyanova</keyname><forenames>Iryna</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Optimized IR-HARQ Schemes Based on Punctured LDPC Codes over the BEC</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study incremental redundancy hybrid ARQ (IR-HARQ) schemes based on
punctured, finite-length, LDPC codes. The transmission is assumed to take place
over time varying binary erasure channels, such as mobile wireless channels at
the applications layer. We analyze and optimize the throughput and delay
performance of these IR-HARQ protocols under iterative, message-passing
decoding. We derive bounds on the performance that are achievable by such
schemes, and show that, with a simple extension, the iteratively decoded,
punctured LDPC code based IR-HARQ protocol can be made rateless, and operating
close to the general theoretical optimum for a wide range of channel erasure
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2378</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2378</id><created>2010-09-13</created><updated>2011-04-21</updated><authors><author><keyname>Shukla</keyname><forenames>Ashish</forenames></author></authors><title>Ensuring Cache Freshness in On-demand Routing Protocols for Mobile Ad
  Hoc Network: A Cross-layer Framework</title><categories>cs.NI</categories><comments>This paper has been withdrawn as it's available as part of IEEE CCNC
  2007 proceedings from IEEExplore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the big challenges in ad hoc network design is packet routing. Studies
have shown that on-demand routing protocols perform better than table-driven
routing protocols. In order to avoid route discovery for each packet, on-demand
routing protocols cache routes previously learnt. A node in ad hoc network
learns routing information by overhearing or forwarding packets to other nodes
and keep learned routes in its route cache. However, node movement results
broken links and therefore increases risk of cache pollution. Ensuring cache
freshness in on-demand routing protocols, therefore, presents a serious
challenge. A lot of research has been done in route cache organization,
however, little effort has been done for route cache timeout policy to prevent
stale routes from being used. In this paper we propose a new cross-layer
framework to improve route cache performance in on-demand routing protocols.
The proposed framework presents novel use of Received Signal Strength Indicator
(RSSI) information to choose cache timeout of individual links in route cache.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2384</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2384</id><created>2010-09-13</created><authors><author><keyname>Bukh</keyname><forenames>Boris</forenames></author></authors><title>Radon partitions in convexity spaces</title><categories>math.CO cs.CG math.MG</categories><comments>11 pages</comments><msc-class>52A01 (Primary), 05D05, 06A15, 52A37 (Secondary)</msc-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Tverberg's theorem asserts that every (k-1)(d+1)+1 points in R^d can be
partitioned into k parts, so that the convex hulls of the parts have a common
intersection. Calder and Eckhoff asked whether there is a purely combinatorial
deduction of Tverberg's theorem from the special case k=2. We dash the hopes of
a purely combinatorial deduction, but show that the case k=2 does imply that
every set of O(k^2 log^2 k) points admits a Tverberg partition into k parts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2405</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2405</id><created>2010-09-13</created><updated>2010-10-20</updated><authors><author><keyname>Abadi</keyname><forenames>Mart&#xed;n</forenames><affiliation>Microsoft Research, Silicon Valley, University of California, Santa Cruz</affiliation></author><author><keyname>Plotkin</keyname><forenames>Gordon D.</forenames><affiliation>Microsoft Research, Silicon Valley, LFCS, University of Edinburgh</affiliation></author></authors><title>A Model of Cooperative Threads</title><categories>cs.PL</categories><comments>39 pages, 5 figures</comments><proxy>LMCS</proxy><acm-class>D.1.3, F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (October
  20, 2010) lmcs:700</journal-ref><doi>10.2168/LMCS-6(4:2)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a model of concurrent imperative programming with threads. We
focus on a small imperative language with cooperative threads which execute
without interruption until they terminate or explicitly yield control. We
define and study a trace-based denotational semantics for this language; this
semantics is fully abstract but mathematically elementary. We also give an
equational theory for the computational effects that underlie the language,
including thread spawning. We then analyze threads in terms of the free algebra
monad for this theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2406</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2406</id><created>2010-09-13</created><authors><author><keyname>Kukielka</keyname><forenames>Przemyslaw</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>Adaptation of the neural network-based IDS to new attacks detection</title><categories>cs.CR</categories><comments>9 pages, 3 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we report our experiment concerning new attacks detection by a
neural network-based Intrusion Detection System. What is crucial for this topic
is the adaptation of the neural network that is already in use to correct
classification of a new &quot;normal traffic&quot; and of an attack representation not
presented during the network training process. When it comes to the new attack
it should also be easy to obtain vectors to test and to retrain the neural
classifier. We describe the proposal of an algorithm and a distributed IDS
architecture that could achieve the goals mentioned above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2411</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2411</id><created>2010-09-13</created><authors><author><keyname>Stoianov</keyname><forenames>Nikolai</forenames></author></authors><title>A Protection Approach for Video Information transmitted in TCP/IP based
  networks</title><categories>cs.CR</categories><comments>5 pages, 7 figures, 3rd INDECT/IEEE International Conference on MCSS
  on May 6th and 7th, Krakow, Poland</comments><journal-ref>PROCEEDINGS IEEE International Conference MCSS 2010 Multimedia
  Communications, Services and Security Krakow, 6-7 May 2010, ISBN
  978-83-88309-92-2 ,</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper an analysis of the existing video information protection
methods is made. Analysis of current H.323 protocol stack has been made. A new
encryption/decryption layer has been suggested. An approach for partial data
encryption in the H.323 protocol stack is proposed and sample architecture of a
Virtual Private Video Network is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2443</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2443</id><created>2010-09-13</created><authors><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Delay-Optimal User Scheduling and Inter-Cell Interference Management in
  Cellular Network via Distributive Stochastic Learning</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a distributive queueaware intra-cell user
scheduling and inter-cell interference (ICI) management control design for a
delay-optimal celluar downlink system with M base stations (BSs), and K users
in each cell. Each BS has K downlink queues for K users respectively with
heterogeneous arrivals and delay requirements. The ICI management control is
adaptive to joint queue state information (QSI) over a slow time scale, while
the user scheduling control is adaptive to both the joint QSI and the joint
channel state information (CSI) over a faster time scale. We show that the
problem can be modeled as an infinite horizon average cost Partially Observed
Markov Decision Problem (POMDP), which is NP-hard in general. By exploiting the
special structure of the problem, we shall derive an equivalent Bellman
equation to solve the POMDP problem. To address the distributive requirement
and the issue of dimensionality and computation complexity, we derive a
distributive online stochastic learning algorithm, which only requires local
QSI and local CSI at each of the M BSs. We show that the proposed learning
algorithm converges almost surely (with probability 1) and has significant gain
compared with various baselines. The proposed solution only has linear
complexity order O(MK).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2452</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2452</id><created>2010-09-13</created><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Swamy</keyname><forenames>Chaitanya</forenames></author></authors><title>Facility Location with Client Latencies: Linear-Programming based
  Techniques for Minimum-Latency Problems</title><categories>cs.DS</categories><acm-class>F.2.2; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a problem that is a common generalization of the uncapacitated
facility location and minimum latency (ML) problems, where facilities need to
be opened to serve clients and also need to be sequentially activated before
they can provide service. Formally, we are given a set \F of n facilities with
facility-opening costs {f_i}, a set of m clients, and connection costs {c_{ij}}
specifying the cost of assigning a client j to a facility i, a root node r
denoting the depot, and a time metric d on \F\cup{r}. Our goal is to open a
subset F of facilities, find a path P starting at r and spanning F to activate
the open facilities, and connect each client j to a facility \phi(j)\in F, so
as to minimize \sum_{i\in F}f_i +\sum_{clients j}(c_{\phi(j),j}+t_j), where t_j
is the time taken to reach \phi(j) along path P. We call this the minimum
latency uncapacitated facility location (MLUFL) problem.
  Our main result is an O(\log n\max{\log n,\log m})-approximation for MLUFL.
We also show that any improvement in this approximation guarantee, implies an
improvement in the (current-best) approximation factor for group Steiner tree.
We obtain constant approximations for two natural special cases of the problem:
(a) related MLUFL (metric connection costs that are a scalar multiple of the
time metric); (b) metric uniform MLUFL (metric connection costs, unform
time-metric). Our LP-based methods are versatile and easily adapted to yield
approximation guarantees for MLUFL in various more general settings, such as
(i) when the latency-cost of a client is a function of the delay faced by the
facility to which it is connected; and (ii) the k-route version, where k
vehicles are routed in parallel to activate the open facilities. Our LP-based
understanding of MLUFL also offers some LP-based insights into ML, which we
believe is a promising direction for obtaining improvements for ML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2464</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2464</id><created>2010-09-13</created><updated>2010-09-16</updated><authors><author><keyname>Malkov</keyname><forenames>Maksim</forenames></author></authors><title>Various virtual structures on single file system</title><categories>cs.IT math.IT</categories><comments>5 pages, 8 figures. In Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article provides a new approach to creating hierarchical structure of
file system. First, it gives overview of the existing ways of storing files in
current operating systems. Second, it describes the new way of building
structures of a file system. This approach allows creating various structures
by different attributes on the same set of files using multiple tree-like
structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2476</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2476</id><created>2010-09-13</created><authors><author><keyname>Stoianov</keyname><forenames>Nikolai</forenames></author></authors><title>One software tool for testing square s-boxes</title><categories>cs.CR</categories><comments>Acknowledgment-The work presented in this paper has been performed in
  the framework of the EU Project INDECT--grant agreement number: 218086. 12th
  International Conference on Research in Telecommunication Technologies RTT
  2010 (September 8 - 10), Ostrava, Czech Republic</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An encryption technique is widely used to keep data confidential. Most of the
block symmetric algorithms use substitution functions. Often this functions use
so called S-BOX matrix. In this paper author presents one software tool for
testing and measuring square s-boxes. Based of information theory functions for
testing static and dynamic criteria are presented. These criteria are
mathematically defined for square s-boxes. Two new criteria &quot;private criteria&quot;
a proposed and pseudo codes for they creation and testing are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2490</identifier>
 <datestamp>2014-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2490</id><created>2010-09-13</created><updated>2011-08-12</updated><authors><author><keyname>Buhrman</keyname><forenames>Harry</forenames></author><author><keyname>Chandran</keyname><forenames>Nishanth</forenames></author><author><keyname>Fehr</keyname><forenames>Serge</forenames></author><author><keyname>Gelles</keyname><forenames>Ran</forenames></author><author><keyname>Goyal</keyname><forenames>Vipul</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author><author><keyname>Schaffner</keyname><forenames>Christian</forenames></author></authors><title>Position-Based Quantum Cryptography: Impossibility and Constructions</title><categories>quant-ph cs.CR</categories><comments>27 pages, 5 figures. v4: improved proofs for the impossibility
  theorem and for the instantaneous computation theorem</comments><doi>10.1137/130913687</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study position-based cryptography in the quantum setting.
The aim is to use the geographical position of a party as its only credential.
On the negative side, we show that if adversaries are allowed to share an
arbitrarily large entangled quantum state, no secure position-verification is
possible at all. We show a distributed protocol for computing any unitary
operation on a state shared between the different users, using local operations
and one round of classical communication. Using this surprising result, we
break any position-verification scheme of a very general form. On the positive
side, we show that if adversaries do not share any entangled quantum state but
can compute arbitrary quantum operations, secure position-verification is
achievable. Jointly, these results suggest the interesting question whether
secure position-verification is possible in case of a bounded amount of
entanglement. Our positive result can be interpreted as resolving this question
in the simplest case, where the bound is set to zero.
  In models where secure positioning is achievable, it has a number of
interesting applications. For example, it enables secure communication over an
insecure channel without having any pre-shared key, with the guarantee that
only a party at a specific location can learn the content of the conversation.
More generally, we show that in settings where secure position-verification is
achievable, other position-based cryptographic schemes are possible as well,
such as secure position-based authentication and position-based key agreement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2491</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2491</id><created>2010-09-13</created><authors><author><keyname>Uruena</keyname><forenames>Manuel</forenames></author><author><keyname>Machnik</keyname><forenames>Petr</forenames></author><author><keyname>Martinez</keyname><forenames>Maria</forenames></author><author><keyname>Niemiec</keyname><forenames>Marcin</forenames></author><author><keyname>Stoianov</keyname><forenames>Nikolai</forenames></author></authors><title>INDECT Advanced Security Requirements</title><categories>cs.CR</categories><comments>PROCEEDINGS (Poster session) IEEE International Conference MCSS 2010
  Multimedia Communications, Services and Security Krakow, 6-7 May 2010, ISBN
  978-83-88309-92-2 Acknowledgment-The work presented in this paper has been
  performed in the framework of the EU Project INDECT--grant agreement number:
  218086</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews the requirements for the security mechanisms that are
currently being developed in the framework of the European research project
INDECT. An overview of features for integrated technologies such as Virtual
Private Networks (VPNs), Cryptographic Algorithms, Quantum Cryptography,
Federated ID Management and Secure Mobile Ad-hoc networking are described
together with their expected use in INDECT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2521</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2521</id><created>2010-09-13</created><authors><author><keyname>Chen</keyname><forenames>Danny Z.</forenames></author><author><keyname>Wang</keyname><forenames>Haitao</forenames></author></authors><title>An Improved Algorithm for Reconstructing a Simple Polygon from the
  Visibility Angles</title><categories>cs.CG cs.DS</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the following problem of reconstructing a simple
polygon: Given a cyclically ordered vertex sequence of an unknown simple
polygon P of n vertices and, for each vertex v of P, the sequence of angles
defined by all the visible vertices of v in P, reconstruct the polygon P (up to
similarity). An O(n^3 log n) time algorithm has been proposed for this problem.
We present an improved algorithm with running time O(n^2), based on new
observations on the geometric structures of the problem. Since the input size
(i.e., the total number of input visibility angles) is O(n^2) in the worst
case, our algorithm is worst-case optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2528</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2528</id><created>2010-09-13</created><authors><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Is Witsenhausen's counterexample a relevant toy?</title><categories>cs.IT cs.SY math.IT</categories><comments>preprint for paper that will appear in proceedings of 49th IEEE
  Conference on Decision and Control (CDC) 2010, Atlanta, Georgia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper answers a question raised by Doyle on the relevance of the
Witsenhausen counterexample as a toy decentralized control problem. The
question has two sides, the first of which focuses on the lack of an external
channel in the counterexample. Using existing results, we argue that the core
difficulty in the counterexample is retained even in the presence of such a
channel. The second side questions the LQG formulation of the counterexample.
We consider alternative formulations and show that the understanding developed
for the LQG case guides the investigation for these other cases as well.
Specifically, we consider 1) a variation on the original counterexample with
general, but bounded, noise distributions, and 2) an adversarial extension with
bounded disturbance and quadratic costs. For each of these formulations, we
show that quantization-based nonlinear strategies outperform linear strategies
by an arbitrarily large factor. Further, these nonlinear strategies also
perform within a constant factor of the optimal, uniformly over all possible
parameter choices (for fixed noise distributions in the Bayesian case).
  Fortuitously, the assumption of bounded noise results in a significant
simplification of proofs as compared to those for the LQG formulation.
Therefore, the results in this paper are also of pedagogical interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2556</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2556</id><created>2010-09-13</created><updated>2011-04-27</updated><authors><author><keyname>Pawar</keyname><forenames>Sameer</forenames></author><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Securing Dynamic Distributed Storage Systems against Eavesdropping and
  Adversarial Attacks</title><categories>cs.IT cs.CR math.IT</categories><comments>37 pages, 11 figures, submitted to IT transactions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of securing distributed storage systems against
eavesdropping and adversarial attacks. An important aspect of these systems is
node failures over time, necessitating, thus, a repair mechanism in order to
maintain a desired high system reliability. In such dynamic settings, an
important security problem is to safeguard the system from an intruder who may
come at different time instances during the lifetime of the storage system to
observe and possibly alter the data stored on some nodes. In this scenario, we
give upper bounds on the maximum amount of information that can be stored
safely on the system. For an important operating regime of the distributed
storage system, which we call the 'bandwidth-limited regime', we show that our
upper bounds are tight and provide explicit code constructions. Moreover, we
provide a way to short list the malicious nodes and expurgate the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2557</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2557</id><created>2010-09-13</created><updated>2011-07-19</updated><authors><author><keyname>Zhu</keyname><forenames>Weiping</forenames></author></authors><title>Loss Rate Inference in Multi-Sources and Multicast-Based General
  Topology</title><categories>cs.NI</categories><comments>submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loss tomography has received considerable attention in recent years and a
number of estimators have been proposed. Unfortunately, almost all of them are
devoted to the tree topology despite the general topology is more common in
practice. In addition, most of the works presented in the literature rely on
iterative approximation to search for the maximum of a likelihood function
formed from observations, which have been known neither scalable nor efficient.
In contrast to the tree topology, there is few paper dedicated to the general
topology because of the lack of understanding the impacts created by the probes
sent by different sources. We in this paper present the analytical results
obtained recently for the general topology that show the correlation created by
the probes sent by multiple sources to a node located in an intersection of
multiple trees. The correlation is expressed by a set of polynomials of the
pass rates of the paths connecting the sources to the node. In addition to the
expression, a closed form solution is proposed to obtain the MLE of the pass
rates of the paths connecting the sources to the node. Then, two strategies are
proposed to estimate the loss rate of a link for the general topology: one is
path-based and the other is link-based, depending on whether we need to obtain
the pass rate of a path first. The two strategies are compared in the context
of the general topology that shows each has its advantages and the link-based
one is more general. Apart from proving the estimates obtained are the MLEs, we
prove the estimator presented here has the optimal asymptotic property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2566</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2566</id><created>2010-09-13</created><authors><author><keyname>Pandey</keyname><forenames>Punit</forenames></author><author><keyname>Pandey</keyname><forenames>Deepshikha</forenames></author><author><keyname>Kumar</keyname><forenames>Shishir</forenames></author></authors><title>Reinforcement Learning by Comparing Immediate Reward</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an approach to Reinforcement Learning Algorithm by
comparing their immediate rewards using a variation of Q-Learning algorithm.
Unlike the conventional Q-Learning, the proposed algorithm compares current
reward with immediate reward of past move and work accordingly. Relative reward
based Q-learning is an approach towards interactive learning. Q-Learning is a
model free reinforcement learning method that used to learn the agents. It is
observed that under normal circumstances algorithm take more episodes to reach
optimal Q-value due to its normal reward or sometime negative reward. In this
new form of algorithm agents select only those actions which have a higher
immediate reward signal in comparison to previous one. The contribution of this
article is the presentation of new Q-Learning Algorithm in order to maximize
the performance of algorithm and reduce the number of episode required to reach
optimal Q-value. Effectiveness of proposed algorithm is simulated in a 20 x20
Grid world deterministic environment and the result for the two forms of
Q-Learning Algorithms is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2574</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2574</id><created>2010-09-14</created><updated>2011-04-21</updated><authors><author><keyname>Shukla</keyname><forenames>Ashish</forenames></author><author><keyname>Tyagi</keyname><forenames>Neeraj</forenames></author></authors><title>A New Route Maintenance in Dynamic Source Routing Protocol</title><categories>cs.NI</categories><comments>This paper has been withdrawn as it's available as part of IEEE ISWPC
  2006 proceedings from IEEExplore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile ad-hoc network (MANET) is infrastructureless, self-organizable, multi
hop packet switched network. A number of routing protocols for MANETs have been
proposed in recent years. Dynamic Source Routing (DSR) protocol is one of the
most popular routing protocol for ad hoc networks. This paper presents a novel
method to enhance route maintenance part of DSR protocol. Our proposed route
maintenance significantly increases the efficiency of the protocol at the time
of route failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2575</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2575</id><created>2010-09-14</created><updated>2011-04-21</updated><authors><author><keyname>Shukla</keyname><forenames>Ashish</forenames></author></authors><title>On the Reduction of Broadcast Traffic in Mobile Ad Hoc Networks</title><categories>cs.NI</categories><comments>This paper has been withdrawn as it's available as part of IEEE WICOM
  2007 proceedings from IEEExplore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many mobile ad hoc network protocols use simple flooding, in order to adapt
to changes in time varying network topology. Most of the times, a network-wide
flood results in redundant packets and increases network congestion,
probability of packet collision, low utilization of available bandwidth, and
most important, higher power consumption. In this paper, we propose a new
cross-layer broadcast scheme to minimize broadcast traffic in mobile ad hoc
networks. Our scheme is based on use of received signal strength indicator,
RSSI, value to reduce the number of broadcast packets. The effectiveness of the
proposed technique is verified using simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2576</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2576</id><created>2010-09-14</created><updated>2011-04-21</updated><authors><author><keyname>Shukla</keyname><forenames>Ashish</forenames></author></authors><title>A Simple Battery Aware Gossip Based Sleep Protocol for Densely Deployed
  Ad-hoc and Sensor Networks</title><categories>cs.NI</categories><comments>This paper has been withdrawn as it's available as part of IEEE CCNC
  2008 proceedings from IEEExplore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conserving power in mobile ad-hoc and sensor networks is a big challenge.
Most of the nodes in these networks, in general, are battery powered,
therefore, an efficient power saving protocol is required to extend the
lifetime of such networks. A lot of work has been done and several protocols
have been proposed to address this problem. Gossip based protocols, which are
based on the results of percolation theory, significantly reduce power
consumption with very little implementation overhead. However, not much work
has been done to make gossiping battery aware. In this paper we introduce a
simple gossip based battery aware sleep protocol. The protocol allows low
battery nodes to sleep more, therefore, improves overall network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2577</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2577</id><created>2010-09-14</created><authors><author><keyname>Praveen</keyname><forenames>M.</forenames></author></authors><title>Small Vertex Cover makes Petri Net Coverability and Boundedness Easier</title><categories>cs.DS cs.CC</categories><comments>Full version of the paper appearing in IPEC 2010</comments><msc-class>68R10</msc-class><acm-class>F.2.2; F.4.1</acm-class><doi>10.1007/978-3-642-17493-3_21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The coverability and boundedness problems for Petri nets are known to be
Expspace-complete. Given a Petri net, we associate a graph with it. With the
vertex cover number k of this graph and the maximum arc weight W as parameters,
we show that coverability and boundedness are in ParaPspace. This means that
these problems can be solved in space O(ef(k,W)poly(n)), where ef(k,W) is some
exponential function and poly(n) is some polynomial in the size of the input.
We then extend the ParaPspace result to model checking a logic that can express
some generalizations of coverability and boundedness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2591</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2591</id><created>2010-09-14</created><authors><author><keyname>Kavitha</keyname><forenames>Telikepalli</forenames></author><author><keyname>Nasre</keyname><forenames>Meghana</forenames></author><author><keyname>Nimbhorkar</keyname><forenames>Prajakta</forenames></author></authors><title>Popularity at Minimum Cost</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an extension of the {\em popular matching} problem in this paper.
The input to the popular matching problem is a bipartite graph G = (A U B,E),
where A is a set of people, B is a set of items, and each person a belonging to
A ranks a subset of items in an order of preference, with ties allowed. The
popular matching problem seeks to compute a matching M* between people and
items such that there is no matching M where more people are happier with M
than with M*. Such a matching M* is called a popular matching. However, there
are simple instances where no popular matching exists.
  Here we consider the following natural extension to the above problem:
associated with each item b belonging to B is a non-negative price cost(b),
that is, for any item b, new copies of b can be added to the input graph by
paying an amount of cost(b) per copy. When G does not admit a popular matching,
the problem is to &quot;augment&quot; G at minimum cost such that the new graph admits a
popular matching. We show that this problem is NP-hard; in fact, it is NP-hard
to approximate it within a factor of sqrt{n1}/2, where n1 is the number of
people. This problem has a simple polynomial time algorithm when each person
has a preference list of length at most 2. However, if we consider the problem
of &quot;constructing&quot; a graph at minimum cost that admits a popular matching that
matches all people, then even with preference lists of length 2, the problem
becomes NP-hard. On the other hand, when the number of copies of each item is
&quot;fixed&quot;, we show that the problem of computing a minimum cost popular matching
or deciding that no popular matching exists can be solved in O(mn1) time, where
m is the number of edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2602</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2602</id><created>2010-09-14</created><authors><author><keyname>Zhou</keyname><forenames>Hui</forenames><affiliation>Tsinghua University, China</affiliation></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames><affiliation>Tsinghua University, China</affiliation></author><author><keyname>Guo</keyname><forenames>Dongning</forenames><affiliation>Northewstern University, US</affiliation></author></authors><title>Joint Channel Probing and Proportional Fair Scheduling in Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>26 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of a scheduling scheme is crucial for the efficiency and
user-fairness of wireless networks. Assuming that the quality of all user
channels is available to a central controller, a simple scheme which maximizes
the utility function defined as the sum logarithm throughput of all users has
been shown to guarantee proportional fairness. However, to acquire the channel
quality information may consume substantial amount of resources. In this work,
it is assumed that probing the quality of each user's channel takes a fraction
of the coherence time, so that the amount of time for data transmission is
reduced. The multiuser diversity gain does not always increase as the number of
users increases. In case the statistics of the channel quality is available to
the controller, the problem of sequential channel probing for user scheduling
is formulated as an optimal stopping time problem. A joint channel probing and
proportional fair scheduling scheme is developed. This scheme is extended to
the case where the channel statistics are not available to the controller, in
which case a joint learning, probing and scheduling scheme is designed by
studying a generalized bandit problem. Numerical results demonstrate that the
proposed scheduling schemes can provide significant gain over existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2617</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2617</id><created>2010-09-14</created><authors><author><keyname>Sarma</keyname><forenames>Anish Das</forenames></author><author><keyname>Gollapudi</keyname><forenames>Sreenivas</forenames></author><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>Understanding Fashion Cycles as a Social Choice</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a formal model for studying fashion trends, in terms of three
parameters of fashionable items: (1) their innate utility; (2) individual
boredom associated with repeated usage of an item; and (3) social influences
associated with the preferences from other people. While there are several
works that emphasize the effect of social influence in understanding fashion
trends, in this paper we show how boredom plays a strong role in both
individual and social choices. We show how boredom can be used to explain the
cyclic choices in several scenarios such as an individual who has to pick a
restaurant to visit every day, or a society that has to repeatedly `vote' on a
single fashion style from a collection. We formally show that a society that
votes for a single fashion style can be viewed as a single individual cycling
through different choices.
  In our model, the utility of an item gets discounted by the amount of boredom
that has accumulated over the past; this boredom increases with every use of
the item and decays exponentially when not used. We address the problem of
optimally choosing items for usage, so as to maximize over-all satisfaction,
i.e., composite utility, over a period of time. First we show that the simple
greedy heuristic of always choosing the item with the maximum current composite
utility can be arbitrarily worse than the optimal. Second, we prove that even
with just a single individual, determining the optimal strategy for choosing
items is NP-hard. Third, we show that a simple modification to the greedy
algorithm that simply doubles the boredom of each item is a provably close
approximation to the optimal strategy. Finally, we present an experimental
study over real-world data collected from query logs to compare our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2622</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2622</id><created>2010-09-14</created><authors><author><keyname>Das</keyname><forenames>Anindya</forenames></author><author><keyname>Jahangir</keyname><forenames>Ifat</forenames></author><author><keyname>Hasan</keyname><forenames>Masud</forenames></author></authors><title>On the Design and Analysis of Quaternary Serial and Parallel Adders</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization techniques for decreasing the time and area of adder circuits
have been extensively studied for years mostly in binary logic system. In this
paper, we provide the necessary equations required to design a full adder in
quaternary logic system. We develop the equations for single-stage parallel
adder which works as a carry look-ahead adder. We also provide the design of a
logarithmic stage parallel adder which can compute the carries within log2(n)
time delay for n qudits. At last, we compare the designs and finally propose a
hybrid adder which combines the advantages of serial and parallel adder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2631</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2631</id><created>2010-09-14</created><authors><author><keyname>Abel</keyname><forenames>M.</forenames></author><author><keyname>Shepelyansky</keyname><forenames>D. L.</forenames></author></authors><title>Google matrix of business process management</title><categories>cs.CY cs.IR physics.soc-ph q-fin.GN</categories><comments>submitted to European Journal of Physics B</comments><journal-ref>Eur. Phys. J. B v.84, p.493 (2011)</journal-ref><doi>10.1140/epjb/e2010-10710-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Development of efficient business process models and determination of their
characteristic properties are subject of intense interdisciplinary research.
Here, we consider a business process model as a directed graph. Its nodes
correspond to the units identified by the modeler and the link direction
indicates the causal dependencies between units. It is of primary interest to
obtain the stationary flow on such a directed graph, which corresponds to the
steady-state of a firm during the business process. Following the ideas
developed recently for the World Wide Web, we construct the Google matrix for
our business process model and analyze its spectral properties. The importance
of nodes is characterized by Page-Rank and recently proposed CheiRank and
2DRank, respectively. The results show that this two-dimensional ranking gives
a significant information about the influence and communication properties of
business model units. We argue that the Google matrix method, described here,
provides a new efficient tool helping companies to make their decisions on how
to evolve in the exceedingly dynamic global market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2634</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2634</id><created>2010-09-14</created><authors><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Evolution of National Nobel Prize Shares in the 20th Century</title><categories>physics.hist-ph cs.CY</categories><comments>19 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the evolution of cumulative national shares of Nobel Prizes since
1901, properly taking into account that most prizes were divided among several
laureates. We rank by citizenship at the moment of the award, and by country of
birth. Surprisingly, graphs of this type have not been published before, even
though they powerfully illustrate the century's migration patterns (brain
drains and gains) in the sciences and other fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2651</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2651</id><created>2010-09-14</created><authors><author><keyname>Sun</keyname><forenames>Qiyu</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Left-Inverses of Fractional Laplacian and Sparse Stochastic Processes</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>Advances in Computational Mathematics, accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fractional Laplacian $(-\triangle)^{\gamma/2}$ commutes with the primary
coordination transformations in the Euclidean space $\RR^d$: dilation,
translation and rotation, and has tight link to splines, fractals and stable
Levy processes. For $0&lt;\gamma&lt;d$, its inverse is the classical Riesz potential
$I_\gamma$ which is dilation-invariant and translation-invariant. In this work,
we investigate the functional properties (continuity, decay and invertibility)
of an extended class of differential operators that share those invariance
properties. In particular, we extend the definition of the classical Riesz
potential $I_\gamma$ to any non-integer number $\gamma$ larger than $d$ and
show that it is the unique left-inverse of the fractional Laplacian
$(-\triangle)^{\gamma/2}$ which is dilation-invariant and
translation-invariant. We observe that, for any $1\le p\le \infty$ and
$\gamma\ge d(1-1/p)$, there exists a Schwartz function $f$ such that $I_\gamma
f$ is not $p$-integrable. We then introduce the new unique left-inverse
$I_{\gamma, p}$ of the fractional Laplacian $(-\triangle)^{\gamma/2}$ with the
property that $I_{\gamma, p}$ is dilation-invariant (but not
translation-invariant) and that $I_{\gamma, p}f$ is $p$-integrable for any
Schwartz function $f$. We finally apply that linear operator $I_{\gamma, p}$
with $p=1$ to solve the stochastic partial differential equation
$(-\triangle)^{\gamma/2} \Phi=w$ with white Poisson noise as its driving term
$w$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2653</identifier>
 <datestamp>2012-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2653</id><created>2010-09-14</created><updated>2012-10-13</updated><authors><author><keyname>Acemoglu</keyname><forenames>Daron</forenames></author><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Opinion fluctuations and disagreement in social networks</title><categories>cs.SI cs.SY math.OC math.PR</categories><comments>33 pages, accepted for publication in Mathematics of Operation
  Research</comments><doi>10.1287/moor.1120.0570</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a tractable opinion dynamics model that generates long-run
disagreements and persistent opinion fluctuations. Our model involves an
inhomogeneous stochastic gossip process of continuous opinion dynamics in a
society consisting of two types of agents: regular agents, who update their
beliefs according to information that they receive from their social neighbors;
and stubborn agents, who never update their opinions. When the society contains
stubborn agents with different opinions, the belief dynamics never lead to a
consensus (among the regular agents). Instead, beliefs in the society fail to
converge almost surely, the belief profile keeps on fluctuating in an ergodic
fashion, and it converges in law to a non-degenerate random vector. The
structure of the network and the location of the stubborn agents within it
shape the opinion dynamics. The expected belief vector evolves according to an
ordinary differential equation coinciding with the Kolmogorov backward equation
of a continuous-time Markov chain with absorbing states corresponding to the
stubborn agents and converges to a harmonic vector, with every regular agent's
value being the weighted average of its neighbors' values, and boundary
conditions corresponding to the stubborn agents'. Expected cross-products of
the agents' beliefs allow for a similar characterization in terms of coupled
Markov chains on the network. We prove that, in large-scale societies which are
highly fluid, meaning that the product of the mixing time of the Markov chain
on the graph describing the social network and the relative size of the
linkages to stubborn agents vanishes as the population size grows large, a
condition of \emph{homogeneous influence} emerges, whereby the stationary
beliefs' marginal distributions of most of the regular agents have
approximately equal first and second moments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2706</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2706</id><created>2010-09-14</created><authors><author><keyname>Alhazov</keyname><forenames>Artiom</forenames></author><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author></authors><title>Minimization Strategies for Maximally Parallel Multiset Rewriting
  Systems</title><categories>cs.FL cs.CC cs.CL cs.DM</categories><comments>This article is an improved version of [1]</comments><msc-class>68Q05, 68Q10, 68Q17</msc-class><acm-class>F.4.3; F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximally parallel multiset rewriting systems (MPMRS) give a convenient way
to express relations between unstructured objects. The functioning of various
computational devices may be expressed in terms of MPMRS (e.g., register
machines and many variants of P systems). In particular, this means that MPMRS
are computationally complete; however, a direct translation leads to quite a
big number of rules. Like for other classes of computationally complete
devices, there is a challenge to find a universal system having the smallest
number of rules. In this article we present different rule minimization
strategies for MPMRS based on encodings and structural transformations. We
apply these strategies to the translation of a small universal register machine
(Korec, 1996) and we show that there exists a universal MPMRS with 23 rules.
Since MPMRS are identical to a restricted variant of P systems with antiport
rules, the results we obtained improve previously known results on the number
of rules for those systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2722</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2722</id><created>2010-09-14</created><authors><author><keyname>Choi</keyname><forenames>Myung Jin</forenames></author><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Willsky</keyname><forenames>Alan S.</forenames></author></authors><title>Learning Latent Tree Graphical Models</title><categories>stat.ML cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of learning a latent tree graphical model where samples
are available only from a subset of variables. We propose two consistent and
computationally efficient algorithms for learning minimal latent trees, that
is, trees without any redundant hidden nodes. Unlike many existing methods, the
observed nodes (or variables) are not constrained to be leaf nodes. Our first
algorithm, recursive grouping, builds the latent tree recursively by
identifying sibling groups using so-called information distances. One of the
main contributions of this work is our second algorithm, which we refer to as
CLGrouping. CLGrouping starts with a pre-processing procedure in which a tree
over the observed variables is constructed. This global step groups the
observed nodes that are likely to be close to each other in the true latent
tree, thereby guiding subsequent recursive grouping (or equivalent procedures)
on much smaller subsets of variables. This results in more accurate and
efficient learning of latent trees. We also present regularized versions of our
algorithms that learn latent tree approximations of arbitrary distributions. We
compare the proposed algorithms to other methods by performing extensive
numerical experiments on various latent tree graphical models such as hidden
Markov models and star graphs. In addition, we demonstrate the applicability of
our methods on real-world datasets by modeling the dependency structure of
monthly stock returns in the S&amp;P index and of the words in the 20 newsgroups
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2738</identifier>
 <datestamp>2013-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2738</id><created>2010-09-14</created><authors><author><keyname>Cie&#x15b;li&#x144;ski</keyname><forenames>Jan L.</forenames></author><author><keyname>Ratkiewicz</keyname><forenames>Bogus&#x142;aw</forenames></author></authors><title>Energy-preserving numerical schemes of high accuracy for one-dimensional
  Hamiltonian systems</title><categories>cs.NA math.NA physics.comp-ph</categories><comments>15 pages, 6 figures. Presented at the conference &quot;BIT 50 - Trends in
  Numerical Computing&quot; (Lund, 17-20 June 2010)</comments><msc-class>65P10, 65L12</msc-class><journal-ref>Journal of Physics A: Mathematical and Theoretical 44 (15) (2011)
  155206 (14 pp)</journal-ref><doi>10.1088/1751-8113/44/15/155206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a class of non-standard numerical schemes which are modifications
of the discrete gradient method. They preserve the energy integral exactly (up
to the round-off error). The considered class contains locally exact discrete
gradient schemes and integrators of arbitrary high order. In numerical
experiments we compare our integrators with some other numerical schemes,
including the standard discrete gradient method, the leap-frog scheme and a
symplectic scheme of 4th order. We study the error accumulation for very long
time and the conservation of the energy integral.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2764</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2764</id><created>2010-09-14</created><updated>2014-08-11</updated><authors><author><keyname>Malbrain</keyname><forenames>Karl</forenames></author></authors><title>A Blink Tree latch method and protocol to support synchronous node
  deletion</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Blink Tree latch method and protocol supports synchronous node deletion in
a high concurrency environment. Full source code is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2765</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2765</id><created>2010-09-14</created><authors><author><keyname>McKeever</keyname><forenames>Ruth</forenames></author><author><keyname>McDaid</keyname><forenames>Kevin</forenames></author></authors><title>How do Range Names Hinder Novice Spreadsheet Debugging Performance?</title><categories>cs.SE</categories><comments>14 Pages, 6 Tables</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 47-60
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although experts diverge on how best to improve spreadsheet quality, it is
generally agreed that more time needs to be spent testing spreadsheets.
Ideally, experienced and trained spreadsheet engineers would carry this out,
but quite often this is neither practical nor possible. Many spreadsheets are a
legacy, developed by staff that have since moved on, or indeed modified by many
staff no longer employed by the organisation. When such spreadsheets fall into
the hands of inexperienced, non-experts, any features that reduce error
visibility may become a risk. Range names are one such feature, and this paper,
building on previous research, investigates in a more structured and controlled
manner the effect they have on the debugging performance of novice spreadsheet
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2775</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2775</id><created>2010-09-14</created><authors><author><keyname>Rittweger</keyname><forenames>Ben G.</forenames></author><author><keyname>Langan</keyname><forenames>Eoin</forenames></author></authors><title>Spreadsheet Risk Management in Organisations</title><categories>cs.SE</categories><comments>12 Pages, 1 Table, 6 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 61-72
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper examines in the context of financial reporting, the controls that
organisations have in place to manage spreadsheet risk and errors. There has
been widespread research conducted in this area, both in Ireland and
internationally. This paper describes a study involving 19 participants (2 case
studies and 17 by survey) from Ireland. Three areas are examined; firstly, the
extent of spreadsheet usage, secondly, the level of complexity employed in
spreadsheets, and finally, the controls in place regarding spreadsheets. The
findings support previous findings of Panko (1998), that errors occur
frequently in spreadsheets and that there is little or unenforced controls
employed, however this research finds that attitudes are changing with regard
to spreadsheet risk and that one organisation is implementing a comprehensive
project regarding policies on the development and control of spreadsheets.
Further research could be undertaken in the future to examine the development
of a &quot;best practice model&quot; both for the reduction in errors and to minimise the
risk in spreadsheet usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2785</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2785</id><created>2010-09-14</created><authors><author><keyname>Aurigemma</keyname><forenames>Salvatore</forenames></author><author><keyname>Panko</keyname><forenames>Raymond R.</forenames></author></authors><title>The Detection of Human Spreadsheet Errors by Humans versus Inspection
  (Auditing) Software</title><categories>cs.SE</categories><comments>14 Pages, 4 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 73-85
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous spreadsheet inspection experiments have had human subjects look for
seeded errors in spreadsheets. In this study, subjects attempted to find errors
in human-developed spreadsheets to avoid the potential artifacts created by
error seeding. Human subject success rates were compared to the successful
rates for error-flagging by spreadsheet static analysis tools (SSATs) applied
to the same spreadsheets. The human error detection results were comparable to
those of studies using error seeding. However, Excel Error Check and
Spreadsheet Professional were almost useless for correctly flagging natural
(human) errors in this study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2787</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2787</id><created>2010-09-14</created><authors><author><keyname>Tort</keyname><forenames>Francoise</forenames></author></authors><title>Teaching Spreadsheets: Curriculum Design Principles</title><categories>cs.SE</categories><comments>12 Pages, 10 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 99-110
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EuSpRIG concerns direct researchers to revisit spreadsheet education, taking
into account error auditing tools, checklists, and good practices. This paper
aims at elaborating principles to design a spreadsheet curriculum. It mainly
focuses on two important issues. Firstly, it is necessary to establish the
spreadsheet invariants to be taught, especially those concerning errors and
good practices. Secondly, it is important to take into account the learners'
ICT experience, and to encourage them to attitudes that foster self-learning.
We suggest key principles for spreadsheet teaching, and we illustrate them with
teaching guidelines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2789</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2789</id><created>2010-09-14</created><authors><author><keyname>Abel</keyname><forenames>Andreas</forenames><affiliation>Ludwig-Maximilians-University</affiliation></author><author><keyname>Pientka</keyname><forenames>Brigitte</forenames><affiliation>McGill University</affiliation></author></authors><title>Explicit Substitutions for Contextual Type Theory</title><categories>cs.LO cs.PL</categories><comments>In Proceedings LFMTP 2010, arXiv:1009.2189</comments><proxy>EPTCS</proxy><acm-class>F.4.1;I.2.3</acm-class><journal-ref>EPTCS 34, 2010, pp. 5-20</journal-ref><doi>10.4204/EPTCS.34.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an explicit substitution calculus which
distinguishes between ordinary bound variables and meta-variables. Its typing
discipline is derived from contextual modal type theory. We first present a
dependently typed lambda calculus with explicit substitutions for ordinary
variables and explicit meta-substitutions for meta-variables. We then present a
weak head normalization procedure which performs both substitutions lazily and
in a single pass thereby combining substitution walks for the two different
classes of variables. Finally, we describe a bidirectional type checking
algorithm which uses weak head normalization and prove soundness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2790</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2790</id><created>2010-09-14</created><authors><author><keyname>Boyland</keyname><forenames>John Tang</forenames></author></authors><title>Generating Bijections between HOAS and the Natural Numbers</title><categories>cs.LO</categories><comments>In Proceedings LFMTP 2010, arXiv:1009.2189</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 34, 2010, pp. 21-35</journal-ref><doi>10.4204/EPTCS.34.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A provably correct bijection between higher-order abstract syntax (HOAS) and
the natural numbers enables one to define a &quot;not equals&quot; relationship between
terms and also to have an adequate encoding of sets of terms, and maps from one
term family to another. Sets and maps are useful in many situations and are
preferably provided in a library of some sort. I have released a map and set
library for use with Twelf which can be used with any type for which a
bijection to the natural numbers exists.
  Since creating such bijections is tedious and error-prone, I have created a
&quot;bijection generator&quot; that generates such bijections automatically together
with proofs of correctness, all in the context of Twelf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2791</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2791</id><created>2010-09-14</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author><author><keyname>Gabbay</keyname><forenames>Murdoch J.</forenames><affiliation>Heriot-Watt University</affiliation></author></authors><title>Closed nominal rewriting and efficiently computable nominal algebra
  equality</title><categories>cs.LO cs.PL</categories><comments>In Proceedings LFMTP 2010, arXiv:1009.2189</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 34, 2010, pp. 37-51</journal-ref><doi>10.4204/EPTCS.34.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the relationship between nominal algebra and nominal rewriting,
giving a new and concise presentation of equational deduction in nominal
theories. With some new results, we characterise a subclass of equational
theories for which nominal rewriting provides a complete procedure to check
nominal algebra equality. This subclass includes specifications of the
lambda-calculus and first-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2792</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2792</id><created>2010-09-14</created><authors><author><keyname>Geuvers</keyname><forenames>Herman</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Krebbers</keyname><forenames>Robbert</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>McKinna</keyname><forenames>James</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Wiedijk</keyname><forenames>Freek</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>Pure Type Systems without Explicit Contexts</title><categories>cs.LO</categories><comments>In Proceedings LFMTP 2010, arXiv:1009.2189</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 34, 2010, pp. 53-67</journal-ref><doi>10.4204/EPTCS.34.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach to type theory in which the typing judgments do not
have explicit contexts. Instead of judgments of shape &quot;Gamma |- A : B&quot;, our
systems just have judgments of shape &quot;A : B&quot;. A key feature is that we
distinguish free and bound variables even in pseudo-terms.
  Specifically we give the rules of the &quot;Pure Type System&quot; class of type
theories in this style. We prove that the typing judgments of these systems
correspond in a natural way with those of Pure Type Systems as traditionally
formulated. I.e., our systems have exactly the same well-typed terms as
traditional presentations of type theory.
  Our system can be seen as a type theory in which all type judgments share an
identical, infinite, typing context that has infinitely many variables for each
possible type. For this reason we call our system &quot;Gamma_infinity&quot;. This name
means to suggest that our type judgment &quot;A : B&quot; should be read as
&quot;Gamma_infinity |- A : B&quot;, with a fixed infinite type context called
&quot;Gamma_infinity&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2793</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2793</id><created>2010-09-14</created><authors><author><keyname>Licata</keyname><forenames>Daniel R.</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Harper</keyname><forenames>Robert</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>A Monadic Formalization of ML5</title><categories>cs.PL cs.LO</categories><comments>In Proceedings LFMTP 2010, arXiv:1009.2189</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 34, 2010, pp. 69-83</journal-ref><doi>10.4204/EPTCS.34.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ML5 is a programming language for spatially distributed computing, based on a
Curry-Howard correspondence with the modal logic S5. Despite being designed by
a correspondence with S5 modal logic, the ML5 programming language differs from
the logic in several ways. In this paper, we explain these discrepancies
between ML5 and S5 by translating ML5 into a slightly different logic:
intuitionistic S5 extended with a lax modality that encapsulates effectful
computations in a monad. This translation both explains the existing ML5 design
and suggests some simplifications and generalizations. We have formalized our
translation within the Agda proof assistant. Rather than formalizing lax S5 as
a proof theory, we \emph{embed} it as a universe within the the dependently
typed host language, with the universe elimination given by implementing the
modal logic's Kripke semantics. This representation technique saves us the work
of defining a proof theory for the logic and proving it correct, and
additionally allows us to inherit the equational theory of the meta-language,
which can be exploited in proving that the semantics validates the operational
semantics of ML5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2794</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2794</id><created>2010-09-14</created><authors><author><keyname>Rabe</keyname><forenames>Florian</forenames><affiliation>Jacobs University Bremen</affiliation></author></authors><title>Representing Isabelle in LF</title><categories>cs.LO</categories><comments>In Proceedings LFMTP 2010, arXiv:1009.2189</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 34, 2010, pp. 85-99</journal-ref><doi>10.4204/EPTCS.34.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LF has been designed and successfully used as a meta-logical framework to
represent and reason about object logics. Here we design a representation of
the Isabelle logical framework in LF using the recently introduced module
system for LF. The major novelty of our approach is that we can naturally
represent the advanced Isabelle features of type classes and locales.
  Our representation of type classes relies on a feature so far lacking in the
LF module system: morphism variables and abstraction over them. While
conservative over the present system in terms of expressivity, this feature is
needed for a representation of type classes that preserves the modular
structure. Therefore, we also design the necessary extension of the LF module
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2795</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2795</id><created>2010-09-14</created><authors><author><keyname>Schack-Nielsen</keyname><forenames>Anders</forenames><affiliation>IT University of Copenhagen</affiliation></author><author><keyname>Sch&#xfc;rmann</keyname><forenames>Carsten</forenames><affiliation>IT University of Copenhagen</affiliation></author></authors><title>Pattern Unification for the Lambda Calculus with Linear and Affine Types</title><categories>cs.LO</categories><comments>In Proceedings LFMTP 2010, arXiv:1009.2189</comments><proxy>EPTCS</proxy><acm-class>F.4.1; I.2.3</acm-class><journal-ref>EPTCS 34, 2010, pp. 101-116</journal-ref><doi>10.4204/EPTCS.34.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the pattern fragment for higher-order unification problems in
linear and affine type theory and give a deterministic unification algorithm
that computes most general unifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2796</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2796</id><created>2010-09-14</created><authors><author><keyname>Lederman</keyname><forenames>Dror</forenames></author></authors><title>Estimation of Infants' Cry Fundamental Frequency using a Modified SIFT
  algorithm</title><categories>cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of infants' cry fundamental frequency
estimation. The fundamental frequency is estimated using a modified simple
inverse filtering tracking (SIFT) algorithm. The performance of the modified
SIFT is studied using a real database of infants' cry. It is shown that the
algorithm is capable of overcoming the problem of under-estimation and
over-estimation of the cry fundamental frequency, with an estimation accuracy
of 6.15% and 3.75%, for hyperphonated and phonated cry segments, respectively.
Some typical examples of the fundamental frequency contour in typical cases of
pathological and healthy cry signals are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2797</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2797</id><created>2010-09-14</created><authors><author><keyname>Kohlhase</keyname><forenames>Andrea</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author></authors><title>What we understand is what we get: Assessment in Spreadsheets</title><categories>cs.SE</categories><comments>11 Pages, 10 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 111-122
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work we have studied how an explicit representation of background
knowledge associated with a specific spreadsheet can be exploited to alleviate
usability problems with spreadsheet-based applications. We have implemented
this approach in the SACHS system to provide a semantic help system for
spreadsheets applications. In this paper, we evaluate the (comprehension)
coverage of SACHS on an Excel-based financial controlling system via a
&quot;Wizard-of-Oz&quot; experiment. This shows that SACHS adds significant value, but
systematically misses important classes of explanations. For judgements about
the information contained in spreadsheets, we provide a first approach for an
&quot;assessment module&quot; in SACHS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2803</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2803</id><created>2010-09-14</created><authors><author><keyname>Gehrke</keyname><forenames>Mai</forenames></author><author><keyname>Vosmaer</keyname><forenames>Jacob</forenames></author></authors><title>A view of canonical extension</title><categories>math.LO cs.LO</categories><comments>24 pages, 2 figures. Presented at the Eighth International Tbilisi
  Symposium on Language, Logic and Computation Bakuriani, Georgia, September
  21-25 2009</comments><journal-ref>N. Bezhanishvili and L. Spada (eds) TbiLLC 2009 proceedings, LNAI
  6618, pp. 77-100, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a short survey illustrating some of the essential aspects of the
theory of canonical extensions. In addition some topological results about
canonical extensions of lattices with additional operations in finitely
generated varieties are given. In particular, they are doubly algebraic
lattices and their interval topologies agree with their double Scott topologies
and make them Priestley topological algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2823</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2823</id><created>2010-09-14</created><authors><author><keyname>Miller</keyname><forenames>Ezra</forenames></author></authors><title>Theory and applications of lattice point methods for binomial ideals</title><categories>math.AC cs.GT math.CO math.DS</categories><comments>57 pages, 31 figures; to appear in proceedings of 2009 Abel Symposium
  (Voss, Norway)</comments><msc-class>Primary: 05E40, 20M25, 13F99, 20M14, 11P21, 20M15, 33C70, 91A46,
  91A05, 80A30, Secondary: 52B20, 20M30, 05A15, 92E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This survey of methods surrounding lattice point methods for binomial ideals
begins with a leisurely treatment of the geometric combinatorics of binomial
primary decomposition. It then proceeds to three independent applications whose
motivations come from outside of commutative algebra: hypergeometric systems,
combinatorial game theory, and chemical dynamics. The exposition is aimed at
students and researchers in algebra; it includes many examples, open problems,
and elementary introductions to the motivations and background from outside of
algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2826</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2826</id><created>2010-09-14</created><authors><author><keyname>Sarmah</keyname><forenames>Dipti Kapoor</forenames></author><author><keyname>Bajpai</keyname><forenames>Neha</forenames></author></authors><title>Proposed System for data hiding using Cryptography and Steganography
  Proposed System for data hiding using Cryptography and Steganography</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Steganography and Cryptography are two popular ways of sending vital
information in a secret way. One hides the existence of the message and the
other distorts the message itself. There are many cryptography techniques
available; among them AES is one of the most powerful techniques. In
Steganography we have various techniques in different domains like spatial
domain, frequency domain etc. to hide the message. It is very difficult to
detect hidden message in frequency domain and for this domain we use various
transformations like DCT, FFT and Wavelets etc. In this project we are
developing a system where we develop a new technique in which Cryptography and
Steganography are used as integrated part along with newly developed enhanced
security module. In Cryptography we are using AES algorithm to encrypt a
message and a part of the message is hidden in DCT of an image; remaining part
of the message is used to generate two secret keys which make this system
highly secured. Keyword: Cryptography, Steganography, Stego- image, Threshold
Value, DCT Coefficient
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2832</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2832</id><created>2010-09-15</created><authors><author><keyname>Sahasranand</keyname><forenames>K. R.</forenames></author><author><keyname>Nagaraj</keyname><forenames>Nithin</forenames></author></authors><title>Sharing Graphs</title><categories>cs.CR</categories><comments>17 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Almost all known secret sharing schemes work on numbers. Such methods will
have difficulty in sharing graphs since the number of graphs increases
exponentially with the number of nodes. We propose a secret sharing scheme for
graphs where we use graph intersection for reconstructing the secret which is
hidden as a sub graph in the shares. Our method does not rely on heavy
computational operations such as modular arithmetic or polynomial interpolation
but makes use of very basic operations like assignment and checking for
equality, and graph intersection can also be performed visually. In certain
cases, the secret could be reconstructed using just pencil and paper by
authorised parties but cannot be broken by an adversary even with unbounded
computational power. The method achieves perfect secrecy for (2, n) scheme and
requires far fewer operations compared to Shamir's algorithm. The proposed
method could be used to share objects such as matrices, sets, plain text and
even a heterogeneous collection of these. Since we do not require a previously
agreed upon encoding scheme, the method is very suitable for sharing
heterogeneous collection of objects in a dynamic fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2854</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2854</id><created>2010-09-15</created><updated>2010-10-20</updated><authors><author><keyname>Bojanczyk</keyname><forenames>Mikolaj</forenames><affiliation>Warsaw University</affiliation></author><author><keyname>Segoufin</keyname><forenames>Luc</forenames><affiliation>INRIA</affiliation></author></authors><title>Tree Languages Defined in First-Order Logic with One Quantifier
  Alternation</title><categories>cs.FL cs.LO</categories><proxy>LMCS</proxy><acm-class>cs.LO</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (October
  20, 2010) lmcs:699</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study tree languages that can be defined in \Delta_2 . These are tree
languages definable by a first-order formula whose quantifier prefix is forall
exists, and simultaneously by a first-order formula whose quantifier prefix is
. For the quantifier free part we consider two signatures, either the
descendant relation alone or together with the lexicographical order relation
on nodes. We provide an effective characterization of tree and forest languages
definable in \Delta_2 . This characterization is in terms of algebraic
equations. Over words, the class of word languages definable in \Delta_2 forms
a robust class, which was given an effective algebraic characterization by Pin
and Weil.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2858</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2858</id><created>2010-09-15</created><authors><author><keyname>Jaffres-Runser</keyname><forenames>Katia</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes, WNET</affiliation></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames><affiliation>WNET</affiliation></author></authors><title>On the performance evaluation of wireless networks with broadcast and
  interference-limited channels</title><categories>cs.NI</categories><proxy>ccsd</proxy><report-no>RR-7379</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we propose a MultiObjective (MO) performance evaluation
framework for wireless ad hoc networks where criteria such as capacity,
robustness, energy and delay are optimized concurrently. Within such a
framework, we can determine both the Pareto-optimal performance bounds and the
networking parameters that provide these bounds. The originality of this
approach is that it accounts for the inherent broadcast properties of the
transmission and finely models the interference distribution. In the proposed
model, the network performance can be optimized when several flows (source-
destination transmissions) exist. One benefit of our approach is that the
complexity does not grow with the number of flows. The other major contribution
of this paper is the new analytical formulation of the performance metrics. It
relies on a matrix representation of the constraints imposed by the
interference- limited and broadcast wireless channel. Because of the similarity
of this matrix with a Markovian transition matrix, we can exploit classical
results from Markov chains theory to derive steady state performance metrics
relative to capacity, robustness, energy and delay. Another very interesting
feature of these new metrics is that the Pareto-optimal solutions related to
them provide a tight bound on capacity, robustness, energy and delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2861</identifier>
 <datestamp>2012-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2861</id><created>2010-09-15</created><updated>2012-08-20</updated><authors><author><keyname>Heldt</keyname><forenames>Daniel</forenames></author><author><keyname>Knauer</keyname><forenames>Kolja</forenames></author><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>Edge-intersection graphs of grid paths: the bend-number</title><categories>math.CO cs.DM</categories><comments>33 pages, 20 figures</comments><msc-class>05C62</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate edge-intersection graphs of paths in the plane grid, regarding
a parameter called the bend-number. I.e., every vertex is represented by a grid
path and two vertices are adjacent if and only if the two grid paths share at
least one grid-edge. The bend-number is the minimum $k$ such that grid-paths
with at most $k$ bends each suffice to represent a given graph. This parameter
is related to the interval-number and the track-number of a graph. We show that
for every $k$ there is a graph with bend-number $k$. Moreover we provide new
upper and lower bounds of the bend-number of graphs in terms of degeneracy,
treewidth, edge clique covers and the maximum degree. Furthermore we give
bounds on the bend-number of $K_{m,n}$ and determine it exactly for some pairs
of $m$ and $n$. Finally, we prove that recognizing single-bend graphs is
NP-complete, providing the first such result in this field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2876</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2876</id><created>2010-09-15</created><authors><author><keyname>Ch&#xe8;ze</keyname><forenames>Guillaume</forenames><affiliation>IMT</affiliation></author></authors><title>Computation of Darboux polynomials and rational first integrals with
  bounded degree in polynomial time</title><categories>math.CA cs.SC math.AC</categories><proxy>ccsd</proxy><journal-ref>Journal of Complexity 27, 2 (2011) 246-262</journal-ref><doi>10.1016/j.jco.2010.10.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study planar polynomial differential systems of this form:
dX/dt=A(X, Y), dY/dt= B(X, Y), where A,B belongs to Z[X, Y], degA \leq d, degB
\leq d, and the height of A and B is smaller than H. A lot of properties of
planar polynomial differential systems are related to irreducible Darboux
polynomials of the corresponding derivation: D =A(X, Y)dX + B(X, Y)dY . Darboux
polynomials are usually computed with the method of undetermined coefficients.
With this method we have to solve a polynomial system. We show that this
approach can give rise to the computation of an exponential number of reducible
Darboux polynomials. Here we show that the Lagutinskii-Pereira's algorithm
computes irreducible Darboux polynomials with degree smaller than N, with a
polynomial number, relatively to d, log(H) and N, binary operations. We also
give a polynomial-time method to compute, if it exists, a rational first
integral with bounded degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2893</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2893</id><created>2010-09-15</created><updated>2010-09-20</updated><authors><author><keyname>Kontinen</keyname><forenames>Juha</forenames><affiliation>University of Helsinki, Finland</affiliation></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames><affiliation>University of Hannover, Germany</affiliation></author></authors><title>On Second-Order Monadic Monoidal and Groupoidal Quantifiers</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  20, 2010) lmcs:1006</journal-ref><doi>10.2168/LMCS-6(3:25)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study logics defined in terms of second-order monadic monoidal and
groupoidal quantifiers. These are generalized quantifiers defined by monoid and
groupoid word-problems, equivalently, by regular and context-free languages. We
give a computational classification of the expressive power of these logics
over strings with varying built-in predicates. In particular, we show that
ATIME(n) can be logically characterized in terms of second-order monadic
monoidal quantifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2900</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2900</id><created>2010-09-15</created><authors><author><keyname>Betz</keyname><forenames>Hariolf</forenames></author><author><keyname>Fr&#xfc;hwirth</keyname><forenames>Thom W.</forenames></author></authors><title>Linear-Logic Based Analysis of Constraint Handling Rules with
  Disjunction</title><categories>cs.PL</categories><acm-class>F.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint Handling Rules (CHR) is a declarative committed-choice programming
language with a strong relationship to linear logic. Its generalization CHR
with Disjunction (CHRv) is a multi-paradigm declarative programming language
that allows the embedding of horn programs. We analyse the assets and the
limitations of the classical declarative semantics of CHR before we motivate
and develop a linear-logic declarative semantics for CHR and CHRv. We show how
to apply the linear-logic semantics to decide program properties and to prove
operational equivalence of CHRv programs across the boundaries of language
paradigms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2902</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2902</id><created>2010-09-15</created><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author></authors><title>Informal Control code logic</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General definitions as well as rules of reasoning regarding control code
production, distribution, deployment, and usage are described. The role of
testing, trust, confidence and risk analysis is considered. A rationale for
control code testing is sought and found for the case of safety critical
embedded control code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2913</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2913</id><created>2010-09-15</created><updated>2011-04-15</updated><authors><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author><author><keyname>Ramasco</keyname><forenames>Jos&#xe9; J.</forenames></author><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author></authors><title>Information filtering in complex weighted networks</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.IR</categories><comments>9 pages, 7 figures, 1 Table. The GloSS filter is implemented in a
  freely downloadable software (http://filrad.homelinux.org/resources)</comments><journal-ref>Phys. Rev. E 83, 046101 (2011)</journal-ref><doi>10.1103/PhysRevE.83.046101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many systems in nature, society and technology can be described as networks,
where the vertices are the system's elements and edges between vertices
indicate the interactions between the corresponding elements. Edges may be
weighted if the interaction strength is measurable. However, the full network
information is often redundant because tools and techniques from network
analysis do not work or become very inefficient if the network is too dense and
some weights may just reflect measurement errors, and shall be discarded.
Moreover, since weight distributions in many complex weighted networks are
broad, most of the weight is concentrated among a small fraction of all edges.
It is then crucial to properly detect relevant edges. Simple thresholding would
leave only the largest weights, disrupting the multiscale structure of the
system, which is at the basis of the structure of complex networks, and ought
to be kept. In this paper we propose a weight filtering technique based on a
global null model (GloSS filter), keeping both the weight distribution and the
full topological structure of the network. The method correctly quantifies the
statistical significance of weights assigned independently to the edges from a
given distribution. Applications to real networks reveal that the GloSS filter
is indeed able to identify relevantconnections between vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2927</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2927</id><created>2010-09-15</created><authors><author><keyname>Yi</keyname><forenames>Na</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author><author><keyname>Tafazolli</keyname><forenames>Rahim</forenames></author></authors><title>Underlay Cognitive Radio with Full or Partial Channel Quality
  Information</title><categories>cs.IT math.IT</categories><comments>29 Pages, 8 figures</comments><journal-ref>International Journal of Navigation and Observation 2010</journal-ref><doi>10.1155/2010/105723</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underlay cognitive radios (UCRs) allow a secondary user to enter a primary
user's spectrum through intelligent utilization of multiuser channel quality
information (CQI) and sharing of codebook. The aim of this work is to study
two-user Gaussian UCR systems by assuming the full or partial knowledge of
multiuser CQI. Key contribution of this work is motivated by the fact that the
full knowledge of multiuser CQI is not always available. We first establish a
location-aided UCR model where the secondary user is assumed to have partial
CQI about the secondary-transmitter to primary-receiver link as well as full
CQI about the other links. Then, new UCR approaches are proposed and carefully
analyzed in terms of the secondary user's achievable rate, denoted by $C_2$,
the capacity penalty to primary user, denoted by $\Delta C_1$, and capacity
outage probability. Numerical examples are provided to visually compare the
performance of UCRs with full knowledge of multiuser CQI and the proposed
approaches with partial knowledge of multiuser CQI.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="15000" completeListSize="102538">1122234|16001</resumptionToken>
</ListRecords>
</OAI-PMH>
