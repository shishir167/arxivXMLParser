<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T01:02:39Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|34001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2892</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2892</id><created>2012-07-12</created><authors><author><keyname>Asperti</keyname><forenames>Andrea</forenames></author><author><keyname>Ricciotti</keyname><forenames>Wilmer</forenames></author></authors><title>A Web Interface for Matita</title><categories>cs.LO cs.SE</categories><journal-ref>Intelligent Computer Mathematics, Lecture Notes in Computer
  Science, 2012, Volume 7362/2012, pp. 417-421</journal-ref><doi>10.1007/978-3-642-31374-5_28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a prototype implementation of a web interface for the
Matita proof assistant. The interface supports all basic functionalities of the
local Gtk interface, but takes advantage of the markup to enrich the document
with several kinds of annotations or active elements. Annotations may have both
a presentational/hypertextual nature, aimed to improve the quality of the proof
script as a human readable document, or a more semantic nature, aimed to help
the system in its processing of the script. The latter kind comprises
information automatically generated by the proof assistant during previous
compilations, and stored to improve the performance of re-executing expensive
operations like disambiguation or automation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2900</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2900</id><created>2012-07-12</created><authors><author><keyname>Rajesh</keyname><forenames>P.</forenames></author><author><keyname>Narasimha</keyname><forenames>G.</forenames></author><author><keyname>Saisumanth</keyname><forenames>N.</forenames></author></authors><title>Privacy Preserving MFI Based Similarity Measure For Hierarchical
  Document Clustering</title><categories>cs.DB cs.IR</categories><comments>6 pages,1 table,1 figure</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing nature of World Wide Web has imposed great challenges for
researchers in improving the search efficiency over the internet. Now days web
document clustering has become an important research topic to provide most
relevant documents in huge volumes of results returned in response to a simple
query. In this paper, first we proposed a novel approach, to precisely define
clusters based on maximal frequent item set (MFI) by Apriori algorithm.
Afterwards utilizing the same maximal frequent item set (MFI) based similarity
measure for Hierarchical document clustering. By considering maximal frequent
item sets, the dimensionality of document set is decreased. Secondly, providing
privacy preserving of open web documents is to avoiding duplicate documents.
There by we can protect the privacy of individual copy rights of documents.
This can be achieved using equivalence relation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2904</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2904</id><created>2012-07-12</created><authors><author><keyname>Vasef</keyname><forenames>Mehdi</forenames></author></authors><title>Effective Capacity of a Rayleigh Fading Channel in the Presence of
  Interference</title><categories>cs.NI</categories><comments>19 Pages,IJWMN</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks 4, 3 (2012)
  1-19</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years the concept of the effective capacity that relates the
physical layer characteristics of a wireless channel to the data link layer has
gained a lot of attraction in wireless networking research community. The
effective capacity is based on G\&quot;artner-Ellis' large deviation theorem and it
is used to provide the statistical QoS provisioning in the wireless networks.
Effective capacity also helps in the analysis of the resource allocation or
scheduling policies in various wireless systems such as Relay networks,
multi-user systems and multi-carrier systems subject to statistical QoS
requirements. The effective capacity in noise limited wireless network has
already been investigated in the recent works. Considering the interference
limited wireless channels, in this paper we propose an analytical approach
based on Laplace's method for the effective capacity of uncorrelated Rayleigh
fading channel in the presence of uncorrelated Rayleigh fading interference.
The accuracy of the analytical model for the effective capacity is validated by
numerical simulations. We also provide the evaluation of tail probability of
the delay and maximum sustainable rate. The validation results reveal that the
proposed mathematical approach to the effective capacity can open the path for
further researches in statistical QoS provisioning in interference limited
wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2908</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2908</id><created>2012-07-12</created><updated>2013-12-30</updated><authors><author><keyname>Auletta</keyname><forenames>Vincenzo</forenames></author><author><keyname>Ferraioli</keyname><forenames>Diodato</forenames></author><author><keyname>Pasquale</keyname><forenames>Francesco</forenames></author><author><keyname>Penna</keyname><forenames>Paolo</forenames></author><author><keyname>Persiano</keyname><forenames>Giuseppe</forenames></author></authors><title>Logit Dynamics with Concurrent Updates for Local-Interaction Games</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logit choice dynamics are a family of randomized best response dynamics based
on the logit choice function [McFadden, 1974], used for modeling players with
limited rationality and knowledge. In this paper we study the all-logit
dynamics, where at each time step all players concurrently update their
strategies according to the logit choice function. In the well studied
one-logit dynamics [Blume, 1993] instead at each step only one randomly chosen
player is allowed to update.
  We study properties of the all-logit dynamics in the context of local
interaction games, a class of games that has been used to model complex social
phenomena and physical systems. In a local interaction game, players are the
vertices of a social graph whose edges are two-player potential games. Each
player picks one strategy to be played for all the games she is involved in and
the payoff of the player is the sum of the payoffs from each of the games. We
prove that local interaction games characterize the class of games for which
the all-logit dynamics is reversible.
  We then compare the stationary behavior of one-logit and all-logit dynamics.
Specifically, we look at the expected value of a notable class of observables,
that we call decomposable observables. We prove that the difference between the
expected values of the observables at stationarity for the two dynamics depends
only on the rationality level beta and on the distance of the social graph from
a bipartite graph. In particular, if the social graph is bipartite then
decomposable observables have the same expected value. Finally, we show that
the mixing time of the all-logit dynamics has the same twofold behavior that
has been highlighted in the case of the one-logit: for some games it
exponentially depends on the rationality level beta, whereas for other games it
can be upper bounded by a function independent from beta.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2922</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2922</id><created>2012-07-12</created><authors><author><keyname>Surbhi</keyname></author><author><keyname>Arora</keyname><forenames>Vishal</forenames></author></authors><title>ROI Segmentation for Feature Extraction from Human Facial Images</title><categories>cs.CV cs.HC</categories><comments>4 pages, 2 figures; International Journal of Research in Computer
  Science, pp. 61-64 (2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human Computer Interaction (HCI) is the biggest goal of computer vision
researchers. Features form the different facial images are able to provide a
very deep knowledge about the activities performed by the different facial
movements. In this paper we presented a technique for feature extraction from
various regions of interest with the help of Skin color segmentation technique,
Thresholding, knowledge based technique for face recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2936</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2936</id><created>2012-07-12</created><updated>2014-04-28</updated><authors><author><keyname>Cascudo</keyname><forenames>Ignacio</forenames></author><author><keyname>Cramer</keyname><forenames>Ronald</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author></authors><title>Torsion Limits and Riemann-Roch Systems for Function Fields and
  Applications</title><categories>math.AG cs.CR math.CO math.NT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory.
  This is an extended version of our paper in Proceedings of 31st Annual IACR
  CRYPTO, Santa Barbara, Ca., USA, 2011. The results in Sections 5 and 6 did
  not appear in that paper. A first version of this paper has been widely
  circulated since November 2009</comments><doi>10.1109/TIT.2014.2314099</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Ihara limit (or -constant) $A(q)$ has been a central problem of study in
the asymptotic theory of global function fields (or equivalently, algebraic
curves over finite fields). It addresses global function fields with many
rational points and, so far, most applications of this theory do not require
additional properties. Motivated by recent applications, we require global
function fields with the additional property that their zero class divisor
groups contain at most a small number of $d$-torsion points. We capture this by
the torsion limit, a new asymptotic quantity for global function fields. It
seems that it is even harder to determine values of this new quantity than the
Ihara constant. Nevertheless, some non-trivial lower- and upper bounds are
derived. Apart from this new asymptotic quantity and bounds on it, we also
introduce Riemann-Roch systems of equations. It turns out that this type of
equation system plays an important role in the study of several other problems
in areas such as coding theory, arithmetic secret sharing and multiplication
complexity of finite fields etc. Finally, we show how our new asymptotic
quantity, our bounds on it and Riemann-Roch systems can be used to improve
results in these areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2940</identifier>
 <datestamp>2014-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2940</id><created>2012-07-12</created><updated>2014-07-25</updated><authors><author><keyname>Deisenroth</keyname><forenames>Marc Peter</forenames></author><author><keyname>Mohamed</keyname><forenames>Shakir</forenames></author></authors><title>Expectation Propagation in Gaussian Process Dynamical Systems: Extended
  Version</title><categories>stat.ML cs.LG cs.SY</categories><journal-ref>Advances in Neural Information Processing Systems 25 (NIPS), pp.
  2609-2617, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rich and complex time-series data, such as those generated from engineering
systems, financial markets, videos or neural recordings, are now a common
feature of modern data analysis. Explaining the phenomena underlying these
diverse data sets requires flexible and accurate models. In this paper, we
promote Gaussian process dynamical systems (GPDS) as a rich model class that is
appropriate for such analysis. In particular, we present a message passing
algorithm for approximate inference in GPDSs based on expectation propagation.
By posing inference as a general message passing problem, we iterate
forward-backward smoothing. Thus, we obtain more accurate posterior
distributions over latent structures, resulting in improved predictive
performance compared to state-of-the-art GPDS smoothers, which are special
cases of our general message passing algorithm. Hence, we provide a unifying
approach within which to contextualize message passing in GPDSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2959</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2959</id><created>2012-07-12</created><authors><author><keyname>Nascimento</keyname><forenames>Abra&#xe3;o D. C.</forenames></author><author><keyname>Cintra</keyname><forenames>Renato J.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>Hypothesis Testing in Speckled Data with Stochastic Distances</title><categories>stat.ML cs.GR</categories><journal-ref>IEEE Transactions on Geoscience and Remote Sensing, vol. 48, p.
  373-385, 2010</journal-ref><doi>10.1109/TGRS.2009.2025498</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images obtained with coherent illumination, as is the case of sonar,
ultrasound-B, laser and Synthetic Aperture Radar -- SAR, are affected by
speckle noise which reduces the ability to extract information from the data.
Specialized techniques are required to deal with such imagery, which has been
modeled by the G0 distribution and under which regions with different degrees
of roughness and mean brightness can be characterized by two parameters; a
third parameter, the number of looks, is related to the overall signal-to-noise
ratio. Assessing distances between samples is an important step in image
analysis; they provide grounds of the separability and, therefore, of the
performance of classification procedures. This work derives and compares eight
stochastic distances and assesses the performance of hypothesis tests that
employ them and maximum likelihood estimation. We conclude that tests based on
the triangular distance have the closest empirical size to the theoretical one,
while those based on the arithmetic-geometric distances have the best power.
Since the power of tests based on the triangular distance is close to optimum,
we conclude that the safest choice is using this distance for hypothesis
testing, even when compared with classical distances as Kullback-Leibler and
Bhattacharyya.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2991</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2991</id><created>2012-07-12</created><authors><author><keyname>Gupta</keyname><forenames>Isha</forenames></author></authors><title>BIGP- a new single protocol that can work as an igp (interior gateway
  protocol) as well as egp (exterior gateway protocol)</title><categories>cs.NI</categories><comments>5 Pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EGP and IGP are the key components of the present internet infrastructure.
Routers in a domain forward IP packet within and between domains. Each domain
uses an intra-domain routing protocol known as Interior Gateway Protocol (IGP)
like IS-IS, OSPF, RIP etc to populate the routing tables of its routers.
Routing information must also be exchanged between domains to ensure that a
host in one domain can reach another host in remote domain. This role is
performed by inter-domain routing protocol called Exterior Gateway Protocol
(EGP). Basically EGP used these days is Border Gateway Protocol (BGP). Basic
difference between the both is that BGP has smaller convergence as compared to
the IGP's. And IGP's on the other hand have lesser scalability as compared to
the BGP. So in this paper a proposal to create a new protocol is given which
can act as an IGP when we consider inter-domain transfer of traffic and acts as
BGP when we consider intra-domain transfer of traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3012</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3012</id><created>2012-07-12</created><updated>2013-02-07</updated><authors><author><keyname>Ramdas</keyname><forenames>Aaditya</forenames></author><author><keyname>Singh</keyname><forenames>Aarti</forenames></author></authors><title>Optimal rates for first-order stochastic convex optimization under
  Tsybakov noise condition</title><categories>cs.LG stat.ML</categories><comments>Accepted for publication at ICML 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on the problem of minimizing a convex function $f$ over a convex set
$S$ given $T$ queries to a stochastic first order oracle. We argue that the
complexity of convex minimization is only determined by the rate of growth of
the function around its minimizer $x^*_{f,S}$, as quantified by a Tsybakov-like
noise condition. Specifically, we prove that if $f$ grows at least as fast as
$\|x-x^*_{f,S}\|^\kappa$ around its minimum, for some $\kappa &gt; 1$, then the
optimal rate of learning $f(x^*_{f,S})$ is
$\Theta(T^{-\frac{\kappa}{2\kappa-2}})$. The classic rate $\Theta(1/\sqrt T)$
for convex functions and $\Theta(1/T)$ for strongly convex functions are
special cases of our result for $\kappa \rightarrow \infty$ and $\kappa=2$, and
even faster rates are attained for $\kappa &lt;2$. We also derive tight bounds for
the complexity of learning $x_{f,S}^*$, where the optimal rate is
$\Theta(T^{-\frac{1}{2\kappa-2}})$. Interestingly, these precise rates for
convex optimization also characterize the complexity of active learning and our
results further strengthen the connections between the two fields, both of
which rely on feedback-driven queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3018</identifier>
 <datestamp>2013-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3018</id><created>2012-07-12</created><updated>2013-02-15</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author></authors><title>Fundamental Limits of Communications in Interference Networks-Part I:
  Basic Structures</title><categories>cs.IT math.IT</categories><comments>A table of contents is given</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In these series of multi-part papers, a systematic study of fundamental
limits of communications in interference networks is established. Here,
interference network is referred to as a general single-hop communication
scenario with arbitrary number of transmitters and receivers, and also
arbitrary distribution of messages among transmitters and receivers. It is
shown that the information flow in such networks follows similar derivations
from many aspects. This systematic study is launched by considering the basic
building blocks in Part I. The Multiple Access Channel (MAC), the Broadcast
Channel (BC), the Classical Interference Channel (CIC) and the Cognitive Radio
Channel (CRC) are proposed as the main building blocks for all interference
networks. First, a brief review of existing results regarding these basic
structures is presented. New observations are also presented in this regard.
Specifically, it is shown that the well-known strong interference conditions
for the two-user CIC do not change if the inputs are dependent. Next, new
capacity outer bounds are established for the basic structures with two
receivers. These outer bounds are all derived based on a unified framework. By
using the derived outer bounds, some new capacity results are proved for the
CIC and the CRC; a mixed interference regime is identified for the two-user
discrete CIC where the sum-rate capacity is established. Also, a noisy
interference regime is derived for the one-sided discrete CIC. For the CRC, a
full characterization of the capacity region for a class of more-capable
channels is obtained. Moreover, it is shown that the derived outer bounds are
useful to study the channels with one-sided receiver side information wherein
one of the receivers has access to the non-intended message; capacity bounds
are also discussed in details for such scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3019</identifier>
 <datestamp>2012-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3019</id><created>2012-07-12</created><updated>2012-10-16</updated><authors><author><keyname>Shen</keyname><forenames>Fei</forenames></author><author><keyname>Wu</keyname><forenames>Wenyuan</forenames></author><author><keyname>Xia</keyname><forenames>Bican</forenames></author></authors><title>Real Root Isolation of Polynomial Equations Based on Hybrid Computation</title><categories>cs.SC</categories><comments>23 pages. Accepted by ASCM2012. Some typos have been corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm for real root isolation of polynomial equations based on
hybrid computation is presented in this paper. Firstly, the approximate
(complex) zeros of the given polynomial equations are obtained via homotopy
continuation method. Then, for each approximate zero, an initial box relying on
the Kantorovich theorem is constructed, which contains the corresponding
accurate zero. Finally, the Krawczyk interval iteration with interval
arithmetic is applied to the initial boxes so as to check whether or not the
corresponding approximate zeros are real and to obtain the real root isolation
boxes. Meanwhile, an empirical construction of initial box is provided for
higher performance. Our experiments on many benchmarks show that the new hybrid
method is more efficient, compared with the traditional symbolic approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3024</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3024</id><created>2012-07-12</created><updated>2014-07-06</updated><authors><author><keyname>Bento</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Ioannidis</keyname><forenames>Stratis</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Yan</keyname><forenames>Jinyun</forenames></author></authors><title>A Time and Space Efficient Algorithm for Contextual Linear Bandits</title><categories>cs.DS cs.GT</categories><comments>European Conference on Machine Learning and Principles and Practice
  of Knowledge Discovery in Databases (ECMLPKDD 2013), Prague, Czech Republic,
  September 23-27, 2013. Proceedings. Springer, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-armed bandit problem where payoffs are a linear function
of an observed stochastic contextual variable. In the scenario where there
exists a gap between optimal and suboptimal rewards, several algorithms have
been proposed that achieve $O(\log T)$ regret after $T$ time steps. However,
proposed methods either have a computation complexity per iteration that scales
linearly with $T$ or achieve regrets that grow linearly with the number of
contexts $|\myset{X}|$. We propose an $\epsilon$-greedy type of algorithm that
solves both limitations. In particular, when contexts are variables in
$\reals^d$, we prove that our algorithm has a constant computation complexity
per iteration of $O(poly(d))$ and can achieve a regret of $O(poly(d) \log T)$
even when $|\myset{X}| = \Omega (2^d) $. In addition, unlike previous
algorithms, its space complexity scales like $O(Kd^2)$ and does not grow with
$T$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3027</identifier>
 <datestamp>2013-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3027</id><created>2012-07-12</created><updated>2013-02-15</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author></authors><title>Fundamental Limits of Communications in Interference Networks-Part II:
  Information Flow in Degraded Networks</title><categories>cs.IT math.IT</categories><comments>A table of contents is given</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this second part of our multi-part papers, the information flow in
degraded interference networks is studied. A full characterization of the
sum-rate capacity for the degraded networks with any possible configuration is
established. It is shown that a successive decoding scheme is sum-rate optimal
for these networks. Also, it is proved that the transmission of only a certain
subset of messages is sufficient to achieve the sum-rate capacity in such
networks. Algorithms are presented to determine this subset of messages
explicitly. According to these algorithms, the optimal strategy to achieve the
sum-rate capacity in degraded networks is that the transmitters try to send
information for the stronger receivers and, if possible, avoid sending the
messages with respect to the weaker receivers. The algorithms are easily
understood using our graphical illustrations for the achievability schemes
based on directed graphs. The sum-rate expression for the degraded networks is
then used to derive a unified outer bound on the sum-rate capacity of arbitrary
non-degraded networks. Several variations of the degraded networks are
identified for which the derived outer bound is sum-rate optimal. Specifically,
noisy interference regimes are derived for certain classes of
multi-user/multi-message interference networks. Also, for the first time,
network scenarios are identified where the incorporation of both successive
decoding and treating interference as noise achieves their sum-rate capacity.
Finally, by taking insight from our results for degraded networks, we establish
a unified outer bound on the entire capacity region of the general interference
networks. These outer bounds for a broad range of network scenarios are tighter
than the existing cut-set bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3031</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3031</id><created>2012-07-12</created><updated>2012-07-19</updated><authors><author><keyname>Tsianos</keyname><forenames>Konstantinos I.</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>Distributed Strongly Convex Optimization</title><categories>cs.DC cs.LG stat.ML</categories><comments>18 pages single column draftcls format, 1 figure, Submitted to
  Allerton 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lot of effort has been invested into characterizing the convergence rates
of gradient based algorithms for non-linear convex optimization. Recently,
motivated by large datasets and problems in machine learning, the interest has
shifted towards distributed optimization. In this work we present a distributed
algorithm for strongly convex constrained optimization. Each node in a network
of n computers converges to the optimum of a strongly convex, L-Lipchitz
continuous, separable objective at a rate O(log (sqrt(n) T) / T) where T is the
number of iterations. This rate is achieved in the online setting where the
data is revealed one at a time to the nodes, and in the batch setting where
each node has access to its full local dataset from the start. The same
convergence rate is achieved in expectation when the subgradients used at each
node are corrupted with additive zero-mean noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3035</identifier>
 <datestamp>2013-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3035</id><created>2012-07-12</created><updated>2013-02-15</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author></authors><title>Fundamental Limits of Communications in Interference Networks-Part III:
  Information Flow in Strong Interference Regime</title><categories>cs.IT math.IT</categories><comments>A table of contents is given</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This third part of the paper is related to the study of information flow in
networks with strong interference. First, the two-receiver networks are
considered. A unified outer bound for the capacity region of these networks is
established. It is shown that this outer bound can be systematically translated
into simple capacity outer bounds for special cases such as the two-user
Classical Interference Channel (CIC) and the Broadcast Channel with Cognitive
Relays (BCCR) with common information. For these channels, special cases are
presented where our outer bounds are tight, which yield the exact capacity.
More importantly, by using the derived outer bounds, a strong interference
regime is identified for the general two-receiver interference networks with
any arbitrary topology. This strong interference regime, which is represented
by only two conditions, includes all previously known results for simple
topologies such as the two-user CIC, the cognitive radio channel, and many
others. Then, networks with arbitrary number of receivers are considered.
Finding non-trivial strong interference regime for such networks, specifically
for the CICs with more than two users, has been one of the open problems in
network information theory. In this paper, we will give a solution to this
problem. Specifically, a new approach is developed based on which one can
obtain strong interference regimes not only for the multi-user CICs but also
for any interference network of arbitrary large sizes. For this development,
some new technical lemmas are proved which have a central role in the
derivations. As a result, this paper establishes the first non-trivial capacity
result for the multi-user classical interference channel. A general formula is
also presented to derive strong interference conditions for any given network
topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3036</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3036</id><created>2012-07-11</created><authors><author><keyname>SureshKumar</keyname><forenames>M.</forenames></author><author><keyname>Varalakshmi</keyname><forenames>P.</forenames></author></authors><title>Dynamic Web Service Composition based on Network Modeling with
  Statistical Analysis and Backtracking</title><categories>cs.SE</categories><comments>arXiv admin note: text overlap with arXiv:1003.1502 by other authors</comments><doi>10.5121/ijwsc.2012.3202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Web service is a software system designed to support interoperable
machine-to-machine interaction over a network. Web services provide a standard
means of interoperating between different software applications, running on a
variety of platforms and/or frameworks. One of the main advantages of the usage
of web services is its ability to integrate with the other services through web
service composition and realize the required functionality. This paper presents
a new paradigm of dynamic web services composition using network analysis
paired with backtracking. An algorithm called &quot;Zeittafel&quot; for the selection and
scheduling of services that are to be composed is also presented. With the
proposed system better percentage of job success rate is obtained compared to
the existing methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3037</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3037</id><created>2012-07-11</created><authors><author><keyname>Mirajkar</keyname><forenames>Nandan</forenames></author><author><keyname>Barde</keyname><forenames>Mohan</forenames></author><author><keyname>Kamble</keyname><forenames>Harshal</forenames></author><author><keyname>Athale</keyname><forenames>Dr. Rahul</forenames></author><author><keyname>Singh</keyname><forenames>Kumud</forenames></author></authors><title>Implementation of Private Cloud using Eucalyptus and an open source
  Operating System</title><categories>cs.DC</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 3, No 3, May 2012 ISSN (Online): 1694-0814</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Cloud computing is bringing a revolution in computing environment replacing
traditional software installations, licensing issues into complete on-demand
services through internet. Microsoft office 365 a cloud based office
application is available to clients online hence no need to buy and install the
software. On Facebook a social networking website, users upload videos which
uses cloud provider's storage service so less hardware cost for
clients.Virtualization technology has great contribution in advent of cloud
computing. Paper describes implementation of Private Cloud using open source
operating system Ubuntu 10.04 server edition, installation of Ubuntu Enterprise
Cloud with Eucalyptus 1.6.2 and providing CentOS 5.3 operating system through
cloud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3040</identifier>
 <datestamp>2013-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3040</id><created>2012-07-12</created><updated>2013-02-15</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author></authors><title>Fundamental Limits of Communications in Interference Networks-Part IV:
  Networks with a Sequence of Less-Noisy Receivers</title><categories>cs.IT math.IT</categories><comments>A table of contents is given</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this fourth part of our multi-part papers, classes of interference
networks with a sequence of less-noisy receivers are identified for which a
successive decoding scheme achieve the sum-rate capacity. First, the
two-receiver networks are analyzed: it is demonstrated that the unified outer
bounds derived in Part III of our multi-part papers are sum-rate optimal for
network scenarios which satisfy certain less-noisy conditions. Then, the
multi-receiver networks are considered. These networks are far less understood.
One of the main difficulties in the analysis of such scenarios is how to
establish useful capacity outer bounds. In this paper, a novel technique
requiring a sequential application of the Csiszar-Korner identity is developed
to establish powerful single-letter outer bounds on the sum-rate capacity of
multi-receiver interference networks which satisfy certain less-noisy
conditions. By using these outer bounds, a full characterization of the
sum-rate capacity is derived for general interference networks of arbitrary
large sizes with a sequence of less-noisy receivers. Some generalizations of
these outer bounds are also presented each of which is efficient to obtain the
exact sum-rate capacity for various scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3045</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3045</id><created>2012-07-12</created><updated>2013-07-16</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author></authors><title>The K-User Interference Channel: Strong Interference Regime</title><categories>cs.IT math.IT</categories><comments>Appeared in Proc. of IEEE ISIT 2013, Turkey. arXiv admin note: text
  overlap with arXiv:1207.3035</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives a solution to one of the long-standing open problems in
network information theory: &quot;What is the generalization of the strong
interference regime to the K-user interference channel?&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3050</identifier>
 <datestamp>2013-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3050</id><created>2012-07-12</created><updated>2013-02-07</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author></authors><title>How Much Rate Splitting Is Required for a Random Coding Scheme? A new
  Achievable Rate Region for the Broadcast Channel with Cognitive Relays</title><categories>cs.IT math.IT</categories><comments>Presented at 50th Annual Allerton Conference on Communication,
  Control, and Computing, Monticello, IL, Oct. 2012. arXiv admin note:
  substantial text overlap with arXiv:1207.3035, arXiv:3018</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, it is shown that for any given single-hop communication
network with two receivers, splitting messages into more than two sub-messages
in a random coding scheme is redundant. To this end, the Broadcast Channel with
Cognitive Relays (BCCR) is considered. A novel achievability scheme is designed
for this network. Our achievability design is derived by a systematic
combination of the best known achievability schemes for the basic building
blocks included in the network: the Han-Kobayashi scheme for the two-user
interference channel and the Marton coding scheme for the broadcast channel.
Meanwhile, in our scheme each private message is split into only two
sub-messages which is identically exploited also in the Han-Kobayashi scheme.
It is shown that the resultant achievable rate region includes previous results
as well. More importantly, the procedure of the achievability design is
described by graphical illustrations based on directed graphs. Then, it is
argued that by extending the proposed scheme on the MACCM plan of messages, one
can derive similar achievability schemes for any other single-hop communication
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3051</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3051</id><created>2012-07-12</created><authors><author><keyname>Travieso</keyname><forenames>Gonzalo</forenames></author><author><keyname>Ruggiero</keyname><forenames>Carlos A.</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir M.</forenames></author><author><keyname>Costa</keyname><forenames>Luciano da F.</forenames></author></authors><title>Predicting Efficiency in master-slave grid computing systems</title><categories>physics.comp-ph cs.DC physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work reports a quantitative analysis to predicting the efficiency of
distributed computing running in three models of complex networks:
Barab\'asi-Albert, Erd\H{o}s-R\'enyi and Watts-Strogatz. A master/slave
computing model is simulated. A node is selected as master and distributes
tasks among the other nodes (the clients). Topological measurements associated
with the master node (e.g. its degree or betwenness centrality) are extracted
and considered as predictors of the total execution time. It is found that the
closeness centrality provides the best alternative. The effect of network size
was also investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3056</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3056</id><created>2012-07-12</created><updated>2012-08-24</updated><authors><author><keyname>Chaudhury</keyname><forenames>Kunal N.</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author></authors><title>Non-Local Euclidean Medians</title><categories>cs.CV cs.DS</categories><comments>6 figures, 1 table</comments><journal-ref>IEEE Signal Processing Letters, vol. 19(11), pp. 745 - 748, 2012</journal-ref><doi>10.1109/LSP.2012.2217329</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we note that the denoising performance of Non-Local Means
(NLM) at large noise levels can be improved by replacing the mean by the
Euclidean median. We call this new denoising algorithm the Non-Local Euclidean
Medians (NLEM). At the heart of NLEM is the observation that the median is more
robust to outliers than the mean. In particular, we provide a simple geometric
insight that explains why NLEM performs better than NLM in the vicinity of
edges, particularly at large noise levels. NLEM can be efficiently implemented
using iteratively reweighted least squares, and its computational complexity is
comparable to that of NLM. We provide some preliminary results to study the
proposed algorithm and to compare it with NLM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3071</identifier>
 <datestamp>2013-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3071</id><created>2012-07-12</created><updated>2013-11-26</updated><authors><author><keyname>Gangeh</keyname><forenames>Mehrdad J.</forenames></author><author><keyname>Ghodsi</keyname><forenames>Ali</forenames></author><author><keyname>Kamel</keyname><forenames>Mohamed S.</forenames></author></authors><title>Supervised Texture Classification Using a Novel Compression-Based
  Similarity Measure</title><categories>cs.CV cs.LG</categories><comments>This paper has been withdrawn by the author since it has already been
  appeared in the proceedings of International Conference on Computer vision
  and Graphics (ICCVG)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised pixel-based texture classification is usually performed in the
feature space. We propose to perform this task in (dis)similarity space by
introducing a new compression-based (dis)similarity measure. The proposed
measure utilizes two dimensional MPEG-1 encoder, which takes into consideration
the spatial locality and connectivity of pixels in the images. The proposed
formulation has been carefully designed based on MPEG encoder functionality. To
this end, by design, it solely uses P-frame coding to find the (dis)similarity
among patches/images. We show that the proposed measure works properly on both
small and large patch sizes. Experimental results show that the proposed
approach significantly improves the performance of supervised pixel-based
texture classification on Brodatz and outdoor images compared to other
compression-based dissimilarity measures as well as approaches performed in
feature space. It also improves the computation speed by about 40% compared to
its rivals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3091</identifier>
 <datestamp>2014-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3091</id><created>2012-07-12</created><updated>2014-11-10</updated><authors><author><keyname>Lerner</keyname><forenames>Vladimir S.</forenames></author></authors><title>Hidden stochastic, quantum and dynamic information of Markov diffusion
  process and its evaluation by an entropy integral measure under the impulse
  controls actions, applied to information observer</title><categories>nlin.AO cs.IT math.IT</categories><comments>46 pages, 5 figures</comments><msc-class>58J65, 60J65, 93B52, 93E02, 93E15, 93E30</msc-class><acm-class>H.1.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Applied impulse controls cutoff Markov multidimensional diffusion process
during transformation to Brownian diffusion and back to Markov process,
concurrently produce Feller kernel and generate quantum information dynamics
that initiate Schr\&quot;odinger bridge and entanglement. Transition jumps describe
mixture of alternating Markov-Brownian processes which model interactive
process. Cutting correlation of random process with interacting virtual events
of real world reveals hidden classical and quantum information in each cutoff.
Entropy integral functional measures hidden information covering the process
correlations for kernel and bridge under this transformation. The interactive
information processes implies transformation of entropy portion from cutting
internal boundary to the information dynamics with feedback to attractive
external cutoff boundary of the interaction. Transforming and selecting the
entropy portion through interactive impulse creates information observer which
kills uncertainty (entropy) to get information in certain information dynamics
under minimax law of optimal extraction and consumption of information for
complex interactions. The minimax law variation equations determine structure
of the information dynamics arising at this transformation. Information path
functional integrates multiple hidden information contributions of the cutting
process correlations in information units, binds their information in doublets
and triplets structures, and enfolds this sequence in the information network
(IN) that successively decreases the entropy and maximizes information of the
micro-macrodynamics. The enclosed triplets, sequentially attaching to IN, free
the bound information, rise information forces, attract, order, structure
information units hierarchy, encode doublet-triplet logic, compose quantum,
classical computation, and integrate IN memory and coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3094</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3094</id><created>2012-07-12</created><updated>2013-07-15</updated><authors><author><keyname>Bah</keyname><forenames>Bubacarr</forenames></author><author><keyname>Tanner</keyname><forenames>Jared</forenames></author></authors><title>Vanishingly Sparse Matrices and Expander Graphs, With Application to
  Compressed Sensing</title><categories>cs.IT math.IT math.NA math.PR</categories><comments>17 pages, 12 Postscript figures</comments><msc-class>15B52, 65F50, 05C80, 42A61, 60F10 (Primary) 94A12, 94A20 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the probabilistic construction of sparse random matrices where
each column has a fixed number of nonzeros whose row indices are drawn
uniformly at random with replacement. These matrices have a one-to-one
correspondence with the adjacency matrices of fixed left degree expander
graphs. We present formulae for the expected cardinality of the set of
neighbors for these graphs, and present tail bounds on the probability that
this cardinality will be less than the expected value. Deducible from these
bounds are similar bounds for the expansion of the graph which is of interest
in many applications. These bounds are derived through a more detailed analysis
of collisions in unions of sets. Key to this analysis is a novel {\em dyadic
splitting} technique. The analysis led to the derivation of better order
constants that allow for quantitative theorems on existence of lossless
expander graphs and hence the sparse random matrices we consider and also
quantitative compressed sensing sampling theorems when using sparse non
mean-zero measurement matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3099</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3099</id><created>2012-07-12</created><authors><author><keyname>Kothapalli</keyname><forenames>Kishore</forenames></author><author><keyname>Pemmaraju</keyname><forenames>Sriram</forenames></author></authors><title>Super-Fast 3-Ruling Sets</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $t$-ruling set of a graph $G = (V, E)$ is a vertex-subset $S \subseteq V$
that is independent and satisfies the property that every vertex $v \in V$ is
at a distance of at most $t$ from some vertex in $S$. A \textit{maximal
independent set (MIS)} is a 1-ruling set. The problem of computing an MIS on a
network is a fundamental problem in distributed algorithms and the fastest
algorithm for this problem is the $O(\log n)$-round algorithm due to Luby
(SICOMP 1986) and Alon et al. (J. Algorithms 1986) from more than 25 years ago.
Since then the problem has resisted all efforts to yield to a sub-logarithmic
algorithm. There has been recent progress on this problem, most importantly an
$O(\log \Delta \cdot \sqrt{\log n})$-round algorithm on graphs with $n$
vertices and maximum degree $\Delta$, due to Barenboim et al. (Barenboim,
Elkin, Pettie, and Schneider, April 2012, arxiv 1202.1983; to appear FOCS
2012).
  We approach the MIS problem from a different angle and ask if O(1)-ruling
sets can be computed much more efficiently than an MIS? As an answer to this
question, we show how to compute a 2-ruling set of an $n$-vertex graph in
$O((\log n)^{3/4})$ rounds. We also show that the above result can be improved
for special classes of graphs such as graphs with high girth, trees, and graphs
of bounded arboricity.
  Our main technique involves randomized sparsification that rapidly reduces
the graph degree while ensuring that every deleted vertex is close to some
vertex that remains. This technique may have further applications in other
contexts, e.g., in designing sub-logarithmic distributed approximation
algorithms. Our results raise intriguing questions about how quickly an MIS (or
1-ruling sets) can be computed, given that 2-ruling sets can be computed in
sub-logarithmic rounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3100</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3100</id><created>2012-07-12</created><updated>2012-08-07</updated><authors><author><keyname>Laber</keyname><forenames>Eric B.</forenames></author><author><keyname>Lizotte</keyname><forenames>Daniel J.</forenames></author><author><keyname>Ferguson</keyname><forenames>Bradley</forenames></author></authors><title>Set-valued dynamic treatment regimes for competing outcomes</title><categories>stat.ME cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic treatment regimes operationalize the clinical decision process as a
sequence of functions, one for each clinical decision, where each function
takes as input up-to-date patient information and gives as output a single
recommended treatment. Current methods for estimating optimal dynamic treatment
regimes, for example Q-learning, require the specification of a single outcome
by which the `goodness' of competing dynamic treatment regimes are measured.
However, this is an over-simplification of the goal of clinical decision
making, which aims to balance several potentially competing outcomes. For
example, often a balance must be struck between treatment effectiveness and
side-effect burden. We propose a method for constructing dynamic treatment
regimes that accommodates competing outcomes by recommending sets of treatments
at each decision point. Formally, we construct a sequence of set-valued
functions that take as input up-to-date patient information and give as output
a recommended subset of the possible treatments. For a given patient history,
the recommended set of treatments contains all treatments that are not inferior
according to any of the competing outcomes. When there is more than one
decision point, constructing these set-valued functions requires solving a
non-trivial enumeration problem. We offer an exact enumeration algorithm by
recasting the problem as a linear mixed integer program. The proposed methods
are illustrated using data from a depression study and the CATIE schizophrenia
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3107</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3107</id><created>2012-07-12</created><updated>2013-06-30</updated><authors><author><keyname>Vila</keyname><forenames>Jeremy P.</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Expectation-Maximization Gaussian-Mixture Approximate Message Passing</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2013.2272287</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When recovering a sparse signal from noisy compressive linear measurements,
the distribution of the signal's non-zero coefficients can have a profound
effect on recovery mean-squared error (MSE). If this distribution was apriori
known, then one could use computationally efficient approximate message passing
(AMP) techniques for nearly minimum MSE (MMSE) recovery. In practice, though,
the distribution is unknown, motivating the use of robust algorithms like
LASSO---which is nearly minimax optimal---at the cost of significantly larger
MSE for non-least-favorable distributions. As an alternative, we propose an
empirical-Bayesian technique that simultaneously learns the signal distribution
while MMSE-recovering the signal---according to the learned
distribution---using AMP. In particular, we model the non-zero distribution as
a Gaussian mixture, and learn its parameters through expectation maximization,
using AMP to implement the expectation step. Numerical experiments on a wide
range of signal classes confirm the state-of-the-art performance of our
approach, in both reconstruction error and runtime, in the high-dimensional
regime, for most (but not all) sensing operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3110</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3110</id><created>2012-07-12</created><updated>2013-04-19</updated><authors><author><keyname>Kim</keyname><forenames>Joohwan</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Real-Time Peer-to-Peer Streaming Over Multiple Random Hamiltonian Cycles</title><categories>cs.NI cs.MM cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are motivated by the problem of designing a simple distributed algorithm
for Peer-to-Peer streaming applications that can achieve high throughput and
low delay, while allowing the neighbor set maintained by each peer to be small.
While previous works have mostly used tree structures, our algorithm constructs
multiple random directed Hamiltonian cycles and disseminates content over the
superposed graph of the cycles. We show that it is possible to achieve the
maximum streaming capacity even when each peer only transmits to and receives
from Theta(1) neighbors. Further, we show that the proposed algorithm achieves
the streaming delay of Theta(log N) when the streaming rate is less than
(1-1/K) of the maximum capacity for any fixed integer K&gt;1, where N denotes the
number of peers in the network. The key theoretical contribution is to
characterize the distance between peers in a graph formed by the superposition
of directed random Hamiltonian cycles, in which edges from one of the cycles
may be dropped at random. We use Doob martingales and graph expansion ideas to
characterize this distance as a function of N, with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3127</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3127</id><created>2012-07-12</created><authors><author><keyname>Wang</keyname><forenames>Quan</forenames></author><author><keyname>Ou</keyname><forenames>Yan</forenames></author><author><keyname>Julius</keyname><forenames>A. Agung</forenames></author><author><keyname>Boyer</keyname><forenames>Kim L.</forenames></author><author><keyname>Kim</keyname><forenames>Min Jun</forenames></author></authors><title>Tracking Tetrahymena Pyriformis Cells using Decision Trees</title><categories>cs.CV</categories><comments>21st International Conference on Pattern Recognition, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching cells over time has long been the most difficult step in cell
tracking. In this paper, we approach this problem by recasting it as a
classification problem. We construct a feature set for each cell, and compute a
feature difference vector between a cell in the current frame and a cell in a
previous frame. Then we determine whether the two cells represent the same cell
over time by training decision trees as our binary classifiers. With the output
of decision trees, we are able to formulate an assignment problem for our cell
association task and solve it using a modified version of the Hungarian
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3132</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3132</id><created>2012-07-12</created><authors><author><keyname>Guenda</keyname><forenames>Kenza</forenames></author><author><keyname>Gulliver</keyname><forenames>T. Aaron</forenames></author></authors><title>On the Automorphism Groups and Equivalence of Cyclic Combinatorial
  Objects</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We determine the permutation groups that arise as the automorphism groups of
cyclic combinatorial objects. As special cases we classify the automorphism
groups of cyclic codes. We also give the permutations by which two cyclic
combinatorial objects on $p^m$ elements are equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3133</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3133</id><created>2012-07-12</created><updated>2012-08-11</updated><authors><author><keyname>Guenda</keyname><forenames>Kenza</forenames></author><author><keyname>Gulliver</keyname><forenames>T. Aaron</forenames></author></authors><title>New Symmetric and Asymmetric Quantum Codes</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  New infinite families of quantum symmetric and asymmetric codes are
constructed. Several of these are MDS. The codes obtained are shown to have
parameters which are better than previously known. A number of known codes are
special cases of the codes given here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3136</identifier>
 <datestamp>2014-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3136</id><created>2012-07-12</created><updated>2014-03-15</updated><authors><author><keyname>Al-Matouq</keyname><forenames>Ali</forenames></author></authors><title>Derivation of the Maximum a Posterori Estimate for Discrete Time
  Descriptor Systems</title><categories>cs.SY math.DS math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report a derivation of the MAP state estimator objective function for
general (possibly non-square) discrete time causal/non-causal descriptor
systems is presented. The derivation made use of the Kronecker Canonical
Transformation to extract the prior distribution on the descriptor state vector
so that Maximum a Posteriori (MAP) point estimation can be used. The analysis
indicates that the MAP estimate for index 1 causal descriptor systems does not
require any model transformations and can be found recursively. Furthermore, if
the descriptor system is of index 2 or higher and the noise free system is
causal, then the MAP estimate can also be found recursively without model
transformations provided that model causality is accounted for in designing the
stochastic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3140</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3140</id><created>2012-07-12</created><authors><author><keyname>Singh</keyname><forenames>Yashpal</forenames><affiliation>Research Scholar, Mewar University, Rajasthan, India</affiliation></author><author><keyname>Deep</keyname><forenames>Kamal</forenames><affiliation>Assistant Professor, Department of Electronics and Communication, JIET Jind, Haryana, India</affiliation></author><author><keyname>Niranjan</keyname><forenames>S</forenames><affiliation>Professor, Department of Computer Science and Engineering, PDM College of Engineering Bahadurgarh, Jhajjar, Haryana, India</affiliation></author></authors><title>Multiple Criteria Clustering of Mobile Agents in WSN</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Wireless sensor networks data aggregation with hundreds and thousands of
sensor nodes is very complex task. Recently, mobile agents have been proposed
for efficient data dissemination in sensor networks. In the traditional
client/server based computing architecture, data is collected from multiple
sources and forwarded to destination for further processing. It requires high
bandwidth, whereas in the mobile agent is a task specific executable code
traverses to the relevant source for gathering data. It reduces communication
overhead, reduce cost, low bandwidth. Agents have capability to perform task
for multiple applications. It will send only useful information to destination
node. The problem is to group similar mobile agents into a number of clusters
such that each cluster has similarity in responding to a group of nodes. By
clustering intelligent mobile agents, it is possible to reduce the cost of time
for each individual agent, decrease the demand imposed on network for a set of
required tasks, decrease total number of visits. This paper, we present the
problem of Multiple Criteria Clustering of Mobile Agents (MCCMA) where the
decision is to cluster mobile agents such that a group of similar intelligent
mobile agents will visit a group of similar sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3142</identifier>
 <datestamp>2012-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3142</id><created>2012-07-13</created><updated>2012-11-08</updated><authors><author><keyname>Li</keyname><forenames>Bing</forenames></author><author><keyname>Xiong</keyname><forenames>Weihua</forenames></author><author><keyname>Hu</keyname><forenames>Weiming</forenames></author></authors><title>Color Constancy based on Image Similarity via Bilayer Sparse Coding</title><categories>cs.CV</categories><comments>14pages, 2figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational color constancy is a very important topic in computer vision
and has attracted many researchers' attention. Recently, lots of research has
shown the effects of high level visual content information for illumination
estimation. However, all of these existing methods are essentially
combinational strategies in which image's content analysis is only used to
guide the combination or selection from a variety of individual illumination
estimation methods. In this paper, we propose a novel bilayer sparse coding
model for illumination estimation that considers image similarity in terms of
both low level color distribution and high level image scene content
simultaneously. For the purpose, the image's scene content information is
integrated with its color distribution to obtain optimal illumination
estimation model. The experimental results on two real-world image sets show
that our algorithm is superior to other prevailing illumination estimation
methods, even better than combinational methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3146</identifier>
 <datestamp>2015-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3146</id><created>2012-07-13</created><updated>2015-01-12</updated><authors><author><keyname>Padakandla</keyname><forenames>Arun</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>Achievable rate region for three user discrete broadcast channel based
  on coset codes</title><categories>cs.IT math.IT</categories><comments>A non-additive 3-user discrete broadcast channel is identified for
  which achievable rate region based on coset codes is analytically proven to
  be strictly larger than that achievable using unstructured iid codes. This
  version is submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an achievable rate region for the general three user discrete
memoryless broadcast channel, based on nested coset codes. We characterize
3-to-1 discrete broadcast channels, a class of broadcast channels for which the
best known coding technique\footnote{We henceforth refer to this as Marton's
coding for three user discrete broadcast channel.}, which is obtained by a
natural generalization of that proposed by Marton for the general two user
discrete broadcast channel, is strictly sub-optimal. In particular, we identify
a novel 3-to-1 discrete broadcast channel for which Marton's coding is
\textit{analytically} proved to be strictly suboptimal. We present achievable
rate regions for the general 3-to-1 discrete broadcast channels, based on
nested coset codes, that strictly enlarge Marton's rate region for the
aforementioned channel. We generalize this to present achievable rate region
for the general three user discrete broadcast channel. Combining together
Marton's coding and that proposed herein, we propose the best known coding
technique, for a general three user discrete broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3154</identifier>
 <datestamp>2012-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3154</id><created>2012-07-13</created><updated>2012-09-06</updated><authors><author><keyname>Stewart</keyname><forenames>Fraser</forenames></author></authors><title>Escape and Evasion on Finite Graphs</title><categories>math.CO cs.CC</categories><comments>This paper has been withdrawn due to an error with theorem 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we will be introducing a type of game which as far as this
author is aware has never been studied before. These are games where there are
two players, one who is trying to get one of his pieces, called a King to a
predefined escape vertex, and the other, called attackers, who is trying to
capture him by occupying all of his neighbours. We will be showing that this
game is PSpace-complete if it is limited to $M$ moves and taking a brief look
at some potential ways to simplify the problem and work out how many attackers
are needed to capture the King on different types of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3165</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3165</id><created>2012-07-13</created><updated>2013-03-11</updated><authors><author><keyname>B&#xfc;sing</keyname><forenames>Christina</forenames><affiliation>RWTH Aachen</affiliation></author><author><keyname>Goetzmann</keyname><forenames>Kai-Simon</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Matuschke</keyname><forenames>Jannik</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Stiller</keyname><forenames>Sebastian</forenames><affiliation>TU Berlin</affiliation></author></authors><title>Reference Point Methods and Approximation in Multicriteria Optimization</title><categories>cs.DS cs.DM</categories><comments>19 pages. Submitted. Small error in Section 4 corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operations research applications often pose multicriteria problems.
Mathematical research on multicriteria problems predominantly revolves around
the set of Pareto optimal solutions, while in practice, methods that output a
single solution are more widespread. In real-world multicriteria optimization,
reference point methods are widely used and successful examples of such
methods. A reference point solution is the solution closest to a given
reference point in the objective space.
  We study the approximation of reference point solutions. In particular, we
establish that approximating reference point solutions is polynomially
equivalent to approximating the Pareto set. Complementing these results, we
show for a number of general algorithmic techniques in single criteria
optimization how they can be lifted to reference point optimization. In
particular, we lift the link between dynamic programming and FPTAS, as well as
oblivious LP-rounding techniques. The latter applies, e.g., to Set Cover and
several machine scheduling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3169</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3169</id><created>2012-07-13</created><updated>2012-09-29</updated><authors><author><keyname>Semple</keyname><forenames>Stuart</forenames></author><author><keyname>Hsu</keyname><forenames>Minna J.</forenames></author><author><keyname>Agoramoorthy</keyname><forenames>Govindasamy</forenames></author><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author></authors><title>The law of brevity in macaque vocal communication is not an artifact of
  analyzing mean call durations</title><categories>q-bio.NC cs.CL physics.data-an</categories><comments>Little improvements of the statistical arguments</comments><journal-ref>Journal of Quantitative Linguistics, 20 (3), 209-217 (2013)</journal-ref><doi>10.1080/09296174.2013.799917</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Words follow the law of brevity, i.e. more frequent words tend to be shorter.
From a statistical point of view, this qualitative definition of the law states
that word length and word frequency are negatively correlated. Here the recent
finding of patterning consistent with the law of brevity in Formosan macaque
vocal communication (Semple et al., 2010) is revisited. It is shown that the
negative correlation between mean duration and frequency of use in the
vocalizations of Formosan macaques is not an artifact of the use of a mean
duration for each call type instead of the customary 'word' length of studies
of the law in human language. The key point demonstrated is that the total
duration of calls of a particular type increases with the number of calls of
that type. The finding of the law of brevity in the vocalizations of these
macaques therefore defies a trivial explanation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3178</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3178</id><created>2012-07-13</created><updated>2014-05-05</updated><authors><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author><author><keyname>Shames</keyname><forenames>Iman</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author></authors><title>Distributed MPC Via Dual Decomposition and Alternating Direction Method
  of Multipliers</title><categories>math.OC cs.SY</categories><comments>Fixed Typos</comments><journal-ref>Distributed Distributed Model Predictive Control Made Easy (J. M.
  Maestre and R. R. Negenborn, eds.), Intelligent Systems, Control and
  Automation: Science and Engineering, 69, Springer, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conventional way to handle model predictive control (MPC) problems
distributedly is to solve them via dual decomposition and gradient ascent.
However, at each time-step, it might not be feasible to wait for the dual
algorithm to converge. As a result, the algorithm might be needed to be
terminated prematurely. One is then interested to see if the solution at the
point of termination is close to the optimal solution and when one should
terminate the algorithm if a certain distance to optimality is to be
guaranteed. In this chapter, we look at this problem for distributed systems
under general dynamical and performance couplings, then, we make a statement on
validity of similar results where the problem is solved using alternating
direction method of multipliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3202</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3202</id><created>2012-07-13</created><updated>2013-03-08</updated><authors><author><keyname>Kerber</keyname><forenames>Michael</forenames></author></authors><title>Embedding the dual complex of hyper-rectangular partitions</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rectangular partition is the partition of an (axis-aligned) rectangle into
interior-disjoint rectangles. We ask whether a rectangular partition permits a
&quot;nice&quot; drawing of its dual, that is, a straight-line embedding of it such that
each dual vertex is placed into the rectangle that it represents. We show that
deciding whether such a drawing exists is NP-complete. Moreover, we consider
the drawing where a vertex is placed in the center of the represented rectangle
and consider sufficient conditions for this drawing to be nice. This question
is studied both in the plane and for the higher-dimensional generalization of
rectangular partitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3205</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3205</id><created>2012-07-13</created><updated>2012-07-30</updated><authors><author><keyname>Ball</keyname><forenames>Frank</forenames></author><author><keyname>Britton</keyname><forenames>Tom</forenames></author><author><keyname>Sirl</keyname><forenames>David</forenames></author></authors><title>A network with tunable clustering, degree correlation and degree
  distribution, and an epidemic thereon</title><categories>math.PR cs.SI physics.soc-ph q-bio.PE</categories><comments>Minor change only: corrected error in reference list. Previous
  version gave details of the incorrect Miller (2009) paper</comments><msc-class>92D30, 05C80, 60J80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A random network model which allows for tunable, quite general forms of
clustering, degree correlation and degree distribution is defined. The model is
an extension of the configuration model, in which stubs (half-edges) are paired
to form a network. Clustering is obtained by forming small completely connected
subgroups, and positive (negative) degree correlation is obtained by connecting
a fraction of the stubs with stubs of similar (dissimilar) degree. An SIR
(Susceptible -&gt; Infective -&gt; Recovered) epidemic model is defined on this
network. Asymptotic properties of both the network and the epidemic, as the
population size tends to infinity, are derived: the degree distribution, degree
correlation and clustering coefficient, as well as a reproduction number $R_*$,
the probability of a major outbreak and the relative size of such an outbreak.
The theory is illustrated by Monte Carlo simulations and numerical examples.
The main findings are that clustering tends to decrease the spread of disease,
the effect of degree correlation is appreciably greater when the disease is
close to threshold than when it is well above threshold and disease spread
broadly increases with degree correlation $\rho$ when $R_*$ is just above its
threshold value of one and decreases with $\rho$ when $R_*$ is well above one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3208</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3208</id><created>2012-07-13</created><authors><author><keyname>Huffman</keyname><forenames>Brian</forenames></author></authors><title>Formal Verification of Monad Transformers</title><categories>cs.LO</categories><comments>ICFP 2012: The 17th ACM SIGPLAN International Conference on
  Functional Programming, 12 pages</comments><acm-class>F.3.1</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We present techniques for reasoning about constructor classes that (like the
monad class) fix polymorphic operations and assert polymorphic axioms. We do
not require a logic with first-class type constructors, first-class
polymorphism, or type quantification; instead, we rely on a domain-theoretic
model of the type system in a universal domain to provide these features.
  These ideas are implemented in the Tycon library for the Isabelle theorem
prover, which builds on the HOLCF library of domain theory. The Tycon library
provides various axiomatic type constructor classes, including functors and
monads. It also provides automation for instantiating those classes, and for
defining further subclasses.
  We use the Tycon library to formalize three Haskell monad transformers: the
error transformer, the writer transformer, and the resumption transformer. The
error and writer transformers do not universally preserve the monad laws;
however, we establish datatype invariants for each, showing that they are valid
monads when viewed as abstract datatypes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3213</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3213</id><created>2012-07-13</created><authors><author><keyname>Khan</keyname><forenames>Imran Akhtar</forenames></author><author><keyname>Singh</keyname><forenames>Roopa</forenames></author></authors><title>Quality Assurance And Integration Testing Aspects In Web Based
  Applications</title><categories>cs.SE</categories><comments>8 pages; http://airccse.org/journal/ijcsea/current2012.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integration testing is one the important phase in software testing life cycle
(STLC). With the fast growth of internet and web services, web-based
applications are also growing rapidly and their importance and complexity is
also increasing. Heterogeneous and diverse nature of distributed components,
applications, along with their multi-platform support and cooperativeness make
these applications more complex and swiftly increasing in their size. Quality
assurance of these applications is becoming more crucial and important. Testing
is one of the key processes to achieve and ensure the quality of these software
or Webbased products. There are many testing challenges involved in Web-based
applications. But most importantly integration is the most critical testing
associated with Web-based applications. There are number of challenging factors
involved in integration testing efforts. These factors have almost 70 percent
to 80 percent impact on overall quality of Web-based applications. In software
industry different kind of testing approaches are used by practitioners to
solve the issues associated with integration which are due to ever increasing
complexities of Web-based applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3223</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3223</id><created>2012-07-13</created><updated>2012-08-09</updated><authors><author><keyname>Clairambault</keyname><forenames>Pierre</forenames><affiliation>Computer Laboratory, University of Cambridge</affiliation></author></authors><title>Isomorphisms of types in the presence of higher-order references
  (extended version)</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 10,
  2012) lmcs:1040</journal-ref><doi>10.2168/LMCS-8(3:8)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of type isomorphisms in the presence of
higher-order references. We first introduce a finitary programming language
with sum types and higher-order references, for which we build a fully abstract
games model following the work of Abramsky, Honda and McCusker. Solving an open
problem by Laurent, we show that two finitely branching arenas are isomorphic
if and only if they are geometrically the same, up to renaming of moves
(Laurent's forest isomorphism). We deduce from this an equational theory
characterizing isomorphisms of types in our language. We show however that
Laurent's conjecture does not hold on infinitely branching arenas, yielding new
non-trivial type isomorphisms in a variant of our language with natural
numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3234</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3234</id><created>2012-07-13</created><authors><author><keyname>Orman</keyname><forenames>G&#xfc;nce Keziban</forenames><affiliation>Le2i, BIT Lab</affiliation></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames><affiliation>Le2i</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>Le2i</affiliation></author></authors><title>An Empirical Study of the Relation Between Community Structure and
  Transitivity</title><categories>cs.SI physics.soc-ph</categories><comments>3rd Workshop on Complex Networks, Melbourne, Florida : United States
  (2012)</comments><proxy>ccsd</proxy><journal-ref>Studies in Computational Intelligence, 424:99-110, 2013</journal-ref><doi>10.1007/978-3-642-30287-9_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most prominent properties in real-world networks is the presence
of a community structure, i.e. dense and loosely interconnected groups of nodes
called communities. In an attempt to better understand this concept, we study
the relationship between the strength of the community structure and the
network transitivity (or clustering coefficient). Although intuitively
appealing, this analysis was not performed before. We adopt an approach based
on random models to empirically study how one property varies depending on the
other. It turns out the transitivity increases with the community structure
strength, and is also affected by the distribution of the community sizes.
Furthermore, increasing the transitivity also results in a stronger community
structure. More surprisingly, if a very weak community structure causes almost
zero transitivity, the opposite is not true and a network with a close to zero
transitivity can still have a clearly defined community structure. Further
analytical work is necessary to characterize the exact nature of the identified
relationship.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3251</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3251</id><created>2012-07-13</created><authors><author><keyname>Zverovich</keyname><forenames>Vadim</forenames></author><author><keyname>Avineri</keyname><forenames>Erel</forenames></author></authors><title>Braess' Paradox in a Generalised Traffic Network</title><categories>math.CO cs.GT</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical network configuration introduced by Braess in 1968 is of
fundamental significance because Valiant and Roughgarden showed in 2006 that
`the &quot;global&quot; behaviour of an equilibrium flow in a large random network is
similar to that in Braess' original four-node example'. In this paper, a
natural generalisation of Braess' network is introduced and conditions for the
occurrence of Braess' paradox are formulated for the generalised network.
  The Braess' paradox has been studied mainly in the context of the classical
problem introduced by Braess and his colleagues, assuming a certain type of
networks. Specifically, two pairs of links in those networks are assumed to
have the same volume-delay functions. The occurrence of Braess' paradox for
this specific case of network symmetry was investigated by Pas and Principio in
1997. Such a symmetry is not common in real-life networks because the
parameters of volume-delay functions are associated with roads physical and
functional characteristics, which typically differ from one link to another
(e.g. roads in networks are of different length). Our research provides an
extension of previous studies on Braess' paradox by considering arbitrary
volume-delay functions, i.e. symmetry properties are not assumed for any of the
network's links and the occurrence of Braess' paradox is studied for a general
configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3262</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3262</id><created>2012-07-13</created><updated>2012-09-13</updated><authors><author><keyname>Conchon</keyname><forenames>Sylvain</forenames><affiliation>LRI-UPS</affiliation></author><author><keyname>Contejean</keyname><forenames>Evelyne</forenames><affiliation>LRI-CNRS</affiliation></author><author><keyname>Iguernelala</keyname><forenames>Mohamed</forenames><affiliation>LRI-UPS</affiliation></author></authors><title>Canonized Rewriting and Ground AC Completion Modulo Shostak Theories :
  Design and Implementation</title><categories>cs.LO</categories><comments>30 pages, full version of the paper TACAS'11 paper &quot;Canonized
  Rewriting and Ground AC-Completion Modulo Shostak Theories&quot; accepted for
  publication by LMCS (Logical Methods in Computer Science)</comments><proxy>LMCS</proxy><acm-class>F.4.1, G.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (September
  14, 2012) lmcs:1034</journal-ref><doi>10.2168/LMCS-8(3:16)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AC-completion efficiently handles equality modulo associative and commutative
function symbols. When the input is ground, the procedure terminates and
provides a decision algorithm for the word problem. In this paper, we present a
modular extension of ground AC-completion for deciding formulas in the
combination of the theory of equality with user-defined AC symbols,
uninterpreted symbols and an arbitrary signature disjoint Shostak theory X. Our
algorithm, called AC(X), is obtained by augmenting in a modular way ground
AC-completion with the canonizer and solver present for the theory X. This
integration rests on canonized rewriting, a new relation reminiscent to
normalized rewriting, which integrates canonizers in rewriting steps. AC(X) is
proved sound, complete and terminating, and is implemented to extend the core
of the Alt-Ergo theorem prover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3265</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3265</id><created>2012-07-13</created><authors><author><keyname>Xu</keyname><forenames>Ge</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>The Sufficiency Principle for Decentralized Data Reduction</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, ISIT 12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops the sufficiency principle suitable for data reduction in
decentralized inference systems. Both parallel and tandem networks are studied
and we focus on the cases where observations at decentralized nodes are
conditionally dependent. For a parallel network, through the introduction of a
hidden variable that induces conditional independence among the observations,
the locally sufficient statistics, defined with respect to the hidden variable,
are shown to be globally sufficient for the parameter of inference interest.
For a tandem network, the notion of conditional sufficiency is introduced and
the related theories and tools are developed. Finally, connections between the
sufficiency principle and some distributed source coding problems are explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3269</identifier>
 <datestamp>2014-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3269</id><created>2012-07-13</created><updated>2014-10-27</updated><authors><author><keyname>Banerjee</keyname><forenames>Siddhartha</forenames></author><author><keyname>Hegde</keyname><forenames>Nidhi</forenames></author><author><keyname>Massouli&#xe9;</keyname><forenames>Laurent</forenames></author></authors><title>The Price of Privacy in Untrusted Recommendation Engines</title><categories>cs.LG cs.IT math.IT</categories><comments>Preliminary version presented at the 50th Allerton Conference, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent increase in online privacy concerns prompts the following question:
can a recommender system be accurate if users do not entrust it with their
private data? To answer this, we study the problem of learning item-clusters
under local differential privacy, a powerful, formal notion of data privacy. We
develop bounds on the sample-complexity of learning item-clusters from
privatized user inputs. Significantly, our results identify a sample-complexity
separation between learning in an information-rich and an information-scarce
regime, thereby highlighting the interaction between privacy and the amount of
information (ratings) available to each user.
  In the information-rich regime, where each user rates at least a constant
fraction of items, a spectral clustering approach is shown to achieve a
sample-complexity lower bound derived from a simple information-theoretic
argument based on Fano's inequality. However, the information-scarce regime,
where each user rates only a vanishing fraction of items, is found to require a
fundamentally different approach both for lower bounds and algorithms. To this
end, we develop new techniques for bounding mutual information under a notion
of channel-mismatch, and also propose a new algorithm, MaxSense, and show that
it achieves optimal sample-complexity in this setting.
  The techniques we develop for bounding mutual information may be of broader
interest. To illustrate this, we show their applicability to $(i)$ learning
based on 1-bit sketches, and $(ii)$ adaptive learning, where queries can be
adapted based on answers to past queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3270</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3270</id><created>2012-07-13</created><updated>2013-08-15</updated><authors><author><keyname>Skarlatidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Paliouras</keyname><forenames>Georgios</forenames></author><author><keyname>Artikis</keyname><forenames>Alexander</forenames></author><author><keyname>Vouros</keyname><forenames>George A.</forenames></author></authors><title>Probabilistic Event Calculus for Event Recognition</title><categories>cs.AI</categories><msc-class>68T37</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symbolic event recognition systems have been successfully applied to a
variety of application domains, extracting useful information in the form of
events, allowing experts or other systems to monitor and respond when
significant events are recognised. In a typical event recognition application,
however, these systems often have to deal with a significant amount of
uncertainty. In this paper, we address the issue of uncertainty in logic-based
event recognition by extending the Event Calculus with probabilistic reasoning.
Markov Logic Networks are a natural candidate for our logic-based formalism.
However, the temporal semantics of the Event Calculus introduce a number of
challenges for the proposed model. We show how and under what assumptions we
can overcome these problems. Additionally, we study how probabilistic modelling
changes the behaviour of the formalism, affecting its key property, the inertia
of fluents. Furthermore, we demonstrate the advantages of the probabilistic
Event Calculus through examples and experiments in the domain of activity
recognition, using a publicly available dataset for video surveillance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3277</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3277</id><created>2012-07-13</created><authors><author><keyname>Omrana</keyname><forenames>Hajar</forenames></author><author><keyname>Nassiri</keyname><forenames>Safae</forenames></author><author><keyname>Belouadha</keyname><forenames>Fatima-Zahra</forenames></author><author><keyname>Roudi&#xe9;s</keyname><forenames>Ounsa</forenames></author></authors><title>Design for Distributed Moroccan Hospital Pharmacy Information
  Environment with Service Oriented Architecture</title><categories>cs.SE</categories><comments>5 pages, 4 figures; Journal of Development Informatics, Aptikom.
  Published 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last five years, Moroccan e-health system has focused on improving the
quality of patient care services by making use of advanced Information and
Communications Technologies (ICT) solutions. In actual fact, achieving runtime
and efficient information sharing, through large-scale distributed environments
such as e-health system, is not a trivial task. It seems to present many issues
due to the heterogeneity and complex nature of data resources. This concerns,
in particular, Moroccan Hospital Pharmacy Information System (HPIS) which needs
to interact with several disparate medical information systems. Service
Oriented Architecture (SOA) offers solution that is both flexible and practical
to effectively address the problem of interoperability of e-health systems. In
this paper, we discuss the limits and challenges of the current Moroccan
information system intended for hospital pharmacy. We therefore propose a
global Web services-based e-health architecture for integrating different
heterogeneous blocks and various data resources of this system. We also present
a solution to secure Web services communication using WS-SecurityPolicy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3285</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3285</id><created>2012-07-12</created><authors><author><keyname>Nikumbh</keyname><forenames>Sarvesh</forenames></author><author><keyname>Ghosh</keyname><forenames>Shameek</forenames></author><author><keyname>Jayaraman</keyname><forenames>Valadi</forenames></author></authors><title>Biogeography-Based Informative Gene Selection and Cancer Classification
  Using SVM and Random Forests</title><categories>cs.NE stat.ML</categories><comments>6 pages; Author's copy; Presented at the IEEE World Congress on
  Computational Intelligence (at IEEE Congress on Evolutionary Computation),
  Brisbane, Australia, June 2012</comments><report-no>CMS-TR-20120509</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microarray cancer gene expression data comprise of very high dimensions.
Reducing the dimensions helps in improving the overall analysis and
classification performance. We propose two hybrid techniques, Biogeography -
based Optimization - Random Forests (BBO - RF) and BBO - SVM (Support Vector
Machines) with gene ranking as a heuristic, for microarray gene expression
analysis. This heuristic is obtained from information gain filter ranking
procedure. The BBO algorithm generates a population of candidate subset of
genes, as part of an ecosystem of habitats, and employs the migration and
mutation processes across multiple generations of the population to improve the
classification accuracy. The fitness of each gene subset is assessed by the
classifiers - SVM and Random Forests. The performances of these hybrid
techniques are evaluated on three cancer gene expression datasets retrieved
from the Kent Ridge Biomedical datasets collection and the libSVM data
repository. Our results demonstrate that genes selected by the proposed
techniques yield classification accuracies comparable to previously reported
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3289</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3289</id><created>2012-07-13</created><authors><author><keyname>Werner</keyname><forenames>Eric</forenames></author></authors><title>The Origin, Evolution and Development of Bilateral Symmetry in
  Multicellular Organisms</title><categories>q-bio.TO cs.CE</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computational theory and model of the ontogeny and development of bilateral
symmetry in multicellular organisms is presented. Understanding the origin and
evolution of bilateral organisms requires an understanding of how bilateral
symmetry develops, starting from a single cell. Bilateral symmetric growth of a
multicellular organism from a single starter cell is explained as resulting
from the opposite handedness and orientation along one axis in two daughter
founder cells that are in equivalent developmental control network states.
Several methods of establishing the initial orientation of the daughter cells
(including oriented cell division and cell signaling) are discussed. The
orientation states of the daughter cells are epigenetically inherited by their
progeny. This results in mirror development with the two founding daughter
cells generating complementary mirror image multicellular morphologies. The end
product is a bilateral symmetric organism. The theory gives a unified
explanation of diverse phenomena including symmetry breaking, situs inversus,
gynandromorphs, inside-out growth, bilaterally symmetric cancers, and the
rapid, punctuated evolution of bilaterally symmetric organisms in the Cambrian
Explosion. The theory is supported by experimental results on early embryonic
development. The theory makes precise testable predications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3292</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3292</id><created>2012-07-13</created><authors><author><keyname>Zhao</keyname><forenames>Yu</forenames></author><author><keyname>Zhu</keyname><forenames>Fangfang</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>The Han-Kobayashi Region for a Class of Gaussian Interference Channels
  with Mixed Interference</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, ISIT2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple encoding scheme based on Sato's non-na\&quot;ive frequency division is
proposed for a class of Gaussian interference channels with mixed interference.
The achievable region is shown to be equivalent to that of Costa's noiseberg
region for the onesided Gaussian interference channel. This allows for an
indirect proof that this simple achievable rate region is indeed equivalent to
the Han-Kobayashi (HK) region with Gaussian input and with time sharing for
this class of Gaussian interference channels with mixed interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3302</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3302</id><created>2012-07-13</created><authors><author><keyname>Jadav</keyname><forenames>Sunil</forenames></author><author><keyname>Vikrant</keyname></author><author><keyname>Vashisath</keyname><forenames>Munish</forenames></author></authors><title>Design and Performance Analysis Of Ultra Low Power 6T SRAM Using
  Adiabatic Technique</title><categories>cs.OH</categories><comments>11 pages</comments><journal-ref>International Journal of VLSI design &amp; Communication Systems
  (VLSICS) Vol.3, No.3, June 2012, 95-105</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Power consumption has become a critical concern in both high performance and
portable applications. Methods for power reduction based on the application of
adiabatic techniques to CMOS circuits have recently come under renewed
investigation. In thermodynamics, an adiabatic energy transfer through a
dissipative medium is one in which losses are made arbitrarily small by causing
the transfer to occur sufficiently slowly. In this work adiabatic technique is
used for reduction of average power dissipation. Simulation of 6T SRAM cell has
been done for 180nm CMOS technology. It shows that average power dissipation is
reduced up to 75% using adiabatic technique and also shows the effect on static
noise margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3315</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3315</id><created>2012-07-13</created><authors><author><keyname>Heras</keyname><forenames>J&#xf3;nathan</forenames></author><author><keyname>Poza</keyname><forenames>Mar&#xed;a</forenames></author><author><keyname>Rubio</keyname><forenames>Julio</forenames></author></authors><title>Verifying an algorithm computing Discrete Vector Fields for digital
  imaging</title><categories>cs.AI cs.LO cs.MS math.AT</categories><comments>Published in the Calculemus track of the CICM 2012 congress</comments><journal-ref>Calculemus 2012, Lecture Notes in Computer Science, 7362, pages
  215--229, 2012</journal-ref><doi>10.1007/978-3-642-31374-5_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a formalization of an algorithm to construct
admissible discrete vector fields in the Coq theorem prover taking advantage of
the SSReflect library. Discrete vector fields are a tool which has been
welcomed in the homological analysis of digital images since it provides a
procedure to reduce the amount of information but preserving the homological
properties. In particular, thanks to discrete vector fields, we are able to
compute, inside Coq, homological properties of biomedical images which
otherwise are out of the reach of this system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3316</identifier>
 <datestamp>2014-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3316</id><created>2012-07-13</created><updated>2014-01-31</updated><authors><author><keyname>&#x10c;irki&#x107;</keyname><forenames>Mirsad</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>SUMIS: Near-Optimal Soft-In Soft-Out MIMO Detection With Low and Fixed
  Complexity</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental problem of our interest here is soft-input soft-output
multiple-input multiple-output (MIMO) detection. We propose a method, referred
to as subspace marginalization with interference suppression (SUMIS), that
yields unprecedented performance at low and fixed (deterministic) complexity.
Our method provides a well-defined tradeoff between computational complexity
and performance. Apart from an initial sorting step consisting of selecting
channel-matrix columns, the algorithm involves no searching nor algorithmic
branching; hence the algorithm has a completely predictable run-time and allows
for a highly parallel implementation. We numerically assess the performance of
SUMIS in different practical settings: full/partial channel state information,
sequential/iterative decoding, and low/high rate outer codes. We also comment
on how the SUMIS method performs in systems with a large number of transmit
antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3322</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3322</id><created>2012-07-13</created><authors><author><keyname>Zhu</keyname><forenames>Fangfang</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>On the Sum Capacity of the Discrete Memoryless Interference Channel with
  One-Sided Weak Interference and Mixed Interference</title><categories>cs.IT math.IT</categories><comments>submitted to ISIT2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum capacity of a class of discrete memoryless interference channels is
determined. This class of channels is defined analogous to the Gaussian
Z-interference channel with weak interference; as a result, the sum capacity is
achieved by letting the transceiver pair subject to the interference
communicates at a rate such that its message can be decoded at the unintended
receiver using single user detection. Moreover, this class of discrete
memoryless interference channels is equivalent in capacity region to certain
discrete degraded interference channels. This allows the construction of a
capacity outer-bound using the capacity region of associated degraded broadcast
channels. The same technique is then used to determine the sum capacity of the
discrete memoryless interference channel with mixed interference. The above
results allow one to determine sum capacities or capacity regions of several
new discrete memoryless interference channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3351</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3351</id><created>2012-07-13</created><authors><author><keyname>George</keyname><forenames>Laurent</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Marchal</keyname><forenames>Maud</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Glondu</keyname><forenames>Loe&#xef;z</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>L&#xe9;cuyer</keyname><forenames>Anatole</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Combining Brain-Computer Interfaces and Haptics: Detecting Mental
  Workload to Adapt Haptic Assistance</title><categories>cs.GR cs.HC</categories><comments>EuroHaptics (2012)</comments><proxy>ccsd</proxy><doi>10.1007/978-3-642-31401-8_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce the combined use of Brain-Computer Interfaces
(BCI) and Haptic interfaces. We propose to adapt haptic guides based on the
mental activity measured by a BCI system. This novel approach is illustrated
within a proof-of-concept system: haptic guides are toggled during a
path-following task thanks to a mental workload index provided by a BCI. The
aim of this system is to provide haptic assistance only when the user's brain
activity reflects a high mental workload. A user study conducted with 8
participants shows that our proof-of-concept is operational and exploitable.
Results show that activation of haptic guides occurs in the most difficult part
of the path-following task. Moreover it allows to increase task performance by
53% by activating assistance only 59% of the time. Taken together, these
results suggest that BCI could be used to determine when the user needs
assistance during haptic interaction and to enable haptic guides accordingly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3358</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3358</id><created>2012-07-13</created><authors><author><keyname>Neji</keyname><forenames>Hasni</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ridha</forenames></author></authors><title>Roadmap for Establishing Interoperability of Heterogeneous Cellular
  Network Technologies -1-</title><categories>cs.NI</categories><comments>12 pages, 8 figures</comments><journal-ref>IJCSNS International Journal of Computer Science and Network
  Security, VOL.12 No.4, April 2012</journal-ref><doi>10.5120/8562-2158</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of interoperability between cellular access networks has long been a
challenging burden, which telecommunication engineers and researchers are
trying to overcome. In second generation networks for example, this problem
lies in the lack of standardization. 3rd G networks is limited to a few
operating modes using different radio transmission technologies that are not
interoperable. 4G technology even being successful in its various trials cannot
guarantee interoperability. The undertaken approach to overcome this issue
within heterogeneous networks begins by establishing a holistic understanding
of cellular communication, and proposing an Ontological approach that expresses
the domain's concepts, classes, and properties in a formal and unambiguous way.
It begins by analyzing the structure of three different cellular technologies,
and producing feature models. Lte-Advanced cellular network is the target of
this ongoing analysis. The final objective sought is to build Ontology capable
of providing a common view of cellular network technologies' domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3365</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3365</id><created>2012-07-13</created><authors><author><keyname>Cremene</keyname><forenames>Ligia</forenames></author><author><keyname>Dumitrescu</keyname><forenames>D.</forenames></author></authors><title>Emergence of Techno-Social Norms in Cognitive Radio Environments</title><categories>nlin.AO cs.GT</categories><comments>(&quot;This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible&quot;)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to explore the potential of Game Theory (GT) in
extracting rules of behaviour for emerging Cognitive Radio environments. We
revisit the commons approach to unlicensed spectrum and try to show that a
commons can be basically regulated from the inside out. GT simulations of CR
interactions reveal the emergence of certain equilibria mirroring
behaviours/trends?. Once these ?trends identified, norms may be expressed and
then embedded into machines (CRs). Internalized norms may thus become the
alternative to external enforcement of rules. We call these emerging norms
techno-social norms (TSNs). TSNs could eventually become a means of regulating
the use of unlicensed spectrum and making open spectrum access feasible. Open
spectrum access scenarios are considered and analysis is performed based on
reformulations of two game theoretical models: Cournot and Bertrand. The
standard oligopoly models are reformulated in terms of radio resource access in
unlicensed bands. In order to capture the large variety of CR interaction
situations, several GT equilibrium concepts are considered: Nash, Pareto,
Berge-Zhukovskii, and Lorenz. In order to capture the heterogeneity of CR
interactions, the standard GT model is enriched allowing players to be biased
toward different types of equilibrium (or rationality). An evolutionary
game-equilibrium detection method is used. Numerical simulations bring relevant
insights on the problem of autonomy vs. regulation in emerging CR environments.
Relying on extensive GT simulations, some rules of behaviour - to be expanded
into techno-social norms - may be derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3368</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3368</id><created>2012-07-13</created><authors><author><keyname>Tapson</keyname><forenames>Jonathan</forenames></author><author><keyname>van Schaik</keyname><forenames>Andre</forenames></author></authors><title>Learning the Pseudoinverse Solution to Network Weights</title><categories>cs.NE</categories><comments>13 pages, 3 figures; in submission to Neural Networks</comments><doi>10.1016/j.neunet.2013.02.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last decade has seen the parallel emergence in computational neuroscience
and machine learning of neural network structures which spread the input signal
randomly to a higher dimensional space; perform a nonlinear activation; and
then solve for a regression or classification output by means of a mathematical
pseudoinverse operation. In the field of neuromorphic engineering, these
methods are increasingly popular for synthesizing biologically plausible neural
networks, but the &quot;learning method&quot; - computation of the pseudoinverse by
singular value decomposition - is problematic both for biological plausibility
and because it is not an online or an adaptive method. We present an online or
incremental method of computing the pseudoinverse, which we argue is
biologically plausible as a learning method, and which can be made adaptable
for non-stationary data streams. The method is significantly more
memory-efficient than the conventional computation of pseudoinverses by
singular value decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3370</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3370</id><created>2012-07-13</created><authors><author><keyname>Perciano</keyname><forenames>Talita</forenames></author><author><keyname>Urban</keyname><forenames>Matthew</forenames></author><author><keyname>Mascarenhas</keyname><forenames>Nelson D. A.</forenames></author><author><keyname>Fatemi</keyname><forenames>Mostafa</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>Silva</keyname><forenames>Glauber T.</forenames></author></authors><title>Deconvolution of vibroacoustic images using a simulation model based on
  a three dimensional point spread function</title><categories>cs.CV</categories><comments>Accepted for publication in Ultrasonics</comments><doi>10.1016/j.ultras.2012.03.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vibro-acoustography (VA) is a medical imaging method based on the
difference-frequency generation produced by the mixture of two focused
ultrasound beams. VA has been applied to different problems in medical imaging
such as imaging bones, microcalcifications in the breast, mass lesions, and
calcified arteries. The obtained images may have a resolution of 0.7--0.8 mm.
Current VA systems based on confocal or linear array transducers generate
C-scan images at the beam focal plane. Images on the axial plane are also
possible, however the system resolution along depth worsens when compared to
the lateral one. Typical axial resolution is about 1.0 cm. Furthermore, the
elevation resolution of linear array systems is larger than that in lateral
direction. This asymmetry degrades C-scan images obtained using linear arrays.
The purpose of this article is to study VA image restoration based on a 3D
point spread function (PSF) using classical deconvolution algorithms: Wiener,
constrained least-squares (CLSs), and geometric mean filters. To assess the
filters' performance, we use an image quality index that accounts for
correlation loss, luminance and contrast distortion. Results for simulated VA
images show that the quality index achieved with the Wiener filter is 0.9 (1
indicates perfect restoration). This filter yielded the best result in
comparison with the other ones. Moreover, the deconvolution algorithms were
applied to an experimental VA image of a phantom composed of three stretched
0.5 mm wires. Experiments were performed using transducer driven at two
frequencies, 3075 kHz and 3125 kHz, which resulted in the difference-frequency
of 50 kHz. Restorations with the theoretical line spread function (LSF) did not
recover sufficient information to identify the wires in the images. However,
using an estimated LSF the obtained results displayed enough information to
spot the wires in the images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3384</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3384</id><created>2012-07-13</created><authors><author><keyname>Guenda</keyname><forenames>Kenza</forenames></author><author><keyname>Gulliver</keyname><forenames>T. Aaron</forenames></author></authors><title>MDS and Self-dual Codes over Rings</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we give the structure of constacyclic codes over formal power
series and chain rings. We also present necessary and sufficient conditions on
the existence of MDS codes over principal ideal rings. These results allow for
the construction of infinite families of MDS self-dual codes over finite chain
rings, formal power series and principal ideal rings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3385</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3385</id><created>2012-07-13</created><authors><author><keyname>Guenda</keyname><forenames>Kenza</forenames></author><author><keyname>Gulliver</keyname><forenames>T. Aaron</forenames></author></authors><title>Construction of Cyclic Codes over $\mathbb{F}_2+u\mathbb{F}_2$ for DNA
  Computing</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We construct codes over the ring $\mathbb{F}_2+u\mathbb{F}_2$ with $u^2=0$.
These code are designed for use in DNA computing applications. The codes
obtained satisfy the reverse complement constraint, the $GC$ content constraint
and avoid the secondary structure. they are derived from the cyclic complement
reversible codes over the ring $\mathbb{F}_2+u\mathbb{F}_2$. We also construct
an infinite family of BCH DNA codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3387</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3387</id><created>2012-07-13</created><authors><author><keyname>Guenda</keyname><forenames>Kenza</forenames></author><author><keyname>Gulliver</keyname><forenames>T. Aaron</forenames></author></authors><title>Self-dual Repeated Root Cyclic and Negacyclic Codes over Finite Fields</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we investigate repeated root cyclic and negacyclic codes of
length $p^rm$ over $\mathbb{F}_{p^s}$ with $(m,p)=1$. In the case $p$ odd, we
give necessary and sufficient conditions on the existence of negacyclic
self-dual codes. When $m=2m'$ with $m'$ odd, we characterize the codes in terms
of their generator polynomials. This provides simple conditions on the
existence of self-dual negacyclic codes, and generalizes the results of Dinh
\cite{dinh}. We also answer an open problem concerning the number of self-dual
cyclic codes given by Jia et al. \cite{jia}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3388</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3388</id><created>2012-07-14</created><authors><author><keyname>Huang</keyname><forenames>Jinyu</forenames></author></authors><title>Eradicating Computer Viruses on Networks</title><categories>physics.soc-ph cs.NI cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spread of computer viruses can be modeled as the SIS
(susceptible-infected-susceptible) epidemic propagation. We show that in order
to ensure the random immunization or the targeted immunization effectively
prevent computer viruses propagation on homogeneous networks, we should install
antivirus programs in every computer node and frequently update those programs.
This may produce large work and cost to install and update antivirus programs.
Then we propose a new policy called &quot;network monitors&quot; to tackle this problem.
In this policy, we only install and update antivirus programs for small number
of computer nodes, namely the &quot;network monitors&quot;. Further, the &quot;network
monitors&quot; can monitor their neighboring nodes' behavior. This mechanism incur
relative small cost to install and update antivirus programs.We also indicate
that the policy of the &quot;network monitors&quot; is efficient to protect the network's
safety. Numerical simulations confirm our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3389</identifier>
 <datestamp>2012-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3389</id><created>2012-07-14</created><updated>2012-07-18</updated><authors><author><keyname>Li</keyname><forenames>Xi</forenames></author><author><keyname>Dick</keyname><forenames>Anthony</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author><author><keyname>Wang</keyname><forenames>Hanzi</forenames></author></authors><title>Incremental Learning of 3D-DCT Compact Representations for Robust Visual
  Tracking</title><categories>cs.CV cs.LG</categories><comments>21 pages. Appearing in IEEE Transactions on Pattern Analysis and
  Machine Intelligence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual tracking usually requires an object appearance model that is robust to
changing illumination, pose and other factors encountered in video. In this
paper, we construct an appearance model using the 3D discrete cosine transform
(3D-DCT). The 3D-DCT is based on a set of cosine basis functions, which are
determined by the dimensions of the 3D signal and thus independent of the input
video data. In addition, the 3D-DCT can generate a compact energy spectrum
whose high-frequency coefficients are sparse if the appearance samples are
similar. By discarding these high-frequency coefficients, we simultaneously
obtain a compact 3D-DCT based object representation and a signal
reconstruction-based similarity measure (reflecting the information loss from
signal reconstruction). To efficiently update the object representation, we
propose an incremental 3D-DCT algorithm, which decomposes the 3D-DCT into
successive operations of the 2D discrete cosine transform (2D-DCT) and 1D
discrete cosine transform (1D-DCT) on the input video data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3392</identifier>
 <datestamp>2015-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3392</id><created>2012-07-14</created><updated>2015-07-08</updated><authors><author><keyname>Cardall</keyname><forenames>Christian Y.</forenames></author><author><keyname>Budiardja</keyname><forenames>Reuben D.</forenames></author><author><keyname>Endeve</keyname><forenames>Eirik</forenames></author><author><keyname>Mezzacappa</keyname><forenames>Anthony</forenames></author></authors><title>GenASiS: General Astrophysical Simulation System. I. Refinable Mesh and
  Nonrelativistic Hydrodynamics</title><categories>astro-ph.IM cs.SE</categories><comments>Belated update to version accepted ApJS</comments><journal-ref>Astrophys.J.Suppl. 210 (2014) 2, 17</journal-ref><doi>10.1088/0067-0049/210/2/17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GenASiS (General Astrophysical Simulation System) is a new code being
developed initially and primarily, though by no means exclusively, for the
simulation of core-collapse supernovae on the world's leading capability
supercomputers. This paper---the first in a series---demonstrates a centrally
refined coordinate patch suitable for gravitational collapse and documents
methods for compressible nonrelativistic hydrodynamics. We benchmark the
hydrodynamics capabilities of GenASiS against many standard test problems; the
results illustrate the basic competence of our implementation, demonstrate the
strengths and limitations of the HLLC relative to the HLL Riemann solver in a
number of interesting cases, and provide preliminary indications of the code's
ability to scale and to function with cell-by-cell fixed-mesh refinement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3394</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3394</id><created>2012-07-14</created><authors><author><keyname>Shadvar</keyname><forenames>Ali</forenames></author></authors><title>Dimension Reduction by Mutual Information Feature Extraction</title><categories>cs.LG cs.CV</categories><comments>International Journal of Computer Science &amp; Information Technology
  (IJCSIT). arXiv admin note: substantial text overlap with arXiv:1206.2058</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  During the past decades, to study high-dimensional data in a large variety of
problems, researchers have proposed many Feature Extraction algorithms. One of
the most effective approaches for optimal feature extraction is based on mutual
information (MI). However it is not always easy to get an accurate estimation
for high dimensional MI. In terms of MI, the optimal feature extraction is
creating a feature set from the data which jointly have the largest dependency
on the target class and minimum redundancy. In this paper, a
component-by-component gradient ascent method is proposed for feature
extraction which is based on one-dimensional MI estimates. We will refer to
this algorithm as Mutual Information Feature Extraction (MIFX). The performance
of this proposed method is evaluated using UCI databases. The results indicate
that MIFX provides a robust performance over different data sets which are
almost always the best or comparable to the best ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3414</identifier>
 <datestamp>2012-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3414</id><created>2012-07-14</created><authors><author><keyname>Frahm</keyname><forenames>K. M.</forenames></author><author><keyname>Shepelyansky</keyname><forenames>D. L.</forenames></author></authors><title>Google matrix of Twitter</title><categories>cs.SI physics.soc-ph</categories><comments>Research at http://www.quantware.ups-tlse.fr/ 8 pages, 8 figures,
  Additional data available at:
  http://www.quantware.ups-tlse.fr/QWLIB/twittermatrix/</comments><journal-ref>Eur. Phys. J. B (2012) 85: 355</journal-ref><doi>10.1140/epjb/e2012-30599-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct the Google matrix of the entire Twitter network, dated by July
2009, and analyze its spectrum and eigenstate properties including the PageRank
and CheiRank vectors and 2DRanking of all nodes. Our studies show much stronger
inter-connectivity between top PageRank nodes for the Twitter network compared
to the networks of Wikipedia and British Universities studied previously. Our
analysis allows to locate the top Twitter users which control the information
flow on the network. We argue that this small fraction of the whole number of
users, which can be viewed as the social network elite, plays the dominant role
in the process of opinion formation on the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3420</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3420</id><created>2012-07-14</created><authors><author><keyname>Bowen</keyname><forenames>Jonathan P.</forenames></author><author><keyname>Wilson</keyname><forenames>Robin J.</forenames></author></authors><title>Visualising Virtual Communities: From Erd\H{o}s to the Arts</title><categories>cs.CY cs.DL</categories><comments>7 pages, 7 figures</comments><msc-class>00A66 (Primary) 68P20 (Secondary)</msc-class><acm-class>E.1; H.3.3; J.5; K.4.0</acm-class><journal-ref>In Stuart Dunn, Jonathan P. Bowen, and Kia Ng (eds.), EVA London
  2012 Conference Proceedings, Electronic Workshops in Computing (eWiC),
  British Computer Society, 2012, pages 238-244</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monitoring communities has become increasingly easy on the web as the number
of visualisation tools and amount of data available about communities increase.
It is possible to visualise connections on social and professional networks
such as Facebook in the form of mathematical graphs. It is also possible to
visualise connections between authors of papers. In particular, Microsoft
Academic Search now has a large corpus of information on publications, together
with author and citation information, that can be visualised in a number of
ways. In mathematical circles, the concept of the &quot;Erd\H{o}s number&quot; has been
introduced, in honour of the Hungarian mathematician Paul Erd\H{o}s, measuring
the &quot;collaborative distance&quot; of a person away from Erd\H{o}s through links by
co-author. Similar metrics have been proposed in other fields, including
acting. The possibility of exploring and visualising such links in arts fields
is proposed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3422</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3422</id><created>2012-07-14</created><authors><author><keyname>Boiano</keyname><forenames>Stefania</forenames></author><author><keyname>Bowen</keyname><forenames>Jonathan P.</forenames></author><author><keyname>Gaia</keyname><forenames>Giuliano</forenames></author></authors><title>Usability, Design and Content Issues of Mobile Apps for Cultural
  Heritage Promotion: The Malta Culture Guide Experience</title><categories>cs.HC cs.CY cs.MM</categories><comments>8 pages, 7 figures, EVA London 2012: Electronic Visualisation and the
  Arts, London, UK, 10-12 July 2012</comments><msc-class>00A66 (Primary) 68N01 (Secondary)</msc-class><acm-class>H.5.1; H.5.2; J.5; K.4.0</acm-class><journal-ref>In Stuart Dunn, Jonathan P. Bowen, and Kia Ng (eds.), EVA London
  2012 Conference Proceedings, Electronic Workshops in Computing (eWiC),
  British Computer Society, 2012, pages 66-73</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper discusses the experience of producing and distributing an iPhone
app for promotion of the Maltese Cultural Heritage on behalf of the Malta
Tourism Authority. Thanks to its position at the heart of the Mediterranean
Sea, Malta has been a crossroads of civilisations whose traces are still
visible today, leaving a particularly rich and varied cultural heritage, from
megalithic temples to baroque palaces and Caravaggio masterpieces. Conveying
all these different aspects within a single application, using textual, visual,
and audio means, has raised many different issues about the planning and
production of cultural content for mobile usage, together with usability
aspects regarding design and distribution of a mobile app. In this paper, we
outline all of these aspects, focusing on the design and planning strategies
for a long-term user commitment and how to evaluate results for cultural mobile
applications. We include experience of all the steps of developing a mobile
app, information that is of possible benefit to other app developers in the
cultural sector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3433</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3433</id><created>2012-07-14</created><authors><author><keyname>Singh</keyname><forenames>Nungleppam Monoranjan</forenames></author><author><keyname>Sarma</keyname><forenames>Kanak Chandra</forenames></author></authors><title>Design and Development of Low Cost PC Based Real Time Temperature and
  Humidity Monitoring System</title><categories>cs.OH</categories><comments>Published in International Journal of Electronics and Computer
  Science Engineering (IJECSE)</comments><journal-ref>IJECSE Vol. 1 No. 3 (1588-1592), June 2012 (ISSN 2277-1956)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and development of a low cost Data Acquisition
System (DAS) using PIC12F675 microcontroller for real time temperature and
humidity monitoring. The designed DAS has 4 analog input channels having 10-bit
resolution and was interfaced through the serial port of the PC. A precision
integrated temperature sensor and an instrumentation-quality RH (Relative
Humidity) sensor were used for sensing the temperature and humidity
respectively. The firmware was written in Basic and compiled using Oshonsoft
PIC IDE and downloaded to the microcontroller by using PICkit2 programmer. An
application program was also developed using Visual Basic 6, which allows
displaying the waveform of the signal(s) in real time and the data can be saved
into the hard disk of the computer for future use and analysis. It can also be
interfaced to the USB port of the PC or laptop using USB to serial adapter BAFO
BF-810. Thus, the designed low cost device works with the legacy hardware as
well as the modern USB interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3434</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3434</id><created>2012-07-14</created><authors><author><keyname>Ceriotti</keyname><forenames>Matteo</forenames></author><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author><author><keyname>Giardini</keyname><forenames>Giovanni</forenames></author><author><keyname>Massari</keyname><forenames>Mauro</forenames></author></authors><title>An Approach to Model Interest for Planetary Rover through
  Dezert-Smarandache Theory</title><categories>cs.AI cs.RO cs.SY</categories><comments>Journal Of Aerospace Computing, Information, And Communication Vol.
  5, Month 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an approach for assigning an interest level to the
goals of a planetary rover. Assigning an interest level to goals, allows the
rover autonomously to transform and reallocate the goals. The interest level is
defined by data-fusing payload and navigation information. The fusion yields an
&quot;interest map&quot;, that quantifies the level of interest of each area around the
rover. In this way the planner can choose the most interesting scientific
objectives to be analyzed, with limited human intervention, and reallocates its
goals autonomously. The Dezert-Smarandache Theory of Plausible and Paradoxical
Reasoning was used for information fusion: this theory allows dealing with
vague and conflicting data. In particular, it allows us directly to model the
behavior of the scientists that have to evaluate the relevance of a particular
set of goals. The paper shows an application of the proposed approach to the
generation of a reliable interest map.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3437</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3437</id><created>2012-07-14</created><authors><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author></authors><title>Robust Mission Design Through Evidence Theory and Multi-Agent
  Collaborative Search</title><categories>cs.CE cs.NE cs.SY math.OC math.PR</categories><journal-ref>Annals of the New York Academy of Science, Volume 1065, New Trends
  in Astrodynamics and Applications pages 152-173, December 2005</journal-ref><doi>10.1196/annals.1370.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the preliminary design of a space mission is approached
introducing uncertainties on the design parameters and formulating the
resulting reliable design problem as a multiobjective optimization problem.
Uncertainties are modelled through evidence theory and the belief, or
credibility, in the successful achievement of mission goals is maximised along
with the reliability of constraint satisfaction. The multiobjective
optimisation problem is solved through a novel algorithm based on the
collaboration of a population of agents in search for the set of highly
reliable solutions. Two typical problems in mission analysis are used to
illustrate the proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3438</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3438</id><created>2012-07-14</created><authors><author><keyname>Guan</keyname><forenames>Naiyang</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Luo</keyname><forenames>Zhigang</forenames></author><author><keyname>Shawe-Taylor</keyname><forenames>John</forenames></author></authors><title>MahNMF: Manhattan Non-negative Matrix Factorization</title><categories>stat.ML cs.LG cs.NA</categories><comments>43 pages, 20 figures, 2 tables, submission to Journal of Machine
  Learning Research</comments><msc-class>65K10</msc-class><acm-class>I.2.4; I.2.10; I.4.6; I.4.8; I.5.3; I.5.4; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-negative matrix factorization (NMF) approximates a non-negative matrix
$X$ by a product of two non-negative low-rank factor matrices $W$ and $H$. NMF
and its extensions minimize either the Kullback-Leibler divergence or the
Euclidean distance between $X$ and $W^T H$ to model the Poisson noise or the
Gaussian noise. In practice, when the noise distribution is heavy tailed, they
cannot perform well. This paper presents Manhattan NMF (MahNMF) which minimizes
the Manhattan distance between $X$ and $W^T H$ for modeling the heavy tailed
Laplacian noise. Similar to sparse and low-rank matrix decompositions, MahNMF
robustly estimates the low-rank part and the sparse part of a non-negative
matrix and thus performs effectively when data are contaminated by outliers. We
extend MahNMF for various practical applications by developing box-constrained
MahNMF, manifold regularized MahNMF, group sparse MahNMF, elastic net inducing
MahNMF, and symmetric MahNMF. The major contribution of this paper lies in two
fast optimization algorithms for MahNMF and its extensions: the rank-one
residual iteration (RRI) method and Nesterov's smoothing method. In particular,
by approximating the residual matrix by the outer product of one row of W and
one row of $H$ in MahNMF, we develop an RRI method to iteratively update each
variable of $W$ and $H$ in a closed form solution. Although RRI is efficient
for small scale MahNMF and some of its extensions, it is neither scalable to
large scale matrices nor flexible enough to optimize all MahNMF extensions.
Since the objective functions of MahNMF and its extensions are neither convex
nor smooth, we apply Nesterov's smoothing method to recursively optimize one
factor matrix with another matrix fixed. By setting the smoothing parameter
inversely proportional to the iteration number, we improve the approximation
accuracy iteratively for both MahNMF and its extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3441</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3441</id><created>2012-07-14</created><authors><author><keyname>Wenzel</keyname><forenames>Makarius</forenames></author></authors><title>Isabelle/jEdit --- a Prover IDE within the PIDE framework</title><categories>cs.LO cs.AI cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PIDE is a general framework for document-oriented prover interaction and
integration, based on a bilingual architecture that combines ML and Scala. The
overall aim is to connect LCF-style provers like Isabelle (or Coq or HOL) with
sophisticated front-end technology on the JVM platform, overcoming command-line
interaction at last.
  The present system description specifically covers Isabelle/jEdit as part of
the official release of Isabelle2011-1 (October 2011). It is a concrete Prover
IDE implementation based on Isabelle/PIDE library modules (implemented in
Scala) on the one hand, and the well-known text editor framework of jEdit
(implemented in Java) on the other hand.
  The interaction model of our Prover IDE follows the idea of continuous proof
checking: the theory source text is annotated by semantic information by the
prover as it becomes available incrementally. This works via an asynchronous
protocol that neither blocks the editor nor stops the prover from exploiting
parallelism on multi-core hardware. The jEdit GUI provides standard metaphors
for augmented text editing (highlighting, squiggles, tooltips, hyperlinks etc.)
that we have instrumented to render the formal content from the prover context.
Further refinement of the jEdit display engine via suitable plugins and fonts
approximates mathematical rendering in the text buffer, including symbols from
the TeX repertoire, and sub-/superscripts.
  Isabelle/jEdit is presented here both as a usable interface for current
Isabelle, and as a reference application to inspire further projects based on
PIDE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3442</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3442</id><created>2012-07-14</created><authors><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author><author><keyname>Minisci</keyname><forenames>Edmondo</forenames></author><author><keyname>Wijnands</keyname><forenames>Quirien</forenames></author></authors><title>Approximated Computation of Belief Functions for Robust Design
  Optimization</title><categories>cs.CE cs.NE cs.SY math.OC math.PR</categories><comments>AIAA-2012-1932 14th AIAA Non-Deterministic Approaches Conference.
  23-26 April 2012 Sheraton Waikiki, Honolulu, Hawaii</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents some ideas to reduce the computational cost of
evidence-based robust design optimization. Evidence Theory crystallizes both
the aleatory and epistemic uncertainties in the design parameters, providing
two quantitative measures, Belief and Plausibility, of the credibility of the
computed value of the design budgets. The paper proposes some techniques to
compute an approximation of Belief and Plausibility at a cost that is a
fraction of the one required for an accurate calculation of the two values.
Some simple test cases will show how the proposed techniques scale with the
dimension of the problem. Finally a simple example of spacecraft system design
is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3445</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3445</id><created>2012-07-14</created><updated>2012-07-19</updated><authors><author><keyname>Currie</keyname><forenames>James D.</forenames></author></authors><title>Infinite ternary square-free words concatenated from permutations of a
  single word</title><categories>cs.FL math.CO</categories><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We answer a question of Harju: An infinite square-free ternary word with an
$n$-stem factorization exists for any $n\ge 13$. We show that there are uniform
ternary morphisms of length $k$ for every $k\ge 23$. This resolves almost
completely a problem of the author and Rampersad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3450</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3450</id><created>2012-07-14</created><authors><author><keyname>Vabishchevich</keyname><forenames>Petr N.</forenames></author></authors><title>Flux-splitting schemes for parabolic problems</title><categories>cs.NA math.NA</categories><msc-class>65M06, 65M12</msc-class><doi>10.1134/S0965542512080106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To solve numerically boundary value problems for parabolic equations with
mixed derivatives, the construction of difference schemes with prescribed
quality faces essential difficulties. In parabolic problems, some possibilities
are associated with the transition to a new formulation of the problem, where
the fluxes (derivatives with respect to a spatial direction) are treated as
unknown quantities. In this case, the original problem is rewritten in the form
of a boundary value problem for the system of equations in the fluxes. This
work deals with studying schemes with weights for parabolic equations written
in the flux coordinates. Unconditionally stable flux locally one-dimensional
schemes of the first and second order of approximation in time are constructed
for parabolic equations without mixed derivatives. A peculiarity of the system
of equations written in flux variables for equations with mixed derivatives is
that there do exist coupled terms with time derivatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3451</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3451</id><created>2012-07-14</created><authors><author><keyname>Talarico</keyname><forenames>Salvatore</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author><author><keyname>Torrieri</keyname><forenames>Don</forenames></author></authors><title>Analysis and Optimization of a Frequency-Hopping Ad Hoc Network in
  Rayleigh Fading</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new method for optimizing frequency-hopping ad hoc
networks in the presence of Rayleigh fading. It is assumed that the system uses
a capacity-approaching code (e.g., turbo or LDPC) and noncoherent binary
continuous-phase frequency-shift keying (CPFSK) modulation. By using
transmission capacity as the performance metric, the number of hopping
channels, CPFSK modulation index, and code rate are jointly optimized. Mobiles
in the network are assumed to be uniformly located within a finite area.
Closed-form expressions for outage probability are given for a network
characterized by a physical interference channel. The outage probability is
first found conditioned on the locations of the mobiles, and then averaged over
the spatial distribution of the mobiles. The transmission capacity, which is a
measure of the spatial spectral efficiency, is obtained from the outage
probability. The transmission capacity is modified to account for the
constraints of the CPFSK modulation and capacity-approaching coding. Two
optimization methods are proposed for maximizing the transmission capacity. The
first is a brute-force method and the second is a gradient-search algorithm.
The results obtained from the optimization shed new insight into the
fundamental tradeoffs among the number of frequency-hopping channels, the
modulation index, and the rate of the error-correcting code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3468</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3468</id><created>2012-07-14</created><authors><author><keyname>Lomeli-Haro</keyname><forenames>Mario</forenames></author></authors><title>Minimal Convex Decompositions</title><categories>cs.CG math.CO math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of $n$ points on the plane in general position. We say that
a set $\Gamma$ of convex polygons with vertices in $P$ is a convex
decomposition of $P$ if: Union of all elements in $\Gamma$ is the convex hull
of $P,$ every element in $\Gamma$ is empty, and for any two different elements
of $\Gamma$ their interiors are disjoint. A minimal convex decomposition of $P$
is a convex decomposition $\Gamma'$ such that for any two adjacent elements in
$\Gamma'$ its union is a non convex polygon. It is known that $P$ always has a
minimal convex decomposition with at most $\frac{3n}{2}$ elements. Here we
prove that $P$ always has a minimal convex decomposition with at most
$\frac{10n}{7}$ elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3472</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3472</id><created>2012-07-14</created><authors><author><keyname>Kim</keyname><forenames>Gol</forenames></author><author><keyname>Yun</keyname><forenames>Ri Suk</forenames></author></authors><title>Optimal Selection of Assets Investing Composition Plan based on Grey
  Multi Objective Programming method</title><categories>cs.CE math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem for selection of appropriate assets investing composition
projects such as assets rationalization plays an important role in promotion of
business systems. We consider the assets investing composition plan problems
subject to grey multiobjective programming with the grey inequality
constraints. In this paper, we show in detail the entire process of the
application from modeling the case problem to generating its solution. To solve
the grey multi objective programming problem, we then develop and apply an
algorithm of grey multiple objective programming by weighting method and an
algorithm of grey multiple objective programming based on q -positioned
programming method. These algorithms all regard as of great importance
uncertainty (greyness) at grey multiobjective programming and simple and easy
the calculating process. The calculating examples of paper also show ability
and effectiveness of algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3485</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3485</id><created>2012-07-15</created><authors><author><keyname>Bauer</keyname><forenames>Sebastian</forenames><affiliation>Ludwig-Maximilians-Universit&#xe4;t M&#xfc;nchen, Germany</affiliation></author><author><keyname>Raclet</keyname><forenames>Jean-Baptiste</forenames><affiliation>University Paul Sabatier-Toulouse III, France</affiliation></author></authors><title>Proceedings Fourth Workshop on Foundations of Interface Technologies</title><categories>cs.LO cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 87, 2012</journal-ref><doi>10.4204/EPTCS.87</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 4th workshop on Foundations of
Interface Technologies (FIT 2012) which was collocated with ETAPS 2012 in
Tallinn, Estonia, and took place on March 25, 2012. The aim of this workshop is
to bring together researchers who are interested in the formal underpinnings of
interface technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3499</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3499</id><created>2012-07-15</created><authors><author><keyname>Mannella</keyname><forenames>Riccardo</forenames></author><author><keyname>Rossi</keyname><forenames>Paolo</forenames></author></authors><title>On the time dependence of the $h$-index</title><categories>physics.soc-ph cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The time dependence of the $h$-index is analyzed by considering the average
behaviour of $h$ as a function of the academic age $A_A$ for about 1400 Italian
physicists, with career lengths spanning from 3 to 46 years. The individual
$h$-index is strongly correlated with the square root of the total citations
$N_C$: $h \approx 0.53 \sqrt{N_C}$. For academic ages ranging from 12 to 24
years, the distribution of the time scaled index $h/\sqrt{A_A}$ is
approximately time-independent and it is well described by the Gompertz
function. The time scaled index $h/\sqrt{A_A}$ has an average approximately
equal to 3.8 and a standard deviation approximately equal to 1.6. Finally, the
time scaled index $h/\sqrt{A_A}$ appears to be strongly correlated with the
contemporary $h$-index $h_c$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3502</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3502</id><created>2012-07-15</created><authors><author><keyname>Galetzka</keyname><forenames>Michael</forenames></author><author><keyname>Glauner</keyname><forenames>Patrick O.</forenames></author></authors><title>A correct even-odd algorithm for the point-in-polygon (PIP) problem for
  complex polygons</title><categories>cs.CG</categories><comments>8 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining if a point is in a polygon or not is used by a lot of
applications in computer graphics, computer games and geoinformatics.
Implementing this check is error-prone since there are many special cases to be
considered. In this paper we present a simple even-odd algorithm to solve this
problem for complex polygons in linear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3506</identifier>
 <datestamp>2013-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3506</id><created>2012-07-15</created><updated>2013-10-20</updated><authors><author><keyname>Bellalta</keyname><forenames>Boris</forenames></author><author><keyname>Faridi</keyname><forenames>Azadeh</forenames></author><author><keyname>Barcelo</keyname><forenames>Jaume</forenames></author><author><keyname>Daza</keyname><forenames>Vanesa</forenames></author><author><keyname>Oliver</keyname><forenames>Miquel</forenames></author></authors><title>Performance Analysis of a Multiuser Multi-Packet Transmission System for
  WLANs in Non-Saturation Conditions</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiuser Multi-Packet Transmission (MPT) from an Access Point (AP) equipped
with multiple antennas to multiple single-antenna nodes can be achieved by
exploiting the spatial dimension of the channel. In this paper we present a
queueing model to analytically study such systems from the link-layer
perspective, in presence of random packet arrivals, heterogeneous channel
conditions and packet errors. The analysis relies on a blind estimation of the
number of different destinations among the packets waiting in the queue, which
allows for building a simple, but general model for MPT systems with per-node
First-In First-Out (FIFO) packet scheduling. Simulation results validate the
accuracy of the analytical model and provide further insights on the
cross-relations between the channel state, the number of antennas, and the
number of active users, as well as how they affect the system performance. The
simplicity and accuracy of the model makes it suitable for the evaluation of
Medium Access Control (MAC) protocols for Ad-Hoc or Wireless Local Area
Networks supporting multiuser MPT in non-saturation conditions, where the
queueing dynamics play an important role on the achieved performance, and
simple user selection algorithms are required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3508</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3508</id><created>2012-07-15</created><updated>2013-06-24</updated><authors><author><keyname>Bellalta</keyname><forenames>Boris</forenames></author><author><keyname>Faridi</keyname><forenames>Azadeh</forenames></author><author><keyname>Staehle</keyname><forenames>Dirk</forenames></author><author><keyname>Barcelo</keyname><forenames>Jaume</forenames></author><author><keyname>Vinel</keyname><forenames>Alexey</forenames></author><author><keyname>Oliver</keyname><forenames>Miquel</forenames></author></authors><title>Performance Analysis of CSMA/CA Protocols with Multi-packet Transmission</title><categories>cs.NI</categories><comments>Computer Networks, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless objects equipped with multiple antennas are able to simultaneously
transmit multiple packets by exploiting the channel's spatial dimensions. In
this paper, we study the benefits of such Multiple Packet Transmission (MPT)
approach, when it is used in combination with a Carrier Sense Multiple Access
with Collision Avoidance (CSMA/CA) protocol for fully interconnected networks,
addressing the interactions between the two mechanisms and showing the
performance gains that can be achieved. To this end, a very simple Media Access
Control (MAC) protocol that captures the fundamental properties and tradeoffs
of a CSMA/CA channel access protocol supporting MPT is introduced. Using this
protocol as a reference, a new analytical model is presented for the case of
non-saturated traffic sources with finite buffer space. Simulation results show
that the analytical model is able to accurately characterize the steady-state
behaviour of the reference protocol for different number of antennas and
different traffic loads, providing a useful tool for understanding the
performance gains achieved by MAC protocols supporting MPT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3510</identifier>
 <datestamp>2012-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3510</id><created>2012-07-15</created><updated>2012-12-18</updated><authors><author><keyname>Wang</keyname><forenames>Quan</forenames></author></authors><title>HMRF-EM-image: Implementation of the Hidden Markov Random Field Model
  and its Expectation-Maximization Algorithm</title><categories>cs.CV</categories><comments>This work originally appears as the final project of Prof. Birsen
  Yazici's course Detection and Estimation Theory at RPI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this project, we study the hidden Markov random field (HMRF) model and its
expectation-maximization (EM) algorithm. We implement a MATLAB toolbox named
HMRF-EM-image for 2D image segmentation using the HMRF-EM framework. This
toolbox also implements edge-prior-preserving image segmentation, and can be
easily reconfigured for other problems, such as 3D image segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3513</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3513</id><created>2012-07-15</created><authors><author><keyname>Gohari</keyname><forenames>Amin</forenames></author><author><keyname>Yassaee</keyname><forenames>Mohammad Hossein</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Secure Channel Simulation</title><categories>cs.IT math.IT</categories><comments>Short version to appear at ITW 2012. This will be replaced by a
  longer version soon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the Output Statistics of Random Binning (OSRB) framework is
used to prove a new inner bound for the problem of secure channel simulation.
Our results subsume some recent results on the secure function computation. We
also provide an achievability result for the problem of simultaneously
simulating a channel and creating a shared secret key. A special case of this
result generalizes the lower bound of Gohari and Anantharam on the source model
to include constraints on the rates of the public discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3520</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3520</id><created>2012-07-15</created><authors><author><keyname>Pedregosa</keyname><forenames>Fabian</forenames><affiliation>INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Pallier</keyname><forenames>Christophe</forenames><affiliation>NEUROSPIN</affiliation></author><author><keyname>Cauvet</keyname><forenames>Elodie</forenames><affiliation>NEUROSPIN</affiliation></author></authors><title>Improved brain pattern recovery through ranking approaches</title><categories>cs.LG stat.ML</categories><proxy>ccsd</proxy><journal-ref>Pattern Recognition in NeuroImaging (PRNI 2012) (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring the functional specificity of brain regions from functional
Magnetic Resonance Images (fMRI) data is a challenging statistical problem.
While the General Linear Model (GLM) remains the standard approach for brain
mapping, supervised learning techniques (a.k.a.} decoding) have proven to be
useful to capture multivariate statistical effects distributed across voxels
and brain regions. Up to now, much effort has been made to improve decoding by
incorporating prior knowledge in the form of a particular regularization term.
In this paper we demonstrate that further improvement can be made by accounting
for non-linearities using a ranking approach rather than the commonly used
least-square regression. Through simulation, we compare the recovery properties
of our approach to linear models commonly used in fMRI based decoding. We
demonstrate the superiority of ranking with a real fMRI dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3523</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3523</id><created>2012-07-15</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Levin</keyname><forenames>Asaf</forenames></author><author><keyname>van Stee</keyname><forenames>Rob</forenames></author></authors><title>A unified approach to truthful scheduling on related machines</title><categories>cs.DS cs.GT</categories><msc-class>68Q25, 68W25, 91A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a unified framework for designing deterministic monotone
polynomial time approximation schemes (PTAS's) for a wide class of scheduling
problems on uniformly related machines. This class includes (among others)
minimizing the makespan, maximizing the minimum load, and minimizing the l_p
norm of the machine loads vector. Previously, this kind of result was only
known for the makespan objective. Monotone algorithms have the property that an
increase in the speed of a machine cannot decrease the amount of work assigned
to it. The key idea of our novel method is to show that for goal functions that
are sufficiently well-behaved functions of the machine loads, it is possible to
compute in polynomial time a highly structured nearly optimal schedule.
Monotone approximation schemes have an important role in the emerging area of
algorithmic mechanism design. In the game-theoretical setting of these
scheduling problems there is a social goal, which is one of the objective
functions that we study. Each machine is controlled by a selfish
single-parameter agent, where its private information is its cost of processing
a unit sized job, which is also the inverse of the speed of its machine. Each
agent wishes to maximize its own profit, defined as the payment it receives
from the mechanism minus its cost for processing all jobs assigned to it, and
places a bid which corresponds to its private information. For each one of the
problems, we show that we can calculate payments that guarantee truthfulness in
an efficient manner. Thus, there exists a dominant strategy where agents report
their true speeds, and we show the existence of a truthful mechanism which can
be implemented in polynomial time, where the social goal is approximated within
a factor of 1+epsilon for every epsilon&gt;0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3532</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3532</id><created>2012-07-15</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Kamousi</keyname><forenames>Pegah</forenames></author><author><keyname>Han</keyname><forenames>Fangqiu</forenames></author><author><keyname>Yang</keyname><forenames>Shengqi</forenames></author><author><keyname>Yan</keyname><forenames>Xifeng</forenames></author><author><keyname>Suri</keyname><forenames>Subhash</forenames></author></authors><title>Memory Efficient De Bruijn Graph Construction</title><categories>cs.DS cs.DB</categories><comments>13 pages, 19 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massively parallel DNA sequencing technologies are revolutionizing genomics
research. Billions of short reads generated at low costs can be assembled for
reconstructing the whole genomes. Unfortunately, the large memory footprint of
the existing de novo assembly algorithms makes it challenging to get the
assembly done for higher eukaryotes like mammals. In this work, we investigate
the memory issue of constructing de Bruijn graph, a core task in leading
assembly algorithms, which often consumes several hundreds of gigabytes memory
for large genomes. We propose a disk-based partition method, called Minimum
Substring Partitioning (MSP), to complete the task using less than 10 gigabytes
memory, without runtime slowdown. MSP breaks the short reads into multiple
small disjoint partitions so that each partition can be loaded into memory,
processed individually and later merged with others to form a de Bruijn graph.
By leveraging the overlaps among the k-mers (substring of length k), MSP
achieves astonishing compression ratio: The total size of partitions is reduced
from $\Theta(kn)$ to $\Theta(n)$, where $n$ is the size of the short read
database, and $k$ is the length of a $k$-mer. Experimental results show that
our method can build de Bruijn graphs using a commodity computer for any
large-volume sequence dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3538</identifier>
 <datestamp>2014-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3538</id><created>2012-07-15</created><updated>2014-08-30</updated><authors><author><keyname>Wang</keyname><forenames>Quan</forenames></author></authors><title>Kernel Principal Component Analysis and its Applications in Face
  Recognition and Active Shape Models</title><categories>cs.CV</categories><comments>This work originally appears as the final project of Professor Qiang
  Ji's course Pattern Recognition at RPI, Troy, NY, USA, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principal component analysis (PCA) is a popular tool for linear
dimensionality reduction and feature extraction. Kernel PCA is the nonlinear
form of PCA, which better exploits the complicated spatial structure of
high-dimensional features. In this paper, we first review the basic ideas of
PCA and kernel PCA. Then we focus on the reconstruction of pre-images for
kernel PCA. We also give an introduction on how PCA is used in active shape
models (ASMs), and discuss how kernel PCA can be applied to improve traditional
ASMs. Then we show some experimental results to compare the performance of
kernel PCA and standard PCA for classification problems. We also implement the
kernel PCA-based ASMs, and use it to construct human face models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3543</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3543</id><created>2012-07-15</created><authors><author><keyname>Keyvanpour</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Azizani</keyname><forenames>Fereshteh</forenames></author></authors><title>Classification of Approaches and Challenges of Frequent Subgraphs Mining
  in Biological Networks</title><categories>cs.AI</categories><journal-ref>International Journal of Advanced Engineering Sciences and
  Technologies, Vol No. 4, Issue No. 2, 014 - 017, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the structure and dynamics of biological networks is one of the
important challenges in system biology. In addition, increasing amount of
experimental data in biological networks necessitate the use of efficient
methods to analyze these huge amounts of data. Such methods require to
recognize common patterns to analyze data. As biological networks can be
modeled by graphs, the problem of common patterns recognition is equivalent
with frequent sub graph mining in a set of graphs. In this paper, at first the
challenges of frequent subgrpahs mining in biological networks are introduced
and the existing approaches are classified for each challenge. then the
algorithms are analyzed on the basis of the type of the approach they apply for
each of the challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3554</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3554</id><created>2012-07-15</created><updated>2012-10-05</updated><authors><author><keyname>Kimura</keyname><forenames>Akisato</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author><author><keyname>Hitoshi</keyname><forenames>Sakano</forenames></author><author><keyname>Kameoka</keyname><forenames>Hirokazu</forenames></author></authors><title>Designing various component analysis at will</title><categories>cs.CV cs.NA stat.ME stat.ML</categories><comments>Accepted to IAPR International Conference on Pattern Recognition,
  submitted to IPSJ Transactions on Mathematical Modeling and its Applications
  (TOM). Just only one-page abstract for new due to novelty violation for
  journal submission. The details will be disclosed in late September</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a generic framework of component analysis (CA) methods
introducing a new expression for scatter matrices and Gram matrices, called
Generalized Pairwise Expression (GPE). This expression is quite compact but
highly powerful: The framework includes not only (1) the standard CA methods
but also (2) several regularization techniques, (3) weighted extensions, (4)
some clustering methods, and (5) their semi-supervised extensions. This paper
also presents quite a simple methodology for designing a desired CA method from
the proposed framework: Adopting the known GPEs as templates, and generating a
new method by combining these templates appropriately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3560</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3560</id><created>2012-07-15</created><authors><author><keyname>Widanapathirana</keyname><forenames>Chathuranga</forenames></author><author><keyname>Sekercioglu</keyname><forenames>Y. Ahmet</forenames></author><author><keyname>Fitzpatrick</keyname><forenames>Paul G.</forenames></author><author><keyname>Ivanovich</keyname><forenames>Milosh V.</forenames></author><author><keyname>Li</keyname><forenames>Jonathan C.</forenames></author></authors><title>Diagnosing client faults using SVM-based intelligent inference from TCP
  packet traces</title><categories>cs.NI cs.AI cs.LG</categories><comments>2011 6th International Conference on Broadband and Biomedical
  Communications (IB2COM)</comments><doi>10.1109/IB2Com.2011.6217894</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the Intelligent Automated Client Diagnostic (IACD) system, which
only relies on inference from Transmission Control Protocol (TCP) packet traces
for rapid diagnosis of client device problems that cause network performance
issues. Using soft-margin Support Vector Machine (SVM) classifiers, the system
(i) distinguishes link problems from client problems, and (ii) identifies
characteristics unique to client faults to report the root cause of the client
device problem. Experimental evaluation demonstrated the capability of the IACD
system to distinguish between faulty and healthy links and to diagnose the
client faults with 98% accuracy in healthy links. The system can perform fault
diagnosis independent of the client's specific TCP implementation, enabling
diagnosis capability on diverse range of client computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3564</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3564</id><created>2012-07-15</created><authors><author><keyname>Yin</keyname><forenames>Yitong</forenames></author><author><keyname>Zhang</keyname><forenames>Chihao</forenames></author></authors><title>Approximate Counting via Correlation Decay on Planar Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show for a broad class of counting problems, correlation decay (strong
spatial mixing) implies FPTAS on planar graphs. The framework for the counting
problems considered by us is the Holant problems with arbitrary constant-size
domain and symmetric constraint functions. We define a notion of regularity on
the constraint functions, which covers a wide range of natural and important
counting problems, including all multi-state spin systems, counting graph
homomorphisms, counting weighted matchings or perfect matchings, the subgraphs
world problem transformed from the ferromagnetic Ising model, and all counting
CSPs and Holant problems with symmetric constraint functions of constant arity.
  The core of our algorithm is a fixed-parameter tractable algorithm which
computes the exact values of the Holant problems with regular constraint
functions on graphs of bounded treewidth. By utilizing the locally tree-like
property of apex-minor-free families of graphs, the parameterized exact
algorithm implies an FPTAS for the Holant problem on these graph families
whenever the Gibbs measure defined by the problem exhibits strong spatial
mixing. We further extend the recursive coupling technique to Holant problems
and establish strong spatial mixing for the ferromagnetic Potts model and the
subgraphs world problem. As consequences, we have new deterministic
approximation algorithms on planar graphs and all apex-minor-free graphs for
several counting problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3572</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3572</id><created>2012-07-16</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Kellett</keyname><forenames>Christopher M.</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author></authors><title>On the Equal-Rate Capacity of the AWGN Multiway Relay Channel</title><categories>cs.IT math.IT</categories><comments>Author's final version (to appear in IEEE Transactions on Information
  Theory)</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 58, No. 9, pp.
  5761-5769, 2012</journal-ref><doi>10.1109/TIT.2012.2204510</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The L-user additive white Gaussian noise multiway relay channel is
investigated, where L users exchange information at the same rate through a
single relay. A new achievable rate region, based on the
functional-decode-forward coding strategy, is derived. For the case where there
are three or more users, and all nodes transmit at the same power, the capacity
is obtained. For the case where the relay power scales with the number of
users, it is shown that both compress-forward and functional-decode-forward
achieve rates within a constant number of bits of the capacity at all SNR
levels; in addition, functional-decode-forward outperforms compress-forward and
complete-decode-forward at high SNR levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3574</identifier>
 <datestamp>2014-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3574</id><created>2012-07-16</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author><author><keyname>Kellett</keyname><forenames>Christopher M.</forenames></author></authors><title>On the Capacity of the Binary-Symmetric Parallel-Relay Network</title><categories>cs.IT math.IT</categories><comments>Author's final version (to appear in Transactions on Emerging
  Telecommunications Technologies)</comments><journal-ref>Transactions on Emerging Telecommunications Technologies, Volume
  25, Issue 2, pages 217-230, February 2014</journal-ref><doi>10.1002/ett.2561</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the binary-symmetric parallel-relay network where there is one
source, one destination, and multiple relays in parallel. We show that
forwarding relays, where the relays merely transmit their received signals,
achieve the capacity in two ways: with coded transmission at the source and a
finite number of relays, or uncoded transmission at the source and a
sufficiently large number of relays. On the other hand, decoding relays, where
the relays decode the source message, re-encode, and forward it to the
destination, achieve the capacity when the number of relays is small. In
addition, we show that any coding scheme that requires decoding at any relay is
suboptimal in large parallel-relay networks, where forwarding relays achieve
strictly higher rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3576</identifier>
 <datestamp>2013-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3576</id><created>2012-07-16</created><updated>2013-07-12</updated><authors><author><keyname>Padmavathi</keyname><forenames>S.</forenames></author><author><keyname>Archana</keyname><forenames>N.</forenames></author><author><keyname>Soman</keyname><forenames>K. P.</forenames></author></authors><title>Hierarchical Approach for Total Variation Digital Image Inpainting</title><categories>cs.CV</categories><comments>7 pages, 7 figures; International Journal of Computer Science,
  Engineering and Applications (IJCSEA), Voulume 2, Number 3, June 2012, ISSN :
  2230 - 9616 [Online] ; 2231 - 0088 [Print]</comments><doi>10.5121/ijcsea.2012.2316</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The art of recovering an image from damage in an undetectable form is known
as inpainting. The manual work of inpainting is most often a very time
consuming process. Due to digitalization of this technique, it is automatic and
faster. In this paper, after the user selects the regions to be reconstructed,
the algorithm automatically reconstruct the lost regions with the help of the
information surrounding them. The existing methods perform very well when the
region to be reconstructed is very small, but fails in proper reconstruction as
the area increases. This paper describes a Hierarchical method by which the
area to be inpainted is reduced in multiple levels and Total Variation(TV)
method is used to inpaint in each level. This algorithm gives better
performance when compared with other existing algorithms such as nearest
neighbor interpolation, Inpainting through Blurring and Sobolev Inpainting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3582</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3582</id><created>2012-07-16</created><authors><author><keyname>Leong</keyname><forenames>Derek</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Erasure Coding for Real-Time Streaming</title><categories>cs.IT math.IT</categories><comments>Extended version of a conference paper in the IEEE International
  Symposium on Information Theory (ISIT), July 2012. 12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a real-time streaming system where messages are created
sequentially at the source, and are encoded for transmission to the receiver
over a packet erasure link. Each message must subsequently be decoded at the
receiver within a given delay from its creation time. The goal is to construct
an erasure correction code that achieves the maximum message size when all
messages must be decoded by their respective deadlines under a specified set of
erasure patterns (erasure model). We present an explicit intrasession code
construction that is asymptotically optimal under erasure models containing a
limited number of erasures per coding window, per sliding window, and
containing erasure bursts of a limited length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3583</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3583</id><created>2012-07-16</created><authors><author><keyname>Nasution</keyname><forenames>Mahyuddin K. M.</forenames></author><author><keyname>Noah</keyname><forenames>Shahrul Azman</forenames></author></authors><title>Information Retrieval Model: A Social Network Extraction Perspective</title><categories>cs.IR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future Information Retrieval, especially in connection with the internet,
will incorporate the content descriptions that are generated with social
network extraction technologies and preferably incorporate the probability
theory for assigning the semantic. Although there is an increasing interest
about social network extraction, but a little of them has a significant impact
to infomation retrieval. Therefore this paper proposes a model of information
retrieval from the social network extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3585</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3585</id><created>2012-07-16</created><updated>2012-07-18</updated><authors><author><keyname>Holub</keyname><forenames>&#x160;t&#x11b;p&#xe1;n</forenames></author></authors><title>Abelian powers in paper-folding words</title><categories>cs.FL cs.DM math.CO</categories><msc-class>68Q45</msc-class><journal-ref>Journal of Combinatorial Theory Series A 120 (4) (2013) 872-881</journal-ref><doi>10.1016/j.jcta.2013.01.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that paper folding words contain arbitrarily large abelian powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3586</identifier>
 <datestamp>2012-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3586</id><created>2012-07-16</created><updated>2012-09-28</updated><authors><author><keyname>Crowston</keyname><forenames>Robert</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Jones</keyname><forenames>Mark</forenames></author></authors><title>Directed Acyclic Subgraph Problem Parameterized above the Poljak-Turzik
  Bound</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An oriented graph is a directed graph without directed 2-cycles. Poljak and
Turz\'{i}k (1986) proved that every connected oriented graph $G$ on $n$
vertices and $m$ arcs contains an acyclic subgraph with at least
$\frac{m}{2}+\frac{n-1}{4}$ arcs. Raman and Saurabh (2006) gave another proof
of this result and left it as an open question to establish the parameterized
complexity of the following problem: does $G$ have an acyclic subgraph with
least $\frac{m}{2}+\frac{n-1}{4}+k$ arcs, where $k$ is the parameter? We answer
this question by showing that the problem can be solved by an algorithm of
runtime $(12k)!n^{O(1)}$. Thus, the problem is fixed-parameter tractable. We
also prove that there is a polynomial time algorithm that either establishes
that the input instance of the problem is a Yes-instance or reduces the input
instance to an equivalent one of size $O(k^2)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3594</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3594</id><created>2012-07-16</created><updated>2013-06-17</updated><authors><author><keyname>Payne</keyname><forenames>Michael S.</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Progress on Dirac's Conjecture</title><categories>math.CO cs.CG</categories><comments>8 pages, 1 figure. Version 3 improves constant in main result via use
  of Hirzebruch's inequality, and adds section on Beck's theorem. Version 4
  fixes formatting errors in html abstract (pdf unchanged)</comments><msc-class>52C10, 52C30</msc-class><journal-ref>Electronic J. Combinatorics 21.2:P2.12, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1951, Gabriel Dirac conjectured that every set P of n non-collinear points
in the plane contains a point in at least n/2-c lines determined by P, for some
constant c. The following weakening was proved by Beck and Szemer\'edi-Trotter:
every set P of n non-collinear points contains a point in at least n/c lines
determined by P, for some large unspecified constant c. We prove that every set
P of n non-collinear points contains a point in at least n/37 lines determined
by P. We also give the best known constant for Beck's Theorem, proving that
every set of n points with at most k collinear determines at least n(n-k)/98
lines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3595</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3595</id><created>2012-07-16</created><authors><author><keyname>Aslam</keyname><forenames>M.</forenames></author><author><keyname>Shah</keyname><forenames>T.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Rahim</keyname><forenames>A.</forenames></author><author><keyname>Rahman</keyname><forenames>Z.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author></authors><title>CEEC: Centralized Energy Efficient Clustering A New Routing Protocol for
  WSNs</title><categories>cs.NI</categories><comments>9th IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc
  Communications and Networks (SECON), Seoul, Korea June, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficient routing protocol for Wireless Sensor Networks (WSNs) is one
of the most challenging task for researcher. Hierarchical routing protocols
have been proved more energy efficient routing protocols, as compare to flat
and location based routing protocols. Heterogeneity of nodes with respect to
their energy level, has also added extra lifespan for sensor network. In this
paper, we propose a Centralized Energy Efficient Clustering (CEEC) routing
protocol. We design the CEEC for three level heterogeneous network. CEEC can
also be implemented in multi-level heterogeneity of networks. For initial
practical, we design and analyze CEEC for three level advance heterogeneous
network. In CEEC, whole network area is divided into three equal regions, in
which nodes with same energy are spread in same region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3597</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3597</id><created>2012-07-16</created><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Goltz</keyname><forenames>Ursula</forenames></author><author><keyname>Schicke-Uffmann</keyname><forenames>Jens-Wolfhard</forenames></author></authors><title>On Distributability of Petri Nets</title><categories>cs.LO</categories><report-no>Technical Report 2011-10, Institut f\&quot;ur Programmierung und Reaktive
  Systeme, Technical University of Braunschweig</report-no><acm-class>F.1.2; B.4.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We formalise a general concept of distributed systems as sequential
components interacting asynchronously. We define a corresponding class of Petri
nets, called LSGA nets, and precisely characterise those system specifications
which can be implemented as LSGA nets up to branching ST-bisimilarity with
explicit divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3598</identifier>
 <datestamp>2012-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3598</id><created>2012-07-16</created><updated>2012-09-30</updated><authors><author><keyname>Pedregosa</keyname><forenames>Fabian</forenames><affiliation>INRIA Paris - Rocquencourt, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Cauvet</keyname><forenames>Elodie</forenames><affiliation>NEUROSPIN</affiliation></author><author><keyname>Pallier</keyname><forenames>Christophe</forenames><affiliation>NEUROSPIN</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>Learning to rank from medical imaging data</title><categories>cs.LG cs.CV</categories><proxy>ccsd</proxy><journal-ref>MLMI 2012 - 3rd International Workshop on Machine Learning in
  Medical Imaging (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical images can be used to predict a clinical score coding for the
severity of a disease, a pain level or the complexity of a cognitive task. In
all these cases, the predicted variable has a natural order. While a standard
classifier discards this information, we would like to take it into account in
order to improve prediction performance. A standard linear regression does
model such information, however the linearity assumption is likely not be
satisfied when predicting from pixel intensities in an image. In this paper we
address these modeling challenges with a supervised learning procedure where
the model aims to order or rank images. We use a linear model for its
robustness in high dimension and its possible interpretation. We show on
simulations and two fMRI datasets that this approach is able to predict the
correct ordering on pairs of images, yielding higher prediction accuracy than
standard regression and multiclass classification techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3599</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3599</id><created>2012-07-16</created><authors><author><keyname>Rahim</keyname><forenames>A.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Aslam</keyname><forenames>M.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author></authors><title>Adaptive-Reliable Medium Access Control Protocol for Wireless Body Area
  Networks</title><categories>cs.NI</categories><comments>9th IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc
  Communications and Networks (SECON), Soul, Korea between June, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extensive energy is consumed by Transceiver communication operation [1].
Existing research on MAC layer focuses to maximize battery-powered sensor
node's life. Bottleneck of MAC layer protocol design for WBAN is to achieve
high reliability and energy minimization. Majority of MAC protocols designed
for WBANs are based upon TDMA approach. However, a new protocol needs to be
defined to achieve high energy efficiency, fairness and avoid extra energy
consumption due to synchronization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3603</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3603</id><created>2012-07-16</created><authors><author><keyname>Orman</keyname><forenames>G&#xfc;nce</forenames><affiliation>Le2i</affiliation></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames><affiliation>BIT Lab</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>Le2i</affiliation></author></authors><title>Qualitative Comparison of Community Detection Algorithms</title><categories>cs.SI cs.CV physics.soc-ph</categories><comments>DICTAP 2011, The International Conference on Digital Information and
  Communication Technology and its Applications, Dijon : France (2011)</comments><proxy>ccsd</proxy><journal-ref>Communications in Computer and Information Science, 167:265-279,
  2011</journal-ref><doi>10.1007/978-3-642-22027-2_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection is a very active field in complex networks analysis,
consisting in identifying groups of nodes more densely interconnected
relatively to the rest of the network. The existing algorithms are usually
tested and compared on real-world and artificial networks, their performance
being assessed through some partition similarity measure. However, artificial
networks realism can be questioned, and the appropriateness of those measures
is not obvious. In this study, we take advantage of recent advances concerning
the characterization of community structures to tackle these questions. We
first generate networks thanks to the most realistic model available to date.
Their analysis reveals they display only some of the properties observed in
real-world community structures. We then apply five community detection
algorithms on these networks and find out the performance assessed
quantitatively does not necessarily agree with a qualitative analysis of the
identified communities. It therefore seems both approaches should be applied to
perform a relevant comparison of the algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3604</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3604</id><created>2012-07-16</created><authors><author><keyname>Mari&#x107;</keyname><forenames>Filip</forenames></author><author><keyname>&#x17d;ivkovi&#x107;</keyname><forenames>Miodrag</forenames></author><author><keyname>Vu&#x10d;kovi&#x107;</keyname><forenames>Bojan</forenames></author></authors><title>Formalizing Frankl's Conjecture: FC-families</title><categories>cs.DM</categories><comments>Intelligent Computer Mathematics (CICM 2012). Calculemus track. LNAI
  7362, Springer, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Frankl's conjecture, formulated in 1979. and still open, states that in
every family of sets closed for unions there is an element contained in at
least half of the sets. FC-families are families for which it is proved that
every union-closed family containing them satisfies the Frankl's condition
(e.g., in every union-closed family that contains a one-element set {a}, the
element a is contained in at least half of the sets, so families of the form
{a} are the simplest FC-families). FC-families play an important role in
attacking the Frankl's conjecture, since they enable significant search space
pruning. We present a formalization of the computer assisted approach for
proving that a family is an FC-family. Proof-by-computation paradigm is used
and the proof assistant Isabelle/HOL is used both to check mathematical
content, and to perform (verified) combinatorial searches on which the proofs
rely. FC-families known in the literature are confirmed, and a new FC-family is
discovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3607</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3607</id><created>2012-07-16</created><authors><author><keyname>Demirkesen</keyname><forenames>Can</forenames><affiliation>BIT Lab, LJK</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>BIT Lab, Le2i</affiliation></author></authors><title>Fusing image representations for classification using support vector
  machines</title><categories>cs.CV cs.LG</categories><comments>Image and Vision Computing New Zealand, 2009. IVCNZ '09. 24th
  International Conference, Wellington : Nouvelle-Z\'elande (2009)</comments><proxy>ccsd</proxy><doi>10.1109/IVCNZ.2009.5378367</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to improve classification accuracy different image representations
are usually combined. This can be done by using two different fusing schemes.
In feature level fusion schemes, image representations are combined before the
classification process. In classifier fusion, the decisions taken separately
based on individual representations are fused to make a decision. In this paper
the main methods derived for both strategies are evaluated. Our experimental
results show that classifier fusion performs better. Specifically Bayes belief
integration is the best performing strategy for image classification task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3622</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3622</id><created>2012-07-16</created><authors><author><keyname>Roditty</keyname><forenames>Liam</forenames></author><author><keyname>Williams</keyname><forenames>Virginia Vassilevska</forenames></author></authors><title>Approximating the diameter of a graph</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the fundamental problem of approximating the
diameter $D$ of directed or undirected graphs. In a seminal paper, Aingworth,
Chekuri, Indyk and Motwani [SIAM J. Comput. 1999] presented an algorithm that
computes in $\Ot(m\sqrt n + n^2)$ time an estimate $\hat{D}$ for the diameter
of an $n$-node, $m$-edge graph, such that $\lfloor 2/3 D \rfloor \leq \hat{D}
\leq D$. In this paper we present an algorithm that produces the same estimate
in $\Ot(m\sqrt n)$ expected running time. We then provide strong evidence that
a better approximation may be hard to obtain if we insist on an $O(m^{2-\eps})$
running time. In particular, we show that if there is some constant $\eps&gt;0$ so
that there is an algorithm for undirected unweighted graphs that runs in
$O(m^{2-\eps})$ time and produces an approximation $\hat{D}$ such that $
(2/3+\eps) D \leq \hat{D} \leq D$, then SAT for CNF formulas on $n$ variables
can be solved in $O^{*}((2-\delta)^{n})$ time for some constant $\delta&gt;0$, and
the strong exponential time hypothesis of [Impagliazzo, Paturi, Zane JCSS'01]
is false.
  Motivated by this somewhat negative result, we study whether it is possible
to obtain a better approximation for specific cases. For unweighted directed or
undirected graphs, we show that if $D=3h+z$, where $h\geq 0$ and $z\in
{0,1,2}$, then it is possible to report in $\tilde{O}(\min{m^{2/3}
n^{4/3},m^{2-1/(2h+3)}})$ time an estimate $\hat{D}$ such that $2h+z \leq
\hat{D}\leq D$, thus giving a better than 3/2 approximation whenever $z\neq 0$.
This is significant for constant values of $D$ which is exactly when the
diameter approximation problem is hardest to solve. For the case of unweighted
undirected graphs we present an $\tilde{O}(m^{2/3} n^{4/3})$ time algorithm
that reports an estimate $\hat{D}$ such that $\lfloor 4D/5\rfloor \leq
\hat{D}\leq D$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3628</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3628</id><created>2012-07-16</created><authors><author><keyname>Sinha</keyname><forenames>Sukanta</forenames></author><author><keyname>Dattagupta</keyname><forenames>Rana</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author></authors><title>Identify Web-page Content meaning using Knowledge based System for Dual
  Meaning Words</title><categories>cs.IR</categories><comments>4 pages, 2 figures; International Journal of Engineering Research and
  Applications, ISSN: 2248-9622, Vol. 2, Issue 4, July-August 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meaning of Web-page content plays a big role while produced a search result
from a search engine. Most of the cases Web-page meaning stored in title or
meta-tag area but those meanings do not always match with Web-page content. To
overcome this situation we need to go through the Web-page content to identify
the Web-page meaning. In such cases, where Webpage content holds dual meaning
words that time it is really difficult to identify the meaning of the Web-page.
In this paper, we are introducing a new design and development mechanism of
identifying the Web-page content meaning which holds dual meaning words in
their Web-page content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3633</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3633</id><created>2012-07-16</created><authors><author><keyname>Bar&#xe1;t</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Payne</keyname><forenames>Michael S.</forenames></author><author><keyname>Scharf</keyname><forenames>Ludmila</forenames></author><author><keyname>Schymura</keyname><forenames>Daria</forenames></author><author><keyname>Valtr</keyname><forenames>Pavel</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Empty pentagons in point sets with collinearities</title><categories>math.CO cs.CG cs.DM</categories><comments>15 pages, 11 figures</comments><msc-class>52C10</msc-class><journal-ref>SIAM J. Discrete Math. 29-1 (2015), pp. 198-209</journal-ref><doi>10.1137/130950422</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An empty pentagon in a point set P in the plane is a set of five points in P
in strictly convex position with no other point of P in their convex hull. We
prove that every finite set of at least 328k^2 points in the plane contains an
empty pentagon or k collinear points. This is optimal up to a constant factor
since the (k-1)x(k-1) grid contains no empty pentagon and no k collinear
points. The previous best known bound was doubly exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3636</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3636</id><created>2012-07-16</created><authors><author><keyname>A.</keyname><forenames>Dinesha H.</forenames></author><author><keyname>Agrawa</keyname><forenames>V. K.</forenames></author></authors><title>Multi-dimensional password generation technique for accessing cloud
  services</title><categories>cs.CR</categories><comments>9 Pages, 8 Figures</comments><journal-ref>International Journal on Cloud Computing: Services and
  Architecture(IJCCSA),Vol.2, No.3, June 2012, 31-39</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is drastically growing technology which provides an on-demand
software, hardware, infrastructure and data storage as services. This
technology is used worldwide to improve the business infrastructure and
performance. However, to utilize these services by intended customer, it is
necessary to have strong password authentication. At present, cloud password
authentication can be done in several ways, such as, textual password,
graphical and 3D password. In this paper, we are proposing the strong password
generation technique by considering multiple input parameters of cloud paradigm
referred as a multidimensional password. This paper presents the
multidimensional password generation technique along with architecture,
sequence diagrams, algorithms and typical user interfaces. At the end, we
derive the probability of breaking our authentication system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3646</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3646</id><created>2012-07-16</created><authors><author><keyname>Pereira</keyname><forenames>Eduardo dos Santos</forenames></author><author><keyname>Miranda</keyname><forenames>Oswaldo D.</forenames></author></authors><title>OGCOSMO: An auxiliary tool for the study of the Universe within
  hierarchical scenario of structure formation</title><categories>cs.CE astro-ph.CO astro-ph.IM</categories><comments>8 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this work is presented the software OGCOSMO. This program was written
using high level design methodology (HLDM), that is based on the use of very
high level (VHL) programing language as main, and the use of the intermediate
level (IL) language only for the critical processing time. The languages used
are PYTHON (VHL) and FORTRAN (IL). The core of OGCOSMO is a package called
OGC{\_}lib. This package contains a group of modules for the study of
cosmological and astrophysical processes, such as: comoving distance, relation
between redshift and time, cosmic star formation rate, number density of dark
matter haloes and mass function of supermassive black holes (SMBHs). The
software is under development and some new features will be implemented for the
research of stochastic background of gravitational waves (GWs) generated by:
stellar collapse to form black holes, binary systems of SMBHs. Even more, we
show that the use of HLDM with PYTHON and FORTRAN is a powerful tool for
producing astrophysical softwares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3654</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3654</id><created>2012-07-16</created><authors><author><keyname>Park</keyname><forenames>Ki-Hong</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Joint Filter Design of Alternate MIMO AF Relaying Networks with
  Interference Alignment</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study in this paper a two-hop relaying network consisting of one source,
one destination, and three amplify-and-forward (AF) relays operating in a
half-duplex mode. In order to compensate for the inherent loss of capacity
pre-log factor 1/2 in a half-duplex mode, we consider alternate transmission
protocol among three relays where two relays and the other relay alternately
forward messages from source to destination. We consider a multiple-antenna
environment where all nodes have $M$ antennas. Aligning the inter-relay
interference due to the alternate transmission is utilized to make additional
degrees of freedom (DOFs) and recover the pre-log factor loss. It is shown that
the proposed relaying scheme can achieve $\frac{3M}{4}$ DOFs compared with the
$\frac{M}{2}$ DOFs of conventional AF relaying. In addition, suboptimal linear
filter designs for a source and three relays are proposed to maximize the
system achievable sum-rate for different fading scenarios when the destination
utilizes a linear minimum mean-square error filter for decoding. We verify from
our selected numerical results that the proposed filter designs give
significant improvement over a naive filter or conventional relaying schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3658</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3658</id><created>2012-07-16</created><authors><author><keyname>Pereira</keyname><forenames>Eduardo dos Santos</forenames></author><author><keyname>Miranda</keyname><forenames>Oswaldo D.</forenames></author></authors><title>Programing Using High Level Design With Python and FORTRAN: A Study Case
  in Astrophysics</title><categories>cs.CE astro-ph.IM</categories><comments>9 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this work, we present a short review about the high level design
methodology (HLDM), that is based on the use of very high level (VHL)
programing language as main, and the use of the intermediate level (IL)
language only for the critical processing time. The languages used are Python
(VHL) and FORTRAN (IL). Moreover, this methodology, making use of the oriented
object programing (OOP), permits to produce a readable, portable and reusable
code. Also is presented the concept of computational framework, that naturally
appears from the OOP paradigm. As an example, we present the framework called
PYGRAWC (Python framework for Gravitational Waves from Cosmological origin).
Even more, we show that the use of HLDM with Python and FORTRAN produces a
powerful tool for solving astrophysical problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3674</identifier>
 <datestamp>2013-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3674</id><created>2012-07-16</created><updated>2013-03-20</updated><authors><author><keyname>Chazal</keyname><forenames>Frederic</forenames><affiliation>INRIA Saclay - France</affiliation></author><author><keyname>de Silva</keyname><forenames>Vin</forenames><affiliation>Pomona College - USA</affiliation></author><author><keyname>Glisse</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - France</affiliation></author><author><keyname>Oudot</keyname><forenames>Steve</forenames><affiliation>INRIA Saclay - France</affiliation></author></authors><title>The structure and stability of persistence modules</title><categories>math.AT cs.CG math.CT</categories><comments>New version. We discuss in greater depth the interpolation lemma for
  persistence modules</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a self-contained treatment of the theory of persistence modules
indexed over the real line. We give new proofs of the standard results.
Persistence diagrams are constructed using measure theory. Linear algebra
lemmas are simplified using a new notation for calculations on quiver
representations. We show that the stringent finiteness conditions required by
traditional methods are not necessary to prove the existence and stability of
the persistence diagram. We introduce weaker hypotheses for taming persistence
modules, which are met in practice and are strong enough for the theory still
to work. The constructions and proofs enabled by our framework are, we claim,
cleaner and simpler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3682</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3682</id><created>2012-07-16</created><authors><author><keyname>Br&#xe2;nzei</keyname><forenames>Simina</forenames></author><author><keyname>Michalak</keyname><forenames>Tomasz P.</forenames></author><author><keyname>Rahwan</keyname><forenames>Talal</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author><author><keyname>Jennings</keyname><forenames>Nicholas R.</forenames></author></authors><title>Matching Games with Additive Externalities</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-sided matchings are an important theoretical tool used to model markets
and social interactions. In many real life problems the utility of an agent is
influenced not only by their own choices, but also by the choices that other
agents make. Such an influence is called an externality. Whereas fully
expressive representations of externalities in matchings require exponential
space, in this paper we propose a compact model of externalities, in which the
influence of a match on each agent is computed additively. In this framework,
we analyze many-to-many and one-to-one matchings under neutral, optimistic, and
pessimistic behaviour, and provide both computational hardness results and
polynomial-time algorithms for computing stable outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3691</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3691</id><created>2012-07-16</created><authors><author><keyname>Souayeh</keyname><forenames>Nihel Ben Youssef Ben</forenames></author><author><keyname>Bouhoula</keyname><forenames>Adel</forenames></author></authors><title>Formal Checking of Multiple Firewalls</title><categories>cs.CR</categories><comments>9 pages; IJCSI journal, volume 9, issue 3, num 2, may 2012, ISSN:
  1694-0814</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When enterprises deploy multiple firewalls, a packet may be examined by
different sets of firewalls. It has been observed that the resulting complex
firewall network is highly error prone and causes serious security holes.
Hence, automated solutions are needed in order to check its correctness. In
this paper, we propose a formal and automatic method for checking whether
multiple firewalls react correctly with respect to a security policy given in a
high level declarative language. When errors are detected, some useful feedback
is returned in order to correct the firewall configurations. Furthermore, we
propose a priority-based approach to ensure that no incoherencies exist within
the security policy. We show that our method is both correct and complete.
Finally, it has been implemented in a prototype of verifier based on a
satisfiability solver modulo theories. Experiment conducted on relevant case
studies demonstrates the efficiency of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3704</identifier>
 <datestamp>2013-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3704</id><created>2012-07-16</created><updated>2012-08-08</updated><authors><author><keyname>Chen</keyname><forenames>Chung Shue</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author></authors><title>Gibbsian Method for the Self-Optimization of Cellular Networks</title><categories>math.OC cs.SY</categories><comments>25 pages, 9 figures, to appear in EURASIP Journal on Wireless
  Communications and Networking 2012</comments><doi>10.1186/1687-1499-2012-273</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose and analyze a class of distributed algorithms
performing the joint optimization of radio resources in heterogeneous cellular
networks made of a juxtaposition of macro and small cells. Within this context,
it is essential to use algorithms able to simultaneously solve the problems of
channel selection, user association and power control. In such networks, the
unpredictability of the cell and user patterns also requires distributed
optimization schemes. The proposed method is inspired from statistical physics
and based on the Gibbs sampler. It does not require the concavity/convexity,
monotonicity or duality properties common to classical optimization problems.
Besides, it supports discrete optimization which is especially useful to
practical systems. We show that it can be implemented in a fully distributed
way and nevertheless achieves system-wide optimality. We use simulation to
compare this solution to today's default operational methods in terms of both
throughput and energy consumption. Finally, we address concrete issues for the
implementation of this solution and analyze the overhead traffic required
within the framework of 3GPP and femtocell standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3713</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3713</id><created>2012-07-10</created><authors><author><keyname>Ibdah</keyname><forenames>Yazan</forenames></author><author><keyname>Ding</keyname><forenames>Yanwu</forenames></author></authors><title>Statistical Simulation Models for Cascaded Rayleigh Fading Channels</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present statistical simulators for cascaded Rayleigh fading
channels with and without line-of-sight (LOS). These simulators contain two
individual summations and are therefore easy to implement with lower
complexity. Detailed statistical properties, including auto- and
cross-correlations of the in-phase, quadrature components of the channels,
envelopes, and squared envelopes, are derived. The time-average statistical
properties and the corresponding variance are also investigated to justify that
the proposed simulators achieve good convergence performance.
  Extensive Monte Carlo simulations are performed for various statistical
properties to validate the proposed simulators. Results show that the
simulators provide fast convergence to all desired statistical properties,
including the probability density function (PDF), various auto- and
cross-correlations, level crossing rate (LCR), and average fading duration
(AFD).
  While various tests and measurements in dense scattering urban and forest
environments indicate that mobile-to-mobile channels may experience cascaded
Rayleigh fading, the proposed statistical models can be applied to simulate the
underlying channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3718</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3718</id><created>2012-07-16</created><updated>2013-05-10</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author><author><keyname>Debbabi</keyname><forenames>Mourad</forenames></author><author><keyname>Sun</keyname><forenames>Yankui</forenames></author></authors><title>MARFCAT: Transitioning to Binary and Larger Data Sets of SATE IV</title><categories>cs.CR cs.PL cs.SE stat.ML</categories><comments>A shorter version submitted for review to 13th IEEE International
  Working Conference on Source Code Analysis and Manipulation. 39 pages with
  figures, tables, TOC, and index</comments><acm-class>K.6.5; D.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a second iteration of a machine learning approach to static code
analysis and fingerprinting for weaknesses related to security, software
engineering, and others using the open-source MARF framework and the MARFCAT
application based on it for the NIST's SATE IV static analysis tool exposition
workshop's data sets that include additional test cases, including new large
synthetic cases. To aid detection of weak or vulnerable code, including source
or binary on different platforms the machine learning approach proved to be
fast and accurate to for such tasks where other tools are either much slower or
have much smaller recall of known vulnerabilities. We use signal and NLP
processing techniques in our approach to accomplish the identification and
classification tasks. MARFCAT's design from the beginning in 2010 made is
independent of the language being analyzed, source code, bytecode, or binary.
In this follow up work with explore some preliminary results in this area. We
evaluated also additional algorithms that were used to process the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3732</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3732</id><created>2012-07-16</created><updated>2012-08-03</updated><authors><author><keyname>Feigenbaum</keyname><forenames>Joan</forenames></author><author><keyname>Godfrey</keyname><forenames>Brighten</forenames></author><author><keyname>Panda</keyname><forenames>Aurojit</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author><author><keyname>Shenker</keyname><forenames>Scott</forenames></author><author><keyname>Singla</keyname><forenames>Ankit</forenames></author></authors><title>On the Resilience of Routing Tables</title><categories>cs.DC</categories><comments>Brief announcement, PODC 2012</comments><doi>10.1145/2332432.2332478</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Many modern network designs incorporate &quot;failover&quot; paths into routers'
forwarding tables. We initiate the theoretical study of the conditions under
which such resilient routing tables can guarantee delivery of packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3740</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3740</id><created>2012-07-07</created><authors><author><keyname>Lee</keyname><forenames>Jinsung</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author><author><keyname>Chong</keyname><forenames>Song</forenames></author><author><keyname>Nardelli</keyname><forenames>Bruno</forenames></author><author><keyname>Knightly</keyname><forenames>Edward W.</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author></authors><title>Making 802.11 DCF Optimal: Design, Implementation, and Evaluation</title><categories>cs.NI</categories><comments>13 pages, 16 figures, submitted for publication</comments><msc-class>68-06</msc-class><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new protocol called Optimal DCF (O-DCF). Inspired by a
sequence of analytic results, O-DCF modifies the rule of adapting CSMA
parameters, such as backoff time and transmission length, based on a function
of the demand-supply differential of link capacity captured by the local queue
length. Unlike clean-slate design, O-DCF is fully compatible with 802.11
hardware, so that it can be easily implemented only with a simple device driver
update. Through extensive simulations and real experiments with a 16-node
wireless network testbed, we evaluate the performance of O-DCF and show that it
achieves near-optimality, and outperforms other competitive ones, such as
802.11 DCF, optimal CSMA, and DiffQ in a wide range of scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3742</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3742</id><created>2012-07-16</created><authors><author><keyname>Boudourides</keyname><forenames>Moses A.</forenames></author></authors><title>Communities in Affiliation Networks with Attitudunal Actors</title><categories>cs.SI physics.soc-ph</categories><comments>12 pages, 1 figure, 1 table. Presented at the European Analytical
  Sociology Network Conference in Paris, June 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our aim here is to plead for the significance of cultural considerations of
overlapping inter-attitudinal patterns right next to well established
structural considerations of interorganizational networks based on overlapping
membership patterns. In particular, we examine how the analytical sociological
methodological incorporation of cultural attributes or attitudes might enhance
our understanding of structural community categorizations in
interorganizational networks. For this purpose, we analyze data of the
International Peace Protest Survey (IPPS) on the world-wide peace protests of
February, 15, 2003, in order to manifest the added value offered by the
consideration of the culture-structure duality in participation studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3745</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3745</id><created>2012-07-16</created><updated>2012-07-21</updated><authors><author><keyname>Gargiulo</keyname><forenames>Floriana</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author></authors><title>Influence of opinion dynamics on the evolution of games</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>7 pages, 5 figures</comments><journal-ref>PLoS ONE 7, e48916 (2012)</journal-ref><doi>10.1371/journal.pone.0048916</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under certain circumstances such as lack of information or bounded
rationality, human players can take decisions on which strategy to choose in a
game on the basis of simple opinions. These opinions can be modified after each
round by observing own or others payoff results but can be also modified after
interchanging impressions with other players. In this way, the update of the
strategies can become a question that goes beyond simple evolutionary rules
based on fitness and become a social issue. In this work, we explore this
scenario by coupling a game with an opinion dynamics model. The opinion is
represented by a continuous variable that corresponds to the certainty of the
agents respect to which strategy is best. The opinions transform into actions
by making the selection of an strategy a stochastic event with a probability
regulated by the opinion. A certain regard for the previous round payoff is
included but the main update rules of the opinion are given by a model inspired
in social interchanges. We find that the dynamics fixed points of the coupled
model is different from those of the evolutionary game or the opinion models
alone. Furthermore, new features emerge such as the resilience of the fraction
of cooperators to the topology of the social interaction network or to the
presence of a small fraction of extremist players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3749</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3749</id><created>2012-06-29</created><authors><author><keyname>Zuiani</keyname><forenames>Federico</forenames></author><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author></authors><title>Preliminary Design of Debris Removal Missions by Means of Simplified
  Models for Low-Thrust, Many-Revolution Transfers</title><categories>math.OC cs.NE</categories><journal-ref>Hindawi, International Journal of Aerospace Engineering, Volume
  2012, Article ID 836250, 22 pages</journal-ref><doi>10.1155/2012/836250</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach for the preliminary design of
Low-Thrust, many-revolution transfers. The main feature of the novel approach
is a considerable reduction in the control parameters and a consequent gain in
computational speed. Each spiral is built by using a predefined pattern for
thrust direction and switching structure. The pattern is then optimised to
minimise propellant consumption and transfer time. The variation of the orbital
elements due to the thrust is computed analytically from a first-order solution
of the perturbed Keplerian motion. The proposed approach allows for a realistic
estimation of {\Delta}V and time of flight required to transfer a spacecraft
between two arbitrary orbits. Eccentricity and plane changes are both accounted
for. The novel approach is applied here to the design of missions for the
removal of space debris by means of an Ion Beam Shepherd Spacecraft. In
particular, two slightly different variants of the proposed low-thrust control
model are used for the different phases of the mission. Thanks to their low
computational cost they can be included in a multiobjective optimisation
problem in which the sequence and timing of the removal of five pieces of
debris are optimised to minimise propellant consumption and mission duration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3750</identifier>
 <datestamp>2013-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3750</id><created>2012-07-16</created><updated>2013-03-20</updated><authors><author><keyname>Lange</keyname><forenames>Alexander</forenames></author><author><keyname>Radziszowski</keyname><forenames>Stanis&#x142;aw</forenames></author><author><keyname>Xu</keyname><forenames>Xiaodong</forenames></author></authors><title>Use of MAX-CUT for Ramsey Arrowing of Triangles</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1967, Erd\H{o}s and Hajnal asked the question: Does there exist a
$K_4$-free graph that is not the union of two triangle-free graphs? Finding
such a graph involves solving a special case of the classical Ramsey arrowing
operation. Folkman proved the existence of these graphs in 1970, and they are
now called Folkman graphs. Erd\H{o}s offered \$100 for deciding if one exists
with less than $10^{10}$ vertices. This problem remained open until 1988 when
Spencer, in a seminal paper using probabilistic techniques, proved the
existence of a Folkman graph of order $3\times 10^9$ (after an erratum),
without explicitly constructing it. In 2008, Dudek and R\&quot;{o}dl developed a
strategy to construct new Folkman graphs by approximating the maximum cut of a
related graph, and used it to improve the upper bound to 941. We improve this
bound first to 860 using their approximation technique and then further to 786
with the MAX-CUT semidefinite programming relaxation as used in the
Goemans-Williamson algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3760</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3760</id><created>2012-07-16</created><authors><author><keyname>G&#xfc;rcan</keyname><forenames>&#xd6;nder</forenames></author><author><keyname>Bernon</keyname><forenames>Carole</forenames></author><author><keyname>T&#xfc;rker</keyname><forenames>Kemal S.</forenames></author></authors><title>Towards a Self-Organized Agent-Based Simulation Model for Exploration of
  Human Synaptic Connections</title><categories>cs.NE cs.AI cs.LG nlin.AO</categories><comments>4 pages, 1 figure, 2nd Computer Science Student Workshop</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, the early design of our self-organized agent-based simulation
model for exploration of synaptic connections that faithfully generates what is
observed in natural situation is given. While we take inspiration from
neuroscience, our intent is not to create a veridical model of processes in
neurodevelopmental biology, nor to represent a real biological system. Instead,
our goal is to design a simulation model that learns acting in the same way of
human nervous system by using findings on human subjects using reflex
methodologies in order to estimate unknown connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3761</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3761</id><created>2012-07-16</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>The Graphs of Planar Soap Bubbles</title><categories>cs.DM cs.CG math.MG</categories><comments>16 pages, 9 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize the graphs formed by two-dimensional soap bubbles as being
exactly the 3-regular bridgeless planar multigraphs. Our characterization
combines a local characterization of soap bubble graphs in terms of the
curvatures of arcs meeting at common vertices, a proof that this
characterization remains invariant under Moebius transformations, an
application of Moebius invariance to prove bridgelessness, and a
Moebius-invariant power diagram of circles previously developed by the author
for its applications in graph drawing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3772</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3772</id><created>2012-07-16</created><updated>2015-03-14</updated><authors><author><keyname>Hanneke</keyname><forenames>Steve</forenames></author><author><keyname>Yang</keyname><forenames>Liu</forenames></author></authors><title>Surrogate Losses in Passive and Active Learning</title><categories>math.ST cs.LG stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active learning is a type of sequential design for supervised machine
learning, in which the learning algorithm sequentially requests the labels of
selected instances from a large pool of unlabeled data points. The objective is
to produce a classifier of relatively low risk, as measured under the 0-1 loss,
ideally using fewer label requests than the number of random labeled data
points sufficient to achieve the same. This work investigates the potential
uses of surrogate loss functions in the context of active learning.
Specifically, it presents an active learning algorithm based on an arbitrary
classification-calibrated surrogate loss function, along with an analysis of
the number of label requests sufficient for the classifier returned by the
algorithm to achieve a given risk under the 0-1 loss. Interestingly, these
results cannot be obtained by simply optimizing the surrogate risk via active
learning to an extent sufficient to provide a guarantee on the 0-1 loss, as is
common practice in the analysis of surrogate losses for passive learning. Some
of the results have additional implications for the use of surrogate losses in
passive learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3790</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3790</id><created>2012-07-16</created><authors><author><keyname>Labatut</keyname><forenames>Vincent</forenames><affiliation>BIT Lab</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>Le2i</affiliation></author></authors><title>Accuracy Measures for the Comparison of Classifiers</title><categories>cs.LG</categories><comments>The 5th International Conference on Information Technology, amman :
  Jordanie (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The selection of the best classification algorithm for a given dataset is a
very widespread problem. It is also a complex one, in the sense it requires to
make several important methodological choices. Among them, in this work we
focus on the measure used to assess the classification performance and rank the
algorithms. We present the most popular measures and discuss their properties.
Despite the numerous measures proposed over the years, many of them turn out to
be equivalent in this specific case, to have interpretation problems, or to be
unsuitable for our purpose. Consequently, classic overall success rate or
marginal rates should be preferred for this specific task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3807</identifier>
 <datestamp>2012-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3807</id><created>2012-07-16</created><authors><author><keyname>Hung</keyname><forenames>Hao-Hsiang</forenames></author></authors><title>Light Spanner and Monotone Tree</title><categories>cs.DS</categories><comments>arXiv admin note: text overlap with arXiv:1104.4669</comments><msc-class>68W25</msc-class><acm-class>F.2.2</acm-class><doi>10.1007/978-3-642-32589-2_42</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In approximation algorithm design, light spanners has applications in
graph-metric problems such as metric TSP (the traveling salesman problem). We
have developed an efficient algorithm for light spanners in bounded pathwidth
graphs, based on an intermediate data structure called monotone tree. In this
paper, we extended the results to include bounded catwidth graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3809</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3809</id><created>2012-07-16</created><authors><author><keyname>McAuley</keyname><forenames>Julian</forenames></author><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author></authors><title>Image Labeling on a Network: Using Social-Network Metadata for Image
  Classification</title><categories>cs.CV cs.SI physics.soc-ph</categories><comments>ECCV 2012; 14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale image retrieval benchmarks invariably consist of images from the
Web. Many of these benchmarks are derived from online photo sharing networks,
like Flickr, which in addition to hosting images also provide a highly
interactive social community. Such communities generate rich metadata that can
naturally be harnessed for image classification and retrieval. Here we study
four popular benchmark datasets, extending them with social-network metadata,
such as the groups to which each image belongs, the comment thread associated
with the image, who uploaded it, their location, and their network of friends.
Since these types of data are inherently relational, we propose a model that
explicitly accounts for the interdependencies between images sharing common
properties. We model the task as a binary labeling problem on a network, and
use structured learning techniques to learn model parameters. We find that
social-network metadata are useful in a variety of classification tasks, in
many cases outperforming methods based on image content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3816</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3816</id><created>2012-07-16</created><updated>2012-08-10</updated><authors><author><keyname>Moszkowski</keyname><forenames>Ben</forenames><affiliation>De Montfort University</affiliation></author></authors><title>A Complete Axiom System for Propositional Interval Temporal Logic with
  Infinite Time</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 13,
  2012) lmcs:759</journal-ref><doi>10.2168/LMCS-8(3:10)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interval Temporal Logic (ITL) is an established temporal formalism for
reasoning about time periods. For over 25 years, it has been applied in a
number of ways and several ITL variants, axiom systems and tools have been
investigated. We solve the longstanding open problem of finding a complete
axiom system for basic quantifier-free propositional ITL (PITL) with infinite
time for analysing nonterminating computational systems. Our completeness proof
uses a reduction to completeness for PITL with finite time and conventional
propositional linear-time temporal logic. Unlike completeness proofs of equally
expressive logics with nonelementary computational complexity, our semantic
approach does not use tableaux, subformula closures or explicit deductions
involving encodings of omega automata and nontrivial techniques for
complementing them. We believe that our result also provides evidence of the
naturalness of interval-based reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3837</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3837</id><created>2012-07-16</created><updated>2012-07-19</updated><authors><author><keyname>Wang</keyname><forenames>Chunyan</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>How Random are Online Social Interactions?</title><categories>cs.CY cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The massive amounts of data that social media generates has facilitated the
study of online human behavior on a scale unimaginable a few years ago. At the
same time, the much discussed apparent randomness with which people interact
online makes it appear as if these studies cannot reveal predictive social
behaviors that could be used for developing better platforms and services. We
use two large social databases to measure the mutual information entropy that
both individual and group actions generate as they evolve over time. We show
that user's interaction sequences have strong deterministic components, in
contrast with existing assumptions and models. In addition, we show that
individual interactions are more predictable when users act on their own rather
than when attending group activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3850</identifier>
 <datestamp>2012-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3850</id><created>2012-07-16</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author></authors><title>On Capacity and Optimal Scheduling for the Half-Duplex Multiple-Relay
  Channel</title><categories>cs.IT math.IT</categories><comments>Author's final version (to appear in IEEE Transactions on Information
  Theory)</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 58, No. 9, pp.
  5770-5784, 2012</journal-ref><doi>10.1109/TIT.2012.2204489</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the half-duplex multiple-relay channel (HD-MRC) where every node can
either transmit or listen but cannot do both at the same time. We obtain a
capacity upper bound based on a max-flow min-cut argument and achievable
transmission rates based on the decode-forward (DF) coding strategy, for both
the discrete memoryless HD-MRC and the phase-fading HD-MRC. We discover that
both the upper bound and the achievable rates are functions of the
transmit/listen state (a description of which nodes transmit and which
receive). More precisely, they are functions of the time fraction of the
different states, which we term a schedule. We formulate the optimal scheduling
problem to find an optimal schedule that maximizes the DF rate. The optimal
scheduling problem turns out to be a maximin optimization, for which we propose
an algorithmic solution. We demonstrate our approach on a four-node
multiple-relay channel, obtaining closed-form solutions in certain scenarios.
Furthermore, we show that for the received signal-to-noise ratio degraded
phase-fading HD-MRC, the optimal scheduling problem can be simplified to a max
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3855</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3855</id><created>2012-07-16</created><authors><author><keyname>Kim</keyname><forenames>Gol</forenames></author><author><keyname>Jong</keyname><forenames>Yunchol</forenames></author><author><keyname>Liu</keyname><forenames>Sifeng</forenames></author><author><keyname>Shong</keyname><forenames>Choe Rim</forenames></author></authors><title>Hybrid Grey Interval Relation Decision-Making in Artistic Talent
  Evaluation of Player</title><categories>cs.AI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1207.2592</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a grey interval relation TOPSIS method for the decision
making in which all of the attribute weights and attribute values are given by
the interval grey numbers. In this paper, all of the subjective and objective
weights are obtained by interval grey number and decision-making is based on
four methods such as the relative approach degree of grey TOPSIS, the relative
approach degree of grey incidence and the relative approach degree method using
the maximum entropy estimation using 2-dimensional Euclidean distance. A
multiple attribute decision-making example for evaluation of artistic talent of
Kayagum (stringed Korean harp) players is given to show practicability of the
proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3859</identifier>
 <datestamp>2012-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3859</id><created>2012-07-16</created><updated>2012-12-01</updated><authors><author><keyname>Kamilov</keyname><forenames>Ulugbek S.</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author><author><keyname>Fletcher</keyname><forenames>Alyson K.</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Approximate Message Passing with Consistent Parameter Estimation and
  Applications to Sparse Learning</title><categories>cs.IT cs.LG math.IT</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the estimation of an i.i.d. (possibly non-Gaussian) vector $\xbf
\in \R^n$ from measurements $\ybf \in \R^m$ obtained by a general cascade model
consisting of a known linear transform followed by a probabilistic
componentwise (possibly nonlinear) measurement channel. A novel method, called
adaptive generalized approximate message passing (Adaptive GAMP), that enables
joint learning of the statistics of the prior and measurement channel along
with estimation of the unknown vector $\xbf$ is presented. The proposed
algorithm is a generalization of a recently-developed EM-GAMP that uses
expectation-maximization (EM) iterations where the posteriors in the E-steps
are computed via approximate message passing. The methodology can be applied to
a large class of learning problems including the learning of sparse priors in
compressed sensing or identification of linear-nonlinear cascade models in
dynamical systems and neural spiking processes. We prove that for large i.i.d.
Gaussian transform matrices the asymptotic componentwise behavior of the
adaptive GAMP algorithm is predicted by a simple set of scalar state evolution
equations. In addition, we show that when a certain maximum-likelihood
estimation can be performed in each step, the adaptive GAMP method can yield
asymptotically consistent parameter estimates, which implies that the algorithm
achieves a reconstruction quality equivalent to the oracle algorithm that knows
the correct parameter values. Remarkably, this result applies to essentially
arbitrary parametrizations of the unknown distributions, including ones that
are nonlinear and non-Gaussian. The adaptive GAMP methodology thus provides a
systematic, general and computationally efficient method applicable to a large
range of complex linear-nonlinear models with provable guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3863</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3863</id><created>2012-07-16</created><authors><author><keyname>Yadav</keyname><forenames>Nitin</forenames></author><author><keyname>Sardina</keyname><forenames>Sebastian</forenames></author></authors><title>Qualitative Approximate Behavior Composition</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The behavior composition problem involves automatically building a controller
that is able to realize a desired, but unavailable, target system (e.g., a
house surveillance) by suitably coordinating a set of available components
(e.g., video cameras, blinds, lamps, a vacuum cleaner, phones, etc.) Previous
work has almost exclusively aimed at bringing about the desired component in
its totality, which is highly unsatisfactory for unsolvable problems. In this
work, we develop an approach for approximate behavior composition without
departing from the classical setting, thus making the problem applicable to a
much wider range of cases. Based on the notion of simulation, we characterize
what a maximal controller and the &quot;closest&quot; implementable target module
(optimal approximation) are, and show how these can be computed using ATL model
checking technology for a special case. We show the uniqueness of optimal
approximations, and prove their soundness and completeness with respect to
their imported controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3866</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3866</id><created>2012-07-16</created><authors><author><keyname>Li</keyname><forenames>Jianwen</forenames></author><author><keyname>Pu</keyname><forenames>Geguang</forenames></author><author><keyname>Zhang</keyname><forenames>Lijun</forenames></author><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>He</keyname><forenames>Jifeng</forenames></author><author><keyname>Larsen</keyname><forenames>Kim G.</forenames></author></authors><title>On the Relationship between LTL Normal Forms and Buechi Automata</title><categories>cs.FL</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of translating LTL formulas to Buechi
automata. We first translate the given LTL formula into a special
disjuctive-normal form (DNF). The formula will be part of the state, and its
DNF normal form specifies the atomic properties that should hold immediately
(labels of the transitions) and the formula that should hold afterwards (the
corresponding successor state). Surprisingly, if the given formula is
Until-free or Release-free, the Buechi automaton can be obtained directly in
this manner. For a general formula, the construction is slightly involved: an
additional component will be needed for each formula that helps us to identify
the set of accepting states. Notably, our construction is an on-the-fly
construction, and the resulting Buechi automaton has in worst case 2^{2n+1}
states where n denotes the number of subformulas. Moreover, it has a better
bound 2^{n+1} when the formula is Until- (or Release-) free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3867</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3867</id><created>2012-07-16</created><authors><author><keyname>Rashed</keyname><forenames>M. G.</forenames></author><author><keyname>Kabir</keyname><forenames>M. Hasnat</forenames></author><author><keyname>Rahim</keyname><forenames>M. Sajjadur</forenames></author><author><keyname>Ullah</keyname><forenames>Sk. Enayet</forenames></author></authors><title>CBHRP: A Cluster Based Routing Protocol for Wireless Sensor Network</title><categories>cs.NI</categories><comments>11 pages</comments><journal-ref>Computer Science &amp; Engineering: An International Journal (CSEIJ),
  Vol.1, No.3, August 2011</journal-ref><doi>10.5121/cseij.2011.1301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new two layer hierarchical routing protocol called Cluster Based
Hierarchical Routing Protocol (CBHRP) is proposed in this paper. It is an
extension of LEACH routing protocol. We introduce cluster head-set idea for
cluster-based routing where several clusters are formed with the deployed
sensors to collect information from target field. On rotation basis, a head-set
member receives data from the neighbor nodes and transmits the aggregated
results to the distance base station. This protocol reduces energy consumption
quite significantly and prolongs the life time of sensor network. It is found
that CBHRP performs better than other well accepted hierarchical routing
protocols like LEACH in term of energy consumption and time requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3868</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3868</id><created>2012-07-16</created><authors><author><keyname>Masum</keyname><forenames>Saleh</forenames></author><author><keyname>Kabir</keyname><forenames>M. Hasnat</forenames></author><author><keyname>Islam</keyname><forenames>Md. Matiqul</forenames></author><author><keyname>Shams</keyname><forenames>Rifat Ara</forenames></author><author><keyname>Ullah</keyname><forenames>Shaikh Enayet</forenames></author></authors><title>Impact of Different Spreading Codes Using FEC on DWT Based MC-CDMA
  System</title><categories>cs.IT cs.PF math.IT</categories><comments>10 Pages; International Journal of Mobile Network Communications &amp;
  Telematics (IJMNCT) Vol.2, No.3, June 2012</comments><doi>10.5121/ijmnct.2012.2301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effect of different spreading codes in DWT based MC-CDMA wireless
communication system is investigated. In this paper, we present the Bit Error
Rate (BER) performance of different spreading codes (Walsh-Hadamard code,
Orthogonal gold code and Golay complementary sequences) using Forward Error
Correction (FEC) of the proposed system. The data is analyzed and is compared
among different spreading codes in both coded and uncoded cases. It is found
via computer simulation that the performance of the proposed coded system is
much better than that of the uncoded system irrespective of the spreading codes
and all the spreading codes show approximately similar nature for both coded
and uncoded in all modulation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3869</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3869</id><created>2012-07-16</created><authors><author><keyname>Widanapathirana</keyname><forenames>Chathuranga</forenames></author><author><keyname>&#x15e;ekercio&#x1e7;lu</keyname><forenames>Y. Ahmet</forenames></author><author><keyname>Ivanovich</keyname><forenames>Milosh V.</forenames></author><author><keyname>Fitzpatrick</keyname><forenames>Paul G.</forenames></author><author><keyname>Li</keyname><forenames>Jonathan C.</forenames></author></authors><title>Automated Inference System for End-To-End Diagnosis of Network
  Performance Issues in Client-Terminal Devices</title><categories>cs.NI cs.AI cs.PF</categories><comments>arXiv admin note: substantial text overlap with arXiv:1207.3560</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) 2012; ISSN: 0975-2293/(e)0974-9322</journal-ref><doi>10.5121/ijcnc.2012.4303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional network diagnosis methods of Client-Terminal Device (CTD)
problems tend to be laborintensive, time consuming, and contribute to increased
customer dissatisfaction. In this paper, we propose an automated solution for
rapidly diagnose the root causes of network performance issues in CTD. Based on
a new intelligent inference technique, we create the Intelligent Automated
Client Diagnostic (IACD) system, which only relies on collection of
Transmission Control Protocol (TCP) packet traces. Using soft-margin Support
Vector Machine (SVM) classifiers, the system (i) distinguishes link problems
from client problems and (ii) identifies characteristics unique to the specific
fault to report the root cause. The modular design of the system enables
support for new access link and fault types. Experimental evaluation
demonstrated the capability of the IACD system to distinguish between faulty
and healthy links and to diagnose the client faults with 98% accuracy. The
system can perform fault diagnosis independent of the user's specific TCP
implementation, enabling diagnosis of diverse range of client devices
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3871</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3871</id><created>2012-07-16</created><authors><author><keyname>Islam</keyname><forenames>Md. Matiqul</forenames></author><author><keyname>Kabir</keyname><forenames>M. Hasnat</forenames></author><author><keyname>Ullah</keyname><forenames>Sk. Enayet</forenames></author></authors><title>Performance Analysis of Wavelet Based MC-CDMA System with Implementation
  of Various Antenna Diversity Schemes</title><categories>cs.IT cs.PF math.IT</categories><journal-ref>International Journal of Research and Reviews in Computer Science
  (IJRRCS) Vol. 2, No. 2, April 2011, 271-274</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The impact of using wavelet based technique on the performance of a MC-CDMA
wireless communication system has been investigated. The system under proposed
study incorporates Walsh Hadamard codes to discriminate the message signal for
individual user. A computer program written in Mathlab source code is developed
and this simulation study is made with implementation of various antenna
diversity schemes and fading (Rayleigh and Rician) channel. Computer simulation
results demonstrate that the proposed wavelet based MC-CDMA system outperforms
in Alamouti (two transmit antenna and one receive antenna) under AWGN and
Rician channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3872</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3872</id><created>2012-07-16</created><authors><author><keyname>Atat</keyname><forenames>Youssef</forenames></author><author><keyname>Rizk</keyname><forenames>Mostafa</forenames></author></authors><title>Top Down Approach: SIMULINK Mixed Hardware / Software Design</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System-level design methodologies have been introduced as a solution to
handle the design complexity of mixed Hardware / Software systems. In this
paper we describe a system-level design flow starting from Simulink
specification, focusing on concurrent hardware and software design and
verification at four different abstraction levels: System Simulink model,
Transaction Simulink model, Macro architecture, and micro architecture. We used
the MP3 CodeC application, to validate our approach and methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3874</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3874</id><created>2012-07-17</created><authors><author><keyname>Yadav</keyname><forenames>Nitin</forenames></author><author><keyname>Sardina</keyname><forenames>Sebastian</forenames></author></authors><title>Reasoning about Agent Programs using ATL-like Logics</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a variant of Alternating-time Temporal Logic (ATL) grounded in the
agents' operational know-how, as defined by their libraries of abstract plans.
Inspired by ATLES, a variant itself of ATL, it is possible in our logic to
explicitly refer to &quot;rational&quot; strategies for agents developed under the
Belief-Desire-Intention agent programming paradigm. This allows us to express
and verify properties of BDI systems using ATL-type logical frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3875</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3875</id><created>2012-07-17</created><authors><author><keyname>Rashed</keyname><forenames>Md. Golam</forenames></author><author><keyname>Kabir</keyname><forenames>M. Hasnat</forenames></author><author><keyname>Reza</keyname><forenames>Md. Selim</forenames></author><author><keyname>Islam</keyname><forenames>Md. Matiqul</forenames></author><author><keyname>Shams</keyname><forenames>Rifat Ara</forenames></author><author><keyname>Masum</keyname><forenames>Saleh</forenames></author><author><keyname>Ullah</keyname><forenames>Sheikh Enayet</forenames></author></authors><title>Transmission of Voice Signal: BER Performance Analysis of Different FEC
  Schemes Based OFDM System over Various Channels</title><categories>cs.IT cs.PF math.IT</categories><comments>12 Pages</comments><journal-ref>International Journal of Advanced Science and Technology, Vol. 34,
  September 2011, 89-100</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the impact of Forward Error Correction (FEC)
codes namely Cyclic Redundancy Code and Convolution Code on the performance of
OFDM wireless communication system for speech signal transmission over both
AWGN and fading (Rayleigh and Rician) channels in term of Bit Error
Probability. The simulation has been done in conjunction with QPSK digital
modulation and compared with uncoded resultstal modulation. In the fading
channels, it is found via computer simulation that the performance of the
Convolution interleaved based OFDM systems outperform than that of CRC
interleaved OFDM system as well as uncoded OFDM channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3876</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3876</id><created>2012-07-17</created><authors><author><keyname>Rashed</keyname><forenames>Md. Golam</forenames></author><author><keyname>Kabir</keyname><forenames>M. Hasnat</forenames></author><author><keyname>Rahim</keyname><forenames>Muhammad Sajjadur</forenames></author><author><keyname>Ullah</keyname><forenames>Shaikh Enayet</forenames></author></authors><title>Cluster Based Hierarchical Routing Protocol for Wireless Sensor Network</title><categories>cs.NI cs.PF</categories><comments>International Journal of Computer and Network Security(IJCNS), Vol.
  2, No. 5, May 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficient use of energy source in a sensor node is most desirable
criteria for prolong the life time of wireless sensor network. In this paper,
we propose a two layer hierarchical routing protocol called Cluster Based
Hierarchical Routing Protocol (CBHRP). We introduce a new concept called
head-set, consists of one active cluster head and some other associate cluster
heads within a cluster. The head-set members are responsible for control and
management of the network. Results show that this protocol reduces energy
consumption quite significantly and prolongs the life time of sensor network as
compared to LEACH.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3877</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3877</id><created>2012-07-17</created><authors><author><keyname>Fang</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Hongbin</forenames></author></authors><title>A New Determinant Inequality of Positive Semi-Definite Matrices</title><categories>cs.IT math.IT</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new determinant inequality of positive semidefinite matrices is discovered
and proved by us. This new inequality is useful for attacking and solving a
variety of optimization problems arising from the design of wireless
communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3880</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3880</id><created>2012-07-17</created><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>One-counter verifiers for decidable languages</title><categories>cs.CC cs.FL quant-ph</categories><comments>16 pages</comments><acm-class>F.1.1; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Condon and Lipton (FOCS 1989) showed that the class of languages having a
space-bounded interactive proof system (IPS) is a proper subset of decidable
languages, where the verifier is a probabilistic Turing machine. In this paper,
we show that if we use architecturally restricted verifiers instead of
restricting the working memory, i.e. replacing the working tape(s) with a
single counter, we can define some IPS's for each decidable language. Such
verifiers are called two-way probabilistic one-counter automata (2pca's). Then,
we show that by adding a fixed-size quantum memory to a 2pca, called a two-way
one-counter automaton with quantum and classical states (2qcca), the protocol
can be space efficient. As a further result, if the 2qcca can use a quantum
counter instead of a classical one, then the protocol can even be public, also
known as Arthur-Merlin games.
  We also investigate the computational power of 2pca's and 2qcca's as language
recognizers. We show that bounded-error 2pca's can be more powerful than their
deterministic counterparts by giving a bounded-error simulation of their
nondeterministic counterparts. Then, we present a new programming technique for
bounded-error 2qcca's and show that they can recognize a language which seems
not to be recognized by any bounded-error 2pca. We also obtain some interesting
results for bounded-error 1-pebble quantum finite automata based on this new
technique. Lastly, we prove a conjecture posed by Ravikumar (FSTTCS 1992)
regarding 1-pebble probabilistic finite automata, i.e. they can recognize some
nonstochastic languages with bounded error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3882</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3882</id><created>2012-07-17</created><authors><author><keyname>Rashed</keyname><forenames>Md. Golam</forenames></author><author><keyname>Kabir</keyname><forenames>M. Hasnat</forenames></author><author><keyname>Ullah</keyname><forenames>Shaikh Enayet</forenames></author></authors><title>WEP: An Energy Efficient Protocol for Cluster Based Heterogeneous
  Wireless Sensor Network</title><categories>cs.IT cs.PF math.IT</categories><comments>7 Pages</comments><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.2, No.2, March 2011, 54-60</journal-ref><doi>10.5121/ijdps.2011.2205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an energy-efficient routing protocol in order to enhance the
stability period of wireless sensor networks. This protocol is called weighted
election protocol (WEP). It introduces a scheme to combine clustering strategy
with chain routing algorithm for satisfy both energy and stable period
constrains under heterogeneous environment in WSNs. Simulation results show
that new one performs better than LEACH, SEP and HEARP in terms of stability
period and network lifetime. It is also found that longer stability period
strongly depend on higher values of extra energy during its heterogeneous
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3884</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3884</id><created>2012-07-17</created><authors><author><keyname>Shams</keyname><forenames>Rifat Ara</forenames></author><author><keyname>Kabir</keyname><forenames>M. Hasnat</forenames></author><author><keyname>Ullah</keyname><forenames>Sheikh Enayet</forenames></author></authors><title>Effect of Interleaved FEC Code on Wavelet Based MC-CDMA System with
  Alamouti STBC in Different Modulation Schemes</title><categories>cs.IT cs.PF math.IT</categories><journal-ref>International Journal of Computer Science, Engineering and
  Information Technology (IJCSEIT), Vol.2, No.1, February 2012, 23-33</journal-ref><doi>10.5121/ijcseit.2012.2103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the impact of Forward Error Correction (FEC) code namely
Trellis code with interleaver on the performance of wavelet based MC-CDMA
wireless communication system with the implementation of Alamouti antenna
diversity scheme has been investigated in terms of Bit Error Rate (BER) as a
function of Signal-to-Noise Ratio (SNR) per bit. Simulation of the system under
proposed study has been done in M-ary modulation schemes (MPSK, MQAM and DPSK)
over AWGN and Rayleigh fading channel incorporating Walsh Hadamard code as
orthogonal spreading code to discriminate the message signal for individual
user. It is observed via computer simulation that the performance of the
interleaved coded based proposed system outperforms than that of the uncoded
system in all modulation schemes over Rayleigh fading channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3885</identifier>
 <datestamp>2013-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3885</id><created>2012-07-17</created><updated>2013-11-15</updated><authors><author><keyname>Chazal</keyname><forenames>Frederic</forenames><affiliation>INRIA Saclay - France</affiliation></author><author><keyname>de Silva</keyname><forenames>Vin</forenames><affiliation>Pomona College - USA</affiliation></author><author><keyname>Oudot</keyname><forenames>Steve</forenames><affiliation>INRIA Saclay - France</affiliation></author></authors><title>Persistence stability for geometric complexes</title><categories>math.AT cs.CG</categories><comments>We include a discussion of ambient Cech complexes and a new class of
  examples called Dowker complexes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the properties of the homology of different geometric
filtered complexes (such as Vietoris-Rips, Cech and witness complexes) built on
top of precompact spaces. Using recent developments in the theory of
topological persistence we provide simple and natural proofs of the stability
of the persistent homology of such complexes with respect to the
Gromov--Hausdorff distance. We also exhibit a few noteworthy properties of the
homology of the Rips and Cech complexes built on top of compact spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3887</identifier>
 <datestamp>2012-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3887</id><created>2012-07-17</created><updated>2012-10-01</updated><authors><author><keyname>Dahan</keyname><forenames>Xavier</forenames></author></authors><title>On lexicographic Groebner bases of radical ideals in dimension zero:
  interpolation and structure</title><categories>cs.SC</categories><comments>Substantial revisions at many places. 23 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the elimination property held by the lexicographic monomial order, the
corresponding Groebner bases display strong structural properties from which
meaningful informations can easily be extracted. We study these properties for
radical ideals of (co)dimension zero. The proof presented relies on a
combinatorial decomposition of the finite set of points whereby iterated
Lagrange interpolation formulas permit to reconstruct a minimal Groebner basis.
This is the first fully explicit interpolation formula for polynomials forming
a lexicographic Groebner basis, from which the structure property can easily be
read off. The inductive nature of the proof also yield as a byproduct a
triangular decomposition algorithm from the Groebner basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3899</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3899</id><created>2012-07-17</created><authors><author><keyname>Ju</keyname><forenames>Munsu</forenames></author><author><keyname>Jong</keyname><forenames>Yunchol</forenames></author></authors><title>Fast View Frustum Culling of Spatial Object by Analytical Bounding Bin</title><categories>cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a common sense to apply the VFC (view frustum culling) of spatial
object to bounding cube of the object in 3D graphics. The accuracy of VFC can
not be guaranteed even in cube rotated three-dimensionally. In this paper is
proposed a method which is able to carry out more precise and fast VFC of any
spatial object in the image domain of cube by an analytic mapping, and is
demonstrated the effect of the method for terrain block on global surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3911</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3911</id><created>2012-07-17</created><updated>2013-11-15</updated><authors><author><keyname>Beigi</keyname><forenames>Salman</forenames></author><author><keyname>Gohari</keyname><forenames>Amin</forenames></author></authors><title>On Dimension Bounds for Auxiliary Quantum Systems</title><categories>quant-ph cs.IT math.IT</categories><comments>30 pages, title changed, structure significantly improved, results
  unchanged, to appear in IEEE TIT</comments><journal-ref>IEEE Transactions on Information Theory, vol 60, pp. 368-387,
  January 2014</journal-ref><doi>10.1109/TIT.2013.2286079</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expressions of several capacity regions in quantum information theory involve
an optimization over auxiliary quantum registers. Evaluating such expressions
requires bounds on the dimension of the Hilbert space of these auxiliary
registers, for which no non-trivial technique is known; we lack a quantum
analog of the Carath\'{e}odory theorem. In this paper, we develop a new
non-Carath\'{e}odory-type tool for evaluating expressions involving a single
quantum auxiliary register and several classical random variables. As we show,
such expressions appear in problems of entanglement-assisted Gray-Wyner and
entanglement-assisted channel simulation, where the question of whether
entanglement helps in these settings is related to that of evaluating
expressions with a single quantum auxiliary register. To evaluate such
expressions, we argue that developing a quantum analog of the Carath\'{e}odory
theorem requires a better understanding of a notion which we call ``quantum
conditioning.&quot; We then proceed by proving a few results about quantum
conditioning, one of which is that quantum conditioning is strictly richer than
the usual classical conditioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3914</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3914</id><created>2012-07-17</created><authors><author><keyname>Zschaler</keyname><forenames>Gerd</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Largenet2: an object-oriented programming library for simulating large
  adaptive networks</title><categories>physics.comp-ph cs.DS cs.SI physics.soc-ph</categories><comments>2 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The largenet2 C++ library provides an infrastructure for the simulation of
large dynamic and adaptive networks with discrete node and link states. The
library is released as free software. It is available at
http://rincedd.github.com/largenet2. Largenet2 is licensed under the Creative
Commons Attribution-NonCommercial 3.0 Unported License.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3921</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3921</id><created>2012-07-17</created><authors><author><keyname>Panuzzo</keyname><forenames>Pasquale</forenames><affiliation>CEA Saclay, Laboratoire AIM, Irfu/SAp, France</affiliation></author><author><keyname>Li</keyname><forenames>Jinjing</forenames><affiliation>National Astronomical Observatories, China</affiliation><affiliation>GSegment Space Technologies, Inc., China</affiliation></author><author><keyname>Caux</keyname><forenames>Emmanuel</forenames><affiliation>Universit&#xe9; de Toulouse, UPS-OMP, IRAP, France</affiliation><affiliation>CNRS, IRAP, France</affiliation></author></authors><title>PlotXY: a high quality plotting system for the Herschel Interactive
  Processing Environment (HIPE), and the astronomical community</title><categories>cs.GR astro-ph.IM</categories><comments>4 pages, 6 figures, proceeding of Astronomical Data Analysis Software
  and Systems XXI, ASP Conf. Ser., in press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Herschel Interactive Processing Environment (HIPE) was developed by the
European Space Agency (ESA) in collaboration with NASA and the Herschel
Instrument Control Centres to provide the astronomical community a complete
environment to process and analyze the data gathered by the Herschel Space
Observatory. One of the most important components of HIPE is the plotting
system (named PlotXY) that we present here. With PlotXY it is possible to
produce easily high quality publication ready 2D plots. It provides a long list
of features, with fully configurable components, and interactive zooming. The
entire code of HIPE is written in Java and is open source released under the
GNU Lesser General Public License version 3. A new version of PlotXY is being
developed to be independent from the HIPE code base; it is available to the
software development community for the inclusion in other projects at the URL
http://code.google.com/p/jplot2d/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3923</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3923</id><created>2012-07-17</created><authors><author><keyname>Gray</keyname><forenames>Norman</forenames></author><author><keyname>Carozzi</keyname><forenames>Tobia</forenames></author><author><keyname>Woan</keyname><forenames>Graham</forenames></author></authors><title>Managing Research Data in Big Science</title><categories>astro-ph.IM cs.DL hep-ex physics.ins-det</categories><comments>Project final report, 45 pages: see
  http://purl.org/nxg/projects/mrd-gw for project details, and
  http://purl.org/nxg/projects/mrd-gw/report for other document versions</comments><acm-class>H.3.7; J.2; K.6.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The project which led to this report was funded by JISC in 2010--2011 as part
of its 'Managing Research Data' programme, to examine the way in which Big
Science data is managed, and produce any recommendations which may be
appropriate.
  Big science data is different: it comes in large volumes, and it is shared
and exploited in ways which may differ from other disciplines. This project has
explored these differences using as a case-study Gravitational Wave data
generated by the LSC, and has produced recommendations intended to be useful
variously to JISC, the funding council (STFC) and the LSC community.
  In Sect. 1 we define what we mean by 'big science', describe the overall data
culture there, laying stress on how it necessarily or contingently differs from
other disciplines.
  In Sect. 2 we discuss the benefits of a formal data-preservation strategy,
and the cases for open data and for well-preserved data that follow from that.
This leads to our recommendations that, in essence, funders should adopt rather
light-touch prescriptions regarding data preservation planning: normal data
management practice, in the areas under study, corresponds to notably good
practice in most other areas, so that the only change we suggest is to make
this planning more formal, which makes it more easily auditable, and more
amenable to constructive criticism.
  In Sect. 3 we briefly discuss the LIGO data management plan, and pull
together whatever information is available on the estimation of digital
preservation costs.
  The report is informed, throughout, by the OAIS reference model for an open
archive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3932</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3932</id><created>2012-07-17</created><authors><author><keyname>Nongmeikapam</keyname><forenames>Kishorjit</forenames></author><author><keyname>RK</keyname><forenames>Vidya Raj</forenames></author><author><keyname>Singh</keyname><forenames>Oinam Imocha</forenames></author><author><keyname>Bandyopadhyay</keyname><forenames>Sivaji</forenames></author></authors><title>Automatic Segmentation of Manipuri (Meiteilon) Word into Syllabic Units</title><categories>cs.CL</categories><comments>12 Pages, 5 Tables See the link
  http://airccse.org/journal/jcsit/0612csit11.pdf</comments><acm-class>I.2.7</acm-class><doi>10.5121/ijcsit.2012.4311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work of automatic segmentation of a Manipuri language (or Meiteilon) word
into syllabic units is demonstrated in this paper. This language is a scheduled
Indian language of Tibeto-Burman origin, which is also a very highly
agglutinative language. This language usages two script: a Bengali script and
Meitei Mayek (Script). The present work is based on the second script. An
algorithm is designed so as to identify mainly the syllables of Manipuri origin
word. The result of the algorithm shows a Recall of 74.77, Precision of 91.21
and F-Score of 82.18 which is a reasonable score with the first attempt of such
kind for this language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3934</identifier>
 <datestamp>2014-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3934</id><created>2012-07-17</created><updated>2014-02-18</updated><authors><author><keyname>Angelini</keyname><forenames>Patrizio</forenames></author><author><keyname>Da Lozzo</keyname><forenames>Giordano</forenames></author><author><keyname>Di Battista</keyname><forenames>Giuseppe</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Patrignani</keyname><forenames>Maurizio</forenames></author><author><keyname>Roselli</keyname><forenames>Vincenzo</forenames></author></authors><title>Relaxing the Constraints of Clustered Planarity</title><categories>cs.DM cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a drawing of a clustered graph vertices and edges are drawn as points and
curves, respectively, while clusters are represented by simple closed regions.
A drawing of a clustered graph is c-planar if it has no edge-edge, edge-region,
or region-region crossings. Determining the complexity of testing whether a
clustered graph admits a c-planar drawing is a long-standing open problem in
the Graph Drawing research area. An obvious necessary condition for c-planarity
is the planarity of the graph underlying the clustered graph. However, such a
condition is not sufficient and the consequences on the problem due to the
requirement of not having edge-region and region-region crossings are not yet
fully understood.
  In order to shed light on the c-planarity problem, we consider a relaxed
version of it, where some kinds of crossings (either edge-edge, edge-region, or
region-region) are allowed even if the underlying graph is planar. We
investigate the relationships among the minimum number of edge-edge,
edge-region, and region-region crossings for drawings of the same clustered
graph. Also, we consider drawings in which only crossings of one kind are
admitted. In this setting, we prove that drawings with only edge-edge or with
only edge-region crossings always exist, while drawings with only region-region
crossings may not. Further, we provide upper and lower bounds for the number of
such crossings. Finally, we give a polynomial-time algorithm to test whether a
drawing with only region-region crossings exist for biconnected graphs, hence
identifying a first non-trivial necessary condition for c-planarity that can be
tested in polynomial time for a noticeable class of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3937</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3937</id><created>2012-07-17</created><authors><author><keyname>Henry</keyname><forenames>Julien</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Moy</keyname><forenames>Matthieu</forenames><affiliation>VERIMAG - IMAG</affiliation></author></authors><title>PAGAI: a path sensitive static analyzer</title><categories>cs.PL cs.LO</categories><comments>Tools for Automatic Program AnalysiS (TAPAS 2012), Deauville : France
  (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the design and the implementation of PAGAI, a new static analyzer
working over the LLVM compiler infrastructure, which computes inductive
invariants on the numerical variables of the analyzed program. PAGAI implements
various state-of-the-art algorithms combining abstract interpretation and
decision procedures (SMT-solving), focusing on distinction of paths inside the
control flow graph while avoiding systematic exponential enumerations. It is
parametric in the abstract domain in use, the iteration algorithm, and the
decision procedure. We compared the time and precision of various combinations
of analysis algorithms and abstract domains, with extensive experiments both on
personal benchmarks and widely available GNU programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3943</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3943</id><created>2012-07-17</created><authors><author><keyname>Sattari</keyname><forenames>Mohammad Reza Jabbarpour</forenames></author><author><keyname>Noor</keyname><forenames>Rafidah Md</forenames></author><author><keyname>Keshavarz</keyname><forenames>Hassan</forenames></author></authors><title>A Taxonomy for Congestion Control Algorithms in Vehicular Ad Hoc
  Networks</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  One of the main criteria in Vehicular Ad hoc Networks (VANETs) that has
attracted the researchers' consideration is congestion control. Accordingly,
many algorithms have been proposed to alleviate the congestion problem,
although it is hard to find an appropriate algorithm for applications and
safety messages among them. Safety messages encompass beacons and event-driven
messages. Delay and reliability are essential requirements for event-driven
messages. In crowded networks where beacon messages are broadcasted at a high
number of frequencies by many vehicles, the Control Channel (CCH), which used
for beacons sending, will be easily congested. On the other hand, to guarantee
the reliability and timely delivery of event-driven messages, having a
congestion free control channel is a necessity. Thus, consideration of this
study is given to find a solution for the congestion problem in VANETs by
taking a comprehensive look at the existent congestion control algorithms. In
addition, the taxonomy for congestion control algorithms in VANETs is presented
based on three classes, namely, proactive, reactive and hybrid. Finally, we
have found the criteria in which fulfill prerequisite of a good congestion
control algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3944</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3944</id><created>2012-07-17</created><authors><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>Jacobo-Berlles</keyname><forenames>Julio</forenames></author><author><keyname>Gambini</keyname><forenames>Juliana</forenames></author><author><keyname>Mejail</keyname><forenames>Marta</forenames></author></authors><title>Polarimetric SAR Image Segmentation with B-Splines and a New Statistical
  Model</title><categories>cs.CV stat.ML</categories><journal-ref>Multidimensional Systems and Signal Processing, vol. 21, 319-342,
  2010</journal-ref><doi>10.1007/s11045-010-0113-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach for polarimetric Synthetic Aperture Radar (SAR) image
region boundary detection based on the use of B-Spline active contours and a
new model for polarimetric SAR data: the GHP distribution. In order to detect
the boundary of a region, initial B-Spline curves are specified, either
automatically or manually, and the proposed algorithm uses a deformable
contours technique to find the boundary. In doing this, the parameters of the
polarimetric GHP model for the data are estimated, in order to find the
transition points between the region being segmented and the surrounding area.
This is a local algorithm since it works only on the region to be segmented.
Results of its performance are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3961</identifier>
 <datestamp>2012-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3961</id><created>2012-07-17</created><updated>2012-11-14</updated><authors><author><keyname>Akdemir</keyname><forenames>Deniz</forenames></author></authors><title>Ensemble Clustering with Logic Rules</title><categories>stat.ML cs.LG</categories><comments>Replacing two articles with one</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, the logic rule ensembles approach to supervised learning is
applied to the unsupervised or semi-supervised clustering. Logic rules which
were obtained by combining simple conjunctive rules are used to partition the
input space and an ensemble of these rules is used to define a similarity
matrix. Similarity partitioning is used to partition the data in an
hierarchical manner. We have used internal and external measures of cluster
validity to evaluate the quality of clusterings or to identify the number of
clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3962</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3962</id><created>2012-07-17</created><authors><author><keyname>Alt</keyname><forenames>Helmut</forenames></author><author><keyname>Scharf</keyname><forenames>Ludmila</forenames></author></authors><title>Computation of the Hausdorff distance between sets of line segments in
  parallel</title><categories>cs.CG cs.CV cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Hausdorff distance for two sets of non-intersecting line
segments can be computed in parallel in $O(\log^2 n)$ time using O(n)
processors in a CREW-PRAM computation model. We discuss how some parts of the
sequential algorithm can be performed in parallel using previously known
parallel algorithms; and identify the so-far unsolved part of the problem for
the parallel computation, which is the following: Given two sets of
$x$-monotone curve segments, red and blue, for each red segment find its
extremal intersection points with the blue set, i.e. points with the minimal
and maximal $x$-coordinate. Each segment set is assumed to be intersection
free. For this intersection problem we describe a parallel algorithm which
completes the Hausdorff distance computation within the stated time and
processor bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3964</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3964</id><created>2012-07-17</created><authors><author><keyname>Shen</keyname><forenames>Liang</forenames></author></authors><title>Developments and Obstacles in Chinese eBook Market</title><categories>cs.DL cs.CY</categories><comments>Lund University Master Degree thesis, 44 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this study was to provide insights into the eBook market in
China through case studies on eBook companies and a survey research with
individual eBook users. The information from three companies, Beijing Superstar
Electric Company, Beijing Founder APABI Technology Limited, and Beijing Sursen
Electronic Technology Company Limited, showed that the B2B market has been
developed due to the huge requirement from organization customers, universities
libraries in particularly, and the B2C market is still immature. The
information from interviews and relative data revealed that both Superstar and
Sursen have serious copyright infringement which is an important problem
impeding the further development of the eBook market. The questionnaire
explored awareness, purchase, reading and other experiences of eBook end-users.
Questions indicated that readers were attracted by the technical advantages
including costless to copy, easy to transfer, searchable and easy to store, but
did not want to pay for eBooks. Because the computers, especially desktop PCs,
were the main device for reading and the CRT displays were massive used while
there were few dedicated reading device in the market, many eBook end-users
still preferred to read extended passages of text on papers rather than
screens. Today the copyrights issue, user acceptance and the reading device are
three significant obstacles for eBook industry in China.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3976</identifier>
 <datestamp>2012-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3976</id><created>2012-07-17</created><updated>2012-12-12</updated><authors><author><keyname>Anand</keyname><forenames>Abhash</forenames></author><author><keyname>Baswana</keyname><forenames>Surender</forenames></author><author><keyname>Gupta</keyname><forenames>Manoj</forenames></author><author><keyname>Sen</keyname><forenames>Sandeep</forenames></author></authors><title>Maintaining Approximate Maximum Weighted Matching in Fully Dynamic
  Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fully dynamic algorithm for maintaining approximate maximum
weight matching in general weighted graphs. The algorithm maintains a matching
${\cal M}$ whose weight is at least $1/8 M^{*}$ where $M^{*}$ is the weight of
the maximum weight matching. The algorithm achieves an expected amortized
$O(\log n \log \mathcal C)$ time per edge insertion or deletion, where
$\mathcal C$ is the ratio of the weights of the highest weight edge to the
smallest weight edge in the given graph. Using a simple randomized scaling
technique, we are able to obtain a matching whith expected approximation ratio
4.9108.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.3994</identifier>
 <datestamp>2014-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.3994</id><created>2012-07-17</created><updated>2013-05-30</updated><authors><author><keyname>Yan</keyname><forenames>Xiaoran</forenames></author><author><keyname>Shalizi</keyname><forenames>Cosma Rohilla</forenames></author><author><keyname>Jensen</keyname><forenames>Jacob E.</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Zdeborova</keyname><forenames>Lenka</forenames></author><author><keyname>Zhang</keyname><forenames>Pan</forenames></author><author><keyname>Zhu</keyname><forenames>Yaojia</forenames></author></authors><title>Model Selection for Degree-corrected Block Models</title><categories>cs.SI cond-mat.stat-mech math.ST physics.soc-ph stat.ML stat.TH</categories><journal-ref>J. Stat. Mech. (2014) P05007</journal-ref><doi>10.1088/1742-5468/2014/05/P05007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of models for networks raises challenging problems of model
selection: the data are sparse and globally dependent, and models are typically
high-dimensional and have large numbers of latent variables. Together, these
issues mean that the usual model-selection criteria do not work properly for
networks. We illustrate these challenges, and show one way to resolve them, by
considering the key network-analysis problem of dividing a graph into
communities or blocks of nodes with homogeneous patterns of links to the rest
of the network. The standard tool for doing this is the stochastic block model,
under which the probability of a link between two nodes is a function solely of
the blocks to which they belong. This imposes a homogeneous degree distribution
within each block; this can be unrealistic, so degree-corrected block models
add a parameter for each node, modulating its over-all degree. The choice
between ordinary and degree-corrected block models matters because they make
very different inferences about communities. We present the first principled
and tractable approach to model selection between standard and degree-corrected
block models, based on new large-graph asymptotics for the distribution of
log-likelihood ratios under the stochastic block model, finding substantial
departures from classical results for sparse graphs. We also develop
linear-time approximations for log-likelihoods under both the stochastic block
model and the degree-corrected model, using belief propagation. Applications to
simulated and real networks show excellent agreement with our approximations.
Our results thus both solve the practical problem of deciding on degree
correction, and point to a general approach to model selection in network
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4017</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4017</id><created>2012-07-17</created><authors><author><keyname>Mansouri</keyname><forenames>Shohreh Sharif</forenames></author><author><keyname>Dubrova</keyname><forenames>Elena</forenames></author></authors><title>Ring Oscillator Physical Unclonable Function with Multi Level Supply
  Voltages</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most common types of Physical Unclonable Functions (PUFs) is the
ring oscillator PUF (RO-PUF), in which the output bits are obtained by
comparing the oscillation frequencies of different ring oscillators. In this
paper we design a new type of ring oscillator PUF in which the different
inverters composing the ring oscillators can be supplied by different voltages.
The new RO-PUF can be used to (1) increase the maximum number of possible
challenge/response pairs produced by the PUF; (2) generate a high number of
bits while consuming a low area; (3) improve the reliability of the PUF in case
of temperature variations. We present the basic idea of the new RO-PUF and then
discuss its applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4028</identifier>
 <datestamp>2012-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4028</id><created>2012-07-17</created><updated>2012-09-20</updated><authors><author><keyname>Brody</keyname><forenames>Dorje C.</forenames></author><author><keyname>Hughston</keyname><forenames>Lane P.</forenames></author><author><keyname>Yang</keyname><forenames>Xun</forenames></author></authors><title>Signal processing with Levy information</title><categories>math.PR cs.IT math.IT math.OC q-fin.GN</categories><comments>27 pages. Version to appear in: Proc. R. Soc. London A</comments><journal-ref>Proc. R. Soc. London A 469, 20120433 (2013)</journal-ref><doi>10.1098/rspa.2012.0433</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Levy processes, which have stationary independent increments, are ideal for
modelling the various types of noise that can arise in communication channels.
If a Levy process admits exponential moments, then there exists a parametric
family of measure changes called Esscher transformations. If the parameter is
replaced with an independent random variable, the true value of which
represents a &quot;message&quot;, then under the transformed measure the original Levy
process takes on the character of an &quot;information process&quot;. In this paper we
develop a theory of such Levy information processes. The underlying Levy
process, which we call the fiducial process, represents the &quot;noise type&quot;. Each
such noise type is capable of carrying a message of a certain specification. A
number of examples are worked out in detail, including information processes of
the Brownian, Poisson, gamma, variance gamma, negative binomial, inverse
Gaussian, and normal inverse Gaussian type. Although in general there is no
additive decomposition of information into signal and noise, one is led
nevertheless for each noise type to a well-defined scheme for signal detection
and enhancement relevant to a variety of practical situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4044</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4044</id><created>2012-07-17</created><authors><author><keyname>Canzian</keyname><forenames>Luca</forenames></author><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author><author><keyname>Zame</keyname><forenames>William</forenames></author><author><keyname>Zorzi</keyname><forenames>Michele</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Designing Information Revelation and Intervention with an Application to
  Flow Control</title><categories>cs.GT cs.IT cs.MA cs.NI math.IT</categories><comments>53 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many familiar situations in which a manager seeks to design a
system in which users share a resource, but outcomes depend on the information
held and actions taken by users. If communication is possible, the manager can
ask users to report their private information and then, using this information,
instruct them on what actions they should take. If the users are compliant,
this reduces the manager's optimization problem to a well-studied problem of
optimal control. However, if the users are self-interested and not compliant,
the problem is much more complicated: when asked to report their private
information, the users might lie; upon receiving instructions, the users might
disobey. Here we ask whether the manager can design the system to get around
both of these difficulties. To do so, the manager must provide for the users
the incentives to report truthfully and to follow the instructions, despite the
fact that the users are self-interested. For a class of environments that
includes many resource allocation games in communication networks, we provide
tools for the manager to design an efficient system. In addition to reports and
recommendations, the design we employ allows the manager to intervene in the
system after the users take actions. In an abstracted environment, we find
conditions under which the manager can achieve the same outcome it could if
users were compliant, and conditions under which it does not. We then apply our
framework and results to design a flow control management system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4047</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4047</id><created>2012-07-17</created><updated>2013-12-22</updated><authors><author><keyname>Alc&#xe1;zar</keyname><forenames>J. G.</forenames></author><author><keyname>Hermoso</keyname><forenames>C.</forenames></author><author><keyname>Muntingh</keyname><forenames>G.</forenames></author></authors><title>Detecting Symmetries of Rational Plane and Space Curves</title><categories>math.AG cs.SC</categories><comments>19 pages</comments><msc-class>14Q05</msc-class><journal-ref>Computer Aided Geometric Design, Volume 31, Issues 3-4, March-May
  2014, Pages 199-209, ISSN 0167-8396</journal-ref><doi>10.1016/j.cagd.2014.02.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of determining the symmetries of a plane or
space curve defined by a rational parametrization. We provide effective methods
to compute the involution and rotation symmetries for the planar case. As for
space curves, our method finds the involutions in all cases, and all the
rotation symmetries in the particular case of Pythagorean-hodograph curves. Our
algorithms solve these problems without converting to implicit form. Instead,
we make use of a relationship between two proper parametrizations of the same
curve, which leads to algorithms that involve only univariate polynomials.
These algorithms have been implemented and tested in the Sage system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4074</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4074</id><created>2012-07-17</created><authors><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>An analytical comparison of coalescent-based multilocus methods: The
  three-taxon case</title><categories>math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Incomplete lineage sorting (ILS) is a common source of gene tree incongruence
in multilocus analyses. A large number of methods have been developed to infer
species trees in the presence of ILS. Here we provide a mathematical analysis
of several coalescent-based methods. Our analysis is performed on a three-taxon
species tree and assumes that the gene trees are correctly reconstructed along
with their branch lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4079</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4079</id><created>2012-07-17</created><authors><author><keyname>Chitnis</keyname><forenames>Rajesh</forenames></author><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Designing FPT algorithms for cut problems using randomized contractions</title><categories>cs.DS</categories><comments>59 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new technique for designing fixed-parameter algorithms for cut
problems, namely randomized contractions. We apply our framework to obtain the
first FPT algorithm for the Unique Label Cover problem and new FPT algorithms
with exponential speed up for the Steiner Cut and Node Multiway Cut-Uncut
problems. More precisely, we show the following:
  - We prove that the parameterized version of the Unique Label Cover problem,
which is the base of the Unique Games Conjecture, can be solved in 2^{O(k^2\log
|\Sigma|)}n^4\log n deterministic time (even in the stronger, vertex-deletion
variant) where k is the number of unsatisfied edges and |\Sigma| is the size of
the alphabet. As a consequence, we show that one can in polynomial time solve
instances of Unique Games where the number of edges allowed not to be satisfied
is upper bounded by O(\sqrt{\log n}) to optimality, which improves over the
trivial O(1) upper bound.
  - We prove that the Steiner Cut problem can be solved in 2^{O(k^2\log
k)}n^4\log n deterministic time and \tilde{O}(2^{O(k^2\log k)}n^2) randomized
time where k is the size of the cutset. This result improves the double
exponential running time of the recent work of Kawarabayashi and Thorup
(FOCS'11).
  - We show how to combine considering `cut' and `uncut' constraints at the
same time. More precisely, we define a robust problem Node Multiway Cut-Uncut
that can serve as an abstraction of introducing uncut constraints, and show
that it admits an algorithm running in 2^{O(k^2\log k)}n^4\log n deterministic
time where k is the size of the cutset. To the best of our knowledge, the only
known way of tackling uncut constraints was via the approach of Marx,
O'Sullivan and Razgon (STACS'10), which yields algorithms with double
exponential running time.
  An interesting aspect of our technique is that, unlike important separators,
it can handle real weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4082</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4082</id><created>2012-07-17</created><authors><author><keyname>Govindarajan</keyname><forenames>Sathish</forenames></author><author><keyname>Khopkar</keyname><forenames>Abhijeet</forenames></author></authors><title>On Locally Gabriel Geometric Graphs</title><categories>cs.CG cs.DM</categories><comments>16 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of $n$ points in the plane. A geometric graph $G$ on $P$ is
said to be {\it locally Gabriel} if for every edge $(u,v)$ in $G$, the disk
with $u$ and $v$ as diameter does not contain any points of $P$ that are
neighbors of $u$ or $v$ in $G$. A locally Gabriel graph is a generalization of
Gabriel graph and is motivated by applications in wireless networks. Unlike a
Gabriel graph, there is no unique locally Gabriel graph on a given point set
since no edge in a locally Gabriel graph is necessarily included or excluded.
Thus the edge set of the graph can be customized to optimize certain network
parameters depending on the application. In this paper, we show the following
combinatorial bounds on edge complexity and independent sets of locally Gabriel
graphs:
  (i) For any $n$, there exists locally Gabriel graphs with $\Omega(n^{5/4})$
edges. This improves upon the previous best bound of $\Omega(n^{1+\frac{1}{\log
\log n}})$.
  (ii) For various subclasses of convex point sets, we show tight linear bounds
on the maximum edge complexity of locally Gabriel graphs.
  (iii) For any locally Gabriel graph on any $n$ point set, there exists an
independent set of size $\Omega(\sqrt{n}\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4083</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4083</id><created>2012-07-17</created><updated>2012-09-10</updated><authors><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author><author><keyname>Torrieri</keyname><forenames>Don</forenames></author><author><keyname>Talarico</keyname><forenames>Salvatore</forenames></author></authors><title>Optimization of a Finite Frequency-Hopping Ad Hoc Network in Nakagami
  Fading</title><categories>cs.IT math.IT</categories><comments>to appear at Milcom-2012. arXiv admin note: text overlap with
  arXiv:1207.3451</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the analysis and optimization of a frequency-hopping ad
hoc network with a finite number of mobiles and finite spatial extent. The
mobiles communicate using coded continuous-phase frequency-shift keying (CPFSK)
modulation. The performance of the system is a function of the number of
hopping channels, the rate of the error-correction code, and the modulation
index used by the CPFSK modulation. For a given channel model and density of
mobiles, these parameters are jointly optimized by maximizing the
(modulation-constrained) transmission capacity, which is a measure of the
spatial spectral efficiency of the system. The transmission capacity of the
finite network is found by using a recent expression for the spatially averaged
outage probability in the presence of Nakagami fading, which is found in closed
form in the absence of shadowing and can be solved using numerical integration
in the presence of shadowing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4084</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4084</id><created>2012-07-17</created><updated>2015-12-10</updated><authors><author><keyname>Kearns</keyname><forenames>Michael</forenames></author><author><keyname>Pai</keyname><forenames>Mallesh M.</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Ullman</keyname><forenames>Jonathan</forenames></author></authors><title>Mechanism Design in Large Games: Incentives and Privacy</title><categories>cs.GT cs.CR cs.DS</categories><comments>Conference version appeared in ITCS 2014. This paper has been merged
  and subsumed by the preprint &quot;Robust Mediators in Large Games&quot;:
  http://arxiv.org/abs/1512.02698</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of implementing equilibria of complete information games
in settings of incomplete information, and address this problem using
&quot;recommender mechanisms.&quot; A recommender mechanism is one that does not have the
power to enforce outcomes or to force participation, rather it only has the
power to suggestion outcomes on the basis of voluntary participation. We show
that despite these restrictions, recommender mechanisms can implement
equilibria of complete information games in settings of incomplete information
under the condition that the game is large---i.e. that there are a large number
of players, and any player's action affects any other's payoff by at most a
small amount.
  Our result follows from a novel application of differential privacy. We show
that any algorithm that computes a correlated equilibrium of a complete
information game while satisfying a variant of differential privacy---which we
call joint differential privacy---can be used as a recommender mechanism while
satisfying our desired incentive properties. Our main technical result is an
algorithm for computing a correlated equilibrium of a large game while
satisfying joint differential privacy.
  Although our recommender mechanisms are designed to satisfy game-theoretic
properties, our solution ends up satisfying a strong privacy property as well.
No group of players can learn &quot;much&quot; about the type of any player outside the
group from the recommendations of the mechanism, even if these players collude
in an arbitrary way. As such, our algorithm is able to implement equilibria of
complete information games, without revealing information about the realized
types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4089</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4089</id><created>2012-07-17</created><authors><author><keyname>Gangeh</keyname><forenames>Mehrdad J.</forenames></author><author><keyname>Duin</keyname><forenames>Robert P. W.</forenames></author><author><keyname>Romeny</keyname><forenames>Bart M. ter Haar</forenames></author><author><keyname>Kamel</keyname><forenames>Mohamed S.</forenames></author></authors><title>A Two-Stage Combined Classifier in Scale Space Texture Classification</title><categories>cs.CV cs.LG</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Textures often show multiscale properties and hence multiscale techniques are
considered useful for texture analysis. Scale-space theory as a biologically
motivated approach may be used to construct multiscale textures. In this paper
various ways are studied to combine features on different scales for texture
classification of small image patches. We use the N-jet of derivatives up to
the second order at different scales to generate distinct pattern
representations (DPR) of feature subsets. Each feature subset in the DPR is
given to a base classifier (BC) of a two-stage combined classifier. The
decisions made by these BCs are combined in two stages over scales and
derivatives. Various combining systems and their significances and differences
are discussed. The learning curves are used to evaluate the performances. We
found for small sample sizes combining classifiers performs significantly
better than combining feature spaces (CFS). It is also shown that combining
classifiers performs better than the support vector machine on CFS in
multiscale texture classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4096</identifier>
 <datestamp>2013-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4096</id><created>2012-07-17</created><updated>2013-01-09</updated><authors><author><keyname>Chatzivasileiadis</keyname><forenames>Spyros</forenames></author><author><keyname>Ernst</keyname><forenames>Damien</forenames></author><author><keyname>Andersson</keyname><forenames>G&#xf6;ran</forenames></author></authors><title>The Global Grid</title><categories>cs.SY physics.soc-ph</categories><comments>Manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper puts forward the vision that a natural future stage of the
electricity network could be a grid spanning the whole planet and connecting
most of the large power plants in the world: this is the &quot;Global Grid&quot;. The
main driving force behind the Global Grid will be the harvesting of remote
renewable sources, and its key infrastructure element will be the high capacity
long transmission lines. Wind farms and solar power plants will supply load
centers with green power over long distances.
  This paper focuses on the introduction of the concept, showing that a
globally interconnected network can be technologically feasible and
economically competitive. We further highlight the multiple opportunities
emerging from a global electricity network such as smoothing the renewable
energy supply and electricity demand, reducing the need for bulk storage, and
reducing the volatility of the energy prices. We also discuss possible
investment mechanisms and operating schemes. Among others, we envision in such
a system a global power market and the establishment of two new coordinating
bodies, the &quot;Global Regulator&quot; and the &quot;Global System Operator&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4098</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4098</id><created>2012-07-17</created><authors><author><keyname>Alimguzhin</keyname><forenames>Vadim</forenames></author><author><keyname>Mari</keyname><forenames>Federico</forenames></author><author><keyname>Melatti</keyname><forenames>Igor</forenames></author><author><keyname>Salvo</keyname><forenames>Ivano</forenames></author><author><keyname>Tronci</keyname><forenames>Enrico</forenames></author></authors><title>Automatic Control Software Synthesis for Quantized Discrete Time Hybrid
  Systems</title><categories>cs.SY cs.SE</categories><comments>Accepted for publication by CDC 2012. arXiv admin note: substantial
  text overlap with arXiv:1107.5638</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many Embedded Systems are indeed Software Based Control Systems, that is
control systems whose controller consists of control software running on a
microcontroller device. This motivates investigation on Formal Model Based
Design approaches for automatic synthesis of embedded systems control software.
This paper addresses control software synthesis for discrete time nonlinear
systems. We present a methodology to overapproximate the dynamics of a discrete
time nonlinear hybrid system H by means of a discrete time linear hybrid system
L(H), in such a way that controllers for L(H) are guaranteed to be controllers
for H. We present experimental results on the inverted pendulum, a challenging
and meaningful benchmark in nonlinear Hybrid Systems control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4104</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4104</id><created>2012-07-17</created><updated>2013-05-27</updated><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Bai</keyname><forenames>Erwei</forenames></author><author><keyname>Cho</keyname><forenames>Myung</forenames></author></authors><title>Outliers and Random Noises in System Identification: a Compressed
  Sensing Approach</title><categories>cs.IT math.IT</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider robust system identification under sparse outliers
and random noises. In this problem, system parameters are observed through a
Toeplitz matrix. All observations are subject to random noises and a few are
corrupted with outliers. We reduce this problem of system identification to a
sparse error correcting problem using a Toeplitz structured real-numbered
coding matrix. We prove the performance guarantee of Toeplitz structured matrix
in sparse error correction. Thresholds on the percentage of correctable errors
for Toeplitz structured matrices are established. When both outliers and
observation noise are present, we have shown that the estimation error goes to
0 asymptotically as long as the probability density function for observation
noise is not &quot;vanishing&quot; around 0. No probabilistic assumptions are imposed on
the outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4107</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4107</id><created>2012-07-11</created><authors><author><keyname>Gretton</keyname><forenames>Charles</forenames></author><author><keyname>Thiebaux</keyname><forenames>Sylvie</forenames></author></authors><title>Exploiting First-Order Regression in Inductive Policy Selection</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-217-225</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing optimal generalised policies for
relational Markov decision processes. We describe an approach combining some of
the benefits of purely inductive techniques with those of symbolic dynamic
programming methods. The latter reason about the optimal value function using
first-order decision theoretic regression and formula rewriting, while the
former, when provided with a suitable hypotheses language, are capable of
generalising value functions or policies for small instances. Our idea is to
use reasoning and in particular classical first-order regression to
automatically generate a hypotheses language dedicated to the domain at hand,
which is then used as input by an inductive solver. This approach avoids the
more complex reasoning of symbolic dynamic programming while focusing the
inductive solver's attention on concepts that are specifically relevant to the
optimal value function for the domain considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4108</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4108</id><created>2012-07-11</created><authors><author><keyname>Greenwald</keyname><forenames>Amy</forenames></author><author><keyname>Boyan</keyname><forenames>Justin</forenames></author></authors><title>Bidding under Uncertainty: Theory and Experiments</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-209-216</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a study of agent bidding strategies, assuming
combinatorial valuations for complementary and substitutable goods, in three
auction environments: sequential auctions, simultaneous auctions, and the
Trading Agent Competition (TAC) Classic hotel auction design, a hybrid of
sequential and simultaneous auctions. The problem of bidding in sequential
auctions is formulated as an MDP, and it is argued that expected marginal
utility bidding is the optimal bidding policy. The problem of bidding in
simultaneous auctions is formulated as a stochastic program, and it is shown by
example that marginal utility bidding is not an optimal bidding policy, even in
deterministic settings. Two alternative methods of approximating a solution to
this stochastic program are presented: the first method, which relies on
expected values, is optimal in deterministic environments; the second method,
which samples the nondeterministic environment, is asymptotically optimal as
the number of samples tends to infinity. Finally, experiments with these
various bidding policies are described in the TAC Classic setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4109</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4109</id><created>2012-07-11</created><authors><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>A Complete Anytime Algorithm for Treewidth</title><categories>cs.DS cs.AI cs.DM</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-201-208</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a Branch and Bound algorithm called QuickBB for
computing the treewidth of an undirected graph. This algorithm performs a
search in the space of perfect elimination ordering of vertices of the graph.
The algorithm uses novel pruning and propagation techniques which are derived
from the theory of graph minors and graph isomorphism. We present a new
algorithm called minor-min-width for computing a lower bound on treewidth that
is used within the branch and bound algorithm and which improves over earlier
available lower bounds. Empirical evaluation of QuickBB on randomly generated
graphs and benchmarks in Graph Coloring and Bayesian Networks shows that it is
consistently better than complete algorithms like QuickTree [Shoikhet and
Geiger, 1997] in terms of cpu time. QuickBB also has good anytime performance,
being able to generate a better upper bound on treewidth of some graphs whose
optimal treewidth could not be computed up to now.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4110</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4110</id><created>2012-07-11</created><authors><author><keyname>Globerson</keyname><forenames>Amir</forenames></author><author><keyname>Tishby</keyname><forenames>Naftali</forenames></author></authors><title>The Minimum Information Principle for Discriminative Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-193-200</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exponential models of distributions are widely used in machine learning for
classiffication and modelling. It is well known that they can be interpreted as
maximum entropy models under empirical expectation constraints. In this work,
we argue that for classiffication tasks, mutual information is a more suitable
information theoretic measure to be optimized. We show how the principle of
minimum mutual information generalizes that of maximum entropy, and provides a
comprehensive framework for building discriminative classiffiers. A game
theoretic interpretation of our approach is then given, and several
generalization bounds provided. We present iterative algorithms for solving the
minimum information problem and its convex dual, and demonstrate their
performance on various classiffication tasks. The results show that minimum
information classiffiers outperform the corresponding maximum entropy models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4111</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4111</id><created>2012-07-11</created><updated>2012-07-31</updated><authors><author><keyname>Giang</keyname><forenames>Phan H.</forenames></author><author><keyname>Sandilya</keyname><forenames>Sathyakama</forenames></author></authors><title>Decision Making for Symbolic Probability</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>Martijn de Jongh</proxy><report-no>UAI-P-2004-PG-185-192</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a decision theory for a symbolic generalization of
probability theory (SP). Darwiche and Ginsberg [2,3] proposed SP to relax the
requirement of using numbers for uncertainty while preserving desirable
patterns of Bayesian reasoning. SP represents uncertainty by symbolic supports
that are ordered partially rather than completely as in the case of standard
probability. We show that a preference relation on acts that satisfies a number
of intuitive postulates is represented by a utility function whose domain is a
set of pairs of supports. We argue that a subjective interpretation is as
useful and appropriate for SP as it is for numerical probability. It is useful
because the subjective interpretation provides a basis for uncertainty
elicitation. It is appropriate because we can provide a decision theory that
explains how preference on acts is based on support comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4112</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4112</id><created>2012-07-11</created><authors><author><keyname>Garcia</keyname><forenames>Luis David</forenames></author></authors><title>Algebraic Statistics in Model Selection</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-177-184</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop the necessary theory in computational algebraic geometry to place
Bayesian networks into the realm of algebraic statistics. We present an
algebra{statistics dictionary focused on statistical modeling. In particular,
we link the notion of effiective dimension of a Bayesian network with the
notion of algebraic dimension of a variety. We also obtain the independence and
non{independence constraints on the distributions over the observable variables
implied by a Bayesian network with hidden variables, via a generating set of an
ideal of polynomials associated to the network. These results extend previous
work on the subject. Finally, the relevance of these results for model
selection is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4113</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4113</id><created>2012-07-11</created><authors><author><keyname>Gammerman</keyname><forenames>Alex</forenames></author><author><keyname>Kalnishkan</keyname><forenames>Yuri</forenames></author><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>On-line Prediction with Kernels and the Complexity Approximation
  Principle</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-170-176</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes an application of Aggregating Algorithm to the problem of
regression. It generalizes earlier results concerned with plain linear
regression to kernel techniques and presents an on-line algorithm which
performs nearly as well as any oblivious kernel predictor. The paper contains
the derivation of an estimate on the performance of this algorithm. The
estimate is then used to derive an application of the Complexity Approximation
Principle to kernel methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4114</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4114</id><created>2012-07-11</created><authors><author><keyname>Ferns</keyname><forenames>Norman</forenames></author><author><keyname>Panangaden</keyname><forenames>Prakash</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>Metrics for Finite Markov Decision Processes</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-162-169</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present metrics for measuring the similarity of states in a finite Markov
decision process (MDP). The formulation of our metrics is based on the notion
of bisimulation for MDPs, with an aim towards solving discounted infinite
horizon reinforcement learning tasks. Such metrics can be used to aggregate
states, as well as to better structure other value function approximators
(e.g., memory-based or nearest-neighbor approximators). We provide bounds that
relate our metric distances to the optimal values of states in the given MDP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4115</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4115</id><created>2012-07-11</created><authors><author><keyname>Feng</keyname><forenames>Zhengzhu</forenames></author><author><keyname>Dearden</keyname><forenames>Richard</forenames></author><author><keyname>Meuleau</keyname><forenames>Nicolas</forenames></author><author><keyname>Washington</keyname><forenames>Richard</forenames></author></authors><title>Dynamic Programming for Structured Continuous Markov Decision Problems</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-154-161</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an approach for exploiting structure in Markov Decision Processes
with continuous state variables. At each step of the dynamic programming, the
state space is dynamically partitioned into regions where the value function is
the same throughout the region. We first describe the algorithm for piecewise
constant representations. We then extend it to piecewise linear
representations, using techniques from POMDPs to represent and reason about
linear surfaces efficiently. We show that for complex, structured problems, our
approach exploits the natural structure so that optimal solutions can be
computed efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4116</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4116</id><created>2012-07-11</created><authors><author><keyname>Feng</keyname><forenames>Zhengzhu</forenames></author><author><keyname>Zilberstein</keyname><forenames>Shlomo</forenames></author></authors><title>Region-Based Incremental Pruning for POMDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-146-153</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a major improvement to the incremental pruning algorithm for
solving partially observable Markov decision processes. Our technique targets
the cross-sum step of the dynamic programming (DP) update, a key source of
complexity in POMDP algorithms. Instead of reasoning about the whole belief
space when pruning the cross-sums, our algorithm divides the belief space into
smaller regions and performs independent pruning in each region. We evaluate
the benefits of the new technique both analytically and experimentally, and
show that it produces very significant performance gains. The results
contribute to the scalability of POMDP algorithms to domains that cannot be
handled by the best existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4117</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4117</id><created>2012-07-11</created><updated>2012-08-06</updated><authors><author><keyname>Dubois</keyname><forenames>Didier</forenames></author><author><keyname>Fargier</keyname><forenames>Helene</forenames></author></authors><title>A Unified framework for order-of-magnitude confidence relations</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>Martijn de Jongh</proxy><report-no>UAI-P-2004-PG-138-145</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this work is to provide a unified framework for ordinal
representations of uncertainty lying at the crosswords between possibility and
probability theories. Such confidence relations between events are commonly
found in monotonic reasoning, inconsistency management, or qualitative decision
theory. They start either from probability theory, making it more qualitative,
or from possibility theory, making it more expressive. We show these two trends
converge to a class of genuine probability theories. We provide
characterization results for these useful tools that preserve the qualitative
nature of possibility rankings, while enjoying the power of expressivity of
additive representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4118</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4118</id><created>2012-07-11</created><authors><author><keyname>Drton</keyname><forenames>Mathias</forenames></author><author><keyname>Richardson</keyname><forenames>Thomas S.</forenames></author></authors><title>Iterative Conditional Fitting for Gaussian Ancestral Graph Models</title><categories>stat.ME cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-130-137</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ancestral graph models, introduced by Richardson and Spirtes (2002),
generalize both Markov random fields and Bayesian networks to a class of graphs
with a global Markov property that is closed under conditioning and
marginalization. By design, ancestral graphs encode precisely the conditional
independence structures that can arise from Bayesian networks with selection
and unobserved (hidden/latent) variables. Thus, ancestral graph models provide
a potentially very useful framework for exploratory model selection when
unobserved variables might be involved in the data-generating process but no
particular hidden structure can be specified. In this paper, we present the
Iterative Conditional Fitting (ICF) algorithm for maximum likelihood estimation
in Gaussian ancestral graph models. The name reflects that in each step of the
procedure a conditional distribution is estimated, subject to constraints,
while a marginal distribution is held fixed. This approach is in duality to the
well-known Iterative Proportional Fitting algorithm, in which marginal
distributions are fitted while conditional distributions are held fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4119</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4119</id><created>2012-07-11</created><authors><author><keyname>Dechter</keyname><forenames>Rina</forenames></author><author><keyname>Mateescu</keyname><forenames>Robert</forenames></author></authors><title>Mixtures of Deterministic-Probabilistic Networks and their AND/OR Search
  Space</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-120-129</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces mixed networks, a new framework for expressing and
reasoning with probabilistic and deterministic information. The framework
combines belief networks with constraint networks, defining the semantics and
graphical representation. We also introduce the AND/OR search space for
graphical models, and develop a new linear space search algorithm. This
provides the basis for understanding the benefits of processing the constraint
information separately, resulting in the pruning of the search space. When the
constraint part is tractable or has a small number of solutions, using the
mixed representation can be exponentially more effective than using pure belief
networks which odel constraints as conditional probability tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4120</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4120</id><created>2012-07-11</created><authors><author><keyname>de Waal</keyname><forenames>Peter</forenames></author><author><keyname>van der Gaag</keyname><forenames>Linda C.</forenames></author></authors><title>Stable Independance and Complexity of Representation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-112-119</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The representation of independence relations generally builds upon the
well-known semigraphoid axioms of independence. Recently, a representation has
been proposed that captures a set of dominant statements of an independence
relation from which any other statement can be generated by means of the
axioms; the cardinality of this set is taken to indicate the complexity of the
relation. Building upon the idea of dominance, we introduce the concept of
stability to provide for a more compact representation of independence. We give
an associated algorithm for establishing such a representation.We show that,
with our concept of stability, many independence relations are found to be of
lower complexity than with existing representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4121</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4121</id><created>2012-07-11</created><authors><author><keyname>Cozman</keyname><forenames>Fabio Gagliardi</forenames></author><author><keyname>de Campos</keyname><forenames>Cassio Polpo</forenames></author><author><keyname>Ide</keyname><forenames>Jaime</forenames></author><author><keyname>da Rocha</keyname><forenames>Jose Carlos Ferreira</forenames></author></authors><title>Propositional and Relational Bayesian Networks Associated with Imprecise
  and Qualitative Probabilistic Assesments</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-104-111</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a representation language with flexibility inspired
by probabilistic logic and compactness inspired by relational Bayesian
networks. The goal is to handle propositional and first-order constructs
together with precise, imprecise, indeterminate and qualitative probabilistic
assessments. The paper shows how this can be achieved through the theory of
credal networks. New exact and approximate inference algorithms based on
multilinear programming and iterated/loopy propagation of interval
probabilities are presented; their superior performance, compared to existing
ones, is shown empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4122</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4122</id><created>2012-07-11</created><authors><author><keyname>Cooper</keyname><forenames>Gregory F.</forenames></author><author><keyname>Dash</keyname><forenames>Denver</forenames></author><author><keyname>Levander</keyname><forenames>John</forenames></author><author><keyname>Wong</keyname><forenames>Weng-Keen</forenames></author><author><keyname>Hogan</keyname><forenames>William</forenames></author><author><keyname>Wagner</keyname><forenames>Michael</forenames></author></authors><title>Bayesian Biosurveillance of Disease Outbreaks</title><categories>stat.AP cs.AI cs.CE</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-94-103</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early, reliable detection of disease outbreaks is a critical problem today.
This paper reports an investigation of the use of causal Bayesian networks to
model spatio-temporal patterns of a non-contagious disease (respiratory anthrax
infection) in a population of people. The number of parameters in such a
network can become enormous, if not carefully managed. Also, inference needs to
be performed in real time as population data stream in. We describe techniques
we have applied to address both the modeling and inference challenges. A key
contribution of this paper is the explication of assumptions and techniques
that are sufficient to allow the scaling of Bayesian network modeling and
inference to millions of nodes for real-time surveillance applications. The
results reported here provide a proof-of-concept that Bayesian networks can
serve as the foundation of a system that effectively performs Bayesian
biosurveillance of disease outbreaks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4123</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4123</id><created>2012-07-11</created><authors><author><keyname>Chesnevar</keyname><forenames>Carlos</forenames></author><author><keyname>Simari</keyname><forenames>Guillermo</forenames></author><author><keyname>Alsinet</keyname><forenames>Teresa</forenames></author><author><keyname>Godo</keyname><forenames>Lluis</forenames></author></authors><title>A Logic Programming Framework for Possibilistic Argumentation with Vague
  Knowledge</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-76-84</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Defeasible argumentation frameworks have evolved to become a sound setting to
formalize commonsense, qualitative reasoning from incomplete and potentially
inconsistent knowledge. Defeasible Logic Programming (DeLP) is a defeasible
argumentation formalism based on an extension of logic programming. Although
DeLP has been successfully integrated in a number of different real-world
applications, DeLP cannot deal with explicit uncertainty, nor with vague
knowledge, as defeasibility is directly encoded in the object language. This
paper introduces P-DeLP, a new logic programming language that extends original
DeLP capabilities for qualitative reasoning by incorporating the treatment of
possibilistic uncertainty and fuzzy knowledge. Such features will be formalized
on the basis of PGL, a possibilistic logic based on Godel fuzzy logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4124</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4124</id><created>2012-07-11</created><authors><author><keyname>Chan</keyname><forenames>Hei</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>Sensitivity Analysis in Bayesian Networks: From Single to Multiple
  Parameters</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-67-75</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work on sensitivity analysis in Bayesian networks has focused on
single parameters, where the goal is to understand the sensitivity of queries
to single parameter changes, and to identify single parameter changes that
would enforce a certain query constraint. In this paper, we expand the work to
multiple parameters which may be in the CPT of a single variable, or the CPTs
of multiple variables. Not only do we identify the solution space of multiple
parameter changes that would be needed to enforce a query constraint, but we
also show how to find the optimal solution, that is, the one which disturbs the
current probability distribution the least (with respect to a specific measure
of disturbance). We characterize the computational complexity of our new
techniques and discuss their applications to developing and debugging Bayesian
networks, and to the problem of reasoning about the value (reliability) of new
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4125</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4125</id><created>2012-07-11</created><authors><author><keyname>Buntine</keyname><forenames>Wray L.</forenames></author><author><keyname>Jakulin</keyname><forenames>Aleks</forenames></author></authors><title>Applying Discrete PCA in Data Analysis</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-59-66</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods for analysis of principal components in discrete data have existed
for some time under various names such as grade of membership modelling,
probabilistic latent semantic analysis, and genotype inference with admixture.
In this paper we explore a number of extensions to the common theory, and
present some application of these methods to some common statistical tasks. We
show that these methods can be interpreted as a discrete version of ICA. We
develop a hierarchical version yielding components at different levels of
detail, and additional techniques for Gibbs sampling. We compare the algorithms
on a text prediction task using support vector machines, and to information
retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4126</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4126</id><created>2012-07-11</created><authors><author><keyname>Brafman</keyname><forenames>Ronen I.</forenames></author><author><keyname>Domshlak</keyname><forenames>Carmel</forenames></author><author><keyname>Kogan</keyname><forenames>Tanya</forenames></author></authors><title>Compact Value-Function Representations for Qualitative Preferences</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-51-59</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the challenge of preference elicitation in systems that help
users discover the most desirable item(s) within a given database. Past work on
preference elicitation focused on structured models that provide a factored
representation of users' preferences. Such models require less information to
construct and support efficient reasoning algorithms. This paper makes two
substantial contributions to this area: (1) Strong representation theorems for
factored value functions. (2) A methodology that utilizes our representation
results to address the problem of optimal item selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4127</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4127</id><created>2012-07-11</created><authors><author><keyname>Bidyuk</keyname><forenames>Bozhena</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>On finding minimal w-cutset</title><categories>cs.DS cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-43-50</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of a reasoning task over a graphical model is tied to the
induced width of the underlying graph. It is well-known that the conditioning
(assigning values) on a subset of variables yields a subproblem of the reduced
complexity where instantiated variables are removed. If the assigned variables
constitute a cycle-cutset, the rest of the network is singly-connected and
therefore can be solved by linear propagation algorithms. A w-cutset is a
generalization of a cycle-cutset defined as a subset of nodes such that the
subgraph with cutset nodes removed has induced-width of w or less. In this
paper we address the problem of finding a minimal w-cutset in a graph. We
relate the problem to that of finding the minimal w-cutset of a
treedecomposition. The latter can be mapped to the well-known set multi-cover
problem. This relationship yields a proof of NP-completeness on one hand and a
greedy algorithm for finding a w-cutset of a tree decomposition on the other.
Empirical evaluation of the algorithms is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4128</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4128</id><created>2012-07-11</created><authors><author><keyname>Bhat</keyname><forenames>Navin</forenames></author><author><keyname>Leyton-Brown</keyname><forenames>Kevin</forenames></author></authors><title>Computing Nash Equilibria of Action-Graph Games</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-35-42</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Action-graph games (AGGs) are a fully expressive game representation which
can compactly express both strict and context-specific independence between
players' utility functions. Actions are represented as nodes in a graph G, and
the payoff to an agent who chose the action s depends only on the numbers of
other agents who chose actions connected to s. We present algorithms for
computing both symmetric and arbitrary equilibria of AGGs using a continuation
method. We analyze the worst-case cost of computing the Jacobian of the payoff
function, the exponential-time bottleneck step, and in all cases achieve
exponential speedup. When the indegree of G is bounded by a constant and the
game is symmetric, the Jacobian can be computed in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4129</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4129</id><created>2012-07-11</created><authors><author><keyname>Anguelov</keyname><forenames>Dragomir</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author><author><keyname>Pang</keyname><forenames>Hoi-Cheung</forenames></author><author><keyname>Srinivasan</keyname><forenames>Praveen</forenames></author><author><keyname>Thrun</keyname><forenames>Sebastian</forenames></author></authors><title>Recovering Articulated Object Models from 3D Range Data</title><categories>cs.CV</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-18-26</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of unsupervised learning of complex articulated object
models from 3D range data. We describe an algorithm whose input is a set of
meshes corresponding to different configurations of an articulated object. The
algorithm automatically recovers a decomposition of the object into
approximately rigid parts, the location of the parts in the different object
instances, and the articulated object skeleton linking the parts. Our algorithm
first registers allthe meshes using an unsupervised non-rigid technique
described in a companion paper. It then segments the meshes using a graphical
model that captures the spatial contiguity of parts. The segmentation is done
using the EM algorithm, iterating between finding a decomposition of the object
into rigid parts, and finding the location of the parts in the object
instances. Although the graphical model is densely connected, the object
decomposition step can be performed optimally and efficiently, allowing us to
identify a large number of object parts while avoiding local maxima. We
demonstrate the algorithm on real world datasets, recovering a 15-part
articulated model of a human puppet from just 7 different puppet
configurations, as well as a 4 part model of a fiexing arm where significant
non-rigid deformation was present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4130</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4130</id><created>2012-07-11</created><authors><author><keyname>Amgoud</keyname><forenames>Leila</forenames></author><author><keyname>Prade</keyname><forenames>Henri</forenames></author></authors><title>Using arguments for making decisions: A possibilistic logic approach</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-10-17</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans currently use arguments for explaining choices which are already made,
or for evaluating potential choices. Each potential choice has usually pros and
cons of various strengths. In spite of the usefulness of arguments in a
decision making process, there have been few formal proposals handling this
idea if we except works by Fox and Parsons and by Bonet and Geffner. In this
paper we propose a possibilistic logic framework where arguments are built from
an uncertain knowledge base and a set of prioritized goals. The proposed
approach can compute two kinds of decisions by distinguishing between
pessimistic and optimistic attitudes. When the available, maybe uncertain,
knowledge is consistent, as well as the set of prioritized goals (which have to
be fulfilled as far as possible), the method for evaluating decisions on the
basis of arguments agrees with the possibility theory-based approach to
decision-making under uncertainty. Taking advantage of its relation with formal
approaches to defeasible argumentation, the proposed framework can be
generalized in case of partially inconsistent knowledge, or goal bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4131</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4131</id><created>2012-07-11</created><authors><author><keyname>Altun</keyname><forenames>Yasemin</forenames></author><author><keyname>Smola</keyname><forenames>Alex</forenames></author><author><keyname>Hofmann</keyname><forenames>Thomas</forenames></author></authors><title>Exponential Families for Conditional Random Fields</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-2-9</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we de ne conditional random elds in reproducing kernel Hilbert
spaces and show connections to Gaussian Process classi cation. More speci
cally, we prove decomposition results for undirected graphical models and we
give constructions for kernels. Finally we present e cient means of solving the
optimization problem using reduced rank decompositions and we show how
stationarity can be exploited e ciently in the optimization process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4132</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4132</id><created>2012-07-11</created><authors><author><keyname>Nielsen</keyname><forenames>Rodney</forenames></author></authors><title>MOB-ESP and other Improvements in Probability Estimation</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-418-425</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key prerequisite to optimal reasoning under uncertainty in intelligent
systems is to start with good class probability estimates. This paper improves
on the current best probability estimation trees (Bagged-PETs) and also
presents a new ensemble-based algorithm (MOB-ESP). Comparisons are made using
several benchmark datasets and multiple metrics. These experiments show that
MOB-ESP outputs significantly more accurate class probabilities than either the
baseline BPETs algorithm or the enhanced version presented here (EB-PETs).
These results are based on metrics closely associated with the average accuracy
of the predictions. MOB-ESP also provides much better probability rankings than
B-PETs. The paper further suggests how these estimation techniques can be
applied in concert with a broader category of classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4133</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4133</id><created>2012-07-11</created><authors><author><keyname>Nachman</keyname><forenames>Iftach</forenames></author><author><keyname>Elidan</keyname><forenames>Gal</forenames></author><author><keyname>Friedman</keyname><forenames>Nir</forenames></author></authors><title>&quot;Ideal Parent&quot; Structure Learning for Continuous Variable Networks</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-400-409</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there is a growing interest in learning Bayesian networks
with continuous variables. Learning the structure of such networks is a
computationally expensive procedure, which limits most applications to
parameter learning. This problem is even more acute when learning networks with
hidden variables. We present a general method for significantly speeding the
structure search algorithm for continuous variable networks with common
parametric distributions. Importantly, our method facilitates the addition of
new hidden variables into the network structure efficiently. We demonstrate the
method on several data sets, both for learning structure on fully observable
data, and for introducing new hidden variables during structure search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4134</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4134</id><created>2012-07-11</created><authors><author><keyname>Murray</keyname><forenames>Iain</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Bayesian Learning in Undirected Graphical Models: Approximate MCMC
  algorithms</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-392-399</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian learning in undirected graphical models|computing posterior
distributions over parameters and predictive quantities is exceptionally
difficult. We conjecture that for general undirected models, there are no
tractable MCMC (Markov Chain Monte Carlo) schemes giving the correct
equilibrium distribution over parameters. While this intractability, due to the
partition function, is familiar to those performing parameter optimisation,
Bayesian learning of posterior distributions over undirected model parameters
has been unexplored and poses novel challenges. we propose several approximate
MCMC schemes and test on fully observed binary models (Boltzmann machines) for
a small coronary heart disease data set and larger artificial systems. While
approximations must perform well on the model, their interaction with the
sampling scheme is also important. Samplers based on variational mean- field
approximations generally performed poorly, more advanced methods using loopy
propagation, brief sampling and stochastic dynamics lead to acceptable
parameter posteriors. Finally, we demonstrate these techniques on a Markov
random field with hidden variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4135</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4135</id><created>2012-07-11</created><authors><author><keyname>McAllester</keyname><forenames>David A.</forenames></author><author><keyname>Collins</keyname><forenames>Michael</forenames></author><author><keyname>Pereira</keyname><forenames>Fernando</forenames></author></authors><title>Case-Factor Diagrams for Structured Probabilistic Modeling</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-382-391</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a probabilistic formalism subsuming Markov random fields of
bounded tree width and probabilistic context free grammars. Our models are
based on a representation of Boolean formulas that we call case-factor diagrams
(CFDs). CFDs are similar to binary decision diagrams (BDDs) but are concise for
circuits of bounded tree width (unlike BDDs) and can concisely represent the
set of parse trees over a given string undera given context free grammar (also
unlike BDDs). A probabilistic model consists of aCFD defining a feasible set of
Boolean assignments and a weight (or cost) for each individual Boolean
variable. We give an insideoutside algorithm for simultaneously computing the
marginal of each Boolean variable, and a Viterbi algorithm for finding the
mininum cost variable assignment. Both algorithms run in time proportional to
the size of the CFD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4136</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4136</id><created>2012-07-11</created><authors><author><keyname>Mao</keyname><forenames>Yongyi</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank</forenames></author><author><keyname>Frey</keyname><forenames>Brendan J.</forenames></author></authors><title>Convolutional Factor Graphs as Probabilistic Models</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-374-381</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on a recent development in the area of error control coding, we
introduce the notion of convolutional factor graphs (CFGs) as a new class of
probabilistic graphical models. In this context, the conventional factor graphs
are referred to as multiplicative factor graphs (MFGs). This paper shows that
CFGs are natural models for probability functions when summation of independent
latent random variables is involved. In particular, CFGs capture a large class
of linear models, where the linearity is in the sense that the observed
variables are obtained as a linear ransformation of the latent variables taking
arbitrary distributions. We use Gaussian models and independent factor models
as examples to emonstrate the use of CFGs. The requirement of a linear
transformation between latent variables (with certain independence restriction)
and the bserved variables, to an extent, limits the modelling flexibility of
CFGs. This structural restriction however provides a powerful analytic tool to
the framework of CFGs; that is, upon taking the Fourier transform of the
function represented by the CFG, the resulting function is represented by a FG
with identical structure. This Fourier transform duality allows inference
problems on a CFG to be solved on the corresponding dual MFG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4137</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4137</id><created>2012-07-11</created><authors><author><keyname>Madsen</keyname><forenames>Anders L.</forenames></author></authors><title>An Empirical Evaluation of Possible Variations of Lazy Propagation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-366-373</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As real-world Bayesian networks continue to grow larger and more complex, it
is important to investigate the possibilities for improving the performance of
existing algorithms of probabilistic inference. Motivated by examples, we
investigate the dependency of the performance of Lazy propagation on the
message computation algorithm. We show how Symbolic Probabilistic Inference
(SPI) and Arc-Reversal (AR) can be used for computation of clique to clique
messages in the addition to the traditional use of Variable Elimination (VE).
In addition, the paper resents the results of an empirical evaluation of the
performance of Lazy propagation using VE, SPI, and AR as the message
computation algorithm. The results of the empirical evaluation show that for
most networks, the performance of inference did not depend on the choice of
message computation algorithm, but for some randomly generated networks the
choice had an impact on both space and time performance. In the cases where the
choice had an impact, AR produced the best results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4138</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4138</id><created>2012-07-11</created><authors><author><keyname>Madani</keyname><forenames>Omid</forenames></author><author><keyname>Lizotte</keyname><forenames>Daniel J.</forenames></author><author><keyname>Greiner</keyname><forenames>Russell</forenames></author></authors><title>Active Model Selection</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-357-365</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical learning assumes the learner is given a labeled data sample, from
which it learns a model. The field of Active Learning deals with the situation
where the learner begins not with a training sample, but instead with resources
that it can use to obtain information to help identify the optimal model. To
better understand this task, this paper presents and analyses the simplified
&quot;(budgeted) active model selection&quot; version, which captures the pure
exploration aspect of many active learning problems in a clean and simple
problem formulation. Here the learner can use a fixed budget of &quot;model probes&quot;
(where each probe evaluates the specified model on a random indistinguishable
instance) to identify which of a given set of possible models has the highest
expected accuracy. Our goal is a policy that sequentially determines which
model to probe next, based on the information observed so far. We present a
formal description of this task, and show that it is NPhard in general. We then
investigate a number of algorithms for this task, including several existing
ones (eg, &quot;Round-Robin&quot;, &quot;Interval Estimation&quot;, &quot;Gittins&quot;) as well as some
novel ones (e.g., &quot;Biased-Robin&quot;), describing first their approximation
properties and then their empirical performance on various problem instances.
We observe empirically that the simple biased-robin algorithm significantly
outperforms the other algorithms in the case of identical costs and priors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4139</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4139</id><created>2012-07-11</created><authors><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author></authors><title>An Extended Cencov-Campbell Characterization of Conditional Information
  Geometry</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-341-348</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate and prove an axiomatic characterization of conditional
information geometry, for both the normalized and the nonnormalized cases. This
characterization extends the axiomatic derivation of the Fisher geometry by
Cencov and Campbell to the cone of positive conditional models, and as a
special case to the manifold of conditional distributions. Due to the close
connection between the conditional I-divergence and the product Fisher
information metric the characterization provides a new axiomatic interpretation
of the primal problems underlying logistic regression and AdaBoost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4140</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4140</id><created>2012-07-11</created><authors><author><keyname>Kuroki</keyname><forenames>Manabu</forenames></author><author><keyname>Cai</keyname><forenames>Zhihong</forenames></author></authors><title>Selection of Identifiability Criteria for Total Effects by using Path
  Diagrams</title><categories>stat.ME cs.AI stat.AP</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-333-340</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pearl has provided the back door criterion, the front door criterion and the
conditional instrumental variable (IV) method as identifiability criteria for
total effects. In some situations, these three criteria can be applied to
identifying total effects simultaneously. For the purpose of increasing
estimating accuracy, this paper compares the three ways of identifying total
effects in terms of the asymptotic variance, and concludes that in some
situations the superior of them can be recognized directly from the graph
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4141</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4141</id><created>2012-07-11</created><authors><author><keyname>Kuncheva</keyname><forenames>Ludmila</forenames></author><author><keyname>Whitaker</keyname><forenames>C.</forenames></author><author><keyname>Cockcroft</keyname><forenames>P.</forenames></author><author><keyname>Hoare</keyname><forenames>Z. S.</forenames></author></authors><title>Pre-Selection of Independent Binary Features: An Application to
  Diagnosing Scrapie in Sheep</title><categories>cs.AI cs.CE</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-325-332</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that the only available information in a multi-class problem are
expert estimates of the conditional probabilities of occurrence for a set of
binary features. The aim is to select a subset of features to be measured in
subsequent data collection experiments. In the lack of any information about
the dependencies between the features, we assume that all features are
conditionally independent and hence choose the Naive Bayes classifier as the
optimal classifier for the problem. Even in this (seemingly trivial) case of
complete knowledge of the distributions, choosing an optimal feature subset is
not straightforward. We discuss the properties and implementation details of
Sequential Forward Selection (SFS) as a feature selection procedure for the
current problem. A sensitivity analysis was carried out to investigate whether
the same features are selected when the probabilities vary around the estimated
values. The procedure is illustrated with a set of probability estimates for
Scrapie in sheep.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4142</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4142</id><created>2012-07-11</created><authors><author><keyname>Kirshner</keyname><forenames>Sergey</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author><author><keyname>Robertson</keyname><forenames>Andrew</forenames></author></authors><title>Conditional Chow-Liu Tree Structures for Modeling Discrete-Valued Vector
  Time Series</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-317-324</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of modeling discrete-valued vector time series data
using extensions of Chow-Liu tree models to capture both dependencies across
time and dependencies across variables. Conditional Chow-Liu tree models are
introduced, as an extension to standard Chow-Liu trees, for modeling
conditional rather than joint densities. We describe learning algorithms for
such models and show how they can be used to learn parsimonious representations
for the output distributions in hidden Markov models. These models are applied
to the important problem of simulating and forecasting daily precipitation
occurrence for networks of rain stations. To demonstrate the effectiveness of
the models, we compare their performance versus a number of alternatives using
historical precipitation data from Southwestern Australia and the Western
United States. We illustrate how the structure and parameters of the models can
be used to provide an improved meteorological interpretation of such data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4143</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4143</id><created>2012-07-11</created><authors><author><keyname>Kim</keyname><forenames>Seyoung</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author><author><keyname>Luther</keyname><forenames>Stefan</forenames></author></authors><title>Modeling Waveform Shapes with Random Eects Segmental Hidden Markov
  Models</title><categories>stat.AP cs.CE</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-309-316</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a general probabilistic framework for modeling
waveforms such as heartbeats from ECG data. The model is based on segmental
hidden Markov models (as used in speech recognition) with the addition of
random effects to the generative model. The random effects component of the
model handles shape variability across different waveforms within a general
class of waveforms of similar shape. We show that this probabilistic model
provides a unified framework for learning these models from sets of waveform
data as well as parsing, classification, and prediction of new waveforms. We
derive a computationally efficient EM algorithm to fit the model on multiple
waveforms, and introduce a scoring method that evaluates a test waveform based
on its shape. Results on two real-world data sets demonstrate that the random
effects methodology leads to improved accuracy (compared to alternative
approaches) on classification and segmentation of real-world waveforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4144</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4144</id><created>2012-07-11</created><authors><author><keyname>Kahn</keyname><forenames>Joseph</forenames></author></authors><title>A Generative Bayesian Model for Aggregating Experts' Probabilities</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-301-308</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to improve forecasts, a decisionmaker often combines probabilities
given by various sources, such as human experts and machine learning
classifiers. When few training data are available, aggregation can be improved
by incorporating prior knowledge about the event being forecasted and about
salient properties of the experts. To this end, we develop a generative
Bayesian aggregation model for probabilistic classi cation. The model includes
an event-specific prior, measures of individual experts' bias, calibration,
accuracy, and a measure of dependence betweeen experts. Rather than require
absolute measures, we show that aggregation may be expressed in terms of
relative accuracy between experts. The model results in a weighted logarithmic
opinion pool (LogOps) that satis es consistency criteria such as the external
Bayesian property. We derive analytic solutions for independent and for
exchangeable experts. Empirical tests demonstrate the model's use, comparing
its accuracy with other aggregation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4145</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4145</id><created>2012-07-11</created><authors><author><keyname>Jojic</keyname><forenames>Nebojsa</forenames></author><author><keyname>Jojic</keyname><forenames>Vladimir</forenames></author><author><keyname>Heckerman</keyname><forenames>David</forenames></author></authors><title>Joint discovery of haplotype blocks and complex trait associations from
  SNP sequences</title><categories>q-bio.GN cs.CE stat.ME</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-286-292</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Haplotypes, the global patterns of DNA sequence variation, have important
implications for identifying complex traits. Recently, blocks of limited
haplotype diversity have been discovered in human chromosomes, intensifying the
research on modelling the block structure as well as the transitions or
co-occurrence of the alleles in these blocks as a way to compress the
variability and infer the associations more robustly. The haplotype block
structure analysis is typically complicated by the fact that the phase
information for each SNP is missing, i.e., the observed allele pairs are not
given in a consistent order across the sequence. The techniques for
circumventing this require additional information, such as family data, or a
more complex sequencing procedure. In this paper we present a hierarchical
statistical model and the associated learning and inference algorithms that
simultaneously deal with the allele ambiguity per locus, missing data, block
estimation, and the complex trait association. While the blo structure may
differ from the structures inferred by other methods, which use the pedigree
information or previously known alleles, the parameters we estimate, including
the learned block structure and the estimated block transitions per locus,
define a good model of variability in the set. The method is completely
datadriven and can detect Chron's disease from the SNP data taken from the
human chromosome 5q31 with the detection rate of 80% and a small error
variance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4146</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4146</id><created>2012-07-11</created><authors><author><keyname>Jin</keyname><forenames>Rong</forenames></author><author><keyname>Si</keyname><forenames>Luo</forenames></author></authors><title>A Bayesian Approach toward Active Learning for Collaborative Filtering</title><categories>cs.LG cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-278-285</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative filtering is a useful technique for exploiting the preference
patterns of a group of users to predict the utility of items for the active
user. In general, the performance of collaborative filtering depends on the
number of rated examples given by the active user. The more the number of rated
examples given by the active user, the more accurate the predicted ratings will
be. Active learning provides an effective way to acquire the most informative
rated examples from active users. Previous work on active learning for
collaborative filtering only considers the expected loss function based on the
estimated model, which can be misleading when the estimated model is
inaccurate. This paper takes one step further by taking into account of the
posterior distribution of the estimated model, which results in more robust
active learning algorithm. Empirical studies with datasets of movie ratings
show that when the number of ratings from the active user is restricted to be
small, active learning methods only based on the estimated model don't perform
well while the active learning method using the model distribution achieves
substantially better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4147</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4147</id><created>2012-07-11</created><authors><author><keyname>Hyafil</keyname><forenames>Nathanael</forenames></author><author><keyname>Boutilier</keyname><forenames>Craig</forenames></author></authors><title>Regret Minimizing Equilibria and Mechanisms for Games with Strict Type
  Uncertainty</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-268-277</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mechanism design has found considerable application to the construction of
agent-interaction protocols. In the standard setting, the type (e.g., utility
function) of an agent is not known by other agents, nor is it known by the
mechanism designer. When this uncertainty is quantified probabilistically, a
mechanism induces a game of incomplete information among the agents. However,
in many settings, uncertainty over utility functions cannot easily be
quantified. We consider the problem of incomplete information games in which
type uncertainty is strict or unquantified. We propose the use of minimax
regret as a decision criterion in such games, a robust approach for dealing
with type uncertainty. We define minimax-regret equilibria and prove that these
exist in mixed strategies for finite games. We also consider the problem of
mechanism design in this framework by adopting minimax regret as an
optimization criterion for the designer itself, and study automated
optimization of such mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4148</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4148</id><created>2012-07-11</created><authors><author><keyname>Howard</keyname><forenames>Andrew</forenames></author><author><keyname>Jebara</keyname><forenames>Tony S.</forenames></author></authors><title>Dynamical Systems Trees</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-260-267</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose dynamical systems trees (DSTs) as a flexible class of models for
describing multiple processes that interact via a hierarchy of aggregating
parent chains. DSTs extend Kalman filters, hidden Markov models and nonlinear
dynamical systems to an interactive group scenario. Various individual
processes interact as communities and sub-communities in a tree structure that
is unrolled in time. To accommodate nonlinear temporal activity, each
individual leaf process is modeled as a dynamical system containing discrete
and/or continuous hidden states with discrete and/or Gaussian emissions.
Subsequent higher level parent processes act like hidden Markov models and
mediate the interaction between leaf processes or between other parent
processes in the hierarchy. Aggregator chains are parents of child processes
that they combine and mediate, yielding a compact overall parameterization. We
provide tractable inference and learning algorithms for arbitrary DST
topologies via an efficient structured mean-field algorithm. The diverse
applicability of DSTs is demonstrated by experiments on gene expression data
and by modeling group behavior in the setting of an American football game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4149</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4149</id><created>2012-07-11</created><authors><author><keyname>Hamze</keyname><forenames>Firas</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>From Fields to Trees</title><categories>stat.CO cs.LG</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-243-250</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new MCMC algorithms for computing the posterior distributions and
expectations of the unknown variables in undirected graphical models with
regular structure. For demonstration purposes, we focus on Markov Random Fields
(MRFs). By partitioning the MRFs into non-overlapping trees, it is possible to
compute the posterior distribution of a particular tree exactly by conditioning
on the remaining tree. These exact solutions allow us to construct efficient
blocked and Rao-Blackwellised MCMC algorithms. We show empirically that tree
sampling is considerably more efficient than other partitioned sampling schemes
and the naive Gibbs sampler, even in cases where loopy belief propagation fails
to converge. We prove that tree sampling exhibits lower variance than the naive
Gibbs sampler and other naive partitioning schemes using the theoretical
measure of maximal correlation. We also construct new information theory tools
for comparing different MCMC schemes and show that, under these, tree sampling
is more efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4150</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4150</id><created>2012-07-11</created><authors><author><keyname>Guestrin</keyname><forenames>Carlos E.</forenames></author><author><keyname>Hauskrecht</keyname><forenames>Milos</forenames></author><author><keyname>Kveton</keyname><forenames>Branislav</forenames></author></authors><title>Solving Factored MDPs with Continuous and Discrete Variables</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-235-242</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although many real-world stochastic planning problems are more naturally
formulated by hybrid models with both discrete and continuous variables,
current state-of-the-art methods cannot adequately address these problems. We
present the first framework that can exploit problem structure for modeling and
solving hybrid problems efficiently. We formulate these problems as hybrid
Markov decision processes (MDPs with continuous and discrete state and action
variables), which we assume can be represented in a factored way using a hybrid
dynamic Bayesian network (hybrid DBN). This formulation also allows us to apply
our methods to collaborative multiagent settings. We present a new linear
program approximation method that exploits the structure of the hybrid MDP and
lets us compute approximate value functions more efficiently. In particular, we
describe a new factored discretization of continuous variables that avoids the
exponential blow-up of traditional approaches. We provide theoretical bounds on
the quality of such an approximation and on its scale-up potential. We support
our theoretical arguments with experiments on a set of control problems with up
to 28-dimensional continuous state space and 22-dimensional action space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4151</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4151</id><created>2012-07-11</created><authors><author><keyname>Narasimhan</keyname><forenames>Mukund</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author></authors><title>PAC-learning bounded tree-width Graphical Models</title><categories>cs.LG cs.DS stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-410-417</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the class of strongly connected graphical models with treewidth
at most k can be properly efficiently PAC-learnt with respect to the
Kullback-Leibler Divergence. Previous approaches to this problem, such as those
of Chow ([1]), and Ho gen ([7]) have shown that this class is PAC-learnable by
reducing it to a combinatorial optimization problem. However, for k &gt; 1, this
problem is NP-complete ([15]), and so unless P=NP, these approaches will take
exponential amounts of time. Our approach differs significantly from these, in
that it first attempts to find approximate conditional independencies by
solving (polynomially many) submodular optimization problems, and then using a
dynamic programming formulation to combine the approximate conditional
independence information to derive a graphical model with underlying graph of
the tree-width specified. This gives us an efficient (polynomial time in the
number of random variables) PAC-learning algorithm which requires only
polynomial number of samples of the true distribution, and only polynomial
running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4152</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4152</id><created>2012-07-11</created><authors><author><keyname>Zitnick</keyname><forenames>Lawrence</forenames></author><author><keyname>Kanade</keyname><forenames>Takeo</forenames></author></authors><title>Maximum Entropy for Collaborative Filtering</title><categories>cs.IR cs.LG</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-636-643</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the task of collaborative filtering two challenges for computing
conditional probabilities exist. First, the amount of training data available
is typically sparse with respect to the size of the domain. Thus, support for
higher-order interactions is generally not present. Second, the variables that
we are conditioning upon vary for each query. That is, users label different
variables during each query. For this reason, there is no consistent input to
output mapping. To address these problems we purpose a maximum entropy approach
using a non-standard measure of entropy. This approach can be simplified to
solving a set of linear equations that can be efficiently solved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4153</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4153</id><created>2012-07-11</created><authors><author><keyname>Yuan</keyname><forenames>Changhe</forenames></author><author><keyname>Lu</keyname><forenames>Tsai-Ching</forenames></author><author><keyname>Druzdzel</keyname><forenames>Marek J.</forenames></author></authors><title>Annealed MAP</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-628-635</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum a Posteriori assignment (MAP) is the problem of finding the most
probable instantiation of a set of variables given the partial evidence on the
other variables in a Bayesian network. MAP has been shown to be a NP-hard
problem [22], even for constrained networks, such as polytrees [18]. Hence,
previous approaches often fail to yield any results for MAP problems in large
complex Bayesian networks. To address this problem, we propose AnnealedMAP
algorithm, a simulated annealing-based MAP algorithm. The AnnealedMAP algorithm
simulates a non-homogeneous Markov chain whose invariant function is a
probability density that concentrates itself on the modes of the target
density. We tested this algorithm on several real Bayesian networks. The
results show that, while maintaining good quality of the MAP solutions, the
AnnealedMAP algorithm is also able to solve many problems that are beyond the
reach of previous approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4154</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4154</id><created>2012-07-11</created><authors><author><keyname>Yu</keyname><forenames>Huizhen</forenames></author><author><keyname>Bertsekas</keyname><forenames>Dimitri</forenames></author></authors><title>Discretized Approximations for POMDP with Average Cost</title><categories>cs.AI cs.SY math.OC</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-619-627</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new lower approximation scheme for POMDP with
discounted and average cost criterion. The approximating functions are
determined by their values at a finite number of belief points, and can be
computed efficiently using value iteration algorithms for finite-state MDP.
While for discounted problems several lower approximation schemes have been
proposed earlier, ours seems the first of its kind for average cost problems.
We focus primarily on the average cost case, and we show that the corresponding
approximation can be computed efficiently using multi-chain algorithms for
finite-state MDP. We give a preliminary analysis showing that regardless of the
existence of the optimal average cost J in the POMDP, the approximation
obtained is a lower bound of the liminf optimal average cost function, and can
also be used to calculate an upper bound on the limsup optimal average cost
function, as well as bounds on the cost of executing the stationary policy
associated with the approximation. Weshow the convergence of the cost
approximation, when the optimal average cost is constant and the optimal
differential cost is continuous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4155</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4155</id><created>2012-07-11</created><authors><author><keyname>Xiong</keyname><forenames>Xuejian</forenames></author><author><keyname>Chan</keyname><forenames>Kap</forenames></author><author><keyname>Tan</keyname><forenames>Kian Lee</forenames></author></authors><title>Similarity-Driven Cluster Merging Method for Unsupervised Fuzzy
  Clustering</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-611-618</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a similarity-driven cluster merging method is proposed for
unsuper-vised fuzzy clustering. The cluster merging method is used to resolve
the problem of cluster validation. Starting with an overspecified number of
clusters in the data, pairs of similar clusters are merged based on the
proposed similarity-driven cluster merging criterion. The similarity between
clusters is calculated by a fuzzy cluster similarity matrix, while an adaptive
threshold is used for merging. In addition, a modified generalized ob- jective
function is used for prototype-based fuzzy clustering. The function includes
the p-norm distance measure as well as principal components of the clusters.
The number of the principal components is determined automatically from the
data being clustered. The properties of this unsupervised fuzzy clustering
algorithm are illustrated by several experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4156</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4156</id><created>2012-07-11</created><authors><author><keyname>Xing</keyname><forenames>Eric P.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author><author><keyname>Russell</keyname><forenames>Stuart</forenames></author></authors><title>Graph partition strategies for generalized mean field inference</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-602-610</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An autonomous variational inference algorithm for arbitrary graphical models
requires the ability to optimize variational approximations over the space of
model parameters as well as over the choice of tractable families used for the
variational approximation. In this paper, we present a novel combination of
graph partitioning algorithms with a generalized mean field (GMF) inference
algorithm. This combination optimizes over disjoint clustering of variables and
performs inference using those clusters. We provide a formal analysis of the
relationship between the graph cut and the GMF approximation, and explore
several graph partition strategies empirically. Our empirical results provide
rather clear support for a weighted version of MinCut as a useful clustering
algorithm for GMF inference, which is consistent with the implications from the
formal analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4157</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4157</id><created>2012-07-11</created><authors><author><keyname>Wellner</keyname><forenames>Ben</forenames></author><author><keyname>McCallum</keyname><forenames>Andrew</forenames></author><author><keyname>Peng</keyname><forenames>Fuchun</forenames></author><author><keyname>Hay</keyname><forenames>Michael</forenames></author></authors><title>An Integrated, Conditional Model of Information Extraction and
  Coreference with Applications to Citation Matching</title><categories>cs.LG cs.DL cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-593-601</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although information extraction and coreference resolution appear together in
many applications, most current systems perform them as ndependent steps. This
paper describes an approach to integrated inference for extraction and
coreference based on conditionally-trained undirected graphical models. We
discuss the advantages of conditional probability training, and of a
coreference model structure based on graph partitioning. On a data set of
research paper citations, we show significant reduction in error by using
extraction uncertainty to improve coreference citation matching accuracy, and
using coreference to improve the accuracy of the extracted fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4158</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4158</id><created>2012-07-11</created><authors><author><keyname>Welling</keyname><forenames>Max</forenames></author></authors><title>On the Choice of Regions for Generalized Belief Propagation</title><categories>cs.AI cs.LG</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-585-592</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized belief propagation (GBP) has proven to be a promising technique
for approximate inference tasks in AI and machine learning. However, the choice
of a good set of clusters to be used in GBP has remained more of an art then a
science until this day. This paper proposes a sequential approach to adding new
clusters of nodes and their interactions (i.e. &quot;regions&quot;) to the approximation.
We first review and analyze the recently introduced region graphs and find that
three kinds of operations (&quot;split&quot;, &quot;merge&quot; and &quot;death&quot;) leave the free energy
and (under some conditions) the fixed points of GBP invariant. This leads to
the notion of &quot;weakly irreducible&quot; regions as the natural candidates to be
added to the approximation. Computational complexity of the GBP algorithm is
controlled by restricting attention to regions with small &quot;region-width&quot;.
Combining the above with an efficient (i.e. local in the graph) measure to
predict the improved accuracy of GBP leads to the sequential &quot;region pursuit&quot;
algorithm for adding new regions bottom-up to the region graph. Experiments
show that this algorithm can indeed perform close to optimally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4160</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4160</id><created>2012-07-11</created><authors><author><keyname>van der Gaag</keyname><forenames>Linda C.</forenames></author><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author><author><keyname>Feelders</keyname><forenames>Ad</forenames></author></authors><title>Monotonicity in Bayesian Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-569-576</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many real-life Bayesian networks, common knowledge dictates that the
output established for the main variable of interest increases with higher
values for the observable variables. We define two concepts of monotonicity to
capture this type of knowledge. We say that a network is isotone in
distribution if the probability distribution computed for the output variable
given specific observations is stochastically dominated by any such
distribution given higher-ordered observations; a network is isotone in mode if
a probability distribution given higher observations has a higher mode. We show
that establishing whether a network exhibits any of these properties of
monotonicity is coNPPP-complete in general, and remains coNP-complete for
polytrees. We present an approximate algorithm for deciding whether a network
is monotone in distribution and illustrate its application to a real-life
network in oncology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4161</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4161</id><created>2012-07-11</created><authors><author><keyname>Tian</keyname><forenames>Jin</forenames></author></authors><title>Identifying Conditional Causal Effects</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-561-568</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the assessment of the effects of actions from a
combination of nonexperimental data and causal assumptions encoded in the form
of a directed acyclic graph in which some variables are presumed to be
unobserved. We provide a procedure that systematically identifies cause effects
between two sets of variables conditioned on some other variables, in time
polynomial in the number of variables in the graph. The identifiable
conditional causal effects are expressed in terms of the observed joint
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4162</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4162</id><created>2012-07-11</created><updated>2012-08-08</updated><authors><author><keyname>Thiesson</keyname><forenames>Bo</forenames></author><author><keyname>Chickering</keyname><forenames>David Maxwell</forenames></author><author><keyname>Heckerman</keyname><forenames>David</forenames></author><author><keyname>Meek</keyname><forenames>Christopher</forenames></author></authors><title>ARMA Time-Series Modeling with Graphical Models</title><categories>stat.AP cs.LG stat.ME</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>Martijn de Jongh</proxy><report-no>UAI-P-2004-PG-552-560</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We express the classic ARMA time-series model as a directed graphical model.
In doing so, we find that the deterministic relationships in the model make it
effectively impossible to use the EM algorithm for learning model parameters.
To remedy this problem, we replace the deterministic relationships with
Gaussian distributions having a small variance, yielding the stochastic ARMA
(ARMA) model. This modification allows us to use the EM algorithm to learn
parmeters and to forecast,even in situations where some data is missing. This
modification, in conjunction with the graphicalmodel approach, also allows us
to include cross predictors in situations where there are multiple times series
and/or additional nontemporal covariates. More surprising,experiments suggest
that the move to stochastic ARMA yields improved accuracy through better
smoothing. We demonstrate improvements afforded by cross prediction and better
smoothing on real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4163</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4163</id><created>2012-07-11</created><authors><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Reputation Systems: An Axiomatic Approach</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-544-551</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reasoning about agent preferences on a set of alternatives, and the
aggregation of such preferences into some social ranking is a fundamental issue
in reasoning about uncertainty and multi-agent systems. When the set of agents
and the set of alternatives coincide, we get the so-called reputation systems
setting. Famous types of reputation systems include page ranking in the context
of search engines and traders ranking in the context of e-commerce. In this
paper we present the first axiomatic study of reputation systems. We present
three basic postulates that the desired/aggregated social ranking should
satisfy and prove an impossibility theorem showing that no appropriate social
ranking, satisfying all requirements, exists. Then we show that by relaxing any
of these requirements an appropriate social ranking can be found. We first
study reputation systems with (only) positive feedbacks. This setting refers to
systems where agents' votes are interpreted as indications for the importance
of other agents, as is the case in page ranking. Following this, we discuss the
case of negative feedbacks, a most common situation in e-commerce settings,
where traders may complain about the behavior of others. Finally, we discuss
the case where both positive and negative feedbacks are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4164</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4164</id><created>2012-07-11</created><authors><author><keyname>Stauffer</keyname><forenames>Chris</forenames></author></authors><title>Factored Latent Analysis for far-field tracking data</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-536-543</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper uses Factored Latent Analysis (FLA) to learn a factorized,
segmental representation for observations of tracked objects over time.
Factored Latent Analysis is latent class analysis in which the observation
space is subdivided and each aspect of the original space is represented by a
separate latent class model. One could simply treat these factors as completely
independent and ignore their interdependencies or one could concatenate them
together and attempt to learn latent class structure for the complete
observation space. Alternatively, FLA allows the interdependencies to be
exploited in estimating an effective model, which is also capable of
representing a factored latent state. In this paper, FLA is used to learn a set
of factored latent classes to represent different modalities of observations of
tracked objects. Different characteristics of the state of tracked objects are
each represented by separate latent class models, including normalized size,
normalized speed, normalized direction, and position. This model also enables
effective temporal segmentation of these sequences. This method is data-driven,
unsupervised using only pairwise observation statistics. This data-driven and
unsupervised activity classi- fication technique exhibits good performance in
multiple challenging environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4165</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4165</id><created>2012-07-11</created><authors><author><keyname>Smorodinsky</keyname><forenames>Rann</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Sequential Information Elicitation in Multi-Agent Systems</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-528-535</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the study of sequential information elicitation in strategic
multi-agent systems. In an information elicitation setup a center attempts to
compute the value of a function based on private information (a-k-a secrets)
accessible to a set of agents. We consider the classical multi-party
computation setup where each agent is interested in knowing the result of the
function. However, in our setting each agent is strategic,and since acquiring
information is costly, an agent may be tempted not spending the efforts of
obtaining the information, free-riding on other agents' computations. A
mechanism which elicits agents' secrets and performs the desired computation
defines a game. A mechanism is 'appropriate' if there exists an equilibrium in
which it is able to elicit (sufficiently many) agents' secrets and perform the
computation, for all possible secret vectors.We characterize a general
efficient procedure for determining an appropriate mechanism, if such mechanism
exists. Moreover, we also address the existence problem, providing a polynomial
algorithm for verifying the existence of an appropriate mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4166</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4166</id><created>2012-07-11</created><authors><author><keyname>Smith</keyname><forenames>Trey</forenames></author><author><keyname>Simmons</keyname><forenames>Reid</forenames></author></authors><title>Heuristic Search Value Iteration for POMDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-520-527</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel POMDP planning algorithm called heuristic search value
iteration (HSVI).HSVI is an anytime algorithm that returns a policy and a
provable bound on its regret with respect to the optimal policy. HSVI gets its
power by combining two well-known techniques: attention-focusing search
heuristics and piecewise linear convex representations of the value function.
HSVI's soundness and convergence have been proven. On some benchmark problems
from the literature, HSVI displays speedups of greater than 100 with respect to
other state-of-the-art POMDP value iteration algorithms. We also apply HSVI to
a new rover exploration problem 10 times larger than most POMDP problems in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4167</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4167</id><created>2012-07-11</created><authors><author><keyname>Singh</keyname><forenames>Satinder</forenames></author><author><keyname>James</keyname><forenames>Michael</forenames></author><author><keyname>Rudary</keyname><forenames>Matthew</forenames></author></authors><title>Predictive State Representations: A New Theory for Modeling Dynamical
  Systems</title><categories>cs.AI cs.LG</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-512-519</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling dynamical systems, both for control purposes and to make predictions
about their behavior, is ubiquitous in science and engineering. Predictive
state representations (PSRs) are a recently introduced class of models for
discrete-time dynamical systems. The key idea behind PSRs and the closely
related OOMs (Jaeger's observable operator models) is to represent the state of
the system as a set of predictions of observable outcomes of experiments one
can do in the system. This makes PSRs rather different from history-based
models such as nth-order Markov models and hidden-state-based models such as
HMMs and POMDPs. We introduce an interesting construct, the systemdynamics
matrix, and show how PSRs can be derived simply from it. We also use this
construct to show formally that PSRs are more general than both nth-order
Markov models and HMMs/POMDPs. Finally, we discuss the main difference between
PSRs and OOMs and conclude with directions for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4168</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4168</id><created>2012-07-11</created><authors><author><keyname>Schubert</keyname><forenames>Lenhart</forenames></author></authors><title>A New Characterization of Probabilities in Bayesian Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-495-503</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize probabilities in Bayesian networks in terms of algebraic
expressions called quasi-probabilities. These are arrived at by casting
Bayesian networks as noisy AND-OR-NOT networks, and viewing the subnetworks
that lead to a node as arguments for or against a node. Quasi-probabilities are
in a sense the &quot;natural&quot; algebra of Bayesian networks: we can easily compute
the marginal quasi-probability of any node recursively, in a compact form; and
we can obtain the joint quasi-probability of any set of nodes by multiplying
their marginals (using an idempotent product operator). Quasi-probabilities are
easily manipulated to improve the efficiency of probabilistic inference. They
also turn out to be representable as square-wave pulse trains, and joint and
marginal distributions can be computed by multiplication and complementation of
pulse trains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4169</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4169</id><created>2012-07-11</created><authors><author><keyname>Rosen-Zvi</keyname><forenames>Michal</forenames></author><author><keyname>Griffiths</keyname><forenames>Thomas</forenames></author><author><keyname>Steyvers</keyname><forenames>Mark</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author></authors><title>The Author-Topic Model for Authors and Documents</title><categories>cs.IR cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-487-494</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the author-topic model, a generative model for documents that
extends Latent Dirichlet Allocation (LDA; Blei, Ng, &amp; Jordan, 2003) to include
authorship information. Each author is associated with a multinomial
distribution over topics and each topic is associated with a multinomial
distribution over words. A document with multiple authors is modeled as a
distribution over topics that is a mixture of the distributions associated with
the authors. We apply the model to a collection of 1,700 NIPS conference papers
and 160,000 CiteSeer abstracts. Exact inference is intractable for these
datasets and we use Gibbs sampling to estimate the topic and author
distributions. We compare the performance with two other generative models for
documents, which are special cases of the author-topic model: LDA (a topic
model) and a simple author model in which each author is associated with a
distribution over words rather than a distribution over topics. We show topics
recovered by the author-topic model, and demonstrate applications to computing
similarity between authors and entropy of author output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4170</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4170</id><created>2012-07-11</created><authors><author><keyname>Renooij</keyname><forenames>Silja</forenames></author><author><keyname>van der Gaag</keyname><forenames>Linda C.</forenames></author></authors><title>Evidence-invariant Sensitivity Bounds</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-479-486</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sensitivities revealed by a sensitivity analysis of a probabilistic
network typically depend on the entered evidence. For a real-life network
therefore, the analysis is performed a number of times, with different
evidence. Although efficient algorithms for sensitivity analysis exist, a
complete analysis is often infeasible because of the large range of possible
combinations of observations. In this paper we present a method for studying
sensitivities that are invariant to the evidence entered. Our method builds
upon the idea of establishing bounds between which a parameter can be varied
without ever inducing a change in the most likely value of a variable of
interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4171</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4171</id><created>2012-07-11</created><authors><author><keyname>Reeves</keyname><forenames>Daniel</forenames></author><author><keyname>Wellman</keyname><forenames>Michael P.</forenames></author></authors><title>Computing Best-Response Strategies in Infinite Games of Incomplete
  Information</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-470-478</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm for computing best response strategies in a class of
two-player infinite games of incomplete information, defined by payoffs
piecewise linear in agents' types and actions, conditional on linear
comparisons of agents' actions. We show that this class includes many
well-known games including a variety of auctions and a novel allocation game.
In some cases, the best-response algorithm can be iterated to compute
Bayes-Nash equilibria. We demonstrate the efficiency of our approach on
existing and new games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4172</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4172</id><created>2012-07-11</created><authors><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author><author><keyname>Lafferty</keyname><forenames>John</forenames></author></authors><title>Variational Chernoff Bounds for Graphical Models</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-462-469</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has made significant progress on the problem of bounding log
partition functions for exponential family graphical models. Such bounds have
associated dual parameters that are often used as heuristic estimates of the
marginal probabilities required in inference and learning. However these
variational estimates do not give rigorous bounds on marginal probabilities,
nor do they give estimates for probabilities of more general events than simple
marginals. In this paper we build on this recent work by deriving rigorous
upper and lower bounds on event probabilities for graphical models. Our
approach is based on the use of generalized Chernoff bounds to express bounds
on event probabilities in terms of convex optimization problems; these
optimization problems, in turn, require estimates of generalized log partition
functions. Simulations indicate that this technique can result in useful,
rigorous bounds to complement the heuristic variational estimates, with
comparable computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4173</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4173</id><created>2012-07-11</created><authors><author><keyname>Pearl</keyname><forenames>Judea</forenames></author></authors><title>Robustness of Causal Claims</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-446-453</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A causal claim is any assertion that invokes causal relationships between
variables, for example that a drug has a certain effect on preventing a
disease. Causal claims are established through a combination of data and a set
of causal assumptions called a causal model. A claim is robust when it is
insensitive to violations of some of the causal assumptions embodied in the
model. This paper gives a formal definition of this notion of robustness and
establishes a graphical condition for quantifying the degree of robustness of a
given causal claim. Algorithms for computing the degree of robustness are also
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4174</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4174</id><created>2012-07-11</created><authors><author><keyname>Paskin</keyname><forenames>Mark</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos E.</forenames></author></authors><title>Robust Probabilistic Inference in Distributed Systems</title><categories>cs.AI cs.DC</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-436-445</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic inference problems arise naturally in distributed systems such
as sensor networks and teams of mobile robots. Inference algorithms that use
message passing are a natural fit for distributed systems, but they must be
robust to the failure situations that arise in real-world settings, such as
unreliable communication and node failures. Unfortunately, the popular
sum-product algorithm can yield very poor estimates in these settings because
the nodes' beliefs before convergence can be arbitrarily different from the
correct posteriors. In this paper, we present a new message passing algorithm
for probabilistic inference which provides several crucial guarantees that the
standard sum-product algorithm does not. Not only does it converge to the
correct posteriors, but it is also guaranteed to yield a principled
approximation at any point before convergence. In addition, the computational
complexity of the message passing updates depends only upon the model, and is
dependent of the network topology of the distributed system. We demonstrate the
approach with detailed experimental results on a distributed sensor calibration
task using data from an actual sensor network deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4175</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4175</id><created>2012-07-11</created><authors><author><keyname>Orlitsky</keyname><forenames>Alon</forenames></author><author><keyname>Santhanam</keyname><forenames>Narayana</forenames></author><author><keyname>Viswanathan</keyname><forenames>Krishnamurthy</forenames></author><author><keyname>Zhang</keyname><forenames>Junan</forenames></author></authors><title>On Modeling Profiles instead of Values</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-426-435</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating the distribution underlying an observed
sample of data. Instead of maximum likelihood, which maximizes the probability
of the ob served values, we propose a different estimate, the high-profile
distribution, which maximizes the probability of the observed profile the
number of symbols appearing any given number of times. We determine the
high-profile distribution of several data samples, establish some of its
general properties, and show that when the number of distinct symbols observed
is small compared to the data size, the high-profile and maximum-likelihood
distributions are roughly the same, but when the number of symbols is large,
the distributions differ, and high-profile better explains the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4176</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4176</id><created>2012-07-12</created><authors><author><keyname>Bayer-Zubek</keyname><forenames>Valentina</forenames></author></authors><title>Learning Diagnostic Policies from Examples by Systematic Search</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-27-34</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A diagnostic policy specifies what test to perform next, based on the results
of previous tests, and when to stop and make a diagnosis. Cost-sensitive
diagnostic policies perform tradeoffs between (a) the cost of tests and (b) the
cost of misdiagnoses. An optimal diagnostic policy minimizes the expected total
cost. We formalize this diagnosis process as a Markov Decision Process (MDP).
We investigate two types of algorithms for solving this MDP: systematic search
based on AO* algorithm and greedy search (particularly the Value of Information
method). We investigate the issue of learning the MDP probabilities from
examples, but only as they are relevant to the search for good policies. We do
not learn nor assume a Bayesian network for the diagnosis process. Regularizers
are developed to control overfitting and speed up the search. This research is
the first that integrates overfitting prevention into systematic search. The
paper has two contributions: it discusses the factors that make systematic
search feasible for diagnosis, and it shows experimentally, on benchmark data
sets, that systematic search methods produce better diagnostic policies than
greedy methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4177</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4177</id><created>2012-07-12</created><authors><author><keyname>Cobb</keyname><forenames>Barry</forenames></author><author><keyname>Shenoy</keyname><forenames>Prakash P.</forenames></author></authors><title>Hybrid Influence Diagrams Using Mixtures of Truncated Exponentials</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-85-93</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mixtures of truncated exponentials (MTE) potentials are an alternative to
discretization for representing continuous chance variables in influence
diagrams. Also, MTE potentials can be used to approximate utility functions.
This paper introduces MTE influence diagrams, which can represent decision
problems without restrictions on the relationships between continuous and
discrete chance variables, without limitations on the distributions of
continuous chance variables, and without limitations on the nature of the
utility functions. In MTE influence diagrams, all probability distributions and
the joint utility function (or its multiplicative factors) are represented by
MTE potentials and decision nodes are assumed to have discrete state spaces.
MTE influence diagrams are solved by variable elimination using a fusion
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4179</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4179</id><created>2012-07-12</created><authors><author><keyname>Jojic</keyname><forenames>Nebojsa</forenames></author><author><keyname>Caspi</keyname><forenames>Yaron</forenames></author><author><keyname>Reyes-Gomez</keyname><forenames>Manuel</forenames></author></authors><title>Probabilistic index maps for modeling natural signals</title><categories>cs.CV</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-293-300</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major problems in modeling natural signals is that signals with
very similar structure may locally have completely different measurements,
e.g., images taken under different illumination conditions, or the speech
signal captured in different environments. While there have been many
successful attempts to address these problems in application-specific settings,
we believe that underlying a large set of problems in signal representation is
a representational deficiency of intensity-derived local measurements that are
the basis of most efficient models. We argue that interesting structure in
signals is better captured when the signal is de- fined as a matrix whose
entries are discrete indices to a separate palette of possible measurements. In
order to model the variability in signal structure, we define a signal class
not by a single index map, but by a probability distribution over the index
maps, which can be estimated from the data, and which we call probabilistic
index maps. The existing algorithm can be adapted to work with this
representation. Furthermore, the probabilistic index map representation leads
to algorithms with computational costs proportional to either the size of the
palette or the log of the size of the palette, making the cost of significantly
increased invariance to non-structural changes quite bearable. We illustrate
the benefits of the probabilistic index map representation in several
applications in computer vision and speech processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4180</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4180</id><created>2012-07-12</created><authors><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author><author><keyname>Cohen</keyname><forenames>William</forenames></author></authors><title>A Hierarchical Graphical Model for Record Linkage</title><categories>cs.LG cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-454-461</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of matching co-referent records is known among other names as rocord
linkage. For large record-linkage problems, often there is little or no labeled
data available, but unlabeled data shows a reasonable clear structure. For such
problems, unsupervised or semi-supervised methods are preferable to supervised
methods. In this paper, we describe a hierarchical graphical model framework
for the linakge-problem in an unsupervised setting. In addition to proposing
new methods, we also cast existing unsupervised probabilistic record-linkage
methods in this framework. Some of the techniques we propose to minimize
overfitting in the above model are of interest in the general graphical model
setting. We describe a method for incorporating monotinicity constraints in a
graphical model. We also outline a bootstrapping approach of using
&quot;single-field&quot; classifiers to noisily label latent variables in a hierarchical
model. Experimental results show that our proposed unsupervised methods perform
quite competitively even with fully supervised record-linkage methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4233</identifier>
 <datestamp>2012-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4233</id><created>2012-07-17</created><updated>2012-11-16</updated><authors><author><keyname>Saari</keyname><forenames>Kalle</forenames></author></authors><title>Lyndon words and Fibonacci numbers</title><categories>math.CO cs.DM</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a fundamental property of non-letter Lyndon words that they can be
expressed as a concatenation of two shorter Lyndon words. This leads to a naive
lower bound log_{2}(n)} + 1 for the number of distinct Lyndon factors that a
Lyndon word of length n must have, but this bound is not optimal. In this paper
we show that a much more accurate lower bound is log_{phi}(n) + 1, where phi
denotes the golden ratio (1 + sqrt{5})/2. We show that this bound is optimal in
that it is attained by the Fibonacci Lyndon words. We then introduce a mapping
L_x that counts the number of Lyndon factors of length at most n in an infinite
word x. We show that a recurrent infinite word x is aperiodic if and only if
L_x &gt;= L_f, where f is the Fibonacci infinite word, with equality if and only
if f is in the shift orbit closure of f.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4247</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4247</id><created>2012-07-17</created><authors><author><keyname>Almunawar</keyname><forenames>Mohammad Nabil</forenames></author></authors><title>Acquiring IT Solutions through Open Source Software</title><categories>cs.OH</categories><comments>15 pages, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open source software is free software that provides user freedom to use,
replicate, modify, and distribute for any purpose. The quality of well-known
open source software is very high and they are used by big companies such as
IBM, Google and Amazon.com. Recently the number of open source software project
growing very fast, which indicates that adoption of open source software is
growing although still limited. Businesses should consider open source software
as alternative solutions to their business problems or opportunities. An
example of a very good open source software for office suite is discussed and
compared with the well-known proprietary counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4252</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4252</id><created>2012-07-17</created><authors><author><keyname>Shen</keyname><forenames>Minqi</forenames></author><author><keyname>H&#xf8;st-Madsen</keyname><forenames>Anders</forenames></author></authors><title>The Wideband Slope of Interference Channels: The Small Bandwidth Case</title><categories>cs.IT math.IT</categories><comments>submitted to Information Theory, IEEE Transactions on</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the low-SNR regime performance of a scalar complex K -user
interference channel with Gaussian noise. The finite bandwidth case is
considered, where the low-SNR regime is approached by letting the input power
go to zero while bandwidth is small and fixed. We show that for all \delta&gt;0
there exists a set with non-zero measure (probability) in which the wideband
slope per user satisfies Slope&lt;2/K+\delta . This is quite contrary to the large
bandwidth case [ShenAHM11IT], where a slope of 1 per user is achievable with
probability 1. We also develop an interference alignment scheme for the finite
bandwidth case that shows some gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4254</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4254</id><created>2012-07-17</created><updated>2012-07-19</updated><authors><author><keyname>Nosrat-Makouei</keyname><forenames>Behrang</forenames></author><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>MIMO Interference Alignment in Random Access Networks</title><categories>cs.IT math.IT</categories><comments>21 pages, 6 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze a multiple-input multiple-output (MIMO)
interference channel where nodes are randomly distributed on a plane as a
spatial Poisson cluster point process. Each cluster uses interference alignment
(IA) to suppress intra-cluster interference but unlike most work on IA, we do
not neglect inter-cluster interference. We also connect the accuracy of channel
state information to the distance between the nodes, i.e. the quality of CSI
degrades with increasing distance. Accounting for the training and feedback
overhead, we derive the transmission capacity of this MIMO IA ad hoc network
and then compare it to open-loop (interference-blind) spatial multiplexing.
Finally, we present exemplary system setups where spatial multiplexing
outperforms IA due to the imperfect channel state information or the
non-aligned inter-cluster interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4255</identifier>
 <datestamp>2015-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4255</id><created>2012-07-17</created><updated>2015-10-24</updated><authors><author><keyname>Honorio</keyname><forenames>Jean</forenames></author><author><keyname>Jaakkola</keyname><forenames>Tommi</forenames></author><author><keyname>Samaras</keyname><forenames>Dimitris</forenames></author></authors><title>On the Statistical Efficiency of $\ell_{1,p}$ Multi-Task Learning of
  Gaussian Graphical Models</title><categories>cs.LG stat.ML</categories><comments>Submitted on October 21, 2015 to the Journal of Machine Learning
  Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present $\ell_{1,p}$ multi-task structure learning for
Gaussian graphical models. We analyze the sufficient number of samples for the
correct recovery of the support union and edge signs. We also analyze the
necessary number of samples for any conceivable method by providing
information-theoretic lower bounds. We compare the statistical efficiency of
multi-task learning versus that of single-task learning. For experiments, we
use a block coordinate descent method that is provably convergent and generates
a sequence of positive definite solutions. We provide experimental validation
on synthetic data as well as on two publicly available real-world data sets,
including functional magnetic resonance imaging and gene expression data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4258</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4258</id><created>2012-07-18</created><authors><author><keyname>Chen</keyname><forenames>Lin</forenames></author><author><keyname>Vasilakos</keyname><forenames>Athanasios V.</forenames></author></authors><title>Joint Rate Adaptation and Medium Access in Wireless LANs: a
  Non-cooperative Game Theoretic Perspective</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless local area networks (WLANs) based on IEEE 802.11 standards are
becoming ubiquitous today and typically support multiple data rates. In such
multi-rate WLANs, distributed medium access and rate adaptation are two key
elements to achieve efficient radio resource utilization, especially in
non-cooperative environments. In this paper, we present an analytical study on
the non-cooperative multi-rate WLANs composed of selfish users jointly
adjusting their data rate and contention window size at the medium access level
to maximize their own throughput, irrespective of the impact of their selfish
behaviors on overall system performance. Specifically, we develop an adapted
Tit-For-Tat (TFT) strategy to guide the system to an efficient equilibrium in
non-cooperative environments. We model the interactions among selfish users
under the adapted TFT framework as a non-cooperative joint medium access and
rate adaptation game. A systematic analysis is conducted on the structural
properties of the game to provide insights on the interaction between rate
adaptation and 802.11 medium access control in a competitive setting. We show
that the game has multiple equilibria, which, after the equilibrium refinement
process that we develop, reduce to a unique efficient equilibrium. We further
develop a distributed algorithm to achieve this equilibrium and demonstrate
that the equilibrium achieves the performance very close to the system optimum
in a social perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4259</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4259</id><created>2012-07-18</created><authors><author><keyname>Almunawar</keyname><forenames>Mohammad Nabil</forenames></author></authors><title>Content Based Multimedia Information Retrieval to Support Digital
  Libraries</title><categories>cs.IR cs.CV</categories><comments>15 pages, conference paper</comments><journal-ref>International Conference on New Information Technologies, 23-26
  July, 2001, Brunei Darussalam</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Content-based multimedia information retrieval is an interesting research
area since it allows retrieval based on inherent characteristic of multimedia
objects. For example retrieval based on visual characteristics such as colour,
shapes or textures of objects in images or retrieval based on spatial
relationships among objects in the media (images or video clips). This paper
reviews some work done in image and video retrieval and then proposes an
integrated model that can handle images and video clips uniformly. Using this
model retrieval on images or video clips can be done based on the same
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4262</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4262</id><created>2012-07-18</created><updated>2012-08-08</updated><authors><author><keyname>Huang</keyname><forenames>Zhenqi</forenames></author><author><keyname>Mitra</keyname><forenames>Sayan</forenames></author><author><keyname>Dullerud</keyname><forenames>Geir</forenames></author></authors><title>Differentially Private Iterative Synchronous Consensus</title><categories>cs.CR cs.DC cs.SY</categories><comments>The original manuscript from 18th July was updated with new proofs
  for Lemmas 3, 6, and 8</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The iterative consensus problem requires a set of processes or agents with
different initial values, to interact and update their states to eventually
converge to a common value. Protocols solving iterative consensus serve as
building blocks in a variety of systems where distributed coordination is
required for load balancing, data aggregation, sensor fusion, filtering, clock
synchronization and platooning of autonomous vehicles. In this paper, we
introduce the private iterative consensus problem where agents are required to
converge while protecting the privacy of their initial values from honest but
curious adversaries. Protecting the initial states, in many applications,
suffice to protect all subsequent states of the individual participants.
  First, we adapt the notion of differential privacy in this setting of
iterative computation. Next, we present a server-based and a completely
distributed randomized mechanism for solving private iterative consensus with
adversaries who can observe the messages as well as the internal states of the
server and a subset of the clients. Finally, we establish the tradeoff between
privacy and the accuracy of the proposed randomized mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4265</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4265</id><created>2012-07-18</created><authors><author><keyname>Sabek</keyname><forenames>Ibrahim</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Spot: An accurate and efficient multi-entity device-free WLAN
  localization system</title><categories>cs.NI</categories><comments>14 pages, 24 figures</comments><acm-class>C.2.4; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-free (DF) localization in WLANs has been introduced as a value-added
service that allows tracking indoor entities that do not carry any devices.
Previous work in DF WLAN localization focused on the tracking of a single
entity due to the intractability of the multi-entity tracking problem whose
complexity grows exponentially with the number of humans being tracked. In this
paper, we introduce Spot as an accurate and efficient system for multi-entity
DF detection and tracking. Spot is based on a probabilistic energy minimization
framework that combines a conditional random field with a Markov model to
capture the temporal and spatial relations between the entities' poses. A novel
cross-calibration technique is introduced to reduce the calibration overhead of
multiple entities to linear, regardless of the number of humans being tracked.
This also helps in increasing the system accuracy. We design the energy
minimization function with the goal of being efficiently solved in mind. We
show that the designed function can be mapped to a binary graph-cut problem
whose solution has a linear complexity on average and a third order polynomial
in the worst case. We further employ clustering on the estimated location
candidates to reduce outliers and obtain more accurate tracking. Experimental
evaluation in two typical testbeds, with a side-by-side comparison with the
state-of-the-art, shows that Spot can achieve a multi-entity tracking accuracy
of less than 1.1m. This corresponds to at least 36% enhancement in median
distance error over the state-of-the-art DF localization systems, which can
only track a single entity. In addition, Spot can estimate the number of
entities correctly to within one difference error. This highlights that Spot
achieves its goals of having an accurate and efficient software-only DF
tracking solution of multiple entities in indoor environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4266</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4266</id><created>2012-07-18</created><authors><author><keyname>Gutfraind</keyname><forenames>Alexander</forenames></author><author><keyname>Meyers</keyname><forenames>Lauren Ancel</forenames></author><author><keyname>Safro</keyname><forenames>Ilya</forenames></author></authors><title>Multiscale Network Generation</title><categories>cs.DM cond-mat.stat-mech cs.SI math.CO physics.soc-ph</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks are widely used in science and technology to represent relationships
between entities, such as social or ecological links between organisms,
enzymatic interactions in metabolic systems, or computer infrastructure.
Statistical analyses of networks can provide critical insights into the
structure, function, dynamics, and evolution of those systems. However, the
structures of real-world networks are often not known completely, and they may
exhibit considerable variation so that no single network is sufficiently
representative of a system. In such situations, researchers may turn to proxy
data from related systems, sophisticated methods for network inference, or
synthetic networks. Here, we introduce a flexible method for synthesizing
realistic ensembles of networks starting from a known network, through a series
of mappings that coarsen and later refine the network structure by randomized
editing. The method, MUSKETEER, preserves structural properties with minimal
bias, including unknown or unspecified features, while introducing realistic
variability at multiple scales. Using examples from several domains, we show
that MUSKETEER produces the intended stochasticity while achieving greater
fidelity across a suite of network properties than do other commonly used
network generation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4268</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4268</id><created>2012-07-18</created><authors><author><keyname>Fahrenberg</keyname><forenames>Uli</forenames><affiliation>INRIA</affiliation></author><author><keyname>Legay</keyname><forenames>Axel</forenames><affiliation>INRIA</affiliation></author></authors><title>A Robust Specification Theory for Modal Event-Clock Automata</title><categories>cs.LO cs.FL</categories><comments>In Proceedings FIT 2012, arXiv:1207.3485</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 87, 2012, pp. 5-16</journal-ref><doi>10.4204/EPTCS.87.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a series of recent work, we have introduced a general framework for
quantitative reasoning in specification theories. The contribution of this
paper is to show how this framework can be applied to yield a robust
specification theory for timed specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4269</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4269</id><created>2012-07-18</created><authors><author><keyname>Traonouez</keyname><forenames>Louis-Marie</forenames><affiliation>Aalborg University</affiliation></author></authors><title>A Parametric Counterexample Refinement Approach for Robust Timed
  Specifications</title><categories>cs.SE cs.FL</categories><comments>In Proceedings FIT 2012, arXiv:1207.3485</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 87, 2012, pp. 17-33</journal-ref><doi>10.4204/EPTCS.87.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness analyzes the impact of small perturbations in the semantics of a
model. This allows to model hardware imprecision and therefore it has been
applied to determine implementability of timed automata. In a recent paper, we
extend this problem to a specification theory for real-timed systems based on
timed input/output automata, that are interpreted as two-player games. We
propose a construction that allows to synthesize an implementation of a
specification that is robust under a given timed perturbation, and we study the
impact of these perturbations when composing different specifications.
  To complete this work we present a technique that evaluates the greatest
admissible perturbation. It consists in an iterative process that extracts a
spoiling strategy when a game is lost, and through a parametric analysis
refines the admissible values for the perturbation. We demonstrate this
approach with a prototype implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4270</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4270</id><created>2012-07-18</created><authors><author><keyname>Carbone</keyname><forenames>Marco</forenames></author><author><keyname>Hildebrandt</keyname><forenames>Thomas</forenames></author><author><keyname>Perrone</keyname><forenames>Gian</forenames></author><author><keyname>W&#x105;sowski</keyname><forenames>Andrzej</forenames></author></authors><title>Refinement for Transition Systems with Responses</title><categories>cs.LO</categories><comments>In Proceedings FIT 2012, arXiv:1207.3485</comments><proxy>EPTCS</proxy><acm-class>F.1.1; F.3.1; H.4.1 Workflow management</acm-class><journal-ref>EPTCS 87, 2012, pp. 48-55</journal-ref><doi>10.4204/EPTCS.87.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the response pattern for property specifications and
applications within flexible workflow management systems, we report upon an
initial study of modal and mixed transition systems in which the must
transitions are interpreted as must eventually, and in which implementations
can contain may behaviors that are resolved at run-time. We propose Transition
Systems with Responses (TSRs) as a suitable model for this study. We prove that
TSRs correspond to a restricted class of mixed transition systems, which we
refer to as the action-deterministic mixed transition systems. We show that
TSRs allow for a natural definition of deadlocked and accepting states. We then
transfer the standard definition of refinement for mixed transition systems to
TSRs and prove that refinement does not preserve deadlock freedom. This leads
to the proposal of safe refinements, which are those that preserve deadlock
freedom. We exemplify the use of TSRs and (safe) refinements on a small
medication workflow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4271</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4271</id><created>2012-07-18</created><authors><author><keyname>La Torre</keyname><forenames>Salvatore</forenames><affiliation>University of Salerno</affiliation></author><author><keyname>Madhusudan</keyname><forenames>P.</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Parlato</keyname><forenames>Gennaro</forenames><affiliation>University of Southampton</affiliation></author></authors><title>Sequentializing Parameterized Programs</title><categories>cs.LO cs.SE</categories><comments>In Proceedings FIT 2012, arXiv:1207.3485</comments><proxy>EPTCS</proxy><acm-class>D.2.4;F.3.1</acm-class><journal-ref>EPTCS 87, 2012, pp. 34-47</journal-ref><doi>10.4204/EPTCS.87.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit assertion-preserving (reachability preserving) transformations
from parameterized concurrent shared-memory programs, under a k-round
scheduling of processes, to sequential programs. The salient feature of the
sequential program is that it tracks the local variables of only one thread at
any point, and uses only O(k) copies of shared variables (it does not use extra
counters, not even one counter to keep track of the number of threads).
Sequentialization is achieved using the concept of a linear interface that
captures the effect an unbounded block of processes have on the shared state in
a k-round schedule. Our transformation utilizes linear interfaces to
sequentialize the program, and to ensure the sequential program explores only
reachable states and preserves local invariants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4278</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4278</id><created>2012-07-18</created><authors><author><keyname>Karjee</keyname><forenames>Jyotirmoy</forenames></author><author><keyname>Jamadagni</keyname><forenames>H. S</forenames></author></authors><title>Spatio-Temporal Data Correlation with Adaptive Strategies in Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major task of sensor nodes in wireless sensor networks is to
transmit a subset of sensor readings to the sink node estimating a desired data
accuracy. Therefore in this paper, we propose an accuracy model using Steepest
Decent method called Adaptive Data Accuracy (ADA) model which doesn't require
any a priori information of input signal statistics to select an optimal set of
sensor nodes in the network. Moreover we develop another model using LMS filter
called Spatio-Temporal Data Prediction (STDP) model which captures the spatial
and temporal correlation of sensing data to reduce the communication overhead
under data reduction strategies. Finally using STDP model, we illustrate a
mechanism to trace the malicious nodes in the network under extreme physical
environment. Computer simulations illustrate the performance of ADA and STDP
models respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4286</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4286</id><created>2012-07-18</created><updated>2012-09-28</updated><authors><author><keyname>Brauer</keyname><forenames>J&#xf6;rg</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>King</keyname><forenames>Andy</forenames><affiliation>Portcullis Computer Security Limited</affiliation></author></authors><title>Transfer Function Synthesis without Quantifier Elimination</title><categories>cs.LO</categories><comments>37 pages, extended version of ESOP 2011 paper</comments><proxy>LMCS</proxy><acm-class>D.2.4, F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (September
  17, 2012) lmcs:814</journal-ref><doi>10.2168/LMCS-8(3:17)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, transfer functions have been designed manually for each
operation in a program, instruction by instruction. In such a setting, a
transfer function describes the semantics of a single instruction, detailing
how a given abstract input state is mapped to an abstract output state. The net
effect of a sequence of instructions, a basic block, can then be calculated by
composing the transfer functions of the constituent instructions. However,
precision can be improved by applying a single transfer function that captures
the semantics of the block as a whole. Since blocks are program-dependent, this
approach necessitates automation. There has thus been growing interest in
computing transfer functions automatically, most notably using techniques based
on quantifier elimination. Although conceptually elegant, quantifier
elimination inevitably induces a computational bottleneck, which limits the
applicability of these methods to small blocks. This paper contributes a method
for calculating transfer functions that finesses quantifier elimination
altogether, and can thus be seen as a response to this problem. The
practicality of the method is demonstrated by generating transfer functions for
input and output states that are described by linear template constraints,
which include intervals and octagons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4291</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4291</id><created>2012-07-18</created><authors><author><keyname>Iaconesi</keyname><forenames>Salvatore</forenames></author><author><keyname>Persico</keyname><forenames>Oriana</forenames></author></authors><title>ConnectiCity, augmented perception of the city</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>19 pages, 6 figures, presented at Information Visualization 12,
  Montpellier, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we move through cities in our daily lives, we are in a constant state of
transformation of the spaces around us. The form and essence of urban space
directly affects people's behavior, describing in their perception what is
possible or impossible, allowed or prohibited, suggested or advised against. We
are now able to fill and stratify space/time with digital information layers,
completely wrapping cities in a membrane of information and of opportunities
for interaction and communication. Mobile devices, smartphones, wearables,
digital tags, near field communication devices, location based services and
mixed/augmented reality have gone much further in this direction, turning the
world into an essentially read/write, ubiquitous publishing surface. The usage
of mobile devices and ubiquitous technologies alters the understanding of
place. In this process, the definition of (urban) landscape powerfully shifts
from a definition which is purely administrative (e.g.: the borders of the
flower bed in the middle of a roundabout) to one that is multiplied according
to all individuals which experience that location; as a lossless sum of their
perceptions; as a stratification of interpretations and activities which forms
our cognition of space and time. In our research we investigated the
possibilities to use the scenario which sees urban spaces progressively filling
with multiple layers of real-time, ubiquitous, digital information to
conceptualize, design and implement a series of usage scenarios. It is possible
to create multiple layers of narratives which traverse the city and which allow
us to read them in different ways, according to the different strategies and
methodologies enabling us to highlight how cities express points of view on the
environment, culture, economy, transports, energy and politics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4292</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4292</id><created>2012-07-18</created><authors><author><keyname>Almunawar</keyname><forenames>Mohammad Nabil</forenames></author></authors><title>Securing Electronic Transactions to Support E-Commerce</title><categories>cs.CR</categories><comments>14 pages, journal paper</comments><journal-ref>Tinjauan: Policy and Management Review, Vol 4. 2001-2002, pp.
  64-78</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many reports regarding online fraud in varieties media create skepticism for
conducting transactions online, especially through an open network such as the
Internet, which offers no security whatsoever. Therefore, encryption technology
is vitally important to support secure e-commerce on the Internet. Two
well-known encryption representing symmetric and asymmetric cryptosystems as
well as their applications are discussed in this paper. Encryption is a key
technology to secure electronic transactions. However, there are several
challenges such as crytoanalysis or code breaker as well as US export
restrictions on encryption. The future threat is the development of quantum
computers, which makes the existing encryption technology cripple.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4293</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4293</id><created>2012-07-18</created><authors><author><keyname>Br&#xf3;dka</keyname><forenames>Piotr</forenames></author><author><keyname>Kazienko</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Musia&#x142;</keyname><forenames>Katarzyna</forenames></author><author><keyname>Skibicki</keyname><forenames>Krzysztof</forenames></author></authors><title>Analysis of Neighbourhoods in Multi-layered Dynamic Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>16 pages, International Journal of Computational Intelligence Systems</comments><journal-ref>International Journal of Computational Intelligence Systems, Vol.
  5, No. 3 (June, 2012), 582-596</journal-ref><doi>10.1080/18756891.2012.696922</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks existing among employees, customers or users of various IT
systems have become one of the research areas of growing importance. A social
network consists of nodes - social entities and edges linking pairs of nodes.
In regular, one-layered social networks, two nodes - i.e. people are connected
with a single edge whereas in the multi-layered social networks, there may be
many links of different types for a pair of nodes. Nowadays data about people
and their interactions, which exists in all social media, provides information
about many different types of relationships within one network. Analysing this
data one can obtain knowledge not only about the structure and characteristics
of the network but also gain understanding about semantic of human relations.
Are they direct or not? Do people tend to sustain single or multiple relations
with a given person? What types of communication is the most important for
them? Answers to these and more questions enable us to draw conclusions about
semantic of human interactions. Unfortunately, most of the methods used for
social network analysis (SNA) may be applied only to one-layered social
networks. Thus, some new structural measures for multi-layered social networks
are proposed in the paper, in particular: cross-layer clustering coefficient,
cross-layer degree centrality and various versions of multi-layered degree
centralities. Authors also investigated the dynamics of multi-layered
neighbourhood for five different layers within the social network. The
evaluation of the presented concepts on the real-world dataset is presented.
The measures proposed in the paper may directly be used to various methods for
collective classification, in which nodes are assigned to labels according to
their structural input features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4297</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4297</id><created>2012-07-18</created><updated>2012-07-22</updated><authors><author><keyname>Br&#xf3;dka</keyname><forenames>Piotr</forenames></author><author><keyname>Saganowski</keyname><forenames>Stanis&#x142;aw</forenames></author><author><keyname>Kazienko</keyname><forenames>Przemys&#x142;aw</forenames></author></authors><title>GED: the method for group evolution discovery in social networks</title><categories>cs.SI physics.soc-ph</categories><comments>14 pages, Social Network Analysis and Mining</comments><doi>10.1007/s13278-012-0058-8</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The continuous interest in the social network area contributes to the fast
development of this field. The new possibilities of obtaining and storing data
facilitate deeper analysis of the entire network, extracted social groups and
single individuals as well. One of the most interesting research topic is the
dynamics of social groups, it means analysis of group evolution over time.
Having appropriate knowledge and methods for dynamic analysis, one may attempt
to predict the future of the group, and then manage it properly in order to
achieve or change this predicted future according to specific needs. Such
ability would be a powerful tool in the hands of human resource managers,
personnel recruitment, marketing, etc.
  The social group evolution consists of individual events and seven types of
such changes have been identified in the paper: continuing, shrinking, growing,
splitting, merging, dissolving and forming. To enable the analysis of group
evolution a change indicator - inclusion measure was proposed. It has been used
in a new method for exploring the evolution of social groups, called Group
Evolution Discovery (GED). The experimental results of its use together with
the comparison to two well-known algorithms in terms of accuracy, execution
time, flexibility and ease of implementation are also described in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4305</identifier>
 <datestamp>2012-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4305</id><created>2012-07-18</created><updated>2012-09-10</updated><authors><author><keyname>Ny</keyname><forenames>Jerome Le</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Differentially Private Filtering</title><categories>math.OC cs.CR</categories><comments>This version subsumes arXiv:1207.4592v1. arXiv admin note:
  substantial text overlap with arXiv:1207.4592</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emerging systems such as smart grids or intelligent transportation systems
often require end-user applications to continuously send information to
external data aggregators performing monitoring or control tasks. This can
result in an undesirable loss of privacy for the users in exchange of the
benefits provided by the application. Motivated by this trend, this paper
introduces privacy concerns in a system theoretic context, and addresses the
problem of releasing filtered signals that respect the privacy of the user data
streams. Our approach relies on a formal notion of privacy from the database
literature, called differential privacy, which provides strong privacy
guarantees against adversaries with arbitrary side information. Methods are
developed to approximate a given filter by a differentially private version, so
that the distortion introduced by the privacy mechanism is minimized. Two
specific scenarios are considered. First, the notion of differential privacy is
extended to dynamic systems with many participants contributing independent
input signals. Kalman filtering is also discussed in this context, when a
released output signal must preserve differential privacy for the measured
signals or state trajectories of the individual participants. Second,
differentially private mechanisms are described to approximate stable filters
when participants contribute to a single event stream, extending previous work
on differential privacy under continual observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4307</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4307</id><created>2012-07-18</created><authors><author><keyname>Ventura</keyname><forenames>Artur</forenames></author><author><keyname>Diegues</keyname><forenames>Nuno</forenames></author><author><keyname>de Matos</keyname><forenames>David Martins</forenames></author></authors><title>Frame Interpretation and Validation in a Open Domain Dialogue System</title><categories>cs.CL cs.RO</categories><comments>10 pages, 5 figures</comments><acm-class>I.2.7; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our goal in this paper is to establish a means for a dialogue platform to be
able to cope with open domains considering the possible interaction between the
embodied agent and humans. To this end we present an algorithm capable of
processing natural language utterances and validate them against knowledge
structures of an intelligent agent's mind. Our algorithm leverages dialogue
techniques in order to solve ambiguities and acquire knowledge about unknown
entities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4308</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4308</id><created>2012-07-18</created><authors><author><keyname>Buemi</keyname><forenames>Maria E.</forenames></author><author><keyname>Mejail</keyname><forenames>Marta</forenames></author><author><keyname>Jacobo</keyname><forenames>Julio</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>Ramos</keyname><forenames>Heitor S.</forenames></author></authors><title>Assessment of SAR Image Filtering using Adaptive Stack Filters</title><categories>cs.CV</categories><journal-ref>Proceedings 16th Iberoamerican Congress on Pattern Recognition
  (CIARP 2011), Lecture Notes in Computer Science vol. 7042, p. 89--96</journal-ref><doi>10.1007/978-3-642-25085-9_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stack filters are a special case of non-linear filters. They have a good
performance for filtering images with different types of noise while preserving
edges and details. A stack filter decomposes an input image into several binary
images according to a set of thresholds. Each binary image is then filtered by
a Boolean function, which characterizes the filter. Adaptive stack filters can
be designed to be optimal; they are computed from a pair of images consisting
of an ideal noiseless image and its noisy version. In this work we study the
performance of adaptive stack filters when they are applied to Synthetic
Aperture Radar (SAR) images. This is done by evaluating the quality of the
filtered images through the use of suitable image quality indexes and by
measuring the classification accuracy of the resulting images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4318</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4318</id><created>2012-07-18</created><authors><author><keyname>Dieterich</keyname><forenames>Johannes M.</forenames></author><author><keyname>Hartke</keyname><forenames>Bernd</forenames></author></authors><title>Empirical review of standard benchmark functions using evolutionary
  global optimization</title><categories>cs.NE</categories><comments>22 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have employed a recent implementation of genetic algorithms to study a
range of standard benchmark functions for global optimization. It turns out
that some of them are not very useful as challenging test functions, since they
neither allow for a discrimination between different variants of genetic
operators nor exhibit a dimensionality scaling resembling that of real-world
problems, for example that of global structure optimization of atomic and
molecular clusters. The latter properties seem to be simulated better by two
other types of benchmark functions. One type is designed to be deceptive,
exemplified here by Lunacek's function. The other type offers additional
advantages of markedly increased complexity and of broad tunability in search
space characteristics. For the latter type, we use an implementation based on
randomly distributed Gaussians. We advocate the use of the latter types of test
functions for algorithm development and benchmarking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4328</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4328</id><created>2012-07-18</created><authors><author><keyname>Toffano</keyname><forenames>Zeno</forenames></author><author><keyname>Doan</keyname><forenames>Bich-Lien</forenames></author></authors><title>Quantum-like Tests for Contextual Querying</title><categories>cs.IR quant-ph</categories><comments>11 pages, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tests are essential in Information Retrieval (IR), in order to evaluate the
effectiveness of a query. Tests intended to exhibit the sense of words in
con-text were undertaken and linked with Quantum Mechanics (QM). Poll tests
were undertaken on heterogeneous media such as music and polysemy in foreign
languages. Interference effects are shown in the results. Bell inequality was
used leading to a significant spread in the results of the poll tests but
without violating the classical limit. Then an automatic pertinence measure
tool on texts has been developed using the HAL algorithm using an orthonormal
vector decomposition model. In this case the spread in the values can lead to
the violation of the Bell inequality even beyond Cirel'son bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4343</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4343</id><created>2012-07-18</created><authors><author><keyname>Bonik</keyname><forenames>Gregory</forenames></author><author><keyname>Goreinov</keyname><forenames>Sergei</forenames></author><author><keyname>Zamarashkin</keyname><forenames>Nickolai</forenames></author></authors><title>Construction and analysis of polar and concatenated polar codes:
  practical approach</title><categories>cs.IT math.IT</categories><comments>17 pages</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two problems related to polar codes. First is the problem of
polar codes construction and analysis of their performance without Monte-Carlo
method. The formulas proposed are the same as those in [Mori-Tanaka], yet we
believe that our approach is original and has clear advantages. The resulting
computational procedure is presented in a fast algorithm form which can be
easily implemented on a computer. Secondly, we present an original method of
construction of concatenated codes based on polar codes. We give an algorithm
for construction of such codes and present numerical experiments showing
significant performance improvement with respect to original polar codes
proposed by Ar\i kan. We use the term \emph{concatenated code} not in its
classical sense (e.g. [Forney]). However we believe that our usage is quite
appropriate for the exploited construction. Further, we solve the optimization
problem of choosing codes minimizing the block error of the whole concatenated
code under the constraint of its fixed rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4366</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4366</id><created>2012-07-18</created><authors><author><keyname>Nutov</keyname><forenames>Zeev</forenames></author></authors><title>Approximating minimum-cost edge-covers of crossing biset-families</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An ordered pair $\hat{S}=(S,S^+)$ of subsets of $V$ is called a {\em biset}
if $S \subseteq S^+$; $(V-S^+,V-S)$ is the co-biset of $\hat{S}$. Two bisets
$\hat{X},\hat{Y}$ intersect if $X \cap Y \neq \emptyset$ and cross if both $X
\cap Y \neq \emptyset$ and $X^+ \cup Y^+ \neq V$. The intersection and the
union of two bisets $\hat{X},\hat{Y}$ is defined by $\hat{X} \cap \hat{Y} = (X
\cap Y, X^+ \cap Y^+)$ and $\hat{X} \cup \hat{Y} = (X \cup Y,X^+ \cup Y^+)$. A
biset-family ${\cal F}$ is crossing (intersecting) if $\hat{X} \cap \hat{Y},
\hat{X} \cup \hat{Y} \in {\cal F}$ for any $\hat{X},\hat{Y} \in {\cal F}$ that
cross (intersect). A directed edge covers a biset $\hat{S}$ if it goes from $S$
to $V-S^+$. We consider the problem of covering a crossing biset-family ${\cal
F}$ by a minimum-cost set of directed edges. While for intersecting ${\cal F}$,
a standard primal-dual algorithm computes an optimal solution, the
approximability of the case of crossing ${\cal F}$ is not yet understood, as it
includes several NP-hard problems, for which a poly-logarithmic approximation
was discovered only recently. Let us say that a biset-family ${\cal F}$ is
$k$-regular if $\hat{X} \cap \hat{Y}, \hat{X} \cup \hat{Y} \in {\cal F}$ for
any $\hat{X},\hat{Y} \in {\cal F}$ with $|V-(X \cup Y)| \geq k+1$ that
intersect. In this paper we obtain an $O(\log |V|)$-approximation algorithm for
arbitrary crossing ${\cal F}$; if in addition both ${\cal F}$ and the family of
co-bisets of ${\cal F}$ are $k$-regular, our ratios are: $O(\log
\frac{|V|}{|V|-k})$ if $|S^+ \setminus S|=k$ for all $\hat{S} \in {\cal F}$,
and $O(\frac{|V|}{|V|-k} \log \frac{|V|}{|V|-k})$ if $|S^+ \setminus S| \leq k$
for all $\hat{S} \in {\cal F}$. Using these generic algorithms, we derive
approximation algorithms for some network design problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4371</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4371</id><created>2012-07-18</created><authors><author><keyname>Berberich</keyname><forenames>Klaus</forenames></author><author><keyname>Bedathur</keyname><forenames>Srikanta</forenames></author></authors><title>Computing n-Gram Statistics in MapReduce</title><categories>cs.IR cs.DB cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistics about n-grams (i.e., sequences of contiguous words or other tokens
in text documents or other string data) are an important building block in
information retrieval and natural language processing. In this work, we study
how n-gram statistics, optionally restricted by a maximum n-gram length and
minimum collection frequency, can be computed efficiently harnessing MapReduce
for distributed data processing. We describe different algorithms, ranging from
an extension of word counting, via methods based on the Apriori principle, to a
novel method Suffix-\sigma that relies on sorting and aggregating suffixes. We
examine possible extensions of our method to support the notions of
maximality/closedness and to perform aggregations beyond occurrence counting.
Assuming Hadoop as a concrete MapReduce implementation, we provide insights on
an efficient implementation of the methods. Extensive experiments on The New
York Times Annotated Corpus and ClueWeb09 expose the relative benefits and
trade-offs of the methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4372</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4372</id><created>2012-07-18</created><updated>2012-09-04</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Sinop</keyname><forenames>Ali Kemal</forenames></author></authors><title>Faster SDP hierarchy solvers for local rounding algorithms</title><categories>cs.DS</categories><comments>30 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convex relaxations based on different hierarchies of linear/semi-definite
programs have been used recently to devise approximation algorithms for various
optimization problems. The approximation guarantee of these algorithms improves
with the number of {\em rounds} $r$ in the hierarchy, though the complexity of
solving (or even writing down the solution for) the $r$'th level program grows
as $n^{\Omega(r)}$ where $n$ is the input size.
  In this work, we observe that many of these algorithms are based on {\em
local} rounding procedures that only use a small part of the SDP solution (of
size $n^{O(1)} 2^{O(r)}$ instead of $n^{\Omega(r)}$). We give an algorithm to
find the requisite portion in time polynomial in its size. The challenge in
achieving this is that the required portion of the solution is not fixed a
priori but depends on other parts of the solution, sometimes in a complicated
iterative manner.
  Our solver leads to $n^{O(1)} 2^{O(r)}$ time algorithms to obtain the same
guarantees in many cases as the earlier $n^{O(r)}$ time algorithms based on $r$
rounds of the Lasserre hierarchy. In particular, guarantees based on $O(\log
n)$ rounds can be realized in polynomial time.
  We develop and describe our algorithm in a fairly general abstract framework.
The main technical tool in our work, which might be of independent interest in
convex optimization, is an efficient ellipsoid algorithm based separation
oracle for convex programs that can output a {\em certificate of infeasibility
with restricted support}. This is used in a recursive manner to find a sequence
of consistent points in nested convex bodies that &quot;fools&quot; local rounding
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4382</identifier>
 <datestamp>2012-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4382</id><created>2012-07-18</created><updated>2012-09-25</updated><authors><author><keyname>Wei</keyname><forenames>Zhewei</forenames></author><author><keyname>Yi</keyname><forenames>Ke</forenames></author></authors><title>The Space Complexity of 2-Dimensional Approximate Range Counting</title><categories>cs.DS</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of 2-dimensional orthogonal range counting with additive
error. Given a set $P$ of $n$ points drawn from an $n\times n$ grid and an
error parameter $\eps$, the goal is to build a data structure, such that for
any orthogonal range $R$, the data structure can return the number of points in
$P\cap R$ with additive error $\eps n$. A well-known solution for this problem
is the {\em $\eps$-approximation}. Informally speaking, an $\eps$-approximation
of $P$ is a subset $A\subseteq P$ that allows us to estimate the number of
points in $P\cap R$ by counting the number of points in $A\cap R$. It is known
that an $\eps$-approximation of size $O(\frac{1}{\eps} \log^{2.5}
\frac{1}{\eps})$ exists for any $P$ with respect to orthogonal ranges, and the
best lower bound is $\Omega(\frac{1}{\eps} \log \frac{1}{\eps})$.
  The $\eps$-approximation is a rather restricted data structure, as we are not
allowed to store any information other than the coordinates of a subset of
points in $P$. In this paper, we explore what can be achieved without any
restriction on the data structure. We first describe a data structure that uses
$O(\frac{1}{\eps} \log \frac{1} {\eps} \log\log \frac{1}{\eps} \log n)$ bits
that answers queries with error $\eps n$. We then prove a lower bound that any
data structure that answers queries with error $O(\log n)$ must use
$\Omega(n\log n)$ bits. This lower bound has two consequences: 1) answering
queries with error $O(\log n)$ is as hard as answering the queries exactly; and
2) our upper bound cannot be improved in general by more than an $O(\log \log
\frac{1}{\eps})$ factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4383</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4383</id><created>2012-07-18</created><authors><author><keyname>Wei</keyname><forenames>Zhewei</forenames></author><author><keyname>Yi</keyname><forenames>Ke</forenames></author></authors><title>Equivalence between Priority Queues and Sorting in External Memory</title><categories>cs.DS</categories><comments>11 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A priority queue is a fundamental data structure that maintains a dynamic
ordered set of keys and supports the followig basic operations: insertion of a
key, deletion of a key, and finding the smallest key. The complexity of the
priority queue is closely related to that of sorting: A priority queue can be
used to implement a sorting algorithm trivially. Thorup
\cite{thorup2007equivalence} proved that the converse is also true in the RAM
model. In particular, he designed a priority queue that uses the sorting
algorithm as a black box, such that the per-operation cost of the priority
queue is asymptotically the same as the per-key cost of sorting. In this paper,
we prove an analogous result in the external memory model, showing that
priority queues are computationally equivalent to sorting in external memory,
under some mild assumptions. The reduction provides a possibility for proving
lower bounds for external sorting via showing a lower bound for priority
queues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4393</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4393</id><created>2012-07-18</created><authors><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Garcia</keyname><forenames>Alfredo</forenames></author><author><keyname>Barrera</keyname><forenames>Jorge</forenames></author><author><keyname>Wilson</keyname><forenames>Stephen G.</forenames></author></authors><title>Joint Access Point Selection and Power Allocation for Uplink Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>Revised and Resubmitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the distributed uplink resource allocation problem in a
multi-carrier wireless network with multiple access points (APs). Each mobile
user can optimize its own transmission rate by selecting a suitable AP and by
controlling its transmit power. Our objective is to devise suitable algorithms
by which mobile users can jointly perform these tasks in a distributed manner.
Our approach relies on a game theoretic formulation of the joint power control
and AP selection problem. In the proposed game, each user is a player with an
associated strategy containing a discrete variable (the AP selection decision)
and a continuous vector (the power allocation among multiple channels). We
provide characterizations of the Nash Equilibrium of the proposed game, and
present a set of novel algorithms that allow the users to efficiently optimize
their rates. Finally, we study the properties of the proposed algorithms as
well as their performance via extensive simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4402</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4402</id><created>2012-07-18</created><updated>2015-06-03</updated><authors><author><keyname>Erd&#x151;s</keyname><forenames>P&#xe9;ter L.</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author><author><keyname>Tardif</keyname><forenames>Claude</forenames></author><author><keyname>Tardos</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Regular families of forests, antichains and duality pairs of relational
  structures</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Homomorphism duality pairs play crucial role in the theory of relational
structures and in the Constraint Satisfaction Problem. The case where both
classes are finite is fully characterized. The case when both side are infinite
seems to be very complex. It is also known that no finite-infinite duality pair
is possible if we make the additional restriction that both classes are
antichains. In this paper we characterize the infinite-finite antichain
dualities and infinite-finite dualities with trees or forest on the left hand
side. This work builds on our earlier papers that gave several examples of
infinite-finite antichain duality pairs of directed graphs and a complete
characterization for caterpillar dualities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4404</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4404</id><created>2012-07-18</created><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Mesnil</keyname><forenames>Gr&#xe9;goire</forenames></author><author><keyname>Dauphin</keyname><forenames>Yann</forenames></author><author><keyname>Rifai</keyname><forenames>Salah</forenames></author></authors><title>Better Mixing via Deep Representations</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has previously been hypothesized, and supported with some experimental
evidence, that deeper representations, when well trained, tend to do a better
job at disentangling the underlying factors of variation. We study the
following related conjecture: better representations, in the sense of better
disentangling, can be exploited to produce faster-mixing Markov chains.
Consequently, mixing would be more efficient at higher levels of
representation. To better understand why and how this is happening, we propose
a secondary conjecture: the higher-level samples fill more uniformly the space
they occupy and the high-density manifolds tend to unfold when represented at
higher levels. The paper discusses these hypotheses and tests them
experimentally through visualization and measurements of mixing and
interpolating between samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4415</identifier>
 <datestamp>2015-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4415</id><created>2012-07-18</created><updated>2015-09-09</updated><authors><author><keyname>Keszegh</keyname><forenames>Bal&#xe1;zs</forenames></author><author><keyname>Lemons</keyname><forenames>Nathan</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Online and quasi-online colorings of wedges and intervals</title><categories>math.CO cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider proper online colorings of hypergraphs defined by geometric
regions. We prove that there is an online coloring algorithm that colors $N$
intervals of the real line using $\Theta(\log N/k)$ colors such that for every
point $p$, contained in at least $k$ intervals, not all the intervals
containing $p$ have the same color. We also prove the corresponding result
about online coloring a family of wedges (quadrants) in the plane that are the
translates of a given fixed wedge. These results contrast the results of the
first and third author showing that in the quasi-online setting 12 colors are
enough to color wedges (independent of $N$ and $k$). We also consider
quasi-online coloring of intervals. In all cases we present efficient coloring
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4417</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4417</id><created>2012-07-18</created><updated>2013-01-19</updated><authors><author><keyname>Liu</keyname><forenames>Jingwei</forenames></author><author><keyname>Xu</keyname><forenames>Meizhi</forenames></author></authors><title>Penalty Constraints and Kernelization of M-Estimation Based Fuzzy
  C-Means</title><categories>cs.CV stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A framework of M-estimation based fuzzy C-means clustering (MFCM) algorithm
is proposed with iterative reweighted least squares (IRLS) algorithm, and
penalty constraint and kernelization extensions of MFCM algorithms are also
developed. Introducing penalty information to the object functions of MFCM
algorithms, the spatially constrained fuzzy C-means (SFCM) is extended to
penalty constraints MFCM algorithms(abbr. pMFCM).Substituting the Euclidean
distance with kernel method, the MFCM and pMFCM algorithms are extended to
kernelized MFCM (abbr. KMFCM) and kernelized pMFCM (abbr.pKMFCM) algorithms.
The performances of MFCM, pMFCM, KMFCM and pKMFCM algorithms are evaluated in
three tasks: pattern recognition on 10 standard data sets from UCI Machine
Learning databases, noise image segmentation performances on a synthetic image,
a magnetic resonance brain image (MRI), and image segmentation of a standard
images from Berkeley Segmentation Dataset and Benchmark. The experimental
results demonstrate the effectiveness of our proposed algorithms in pattern
recognition and image segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4420</identifier>
 <datestamp>2014-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4420</id><created>2012-07-18</created><updated>2014-04-23</updated><authors><author><keyname>Dai</keyname><forenames>Liang</forenames></author><author><keyname>Pelckmans</keyname><forenames>Kristiaan</forenames></author></authors><title>On the Nuclear Norm heuristic for a Hankel matrix Recovery Problem</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note addresses the question if and why the nuclear norm heuristic can
recover an impulse response generated by a stable single-real-pole system, if
elements of the upper-triangle of the associated Hankel matrix were given.
  Since the setting is deterministic, theories based on stochastic assumptions
for low-rank matrix recovery do not apply here. A 'certificate' which
guarantees the completion is constructed by exploring the structural
information of the hidden matrix. Experimental results and discussions
regarding the nuclear norm heuristic applied to a more general setting are also
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4421</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4421</id><created>2012-07-18</created><authors><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Negahban</keyname><forenames>Sahand</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Stochastic optimization and sparse statistical recovery: An optimal
  algorithm for high dimensions</title><categories>stat.ML cs.LG math.OC</categories><comments>2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop and analyze stochastic optimization algorithms for problems in
which the expected loss is strongly convex, and the optimum is (approximately)
sparse. Previous approaches are able to exploit only one of these two
structures, yielding an $\order(\pdim/T)$ convergence rate for strongly convex
objectives in $\pdim$ dimensions, and an $\order(\sqrt{(\spindex \log
\pdim)/T})$ convergence rate when the optimum is $\spindex$-sparse. Our
algorithm is based on successively solving a series of $\ell_1$-regularized
optimization problems using Nesterov's dual averaging algorithm. We establish
that the error of our solution after $T$ iterations is at most
$\order((\spindex \log\pdim)/T)$, with natural extensions to approximate
sparsity. Our results apply to locally Lipschitz losses including the logistic,
exponential, hinge and least-squares losses. By recourse to statistical minimax
results, we show that our convergence rates are optimal up to multiplicative
constant factors. The effectiveness of our approach is also confirmed in
numerical simulations, in which we compare to several baselines on a
least-squares regression problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4432</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4432</id><created>2012-07-18</created><authors><author><keyname>Marinkovic</keyname><forenames>Vesna</forenames></author><author><keyname>Janicic</keyname><forenames>Predrag</forenames></author></authors><title>Towards Understanding Triangle Construction Problems</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Straightedge and compass construction problems are one of the oldest and most
challenging problems in elementary mathematics. The central challenge, for a
human or for a computer program, in solving construction problems is a huge
search space. In this paper we analyze one family of triangle construction
problems, aiming at detecting a small core of the underlying geometry
knowledge. The analysis leads to a small set of needed definitions, lemmas and
primitive construction steps, and consequently, to a simple algorithm for
automated solving of problems from this family. The same approach can be
applied to other families of construction problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4442</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4442</id><created>2012-07-18</created><authors><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames></author></authors><title>Complex-network analysis of combinatorial spaces: The NK landscape case</title><categories>cond-mat.stat-mech cs.NE nlin.AO</categories><comments>arXiv admin note: substantial text overlap with arXiv:0810.3492,
  arXiv:0810.3484</comments><proxy>ccsd</proxy><journal-ref>Physical Review E: Statistical, Nonlinear, and Soft Matter Physics
  78, 6 (2008) 066114</journal-ref><doi>10.1103/PhysRevE.78.066114</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a network characterization of combinatorial fitness landscapes by
adapting the notion of inherent networks proposed for energy surfaces. We use
the well-known family of NK landscapes as an example. In our case the inherent
network is the graph whose vertices represent the local maxima in the
landscape, and the edges account for the transition probabilities between their
corresponding basins of attraction. We exhaustively extracted such networks on
representative NK landscape instances, and performed a statistical
characterization of their properties. We found that most of these network
properties are related to the search difficulty on the underlying NK landscapes
with varying values of K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4445</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4445</id><created>2012-07-18</created><authors><author><keyname>Daolio</keyname><forenames>Fabio</forenames><affiliation>ISI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames></author></authors><title>Communities of Minima in Local Optima Networks of Combinatorial Spaces</title><categories>cs.NE cs.AI</categories><proxy>ccsd</proxy><journal-ref>Physica A: Statistical Mechanics and its Applications 390, 9
  (2011) 1684 - 1694</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present a new methodology to study the structure of the
configuration spaces of hard combinatorial problems. It consists in building
the network that has as nodes the locally optimal configurations and as edges
the weighted oriented transitions between their basins of attraction. We apply
the approach to the detection of communities in the optima networks produced by
two different classes of instances of a hard combinatorial optimization
problem: the quadratic assignment problem (QAP). We provide evidence indicating
that the two problem instance classes give rise to very different configuration
spaces. For the so-called real-like class, the networks possess a clear modular
structure, while the optima networks belonging to the class of random uniform
instances are less well partitionable into clusters. This is convincingly
supported by using several statistical tests. Finally, we shortly discuss the
consequences of the findings for heuristically searching the corresponding
problem spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4448</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4448</id><created>2012-07-18</created><authors><author><keyname>Derbel</keyname><forenames>Bilel</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>DAMS: Distributed Adaptive Metaheuristic Selection</title><categories>cs.NE cs.AI</categories><proxy>ccsd</proxy><journal-ref>Genetic And Evolutionary Computation Conference, Dublin : Ireland
  (2011)</journal-ref><doi>10.1145/2001576.2001839</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a distributed generic algorithm called DAMS dedicated to adaptive
optimization in distributed environments. Given a set of metaheuristic, the
goal of DAMS is to coordinate their local execution on distributed nodes in
order to optimize the global performance of the distributed system. DAMS is
based on three-layer architecture allowing node to decide distributively what
local information to communicate, and what metaheuristic to apply while the
optimization process is in progress. The adaptive features of DAMS are first
addressed in a very general setting. A specific DAMS called SBM is then
described and analyzed from both a parallel and an adaptive point of view. SBM
is a simple, yet efficient, adaptive distributed algorithm using an
exploitation component allowing nodes to select the metaheuristic with the best
locally observed performance, and an exploration component allowing nodes to
detect the metaheuristic with the actual best performance. The efficiency of
BSM-DAMS is demonstrated through experimentations and comparisons with other
adaptive strategies (sequential and distributed).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4450</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4450</id><created>2012-07-18</created><authors><author><keyname>Marmion</keyname><forenames>Marie-Eleonore</forenames><affiliation>LIFL</affiliation></author><author><keyname>Dhaenens</keyname><forenames>Clarisse</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Jourdan</keyname><forenames>Laetitia</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Liefooghe</keyname><forenames>Arnaud</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>NILS: a Neutrality-based Iterated Local Search and its application to
  Flowshop Scheduling</title><categories>cs.NE cs.AI</categories><proxy>ccsd</proxy><journal-ref>11th European Conference on Evolutionary Computation in
  Combinatorial Optimisation, Turino : Italy (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new methodology that exploits specific characteristics
from the fitness landscape. In particular, we are interested in the property of
neutrality, that deals with the fact that the same fitness value is assigned to
numerous solutions from the search space. Many combinatorial optimization
problems share this property, that is generally very inhibiting for local
search algorithms. A neutrality-based iterated local search, that allows
neutral walks to move on the plateaus, is proposed and experimented on a
permutation flowshop scheduling problem with the aim of minimizing the
makespan. Our experiments show that the proposed approach is able to find
improving solutions compared with a classical iterated local search. Moreover,
the tradeoff between the exploitation of neutrality and the exploration of new
parts of the search space is deeply analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4451</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4451</id><created>2012-07-18</created><authors><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Liefooghe</keyname><forenames>Arnaud</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Dhaenens</keyname><forenames>Clarisse</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author></authors><title>Set-based Multiobjective Fitness Landscapes: A Preliminary Study</title><categories>cs.NE cs.AI</categories><proxy>ccsd</proxy><journal-ref>Genetic And Evolutionary Computation Conference, Dublin : Ireland
  (2011)</journal-ref><doi>10.1145/2001576.2001681</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fitness landscape analysis aims to understand the geometry of a given
optimization problem in order to design more efficient search algorithms.
However, there is a very little knowledge on the landscape of multiobjective
problems. In this work, following a recent proposal by Zitzler et al. (2010),
we consider multiobjective optimization as a set problem. Then, we give a
general definition of set-based multiobjective fitness landscapes. An
experimental set-based fitness landscape analysis is conducted on the
multiobjective NK-landscapes with objective correlation. The aim is to adapt
and to enhance the comprehensive design of set-based multiobjective search
approaches, motivated by an a priori analysis of the corresponding set problem
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4452</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4452</id><created>2012-07-18</created><authors><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Liefooghe</keyname><forenames>Arnaud</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Jourdan</keyname><forenames>Laetitia</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Dhaenens</keyname><forenames>Clarisse</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author></authors><title>Pareto Local Optima of Multiobjective NK-Landscapes with Correlated
  Objectives</title><categories>cs.NE cs.AI</categories><proxy>ccsd</proxy><journal-ref>11th European Conference on Evolutionary Computation in
  Combinatorial Optimisation, Turino : Italy (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we conduct a fitness landscape analysis for multiobjective
combinatorial optimization, based on the local optima of multiobjective
NK-landscapes with objective correlation. In single-objective optimization, it
has become clear that local optima have a strong impact on the performance of
metaheuristics. Here, we propose an extension to the multiobjective case, based
on the Pareto dominance. We study the co-influence of the problem dimension,
the degree of non-linearity, the number of objectives and the correlation
degree between objective functions on the number of Pareto local optima.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4455</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4455</id><created>2012-07-18</created><authors><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author></authors><title>First-improvement vs. Best-improvement Local Optima Networks of NK
  Landscapes</title><categories>cs.NE cs.AI</categories><proxy>ccsd</proxy><journal-ref>11th International Conference on Parallel Problem Solving From
  Nature, Krakow : Poland (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends a recently proposed model for combinatorial landscapes:
Local Optima Networks (LON), to incorporate a first-improvement (greedy-ascent)
hill-climbing algorithm, instead of a best-improvement (steepest-ascent) one,
for the definition and extraction of the basins of attraction of the landscape
optima. A statistical analysis comparing best and first improvement network
models for a set of NK landscapes, is presented and discussed. Our results
suggest structural differences between the two models with respect to both the
network connectivity, and the nature of the basins of attraction. The impact of
these differences in the behavior of search heuristics based on first and best
improvement local search is thoroughly discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4462</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4462</id><created>2012-07-18</created><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>A Quantum Copy-Protection Scheme with Authentication</title><categories>quant-ph cs.IT math.IT</categories><comments>24 pages, 19 figures, Journal-ref: Int. J. Internet Technology and
  Secured Transactions (IJITST, 2009), presented in part at IEEE ICITST-2009,
  IEEE 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a quantum copy-protection system which protects classical
information in the form of non-orthogonal quantum states. The decryption of the
stored information is not possible in the classical representation and the
decryption mechanism of data qubits is realized by secret unitary rotations. We
define an authentication method for the proposed copy-protection scheme and
analyse the success probabilities of the authentication process. A possible
experimental realization of the scheme is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4463</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4463</id><created>2012-07-18</created><authors><author><keyname>Liu</keyname><forenames>Jingwei</forenames></author></authors><title>Protein Function Prediction Based on Kernel Logistic Regression with
  2-order Graphic Neighbor Information</title><categories>q-bio.QM cs.LG q-bio.MN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To enhance the accuracy of protein-protein interaction function prediction, a
2-order graphic neighbor information feature extraction method based on
undirected simple graph is proposed in this paper, which extends the 1-order
graphic neighbor featureextraction method. And the chi-square test statistical
method is also involved in feature combination. To demonstrate the
effectiveness of our 2-order graphic neighbor feature, four logistic regression
models (logistic regression (abbrev. LR), diffusion kernel logistic regression
(abbrev. DKLR), polynomial kernel logistic regression (abbrev. PKLR), and
radial basis function (RBF) based kernel logistic regression (abbrev. RBF KLR))
are investigated on the two feature sets. The experimental results of protein
function prediction of Yeast Proteome Database (YPD) using the the
protein-protein interaction data of Munich Information Center for Protein
Sequences (MIPS) show that 2-order graphic neighbor information of proteins can
significantly improve the average overall percentage of protein function
prediction especially with RBF KLR. And, with a new 5-top chi-square feature
combination method, RBF KLR can achieve 99.05% average overall percentage on
2-order neighbor feature combination set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4464</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4464</id><created>2012-07-18</created><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>An Improvement in Quantum Fourier Transform</title><categories>quant-ph cs.IT math.IT</categories><comments>30 pages, 10 figures, Journal-ref: Journal of Circuits, Systems, and
  Computers (JCSC), World Scientific, Print ISSN: 0218-1266, Online ISSN:
  1793-6454; 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Singular Value Decomposition (SVD) is one of the most useful techniques for
analyzing data in linear algebra. SVD decomposes a rectangular real or complex
matrix into two orthogonal matrices and one diagonal matrix. In this work we
introduce a new approach to improve the preciseness of the standard Quantum
Fourier Transform. The presented Quantum-SVD algorithm is based on the singular
value decomposition mechanism. While the complexity of the proposed scheme is
the same as the standard Quantum Fourier Transform, the precision of the
Quantum-SVD approach is some orders higher. The Quantum-SVD approach also
exploits the benefits of quantum searching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4467</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4467</id><created>2012-07-18</created><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Information Geometric Security Analysis of Differential Phase Shift
  Quantum Key Distribution Protocol</title><categories>quant-ph cs.IT math.IT</categories><comments>42 pages, 34 figures, Journal-ref: Security and Communication
  Networks (John Wiley &amp; Sons, 2012), presented in part at the IEEE Int.
  Conference on Network and Service Security (IEEE N2S 2009)</comments><doi>10.1002/sec.542</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the information-theoretical security of the Differential
Phase Shift (DPS) Quantum Key Distribution (QKD) protocol, using efficient
computational information geometric algorithms. The DPS QKD protocol was
introduced for practical reasons, since the earlier QKD schemes were too
complicated to implement in practice. The DPS QKD protocol can be an integrated
part of current network security applications, hence it's practical
implementation is much easier with the current optical devices and optical
networks. The proposed algorithm could be a very valuable tool to answer the
still open questions related to the security bounds of the DPS QKD protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4474</identifier>
 <datestamp>2013-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4474</id><created>2012-07-17</created><updated>2013-02-18</updated><authors><author><keyname>Alimguzhin</keyname><forenames>Vadim</forenames></author><author><keyname>Mari</keyname><forenames>Federico</forenames></author><author><keyname>Melatti</keyname><forenames>Igor</forenames></author><author><keyname>Salvo</keyname><forenames>Ivano</forenames></author><author><keyname>Tronci</keyname><forenames>Enrico</forenames></author></authors><title>On Model Based Synthesis of Embedded Control Software</title><categories>cs.SE cs.SY</categories><comments>Accepted for publication by EMSOFT 2012. arXiv admin note:
  substantial text overlap with arXiv:1107.5638,arXiv:1207.4098</comments><acm-class>D.2.2; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many Embedded Systems are indeed Software Based Control Systems (SBCSs), that
is control systems whose controller consists of control software running on a
microcontroller device. This motivates investigation on Formal Model Based
Design approaches for control software. Given the formal model of a plant as a
Discrete Time Linear Hybrid System and the implementation specifications (that
is, number of bits in the Analog-to-Digital (AD) conversion)
correct-by-construction control software can be automatically generated from
System Level Formal Specifications of the closed loop system (that is, safety
and liveness requirements), by computing a suitable finite abstraction of the
plant.
  With respect to given implementation specifications, the automatically
generated code implements a time optimal control strategy (in terms of set-up
time), has a Worst Case Execution Time linear in the number of AD bits $b$, but
unfortunately, its size grows exponentially with respect to $b$. In many
embedded systems, there are severe restrictions on the computational resources
(such as memory or computational power) available to microcontroller devices.
  This paper addresses model based synthesis of control software by trading
system level non-functional requirements (such us optimal set-up time, ripple)
with software non-functional requirements (its footprint). Our experimental
results show the effectiveness of our approach: for the inverted pendulum
benchmark, by using a quantization schema with 12 bits, the size of the small
controller is less than 6% of the size of the time optimal one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4491</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4491</id><created>2012-07-18</created><updated>2012-08-27</updated><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Algorithmic Superactivation of Asymptotic Quantum Capacity of
  Zero-Capacity Quantum Channels</title><categories>quant-ph cs.IT math.IT</categories><comments>35 pages, 17 figures, Journal-ref: Information Sciences (Elsevier,
  2012), presented in part at Quantum Information Processing 2012 (QIP2012),
  v2: minor changes, v3: published version; Information Sciences, Elsevier,
  ISSN: 0020-0255; 2012</comments><doi>10.1016/j.ins.2012.08.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The superactivation of zero-capacity quantum channels makes it possible to
use two zero-capacity quantum channels with a positive joint capacity for their
output. Currently, we have no theoretical background to describe all possible
combinations of superactive zero-capacity channels; hence, there may be many
other possible combinations. In practice, to discover such superactive
zero-capacity channel-pairs, we must analyze an extremely large set of possible
quantum states, channel models, and channel probabilities. There is still no
extremely efficient algorithmic tool for this purpose. This paper shows an
efficient algorithmical method of finding such combinations. Our method can be
a very valuable tool for improving the results of fault-tolerant quantum
computation and possible communication techniques over very noisy quantum
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4497</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4497</id><created>2012-07-18</created><authors><author><keyname>Ahlbach</keyname><forenames>Connor</forenames></author><author><keyname>Usatine</keyname><forenames>Jeremy</forenames></author><author><keyname>Pippenger</keyname><forenames>Nicholas</forenames></author></authors><title>Efficient Algorithms for Zeckendorf Arithmetic</title><categories>cs.DS math.CO</categories><comments>i+6 pp</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of addition and subtraction using the Zeckendorf
representation of integers. We show that both operations can be performed in
linear time; in fact they can be performed by combinational logic networks with
linear size and logarithmic depth. The implications of these results for
multiplication, division and square-root extraction are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4498</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4498</id><created>2012-07-18</created><updated>2013-07-12</updated><authors><author><keyname>Biton</keyname><forenames>Erez</forenames></author><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author><author><keyname>Reina</keyname><forenames>Guy</forenames></author><author><keyname>Gurewitz</keyname><forenames>Omer</forenames></author></authors><title>Distributed Inter-Cell Interference Mitigation Via Joint Scheduling and
  Power Control Under Noise Rise Constraints</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the problem of joint uplink scheduling and power allocation. Being
inherent to almost any wireless system, this resource allocation problem has
received extensive attention. Yet, most common techniques either adopt
classical power control, in which mobile stations are received with the same
Signal-to-Interference-plus-Noise Ratio, or use centralized schemes, in which
base stations coordinate their allocations.
  In this work, we suggest a novel scheduling approach in which each base
station, besides allocating the time and frequency according to given
constraints, also manages its uplink power budget such that the aggregate
interference, &quot;Noise Rise&quot;, caused by its subscribers at the neighboring cells
is bounded. Our suggested scheme is distributed, requiring neither coordination
nor message exchange.
  We rigorously define the allocation problem under noise rise constraints,
give the optimal solution and derive an efficient iterative algorithm to
achieve it. We then discuss a relaxed problem, where the noise rise is
constrained separately for each sub-channel or resource unit. While
sub-optimal, this view renders the scheduling and power allocation problems
separate, yielding an even simpler and more efficient solution, while the
essence of the scheme is kept. Via extensive simulations, we show that the
suggested approach increases overall performance dramatically, with the same
level of fairness and power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4502</identifier>
 <datestamp>2013-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4502</id><created>2012-07-18</created><updated>2013-02-01</updated><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Pilot Quantum Error Correction for Global-Scale Quantum Communications</title><categories>quant-ph cs.IT math.IT</categories><comments>50 pages, 2 tables, 17 figures, minor improvements. Journal-ref: IEEE
  Symposium on Quantum Computing and Computational Intelligence 2013 (IEEE QCCI
  2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real global-scale quantum communications and quantum key distribution systems
cannot be implemented by the current fiber and free-space links. These links
have high attenuation, low polarization-preserving capability or extreme
sensitivity to the environment. A potential solution to the problem is the
space-earth quantum channels. These channels have no absorption since the
signal states are propagated in empty space, however a small fraction of these
channels is in the atmosphere, which causes slight depolarizing effect.
Furthermore, the relative motion of the ground station and the satellite causes
a rotation in the polarization of the quantum states. In the current approaches
to compensate for these types of polarization errors, high computational costs
and extra physical apparatuses are required. Here we introduce a novel approach
which breaks with the traditional views of currently developed quantum-error
correction schemes. The proposed quantum error-correction technique can be
applied to fix the polarization errors which are critical in space-earth
quantum communication systems. Moreover, the channel coding scheme provides
capacity-achieving communication over slightly depolarizing space-earth
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4525</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4525</id><created>2012-07-18</created><authors><author><keyname>Lacoste-Julien</keyname><forenames>Simon</forenames></author><author><keyname>Palla</keyname><forenames>Konstantina</forenames></author><author><keyname>Davies</keyname><forenames>Alex</forenames></author><author><keyname>Kasneci</keyname><forenames>Gjergji</forenames></author><author><keyname>Graepel</keyname><forenames>Thore</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>SiGMa: Simple Greedy Matching for Aligning Large Knowledge Bases</title><categories>cs.AI cs.DB cs.IR</categories><comments>10 pages + 2 pages appendix; 5 figures -- initial preprint</comments><acm-class>I.2.4; H.3.4; D.2.12</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet has enabled the creation of a growing number of large-scale
knowledge bases in a variety of domains containing complementary information.
Tools for automatically aligning these knowledge bases would make it possible
to unify many sources of structured knowledge and answer complex queries.
However, the efficient alignment of large-scale knowledge bases still poses a
considerable challenge. Here, we present Simple Greedy Matching (SiGMa), a
simple algorithm for aligning knowledge bases with millions of entities and
facts. SiGMa is an iterative propagation algorithm which leverages both the
structural information from the relationship graph as well as flexible
similarity measures between entity properties in a greedy local search, thus
making it scalable. Despite its greedy nature, our experiments indicate that
SiGMa can efficiently match some of the world's largest knowledge bases with
high precision. We provide additional experiments on benchmark datasets which
demonstrate that SiGMa can outperform state-of-the-art approaches both in
accuracy and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4526</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4526</id><created>2012-07-18</created><authors><author><keyname>Vargas</keyname><forenames>Ricardo A.</forenames></author><author><keyname>Burrus</keyname><forenames>C. Sidney</forenames></author></authors><title>Iterative Design of L_p Digital Filters</title><categories>cs.IT math.IT</categories><comments>This paper has 29 pages and is mostly a derivative of the PhD thesis
  of the first author</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The design of digital filters is a fundamental process in the context of
digital signal processing. The purpose of this paper is to study the use of
$\lp$ norms (for $2 &lt; p &lt; \infty$) as design criteria for digital filters, and
to introduce a set of algorithms for the design of Finite (FIR) and Infinite
(IIR) Impulse Response digital filters based on the Iterative Reweighted Least
Squares (IRLS) algorithm. The proposed algorithms rely on the idea of breaking
the $\lp$ filter design problem into a sequence of approximations rather than
solving the original $\lp$ problem directly. It is shown that one can
efficiently design filters that arbitrarily approximate a desired $\lp$
solution (for $2 &lt; p &lt; \infty$) including the commonly used $l_\infty$ (or
minimax) design problem. A method to design filters with different norms in
different bands is presented (allowing the user for better control of the
signal and noise behavior per band). Among the main contributions of this work
is a method for the design of {\it magnitude} $\lp$ IIR filters. Experimental
results show that the algorithms in this work are robust and efficient,
improving over traditional off-the-shelf optimization tools. The group of
proposed algorithms form a flexible collection that offers robustness and
efficiency for a wide variety of digital filter design applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4530</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4530</id><created>2012-07-18</created><authors><author><keyname>Qin</keyname><forenames>Minghai</forenames></author><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Time-Space Constrained Codes for Phase-Change Memories</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase-change memory (PCM) is a promising non-volatile solid-state memory
technology. A PCM cell stores data by using its amorphous and crystalline
states. The cell changes between these two states using high temperature.
However, since the cells are sensitive to high temperature, it is important,
when programming cells, to balance the heat both in time and space.
  In this paper, we study the time-space constraint for PCM, which was
originally proposed by Jiang et al. A code is called an
\emph{$(\alpha,\beta,p)$-constrained code} if for any $\alpha$ consecutive
rewrites and for any segment of $\beta$ contiguous cells, the total rewrite
cost of the $\beta$ cells over those $\alpha$ rewrites is at most $p$. Here,
the cells are binary and the rewrite cost is defined to be the Hamming distance
between the current and next memory states. First, we show a general upper
bound on the achievable rate of these codes which extends the results of Jiang
et al. Then, we generalize their construction for $(\alpha\geq 1,
\beta=1,p=1)$-constrained codes and show another construction for $(\alpha = 1,
\beta\geq 1,p\geq1)$-constrained codes. Finally, we show that these two
constructions can be used to construct codes for all values of $\alpha$,
$\beta$, and $p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4537</identifier>
 <datestamp>2012-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4537</id><created>2012-07-18</created><updated>2012-09-25</updated><authors><author><keyname>Gharibi</keyname><forenames>Mirmojtaba</forenames></author></authors><title>Reduction from non-injective hidden shift problem to injective hidden
  shift problem</title><categories>quant-ph cs.CC</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a simple tool that can be used to reduce non-injective instances
of the hidden shift problem over arbitrary group to injective instances over
the same group. In particular, we show that the average-case non-injective
hidden shift problem admit this reduction. We show similar results for
(non-injective) hidden shift problem for bent functions. We generalize the
notion of influence and show how it relates to applicability of this tool for
doing reductions. In particular, these results can be used to simplify the main
results by Gavinsky, Roetteler, and Roland about the hidden shift problem for
the Boolean-valued functions and bent functions, and also to generalize their
results to non-Boolean domains (thereby answering an open question that they
pose).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4552</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4552</id><created>2012-07-19</created><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Krstic</keyname><forenames>Miroslav</forenames></author></authors><title>Delay-Robustness of Linear Predictor Feedback Without Restriction on
  Delay Rate</title><categories>math.OC cs.SY</categories><comments>13 pages, 1 figure, submitted for possible publication to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness is established for the predictor feedback for linear
time-invariant systems with respect to possibly time-varying perturbations of
the input delay, with a constant nominal delay. Prior results have addressed
qualitatively constant delay perturbations (robustness of stability in L2 norm
of actuator state) and delay perturbations with restricted rate of change
(robustness of stability in H1 norm of actuator state). The present work
provides simple formulae that allow direct and accurate computation of the
least upper bound of the magnitude of the delay perturbation for which
exponential stability in supremum norm on the actuator state is preserved.
While prior work has employed Lyapunov-Krasovskii functionals constructed via
backstepping, the present work employs a particular form of small-gain
analysis. Two cases are considered: the case of measurable (possibly
discontinuous) perturbations and the case of constant perturbations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4553</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4553</id><created>2012-07-19</created><authors><author><keyname>Zhang</keyname><forenames>Hai-Feng</forenames></author><author><keyname>Wu</keyname><forenames>Zhi-Xi</forenames></author><author><keyname>Xu</keyname><forenames>Xiao-Ke</forenames></author><author><keyname>Small</keyname><forenames>Michael</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>The Impacts of Subsidy Policies on Vaccination Decisions in Contact
  Networks</title><categories>physics.soc-ph cs.SI physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often, vaccination programs are carried out based on self-interest rather
than being mandatory. Owing to the perceptions about risks associated with
vaccines and the `herd immunity' effect, it may provide suboptimal vaccination
coverage for the population as a whole. In this case, some subsidy policies may
be offered by the government to promote vaccination coverage. But, not all
subsidy policies are effective in controlling the transmission of infectious
diseases. We address the question of which subsidy policy is best, and how to
appropriately distribute the limited subsidies to maximize vaccine coverage. To
answer these questions, we establish a model based on evolutionary game theory,
where individuals try to maximize their personal payoffs when considering the
voluntary vaccination mechanism. Our model shows that voluntary vaccination
alone is insufficient to control an epidemic. Hence, two subsidy policies are
systematically studied: (1) in the free subsidy policy the total amount of
subsidies is distributed to some individuals and all the donees may vaccinate
at no cost, and (2) in the part-offset subsidy policy each vaccinated person is
offset by a certain proportion of the vaccination cost. Simulations suggest
that, since the part-offset subsidy policy can encourage more individuals to be
vaccinated, the performance of this policy is significantly better than that of
the free subsidy policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4556</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4556</id><created>2012-07-19</created><updated>2013-01-24</updated><authors><author><keyname>Neininger</keyname><forenames>Ralph</forenames></author></authors><title>Refined Quicksort asymptotics</title><categories>math.PR cs.DS</categories><comments>revised version; title slightly changed; accepted for publication in
  Random Structures and Algorithms</comments><msc-class>60F05, 60F15, 68P10, 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of the Quicksort algorithm is usually measured by the number
of key comparisons used during its execution. When operating on a list of $n$
data, permuted uniformly at random, the appropriately normalized complexity
$Y_n$ is known to converge almost surely to a non-degenerate random limit $Y$.
This assumes a natural embedding of all $Y_n$ on one probability space, e.g.,
via random binary search trees. In this note a central limit theorem for the
error term in the latter almost sure convergence is shown:
$$\sqrt{\frac{n}{2\log n}}(Y_n-Y) \stackrel{d}{\longrightarrow} {\cal N} \qquad
(n\to\infty),$$ where ${\cal N}$ denotes a standard normal random variable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4567</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4567</id><created>2012-07-19</created><authors><author><keyname>Li</keyname><forenames>Rong-Hua</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author></authors><title>Efficient Core Maintenance in Large Dynamic Graphs</title><categories>cs.DS cs.DB cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $k$-core decomposition in a graph is a fundamental problem for social
network analysis. The problem of $k$-core decomposition is to calculate the
core number for every node in a graph. Previous studies mainly focus on
$k$-core decomposition in a static graph. There exists a linear time algorithm
for $k$-core decomposition in a static graph. However, in many real-world
applications such as online social networks and the Internet, the graph
typically evolves over time. Under such applications, a key issue is to
maintain the core number of nodes given the graph changes over time. A simple
implementation is to perform the linear time algorithm to recompute the core
number for every node after the graph is updated. Such simple implementation is
expensive when the graph is very large. In this paper, we propose a new
efficient algorithm to maintain the core number for every node in a dynamic
graph. Our main result is that only certain nodes need to update their core
number given the graph is changed by inserting/deleting an edge. We devise an
efficient algorithm to identify and recompute the core number of such nodes.
The complexity of our algorithm is independent of the graph size. In addition,
to further accelerate the algorithm, we develop two pruning strategies by
exploiting the lower and upper bounds of the core number. Finally, we conduct
extensive experiments over both real-world and synthetic datasets, and the
results demonstrate the efficiency of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4570</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4570</id><created>2012-07-19</created><updated>2012-07-21</updated><authors><author><keyname>Parseh</keyname><forenames>Farzad</forenames><affiliation>behdad</affiliation></author><author><keyname>Moghaddam</keyname><forenames>Davood Karimzadgan</forenames><affiliation>behdad</affiliation></author><author><keyname>Pedram</keyname><forenames>Mir Mohsen</forenames><affiliation>behdad</affiliation></author><author><keyname>Manesh</keyname><forenames>Rohollah Esmaeli</forenames><affiliation>behdad</affiliation></author><author><keyname>Mohammad</keyname><affiliation>behdad</affiliation></author><author><keyname>Jamshidi</keyname></author></authors><title>Presentation an Approach for Optimization of Semantic Web Language Based
  on the Document Structure</title><categories>cs.DB</categories><comments>7 pages, 8 figures, 2 Tables</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 3, No 1, May 2012 ISSN (Online): 1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pattern tree are based on integrated rules which are equal to a combination
of some points connected to each other in a hierarchical structure, called
Enquiry Hierarchical (EH). The main operation in pattern enquiry seeking is to
locate the steps that match the given EH in the dataset. A point of algorithms
has offered for EH matching; but the majority of this algorithms seeks all of
the enquiry steps to access all EHs in the dataset. A few algorithms such as
seek only steps that satisfy end points of EH. All of above algorithms are
trying to locate a way just for investigating direct testing of steps and to
locate the answer of enquiry, directly via these points. In this paper, we
describe a novel algorithm to locate the answer of enquiry without access to
real point of the dataset blindly. In this algorithm, first, the enquiry will
be executed on enquiry schema and this leads to a schema. Using this plan, it
will be clear how to seek end steps and how to achieve enquiry dataset, before
seeking of the dataset steps. Therefore, none of dataset steps will be seek
blindly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4577</identifier>
 <datestamp>2013-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4577</id><created>2012-07-19</created><updated>2013-06-11</updated><authors><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames><affiliation>Inria Rennes Bretagne Atlantique</affiliation></author><author><keyname>Schnoebelen</keyname><forenames>Philippe</forenames><affiliation>LSV, CNRS and ENS Cachan</affiliation></author></authors><title>Solving Stochastic B\&quot;uchi Games on Infinite Arenas with a Finite
  Attractor</title><categories>cs.LO cs.FL cs.GT</categories><comments>In Proceedings QAPL 2013, arXiv:1306.2413</comments><proxy>EPTCS</proxy><acm-class>D.2.4; G.3; C.2.2</acm-class><journal-ref>EPTCS 117, 2013, pp. 116-131</journal-ref><doi>10.4204/EPTCS.117.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider games played on an infinite probabilistic arena where the first
player aims at satisfying generalized B\&quot;uchi objectives almost surely, i.e.,
with probability one. We provide a fixpoint characterization of the winning
sets and associated winning strategies in the case where the arena satisfies
the finite-attractor property. From this we directly deduce the decidability of
these games on probabilistic lossy channel systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4587</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4587</id><created>2012-07-19</created><authors><author><keyname>Baik</keyname><forenames>Ihn-Jung</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Causal relay networks</title><categories>cs.IT math.IT</categories><comments>27 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study causal discrete-memoryless relay networks (DMRNs).
The network consists of multiple nodes, each of which can be a source, relay,
and/or destination. In the network, there are two types of relays, i.e., relays
with one sample delay (strictly causal) and relays without delay (causal) whose
transmit signal depends not only on the past received symbols but also on the
current received symbol. For this network, we derive two new cut-set bounds,
one when the causal relays have their own messages and the other when not.
Using examples of a causal vector Gaussian two-way relay channel and a causal
vector Gaussian relay channel, we show that the new cut-set bounds can be
achieved by a simple amplify-and-forward type relaying. Our result for the
causal relay channel strengthens the previously known capacity result for the
same channel by El Gamal, Hassanpour, and Mammen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4589</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4589</id><created>2012-07-19</created><authors><author><keyname>Angelakis</keyname><forenames>Vangelis</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author><author><keyname>He</keyname><forenames>Qing</forenames></author><author><keyname>Yuan</keyname><forenames>Di</forenames></author></authors><title>Minimum-Length Scheduling with Finite Queues: Solution Characterization
  and Algorithmic Framework</title><categories>cs.IT cs.NI math.IT</categories><comments>30 pages, 4 figures. Submitted July 18th to the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a set of transmitter-receiver pairs, or links, that share a
common channel and address the problem of emptying backlogged queues at the
transmitters in minimum time. The problem amounts to determining activation
subsets of links and their time durations to form a minimum-length schedule.
The problem of scheduling has been studied under various formulations before.
In this paper, we present fundamental insights and solution characterizations
that include: (i) showing that the complexity of the problem remains high for
any continuous and increasing rate function, (ii) formulating and proving
sufficient and necessary optimality conditions of two base scheduling
strategies that correspond to emptying the queues using &quot;one-at-a-time&quot; or
&quot;all-at-once&quot; strategies, (iii) presenting and proving the tractability of the
special case in which the transmission rates are functions only of the
cardinality of the link activation sets. These results are independent of
physical-layer system specifications and are valid for any form of rate
function. We then develop an algorithmic framework. The framework encompasses
exact as well as sub-optimal, but fast, scheduling algorithms, all under a
unified principle design. Through computational experiments we finally
investigate the performance of several specific algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4592</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4592</id><created>2012-07-19</created><authors><author><keyname>Ny</keyname><forenames>Jerome Le</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Differentially Private Kalman Filtering</title><categories>math.OC cs.CR cs.SY</categories><comments>9 pages. arXiv admin note: substantial text overlap with
  arXiv:1207.4305</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the H2 (Kalman) filtering problem in the situation where a
signal estimate must be constructed based on inputs from individual
participants, whose data must remain private. This problem arises in emerging
applications such as smart grids or intelligent transportation systems, where
users continuously send data to third-party aggregators performing global
monitoring or control tasks, and require guarantees that this data cannot be
used to infer additional personal information. To provide strong formal privacy
guarantees against adversaries with arbitrary side information, we rely on the
notion of differential privacy introduced relatively recently in the database
literature. This notion is extended to dynamic systems with many participants
contributing independent input signals, and mechanisms are then proposed to
solve the H2 filtering problem with a differential privacy constraint. A method
for mitigating the impact of the privacy-inducing mechanism on the estimation
performance is described, which relies on controlling the Hinfinity norm of the
filter. Finally, we discuss an application to a privacy-preserving traffic
monitoring system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4597</identifier>
 <datestamp>2012-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4597</id><created>2012-07-19</created><authors><author><keyname>Martin</keyname><forenames>Victorin</forenames></author><author><keyname>Lasgouttes</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Furtlehner</keyname><forenames>Cyril</forenames></author></authors><title>Local stability of Belief Propagation algorithm with multiple fixed
  points</title><categories>stat.ML cs.LG</categories><comments>arXiv admin note: substantial text overlap with arXiv:1101.4170</comments><doi>10.3233/978-1-61499-096-3-180</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of problems in statistical physics and computer science can be
expressed as the computation of marginal probabilities over a Markov random
field. Belief propagation, an iterative message-passing algorithm, computes
exactly such marginals when the underlying graph is a tree. But it has gained
its popularity as an efficient way to approximate them in the more general
case, even if it can exhibits multiple fixed points and is not guaranteed to
converge. In this paper, we express a new sufficient condition for local
stability of a belief propagation fixed point in terms of the graph structure
and the beliefs values at the fixed point. This gives credence to the usual
understanding that Belief Propagation performs better on sparse graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4598</identifier>
 <datestamp>2012-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4598</id><created>2012-07-19</created><updated>2012-11-29</updated><authors><author><keyname>Russo</keyname><forenames>Lu&#xed;s M. S.</forenames></author><author><keyname>Francisco</keyname><forenames>Alexandre P.</forenames></author></authors><title>Quick HyperVolume</title><categories>cs.DS cs.DM cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm to calculate exact hypervolumes. Given a set of
$d$-dimensional points, it computes the hypervolume of the dominated space.
Determining this value is an important subroutine of Multiobjective
Evolutionary Algorithms (MOEAs). We analyze the &quot;Quick Hypervolume&quot; (QHV)
algorithm theoretically and experimentally. The theoretical results are a
significant contribution to the current state of the art. Moreover the
experimental performance is also very competitive, compared with existing exact
hypervolume algorithms.
  A full description of the algorithm is currently submitted to IEEE
Transactions on Evolutionary Computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4600</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4600</id><created>2012-07-19</created><authors><author><keyname>ElKabbany</keyname><forenames>Ghada F.</forenames></author><author><keyname>Aslan</keyname><forenames>Heba K.</forenames></author></authors><title>Efficient Design for the Implementation of Wong-Lam Multicast
  Authentication Protocol Using Two-Levels of Parallelism</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues (IJCSI), Volume 9,
  Issue 3, No. 1, May 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group communication can benefit from Internet Protocol (IP) multicast
protocol to achieve efficient exchange of messages. However, IP multicast does
not provide any mechanisms for authentication. In literature, many solutions to
solve this problem were presented. It has been shown that Wong and Lam protocol
is the only protocol that can resist both packet loss and pollution attacks. In
contrast, it has high computation and communication overheads. In the present
paper, an efficient design for the implementation of Wong and Lam multicast
authentication protocol is proposed. In order to solve the computation overhead
problem, we use two-levels of parallelism. To reduce the communication
overhead, we use Universal Message Authentication Codes (UMAC) instead of hash
functions. The design is analyzed for both NTRU and elliptic curve cryptography
signature algorithms. The analysis shows that the proposed design decreases
significantly the execution time of Wong-Lam protocol which makes it suitable
for real-time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4607</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4607</id><created>2012-07-19</created><authors><author><keyname>Bannai</keyname><forenames>Hideo</forenames></author><author><keyname>Inenaga</keyname><forenames>Shunsuke</forenames></author><author><keyname>Takeda</keyname><forenames>Masayuki</forenames></author></authors><title>Efficient LZ78 factorization of grammar compressed text</title><categories>cs.DS</categories><comments>SPIRE 2012</comments><doi>10.1007/978-3-642-34109-0_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient algorithm for computing the LZ78 factorization of a
text, where the text is represented as a straight line program (SLP), which is
a context free grammar in the Chomsky normal form that generates a single
string. Given an SLP of size $n$ representing a text $S$ of length $N$, our
algorithm computes the LZ78 factorization of $T$ in $O(n\sqrt{N}+m\log N)$ time
and $O(n\sqrt{N}+m)$ space, where $m$ is the number of resulting LZ78 factors.
We also show how to improve the algorithm so that the $n\sqrt{N}$ term in the
time and space complexities becomes either $nL$, where $L$ is the length of the
longest LZ78 factor, or $(N - \alpha)$ where $\alpha \geq 0$ is a quantity
which depends on the amount of redundancy that the SLP captures with respect to
substrings of $S$ of a certain length. Since $m = O(N/\log_\sigma N)$ where
$\sigma$ is the alphabet size, the latter is asymptotically at least as fast as
a linear time algorithm which runs on the uncompressed string when $\sigma$ is
constant, and can be more efficient when the text is compressible, i.e. when
$m$ and $n$ are small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4616</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4616</id><created>2012-07-19</created><authors><author><keyname>Prosser</keyname><forenames>Patrick</forenames></author></authors><title>Exact Algorithms for Maximum Clique: a computational study</title><categories>cs.DS</categories><comments>40 pages, 14 figures, 10 tables, 12 short java program listings, code
  afailable to download at
  http://www.dcs.gla.ac.uk/~pat/maxClique/distribution/</comments><report-no>TR-2012-333</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a number of recently reported exact algorithms for the maximum
clique problem (MCQ, MCR, MCS, BBMC). The program code used is presented and
critiqued showing how small changes in implementation can have a drastic effect
on performance. The computational study demonstrates how problem features and
hardware platforms influence algorithm behaviour. The minimum width order
(smallest-last) is investigated, and MCS is broken into its consituent parts
and we discover that one of these parts degrades performance. It is shown that
the standard procedure used for rescaling published results is unsafe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4625</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4625</id><created>2012-07-19</created><authors><author><keyname>Laporte</keyname><forenames>E.</forenames><affiliation>LIGM</affiliation></author></authors><title>Appropriate Nouns with Obligatory Modifiers</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>Language research, Seoul National University 31, 2 (1995) 251-289</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of appropriate sequence as introduced by Z. Harris provides a
powerful syntactic way of analysing the detailed meaning of various sentences,
including ambiguous ones. In an adjectival sentence like 'The leather was
yellow', the introduction of an appropriate noun, here 'colour', specifies
which quality the adjective describes. In some other adjectival sentences with
an appropriate noun, that noun plays the same part as 'colour' and seems to be
relevant to the description of the adjective. These appropriate nouns can
usually be used in elementary sentences like 'The leather had some colour', but
in many cases they have a more or less obligatory modifier. For example, you
can hardly mention that an object has a colour without qualifying that colour
at all. About 300 French nouns are appropriate in at least one adjectival
sentence and have an obligatory modifier. They enter in a number of sentence
structures related by several syntactic transformations. The appropriateness of
the noun and the fact that the modifier is obligatory are reflected in these
transformations. The description of these syntactic phenomena provides a basis
for a classification of these nouns. It also concerns the lexical properties of
thousands of predicative adjectives, and in particular the relations between
the sentence without the noun : 'The leather was yellow' and the adjectival
sentence with the noun : 'The colour of the leather was yellow'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4626</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4626</id><created>2012-07-19</created><authors><author><keyname>Marmion</keyname><forenames>Marie-Eleonore</forenames><affiliation>LIFL</affiliation></author><author><keyname>Dhaenens</keyname><forenames>Clarisse</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Jourdan</keyname><forenames>Laetitia</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Liefooghe</keyname><forenames>Arnaud</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>The Road to VEGAS: Guiding the Search over Neutral Networks</title><categories>cs.NE</categories><comments>Genetic And Evolutionary Computation Conference, Dublin : Ireland
  (2011)</comments><proxy>ccsd</proxy><doi>10.1145/2001576.2001842</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  VEGAS (Varying Evolvability-Guided Adaptive Search) is a new methodology
proposed to deal with the neutrality property of some optimization problems. ts
main feature is to consider the whole neutral network rather than an arbitrary
solution. Moreover, VEGAS is designed to escape from plateaus based on the
evolvability of solution and a multi-armed bandit. Experiments are conducted on
NK-landscapes with neutrality. Results show the importance of considering the
whole neutral network and of guiding the search cleverly. The impact of the
level of neutrality and of the exploration-exploitation trade-off are deeply
analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4628</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4628</id><created>2012-07-19</created><authors><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Liefooghe</keyname><forenames>Arnaud</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Humeau</keyname><forenames>J&#xe9;r&#xe9;mie</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Jourdan</keyname><forenames>Laetitia</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Dhaenens</keyname><forenames>Clarisse</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author></authors><title>On the Effect of Connectedness for Biobjective Multiple and Long Path
  Problems</title><categories>cs.NE cs.AI</categories><comments>Learning and Intelligent OptimizatioN Conference (LION 5), Rome :
  Italy (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the property of connectedness has been claimed to give a strong
motivation on the design of local search techniques for multiobjective
combinatorial optimization (MOCO). Indeed, when connectedness holds, a basic
Pareto local search, initialized with at least one non-dominated solution,
allows to identify the efficient set exhaustively. However, this becomes
quickly infeasible in practice as the number of efficient solutions typically
grows exponentially with the instance size. As a consequence, we generally have
to deal with a limited-size approximation, where a good sample set has to be
found. In this paper, we propose the biobjective multiple and long path
problems to show experimentally that, on the first problems, even if the
efficient set is connected, a local search may be outperformed by a simple
evolutionary algorithm in the sampling of the efficient set. At the opposite,
on the second problems, a local search algorithm may successfully approximate a
disconnected efficient set. Then, we argue that connectedness is not the single
property to study for the design of local search heuristics for MOCO. This work
opens new discussions on a proper definition of the multiobjective fitness
landscape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4629</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4629</id><created>2012-07-19</created><authors><author><keyname>Marmion</keyname><forenames>Marie-Eleonore</forenames><affiliation>LIFL</affiliation></author><author><keyname>Dhaenens</keyname><forenames>Clarisse</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Jourdan</keyname><forenames>Laetitia</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Liefooghe</keyname><forenames>Arnaud</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>On the Neutrality of Flowshop Scheduling Fitness Landscapes</title><categories>cs.NE cs.AI</categories><comments>Learning and Intelligent OptimizatioN Conference (LION 5), Rome :
  Italy (2011)</comments><proxy>ccsd</proxy><doi>10.1007/978-3-642-25566-3_18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving efficiently complex problems using metaheuristics, and in particular
local searches, requires incorporating knowledge about the problem to solve. In
this paper, the permutation flowshop problem is studied. It is well known that
in such problems, several solutions may have the same fitness value. As this
neutrality property is an important one, it should be taken into account during
the design of optimization methods. Then in the context of the permutation
flowshop, a deep landscape analysis focused on the neutrality property is
driven and propositions on the way to use this neutrality to guide efficiently
the search are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4631</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4631</id><created>2012-07-19</created><authors><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Liefooghe</keyname><forenames>Arnaud</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Jourdan</keyname><forenames>Laetitia</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Dhaenens</keyname><forenames>Clarisse</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author></authors><title>Analyzing the Effect of Objective Correlation on the Efficient Set of
  MNK-Landscapes</title><categories>cs.NE cs.AI</categories><comments>Learning and Intelligent OptimizatioN Conference (LION 5), Rome :
  Italy (2011)</comments><proxy>ccsd</proxy><doi>10.1007/978-3-642-25566-3_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multiobjective combinatorial optimization, there exists two main classes
of metaheuristics, based either on multiple aggregations, or on a dominance
relation. As in the single objective case, the structure of the search space
can explain the difficulty for multiobjective metaheuristics, and guide the
design of such methods. In this work we analyze the properties of
multiobjective combinatorial search spaces. In particular, we focus on the
features related the efficient set, and we pay a particular attention to the
correlation between objectives. Few benchmark takes such objective correlation
into account. Here, we define a general method to design multiobjective
problems with correlation. As an example, we extend the well-known
multiobjective NK-landscapes. By measuring different properties of the search
space, we show the importance of considering the objective correlation on the
design of metaheuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4632</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4632</id><created>2012-07-19</created><authors><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Daolio</keyname><forenames>Fabio</forenames><affiliation>ISI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author></authors><title>Clustering of Local Optima in Combinatorial Fitness Landscapes</title><categories>cs.NE cs.AI</categories><comments>Learning and Intelligent OptimizatioN Conference (LION 5), Rome :
  Italy (2011)</comments><proxy>ccsd</proxy><doi>10.1007/978-3-642-25566-3_35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the recently proposed model of combinatorial landscapes: local optima
networks, we study the distribution of local optima in two classes of instances
of the quadratic assignment problem. Our results indicate that the two problem
instance classes give rise to very different configuration spaces. For the
so-called real-like class, the optima networks possess a clear modular
structure, while the networks belonging to the class of random uniform
instances are less well partitionable into clusters. We briefly discuss the
consequences of the findings for heuristically searching the corresponding
problem spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4642</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4642</id><created>2012-07-19</created><updated>2014-12-12</updated><authors><author><keyname>Weinmann</keyname><forenames>Andreas</forenames></author><author><keyname>Storath</keyname><forenames>Martin</forenames></author><author><keyname>Demaret</keyname><forenames>Laurent</forenames></author></authors><title>The L1-Potts functional for robust jump-sparse reconstruction</title><categories>math.OC cs.NA math.NA</categories><msc-class>90C39, 90C26, 65K10, 65J22</msc-class><doi>10.1137/120896256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the non-smooth and non-convex $L^1$-Potts functional in
discrete and continuous time. We show $\Gamma$-convergence of discrete
$L^1$-Potts functionals towards their continuous counterpart and obtain a
convergence statement for the corresponding minimizers as the discretization
gets finer. For the discrete $L^1$-Potts problem, we introduce an $O(n^2)$ time
and $O(n)$ space algorithm to compute an exact minimizer. We apply $L^1$-Potts
minimization to the problem of recovering piecewise constant signals from noisy
measurements $f.$ It turns out that the $L^1$-Potts functional has a quite
interesting blind deconvolution property. In fact, we show that mildly blurred
jump-sparse signals are reconstructed by minimizing the $L^1$-Potts functional.
Furthermore, for strongly blurred signals and known blurring operator, we
derive an iterative reconstruction algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4656</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4656</id><created>2012-07-19</created><authors><author><keyname>Zhang</keyname><forenames>Hai-Feng</forenames></author><author><keyname>Liu</keyname><forenames>Run-Ran</forenames></author><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Yang</keyname><forenames>Han-Xin</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>Aspiration-induced reconnection in spatial public goods game</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 5 figures</comments><journal-ref>EPL, 94 (2011) 18006</journal-ref><doi>10.1209/0295-5075/94/18006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this Letter, we introduce an aspiration-induced reconnection mechanism
into the spatial public goods game. A player will reconnect to a randomly
chosen player if its payoff acquired from the group centered on the neighbor
does not exceed the aspiration level. We find that an intermediate aspiration
level can best promote cooperation. This optimal phenomenon can be explained by
a negative feedback effect, namely, a moderate level of reconnection induced by
the intermediate aspiration level induces can change the downfall of
cooperators, and then facilitate the fast spreading of cooperation. While
insufficient reconnection and excessive reconnection induced by low and high
aspiration levels respectively are not conductive to such an effect. Moreover,
we find that the intermediate aspiration level can lead to the heterogeneous
distribution of degree, which will be beneficial to the evolution of
cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4660</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4660</id><created>2012-07-19</created><authors><author><keyname>Ghebleh</keyname><forenames>M.</forenames></author><author><keyname>Niepel</keyname><forenames>L.</forenames></author></authors><title>Locating and Identifying Codes in Circulant Networks</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set S of vertices of a graph G is a dominating set of G if every vertex u
of G is either in S or it has a neighbour in S. In other words, S is dominating
if the sets S\cap N[u] where u \in V(G) and N[u] denotes the closed
neighbourhood of u in G, are all nonempty. A set S \subseteq V(G) is called a
locating code in G, if the sets S \cap N[u] where u \in V(G) \setminus S are
all nonempty and distinct. A set S \subseteq V(G) is called an identifying code
in G, if the sets S\cap N[u] where u\in V(G) are all nonempty and distinct. We
study locating and identifying codes in the circulant networks C_n(1,3). For an
integer n&gt;6, the graph C_n(1,3) has vertex set Z_n and edges xy where x,y \in
Z_n and |x-y| \in {1,3}. We prove that a smallest locating code in C_n(1,3) has
size \lceil n/3 \rceil + c, where c \in {0,1}, and a smallest identifying code
in C_n(1,3) has size \lceil 4n/11 \rceil + c', where c' \in {0,1}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4661</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4661</id><created>2012-07-19</created><authors><author><keyname>Bonik</keyname><forenames>Gregory</forenames></author><author><keyname>Goreinov</keyname><forenames>Sergei</forenames></author><author><keyname>Zamarashkin</keyname><forenames>Nickolai</forenames></author></authors><title>A variant of list plus CRC concatenated polar code</title><categories>cs.IT math.IT</categories><comments>4 pages</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new family of codes based on polar codes, soft concatenation and list+CRC
decoding is proposed. Numerical experiments show the performance competitive
with industry standards and Tal, Vardy approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4666</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4666</id><created>2012-07-19</created><authors><author><keyname>Kowalik</keyname><forenames>Lukasz</forenames></author><author><keyname>Mucha</keyname><forenames>Marcin</forenames></author></authors><title>A 9k kernel for nonseparating independent set in planar graphs</title><categories>cs.DS cs.DM math.CO</categories><comments>An extended abstract was presented at WG 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study kernelization (a kind of efficient preprocessing) for NP-hard
problems on planar graphs. Our main result is a kernel of size at most 9k
vertices for the Planar Maximum Nonseparating Independent Set problem. A direct
consequence of this result is that Planar Connected Vertex Cover has no kernel
with at most (9/8 - epsilon)k vertices, for any epsilon &gt; 0, assuming P \ne NP.
We also show a very simple 5k-vertices kernel for Planar Max Leaf, which
results in a lower bound of (5/4 - epsilon)k vertices for the kernel of Planar
Connected Dominating Set (also under P \ne NP).
  As a by-product we show a few extremal graph theory results which might be of
independent interest. We prove that graphs that contain no separator consisting
of only degree two vertices contain (a) a spanning tree with at least n/4
leaves and (b) a nonseparating independent set of size at least n/9 (also,
equivalently, a connected vertex cover of size at most 8/9n). The result (a) is
a generalization of a theorem of Kleitman and West [SIDMA 1991] who showed the
same bound for graphs of minimum degree three. Finally we show that every
n-vertex outerplanar graph contains an independent set I and a collection of
vertex-disjoint cycles C such that 9|I| &gt;= 4n-3|C|.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4676</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4676</id><created>2012-07-19</created><updated>2012-09-16</updated><authors><author><keyname>Langford</keyname><forenames>John</forenames><affiliation>Editors</affiliation></author><author><keyname>Pineau</keyname><forenames>Joelle</forenames><affiliation>Editors</affiliation></author></authors><title>Proceedings of the 29th International Conference on Machine Learning
  (ICML-12)</title><categories>cs.LG stat.ML</categories><comments>Proceedings of the 29th International Conference on Machine Learning
  (ICML-12). Editors: John Langford and Joelle Pineau. Publisher: Omnipress,
  2012</comments><proxy>Amir Globerson</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is an index to the papers that appear in the Proceedings of the 29th
International Conference on Machine Learning (ICML-12). The conference was held
in Edinburgh, Scotland, June 27th - July 3rd, 2012.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4680</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4680</id><created>2012-07-19</created><updated>2012-10-04</updated><authors><author><keyname>Schuh</keyname><forenames>Fabian</forenames></author><author><keyname>Schenk</keyname><forenames>Andreas</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author></authors><title>Reduced Complexity Super-Trellis Decoding for Convolutionally Encoded
  Transmission Over ISI-Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 8 figures, accepted for ICNC'13. (see also: arXiv:1205.7031)</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we propose a matched encoding (ME) scheme for convolutionally
encoded transmission over intersymbol interference (usually called ISI)
channels. A novel trellis description enables to perform equalization and
decoding jointly, i.e., enables efficient super-trellis decoding. By means of
this matched non-linear trellis description we can significantly reduce the
number of states needed for the receiver-side Viterbi algorithm to perform
maximum-likelihood sequence estimation. Further complexity reduction is
achieved using the concept of reduced-state sequence estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4681</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4681</id><created>2012-07-19</created><authors><author><keyname>Kowalik</keyname><forenames>Lukasz</forenames></author></authors><title>Nonblocker in H-minor free graphs: kernelization meets discharging</title><categories>cs.DS cs.DM math.CO</categories><comments>16 pages; accepted to IPEC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perhaps the best known kernelization result is the kernel of size 335k for
the Planar Dominating Set problem by Alber et al. [JACM 2004], later improved
to 67k by Chen et al. [SICOMP 2007]. This result means roughly, that the
problem of finding the smallest dominating set in a planar graph is easy when
the optimal solution is small. On the other hand, it is known that Planar
Dominating Set parameterized by k'=|V|-k (also known as Planar Nonblocker) has
a kernel of size 2k'. This means that Planar Dominating Set is easy when the
optimal solution is very large. We improve the kernel for Planar Nonblocker to
7/4k'. This also implies that Planar Dominating Set has no kernel of size at
most (7/3-epsilon)k, for any epsilon&gt;0, unless P=NP. This improves the previous
lower bound of (2-epsilon)k of Chen et al. Both of these results immediately
generalize to H-minor free graphs (without changing the constants). In our
proof of the bound on the kernel size we use a variant of the discharging
method (used e.g. in the proof of the four color theorem). We give some
arguments that this method is natural in the context of kernelization and we
hope it will be applied to get improved kernel size bounds for other problems
as well. As a by-product we show a result which might be of independent
interest: every n-vertex graph with no isolated vertices and such that every
pair of degree 1 vertices is at distance at least 5 and every pair of degree 2
vertices is at distance at least 2 has a dominating set of size at most 3/7n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4684</identifier>
 <datestamp>2014-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4684</id><created>2012-07-19</created><updated>2014-04-05</updated><authors><author><keyname>Clarkson</keyname><forenames>Kenneth L.</forenames></author><author><keyname>Drineas</keyname><forenames>Petros</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author><author><keyname>Meng</keyname><forenames>Xiangrui</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>The Fast Cauchy Transform and Faster Robust Linear Regression</title><categories>cs.DS stat.ML</categories><comments>48 pages; substantially extended and revised; short version in SODA
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide fast algorithms for overconstrained $\ell_p$ regression and
related problems: for an $n\times d$ input matrix $A$ and vector
$b\in\mathbb{R}^n$, in $O(nd\log n)$ time we reduce the problem
$\min_{x\in\mathbb{R}^d} \|Ax-b\|_p$ to the same problem with input matrix
$\tilde A$ of dimension $s \times d$ and corresponding $\tilde b$ of dimension
$s\times 1$. Here, $\tilde A$ and $\tilde b$ are a coreset for the problem,
consisting of sampled and rescaled rows of $A$ and $b$; and $s$ is independent
of $n$ and polynomial in $d$. Our results improve on the best previous
algorithms when $n\gg d$, for all $p\in[1,\infty)$ except $p=2$. We also
provide a suite of improved results for finding well-conditioned bases via
ellipsoidal rounding, illustrating tradeoffs between running time and
conditioning quality, including a one-pass conditioning algorithm for general
$\ell_p$ problems.
  We also provide an empirical evaluation of implementations of our algorithms
for $p=1$, comparing them with related algorithms. Our empirical results show
that, in the asymptotic regime, the theory is a very good guide to the
practical performance of these algorithms. Our algorithms use our faster
constructions of well-conditioned bases for $\ell_p$ spaces and, for $p=1$, a
fast subspace embedding of independent interest that we call the Fast Cauchy
Transform: a distribution over matrices $\Pi:\mathbb{R}^n\mapsto
\mathbb{R}^{O(d\log d)}$, found obliviously to $A$, that approximately
preserves the $\ell_1$ norms: that is, with large probability, simultaneously
for all $x$, $\|Ax\|_1 \approx \|\Pi Ax\|_1$, with distortion $O(d^{2+\eta})$,
for an arbitrarily small constant $\eta&gt;0$; and, moreover, $\Pi A$ can be
computed in $O(nd\log d)$ time. The techniques underlying our Fast Cauchy
Transform include fast Johnson-Lindenstrauss transforms, low-coherence
matrices, and rescaling by Cauchy random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4694</identifier>
 <datestamp>2012-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4694</id><created>2012-07-19</created><updated>2012-11-30</updated><authors><author><keyname>Liskiewicz</keyname><forenames>Maciej</forenames></author><author><keyname>Schuster</keyname><forenames>Martin R.</forenames></author></authors><title>A New Upper Bound for the Traveling Salesman Problem in Cubic Graphs</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a new upper bound for traveling salesman problem (TSP) in cubic
graphs, i.e. graphs with maximum vertex degree three, and prove that the
problem for an $n$-vertex graph can be solved in $O(1.2553^n)$ time and in
linear space. We show that the exact TSP algorithm of Eppstein, with some minor
modifications, yields the stated result. The previous best known upper bound
$O(1.251^n)$ was claimed by Iwama and Nakashima [Proc. COCOON 2007].
Unfortunately, their analysis contains several mistakes that render the proof
for the upper bound invalid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4701</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4701</id><created>2012-07-19</created><authors><author><keyname>Li</keyname><forenames>Chenyang</forenames></author><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Cogill</keyname><forenames>Randy</forenames></author><author><keyname>Garcia</keyname><forenames>Alfredo</forenames></author></authors><title>An Adaptive Online Ad Auction Scoring Algorithm for Revenue Maximization</title><categories>cs.GT cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sponsored search becomes an easy platform to match potential consumers'
intent with merchants' advertising. Advertisers express their willingness to
pay for each keyword in terms of bids to the search engine. When a user's query
matches the keyword, the search engine evaluates the bids and allocates slots
to the advertisers that are displayed along side the unpaid algorithmic search
results. The advertiser only pays the search engine when its ad is clicked by
the user and the price-per-click is determined by the bids of other competing
advertisers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4707</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4707</id><created>2012-07-19</created><updated>2013-11-04</updated><authors><author><keyname>Hammerich</keyname><forenames>Edwin</forenames></author></authors><title>Correction to &quot;A Note on Gallager's Capacity Theorem for Waveform
  Channels&quot;</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We correct an alleged contradiction to Gallager's capacity theorem for
waveform channels as presented in a poster at the 2012 IEEE International
Symposium on Information Theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4708</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4708</id><created>2012-07-19</created><updated>2013-06-21</updated><authors><author><keyname>Bellemare</keyname><forenames>Marc G.</forenames></author><author><keyname>Naddaf</keyname><forenames>Yavar</forenames></author><author><keyname>Veness</keyname><forenames>Joel</forenames></author><author><keyname>Bowling</keyname><forenames>Michael</forenames></author></authors><title>The Arcade Learning Environment: An Evaluation Platform for General
  Agents</title><categories>cs.AI</categories><journal-ref>Journal of Artificial Intelligence Research 47, pages 253-279</journal-ref><doi>10.1613/jair.3912</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we introduce the Arcade Learning Environment (ALE): both a
challenge problem and a platform and methodology for evaluating the development
of general, domain-independent AI technology. ALE provides an interface to
hundreds of Atari 2600 game environments, each one different, interesting, and
designed to be a challenge for human players. ALE presents significant research
challenges for reinforcement learning, model learning, model-based planning,
imitation learning, transfer learning, and intrinsic motivation. Most
importantly, it provides a rigorous testbed for evaluating and comparing
approaches to these problems. We illustrate the promise of ALE by developing
and benchmarking domain-independent agents designed using well-established AI
techniques for both reinforcement learning and planning. In doing so, we also
propose an evaluation methodology made possible by ALE, reporting empirical
results on over 55 different games. All of the software, including the
benchmark agents, is publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4710</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4710</id><created>2012-07-19</created><authors><author><keyname>Fried</keyname><forenames>Dror</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author><author><keyname>Benbassat</keyname><forenames>Amit</forenames></author><author><keyname>Wenner</keyname><forenames>Cenny</forenames></author></authors><title>Complexity of Canadian Traveler Problem Variants</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Canadian traveler problem (CTP) is the problem of traversing a given
graph, where some of the edges may be blocked - a state which is revealed only
upon reaching an incident vertex. Originally stated by Papadimitriou and
Yannakakis (1991), the adversarial version of CTP was shown to be
PSPACE-complete, with the stochastic version shown to be #P-hard. We show that
stochastic CTP is also PSPACE-complete: initially proving PSPACE-hardness for
the dependent version of stochastic CTP,and proceeding with gadgets that allow
us to extend the proof to the independent case. Since for disjoint-path graphs,
CTP can be solved in polynomial time, we examine the complexity of the more
general remote-sensing CTP, and show that it is NP-hard even for disjoint-path
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4711</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4711</id><created>2012-07-19</created><authors><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Efficient Feedback-Based Scheduling Policies for Chunked Network Codes
  over Networks with Loss and Delay</title><categories>cs.IT cs.NI math.IT</categories><comments>12 pages, 13 tables; Submitted to IEEE Trans. on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of designing efficient feedback-based scheduling policies for
chunked codes (CC) over packet networks with delay and loss is considered. For
networks with feedback, two scheduling policies, referred to as random push
(RP) and local-rarest-first (LRF), already exist. We propose a new scheduling
policy, referred to as minimum-distance-first (MDF), based on the expected
number of innovative successful packet transmissions at each node of the
network prior to the &quot;next&quot; transmission time, given the feedback information
from the downstream node(s) about the received packets. Unlike the existing
policies, the MDF policy incorporates loss and delay models of the link in the
selection process of the chunk to be transmitted. Our simulations show that MDF
significantly reduces the expected time required for all the chunks (or
equivalently, all the message packets) to be decodable compared to the existing
scheduling policies for line networks with feedback. The improvements are
particularly profound (up to about 46% for the tested cases) for smaller chunks
and larger networks which are of more practical interest. The improvement in
the performance of the proposed scheduling policy comes at the cost of more
computations, and a slight increase in the amount of feedback. We also propose
a low-complexity version of MDF with a rather small loss in the performance,
referred to as minimumcurrent-metric-first (MCMF). The MCMF policy is based on
the expected number of innovative packet transmissions prior to the &quot;current&quot;
transmission time, as opposed to the next transmission time, used in MDF. Our
simulations (over line networks) demonstrate that MCMF is always superior to RP
and LRF policies, and the superiority becomes more pronounced for smaller
chunks and larger networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4715</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4715</id><created>2012-07-19</created><authors><author><keyname>Petrovi&#x107;</keyname><forenames>Tomislav</forenames></author></authors><title>&quot;Two betting strategies that predict all compressible sequences&quot;
  presentation</title><categories>cs.CC</categories><comments>the prezentacija.tex file also contains text that goes with each
  slide, it's in the comments at the end of the file</comments><msc-class>68Q30</msc-class><acm-class>F.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Presentation for a talk &quot;Two betting strategies that predict all compressible
sequences&quot; given at Seventh International Conference on Computability,
Complexity and Randomness (CCR 2012)
http://www.newton.ac.uk/programmes/SAS/seminars/070217001.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4738</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4738</id><created>2012-07-19</created><updated>2013-08-28</updated><authors><author><keyname>Kubena</keyname><forenames>Ales Antonin</forenames></author><author><keyname>Franek</keyname><forenames>Peter</forenames></author></authors><title>Symmetries of Quasi-Values</title><categories>cs.GT math.CO math.GR</categories><msc-class>91A12, 91A46, 05A15, 20B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to Shapley's game-theoretical result, there exists a unique game
value of finite cooperative games that satisfies axioms on additivity,
efficiency, null-player property and symmetry. The original setting requires
symmetry with respect to arbitrary permutations of players. We analyze the
consequences of weakening the symmetry axioms and study quasi-values that are
symmetric with respect to permutations from a group $G\leq S_n$. We classify
all the permutation groups $G$ that are large enough to assure a unique
$G$-symmetric quasi-value, as well as the structure and dimension of the space
of all such quasi-values for a general permutation group $G$.
  We show how to construct $G$-symmetric quasi-values algorithmically by
averaging certain basic quasi-values (marginal operators).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4746</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4746</id><created>2012-07-19</created><authors><author><keyname>Poletto</keyname><forenames>Chiara</forenames></author><author><keyname>Tizzoni</keyname><forenames>Michele</forenames></author><author><keyname>Colizza</keyname><forenames>Vittoria</forenames></author></authors><title>Heterogeneous length of stay of hosts' movements and spatial epidemic
  spread</title><categories>physics.soc-ph cs.SI</categories><comments>31 pages, 7 figures</comments><journal-ref>Scientific Reports 2, Article number: 476, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Infectious diseases outbreaks are often characterized by a spatial component
induced by hosts' distribution, mobility, and interactions. Spatial models that
incorporate hosts' movements are being used to describe these processes, to
investigate the conditions for propagation, and to predict the spatial spread.
Several assumptions are being considered to model hosts' movements, ranging
from permanent movements to daily commuting, where the time spent at
destination is either infinite or assumes a homogeneous fixed value,
respectively. Prompted by empirical evidence, here we introduce a general
metapopulation approach to model the disease dynamics in a spatially structured
population where the mobility process is characterized by a heterogeneous
length of stay. We show that large fluctuations of the length of stay, as
observed in reality, can have a significant impact on the threshold conditions
for the global epidemic invasion, thus altering model predictions based on
simple assumptions, and displaying important public health implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4747</identifier>
 <datestamp>2013-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4747</id><created>2012-07-19</created><updated>2013-01-14</updated><authors><author><keyname>Lacoste-Julien</keyname><forenames>Simon</forenames></author><author><keyname>Jaggi</keyname><forenames>Martin</forenames></author><author><keyname>Schmidt</keyname><forenames>Mark</forenames></author><author><keyname>Pletscher</keyname><forenames>Patrick</forenames></author></authors><title>Block-Coordinate Frank-Wolfe Optimization for Structural SVMs</title><categories>cs.LG math.OC stat.ML</categories><comments>Appears in Proceedings of the 30th International Conference on
  Machine Learning (ICML 2013). 9 pages main text + 22 pages appendix. Changes
  from v3 to v4: 1) Re-organized appendix; improved &amp; clarified duality gap
  proofs; re-drew all plots; 2) Changed convention for Cf definition; 3) Added
  weighted averaging experiments + convergence results; 4) Clarified main text
  and relationship with appendix</comments><msc-class>90C52, 90C90, 90C06, 68T05</msc-class><acm-class>G.1.6; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a randomized block-coordinate variant of the classic Frank-Wolfe
algorithm for convex optimization with block-separable constraints. Despite its
lower iteration cost, we show that it achieves a similar convergence rate in
duality gap as the full Frank-Wolfe algorithm. We also show that, when applied
to the dual structural support vector machine (SVM) objective, this yields an
online algorithm that has the same low iteration complexity as primal
stochastic subgradient methods. However, unlike stochastic subgradient methods,
the block-coordinate Frank-Wolfe algorithm allows us to compute the optimal
step-size and yields a computable duality gap guarantee. Our experiments
indicate that this simple algorithm outperforms competing structural SVM
solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4748</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4748</id><created>2012-07-19</created><authors><author><keyname>Eriksson</keyname><forenames>Brian</forenames></author></authors><title>Hierarchical Clustering using Randomly Selected Similarities</title><categories>stat.ML cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of hierarchical clustering items from pairwise similarities is
found across various scientific disciplines, from biology to networking. Often,
applications of clustering techniques are limited by the cost of obtaining
similarities between pairs of items. While prior work has been developed to
reconstruct clustering using a significantly reduced set of pairwise
similarities via adaptive measurements, these techniques are only applicable
when choice of similarities are available to the user. In this paper, we
examine reconstructing hierarchical clustering under similarity observations
at-random. We derive precise bounds which show that a significant fraction of
the hierarchical clustering can be recovered using fewer than all the pairwise
similarities. We find that the correct hierarchical clustering down to a
constant fraction of the total number of items (i.e., clusters sized O(N)) can
be found using only O(N log N) randomly selected pairwise similarities in
expectation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4763</identifier>
 <datestamp>2013-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4763</id><created>2012-07-19</created><updated>2013-02-18</updated><authors><author><keyname>Zlatanov</keyname><forenames>Nikola</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Buffer-Aided Relaying with Adaptive Link Selection - Fixed and Mixed
  Rate Transmission</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory. (Published)</comments><doi>10.1109/TIT.2013.2238607</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a simple network consisting of a source, a half-duplex DF relay
with a buffer, and a destination. We assume that the direct source-destination
link is not available and all links undergo fading. We propose two new
buffer-aided relaying schemes. In the first scheme, neither the source nor the
relay have CSIT, and consequently, both nodes are forced to transmit with fixed
rates. In contrast, in the second scheme, the source does not have CSIT and
transmits with fixed rate but the relay has CSIT and adapts its transmission
rate accordingly. In the absence of delay constraints, for both fixed rate and
mixed rate transmission, we derive the throughput-optimal buffer-aided relaying
protocols which select either the source or the relay for transmission based on
the instantaneous SNRs of the source-relay and the relay-destination links. In
addition, for the delay constrained case, we develop buffer-aided relaying
protocols that achieve a predefined average delay. Compared to conventional
relaying protocols, which select the transmitting node according to a
predefined schedule independent of the link instantaneous SNRs, the proposed
buffer-aided protocols with adaptive link selection achieve large performance
gains. In particular, for fixed rate transmission, we show that the proposed
protocol achieves a diversity gain of two as long as an average delay of more
than three time slots can be afforded. Furthermore, for mixed rate transmission
with an average delay of $E{T}$ time slots, a multiplexing gain of
$r=1-1/(2E{T})$ is achieved. Hence, for mixed rate transmission, for
sufficiently large average delays, buffer-aided half-duplex relaying with and
without adaptive link selection does not suffer from a multiplexing gain loss
compared to full-duplex relaying.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4766</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4766</id><created>2012-07-19</created><authors><author><keyname>Briat</keyname><forenames>Corentin</forenames></author><author><keyname>Khammash</keyname><forenames>Mustafa</forenames></author></authors><title>Computer control of gene expression: Robust setpoint tracking of protein
  mean and variance using integral feedback</title><categories>math.OC cs.SY q-bio.MN q-bio.QM</categories><comments>8 pages; 4 figures; Accepted for publication at the 51st IEEE
  Conference on Decision and Control, Maui, Hawaii, USA, December 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protein mean and variance levels in a simple stochastic gene expression
circuit are controlled using proportional integral feedback. It is shown that
the protein mean level can be globally and robustly tracked to any desired
value using a simple PI controller that satisfies explicit sufficient
conditions. Controlling both the mean and variance on the other hand requires
the use of an additional control input, chosen here as the mRNA degradation
rate. Local robust tracking of mean and variance is proved to be achievable
using multivariable PI control, provided that the reference point satisfies
necessary conditions imposed by the system. Even more importantly, it is shown
that there exist PI controllers that locally, robustly and simultaneously
stabilize all the equilibrium points inside the admissible region. Simulation
examples illustrate the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4776</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4776</id><created>2012-07-19</created><authors><author><keyname>Brock</keyname><forenames>Anke</forenames><affiliation>IRIT</affiliation></author><author><keyname>Truillet</keyname><forenames>Philippe</forenames><affiliation>IRIT</affiliation></author><author><keyname>Oriola</keyname><forenames>Bernard</forenames><affiliation>IRIT</affiliation></author><author><keyname>Picard</keyname><forenames>Delphine</forenames><affiliation>Octogone</affiliation></author><author><keyname>Jouffrais</keyname><forenames>Christophe</forenames><affiliation>IRIT</affiliation></author></authors><title>Design and User Satisfaction of Interactive Maps for Visually Impaired
  People</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>ICCHP 2012 (2012) 544-551</journal-ref><doi>10.1007/978-3-642-31534-3_80</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimodal interactive maps are a solution for presenting spatial information
to visually impaired people. In this paper, we present an interactive
multimodal map prototype that is based on a tactile paper map, a multi-touch
screen and audio output. We first describe the different steps for designing an
interactive map: drawing and printing the tactile paper map, choice of
multi-touch technology, interaction technologies and the software architecture.
Then we describe the method used to assess user satisfaction. We provide data
showing that an interactive map - although based on a unique, elementary,
double tap interaction - has been met with a high level of user satisfaction.
Interestingly, satisfaction is independent of a user's age, previous visual
experience or Braille experience. This prototype will be used as a platform to
design advanced interactions for spatial learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4783</identifier>
 <datestamp>2012-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4783</id><created>2012-07-19</created><authors><author><keyname>Arora</keyname><forenames>Sanjeev</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Manokaran</keyname><forenames>Rajsekar</forenames></author><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author></authors><title>Testing Permanent Oracles -- Revisited</title><categories>cs.DS cs.CC</categories><comments>Appears at RANDOM '12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we are given an oracle that claims to approximate the permanent for
most matrices X, where X is chosen from the Gaussian ensemble (the matrix
entries are i.i.d. univariate complex Gaussians). Can we test that the oracle
satisfies this claim? This paper gives a polynomial-time algorithm for the
task. The oracle-testing problem is of interest because a recent paper of
Aaronson and Arkhipov showed that if there is a polynomial-time algorithm for
simulating boson-boson interactions in quantum mechanics, then an approximation
oracle for the permanent (of the type described above) exists in BPP^NP. Since
computing the permanent of even 0/1 matrices is #P-complete, this seems to
demonstrate more computational power in quantum mechanics than Shor's factoring
algorithm does. However, unlike factoring, which is in NP, it was unclear
previously how to test the correctness of an approximation oracle for the
permanent, and this is the contribution of the paper. The technical difficulty
overcome here is that univariate polynomial self-correction, which underlies
similar oracle-testing algorithms for permanent over finite fields --- and
whose discovery led to a revolution in complexity theory --- does not seem to
generalize to complex (or even, real) numbers. We believe that this tester will
motivate further progress on understanding the permanent of Gaussian matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4800</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4800</id><created>2012-07-19</created><authors><author><keyname>Planjery</keyname><forenames>Shiva Kumar</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author><author><keyname>Danjean</keyname><forenames>Ludovic</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author></authors><title>Finite Alphabet Iterative Decoders, Part I: Decoding Beyond Belief
  Propagation on BSC</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications, 26 pages, 6
  Figures, 2 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new paradigm for finite precision iterative decoding on
low-density parity-check codes over the Binary Symmetric channel. The messages
take values from a finite alphabet, and unlike traditional quantized decoders
which are quantized versions of the Belief propagation (BP) decoder, the
proposed finite alphabet iterative decoders (FAIDs) do not propagate quantized
probabilities or log-likelihoods and the variable node update functions do not
mimic the BP decoder. Rather, the update functions are maps designed using the
knowledge of potentially harmful subgraphs that could be present in a given
code, thereby rendering these decoders capable of outperforming the BP in the
error floor region. On certain column-weight-three codes of practical interest,
we show that there exist 3-bit precision FAIDs that surpass the BP decoder in
the error floor. Hence, FAIDs are able to achieve a superior performance at
much lower complexity. We also provide a methodology for the selection of FAIDs
that is not code-specific, but gives a set of candidate FAIDs containing
potentially good decoders in the error floor region for any column-weight-three
code. We validate the code generality of our methodology by providing
particularly good three-bit precision FAIDs for a variety of codes with
different rates and lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4804</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4804</id><created>2012-07-19</created><authors><author><keyname>Abdo</keyname><forenames>Hosam</forenames></author><author><keyname>Cohen</keyname><forenames>Nathann</forenames></author><author><keyname>Dimitrov</keyname><forenames>Darko</forenames></author></authors><title>Bounds and Computation of Irregularity of a Graph</title><categories>cs.DM math.CO</categories><comments>13 Pages, 3 figures, Journal Paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Albertson has defined the irregularity of a simple undirected graph $G=(V,E)$
as $ \irr(G) = \sum_{uv\in E}|d_G(u)-d_G(v)|,$ where $d_G(u)$ denotes the
degree of a vertex $u \in V$. Recently, this graph invariant gained interest in
the chemical graph theory, where it occured in some bounds on the first and the
second Zagreb index, and was named the third Zagreb index Fath-Tabar. For
general graphs with $n$ vertices, Albertson has obtained an asymptotically
tight upper bound on the irregularity of $4 n^3 /27.$ Here, by exploiting a
different approach than in Albertson, we show that for general graphs with $n$
vertices the upper bound $\lfloor \frac{n}{3} \rfloor \lceil \frac{2 n}{3}
\rceil (\lceil \frac{2 n}{3} \rceil -1)$ is sharp. Next, we determine
$k$-cyclic graphs with maximal irregularity. We also present some bounds on the
maximal/minimal irregularity of graphs with fixed minimal and/or maximal vertex
degrees, and consider an approximate computation of the irregularity of a
graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4807</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4807</id><created>2012-07-19</created><authors><author><keyname>Declercq</keyname><forenames>David</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Planjery</keyname><forenames>Shiva Kumar</forenames></author><author><keyname>Li</keyname><forenames>Erbao</forenames></author></authors><title>Finite Alphabet Iterative Decoders, Part II: Improved Guaranteed Error
  Correction of LDPC Codes via Iterative Decoder Diversity</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications, 29 Pages, 3
  Figures, 7 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, we introduced a new class of finite alphabet iterative decoders
(FAIDs) for low-density parity-check (LDPC) codes. These decoders are capable
of surpassing belief propagation in the error floor region on the Binary
Symmetric channel with much lower complexity. In this paper, we introduce a a
novel scheme to further increase the guaranteed error correction capability
from what is achievable by a FAID on column-weight-three LDPC codes. The
proposed scheme uses a plurality of FAIDs which collectively correct more error
patterns than a single FAID on a given code. The collection of FAIDs utilized
by the scheme is judiciously chosen to ensure that individual decoders have
different decoding dynamics and correct different error patterns. Consequently,
they can collectively correct a diverse set of error patterns, which is
referred to as decoder diversity. We provide a systematic method to generate
the set of FAIDs for decoder diversity on a given code based on the knowledge
of the most harmful trapping sets present in the code. Using the well-known
column-weight-three $(155,64)$ Tanner code with $d_{min}$ = 20 as an example,
we describe the method in detail and show that the guaranteed error correction
capability can be significantly increased with decoder diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4813</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4813</id><created>2012-07-19</created><authors><author><keyname>Chac&#xf3;n</keyname><forenames>Jos&#xe9; Luis</forenames></author><author><keyname>P&#xe9;rez</keyname><forenames>Ram&#xf3;n Pino</forenames></author></authors><title>Exploring the rationality of some syntactic merging operators (extended
  version)</title><categories>cs.AI</categories><msc-class>68T30, 68T27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most merging operators are defined by semantics methods which have very high
computational complexity. In order to have operators with a lower computational
complexity, some merging operators defined in a syntactical way have be
proposed. In this work we define some syntactical merging operators and
exploring its rationality properties. To do that we constrain the belief bases
to be sets of formulas very close to logic programs and the underlying logic is
defined through forward chaining rule (Modus Ponens). We propose two types of
operators: arbitration operators when the inputs are only two bases and fusion
with integrity constraints operators. We introduce a set of postulates inspired
of postulates LS, proposed by Liberatore and Shaerf and then we analyzed the
first class of operators through these postulates. We also introduce a set of
postulates inspired of postulates KP, proposed by Konieczny and Pino P\'erez
and then we analyzed the second class of operators through these postulates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4814</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4814</id><created>2012-07-19</created><authors><author><keyname>Bui</keyname><forenames>Hung Hai</forenames></author><author><keyname>Huynh</keyname><forenames>Tuyen N.</forenames></author><author><keyname>Riedel</keyname><forenames>Sebastian</forenames></author></authors><title>Automorphism Groups of Graphical Models and Lifted Variational Inference</title><categories>cs.AI cs.LG math.CO stat.CO stat.ML</categories><comments>Extended version of the paper to appear in Statistical Relational AI
  (StaRAI-12) workshop at UAI '12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the theory of group action, we first introduce the concept of the
automorphism group of an exponential family or a graphical model, thus
formalizing the general notion of symmetry of a probabilistic model. This
automorphism group provides a precise mathematical framework for lifted
inference in the general exponential family. Its group action partitions the
set of random variables and feature functions into equivalent classes (called
orbits) having identical marginals and expectations. Then the inference problem
is effectively reduced to that of computing marginals or expectations for each
class, thus avoiding the need to deal with each individual variable or feature.
We demonstrate the usefulness of this general framework in lifting two classes
of variational approximation for MAP inference: local LP relaxation and local
LP relaxation with cycle constraints; the latter yields the first lifted
inference that operate on a bound tighter than local constraints. Initial
experimental results demonstrate that lifted MAP inference with cycle
constraints achieved the state of the art performance, obtaining much better
objective function values than local approximation while remaining relatively
efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4821</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4821</id><created>2012-07-19</created><authors><author><keyname>Macdonald</keyname><forenames>Angus</forenames></author></authors><title>The Architecture of an Autonomic, Resource-Aware, Workstation-Based
  Distributed Database System</title><categories>cs.DB cs.DC</categories><comments>Ph.D. Thesis</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Distributed software systems that are designed to run over workstation
machines within organisations are termed workstation-based. Workstation-based
systems are characterised by dynamically changing sets of machines that are
used primarily for other, user-centric tasks. They must be able to adapt to and
utilize spare capacity when and where it is available, and ensure that the
non-availability of an individual machine does not affect the availability of
the system. This thesis focuses on the requirements and design of a
workstation-based database system, which is motivated by an analysis of
existing database architectures that are typically run over static, specially
provisioned sets of machines. A typical clustered database system -- one that
is run over a number of specially provisioned machines -- executes queries
interactively, returning a synchronous response to applications, with its data
made durable and resilient to the failure of machines. There are no existing
workstation-based databases. Furthermore, other workstation-based systems do
not attempt to achieve the requirements of interactivity and durability,
because they are typically used to execute asynchronous batch processing jobs
that tolerate data loss -- results can be re-computed. These systems use
external servers to store the final results of computations rather than
workstation machines. This thesis describes the design and implementation of a
workstation-based database system and investigates its viability by evaluating
its performance against existing clustered database systems and testing its
availability during machine failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4825</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4825</id><created>2012-07-19</created><authors><author><keyname>Sethu</keyname><forenames>Harish</forenames></author><author><keyname>Chu</keyname><forenames>Xiaoyu</forenames></author></authors><title>A new algorithm for extracting a small representative subgraph from a
  very large graph</title><categories>cs.DS cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world networks are prohibitively large for data retrieval, storage
and analysis of all of its nodes and links. Understanding the structure and
dynamics of these networks entails creating a smaller representative sample of
the full graph while preserving its relevant topological properties. In this
report, we show that graph sampling algorithms currently proposed in the
literature are not able to preserve network properties even with sample sizes
containing as many as 20% of the nodes from the original graph. We present a
new sampling algorithm, called Tiny Sample Extractor, with a new goal of a
sample size smaller than 5% of the original graph while preserving two key
properties of a network, the degree distribution and its clustering
co-efficient. Our approach is based on a new empirical method of estimating
measurement biases in crawling algorithms and compensating for them
accordingly. We present a detailed comparison of best known graph sampling
algorithms, focusing in particular on how the properties of the sample
subgraphs converge to those of the original graph as they grow. These results
show that our sampling algorithm extracts a smaller subgraph than other
algorithms while also achieving a closer convergence to the degree
distribution, measured by the degree exponent, of the original graph. The
subgraph generated by the Tiny Sample Extractor, however, is not necessarily
representative of the full graph with regard to other properties such as
assortativity. This indicates that the problem of extracting a truly
representative small subgraph from a large graph remains unsolved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4831</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4831</id><created>2012-07-19</created><updated>2013-05-26</updated><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Gatsis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Robust Energy Management for Microgrids With High-Penetration Renewables</title><categories>math.OC cs.SY</categories><comments>Short versions were accepted by the IEEE Transactions on Sustainable
  Energy, and presented in part at the IEEE SmartGridComm 2012</comments><doi>10.1109/TSTE.2013.2255135</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to its reduced communication overhead and robustness to failures,
distributed energy management is of paramount importance in smart grids,
especially in microgrids, which feature distributed generation (DG) and
distributed storage (DS). Distributed economic dispatch for a microgrid with
high renewable energy penetration and demand-side management operating in
grid-connected mode is considered in this paper. To address the intrinsically
stochastic availability of renewable energy sources (RES), a novel power
scheduling approach is introduced. The approach involves the actual renewable
energy as well as the energy traded with the main grid, so that the
supply-demand balance is maintained. The optimal scheduling strategy minimizes
the microgrid net cost, which includes DG and DS costs, utility of dispatchable
loads, and worst-case transaction cost stemming from the uncertainty in RES.
Leveraging the dual decomposition, the optimization problem formulated is
solved in a distributed fashion by the local controllers of DG, DS, and
dispatchable loads. Numerical results are reported to corroborate the
effectiveness of the novel approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4860</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4860</id><created>2012-07-20</created><updated>2013-10-26</updated><authors><author><keyname>Sato</keyname><forenames>Aki-Hiro</forenames></author></authors><title>Inference of Extreme Synchrony with an Entropy Measure on a Bipartite
  Network</title><categories>physics.data-an cs.CE physics.soc-ph q-fin.RM</categories><comments>9 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article proposes a method to quantify the structure of a bipartite graph
using a network entropy per link. The network entropy of a bipartite graph with
random links is calculated both numerically and theoretically. As an
application of the proposed method to analyze collective behavior, the affairs
in which participants quote and trade in the foreign exchange market are
quantified. The network entropy per link is found to correspond to the
macroeconomic situation. A finite mixture of Gumbel distributions is used to
fit the empirical distribution for the minimum values of network entropy per
link in each week. The mixture of Gumbel distributions with parameter estimates
by segmentation procedure is verified by the Kolmogorov--Smirnov test. The
finite mixture of Gumbel distributions that extrapolate the empirical
probability of extreme events has explanatory power at a statistically
significant level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4871</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4871</id><created>2012-07-20</created><authors><author><keyname>Avanesov</keyname><forenames>Tigran</forenames><affiliation>S'nT</affiliation></author><author><keyname>Chevalier</keyname><forenames>Yannick</forenames><affiliation>IRIT</affiliation></author><author><keyname>Rusinowitch</keyname><forenames>Micha&#xeb;l</forenames></author><author><keyname>Turuani</keyname><forenames>Mathieu</forenames></author></authors><title>Intruder deducibility constraints with negation. Decidability and
  application to secured service compositions</title><categories>cs.CR</categories><comments>(2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of finding a mediator to compose secured services has been
reduced in our former work to the problem of solving deducibility constraints
similar to those employed for cryptographic protocol analysis. We extend in
this paper the mediator synthesis procedure by a construction for expressing
that some data is not accessible to the mediator. Then we give a decision
procedure for verifying that a mediator satisfying this non-disclosure policy
can be effectively synthesized. This procedure has been implemented in CL-AtSe,
our protocol analysis tool. The procedure extends constraint solving for
cryptographic protocol analysis in a significative way as it is able to handle
negative deducibility constraints without restriction. In particular it applies
to all subterm convergent theories and therefore covers several interesting
theories in formal security analysis including encryption, hashing, signature
and pairing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4883</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4883</id><created>2012-07-20</created><updated>2013-07-15</updated><authors><author><keyname>Bah</keyname><forenames>Bubacarr</forenames></author><author><keyname>Tanner</keyname><forenames>Jared</forenames></author></authors><title>Bounds of restricted isometry constants in extreme asymptotics: formulae
  for Gaussian matrices</title><categories>math.NA cs.IT math.IT</categories><comments>40 pages, 5 figures</comments><msc-class>15B52, 60F10, 94A20 (Primary) 94A12 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restricted Isometry Constants (RICs) provide a measure of how far from an
isometry a matrix can be when acting on sparse vectors. This, and related
quantities, provide a mechanism by which standard eigen-analysis can be applied
to topics relying on sparsity. RIC bounds have been presented for a variety of
random matrices and matrix dimension and sparsity ranges. We provide explicitly
formulae for RIC bounds, of n by N Gaussian matrices with sparsity k, in three
settings: a) n/N fixed and k/n approaching zero, b) k/n fixed and n/N
approaching zero, and c) n/N approaching zero with k/n decaying inverse
logrithmically in N/n; in these three settings the RICs a) decay to zero, b)
become unbounded (or approach inherent bounds), and c) approach a non-zero
constant. Implications of these results for RIC based analysis of compressed
sensing algorithms are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4884</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4884</id><created>2012-07-20</created><updated>2014-05-16</updated><authors><author><keyname>Braun</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Pokutta</keyname><forenames>Sebastian</forenames></author></authors><title>A short proof for the polyhedrality of the Chv\'atal-Gomory closure of a
  compact convex set</title><categories>math.CO cs.CG cs.DM math.MG</categories><comments>7 pages, minor corrections</comments><msc-class>90C25, 90C05, 90C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently Schrijver's open problem, whether the Chv\'atal--Gomory closure of
an irrational polytope is polyhedral was answered independently in the
affirmative by Dadush, Dey, and Vielma (even for arbitrarily compact convex
set) as well as by Dunkel and Schulz. We present a very short, easily accesible
proof that the Chv\'atal--Gomory closure of a compact convex set is a polytope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4900</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4900</id><created>2012-07-20</created><authors><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>Kernel Bounds for Structural Parameterizations of Pathwidth</title><categories>cs.DS cs.CC</categories><comments>This paper contains the proofs omitted from the extended abstract
  published in the proceedings of Algorithm Theory - SWAT 2012 - 13th
  Scandinavian Symposium and Workshops, Helsinki, Finland, July 4-6, 2012</comments><msc-class>05C85, 68R10, 68Q25</msc-class><acm-class>F.2.2; G.2.2</acm-class><journal-ref>Lecture Notes in Computer Science 7357 (2012) 352-363</journal-ref><doi>10.1007/978-3-642-31155-0_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assuming the AND-distillation conjecture, the Pathwidth problem of
determining whether a given graph G has pathwidth at most k admits no
polynomial kernelization with respect to k. The present work studies the
existence of polynomial kernels for Pathwidth with respect to other,
structural, parameters. Our main result is that, unless NP is in coNP/poly,
Pathwidth admits no polynomial kernelization even when parameterized by the
vertex deletion distance to a clique, by giving a cross-composition from
Cutwidth. The cross-composition works also for Treewidth, improving over
previous lower bounds by the present authors. For Pathwidth, our result rules
out polynomial kernels with respect to the distance to various classes of
polynomial-time solvable inputs, like interval or cluster graphs. This leads to
the question whether there are nontrivial structural parameters for which
Pathwidth does admit a polynomial kernelization. To answer this, we give a
collection of graph reduction rules that are safe for Pathwidth. We analyze the
success of these results and obtain polynomial kernelizations with respect to
the following parameters: the size of a vertex cover of the graph, the vertex
deletion distance to a graph where each connected component is a star, and the
vertex deletion distance to a graph where each connected component has at most
c vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4911</identifier>
 <datestamp>2012-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4911</id><created>2012-07-20</created><updated>2012-10-10</updated><authors><author><keyname>Toyota</keyname><forenames>Norihito</forenames></author></authors><title>Second Parrondo's Paradox in Scale Free Networks</title><categories>physics.soc-ph cs.GT</categories><comments>10 pages, 5 figures, 1 Table. In new version, I refined some
  discussions in the section 4 and corrected some trivial typing errors. arXiv
  admin note: substantial text overlap with arXiv:1204.5249</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parrondo's paradox occurs in sequences of games in which a winning
expectation value of a payoff may be obtained by playing two games in a random
order, even though each game in the sequence may be lost when played
individually.Several variations of Parrondo's games apparently with the same
paradoxical property have been introduced by G.P. Harmer and D. Abbott; history
dependence, one dimensional line, two dimensional lattice and so on. I have
shown that Parrondo's paradox does not occur in scale free networks in the
simplest case with the same number of parameters as the original Parrondo's
paradox. It suggests that some technical complexities are needed to present
Parrondo's paradox in scale free networks. In this article, I show that a
simple modification with the same number of parameters as the original
Parrondo's paradox creates Parrondo's paradox in scale free. This paradox is,
however, created by a quite different mechanism from the original Parrondo's
paradox and a considerably rare phenomenon, where the discrete property of
degree of nodes is crucial. I call it the second Parrondo's paradox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4914</identifier>
 <datestamp>2013-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4914</id><created>2012-07-20</created><updated>2012-11-22</updated><authors><author><keyname>T&#xf6;r&#xf6;k</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>I&#xf1;iguez</keyname><forenames>Gerardo</forenames></author><author><keyname>Yasseri</keyname><forenames>Taha</forenames></author><author><keyname>Miguel</keyname><forenames>Maxi San</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>Opinions, Conflicts and Consensus: Modeling Social Dynamics in a
  Collaborative Environment</title><categories>physics.soc-ph cs.CY cs.SI nlin.AO</categories><comments>6 pages, 5 figures. Submitted for publication</comments><journal-ref>Phys. Rev. Lett. 110 (8), 088701 (2013)</journal-ref><doi>10.1103/PhysRevLett.110.088701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information-communication technology promotes collaborative environments like
Wikipedia where, however, controversiality and conflicts can appear. To
describe the rise, persistence, and resolution of such conflicts we devise an
extended opinion dynamics model where agents with different opinions perform a
single task to make a consensual product. As a function of the convergence
parameter describing the influence of the product on the agents, the model
shows spontaneous symmetry breaking of the final consensus opinion represented
by the medium. In the case when agents are replaced with new ones at a certain
rate, a transition from mainly consensus to a perpetual conflict occurs, which
is in qualitative agreement with the scenarios observed in Wikipedia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4931</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4931</id><created>2012-07-20</created><authors><author><keyname>Tripathi</keyname><forenames>G. N.</forenames></author><author><keyname>Rihani</keyname><forenames>V.</forenames></author></authors><title>Motion Planning Of an Autonomous Mobile Robot Using Artificial Neural
  Network</title><categories>cs.RO cs.AI cs.LG cs.NE</categories><comments>7 pages, 4 figures, 1 table, 1 graph chart, ITCA-2012, Chennai, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents the electronic design and motion planning of a robot based
on decision making regarding its straight motion and precise turn using
Artificial Neural Network (ANN). The ANN helps in learning of robot so that it
performs motion autonomously. The weights calculated are implemented in
microcontroller. The performance has been tested to be excellent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4933</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4933</id><created>2012-07-20</created><authors><author><keyname>McCullen</keyname><forenames>Nicholas J.</forenames></author><author><keyname>Rucklidge</keyname><forenames>Alastair M.</forenames></author><author><keyname>Bale</keyname><forenames>Catherine S. E.</forenames></author><author><keyname>Foxon</keyname><forenames>Tim J.</forenames></author><author><keyname>Gale</keyname><forenames>William F.</forenames></author></authors><title>Multi-parameter models of innovation diffusion on complex networks</title><categories>nlin.AO cs.MA cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model, applicable to a range of innovation diffusion applications with a
strong peer to peer component, is developed and studied, along with methods for
its investigation and analysis. A particular application is to individual
households deciding whether to install an energy efficiency measure in their
home. The model represents these individuals as nodes on a network, each with a
variable representing their current state of adoption of the innovation. The
motivation to adopt is composed of three terms, representing personal
preference, an average of each individual's network neighbours' states and a
system average, which is a measure of the current social trend. The adoption
state of a node changes if a weighted linear combination of these factors
exceeds some threshold. Numerical simulations have been carried out, computing
the average uptake after a sufficient number of time-steps over many
realisations at a range of model parameter values, on various network
topologies, including random (Erdos-Renyi), small world (Watts-Strogatz) and
(Newman's) highly clustered, community-based networks. An analytical and
probabilistic approach has been developed to account for the observed
behaviour, which explains the results of the numerical calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4938</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4938</id><created>2012-07-20</created><authors><author><keyname>Basha</keyname><forenames>N. Md. Jubair</forenames></author><author><keyname>Moiz</keyname><forenames>Salman Abdul</forenames></author></authors><title>A Methodology to manage victim components using CBO measure</title><categories>cs.SE</categories><comments>10 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1202.5609</comments><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.3, No.2, March 2012, 87-96</journal-ref><doi>10.5121/ijsea.2012.3207</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current practices of software industry demands development of a software
within time and budget which is highly productive. The traditional approach of
developing a software from scratch requires considerable amount of effort. To
overcome the drawback a reuse drive software development approach is adopted.
However there is a dire need for realizing effective software reuse. This paper
presents several measures of reusability and presents a methodology of
reconfiguring the victim components. The CBO measure helps in identifying the
component to be reconfigured. The proposed strategy is simulated using HR
portal domain specific component system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4940</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4940</id><created>2012-07-20</created><authors><author><keyname>Neji</keyname><forenames>Hasni</forenames></author></authors><title>Ontology for Cellular Communication</title><categories>cs.SE cs.AI</categories><comments>4 pages, the Tunisian Japanese Symposium on Science, Society and
  Technology, Tunisia, NOVEMBER 11th-13th 2011; Proceedings of the Tunisian
  Japanese Symposium on Science, Society and Technology, Tunisia, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of interoperability between mobile cellular access networks has long
been a challenging obstacle, which telecommunication engineering is trying to
overcome. In second generation networks for example, this problem lies in the
fact that there are multiple standards. Each of these standards can operate in
the same frequency range. However, each utilizes a different Radio Technology
and Modulation Scheme, which are characteristics of the standard. Therefore,
the lack of interoperability in 2G occurs because of the lack of
standardization. Interoperability within 3G networks is limited to a few
operating modes using different Radio Transmission Technologies that are not
inter-operable. Thus, interoperability remains an issue for 3G. 4G technology
even being successful in its various trials cannot guarantee the
interoperability. This is within each network generation; meanwhile between
heterogeneous network generations the situation seems to be worst. This
approach is first to analyze the structure, inputs, and outputs of three
different cellular technologies, performing a domain analysis (of this subset
of technologies) and producing a feature model of the domain. Finally, we
sought to build an ontology capable of providing a common view of the domain,
providing an effective representation of relations between representations of
corresponding concepts in different cellular technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4941</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4941</id><created>2012-07-20</created><updated>2013-04-26</updated><authors><author><keyname>Bloznelis</keyname><forenames>Mindaugas</forenames></author><author><keyname>Kurauskas</keyname><forenames>Valentas</forenames></author></authors><title>Clustering function: a measure of social influence</title><categories>stat.AP cs.SI math.CO math.PR physics.soc-ph</categories><comments>Revised argument in section 5. Correction: factor 0.5 has been
  removed from denominator in (12), (13)</comments><msc-class>91D30, 05C80, 05C07, 91C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A commonly used characteristic of statistical dependence of adjacency
relations in real networks, the clustering coefficient, evaluates chances that
two neighbours of a given vertex are adjacent. An extension is obtained by
considering conditional probabilities that two randomly chosen vertices are
adjacent given that they have r common neighbours. We denote such probabilities
cl(r) and call r-&gt; cl(r) the clustering function.
  We compare clustering functions of several networks having non-negligible
clustering coefficient. They show similar patterns and surprising regularity.
We establish a first order asymptotic (as the number of vertices tends to
infinity) of the clustering function of related random intersection graph
models admitting nonvanishing clustering coefficient and asymptotic degree
distribution having a finite second moment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4948</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4948</id><created>2012-07-20</created><authors><author><keyname>Morcrette</keyname><forenames>Basile</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Mahmoud</keyname><forenames>Hosam M.</forenames></author></authors><title>Exactly Solvable Balanced Tenable Urns with Random Entries via the
  Analytic Methodology</title><categories>math.CO cs.DM math.PR</categories><comments>23rd International Meeting on Probabilistic, Combinatorial, and
  Asymptotic Methods for the Analysis of Algorithms (AofA'12), Montreal :
  Canada (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops an analytic theory for the study of some Polya urns with
random rules. The idea is to extend the isomorphism theorem in Flajolet et al.
(2006), which connects deterministic balanced urns to a differential system for
the generating function. The methodology is based upon adaptation of operators
and use of a weighted probability generating function. Systems of differential
equations are developed, and when they can be solved, they lead to
characterization of the exact distributions underlying the urn evolution. We
give a few illustrative examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4958</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4958</id><created>2012-07-11</created><authors><author><keyname>Gupta</keyname><forenames>Ashish</forenames></author><author><keyname>Mittal</keyname><forenames>Akshay</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author></authors><title>Minimally Infrequent Itemset Mining using Pattern-Growth Paradigm and
  Residual Trees</title><categories>cs.DB</categories><comments>Best paper award in International Conference on Management of Data
  (COMAD), 2011</comments><acm-class>H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Itemset mining has been an active area of research due to its successful
application in various data mining scenarios including finding association
rules. Though most of the past work has been on finding frequent itemsets,
infrequent itemset mining has demonstrated its utility in web mining,
bioinformatics and other fields. In this paper, we propose a new algorithm
based on the pattern-growth paradigm to find minimally infrequent itemsets. A
minimally infrequent itemset has no subset which is also infrequent. We also
introduce the novel concept of residual trees. We further utilize the residual
trees to mine multiple level minimum support itemsets where different
thresholds are used for finding frequent itemsets for different lengths of the
itemset. Finally, we analyze the behavior of our algorithm with respect to
different parameters and show through experiments that it outperforms the
competing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4966</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4966</id><created>2012-07-20</created><authors><author><keyname>Khan</keyname><forenames>Ahmad Raza</forenames></author><author><keyname>Khan</keyname><forenames>Rquaiya</forenames></author><author><keyname>Sontakke</keyname><forenames>Trimbak R</forenames></author><author><keyname>Khonde</keyname><forenames>Shraddha R</forenames></author><author><keyname>Wahul</keyname><forenames>Revati</forenames></author><author><keyname>alam</keyname><forenames>Mahtab</forenames></author></authors><title>Service Oriented Architecture A Revolution For Comprehensive Web Based
  Project Management Software</title><categories>cs.SE</categories><comments>7 Pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service Oriented Architecture A Revolution for Project Management Software
has changed the way projects today are moving on the fly with the help of web
services booming the industry. Service oriented architecture improves
performance and the communication between the distributed and remote teams. Web
Services to Provide Project Management software the visibility and control of
the application development lifecycle-giving a better control over the entire
development process, from the management stage through development. The goal of
Service Oriented Architecture for Project Management Software is to produce a
product that is delivered on time, within the allocated budget, and with the
capabilities expected by the customer. Web Services in Project management
Project management software is basically a properly managed project and has a
clear, communicated, and managed set of goals and objectives, whose progress is
quantifiable and controlled. Resources are used effectively and efficiently to
produce the desired product. With the help of service oriented architecture we
can move into the future without abandoning the past. A project usually has a
communicated set of processes that cover the daily activities of the project,
forming the project framework. As a result, every team member understands their
roles, responsibilities and how they fit into the big picture thus promoting
the efficient use of resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4973</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4973</id><created>2012-07-20</created><authors><author><keyname>Hamdi</keyname><forenames>Noureddine</forenames></author></authors><title>Variance Based Algorithm for Grouped-Subcarrier Allocation in OFDMA
  Wireless Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a reduced complexity algorithm is proposed for
grouped-subcarriers and power allocation in the downlink of OFDMA packet access
wireless systems. The available subcarriers for data communication are grouped
into partitions (groups) where each group is defined as a subchannel. The
scheduler located at the base station allocates subchannels to users based on
the variance of subchannel gains. The proposed algorithm for group allocation
is a two-step algorithm that allocates groups to users based on the descending
order of their variances to resolve the conflicting selection problem, followed
by a step of fairness proportionality enhancement. To reduce the feedback
burden and the complexity of the power allocation algorithm, each user feeds
back the CSI on each group if the variance of gains of subcarriers inside it is
less than a predefined threshold. To Show the performance of the proposed
scheme, a selection of simulation results is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4978</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4978</id><created>2012-07-20</created><updated>2012-08-12</updated><authors><author><keyname>Sahai</keyname><forenames>Esha</forenames></author><author><keyname>Sahai</keyname><forenames>Tuhin</forenames></author></authors><title>Mapping and Reducing the Brain on the Cloud</title><categories>cs.DC math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of cloud computing has enabled an incredible growth in
available hardware resources at very low costs. These resources are being
increasingly utilized by corporations for scalable analysis of &quot;big data&quot;
problems. In this work, we explore the possibility of using commodity hardware
such as Amazon EC2 for performing large scale scientific computation. In
particular, we simulate interconnected cortical neurons using MapReduce. We
build and model a network of 1000 spiking cortical neurons in Hadoop, an
opensource implementation of MapReduce, and present results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4984</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4984</id><created>2012-07-10</created><authors><author><keyname>Benattar</keyname><forenames>Gilles</forenames></author><author><keyname>Cassez</keyname><forenames>Franck</forenames></author><author><keyname>Lime</keyname><forenames>Didier</forenames></author><author><keyname>Roux</keyname><forenames>Olivier H.</forenames></author></authors><title>Control and Synthesis of Non-Interferent Timed Systems</title><categories>cs.LO cs.FL cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the synthesis of secure timed systems which are
modelled as timed automata. The security property that the system must satisfy
is a non-interference property. Intuitively, non-interference ensures the
absence of any causal dependency from a high-level domain to a lower-level
domain. Various notions of non-interference have been defined in the
literature, and in this paper we focus on Strong Non-deterministic
Non-Interference (SNNI) and two (bi)simulation based variants thereof (CSNNI
and BSNNI). We consider timed non-interference properties for timed systems
specified by timed automata and we study the two following problems: (1) check
whether it is possible to find a sub-system so that it is non-interferent; if
yes (2) compute a (largest) sub-system which is non-interferent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.4992</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.4992</id><created>2012-07-20</created><updated>2012-12-17</updated><authors><author><keyname>Lange</keyname><forenames>Tatjana</forenames></author><author><keyname>Mosler</keyname><forenames>Karl</forenames></author><author><keyname>Mozharovskyi</keyname><forenames>Pavlo</forenames></author></authors><title>Fast nonparametric classification based on data depth</title><categories>stat.ML cs.LG</categories><msc-class>62H30</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A new procedure, called DDa-procedure, is developed to solve the problem of
classifying d-dimensional objects into q &gt;= 2 classes. The procedure is
completely nonparametric; it uses q-dimensional depth plots and a very
efficient algorithm for discrimination analysis in the depth space [0,1]^q.
Specifically, the depth is the zonoid depth, and the algorithm is the
alpha-procedure. In case of more than two classes several binary
classifications are performed and a majority rule is applied. Special
treatments are discussed for 'outsiders', that is, data having zero depth
vector. The DDa-classifier is applied to simulated as well as real data, and
the results are compared with those of similar procedures that have been
recently proposed. In most cases the new procedure has comparable error rates,
but is much faster than other classification approaches, including the SVM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5007</identifier>
 <datestamp>2013-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5007</id><created>2012-07-20</created><authors><author><keyname>Srivastava</keyname><forenames>Madhur</forenames></author><author><keyname>Yashu</keyname><forenames>Yashwant</forenames></author><author><keyname>Singh</keyname><forenames>Satish K.</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>Multisegmentation through wavelets: Comparing the efficacy of Daubechies
  vs Coiflets</title><categories>cs.CV</categories><comments>4 pages</comments><journal-ref>Proceedings in Signal Processing and Real Time Operating System (
  SPRTOS), March 26 - 27 , 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we carry out a comparative study of the efficacy of wavelets
belonging to Daubechies and Coiflet family in achieving image segmentation
through a fast statistical algorithm.The fact that wavelets belonging to
Daubechies family optimally capture the polynomial trends and those of Coiflet
family satisfy mini-max condition, makes this comparison interesting. In the
context of the present algorithm, it is found that the performance of Coiflet
wavelets is better, as compared to Daubechies wavelet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5010</identifier>
 <datestamp>2012-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5010</id><created>2012-07-20</created><updated>2012-08-27</updated><authors><author><keyname>Bae</keyname><forenames>Jung Hyun</forenames></author><author><keyname>Lee</keyname><forenames>Jungwon</forenames></author><author><keyname>Kang</keyname><forenames>Inyup</forenames></author></authors><title>The GDOF of 3-user MIMO Gaussian interference channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper establishes the optimal generalized degrees of freedom (GDOF) of
3-user $M \times N$ multiple-input multiple-output (MIMO) Gaussian interference
channel (GIC) in which each transmitter has $M$ antennas and each receiver has
$N$ antennas. A constraint of $2M \leq N$ is imposed so that random coding with
message-splitting achieves the optimal GDOF. Unlike symmetric case, two cross
channels to unintended receivers from each transmitter can have different
strengths, and hence, well known Han-Kobayashi common-private message splitting
would not achieve the optimal GDOF. Instead, splitting each user's message into
three parts is shown to achieve the optimal GDOF. The capacity of the
corresponding deterministic model is first established which provides
systematic way of determining side information for converse. Although this
deterministic model is philosophically similar to the one considered by Gou and
Jafar, additional constraints are imposed so that capacity description of the
deterministic model only contains the essential terms for establishing the GDOF
of Gaussian case. Based on this, the optimal GDOF of Gaussian case is
established with $\mathcal{O}(1)$ capacity approximation. The behavior of the
GDOF is interestingly different from that of the corresponding symmetric case.
Regarding the converse, several multiuser outer bounds which are suitable for
asymmetric case are derived by non-trivial generalization of the symmetric
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5014</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5014</id><created>2012-07-20</created><authors><author><keyname>Goldberg</keyname><forenames>Eugene</forenames></author><author><keyname>Manolios</keyname><forenames>Panagiotis</forenames></author></authors><title>Checking Satisfiability by Dependency Sequents</title><categories>cs.LO cs.DM</categories><comments>25 pages, 6 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new algorithm for checking satisfiability based on a calculus
of Dependency sequents (D-sequents). Given a CNF formula F(X), a D-sequent is a
record stating that under a partial assignment a set of variables of X is
redundant in formula \exists{X}[F]. The D-sequent calculus is based on
operation join that forms a new D-sequent from two existing D-sequents. The new
algorithm solves the quantified version of SAT. That is, given a satisfiable
formula F, it, in general, does not produce an assignment satisfying F.
  The new algorithm is called DS-QSAT where DS stands for Dependency Sequent
and Q for Quantified.
  Importantly, a DPLL-like procedure is only a special case of DS-QSAT where a
very restricted kind of D-sequents is used. We argue that this restriction a)
adversely affects scalability of SAT-solvers and b) is caused by looking for an
explicit satisfying assignment rather than just proving satisfiability. We give
experimental results substantiating these claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5027</identifier>
 <datestamp>2012-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5027</id><created>2012-07-20</created><authors><author><keyname>Hatton</keyname><forenames>Les</forenames></author></authors><title>Power-Laws and the Conservation of Information in discrete token
  systems: Part 1 General Theory</title><categories>cs.IT math-ph math.IT math.MP q-bio.GN</categories><comments>26 pages, 7 figures</comments><acm-class>H.1.1; D.3.3; F.1.1; I.5.2; J.3</acm-class><journal-ref>IFIP AICT 377 Advances in Information and Communication Technology
  2011, ISBN 978-3-642-32676-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Conservation of Energy plays a pivotal part in the development of the
physical sciences. With the growth of computation and the study of other
discrete token based systems such as the genome, it is useful to ask if there
are conservation principles which apply to such systems and what kind of
functional behaviour they imply for such systems.
  Here I propose that the Conservation of Hartley-Shannon Information plays the
same over-arching role in discrete token based systems as the Conservation of
Energy does in physical systems. I will go on to prove that this implies
power-law behaviour in component sizes in software systems no matter what they
do or how they were built, and also implies the constancy of average gene
length in biological systems as reported for example by Lin Xu et al
(10.1093/molbev/msk019).
  These propositions are supported by very large amounts of experimental data
extending the first presentation of these ideas in Hatton (2011, IFIP / SIAM /
NIST Working Conference on Uncertainty Quantification in Scientific Computing,
Boulder, August 2011).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5040</identifier>
 <datestamp>2014-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5040</id><created>2012-07-20</created><updated>2014-02-20</updated><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author><author><keyname>Ebrahimpour</keyname><forenames>Reza</forenames></author></authors><title>Capacity Theorems for the Cognitive Radio Channel with Confidential
  Messages</title><categories>cs.IT math.IT</categories><comments>Two-Column Version, Introduction Revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a brain inspired wireless communication scheme, cognitive radio is a novel
approach to promote the efficient use of the scarce radio spectrum by allowing
some users called cognitive users to access the under-utilized spectrum
licensed out to the primary users. Besides highly reliable communication and
efficient utilization of the radio spectrum, the security of information
transmission against eavesdropping is critical in the cognitive radios for many
potential applications. In this paper, this problem is investigated from an
information theoretic viewpoint. Capacity limits are explored for the Cognitive
Radio Channel (CRC) with confidential messages. As an idealized information
theoretic model for the cognitive radio, this channel includes two transmitters
which send independent messages to their corresponding receivers such that one
transmitter, i.e., the cognitive transmitter, has access non-causally to the
message of the other transmitter, i.e., the primary transmitter. The message
designated to each receiver is required to be kept confidential with respect to
the other receiver. The secrecy level for each message is evaluated using the
equivocation rate. Novel inner and outer bounds for the capacity-equivocation
region are established. It is shown that these bounds coincide for some special
cases. Specifically, the capacity-equivocation region is derived for a class of
less-noisy CRCs and also a class of semi-deterministic CRCs. For the case where
only the message of the cognitive transmitter is required to be kept
confidential, the capacity-equivocation region is also established for the
Gaussian CRC with weak interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5054</identifier>
 <datestamp>2012-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5054</id><created>2012-07-20</created><authors><author><keyname>Lazar</keyname><forenames>Emanual A.</forenames></author><author><keyname>Mason</keyname><forenames>Jeremy K.</forenames></author><author><keyname>MacPherson</keyname><forenames>Robert D.</forenames></author><author><keyname>Srolovitz</keyname><forenames>David J.</forenames></author></authors><title>Complete topology of cells, grains, and bubbles in three-dimensional
  microstructures</title><categories>cond-mat.mtrl-sci cs.CG</categories><comments>5 pages, 6 figures, 5 supplementary pages</comments><journal-ref>Phys. Rev. Lett. 109, 095505 (2012)</journal-ref><doi>10.1103/PhysRevLett.109.095505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a general, efficient method to completely describe the topology
of individual grains, bubbles, and cells in three-dimensional polycrystals,
foams, and other multicellular microstructures. This approach is applied to a
pair of three-dimensional microstructures that are often regarded as close
analogues in the literature: one resulting from normal grain growth (mean
curvature flow) and another resulting from a random Poisson-Voronoi
tessellation of space. Grain growth strongly favors particular grain
topologies, compared with the Poisson-Voronoi model. Moreover, the frequencies
of highly symmetric grains are orders of magnitude higher in the the grain
growth microstructure than they are in the Poisson-Voronoi one. Grain topology
statistics provide a strong, robust differentiator of different cellular
microstructures and provide hints to the processes that drive different classes
of microstructure evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5055</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5055</id><created>2012-07-20</created><authors><author><keyname>Datta</keyname><forenames>Somantika</forenames></author></authors><title>Construction of zero autocorrelation stochastic waveforms</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic waveforms are constructed whose expected autocorrelation can be
made arbitrarily small outside the origin. These waveforms are unimodular and
complex-valued. Waveforms with such spike like autocorrelation are desirable in
waveform design and are particularly useful in areas of radar and
communications. Both discrete and continuous waveforms with low expected
autocorrelation are constructed. Further, in the discrete case, frames for the
d-dimensional complex space are constructed from these waveforms and the frame
properties of such frames are studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5063</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5063</id><created>2012-07-20</created><authors><author><keyname>Geraci</keyname><forenames>Giovanni</forenames></author><author><keyname>Egan</keyname><forenames>Malcolm</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author><author><keyname>Razi</keyname><forenames>Adeel</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Secrecy Sum-Rates for Multi-User MIMO Regularized Channel Inversion
  Precoding</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Communications, accepted for publication</comments><doi>10.1109/TCOMM.2012.072612.110686</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a linear precoder for the downlink of a multi-user
MIMO system with multiple users that potentially act as eavesdroppers. The
proposed precoder is based on regularized channel inversion (RCI) with a
regularization parameter $\alpha$ and power allocation vector chosen in such a
way that the achievable secrecy sum-rate is maximized. We consider the
worst-case scenario for the multi-user MIMO system, where the transmitter
assumes users cooperate to eavesdrop on other users. We derive the achievable
secrecy sum-rate and obtain the closed-form expression for the optimal
regularization parameter $\alpha_{\mathrm{LS}}$ of the precoder using
large-system analysis. We show that the RCI precoder with
$\alpha_{\mathrm{LS}}$ outperforms several other linear precoding schemes, and
it achieves a secrecy sum-rate that has same scaling factor as the sum-rate
achieved by the optimum RCI precoder without secrecy requirements. We propose a
power allocation algorithm to maximize the secrecy sum-rate for fixed $\alpha$.
We then extend our algorithm to maximize the secrecy sum-rate by jointly
optimizing $\alpha$ and the power allocation vector. The jointly optimized
precoder outperforms RCI with $\alpha_{\mathrm{LS}}$ and equal power allocation
by up to 20 percent at practical values of the signal-to-noise ratio and for 4
users and 4 transmit antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5064</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5064</id><created>2012-07-20</created><authors><author><keyname>Al-Wassai</keyname><forenames>Firouz Abdullah</forenames></author><author><keyname>Kalyankar</keyname><forenames>Dr. N. V.</forenames></author></authors><title>A Novel Metric Approach Evaluation For The Spatial Enhancement Of
  Pan-Sharpened Images</title><categories>cs.CV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1110.4970</comments><journal-ref>International Conference of Advanced Computer Science &amp;
  Information Technology (ACSIT-2012),July 15, 2012, Chennai, India</journal-ref><doi>10.5121/csit.2012.2347</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various and different methods can be used to produce high-resolution
multispectral images from high-resolution panchromatic image (PAN) and
low-resolution multispectral images (MS), mostly on the pixel level. The
Quality of image fusion is an essential determinant of the value of processing
images fusion for many applications. Spatial and spectral qualities are the two
important indexes that used to evaluate the quality of any fused image.
However, the jury is still out of fused image's benefits if it compared with
its original images. In addition, there is a lack of measures for assessing the
objective quality of the spatial resolution for the fusion methods. So, an
objective quality of the spatial resolution assessment for fusion images is
required. Therefore, this paper describes a new approach proposed to estimate
the spatial resolution improve by High Past Division Index (HPDI) upon
calculating the spatial-frequency of the edge regions of the image and it deals
with a comparison of various analytical techniques for evaluating the Spatial
quality, and estimating the colour distortion added by image fusion including:
MG, SG, FCC, SD, En, SNR, CC and NRMSE. In addition, this paper devotes to
concentrate on the comparison of various image fusion techniques based on pixel
and feature fusion technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5072</identifier>
 <datestamp>2014-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5072</id><created>2012-07-20</created><updated>2014-09-01</updated><authors><author><keyname>Zhang</keyname><forenames>Renyuan</forenames></author><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Gan</keyname><forenames>Yongmei</forenames></author><author><keyname>Wonham</keyname><forenames>W. M.</forenames></author></authors><title>Distributed Supervisory Control of Discrete-Event Systems with
  Communication Delay</title><categories>cs.SY cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper identifies a property of delay-robustness in distributed
supervisory control of discrete-event systems (DES) with communication delays.
In previous work a distributed supervisory control problem has been
investigated on the assumption that inter-agent communications take place with
negligible delay. From an applications viewpoint it is desirable to relax this
constraint and identify communicating distributed controllers which are
delay-robust, namely logically equivalent to their delay-free counterparts. For
this we introduce inter-agent channels modeled as 2-state automata, compute the
overall system behavior, and present an effective computational test for
delay-robustness. From the test it typically results that the given delay-free
distributed control is delay-robust with respect to certain communicated
events, but not for all, thus distinguishing events which are not
delay-critical from those that are. The approach is illustrated by a workcell
model with three communicating agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5082</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5082</id><created>2012-07-20</created><updated>2013-01-08</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Diamond-Kite Adaptive Quadrilateral Meshing</title><categories>cs.CG</categories><comments>21 pages, 11 figures. Expanded version of a paper from the 21st
  International Meshing Roundtable, 2012, including additional results on
  implementation, smoothing invariance, and a related well-centered mesh</comments><acm-class>J.2</acm-class><journal-ref>Engineering with Computers 30(2):223-225, 2014</journal-ref><doi>10.1007/s00366-013-0327-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a family of quadrilateral meshes based on diamonds, rhombi with
60 and 120 degree angles, and kites with 60, 90, and 120 degree angles, that
can be adapted to a local size function by local subdivision operations. Our
meshes use a number of elements that is within a constant factor of the minimum
possible for any mesh of bounded aspect ratio elements, graded by the same
local size function, and is invariant under Laplacian smoothing. The vertices
of our meshes form the centers of the circles in a pair of dual circle
packings. The same vertex placement algorithm but a different mesh topology
gives a pair of dual well-centered meshes adapted to the given size function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5086</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5086</id><created>2012-07-20</created><authors><author><keyname>Komuravelli</keyname><forenames>Anvesh</forenames></author><author><keyname>Pasareanu</keyname><forenames>Corina S.</forenames></author><author><keyname>Clarke</keyname><forenames>Edmund M.</forenames></author></authors><title>Assume-Guarantee Abstraction Refinement for Probabilistic Systems</title><categories>cs.LO cs.FL</categories><comments>23 pages, conference paper with full proofs</comments><journal-ref>CAV, vol. 7358 of LNCS, pp. 310-326. Springer-Verlag. 2012</journal-ref><doi>10.1007/978-3-642-31424-7_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an automated technique for assume-guarantee style checking of
strong simulation between a system and a specification, both expressed as
non-deterministic Labeled Probabilistic Transition Systems (LPTSes). We first
characterize counterexamples to strong simulation as &quot;stochastic&quot; trees and
show that simpler structures are insufficient. Then, we use these trees in an
abstraction refinement algorithm that computes the assumptions for
assume-guarantee reasoning as conservative LPTS abstractions of some of the
system components. The abstractions are automatically refined based on tree
counterexamples obtained from failed simulation checks with the remaining
components. We have implemented the algorithms for counterexample generation
and assume-guarantee abstraction refinement and report encouraging results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5091</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5091</id><created>2012-07-20</created><authors><author><keyname>Komuravelli</keyname><forenames>Anvesh</forenames></author><author><keyname>Pasareanu</keyname><forenames>Corina S.</forenames></author><author><keyname>Clarke</keyname><forenames>Edmund M.</forenames></author></authors><title>Learning Probabilistic Systems from Tree Samples</title><categories>cs.LO cs.LG</categories><comments>14 pages, conference paper with full proofs</comments><journal-ref>LICS, pp. 441-450, IEEE, 2012</journal-ref><doi>10.1109/LICS.2012.54</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning a non-deterministic probabilistic system
consistent with a given finite set of positive and negative tree samples.
Consistency is defined with respect to strong simulation conformance. We
propose learning algorithms that use traditional and a new &quot;stochastic&quot;
state-space partitioning, the latter resulting in the minimum number of states.
We then use them to solve the problem of &quot;active learning&quot;, that uses a
knowledgeable teacher to generate samples as counterexamples to simulation
equivalence queries. We show that the problem is undecidable in general, but
that it becomes decidable under a suitable condition on the teacher which comes
naturally from the way samples are generated from failed simulation checks. The
latter problem is shown to be undecidable if we impose an additional condition
on the learner to always conjecture a &quot;minimum state&quot; hypothesis. We therefore
propose a semi-algorithm using stochastic partitions. Finally, we apply the
proposed (semi-) algorithms to infer intermediate assumptions in an automated
assume-guarantee verification framework for probabilistic systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5104</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5104</id><created>2012-07-21</created><authors><author><keyname>Khulage</keyname><forenames>A. A.</forenames></author><author><keyname>Pathak</keyname><forenames>Prof. B. V.</forenames></author></authors><title>Analysis of speech under stress using Linear techniques and Non-Linear
  techniques for emotion recognition system</title><categories>cs.SD</categories><comments>10 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of speech for recognition of stress is important for identification
of emotional state of person. This can be done using 'Linear Techniques', which
has different parameters like pitch, vocal tract spectrum, formant frequencies,
Duration, MFCC etc. which are used for extraction of features from speech.
TEO-CB-Auto-Env is the method which is non-linear method of features
extraction. Analysis is done using TU-Berlin (Technical University of Berlin)
German database. Here emotion recognition is done for different emotions like
neutral, happy, disgust, sad, boredom and anger. Emotion recognition is used in
lie detector, database access systems, and in military for recognition of
soldiers' emotion identification during the war.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5108</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5108</id><created>2012-07-21</created><authors><author><keyname>Shafiee</keyname><forenames>Mahmood</forenames></author><author><keyname>Amooee</keyname><forenames>Golriz</forenames></author><author><keyname>Farjami</keyname><forenames>Yaghoub</forenames></author></authors><title>Developing an Activity-Based Costing Approach to Maximize the Efficiency
  of Customer Relationship Management Projects</title><categories>cs.OH</categories><comments>9 Pages</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 3, No 2, May 2012 ISSN (Online): 1694-0814 www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's competitive environment, profitability analysis is not just about
looking at the profit and loss statement. It is more about knowing which of
your customers are making you money and which are losing you money. This paper
considers how activity-based costing approach may complement a customer
relationship management effort. The model presented in this paper combines the
principles of activity-based costing with performance measurement. Applying
this model helps managers understand the true costs of providing products and
services, and the factors that drive these costs, while addressing other
concerns such as customer satisfaction. This approach has the potential to
integrate all business processes around the requirements of significant
profitable customers, a fact that most of the previous researches fail to
acknowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5113</identifier>
 <datestamp>2014-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5113</id><created>2012-07-21</created><authors><author><keyname>Wang</keyname><forenames>Junyan</forenames></author><author><keyname>Chan</keyname><forenames>Kap Luk</forenames></author></authors><title>Piecewise Linear Patch Reconstruction for Segmentation and Description
  of Non-smooth Image Structures</title><categories>cs.CV</categories><doi>10.1109/TIP.2013.2274385</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we propose a unified energy minimization model for the
segmentation of non-smooth image structures. The energy of piecewise linear
patch reconstruction is considered as an objective measure of the quality of
the segmentation of non-smooth structures. The segmentation is achieved by
minimizing the single energy without any separate process of feature
extraction. We also prove that the error of segmentation is bounded by the
proposed energy functional, meaning that minimizing the proposed energy leads
to reducing the error of segmentation. As a by-product, our method produces a
dictionary of optimized orthonormal descriptors for each segmented region. The
unique feature of our method is that it achieves the simultaneous segmentation
and description for non-smooth image structures under the same optimization
framework. The experiments validate our theoretical claims and show the clear
superior performance of our methods over other related methods for segmentation
of various image textures. We show that our model can be coupled with the
piecewise smooth model to handle both smooth and non-smooth structures, and we
demonstrate that the proposed model is capable of coping with multiple
different regions through the one-against-all strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5117</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5117</id><created>2012-07-21</created><authors><author><keyname>Nasution</keyname><forenames>Mahyuddin K. M.</forenames></author></authors><title>Algebraic on Magic Square of Odd Order n</title><categories>cs.DM math.CO</categories><comments>8 pages, Proceedings of The 1st IMT-GT Regional Conference on
  Mathematics, Statistics and Their Application, Toba Lake, Sumatera Utara,
  Indonesia: 29-36</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to address the relation between a magic square of odd order
$n$ and a group, and their properties. By the modulo number $n$, we construct
entries for each table from initial table of magic square with large number
$n^2$. Generalization of the underlying idea is presented, we obtain unique
group, and we also prove variants of the main results for magic cubes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5119</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5119</id><created>2012-07-21</created><authors><author><keyname>Jungers</keyname><forenames>Raphael M.</forenames></author><author><keyname>D'Innocenzo</keyname><forenames>Alessandro</forenames></author><author><keyname>Di Benedetto</keyname><forenames>Maria D.</forenames></author></authors><title>Feedback stabilization of dynamical systems with switched delays</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a classification of two main families of controllers that are of
interest when the feedback loop is subject to switching propagation delays due
to routing via a wireless multi-hop communication network. We show that we can
cast this problem as a subclass of classical switching systems, which is a
non-trivial generalization of classical LTI systems with timevarying delays. We
consider both cases where delay-dependent and delay independent controllers are
used, and show that both can be modeled as switching systems with unconstrained
switchings. We provide NP-hardness results for the stability verification
problem, and propose a general methodology for approximate stability analysis
with arbitrary precision. We finally give evidence that non-trivial design
problems arise for which new algorithmic methods are needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5123</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5123</id><created>2012-07-21</created><authors><author><keyname>Jungers</keyname><forenames>Raphael M.</forenames></author><author><keyname>Guglielmi</keyname><forenames>Nicola</forenames></author><author><keyname>Cicone</keyname><forenames>Antonio</forenames></author></authors><title>Lifted polytope methods for stability analysis of switching systems</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe new methods for deciding the stability of switching systems. The
methods build on two ideas previously appeared in the literature: the polytope
norm iterative construction, and the lifting procedure. Moreover, the
combination of these two ideas allows us to introduce a pruning algorithm which
can importantly reduce the computational burden. We prove several appealing
theoretical properties of our methods like a finiteness computational result
which extends a known result for unlifted sets of matrices, and provide
numerical examples of their good behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5124</identifier>
 <datestamp>2012-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5124</id><created>2012-07-21</created><updated>2012-11-06</updated><authors><author><keyname>Goc</keyname><forenames>Daniel</forenames></author><author><keyname>Saari</keyname><forenames>Kalle</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Primitive Words and Lyndon Words in Automatic and Linearly Recurrent
  Sequences</title><categories>cs.FL math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate questions related to the presence of primitive words and
Lyndon words in automatic and linearly recurrent sequences. We show that the
Lyndon factorization of a k-automatic sequence is itself k-automatic. We also
show that the function counting the number of primitive factors (resp., Lyndon
factors) of length n in a k-automatic sequence is k-regular. Finally, we show
that the number of Lyndon factors of a linearly recurrent sequence is bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5136</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5136</id><created>2012-07-21</created><authors><author><keyname>Peters</keyname><forenames>Jonas</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Causal Inference on Time Series using Structural Equation Models</title><categories>stat.ML cs.LG stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Causal inference uses observations to infer the causal structure of the data
generating system. We study a class of functional models that we call Time
Series Models with Independent Noise (TiMINo). These models require independent
residual time series, whereas traditional methods like Granger causality
exploit the variance of residuals. There are two main contributions: (1)
Theoretical: By restricting the model class (e.g. to additive noise) we can
provide a more general identifiability result than existing ones. This result
incorporates lagged and instantaneous effects that can be nonlinear and do not
need to be faithful, and non-instantaneous feedbacks between the time series.
(2) Practical: If there are no feedback loops between time series, we propose
an algorithm based on non-linear independence tests of time series. When the
data are causally insufficient, or the data generating process does not satisfy
the model assumptions, this algorithm may still give partial results, but
mostly avoids incorrect answers. An extension to (non-instantaneous) feedbacks
is possible, but not discussed. It outperforms existing methods on artificial
and real data. Code can be provided upon request.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5138</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5138</id><created>2012-07-21</created><authors><author><keyname>Nayaka</keyname><forenames>Raja Jitendra</forenames></author><author><keyname>Biradar</keyname><forenames>R. C.</forenames></author></authors><title>Ethernet Packet Processor for SoC Application</title><categories>cs.AR cs.NI</categories><comments>The International Workshop Of Information Technology, Control And
  Automation (Itca-2012), Sl.No.27. Proceedings In Computer Science &amp;
  Information Technology (Cs &amp; It) Series</comments><report-no>ReportNo27</report-no><msc-class>Airccse Conferences</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  As the demand for Internet expands significantly in numbers of users,
servers, IP addresses, switches and routers, the IP based network architecture
must evolve and change. The design of domain specific processors that require
high performance, low power and high degree of programmability is the
bottleneck in many processor based applications. This paper describes the
design of ethernet packet processor for system-on-chip (SoC) which performs all
core packet processing functions, including segmentation and reassembly,
packetization classification, route and queue management which will speedup
switching/routing performance. Our design has been configured for use with
multiple projects ttargeted to a commercial configurable logic device the
system is designed to support 10/100/1000 links with a speed advantage. VHDL
has been used to implement and simulated the required functions in FPGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5140</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5140</id><created>2012-07-21</created><authors><author><keyname>Fern&#xe1;ndez-Duque</keyname><forenames>David</forenames></author></authors><title>Non-finite axiomatizability of Dynamic Topological Logic</title><categories>math.LO cs.LO</categories><comments>arXiv admin note: text overlap with arXiv:1201.5162 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic topological logic (DTL) is a polymodal logic designed for reasoning
about {\em dynamic topological systems. These are pairs (X,f), where X is a
topological space and f:X-&gt;X is continuous. DTL uses a language L which
combines the topological S4 modality [] with temporal operators from linear
temporal logic.
  Recently, I gave a sound and complete axiomatization DTL* for an extension of
the logic to the language L*, where &lt;&gt; is allowed to act on finite sets of
formulas and is interpreted as a tangled closure operator. No complete
axiomatization is known over L, although one proof system, which we shall call
$\mathsf{KM}$, was conjectured to be complete by Kremer and Mints.
  In this paper we show that, given any language L' between L and L*, the set
of valid formulas of L' is not finitely axiomatizable. It follows, in
particular, that KM is incomplete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5146</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5146</id><created>2012-07-21</created><authors><author><keyname>Dinitz</keyname><forenames>Michael</forenames></author><author><keyname>Kortsarz</keyname><forenames>Guy</forenames></author></authors><title>Matroid Secretary for Regular and Decomposable Matroids</title><categories>cs.DS math.CO</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the matroid secretary problem we are given a stream of elements and asked
to choose a set of elements that maximizes the total value of the set, subject
to being an independent set of a matroid given in advance. The difficulty comes
from the assumption that decisions are irrevocable: if we choose to accept an
element when it is presented by the stream then we can never get rid of it, and
if we choose not to accept it then we cannot later add it. Babaioff, Immorlica,
and Kleinberg [SODA 2007] introduced this problem, gave O(1)-competitive
algorithms for certain classes of matroids, and conjectured that every matroid
admits an O(1)-competitive algorithm. However, most matroids that are known to
admit an O(1)-competitive algorithm can be easily represented using graphs
(e.g. graphic and transversal matroids). In particular, there is very little
known about F-representable matroids (the class of matroids that can be
represented as elements of a vector space over a field F), which are one of the
foundational matroid classes. Moreover, most of the known techniques are as
dependent on graph theory as they are on matroid theory. We go beyond graphs by
giving an O(1)-competitive algorithm for regular matroids (the class of
matroids that are representable over every field), and use techniques that are
matroid-theoretic rather than graph-theoretic. We use the regular matroid
decomposition theorem of Seymour to decompose any regular matroid into matroids
which are either graphic, cographic, or isomorphic to R_{10}, and then show how
to combine algorithms for these basic classes into an algorithm for regular
matroids. This allows us to generalize beyond regular matroids to any class of
matroids that admits such a decomposition into classes for which we already
have good algorithms. In particular, we give an O(1)-competitive algorithm for
the class of max-flow min-cut matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5152</identifier>
 <datestamp>2012-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5152</id><created>2012-07-21</created><authors><author><keyname>Korkmaz</keyname><forenames>Fatih</forenames></author><author><keyname>Cakir</keyname><forenames>M. Faruk</forenames></author><author><keyname>Korkmaz</keyname><forenames>Yilmaz</forenames></author><author><keyname>Topaloglu</keyname><forenames>Ismail</forenames></author></authors><title>Stator flux optimization on direct torque control with fuzzy logic</title><categories>cs.AI</categories><comments>8 pages, 8 figures, Itca 2012 conference</comments><doi>10.5121/csit.2012.2355</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Direct Torque Control (DTC) is well known as an effective control
technique for high performance drives in a wide variety of industrial
applications and conventional DTC technique uses two constant reference value:
torque and stator flux. In this paper, fuzzy logic based stator flux
optimization technique for DTC drives that has been proposed. The proposed
fuzzy logic based stator flux optimizer self-regulates the stator flux
reference using induction motor load situation without need of any motor
parameters. Simulation studies have been carried out with Matlab/Simulink to
compare the proposed system behaviors at vary load conditions. Simulation
results show that the performance of the proposed DTC technique has been
improved and especially at low-load conditions torque ripple are greatly
reduced with respect to the conventional DTC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5155</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5155</id><created>2012-07-21</created><authors><author><keyname>Kozik</keyname><forenames>Jakub</forenames></author><author><keyname>Micek</keyname><forenames>Piotr</forenames></author></authors><title>Nonrepetitive choice number of trees</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A nonrepetitive coloring of a path is a coloring of its vertices such that
the sequence of colors along the path does not contain two identical,
consecutive blocks. The remarkable construction of Thue asserts that 3 colors
are enough to color nonrepetitively paths of any length. A nonrepetitive
coloring of a graph is a coloring of its vertices such that all simple paths
are nonrepetitively colored. Assume that each vertex $v$ of a graph $G$ has
assigned a set (list) of colors $L_v$. A coloring is chosen from $\{L_v\}_{v\in
V(G)}$ if the color of each $v$ belongs to $L_v$. The Thue choice number of
$G$, denoted by $\pi_l(G)$, is the minimum $k$ such that for any list
assignment $\set{L_v}$ of $G$ with each $|L_v|\geq k$ there is a nonrepetitive
coloring of $G$ chosen from $\{L_v\}$. Alon et al. (2002) proved that
$\pi_l(G)=O(\Delta^2)$ for every graph $G$ with maximum degree at most
$\Delta$. We propose an almost linear bound in $\Delta$ for trees, namely for
any $\epsi&gt;0$ there is a constant $c$ such that $\pi_l(T)\leq
c\Delta^{1+\epsi}$ for every tree $T$ with maximum degree $\Delta$. The only
lower bound for trees is given by a recent result of Fiorenzi et al. (2011)
that for any $\Delta$ there is a tree $T$ such that
$\pi_l(T)=\Omega(\frac{\log\Delta}{\log\log\Delta})$. We also show that if one
allows repetitions in a coloring but still forbid 3 identical consecutive
blocks of colors on any simple path, then a constant size of the lists allows
to color any tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5176</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5176</id><created>2012-07-21</created><authors><author><keyname>Zinoviev</keyname><forenames>Dmitry</forenames></author></authors><title>Clown: a Microprocessor Simulator for Operating System Studies</title><categories>cs.OH</categories><comments>6 pages, 3 figures, 2 tables. Presented at Summer Computer Simulation
  Conference, San Jose, July 2004</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, I present the design and implementation of Clown--a simulator
of a microprocessor-based computer system specifically optimized for teaching
operating system courses at undergraduate or graduate levels. The package
includes the simulator itself, as well as a collection of basic I/O devices, an
assembler, a linker, and a disk formatter. The simulator architecturally
resembles mainstream microprocessors from the Intel 80386 family, but is much
easier to learn and program. The simulator is fast enough to be used as an
emulator--in the direct user interaction mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5184</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5184</id><created>2012-07-21</created><authors><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Bharadia</keyname><forenames>Dinesh</forenames></author><author><keyname>Chowdhury</keyname><forenames>Mainak</forenames></author><author><keyname>Ochoa</keyname><forenames>Idoia</forenames></author><author><keyname>Sharon</keyname><forenames>Itai</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Lossy Compression of Quality Values via Rate Distortion Theory</title><categories>q-bio.GN cs.IT math.IT q-bio.QM</categories><comments>7 Pages, 8 Figures, Submitted to Bioinformatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivation: Next Generation Sequencing technologies revolutionized many
fields in biology by enabling the fast and cheap sequencing of large amounts of
genomic data. The ever increasing sequencing capacities enabled by current
sequencing machines hold a lot of promise as for the future applications of
these technologies, but also create increasing computational challenges related
to the analysis and storage of these data. A typical sequencing data file may
occupy tens or even hundreds of gigabytes of disk space, prohibitively large
for many users. Raw sequencing data consists of both the DNA sequences (reads)
and per-base quality values that indicate the level of confidence in the
readout of these sequences. Quality values account for about half of the
required disk space in the commonly used FASTQ format and therefore their
compression can significantly reduce storage requirements and speed up analysis
and transmission of these data.
  Results: In this paper we present a framework for the lossy compression of
the quality value sequences of genomic read files. Numerical experiments with
reference based alignment using these quality values suggest that we can
achieve significant compression with little compromise in performance for
several downstream applications of interest, as is consistent with our
theoretical analysis. Our framework also allows compression in a regime - below
one bit per quality value - for which there are no existing compressors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5191</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5191</id><created>2012-07-21</created><authors><author><keyname>Ma</keyname><forenames>Li</forenames></author><author><keyname>Wang</keyname><forenames>X. Y.</forenames></author></authors><title>Schrodinger equation and wave equation on finite graphs</title><categories>math.AP cs.IT math.DG math.DS math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the schrodinger equation and wave equation with the
Dirichlet boundary condition on a connected finite graph. The explicit
expressions for solutions are given and the energy conservations are derived.
Applications to the corresponding nonlinear problems are indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5200</identifier>
 <datestamp>2013-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5200</id><created>2012-07-22</created><updated>2013-10-18</updated><authors><author><keyname>Minton</keyname><forenames>Gregory T.</forenames></author><author><keyname>Price</keyname><forenames>Eric</forenames></author></authors><title>Improved Concentration Bounds for Count-Sketch</title><categories>cs.DS</categories><comments>25 pages SODA 2014</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present a refined analysis of the classic Count-Sketch streaming heavy
hitters algorithm [CCF02]. Count-Sketch uses O(k log n) linear measurements of
a vector x in R^n to give an estimate x' of x. The standard analysis shows that
this estimate x' satisfies ||x'-x||_infty^2 &lt; ||x_tail||_2^2 / k, where x_tail
is the vector containing all but the largest k coordinates of x. Our main
result is that most of the coordinates of x' have substantially less error than
this upper bound; namely, for any c &lt; O(log n), we show that each coordinate i
satisfies (x'_i - x_i)^2 &lt; (c/log n) ||x_tail||_2^2/k with probability
1-2^{-Omega(c)}, as long as the hash functions are fully independent. This
subsumes the previous bound and is optimal for all c. Using these improved
point estimates, we prove a stronger concentration result for set estimates by
first analyzing the covariance matrix and then using a
median-of-median-of-medians argument to bootstrap the failure probability
bounds. These results also give improved results for l_2 recovery of exactly
k-sparse estimates x^* when x is drawn from a distribution with suitable decay,
such as a power law or lognormal. We complement our results with simulations of
Count-Sketch on a power law distribution. The empirical evidence indicates that
our theoretical bounds give a precise characterization of the algorithm's
performance: the asymptotics are correct and the associated constants are
small. Our proof shows that any symmetric random variable with finite variance
and positive Fourier transform concentrates around 0 at least as well as a
Gaussian. This result, which may be of independent interest, gives good
concentration even when the noise does not converge to a Gaussian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5206</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5206</id><created>2012-07-22</created><updated>2013-03-11</updated><authors><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Gunawan</keyname><forenames>Erry</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Transmit Optimization with Improper Gaussian Signaling for Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the achievable rates of Gaussian interference channels
with additive white Gaussian noise (AWGN), when improper or circularly
asymmetric complex Gaussian signaling is applied. For the Gaussian
multiple-input multiple-output interference channel (MIMO-IC) with the
interference treated as Gaussian noise, we show that the user's achievable rate
can be expressed as a summation of the rate achievable by the conventional
proper or circularly symmetric complex Gaussian signaling in terms of the
users' transmit covariance matrices, and an additional term, which is a
function of both the users' transmit covariance and pseudo-covariance matrices.
The additional degrees of freedom in the pseudo-covariance matrix, which is
conventionally set to be zero for the case of proper Gaussian signaling,
provide an opportunity to further improve the achievable rates of Gaussian
MIMO-ICs by employing improper Gaussian signaling. To this end, this paper
proposes widely linear precoding, which efficiently maps proper
information-bearing signals to improper transmitted signals at each transmitter
for any given pair of transmit covariance and pseudo-covariance matrices. In
particular, for the case of two-user Gaussian single-input single-output
interference channel (SISO-IC), we propose a joint covariance and
pseudo-covariance optimization algorithm with improper Gaussian signaling to
achieve the Pareto-optimal rates. By utilizing the separable structure of the
achievable rate expression, an alternative algorithm with separate covariance
and pseudo-covariance optimization is also proposed, which guarantees the rate
improvement over conventional proper Gaussian signaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5208</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5208</id><created>2012-07-22</created><authors><author><keyname>Maes</keyname><forenames>Francis</forenames></author><author><keyname>Ernst</keyname><forenames>Damien</forenames></author><author><keyname>Wehenkel</keyname><forenames>Louis</forenames></author></authors><title>Meta-Learning of Exploration/Exploitation Strategies: The Multi-Armed
  Bandit Case</title><categories>cs.AI cs.LG stat.ML</categories><comments>16 pages, Springer Selection of papers of ICAART'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exploration/exploitation (E/E) dilemma arises naturally in many subfields
of Science. Multi-armed bandit problems formalize this dilemma in its canonical
form. Most current research in this field focuses on generic solutions that can
be applied to a wide range of problems. However, in practice, it is often the
case that a form of prior information is available about the specific class of
target problems. Prior knowledge is rarely used in current solutions due to the
lack of a systematic approach to incorporate it into the E/E strategy.
  To address a specific class of E/E problems, we propose to proceed in three
steps: (i) model prior knowledge in the form of a probability distribution over
the target class of E/E problems; (ii) choose a large hypothesis space of
candidate E/E strategies; and (iii), solve an optimization problem to find a
candidate E/E strategy of maximal average performance over a sample of problems
drawn from the prior distribution.
  We illustrate this meta-learning approach with two different hypothesis
spaces: one where E/E strategies are numerically parameterized and another
where E/E strategies are represented as small symbolic formulas. We propose
appropriate optimization algorithms for both cases. Our experiments, with
two-armed Bernoulli bandit problems and various playing budgets, show that the
meta-learnt E/E strategies outperform generic strategies of the literature
(UCB1, UCB1-Tuned, UCB-v, KL-UCB and epsilon greedy); they also evaluate the
robustness of the learnt E/E strategies, by tests carried out on arms whose
rewards follow a truncated Gaussian distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5211</identifier>
 <datestamp>2014-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5211</id><created>2012-07-22</created><updated>2014-05-08</updated><authors><author><keyname>Elkin</keyname><forenames>Michael</forenames></author><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author></authors><title>Can Quantum Communication Speed Up Distributed Computation?</title><categories>cs.DC cs.CC cs.DS quant-ph</categories><comments>Full version of PODC 2014 paper</comments><acm-class>C.2.4; F.0; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of this paper is on {\em quantum distributed} computation, where we
investigate whether quantum communication can help in {\em speeding up}
distributed network algorithms. Our main result is that for certain fundamental
network problems such as minimum spanning tree, minimum cut, and shortest
paths, quantum communication {\em does not} help in substantially speeding up
distributed algorithms for these problems compared to the classical setting.
  In order to obtain this result, we extend the technique of Das Sarma et al.
[SICOMP 2012] to obtain a uniform approach to prove non-trivial lower bounds
for quantum distributed algorithms for several graph optimization (both exact
and approximate versions) as well as verification problems, some of which are
new even in the classical setting, e.g. tight randomized lower bounds for
Hamiltonian cycle and spanning tree verification, answering an open problem of
Das Sarma et al., and a lower bound in terms of the weight aspect ratio,
matching the upper bounds of Elkin [STOC 2004]. Our approach introduces the
{\em Server model} and {\em Quantum Simulation Theorem} which together provide
a connection between distributed algorithms and communication complexity. The
Server model is the standard two-party communication complexity model augmented
with additional power; yet, most of the hardness in the two-party model is
carried over to this new model. The Quantum Simulation Theorem carries this
hardness further to quantum distributed computing. Our techniques, except the
proof of the hardness in the Server model, require very little knowledge in
quantum computing, and this can help overcoming a usual impediment in proving
bounds on quantum distributed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5212</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5212</id><created>2012-07-22</created><authors><author><keyname>Fotakis</keyname><forenames>Dimitris</forenames></author><author><keyname>Kaporis</keyname><forenames>Alexis C.</forenames></author><author><keyname>Lianeas</keyname><forenames>Thanasis</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>On the Hardness of Network Design for Bottleneck Routing Games</title><categories>cs.GT</categories><comments>Extended abstract to appear in the Proceedings of the 5th
  International Symposium on Algorithmic Game Theory (SAGT 2012), October
  22-24, 2012, Barcelona, Spain</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In routing games, the network performance at equilibrium can be significantly
improved if we remove some edges from the network. This counterintuitive fact,
widely known as Braess's paradox, gives rise to the (selfish) network design
problem, where we seek to recognize routing games suffering from the paradox,
and to improve the equilibrium performance by edge removal. In this work, we
investigate the computational complexity and the approximability of the network
design problem for non-atomic bottleneck routing games, where the individual
cost of each player is the bottleneck cost of her path, and the social cost is
the bottleneck cost of the network. We first show that bottleneck routing games
do not suffer from Braess's paradox either if the network is series-parallel,
or if we consider only subpath-optimal Nash flows. On the negative side, we
prove that even for games with strictly increasing linear latencies, it is
NP-hard not only to recognize instances suffering from the paradox, but also to
distinguish between instances for which the Price of Anarchy (PoA) can decrease
to 1 and instances for which the PoA is as large as \Omega(n^{0.121}) and
cannot improve by edge removal. Thus, the network design problem for such games
is NP-hard to approximate within a factor of O(n^{0.121-\eps}), for any
constant \eps &gt; 0. On the positive side, we show how to compute an almost
optimal subnetwork w.r.t. the bottleneck cost of its worst Nash flow, when the
worst Nash flow in the best subnetwork routes a non-negligible amount of flow
on all used edges. The running time is determined by the total number of paths,
and is quasipolynomial when the number of paths is quasipolynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5215</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5215</id><created>2012-07-22</created><updated>2012-07-30</updated><authors><author><keyname>Chakaravarthy</keyname><forenames>Venkatesan T.</forenames></author><author><keyname>Modani</keyname><forenames>Natwar</forenames></author><author><keyname>Natarajan</keyname><forenames>Sivaramakrishnan R.</forenames></author><author><keyname>Roy</keyname><forenames>Sambuddha</forenames></author><author><keyname>Sabharwal</keyname><forenames>Yogish</forenames></author></authors><title>Density Functions subject to a Co-Matroid Constraint</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of finding the {\em densest} subset
subject to {\em co-matroid constraints}. We are given a {\em monotone
supermodular} set function $f$ defined over a universe $U$, and the density of
a subset $S$ is defined to be $f(S)/\crd{S}$. This generalizes the concept of
graph density. Co-matroid constraints are the following: given matroid $\calM$
a set $S$ is feasible, iff the complement of $S$ is {\em independent} in the
matroid. Under such constraints, the problem becomes $\np$-hard. The specific
case of graph density has been considered in literature under specific
co-matroid constraints, for example, the cardinality matroid and the partition
matroid. We show a 2-approximation for finding the densest subset subject to
co-matroid constraints. Thus, for instance, we improve the approximation
guarantees for the result for partition matroids in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5216</identifier>
 <datestamp>2014-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5216</id><created>2012-07-22</created><updated>2014-03-26</updated><authors><author><keyname>Cord&#xf3;n-Franco</keyname><forenames>Andr&#xe9;s</forenames></author><author><keyname>van Ditmarsch</keyname><forenames>Hans</forenames></author><author><keyname>Fern&#xe1;ndez-Duque</keyname><forenames>David</forenames></author><author><keyname>Soler-Toscano</keyname><forenames>Fernando</forenames></author></authors><title>A colouring protocol for the generalized Russian cards problem</title><categories>cs.IT math.IT</categories><journal-ref>Andr\'es Cord\'on-Franco, Hans P. van Ditmarsch, David
  Fern\'andez-Duque, Fernando Soler-Toscano: A colouring protocol for the
  generalized Russian cards problem. Theoretical Computer Science 495: 81-95
  (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the generalized Russian cards problem, Alice, Bob and Cath draw $a$, $b$
and $c$ cards, respectively, from a deck of size $a+b+c$. Alice and Bob must
then communicate their entire hand to each other, without Cath learning the
owner of a single card she does not hold. Unlike many traditional problems in
cryptography, however, they are not allowed to encode or hide the messages they
exchange from Cath. The problem is then to find methods through which they can
achieve this. We propose a general four-step solution based on finite vector
spaces, and call it the &quot;colouring protocol&quot;, as it involves colourings of
lines.
  Our main results show that the colouring protocol may be used to solve the
generalized Russian cards problem in cases where $a$ is a power of a prime,
$c=O(a^2)$ and $b=O(c^2)$. This improves substantially on the set of parameters
for which solutions are known to exist; in particular, it had not been shown
previously that the problem could be solved in cases where the eavesdropper has
more cards than one of the communicating players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5217</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5217</id><created>2012-07-22</created><updated>2012-08-27</updated><authors><author><keyname>Peise</keyname><forenames>Elmar</forenames><affiliation>AICES, RWTH Aachen</affiliation></author></authors><title>Hierarchical Performance Modeling for Ranking Dense Linear Algebra
  Algorithms</title><categories>cs.PF</categories><comments>Master's Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large class of dense linear algebra operations, such as LU decomposition or
inversion of a triangular matrix, are usually performed by blocked algorithms.
For one such operation, typically, not only one but many algorithmic variants
exist; depending on computing architecture, libraries and problem size, each
variant attains a different performances. We propose methods and tools to rank
the algorithmic variants according to their performance for a given scenario
without executing them.
  For this purpose, we identify the routines upon which the algorithms are
built. A first tool - the Sampler - measures the performance of these routines.
Using the Sampler, a second tool models their performance. The generated models
are then used to predict the performance of the considered algorithms. For a
given scenario, these predictions allow us to correctly rank the algorithms
according to their performance without executing them. With the help of the
same tools, algorithmic parameters such as block-size can be optimally tuned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5220</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5220</id><created>2012-07-22</created><updated>2015-07-28</updated><authors><author><keyname>Je&#x159;&#xe1;bek</keyname><forenames>Emil</forenames></author></authors><title>Integer factoring and modular square roots</title><categories>cs.CC cs.LO</categories><comments>24 pages; to appear in Journal of Computer and System Sciences</comments><acm-class>F.2.1; F.1.3</acm-class><journal-ref>Journal of Computer and System Sciences 82 (2016), no. 2, pp.
  380--394</journal-ref><doi>10.1016/j.jcss.2015.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Buresh-Oppenheim proved that the NP search problem to find nontrivial factors
of integers of a special form belongs to Papadimitriou's class PPA, and is
probabilistically reducible to a problem in PPP. In this paper, we use ideas
from bounded arithmetic to extend these results to arbitrary integers. We show
that general integer factoring is reducible in randomized polynomial time to a
PPA problem and to the problem WEAKPIGEON in PPP. Both reductions can be
derandomized under the assumption of the generalized Riemann hypothesis. We
also show (unconditionally) that PPA contains some related problems, such as
square root computation modulo n, and finding quadratic nonresidues modulo n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5226</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5226</id><created>2012-07-22</created><updated>2012-07-24</updated><authors><author><keyname>Beskales</keyname><forenames>George</forenames></author><author><keyname>Ilyas</keyname><forenames>Ihab F.</forenames></author><author><keyname>Golab</keyname><forenames>Lukasz</forenames></author><author><keyname>Galiullin</keyname><forenames>Artur</forenames></author></authors><title>On the Relative Trust between Inconsistent Data and Inaccurate
  Constraints</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional dependencies (FDs) specify the intended data semantics while
violations of FDs indicate deviation from these semantics. In this paper, we
study a data cleaning problem in which the FDs may not be completely correct,
e.g., due to data evolution or incomplete knowledge of the data semantics. We
argue that the notion of relative trust is a crucial aspect of this problem: if
the FDs are outdated, we should modify them to fit the data, but if we suspect
that there are problems with the data, we should modify the data to fit the
FDs. In practice, it is usually unclear how much to trust the data versus the
FDs. To address this problem, we propose an algorithm for generating
non-redundant solutions (i.e., simultaneous modifications of the data and the
FDs) corresponding to various levels of relative trust. This can help users
determine the best way to modify their data and/or FDs to achieve consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5232</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5232</id><created>2012-07-22</created><authors><author><keyname>Kindler</keyname><forenames>Alex</forenames></author><author><keyname>Solomon</keyname><forenames>Sorin</forenames></author><author><keyname>Stauffer</keyname><forenames>Dietrich</forenames></author></authors><title>Peer-to-Peer and Mass Communication Effect on Revolution Dynamics</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.physa.2012.10.038</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Revolution dynamics is studied through a minimal Ising model with three main
influences (fields): personal conservatism (power-law distributed),
inter-personal and group pressure, and a global field incorporating
peer-to-peer and mass communications, which is generated bottom-up from the
revolutionary faction. A rich phase diagram appears separating possible
terminal stages of the revolution, characterizing failure phases by the
features of the individuals who had joined the revolution. An exhaustive
solution of the model is produced, allowing predictions to be made on the
revolution's outcome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5259</identifier>
 <datestamp>2013-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5259</id><created>2012-07-22</created><updated>2013-03-29</updated><authors><author><keyname>Bubeck</keyname><forenames>Sebastien</forenames></author><author><keyname>Ernst</keyname><forenames>Damien</forenames></author><author><keyname>Garivier</keyname><forenames>Aurelien</forenames></author></authors><title>Optimal discovery with probabilistic expert advice: finite time analysis
  and macroscopic optimality</title><categories>cs.LG stat.ML</categories><comments>arXiv admin note: substantial text overlap with arXiv:1110.5447</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an original problem that arises from the issue of security
analysis of a power system and that we name optimal discovery with
probabilistic expert advice. We address it with an algorithm based on the
optimistic paradigm and on the Good-Turing missing mass estimator. We prove two
different regret bounds on the performance of this algorithm under weak
assumptions on the probabilistic experts. Under more restrictive hypotheses, we
also prove a macroscopic optimality result, comparing the algorithm both with
an oracle strategy and with uniform sampling. Finally, we provide numerical
experiments illustrating these theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5261</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5261</id><created>2012-07-22</created><authors><author><keyname>Martins</keyname><forenames>Andre C. R.</forenames></author></authors><title>Modelling Epistemic Systems</title><categories>physics.soc-ph cs.SI</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this Chapter, I will explore the use of modeling in order to understand
how Science works. I will discuss the modeling of scientific communities,
providing a general, non-comprehensive overview of existing models, with a
focus on the use of the tools of Agent-Based Modeling and Opinion Dynamics. A
special attention will be paid to models inspired by a Bayesian formalism of
Opinion Dynamics. The objective of this exploration is to better understand the
effect that different conditions might have on the reliability of the opinions
of a scientific community. We will see that, by using artificial worlds as
exploring grounds, we can prevent some epistemological problems with the
definition of truth and obtain insights on the conditions that might cause the
quest for more reliable knowledge to fail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5265</identifier>
 <datestamp>2014-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5265</id><created>2012-07-22</created><updated>2013-01-18</updated><authors><author><keyname>Lerner</keyname><forenames>Vladimir S.</forenames></author></authors><title>Hidden information and regularities of information dynamics IR</title><categories>nlin.AO cs.IT math.IT</categories><comments>40 pages,3 figures. arXiv admin note: text overlap with
  arXiv:1201.0035</comments><msc-class>58J65, 60J65, 93B52, 93E02, 93E15, 93E30</msc-class><acm-class>H.1.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The introduced entropy functional's (EF) information measure of random
process integrates multiple information contributions along the process
trajectories, evaluating both the states' and between states' bound information
connections. This measure reveals information that is hidden by traditional
information measures, which commonly use Shannon's entropy function for each
selected stationary states of the process. The hidden information is important
for evaluation of missing connections, disclosing the process' meaningful
information, which enables producing logic of the information. The presentation
consists of three Parts. In Part 1R-revised we analyze mechanism of arising
information regularities from a stochastic process, measured by EF,
independently of the process' specific source and origin. Uncovering the
process' regularities leads us to an information law, based on extracting
maximal information from its minimum, which could create these regularities.
The solved variation problem (VP) determines a dynamic process, measured by
information path functional (IPF), and information dynamic model, approximating
the EF measured stochastic process with a maximal functional probability on
trajectories. In Part 2, we study the cooperative processes, arising at the
consolidation, as a result of the VP-EF-IPF approach, which is able to produce
multiple cooperative structures, concurrently assembling in hierarchical
information network (IN) and generating the IN's digital genetic code. In Part
3 we study the evolutionary information processes and regularities of evolution
dynamics, evaluated by the entropy functional (EF) of random field and
informational path functional of a dynamic space-time process. The information
law and the regularities determine unified functional informational mechanisms
of evolution dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5267</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5267</id><created>2012-07-22</created><authors><author><keyname>Abdo</keyname><forenames>Hosam</forenames></author><author><keyname>Dimitrov</keyname><forenames>Darko</forenames></author></authors><title>The total irregularity of a graph</title><categories>cs.DM math.CO</categories><comments>7 pages, 2 figures</comments><journal-ref>DMTCS vol. 16:1, 2-14, 201--206 (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note a new measure of irregularity of a simple undirected graph $G$
is introduced. It is named the total irregularity of a graph and is defined as
$\irr_t(G) = 1/2\sum_{u,v \in V(G)} |d_G(u)-d_G(v)|$, where $d_G(u)$ denotes
the degree of a vertex $u \in V(G)$. The graphs with maximal total irregularity
are determined. It is also shown that among all trees of same order the star
graph has the maximal total irregularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5272</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5272</id><created>2012-07-22</created><updated>2013-08-19</updated><authors><author><keyname>Liu</keyname><forenames>Chuang</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author></authors><title>Information spreading on dynamic social networks</title><categories>physics.soc-ph cs.SI</categories><comments>11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, information spreading on social networks has triggered an explosive
attention in various disciplines. Most of previous works in this area mainly
focus on discussing the effects of spreading probability or immunization
strategy on static networks. However, in real systems, the peer-to-peer network
structure changes constantly according to frequently social activities of
users. In order to capture this dynamical property and study its impact on
information spreading, in this paper, a link rewiring strategy based on the
Fermi function is introduced. In the present model, the informed individuals
tend to break old links and reconnect to their second-order friends with more
uninformed neighbors. Simulation results on the susceptible-infected-recovered
(\textit{SIR}) model with fixed recovery time $T=1$ indicate that the
information would spread more faster and broader with the proposed rewiring
strategy. Extensive analyses of the information cascade size distribution show
that the spreading process of the initial steps plays a very important role,
that is to say, the information will spread out if it is still survival at the
beginning time. The proposed model may shed some light on the in-depth
understanding of information spreading on dynamical social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5293</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5293</id><created>2012-07-23</created><updated>2012-10-07</updated><authors><author><keyname>Wang</keyname><forenames>Xing M.</forenames></author></authors><title>Probability Bracket Notation, Multivariable Systems and Static Bayesian
  Networks</title><categories>cs.AI math.PR</categories><msc-class>62F15</msc-class><acm-class>G.3; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probability Bracket Notation (PBN) is applied to systems of multiple random
variables for preliminary study of static Bayesian Networks (BN) and
Probabilistic Graphic Models (PGM). The famous Student BN Example is explored
to show the local independences and reasoning power of a BN. Software package
Elvira is used to graphically display the student BN. Our investigation shows
that PBN provides a consistent and convenient alternative to manipulate many
expressions related to joint, marginal and conditional probability
distributions in static BN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5298</identifier>
 <datestamp>2014-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5298</id><created>2012-07-23</created><updated>2014-05-22</updated><authors><author><keyname>He</keyname><forenames>Jianghao</forenames></author><author><keyname>Liew</keyname><forenames>Soung-Chang</forenames></author></authors><title>Building Blocks of Physical-layer Network Coding</title><categories>cs.NI</categories><comments>38 pages, 7 figures, 10 tables, accepted by IEEE SECON 2013</comments><msc-class>90C05</msc-class><doi>10.1109/SAHCN.2013.6645013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the fundamental building blocks of physical-layer
network coding (PNC). Most prior work on PNC focused on its application in a
simple two-way-relay channel (TWRC) consisting of three nodes only. Studies of
the application of PNC in general networks are relatively few. This paper is an
attempt to fill this gap. We put forth two ideas: 1) A general network can be
decomposed into small building blocks of PNC, referred to as the PNC atoms, for
scheduling of PNC transmissions. 2) We identify nine PNC atoms, with TWRC being
one of them. Three major results are as follows. First, using the decomposition
framework, the throughput performance of PNC is shown to be significantly
better than those of the traditional multi-hop scheme and the conventional
network coding scheme. For example, under heavy traffic volume, PNC can achieve
100% throughput gain relative to the traditional multi-hop scheme. Second, PNC
decomposition based on a variety of different PNC atoms can yield much better
performance than PNC decomposition based on the TWRC atom alone. Third, three
out of the nine atoms are most important to good performance. Specifically, the
decomposition based on these three atoms is good enough most of the time, and
it is not necessary to use the other six atoms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5310</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5310</id><created>2012-07-23</created><authors><author><keyname>Udayakumar</keyname><forenames>P.</forenames></author><author><keyname>Indhumathi</keyname><forenames>M.</forenames></author></authors><title>Semantic web based Sensor Planning Services (SPS) for Sensor Web
  Enablement (SWE)</title><categories>cs.SE cs.NI</categories><comments>13 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sensor Planning Service (SPS) is service model to define the web service
interface for requesting user driven acquisitions and observation. It's defined
by the Open Geospatial Consortium (OGC) Sensor Web Enablement (SWE) group to
provide standardized interface for tasking sensors to allow to defining,
checking, modifying and cancelling tasks of sensor and sensor data. The goal of
Sensor Planning Service (SPS) of OGC - SWE is standardize the interoperability
between a client and a server collection management environment. The Sensor
Planning Service (SPS) is need to automate complex data flow in a large
enterprises that are depend on live &amp; stored data from sensors and multimedia
equipment. The obstacle are faced in Sensor Planning Service (SPS) are (I)
Observation from sensor at the right time and right place will be problem, (II)
acquisition information(data) that are collected at a specific time and
specific place will be problem. The above two obstacle are accomplished and
obtained by the web based semantic technology in order to provide &amp; apply the
ontology based semantic rule to user driven a acquisitions and observation of
Sensor Planning Service (SPS). The novelty of our approach is by adding the
semantic rule to Sensor Planning Service model in SWE and we implemented Sensor
Planning Service (SPS) with semantic knowledge based to achieve high
standardized service model for Sensor Planning Service (SPS) of OGC - SWE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5319</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5319</id><created>2012-07-23</created><updated>2013-09-30</updated><authors><author><keyname>Cardone</keyname><forenames>Martina</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Knopp</keyname><forenames>Raymond</forenames></author><author><keyname>Salim</keyname><forenames>Umer</forenames></author></authors><title>On the Capacity of the Two-user Gaussian Causal Cognitive Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>Under second round review in IEEE Transactions in Information Theory
  - Submitted September 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the two-user Gaussian Causal Cognitive Interference
Channel (GCCIC), which consists of two source-destination pairs that share the
same channel and where one full-duplex cognitive source can causally learn the
message of the primary source through a noisy link. The GCCIC is an
interference channel with unilateral source cooperation that better models
practical cognitive radio networks than the commonly used model which assumes
that one source has perfect non-causal knowledge of the other source's message.
First the sum-capacity of the symmetric GCCIC is determined to within a
constant gap. Then, the insights gained from the derivation of the symmetric
sum-capacity are extended to characterize the whole capacity region to within a
constant gap for more general cases. In particular, the capacity is determined
(a) to within 2 bits for the fully connected GCCIC when, roughly speaking, the
interference is not weak at both receivers, (b) to within 2 bits for the
Z-channel, i.e., when there is no interference from the primary user, and (c)
to within 2 bits for the S-channel, i.e., when there is no interference from
the secondary user. The parameter regimes where the GCCIC is equivalent, in
terms of generalized degrees-of-freedom, to the noncooperative interference
channel (i.e., unilateral causal cooperation is not useful), to the non-causal
cognitive interference channel (i.e., causal cooperation attains the ultimate
limit of cognitive radio technology), and to bilateral source cooperation are
identified. These comparisons shed lights into the parameter regimes and
network topologies that in practice might provide an unbounded throughput gain
compared to currently available (non cognitive) technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5321</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5321</id><created>2012-07-23</created><authors><author><keyname>Boyar</keyname><forenames>Joan</forenames></author><author><keyname>Find</keyname><forenames>Magnus</forenames></author></authors><title>Cancellation-free circuits: An approach for proving superlinear lower
  bounds for linear Boolean operators</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue to study the notion of cancellation-free linear circuits. We show
that every matrix can be computed by a cancellation- free circuit, and almost
all of these are at most a constant factor larger than the optimum linear
circuit that computes the matrix. It appears to be easier to prove statements
about the structure of cancellation-free linear circuits than for linear
circuits in general. We prove two nontrivial superlinear lower bounds. We show
that a cancellation-free linear circuit computing the $n\times n$ Sierpinski
gasket matrix must use at least 1/2 n logn gates, and that this is tight. This
supports a conjecture by Aaronson. Furthermore we show that a proof strategy
for proving lower bounds on monotone circuits can be almost directly converted
to prove lower bounds on cancellation-free linear circuits. We use this
together with a result from extremal graph theory due to Andreev to prove a
lower bound of {\Omega}(n^(2- \epsilon)) for infinitely many $n \times n$
matrices for every $\epsilon &gt; 0$ for. These lower bounds for concrete matrices
are almost optimal since all matrices can be computed with $O(n^2/\log n)$
gates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5323</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5323</id><created>2012-07-23</created><authors><author><keyname>Jayaraj</keyname><forenames>V.</forenames></author><author><keyname>Indhumathi</keyname><forenames>M.</forenames></author></authors><title>High Reliable secure data collection using Complexity exchanging code
  key method addressing protocol in Wireless Sensor Network</title><categories>cs.NI cs.CR</categories><comments>13 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Wireless Sensor Network (WSN) is emerging field in Information and
communication technology. In WSN data transmission and data collection are
unsecure because of sensor node Incompatibility. So providing security to
Sensor network is very important. The key based Mechanism is secure data
collection and it's mainly used to guarantee data confidentiality. Range pair
wise key is largely used due to the necessary of data encryption and decryption
between each pair range of communication node. Fixed key mechanism difficult
for the attacker to detect the regularity of the randomly generated key chain
function in privacy homomorphism (PH).PH means no intermediate node to encrypt
and decrypt only direct collect and aggregate data for encryption and
decryption. It is special key based scheme. It's totally based on beta
distribution and some statistical tool using key code method by using
Complexity exchanging code key method addressing protocol. We show how to
reduce significant attacks and secure data collection on wireless sensor
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5326</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5326</id><created>2012-07-23</created><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author><author><keyname>Han</keyname><forenames>Jiqing</forenames></author><author><keyname>Zheng</keyname><forenames>Tieran</forenames></author><author><keyname>Deng</keyname><forenames>Shiwen</forenames></author><author><keyname>Li</keyname><forenames>Ji</forenames></author></authors><title>Guarantees of Augmented Trace Norm Models in Tensor Recovery</title><categories>cs.IT cs.CV math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the recovery guarantees of the models of minimizing
$\|\mathcal{X}\|_*+\frac{1}{2\alpha}\|\mathcal{X}\|_F^2$ where $\mathcal{X}$ is
a tensor and $\|\mathcal{X}\|_*$ and $\|\mathcal{X}\|_F$ are the trace and
Frobenius norm of respectively. We show that they can efficiently recover
low-rank tensors. In particular, they enjoy exact guarantees similar to those
known for minimizing $\|\mathcal{X}\|_*$ under the conditions on the sensing
operator such as its null-space property, restricted isometry property, or
spherical section property. To recover a low-rank tensor $\mathcal{X}^0$,
minimizing $\|\mathcal{X}\|_*+\frac{1}{2\alpha}\|\mathcal{X}\|_F^2$ returns the
same solution as minimizing $\|\mathcal{X}\|_*$ almost whenever
$\alpha\geq10\mathop {\max}\limits_{i}\|X^0_{(i)}\|_2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5328</identifier>
 <datestamp>2012-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5328</id><created>2012-07-23</created><updated>2012-08-31</updated><authors><author><keyname>Haddar</keyname><forenames>Kais</forenames><affiliation>MIRACL</affiliation></author><author><keyname>Fehri</keyname><forenames>H&#xe9;la</forenames><affiliation>MIRACL</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>IDSL, INRIA Saclay - Ile de France</affiliation></author></authors><title>A prototype for projecting HPSG syntactic lexica towards LMF</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>Journal of Language Technology and Computational Linguistics 27, 1
  (2012) 21-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The comparative evaluation of Arabic HPSG grammar lexica requires a deep
study of their linguistic coverage. The complexity of this task results mainly
from the heterogeneity of the descriptive components within those lexica
(underlying linguistic resources and different data categories, for example).
It is therefore essential to define more homogeneous representations, which in
turn will enable us to compare them and eventually merge them. In this context,
we present a method for comparing HPSG lexica based on a rule system. This
method is implemented within a prototype for the projection from Arabic HPSG to
a normalised pivot language compliant with LMF (ISO 24613 - Lexical Markup
Framework) and serialised using a TEI (Text Encoding Initiative) based
representation. The design of this system is based on an initial study of the
HPSG formalism looking at its adequacy for the representation of Arabic, and
from this, we identify the appropriate feature structures corresponding to each
Arabic lexical category and their possible LMF counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5329</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5329</id><created>2012-07-23</created><authors><author><keyname>Giannopoulou</keyname><forenames>Archontia C.</forenames></author><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Forbidding Kuratowski Graphs as Immersions</title><categories>math.CO cs.DM</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The immersion relation is a partial ordering relation on graphs that is
weaker than the topological minor relation in the sense that if a graph $G$
contains a graph $H$ as a topological minor, then it also contains it as an
immersion but not vice versa. Kuratowski graphs, namely $K_{5}$ and $K_{3,3}$,
give a precise characterization of planar graphs when excluded as topological
minors. In this note we give a structural characterization of the graphs that
exclude Kuratowski graphs as immersions. We prove that they can be constructed
by applying consecutive $i$-edge-sums, for $i\leq 3$, starting from graphs that
are planar sub-cubic or of branch-width at most 10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5342</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5342</id><created>2012-07-23</created><authors><author><keyname>Cao</keyname><forenames>Hanwen</forenames></author><author><keyname>Peissig</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>A Robust Signal Classification Scheme for Cognitive Radio</title><categories>cs.IT cs.LG cs.NI math.IT</categories><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a robust signal classification scheme for achieving
comprehensive spectrum sensing of multiple coexisting wireless systems. It is
built upon a group of feature-based signal detection algorithms enhanced by the
proposed dimension cancelation (DIC) method for mitigating the noise
uncertainty problem. The classification scheme is implemented on our testbed
consisting real-world wireless devices. The simulation and experimental
performances agree with each other well and shows the e?ectiveness and
robustness of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5343</identifier>
 <datestamp>2012-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5343</id><created>2012-07-23</created><updated>2012-07-24</updated><authors><author><keyname>Vilone</keyname><forenames>Daniele</forenames></author><author><keyname>Ramasco</keyname><forenames>Jos&#xe9; J.</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Angel</forenames></author><author><keyname>Miguel</keyname><forenames>Maxi San</forenames></author></authors><title>Social and strategic imitation: the way to consensus</title><categories>physics.soc-ph cs.SI</categories><comments>13 pages, 5 figures. Submitted to Scientific Reports</comments><journal-ref>Scientific Reports 2, 686 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans do not always make rational choices, a fact that experimental
economics is putting on solid grounds. The social context plays an important
role in determining our actions, and often we imitate friends or acquaintances
without any strategic consideration. We explore here the interplay between
strategic and social imitative behaviors in a coordination problem on a social
network. We observe that for interactions in 1D and 2D lattices any amount of
social imitation prevents the freezing of the network in domains with different
conventions, thus leading to global consensus. For interactions in complex
networks, the interplay of social and strategic imitation also drives the
system towards global consensus while neither dynamics alone does. We find an
optimum value for the combination of imitative behaviors to reach consensus in
a minimum time, and two different dynamical regimes to approach it: exponential
when social imitation predominates, and power-law when strategic considerations
dominate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5345</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5345</id><created>2012-07-23</created><authors><author><keyname>Liao</keyname><forenames>Gang</forenames></author><author><keyname>Liu</keyname><forenames>Lei</forenames></author><author><keyname>Luo</keyname><forenames>Lian</forenames></author></authors><title>A New P2N Approach to Software Development Under the Clustering</title><categories>cs.SE cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this computer era of rapid development, software development can be seen
everywhere, but a lot of softwares are dead in modern development of software.
Just as The Mythical Man-Month said, it exists a problem in the software
development, and the problem is interflow.A lock of interflow can be said great
calamity. Clustering is a environment to breed new life. In this thesis, we
elaborate how P2N can be used to thinking, planning, developing, collaborating,
releasing. And the approach that make your team and organization more perfect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5371</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5371</id><created>2012-07-23</created><authors><author><keyname>Feragen</keyname><forenames>Aasa</forenames></author><author><keyname>Lo</keyname><forenames>Pechin</forenames></author><author><keyname>de Bruijne</keyname><forenames>Marleen</forenames></author><author><keyname>Nielsen</keyname><forenames>Mads</forenames></author><author><keyname>Lauze</keyname><forenames>Francois</forenames></author></authors><title>Towards a theory of statistical tree-shape analysis</title><categories>stat.ME cs.CV math.MG</categories><comments>36 pages, 15 figures</comments><msc-class>62H35, 05C05, 51Fxx, 58A35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to develop statistical methods for shapes with a tree-structure, we
construct a shape space framework for tree-like shapes and study metrics on the
shape space. This shape space has singularities, corresponding to topological
transitions in the represented trees. We study two closely related metrics on
the shape space, TED and QED. QED is a quotient Euclidean distance arising
naturally from the shape space formulation, while TED is the classical tree
edit distance. Using Gromov's metric geometry we gain new insight into the
geometries defined by TED and QED. We show that the new metric QED has nice
geometric properties which facilitate statistical analysis, such as existence
and local uniqueness of geodesics and averages. TED, on the other hand, does
not share the geometric advantages of QED, but has nice algorithmic properties.
We provide a theoretical framework and experimental results on synthetic data
trees as well as airway trees from pulmonary CT scans. This way, we effectively
illustrate that our framework has both the theoretical and qualitative
properties necessary to build a theory of statistical tree-shape analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5384</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5384</id><created>2012-07-23</created><authors><author><keyname>Filipiuk</keyname><forenames>Piotr</forenames></author><author><keyname>Nielson</keyname><forenames>Flemming</forenames></author><author><keyname>Nielson</keyname><forenames>Hanne Riis</forenames></author></authors><title>Lattice based Least Fixed Point Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As software systems become more complex, there is an increasing need for new
static analyses. Thanks to the declarative style, logic programming is an
attractive formalism for specifying them. However, prior work on using logic
programming for static analysis focused on analyses defined over some powerset
domain, which is quite limiting. In this paper we present a logic that lifts
this restriction, called Lattice based Least Fixed Point Logic (LLFP), that
allows interpretations over any complete lattice satisfying Ascending Chain
Condition. The main theoretical contribution is a Moore Family result that
guarantees that there always is a unique least solution for a given problem.
Another contribution is the development of solving algorithm that computes the
least model of LLFP formulae guaranteed by the Moore Family result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5409</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5409</id><created>2012-07-23</created><authors><author><keyname>Kumar</keyname><forenames>Deepak</forenames></author><author><keyname>Singh</keyname><forenames>Manjeet</forenames></author><author><keyname>Shukla</keyname><forenames>Seema</forenames></author></authors><title>FST Based Morphological Analyzer for Hindi Language</title><categories>cs.CL cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hindi being a highly inflectional language, FST (Finite State Transducer)
based approach is most efficient for developing a morphological analyzer for
this language. The work presented in this paper uses the SFST (Stuttgart Finite
State Transducer) tool for generating the FST. A lexicon of root words is
created. Rules are then added for generating inflectional and derivational
words from these root words. The Morph Analyzer developed was used in a Part Of
Speech (POS) Tagger based on Stanford POS Tagger. The system was first trained
using a manually tagged corpus and MAXENT (Maximum Entropy) approach of
Stanford POS tagger was then used for tagging input sentences. The
morphological analyzer gives approximately 97% correct results. POS tagger
gives an accuracy of approximately 87% for the sentences that have the words
known to the trained model file, and 80% accuracy for the sentences that have
the words unknown to the trained model file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5419</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5419</id><created>2012-07-23</created><authors><author><keyname>Cord-Landwehr</keyname><forenames>Andreas</forenames></author><author><keyname>H&#xfc;llmann</keyname><forenames>Martina</forenames></author><author><keyname>Kling</keyname><forenames>Peter</forenames></author><author><keyname>Setzer</keyname><forenames>Alexander</forenames></author></authors><title>Basic Network Creation Games with Communication Interests</title><categories>cs.GT</categories><comments>An extended abstract of this paper has been accepted for publication
  in the proceedings of the 5th International Symposium on Algorithmic Game
  Theory (SAGT)</comments><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network creation games model the creation and usage costs of networks formed
by a set of selfish peers. Each peer has the ability to change the network in a
limited way, e.g., by creating or deleting incident links. In doing so, a peer
can reduce its individual communication cost. Typically, these costs are
modeled by the maximum or average distance in the network. We introduce a
generalized version of the basic network creation game (BNCG). In the BNCG (by
Alon et al., SPAA 2010), each peer may replace one of its incident links by a
link to an arbitrary peer. This is done in a selfish way in order to minimize
either the maximum or average distance to all other peers. That is, each peer
works towards a network structure that allows himself to communicate
efficiently with all other peers. However, participants of large networks are
seldom interested in all peers. Rather, they want to communicate efficiently
only with a small subset of peers. Our model incorporates these (communication)
interests explicitly. In the MAX-version, each node tries to minimize its
maximum distance to nodes it is interested in.
  Given peers with interests and a communication network forming a tree, we
prove several results on the structure and quality of equilibria in our model.
For the MAX-version, we give an upper worst case bound of O(\sqrt{n}) for the
private costs in an equilibrium of n peers. Moreover, we give an equilibrium
for a circular interest graph where a node has private cost \Omega(\sqrt{n}),
showing that our bound is tight. This example can be extended such that we get
a tight bound of \Theta(\sqrt{n}) for the price of anarchy. For the case of
general communication networks we show the price of anarchy to be \Theta(n).
Additionally, we prove an interesting connection between a maximum independent
set in the interest graph and the private costs of the peers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5425</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5425</id><created>2012-07-23</created><authors><author><keyname>Brisaboa</keyname><forenames>Nieves R.</forenames></author><author><keyname>Cerdeira-Pena</keyname><forenames>Ana</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author><author><keyname>Pedreira</keyname><forenames>Oscar</forenames></author></authors><title>Ranked Document Retrieval in (Almost) No Space</title><categories>cs.IR cs.DB</categories><comments>This is an extended version of the paper that will appear in Proc. of
  SPIRE'2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ranked document retrieval is a fundamental task in search engines. Such
queries are solved with inverted indexes that require additional 45%-80% of the
compressed text space, and take tens to hundreds of microseconds per query. In
this paper we show how ranked document retrieval queries can be solved within
tens of milliseconds using essentially no extra space over an in-memory
compressed representation of the document collection. More precisely, we
enhance wavelet trees on bytecodes (WTBCs), a data structure that rearranges
the bytes of the compressed collection, so that they support ranked conjunctive
and disjunctive queries, using just 6%-18% of the compressed text space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5434</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5434</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author></authors><title>sSCADA: Securing SCADA Infrastructure Communications</title><categories>cs.IT cs.NI math.IT</categories><journal-ref>Int. J. Communication Networks and Distributed Systems,
  6(1):59--78, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed control systems (DCS) and supervisory control and data
acquisition (SCADA) systems were developed to reduce labour costs, and to allow
system-wide monitoring and remote control from a central location. Control
systems are widely used in critical infrastructures such as electric grid,
natural gas, water and wastewater industries. While control systems can be
vulnerable to a variety of types of cyber attacks that could have devastating
consequences, little research has been done to secure the control systems.
American Gas Association (AGA), IEC TC57 WG15, IEEE, NIST and National SCADA
Test Bed Program have been actively designing cryptographic standard to protect
SCADA systems. American Gas Association (AGA) had originally been designing
cryptographic standard to protect SCADA communication links and finished the
report AGA 12 part 1. The AGA 12 part 2 has been transferred to IEEE P1711.
This paper presents an attack on the protocols in the first draft of AGA
standard (Wright et al., 2004). This attack shows that the security mechanisms
in the first version of the AGA standard protocol could be easily defeated. We
then propose a suite of security protocols optimised for SCADA/DCS systems
which include: point-to-point secure channels, authenticated broadcast
channels, authenticated emergency channels, and revised authenticated emergency
channels. These protocols are designed to address the specific challenges that
SCADA systems have.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5437</identifier>
 <datestamp>2013-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5437</id><created>2012-07-23</created><updated>2013-03-17</updated><authors><author><keyname>Cao</keyname><forenames>Qiong</forenames></author><author><keyname>Guo</keyname><forenames>Zheng-Chu</forenames></author><author><keyname>Ying</keyname><forenames>Yiming</forenames></author></authors><title>Generalization Bounds for Metric and Similarity Learning</title><categories>cs.LG stat.ML</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, metric learning and similarity learning have attracted a large
amount of interest. Many models and optimisation algorithms have been proposed.
However, there is relatively little work on the generalization analysis of such
methods. In this paper, we derive novel generalization bounds of metric and
similarity learning. In particular, we first show that the generalization
analysis reduces to the estimation of the Rademacher average over
&quot;sums-of-i.i.d.&quot; sample-blocks related to the specific matrix norm. Then, we
derive generalization bounds for metric/similarity learning with different
matrix-norm regularisers by estimating their specific Rademacher complexities.
Our analysis indicates that sparse metric/similarity learning with $L^1$-norm
regularisation could lead to significantly better bounds than those with
Frobenius-norm regularisation. Our novel generalization analysis develops and
refines the techniques of U-statistics and Rademacher complexity analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5438</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5438</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author></authors><title>Efficient Identity-Based and Authenticated Key Agreement Protocol</title><categories>cs.CR</categories><comments>Transcations on Computational Sciences, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several identity based and implicitly authenticated key agreement protocols
have been proposed in recent years and none of them has achieved all required
security properties. In this paper, we propose an efficient identity-based and
authenticated key agreement protocol IDAK using Weil/Tate pairing. The security
of IDAK is proved in Bellare-Rogaway model. Several required properties for key
agreement protocols are not implied by the Bellare-Rogaway model. We proved
these properties for IDAK separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5439</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5439</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author><author><keyname>Desmedt</keyname><forenames>Yvo</forenames></author></authors><title>Edge-Colored Graphs with Applications To Homogeneous Faults</title><categories>cs.DM cs.IT math.CO math.IT</categories><journal-ref>Information Processing Letters 111(2011) 634-641</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use the concept of colored edge graphs to model homogeneous
faults in networks. We then use this model to study the minimum connectivity
(and design) requirements of networks for being robust against homogeneous
faults within certain thresholds. In particular, necessary and sufficient
conditions for most interesting cases are obtained. For example, we will study
the following cases: (1) the number of colors (or the number of non-homogeneous
network device types) is one more than the homogeneous fault threshold; (2)
there is only one homogeneous fault (i.e., only one color could fail); and (3)
the number of non-homogeneous network device types is less than five.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5442</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5442</id><created>2012-07-23</created><authors><author><keyname>Zhao</keyname><forenames>Z.</forenames></author><author><keyname>Wang</keyname><forenames>Z. Dongand Yongge</forenames></author></authors><title>Security Analysis of a Password-Based Authentication Protocol Proposed
  to IEEE 1363</title><categories>cs.CR</categories><journal-ref>Theoretical Computer Science, 352(1-3):280--287, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, several protocols for password-based authenticated key
exchange have been proposed. These protocols aim to be secure even though the
sample space of passwords may be small enough to be enumerated by an off-line
adversary. In Eurocrypt 2000, Bellare, Pointcheval and Rogaway (BPR) presented
a model and security definition for authenticated key exchange. They claimed
that in the ideal-cipher model (random oracles), the two-flow protocol at the
core of Encrypted Key Exchange (EKE) is secure. Bellare and Rogaway suggested
several instantiations of the ideal cipher in their proposal to the IEEE
P1363.2 working group. Since then there has been an increased interest in
proving the security of password-based protocols in the ideal-cipher model. For
example, Bresson, Chevassut, and Pointcheval have recently showed that the
One-Encryption-Key-Exchange (OEKE) protocol is secure in the ideal cipher
model. In this paper, we present examples of real (NOT ideal) ciphers
(including naive implementations of the instantiations proposed to IEEE
P1363.2) that would result in broken instantiations of the idealised AuthA
protocol and OEKE protocol. Our result shows that the AuthA protocol can be
instantiated in an insecure way, and that there are no well defined (let alone
rigorous) ways to distinguish between secure and insecure instantiations. Thus,
without a rigorous metric for ideal-ciphers, the value of provable security in
ideal cipher model is limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5444</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5444</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author></authors><title>Using mobile agent results to create hard-to-detect computer viruses</title><categories>cs.CR</categories><comments>Information Security for Global Information Infrastructures, the 16th
  IFIP SEC (2000)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of computer viruses has been studied by several authors, though
there is no systematic theoretical study up to now. The long time open question
in this area is as follows: Is it possible to design a signature-free
(including dynamic signatures which we will define late) virus? In this paper,
we give an affirmative answer to this question from a theoretical viewpoint. We
will introduce a new stronger concept: dynamic signatures of viruses, and
present a method to design viruses which are static signature-free and whose
dynamic signatures are hard to determine unless some cryptographic assumption
fails. We should remark that our results are only for theoretical interest and
may be resource intensive in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5446</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5446</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author></authors><title>Public Key Cryptography Standards: PKCS</title><categories>cs.CR</categories><comments>Handbook of Information Security, 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptographic standards serve two important goals: making different
implementations interoperable and avoiding various known pitfalls in commonly
used schemes. This chapter discusses Public-Key Cryptography Standards (PKCS)
which have significant impact on the use of public key cryptography in
practice. PKCS standards are a set of standards, called PKCS #1 through #15.
These standards cover RSA encryption, RSA signature, password-based encryption,
cryptographic message syntax, private-key information syntax, selected object
classes and attribute types, certification request syntax, cryptographic token
interface, personal information exchange syntax, and cryptographic token
information syntax. The PKCS standards are published by RSA Laboratories.
Though RSA Laboratories solicits public opinions and advice for PKCS standards,
RSA Laboratories retain sole decision-making authority on all aspects of PKCS
standards. PKCS has been the basis for many other standards such as S/MIME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5450</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5450</id><created>2012-07-23</created><authors><author><keyname>Goc</keyname><forenames>Daniel</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Least periods of k-automatic sequences</title><categories>cs.FL cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currie and Saari initiated the study of least periods of infinite words, and
they showed that every integer n &gt;= 1 is a least period of the Thue-Morse
sequence. We generalize this result to show that the characteristic sequence of
least periods of a k-automatic sequence is (effectively) k-automatic. Through
an implementation of our construction, we confirm the result of Currie and
Saari, and we obtain similar results for the period-doubling sequence, the
Rudin-Shapiro sequence, and the paperfolding sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5458</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5458</id><created>2012-07-23</created><authors><author><keyname>Kaced</keyname><forenames>Tarik</forenames></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author></authors><title>On the Non-robustness of Essentially Conditional Information
  Inequalities</title><categories>cs.IT math.IT math.PR</categories><comments>ITW 2012 Conference paper, 5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that two essentially conditional linear inequalities for Shannon's
entropies (including the Zhang-Yeung'97 conditional inequality) do not hold for
asymptotically entropic points. This means that these inequalities are
non-robust in a very strong sense. This result raises the question of the
meaning of these inequalities and the validity of their use in
practice-oriented applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5461</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5461</id><created>2012-07-23</created><authors><author><keyname>Aminzou</keyname><forenames>Said</forenames></author><author><keyname>Er-Raha</keyname><forenames>Brahim</forenames></author><author><keyname>Khamlichi</keyname><forenames>Youness Idrissi</forenames></author><author><keyname>Machkour</keyname><forenames>Mustapha</forenames></author><author><keyname>Afdel</keyname><forenames>Karim</forenames></author></authors><title>Enhancing Data Security in Medical Information System Using the
  Watermarking Techniques and Oracle SecureFile LOBs</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient digital watermarking scheme to
strengthen the security level already present in the database management system
and to avoid illegal access to comprehensive content of database including
patient's information. Doctors diagnose medical images by seeing Region of
Interest (ROI). A ROI of a medical image is an area including important
information and must be stored without any distortion. If a medical image is
illegally obtained or if its content is changed, it may lead to wrong
diagnosis. We substitute the part out of ROI of LSB bitplane of the image with
the patient data and a binary feature map. This latter is obtained by
extracting edges of the resized image to the quarter of its size using
Laplacian operator. This image is directly integrated into the database. The
edge map and invariant moments are used to check the integrity of the image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5466</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5466</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author><author><keyname>Wu</keyname><forenames>Xintao</forenames></author></authors><title>Approximate Inverse Frequent Itemset Mining: Privacy, Complexity, and
  Approximation</title><categories>cs.DB</categories><journal-ref>Proc. 5th IEEE ICDM, pages 482-289, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to generate synthetic basket data sets for better benchmark testing,
it is important to integrate characteristics from real-life databases into the
synthetic basket data sets. The characteristics that could be used for this
purpose include the frequent itemsets and association rules. The problem of
generating synthetic basket data sets from frequent itemsets is generally
referred to as inverse frequent itemset mining. In this paper, we show that the
problem of approximate inverse frequent itemset mining is {\bf NP}-complete.
Then we propose and analyze an approximate algorithm for approximate inverse
frequent itemset mining, and discuss privacy issues related to the synthetic
basket data set. In particular, we propose an approximate algorithm to
determine the privacy leakage in a synthetic basket data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5480</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5480</id><created>2012-07-23</created><authors><author><keyname>Salih</keyname><forenames>Nadir K.</forenames></author><author><keyname>Zang</keyname><forenames>Tianyi</forenames></author></authors><title>Survey and comparison for Open and closed sources in cloud computing</title><categories>cs.DC</categories><comments>6pages, 3figures; International Journal of Computer Science Issues
  (&quot;IJCSI&quot;),2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is a new technology widely studied in recent years. Now there
are many cloud platforms both in industry and in academic circle. How to
understand and use these platforms is a big issue. A detailed comparison has
been presented in this paper focused on the aspects such as the architecture,
characteristics, application and so on. To know the differences between open
source and close source in cloud environment we mention some examples for
Software-as-a-Service, Platform-as-a-Service, and Infrastructure-as-a-Service.
We made comparison between them. Before conclusion we demonstrate some
convergences and differences between open and closed platform, but we realized
open source should be the best option.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5483</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5483</id><created>2012-07-23</created><authors><author><keyname>Abdallah</keyname><forenames>Saeed</forenames></author><author><keyname>Psaromiligkos</keyname><forenames>Ioannis N.</forenames></author></authors><title>Exact Cramer-Rao Bounds for Semi-blind Channel Estimation in
  Amplify-and-Forward Two-Way Relay Networks</title><categories>cs.IT math.IT</categories><comments>11 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive for the first time the exact Cramer-Rao bounds
(CRBs) on semi-blind channel estimation for amplify-and-forward two-way relay
networks. The bounds cover a wide range of modulation schemes that satisfy a
certain symmetry condition. In particular, the important classes of PSK and
square QAM are covered. For the case square QAM, we also provide simplified
expressions that lend themselves more easily to numerical implementation. The
derived bounds are used to show that the semi-blind approach, which exploits
both the transmitted pilots and the transmitted data symbols, can provide
substantial improvements in estimation accuracy over the training-based
approach which only uses pilot symbols to estimate the channel parameters. We
also derive the more tractable modified CRB which accurately approximates the
exact CRB at high SNR for low modulation orders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5490</identifier>
 <datestamp>2014-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5490</id><created>2012-07-23</created><updated>2013-06-20</updated><authors><author><keyname>Lefebvre</keyname><forenames>Antoine</forenames><affiliation>LMA</affiliation></author><author><keyname>Scavone</keyname><forenames>Gary P.</forenames><affiliation>LMA</affiliation></author><author><keyname>Kergomard</keyname><forenames>Jean</forenames><affiliation>LMA</affiliation></author></authors><title>External Tonehole Interactions in Woodwind Instruments</title><categories>physics.class-ph cs.SD</categories><proxy>ccsd</proxy><journal-ref>Acta Acustica united with Acustica 99 (2013) 975-985</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical Transfer-Matrix Method (TMM) is often used to calculate the
input impedance of woodwind instruments. However, the TMM ignores the possible
influence of the radiated sound from toneholes on other open holes. In this
paper a method is proposed to account for external tonehole interactions. We
describe the Transfer-Matrix Method with external Interaction (TMMI) and then
compare results using this approach with the Finite Element Method (FEM) and
TMM, as well as with experimental data. It is found that the external tonehole
interactions increase the amount of radiated energy, reduce slightly the lower
resonance frequencies, and modify significantly the response near and above the
tonehole lattice cutoff frequency. In an appendix, a simple perturbation of the
TMM to account for external interactions is investigated, though it is found to
be inadequate at low frequencies and for holes spaced far apart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5497</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5497</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author></authors><title>Password Protected Smart Card and Memory Stick Authentication Against
  Off-line Dictionary Attacks</title><categories>cs.CR</categories><journal-ref>SEC 2012, IFIP AICT 376, pp. 489-500, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the security requirements for remote authentication
with password protected smart card. In recent years, several protocols for
password-based authenticated key exchange have been proposed. These protocols
are used for the protection of password based authentication between a client
and a remote server. In this paper, we will focus on the password based
authentication between a smart card owner and smart card via an untrusted card
reader. In a typical scenario, a smart card owner inserts the smart card into
an untrusted card reader and input the password via the card reader in order
for the smart card to carry out the process of authentication with a remote
server. In this case, we want to guarantee that the card reader will not be
able to impersonate the card owner in future without the smart card itself.
Furthermore, the smart card could be stolen. If this happens, we want the
assurance that an adversary could not use the smart card to impersonate the
card owner even though the sample space of passwords may be small enough to be
enumerated by an off-line adversary. At the end of this paper, we further
extend our results to credential storage on portable non-tamper resistant
storage devices such as USB memory sticks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5518</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5518</id><created>2012-07-23</created><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>Optimal Multi-Dimensional Mechanism Design: Reducing Revenue to Welfare
  Maximization</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a reduction from revenue maximization to welfare maximization in
multi-dimensional Bayesian auctions with arbitrary (possibly combinatorial)
feasibility constraints and independent bidders with arbitrary (possibly
combinatorial) demand constraints, appropriately extending Myerson's result to
this setting. We also show that every feasible Bayesian auction can be
implemented as a distribution over virtual VCG allocation rules. A virtual VCG
allocation rule has the following simple form: Every bidder's type t_i is
transformed into a virtual type f_i(t_i), via a bidder-specific function. Then,
the allocation maximizing virtual welfare is chosen. Using this
characterization, we show how to find and run the revenue-optimal auction given
only black box access to an implementation of the VCG allocation rule. We
generalize this result to arbitrarily correlated bidders, introducing the
notion of a second-order VCG allocation rule.
  We obtain our reduction from revenue to welfare optimization via two
algorithmic results on reduced forms in settings with arbitrary feasibility and
demand constraints. First, we provide a separation oracle for determining
feasibility of a reduced form. Second, we provide a geometric algorithm to
decompose any feasible reduced form into a distribution over virtual VCG
allocation rules. In addition, we show how to execute both algorithms given
only black box access to an implementation of the VCG allocation rule.
  Our results are computationally efficient for all multi-dimensional settings
where the bidders are additive. In this case, our mechanisms run in time
polynomial in the total number of bidder types, but not type profiles. For
generic correlated distributions, this is the natural description complexity of
the problem. The runtime can be further improved to poly(#items, #bidders) in
item-symmetric settings by making use of recent techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5528</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5528</id><created>2012-07-23</created><authors><author><keyname>Delgado</keyname><forenames>Moises</forenames></author><author><keyname>Janwa</keyname><forenames>Heeralal</forenames></author></authors><title>On the Conjecture on APN Functions</title><categories>cs.IT math.AG math.CO math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An almost perfect nonlinear (APN) function (necessarily a polynomial
function) on a finite field $\mathbb{F}$ is called exceptional APN, if it is
also APN on infinitely many extensions of $\mathbb{F}$. In this article we
consider the most studied case of $\mathbb{F}=\mathbb{F}_{2^n}$.
  A conjecture of Janwa-Wilson and McGuire-Janwa-Wilson (1993/1996), settled in
2011, was that the only exceptional monomial APN functions are the monomials
$x^n$, where $n=2^i+1$ or $n={2^{2i}-2^i+1}$ (the Gold or the Kasami exponents
respectively). A subsequent conjecture states that any exceptional APN function
is one of the monomials just described. One of our result is that all functions
of the form $f(x)=x^{2^k+1}+h(x)$ (for any odd degree $h(x)$, with a mild
condition in few cases), are not exceptional APN, extending substantially
several recent results towards the resolution of the stated conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5536</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5536</id><created>2012-07-23</created><authors><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>MCTS Based on Simple Regret</title><categories>cs.AI cs.LG</categories><comments>AAAI 2012, 7 pages. arXiv admin note: text overlap with
  arXiv:1108.3711</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UCT, a state-of-the art algorithm for Monte Carlo tree search (MCTS) in games
and Markov decision processes, is based on UCB, a sampling policy for the
Multi-armed Bandit problem (MAB) that minimizes the cumulative regret. However,
search differs from MAB in that in MCTS it is usually only the final &quot;arm pull&quot;
(the actual move selection) that collects a reward, rather than all &quot;arm
pulls&quot;. Therefore, it makes more sense to minimize the simple regret, as
opposed to the cumulative regret. We begin by introducing policies for
multi-armed bandits with lower finite-time and asymptotic simple regret than
UCB, using it to develop a two-stage scheme (SR+CR) for MCTS which outperforms
UCT empirically.
  Optimizing the sampling process is itself a metareasoning problem, a solution
of which can use value of information (VOI) techniques. Although the theory of
VOI for search exists, applying it to MCTS is non-trivial, as typical myopic
assumptions fail. Lacking a complete working VOI theory for MCTS, we
nevertheless propose a sampling scheme that is &quot;aware&quot; of VOI, achieving an
algorithm that in empirical evaluation outperforms both UCT and the other
proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5542</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5542</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Yongge</forenames></author></authors><title>LT Codes For Efficient and Reliable Distributed Storage Systems
  Revisited</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LT codes and digital fountain techniques have received significant attention
from both academics and industry in the past few years. There have also been
extensive interests in applying LT code techniques to distributed storage
systems such as cloud data storage in recent years. However, Plank and
Thomason's experimental results show that LDPC code performs well only
asymptotically when the number of data fragments increases and it has the worst
performance for small number of data fragments (e.g., less than 100). In their
INFOCOM 2012 paper, Cao, Yu, Yang, Lou, and Hou proposed to use exhaustive
search approach to find a deterministic LT code that could be used to decode
the original data content correctly in distributed storage systems. However, by
Plank and Thomason's experimental results, it is not clear whether the
exhaustive search approach will work efficiently or even correctly. This paper
carries out the theoretical analysis on the feasibility and performance issues
for applying LT codes to distributed storage systems. By employing the
underlying ideas of efficient Belief Propagation (BP) decoding process in LT
codes, this paper introduces two classes of codes called flat BP-XOR codes and
array BP-XOR codes (which can be considered as a deterministic version of LT
codes). We will show the equivalence between the edge-colored graph model and
degree-one-and-two encoding symbols based array BP-XOR codes. Using this
equivalence result, we are able to design general array BP-XOR codes using
graph based results. Similarly, based on this equivalence result, we are able
to get new results for edge-colored graph models using results from array
BP-XOR codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5545</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5545</id><created>2012-07-23</created><authors><author><keyname>Tapiador</keyname><forenames>Antonio</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>V&#xed;ctor</forenames></author><author><keyname>Salvach&#xfa;a</keyname><forenames>Joaqu&#xed;n</forenames></author></authors><title>An analysis of social network connect services</title><categories>cs.SE</categories><comments>Preprint of article published in Proceedings of WEBIST 2012. Porto,
  Portugal</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Social network platforms are increasingly becoming identity providers and a
media for showing multiple types of activity from third-party web sites. In
this article, we analyze the services provided by seven of the most popular
social network platforms. Results show OAuth emerging as the authentication and
authorization protocol, giving support to three types of APIs, client-side or
Javascript, server-side or representational state transfer (REST) and
streaming. JSON is the most popular format, but there a considerable variety of
resource types and a lack of representation standard, which makes harder for
the third-party developer integrating with several services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5550</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5550</id><created>2012-07-23</created><authors><author><keyname>McCann</keyname><forenames>Mark</forenames></author><author><keyname>Pippenger</keyname><forenames>Nicholas</forenames></author></authors><title>Fault Tolerance in Cellular Automata at Low Fault Rates</title><categories>math.PR cs.CG cs.DM</categories><comments>i+26 pp</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A commonly used model for fault-tolerant computation is that of cellular
automata. The essential difficulty of fault-tolerant computation is present in
the special case of simply remembering a bit in the presence of faults, and
that is the case we treat in this paper. The conceptually simplest mechanism
for correcting errors in a cellular automaton is to determine the next state of
a cell by taking a majority vote among its neighbors (including the cell
itself, if necessary to break ties). We are interested in which regular
two-dimensional tessellations can tolerate faults using this mechanism, when
the fault rate is sufficiently low. We consider both the traditional transient
fault model (where faults occur independently in time and space) and a recently
introduced combined fault model which also includes manufacturing faults (which
occur independently in space, but which affect cells for all time). We
completely classify regular two-dimensional tessellations as to whether they
can tolerate combined transient and manufacturing faults, transient faults but
not manufacturing faults, or not even transient faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5554</identifier>
 <datestamp>2012-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5554</id><created>2012-07-23</created><updated>2012-09-21</updated><authors><author><keyname>Fard</keyname><forenames>Mahdi Milani</forenames></author><author><keyname>Grinberg</keyname><forenames>Yuri</forenames></author><author><keyname>Farahmand</keyname><forenames>Amir-massoud</forenames></author><author><keyname>Pineau</keyname><forenames>Joelle</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>Bellman Error Based Feature Generation using Random Projections on
  Sparse Spaces</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of automatic generation of features for value function
approximation. Bellman Error Basis Functions (BEBFs) have been shown to improve
the error of policy evaluation with function approximation, with a convergence
rate similar to that of value iteration. We propose a simple, fast and robust
algorithm based on random projections to generate BEBFs for sparse feature
spaces. We provide a finite sample analysis of the proposed method, and prove
that projections logarithmic in the dimension of the original space are enough
to guarantee contraction in the error. Empirical results demonstrate the
strength of this method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5555</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5555</id><created>2012-07-23</created><authors><author><keyname>Wang</keyname><forenames>Chung-Li</forenames></author><author><keyname>Chen</keyname><forenames>Xiaoheng</forenames></author><author><keyname>Li</keyname><forenames>Zongwang</forenames></author><author><keyname>Yang</keyname><forenames>Shaohua</forenames></author></authors><title>A Simplified Min-Sum Decoding Algorithm for Non-Binary LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Partially presented in ICNC 2012, International Conference on
  Computing, Networking and Communications. Accepted by IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-binary low-density parity-check codes are robust to various channel
impairments. However, based on the existing decoding algorithms, the decoder
implementations are expensive because of their excessive computational
complexity and memory usage. Based on the combinatorial optimization, we
present an approximation method for the check node processing. The simulation
results demonstrate that our scheme has small performance loss over the
additive white Gaussian noise channel and independent Rayleigh fading channel.
Furthermore, the proposed reduced-complexity realization provides significant
savings on hardware, so it yields a good performance-complexity tradeoff and
can be efficiently implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5558</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5558</id><created>2012-07-23</created><updated>2013-04-20</updated><authors><author><keyname>Khalid</keyname><forenames>Z.</forenames></author><author><keyname>Kennedy</keyname><forenames>R. A.</forenames></author><author><keyname>Durrani</keyname><forenames>S.</forenames></author><author><keyname>Sadeghi</keyname><forenames>P.</forenames></author><author><keyname>Wiaux</keyname><forenames>Y.</forenames></author><author><keyname>McEwen</keyname><forenames>J. D.</forenames></author></authors><title>Fast directional spatially localized spherical harmonic transform</title><categories>cs.IT astro-ph.IM math.IT</categories><comments>12 pages, 5 figures</comments><journal-ref>IEEE Trans. Signal Process. Vol 61, No 9, 2013, pp 2192-2203</journal-ref><doi>10.1109/TSP.2013.2247601</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a transform for signals defined on the sphere that reveals their
localized directional content in the spatio-spectral domain when used in
conjunction with an asymmetric window function. We call this transform the
directional spatially localized spherical harmonic transform (directional
SLSHT) which extends the SLSHT from the literature whose usefulness is limited
to symmetric windows. We present an inversion relation to synthesize the
original signal from its directional-SLSHT distribution for an arbitrary window
function. As an example of an asymmetric window, the most concentrated
band-limited eigenfunction in an elliptical region on the sphere is proposed
for directional spatio-spectral analysis and its effectiveness is illustrated
on the synthetic and Mars topographic data-sets. Finally, since such typical
data-sets on the sphere are of considerable size and the directional SLSHT is
intrinsically computationally demanding depending on the band-limits of the
signal and window, a fast algorithm for the efficient computation of the
transform is developed. The floating point precision numerical accuracy of the
fast algorithm is demonstrated and a full numerical complexity analysis is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5560</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5560</id><created>2012-07-23</created><authors><author><keyname>Jacobs</keyname><forenames>Jeffrey Power</forenames></author><author><keyname>Reggia</keyname><forenames>James</forenames></author></authors><title>Evolving Musical Counterpoint: The Chronopoint Musical Evolution System</title><categories>cs.SD cs.AI cs.NE</categories><comments>6 pages, 6 figures</comments><journal-ref>Proceedings of the First International Workshop on Evolutionary
  Music, 2011 IEEE Congress on Evolutionary Computation, 6-11 (2011)</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Musical counterpoint, a musical technique in which two or more independent
melodies are played simultaneously with the goal of creating harmony, has been
around since the baroque era. However, to our knowledge computational
generation of aesthetically pleasing linear counterpoint based on subjective
fitness assessment has not been explored by the evolutionary computation
community (although generation using objective fitness has been attempted in
quite a few cases). The independence of contrapuntal melodies and the
subjective nature of musical aesthetics provide an excellent platform for the
application of genetic algorithms. In this paper, a genetic algorithm approach
to generating contrapuntal melodies is explained, with a description of the
various musical heuristics used and of how variable-length chromosome strings
are used to avoid generating &quot;jerky&quot; rhythms and melodic phrases, as well as
how subjectivity is incorporated into the algorithm's fitness measures. Next,
results from empirical testing of the algorithm are presented, with a focus on
how a user's musical sophistication influences their experience. Lastly,
further musical and compositional applications of the algorithm are discussed
along with planned future work on the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5589</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5589</id><created>2012-07-24</created><authors><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>VOI-aware MCTS</title><categories>cs.AI cs.LG</categories><comments>2 pages, ECAI 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UCT, a state-of-the art algorithm for Monte Carlo tree search (MCTS) in games
and Markov decision processes, is based on UCB1, a sampling policy for the
Multi-armed Bandit problem (MAB) that minimizes the cumulative regret. However,
search differs from MAB in that in MCTS it is usually only the final &quot;arm pull&quot;
(the actual move selection) that collects a reward, rather than all &quot;arm
pulls&quot;. In this paper, an MCTS sampling policy based on Value of Information
(VOI) estimates of rollouts is suggested. Empirical evaluation of the policy
and comparison to UCB1 and UCT is performed on random MAB instances as well as
on Computer Go.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5592</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5592</id><created>2012-07-24</created><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Petit</keyname><forenames>Barbara</forenames></author></authors><title>Linear Dependent Types in a Call-by-Value Scenario (Long Version)</title><categories>cs.LO cs.PL</categories><comments>22 pages</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear dependent types allow to precisely capture both the extensional
behaviour and the time complexity of lambda terms, when the latter are
evaluated by Krivine's abstract machine. In this work, we show that the same
paradigm can be applied to call-by-value evaluation. A system of linear
dependent types for Plotkin's PCF is introduced, called dlPCFV, whose types
reflect the complexity of evaluating terms in the so-called CEK machine. dlPCFV
is proved to be sound, but also relatively complete: every true statement about
the extensional and intentional behaviour of terms can be derived, provided all
true index term inequalities can be used as assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5627</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5627</id><created>2012-07-24</created><authors><author><keyname>Chikouche</keyname><forenames>Noureddine</forenames></author><author><keyname>Cherif</keyname><forenames>Foudil</forenames></author><author><keyname>Benmohammed</keyname><forenames>Mohamed</forenames></author></authors><title>An Authentication Protocol Based on Combined RFID-Biometric System
  RFID-Biometric System</title><categories>cs.CR</categories><comments>6 pages, 3 figures</comments><journal-ref>International Journal of Advanced Computer Science and
  Applications(IJACSA), Vol. 3, No.4, 2012, 62-67</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio Frequency Identification (RFID) and biometric technologies saw fast
evolutions during the last years and which are used in several applications,
such as access control. Among important characteristics in the RFID tags, we
mention the limitation of resources (memory, energy, ...). Our work focuses on
the design of a RFID authentication protocol which uses biometric data and
which confirms the secrecy, the authentication and the privacy. Our protocol
requires a PRNG (Pseud-Random Number Generator), a robust hash function and
Biometric hash function. The Biometric hash function is used to optimize and to
protect biometric data. For Security analysis of protocol proposed, we will use
AVISPA and SPAN tools to verify the authentication and the secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5636</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5636</id><created>2012-07-24</created><authors><author><keyname>Giannopoulou</keyname><forenames>Archontia C.</forenames></author><author><keyname>Salem</keyname><forenames>Iosif</forenames></author><author><keyname>Zoros</keyname><forenames>Dimitris</forenames></author></authors><title>Effective Computation of Immersion Obstructions for Unions of Graph
  Classes</title><categories>cs.DS cs.CC cs.DM math.CO</categories><comments>An extended abstract of this paper has appeared in the proceedings of
  the 13th Scandinavian Symposium and Workshops on Algorithm Theory (SWAT 2012)
  that took place in Helsinki, Finland</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the final paper of the Graph Minors series N. Robertson and P. Seymour
proved that graphs are well-quasi-ordered under the immersion ordering. A
direct implication of this theorem is that each class of graphs that is closed
under taking immersions can be fully characterized by forbidding a finite set
of graphs (immersion obstruction set). However, as the proof of the
well-quasi-ordering theorem is non-constructive, there is no generic procedure
for computing such a set. Moreover, it remains an open issue to identify for
which immersion-closed graph classes the computation of those sets can become
effective. By adapting the tools that were introduced by I. Adler, M. Grohe and
S. Kreutzer, for the effective computation of minor obstruction sets, we expand
the horizon of computability to immersion obstruction sets. In particular, our
results propagate the computability of immersion obstruction sets of
immersion-closed graph classes to immersion obstruction sets of finite unions
of immersion closed graph classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5640</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5640</id><created>2012-07-24</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Enabling Wireless Power Transfer in Cellular Networks: Architecture,
  Modeling and Deployment</title><categories>cs.IT math.IT</categories><comments>25 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microwave power transfer (MPT) delivers energy wirelessly from stations
called power beacons (PBs) to mobile devices by microwave radiation. This
provides mobiles practically infinite battery lives and eliminates the need of
power cords and chargers. To enable MPT for mobile charging, this paper
proposes a new network architecture that overlays an uplink cellular network
with randomly deployed PBs for powering mobiles, called a hybrid network. The
deployment of the hybrid network under an outage constraint on data links is
investigated based on a stochastic-geometry model where single-antenna base
stations (BSs) and PBs form independent homogeneous Poisson point processes
(PPPs) and single-antenna mobiles are uniformly distributed in Voronoi cells
generated by BSs. In this model, mobiles and PBs fix their transmission power
at p and q, respectively; a PB either radiates isotropically, called isotropic
MPT, or directs energy towards target mobiles by beamforming, called directed
MPT. The model is applied to derive the tradeoffs between the network
parameters including p, q, and the BS/PB densities under the outage constraint.
First, consider the deployment of the cellular network. It is proved that the
outage constraint is satisfied so long as the product the BS density decreases
with increasing p following a power law where the exponent is proportional to
the path-loss exponent. Next, consider the deployment of the hybrid network
assuming infinite energy storage at mobiles. It is shown that for isotropic
MPT, the product between q, the PB density, and the BS density raised to a
power proportional to the path-loss exponent has to be above a given threshold
so that PBs are sufficiently dense; for directed MPT, a similar result is
obtained with the aforementioned product increased by the array gain. Last,
similar results are derived for the case of mobiles having small energy
storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5660</identifier>
 <datestamp>2013-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5660</id><created>2012-07-24</created><updated>2013-08-08</updated><authors><author><keyname>Chern</keyname><forenames>Bobbie</forenames></author><author><keyname>&#xd6;zg&#xfc;r</keyname><forenames>Ayfer</forenames></author></authors><title>Achieving the Capacity of the N-Relay Gaussian Diamond Network Within
  log N Bits</title><categories>cs.IT math.IT</categories><comments>18 pages; Submitted to Transactions on Information Theory in August
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the N-relay Gaussian diamond network where a source node
communicates to a destination node via N parallel relays through a cascade of a
Gaussian broadcast (BC) and a multiple access (MAC) channel. Introduced in 2000
by Schein and Gallager, the capacity of this relay network is unknown in
general. The best currently available capacity approximation, independent of
the coefficients and the SNR's of the constituent channels, is within an
additive gap of 1.3 N bits, which follows from the recent capacity
approximations for general Gaussian relay networks with arbitrary topology.
  In this paper, we approximate the capacity of this network within 2 log N
bits. We show that two strategies can be used to achieve the
information-theoretic cutset upper bound on the capacity of the network up to
an additive gap of O(log N) bits, independent of the channel configurations and
the SNR's. The first of these strategies is simple partial decode-and-forward.
Here, the source node uses a superposition codebook to broadcast independent
messages to the relays at appropriately chosen rates; each relay decodes its
intended message and then forwards it to the destination over the MAC channel.
A similar performance can be also achieved with compress-and-forward type
strategies (such as quantize-map-and-forward and noisy network coding) that
provide the 1.3 N-bit approximation for general Gaussian networks, but only if
the relays quantize their observed signals at a resolution inversely
proportional to the number of relay nodes N. This suggest that the
rule-of-thumb to quantize the received signals at the noise level in the
current literature can be highly suboptimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5661</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5661</id><created>2012-07-24</created><authors><author><keyname>Li</keyname><forenames>Rong-Hua</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author><author><keyname>Huang</keyname><forenames>Xin</forenames></author><author><keyname>Cheng</keyname><forenames>Hong</forenames></author></authors><title>A Framework of Algorithms: Computing the Bias and Prestige of Nodes in
  Trust Networks</title><categories>cs.SI physics.soc-ph</categories><doi>10.1371/journal.pone.0050843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A trust network is a social network in which edges represent the trust
relationship between two nodes in the network. In a trust network, a
fundamental question is how to assess and compute the bias and prestige of the
nodes, where the bias of a node measures the trustworthiness of a node and the
prestige of a node measures the importance of the node. The larger bias of a
node implies the lower trustworthiness of the node, and the larger prestige of
a node implies the higher importance of the node. In this paper, we define a
vector-valued contractive function to characterize the bias vector which
results in a rich family of bias measurements, and we propose a framework of
algorithms for computing the bias and prestige of nodes in trust networks.
Based on our framework, we develop four algorithms that can calculate the bias
and prestige of nodes effectively and robustly. The time and space complexities
of all our algorithms are linear w.r.t. the size of the graph, thus our
algorithms are scalable to handle large datasets. We evaluate our algorithms
using five real datasets. The experimental results demonstrate the
effectiveness, robustness, and scalability of our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5663</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5663</id><created>2012-07-24</created><updated>2012-11-18</updated><authors><author><keyname>Nakamura</keyname><forenames>Mitsuhiro</forenames></author><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author></authors><title>Groupwise information sharing promotes ingroup favoritism in indirect
  reciprocity</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>25 pages, 7 figures. The Abstract is shortened to fill in arXiv's
  abstract form</comments><journal-ref>BMC Evolutionary Biology 2012, 12:213</journal-ref><doi>10.1186/1471-2148-12-213</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indirect reciprocity is a mechanism for cooperation in social dilemma
situations, in which an individual is motivated to help another to acquire a
good reputation and receive help from others afterwards. Ingroup favoritism is
another aspect of human cooperation, whereby individuals help members in their
own group more often than those in other groups. Ingroup favoritism is a puzzle
for the theory of cooperation because it is not easily evolutionarily stable.
In the context of indirect reciprocity, ingroup favoritism has been shown to be
a consequence of employing a double standard when assigning reputations to
ingroup and outgroup members; e.g., helping an ingroup member is regarded as
good, whereas the same action toward an outgroup member is regarded as bad. We
analyze a model of indirect reciprocity in which information sharing is
conducted groupwise. In our model, individuals play social dilemma games within
and across groups, and the information about their reputations is shared within
each group. We show that evolutionarily stable ingroup favoritism emerges even
if all the players use the same reputation assignment rule regardless of group
(i.e., a single standard). Two reputation assignment rules called simple
standing and stern judging yield ingroup favoritism. Stern judging induces much
stronger ingroup favoritism than does simple standing. Simple standing and
stern judging are evolutionarily stable against each other when groups
employing different assignment rules compete and the number of groups is
sufficiently large. In addition, we analytically show as a limiting case that
homogeneous populations of reciprocators that use reputations are unstable when
individuals independently infer reputations of individuals, which is consistent
with previously reported numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5672</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5672</id><created>2012-07-24</created><authors><author><keyname>Dosa</keyname><forenames>Gyorgy</forenames></author><author><keyname>Tuza</keyname><forenames>Zsolt</forenames></author></authors><title>Bin Packing/Covering with Delivery: Some variations, theoretical results
  and efficient offline algorithms</title><categories>cs.DS cs.DM</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent paper \cite{BDT10} we introduced a new problem that we call Bin
Packing/Covering with Delivery, or BP/CD for short. Mainly we mean under this
expression that we look for not only a good, but a &quot;good and fast&quot; packing or
covering. In that paper we mainly dealt with only one possible online BP/CD
model, and proposed a new method that we call the Evolution of Algorithms. In
case of such methods a neighborhood structure is defined among algorithms, and
using a metaheuristic (for example simulated annealing) in some sense the best
algorithm is chosen to solve the problem. Now we turn to investigate the
offline case. We define several ways to treat such a BP/CD problem, although we
investigate only one of them here. For the analysis, a novel view on &quot;offline
optimum&quot; is introduced, which appears to be relevant concerning all problems
where a final solution is ordering-dependent. We prove that if the item sizes
are not allowed to be arbitrarily close to zero, then an optimal offline
solution can be found in polynomial time. On the other hand, for unrestricted
problem instances, no polynomial-time algorithm can achieve an approximation
ratio better than 6/7 if $P\ne NP$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5690</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5690</id><created>2012-07-24</created><authors><author><keyname>Matocha</keyname><forenames>Vojt&#x11b;ch</forenames></author><author><keyname>Holub</keyname><forenames>&#x160;t&#x11b;p&#xe1;n</forenames></author></authors><title>Complexity of testing morphic primitivity</title><categories>cs.FL math.CO</categories><msc-class>68R15</msc-class><journal-ref>Kybernetika, 49 (2) (2013), 216-223</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the algorithm in [Holub, 2009], which decides whether a given word
is a fixed point of a nontrivial morphism. We show that it can be implemented
to have complexity in O(mn), where n is the length of the word and m the size
of the alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5696</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5696</id><created>2012-07-24</created><authors><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author><author><keyname>Philip</keyname><forenames>Geevarghese</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Such&#xfd;</keyname><forenames>Ond&#x159;ej</forenames></author></authors><title>Beyond Max-Cut: \lambda-Extendible Properties Parameterized Above the
  Poljak-Turz\'{i}k Bound</title><categories>cs.DS cs.CC math.CO</categories><comments>23 pages, no figure</comments><msc-class>05C85</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Poljak and Turz\'ik (Discrete Math. 1986) introduced the notion of
\lambda-extendible properties of graphs as a generalization of the property of
being bipartite. They showed that for any 0&lt;\lambda&lt;1 and \lambda-extendible
property \Pi, any connected graph G on n vertices and m edges contains a
subgraph H \in {\Pi} with at least \lambda m+ (1-\lambda)/2 (n-1) edges. The
property of being bipartite is 1/2-extendible, and thus this bound generalizes
the Edwards-Erd\H{o}s bound for Max-Cut.
  We define a variant, namely strong \lambda-extendibility, to which the bound
applies. For a strongly \lambda-extendible graph property \Pi, we define the
parameterized Above Poljak- Turz\'ik (APT) (\Pi) problem as follows: Given a
connected graph G on n vertices and m edges and an integer parameter k, does
there exist a spanning subgraph H of G such that H \in {\Pi} and H has at least
\lambda m + (1-\lambda)/2 (n - 1) + k edges? The parameter is k, the surplus
over the number of edges guaranteed by the Poljak-Turz\'ik bound.
  We consider properties {\Pi} for which APT (\Pi) is fixed- parameter
tractable (FPT) on graphs which are O(k) vertices away from being a graph in
which each block is a clique. We show that for all such properties, APT (\Pi)
is FPT for all 0&lt;\lambda&lt;1. Our results hold for properties of oriented graphs
and graphs with edge labels. Our results generalize the result of Crowston et
al. (ICALP 2012) on Max-Cut parameterized above the Edwards-Erd\H{o}s bound,
and yield FPT algorithms for several graph problems parameterized above lower
bounds, e.g., Max q-Colorable Subgraph problem. Our results also imply that the
parameterized above-guarantee Oriented Max Acyclic Digraph problem is FPT, thus
solving an open question of Raman and Saurabh (Theor. Comput. Sci. 2006).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5708</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5708</id><created>2012-07-24</created><authors><author><keyname>Agrawal</keyname><forenames>Pragya</forenames></author><author><keyname>Das</keyname><forenames>Gautam K.</forenames></author></authors><title>Improved Interference in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set ${\cal V}$ of $n$ sensor node distributed on a 2-dimensional
plane and a source node $s \in {\cal V}$, the {\it interference problem} deals
with assigning transmission range to each $v \in {\cal V}$ such that the
members in ${\cal V}$ maintain connectivity predicate ${\cal P}$, and the
maximum/total interference is minimum. We propose algorithm for both {\it
minimizing maximum interference} and {\it minimizing total interference} of the
networks. For minimizing maximum interference we present optimum solution with
running time $O(({\cal P}_n + n^2) \log n)$ for connectivity predicate ${\cal
P}$ like strong connectivity, broadcast ($s$ is the source), $k$-edge(vertex)
connectivity, spanner, where $O({\cal P}_n)$ is the time complexity for
checking the connectivity predicate ${\cal P}$. The running time of the
previous best known solution was $O({\cal P}_n \times n^2)$ [Bil$\grave{o}$ and
Proietti, 2008].
  For the minimizing total interference we propose optimum algorithm for the
connectivity predicate broadcast. The running time of the propose algorithm is
O(n). For the same problem, the previous best known result was $2(1 + \ln
(n-1))$-factor approximation algorithm [Bil$\grave{o}$ and Proietti, 2008]. We
also propose a heuristic for minimizing total interference in the case of
strongly connected predicate and compare our result with the best result
available in the literature. Experimental results demonstrate that our
heuristic outperform existing result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5711</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5711</id><created>2012-07-24</created><authors><author><keyname>Beyries</keyname><forenames>G&#xe9;r&#xf4;me</forenames><affiliation>SPCMIB</affiliation></author><author><keyname>Rodriguez</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>SPCMIB</affiliation></author></authors><title>Technical Report: CSVM format for scientific tabular data</title><categories>q-bio.QM cs.SE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The CSVM (CSV with metadata data) is issued from CSV format and used for
storing experimental data, models, specifications. CSVM allows the storage of
tabular data with a limited but extensible amount of metadata. This increases
the exchange and long term use of RAW data because all information needed to
use subsequently the data are included in the CSVM file. Basic CSVM files are
readable by current tools (i.e. spreadsheets) for handling tables. Using full
possibilities of concept, it is possible to deviate from a strict table and
annotate also inside the data block. CSVM file are pure ASCII files and could
provide a template for implementing best practices in handling raw data at a
laboratory level, in exchange between data sources, in long term resources, or
in collaborative processes particularly when different scientific fields are
implied. In this document we describe the first (CSVM-1) release of CSVM
format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5720</identifier>
 <datestamp>2012-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5720</id><created>2012-07-24</created><updated>2012-10-10</updated><authors><author><keyname>Rutkowski</keyname><forenames>Tomasz M.</forenames></author><author><keyname>Mori</keyname><forenames>Hiromu</forenames></author><author><keyname>Matsumoto</keyname><forenames>Yoshihiro</forenames></author><author><keyname>Cai</keyname><forenames>Zhenyu</forenames></author><author><keyname>Chang</keyname><forenames>Moonjeong</forenames></author><author><keyname>Nishikawa</keyname><forenames>Nozomu</forenames></author><author><keyname>Makino</keyname><forenames>Shoji</forenames></author><author><keyname>Mori</keyname><forenames>Koichi</forenames></author></authors><title>Haptic BCI Paradigm based on Somatosensory Evoked Potential</title><categories>cs.HC q-bio.NC</categories><comments>2 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new concept and an online prototype of haptic BCI paradigm are presented.
Our main goal is to develop a new, alternative and low cost paradigm, with
open-source hardware and software components. We also report results obtained
with the novel dry EEG electrodes based signal acquisition system by g.tec,
which further improves experimental comfort. We address the following points: a
novel application of the BCI; a new methodological approach used compared to
earlier projects; a new benefit for potential users of a BCI; the approach
working online/in real-time; development of a novel stimuli delivery hardware
and software. The results with five healthy subjects and discussion of future
developments conclude this submission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5721</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5721</id><created>2012-07-24</created><updated>2012-07-27</updated><authors><author><keyname>Guazzini</keyname><forenames>Andrea</forenames></author><author><keyname>Vilone</keyname><forenames>Daniele</forenames></author><author><keyname>Bagnoli</keyname><forenames>Franco</forenames></author><author><keyname>Carletti</keyname><forenames>Timoteo</forenames></author><author><keyname>Grotto</keyname><forenames>Rosapia Lauro</forenames></author></authors><title>Cognitive network structure: an experimental study</title><categories>physics.soc-ph cs.SI</categories><comments>15 pages, 5 figures, 3 tables</comments><journal-ref>Advances in Complex Systems; vol. 15, no. 6, 1250084 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present first experimental results about a small group of
people exchanging private and public messages in a virtual community. Our goal
is the study of the cognitive network that emerges during a chat seance. We
used the Derrida coefficient and the triangle structure under the working
assumption that moods and perceived mutual affinity can produce results
complementary to a full semantic analysis. The most outstanding outcome is the
difference between the network obtained considering publicly exchanged messages
and the one considering only privately exchanged messages: in the former case,
the network is very homogeneous, in the sense that each individual interacts in
the same way with all the participants, whilst in the latter the interactions
among different agents are very heterogeneous, and are based on &quot;the enemy of
my enemy is my friend&quot; strategy. Finally a recent characterization of the
triangular cliques has been considered in order to describe the intimate
structure of the network. Experimental results confirm recent theoretical
studies indicating that certain 3-vertex structures can be used as indicators
for the network aging and some relevant dynamical features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5722</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5722</id><created>2012-07-24</created><authors><author><keyname>Cheriyan</keyname><forenames>Joseph</forenames></author><author><keyname>Friggstad</keyname><forenames>Zachary</forenames></author><author><keyname>Gao</keyname><forenames>Zhihan</forenames></author></authors><title>Approximating Minimum-Cost Connected T-Joins</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design and analyse approximation algorithms for the minimum-cost connected
T-join problem: given an undirected graph G = (V;E) with nonnegative costs on
the edges, and a subset of nodes T, find (if it exists) a spanning connected
subgraph H of minimum cost such that every node in T has odd degree and every
node not in T has even degree; H may have multiple copies of any edge of G. Two
well-known special cases are the TSP (|T| = 0) and the s-t path TSP (|T| = 2).
Recently, An, Kleinberg, and Shmoys [STOC 2012] improved on the long-standing
5/3-approximation guarantee for the latter problem and presented an algorithm
based on LP rounding that achieves an approximation guarantee of (1+sqrt(5))/2
&lt; 1.6181.
  We show that the methods of An et al. extend to the minimum-cost connected
T-join problem. They presented a new proof for a 5/3-approximation guarantee
for the s-t path TSP; their proof extends easily to the minimum-cost connected
T-join problem. Next, we improve on the approximation guarantee of 5/3 by
extending their LP-rounding algorithm to get an approximation guarantee of 13/8
= 1.625 for all |T| &gt;= 4.
  Finally, we focus on the prize-collecting version of the problem, and present
a primal-dual algorithm that is &quot;Lagrangian multiplier preserving&quot; and that
achieves an approximation guarantee 3 - 2/(|T|-1) when |T| &gt;= 4. Our
primal-dual algorithm is a generalization of the known primal-dual
2-approximation for the prize-collecting s-t path TSP. Furthermore, we show
that our analysis is tight by presenting instances with |T| &gt;= 4 such that the
cost of the solution found by the algorithm is exactly 3 - 2/(|T|-1) times the
cost of the constructed dual solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5723</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5723</id><created>2012-07-24</created><authors><author><keyname>Badkobeh</keyname><forenames>Golnaz</forenames></author><author><keyname>Crochemore</keyname><forenames>Maxime</forenames></author></authors><title>Fewest repetitions in infinite binary words</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A square is the concatenation of a nonempty word with itself. A word has
period p if its letters at distance p match. The exponent of a nonempty word is
the quotient of its length over its smallest period.
  In this article we give a proof of the fact that there exists an infinite
binary word which contains finitely many squares and simultaneously avoids
words of exponent larger than 7/3. Our infinite word contains 12 squares, which
is the smallest possible number of squares to get the property, and 2 factors
of exponent 7/3. These are the only factors of exponent larger than 2. The
value 7/3 introduces what we call the finite-repetition threshold of the binary
alphabet. We conjecture it is 7/4 for the ternary alphabet, like its repetitive
threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5734</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5734</id><created>2012-07-24</created><authors><author><keyname>Selvakanmani</keyname><forenames>S.</forenames></author><author><keyname>Sumathi</keyname><forenames>M.</forenames></author></authors><title>A Review of routing protocols for mobile cognitive radio ad hoc networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ad hoc network is a collection of wireless mobile nodes that dynamically form
a temporary network without the use of any existing network infrastructure or
centralized administration. A cognitive radio is a radio that can change its
transmitter parameters based on interaction with the environment in which it
operates. The basic idea of cognitive radio networks is that the unlicensed
devices (cognitive radio users or secondary users) need to vacate the spectrum
band once the licensed device (primary user) is detected. Cognitive capability
and reconfigurability are the key characteristics of cognitive radio. Routing
is an important issue in Mobile Cognitive Radio Ad Hoc Networks (MCRAHNs). In
this paper, a survey of routing protocols for mobile cognitive radio ad
networks is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5736</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5736</id><created>2012-07-24</created><authors><author><keyname>Divya</keyname><forenames>A.</forenames></author><author><keyname>Singh</keyname><forenames>Sanjay</forenames></author></authors><title>Differentiated QoS with Modified C/I Based Scheduling Algorithm</title><categories>cs.NI</categories><comments>14 pages, 8 figures, Preprint submitted to 2nd world congress on
  Information &amp; Communication Technologies (WICT 2012), Trivandrum</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Second-generation (2G) digital cellular systems constitute the majority of
cellular communication deployed today. A variety of services of 2G systems has
increased significantly and this will continue to grow even further in the
emerging third-generation (3G) systems. Universal Mobile Telecommunication
System (UMTS) is a third-generation mobile communications system which uses the
Wide-Band Code Division Multiple Access (WCDMA) technique to support a wide
variety of services, like speech, video telephony, Internet browsing, etc.
These services require a wide range of Quality of Service (QoS) requirements.
QoS is an important issue as the number of multimedia services increases day by
day. Differentiated QoS methods allow the differentiation of users based on
their priority levels and channel conditions so that the network can allocate
the bandwidth for a particular request based on the QoS requirements. These
requirements are controlled by Radio Resource Management (RRM) mechanisms. In
this paper we have proposed two RRM algorithms which are modification to the
existing scheduling algorithms. One is Prioritized C/I scheduling, which takes
the priorities into consideration, and this algorithm serves the user with
highest priority. Other algorithm is Modified Inverse C/I scheduling, which
takes channel conditions into consideration and serves the users in degraded
conditions, thereby improving QoS. The performance evaluation of two algorithms
is done with EURANE extensions for NS-2. Simulation results shows the
improvement in QoS for the users who are at equidistance from Base Station (BS)
but requesting for different services by implementing Prioritized C/I
scheduling and also for the users who are in degraded conditions by
implementing Modified Inverse C/I scheduling when compared to Max C/I and
Inverse C/I scheduling algorithm respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5742</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5742</id><created>2012-07-24</created><updated>2013-08-16</updated><authors><author><keyname>Kaced</keyname><forenames>Tarik</forenames></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author></authors><title>Conditional Information Inequalities for Entropic and Almost Entropic
  Points</title><categories>cs.IT cs.DM math.IT math.PR</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory 59(11), 2013, pp.
  7149-7167</journal-ref><doi>10.1109/TIT.2013.2274614</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study conditional linear information inequalities, i.e., linear
inequalities for Shannon entropy that hold for distributions whose entropies
meet some linear constraints. We prove that some conditional information
inequalities cannot be extended to any unconditional linear inequalities. Some
of these conditional inequalities hold for almost entropic points, while others
do not. We also discuss some counterparts of conditional information
inequalities for Kolmogorov complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5745</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5745</id><created>2012-07-24</created><authors><author><keyname>Rajasurya</keyname><forenames>Swathi</forenames></author><author><keyname>Muralidharan</keyname><forenames>Tamizhamudhu</forenames></author><author><keyname>Devi</keyname><forenames>Sandhiya</forenames></author><author><keyname>Swamynathan</keyname><forenames>S.</forenames></author></authors><title>Semantic Information Retrieval Using Ontology In University Domain</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's conventional search engines hardly do provide the essential content
relevant to the user's search query. This is because the context and semantics
of the request made by the user is not analyzed to the full extent. So here the
need for a semantic web search arises. SWS is upcoming in the area of web
search which combines Natural Language Processing and Artificial Intelligence.
The objective of the work done here is to design, develop and implement a
semantic search engine- SIEU(Semantic Information Extraction in University
Domain) confined to the university domain. SIEU uses ontology as a knowledge
base for the information retrieval process. It is not just a mere keyword
search. It is one layer above what Google or any other search engines retrieve
by analyzing just the keywords. Here the query is analyzed both syntactically
and semantically. The developed system retrieves the web results more relevant
to the user query through keyword expansion. The results obtained here will be
accurate enough to satisfy the request made by the user. The level of accuracy
will be enhanced since the query is analyzed semantically. The system will be
of great use to the developers and researchers who work on web. The Google
results are re-ranked and optimized for providing the relevant links. For
ranking an algorithm has been applied which fetches more apt results for the
user query.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5746</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5746</id><created>2012-07-24</created><authors><author><keyname>Markakis</keyname><forenames>Mihalis G.</forenames></author><author><keyname>Modiano</keyname><forenames>Eytan</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Delay Stability Regions of the Max-Weight Policy under Heavy-Tailed
  Traffic</title><categories>cs.SY cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We carry out a delay stability analysis (i.e., determine conditions under
which expected steady-state delays at a queue are finite) for a simple 3-queue
system operated under the Max-Weight scheduling policy, for the case where one
of the queues is fed by heavy-tailed traffic (i.e, when the number of arrivals
at each time slot has infinite second moment). This particular system
exemplifies an intricate phenomenon whereby heavy-tailed traffic at one queue
may or may not result in the delay instability of another queue, depending on
the arrival rates.
  While the ordinary stability region (in the sense of convergence to a
steady-state distribution) is straightforward to determine, the determination
of the delay stability region is more involved: (i) we use &quot;fluid-type&quot; sample
path arguments, combined with renewal theory, to prove delay instability
outside a certain region; (ii) we use a piecewise linear Lyapunov function to
prove delay stability in the interior of that same region; (iii) as an
intermediate step in establishing delay stability, we show that the expected
workload of a stable M/GI/1 queue scales with time as
$\mathcal{O}(t^{1/(1+\gamma)})$, assuming that service times have a finite
$1+\gamma$ moment, where $\gamma \in (0,1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5747</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5747</id><created>2012-07-24</created><authors><author><keyname>Kokolaki</keyname><forenames>Evangelia</forenames></author><author><keyname>Karaliopoulos</keyname><forenames>Merkouris</forenames></author><author><keyname>Stavrakakis</keyname><forenames>Ioannis</forenames></author></authors><title>Leveraging information in vehicular parking games</title><categories>cs.GT cs.NI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our paper approaches the parking assistance service in urban environments as
an instance of service provision in non-cooperative network environments. We
propose normative abstractions for the way drivers pursue parking space and the
way they respond to partial or complete information for parking demand and
supply as well as specific pricing policies on public and private parking
facilities. The drivers are viewed as strategic agents who make rational
decisions attempting to minimize the cost of the acquired parking spot. We
formulate the resulting games as resource selection games and derive their
equilibria under different expressions of uncertainty about the overall parking
demand. The efficiency of the equilibrium states is compared against the
optimal assignment that could be determined by a centralized entity and
conditions are derived for minimizing the related price of anarchy value. Our
results provide useful hints for the pricing and practical management of
on-street and private parking resources. More importantly, they exemplify
counterintuitive less-is-more effects about the way information availability
modulates the service cost, which underpin general competitive service
provision settings and contribute to the better understanding of effective
information mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5774</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5774</id><created>2012-07-22</created><updated>2012-07-27</updated><authors><author><keyname>Caraig</keyname><forenames>Lou Marvin</forenames></author></authors><title>A New Training Algorithm for Kanerva's Sparse Distributed Memory</title><categories>cs.CV cs.LG cs.NE</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sparse Distributed Memory proposed by Pentii Kanerva (SDM in short) was
thought to be a model of human long term memory. The architecture of the SDM
permits to store binary patterns and to retrieve them using partially matching
patterns. However Kanerva's model is especially efficient only in handling
random data. The purpose of this article is to introduce a new approach of
training Kanerva's SDM that can handle efficiently non-random data, and to
provide it the capability to recognize inverted patterns. This approach uses a
signal model which is different from the one proposed for different purposes by
Hely, Willshaw and Hayes in [4]. This article additionally suggests a different
way of creating hard locations in the memory despite the Kanerva's static
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5777</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5777</id><created>2012-07-24</created><authors><author><keyname>Khurana</keyname><forenames>Udayan</forenames></author><author><keyname>Deshpande</keyname><forenames>Amol</forenames></author></authors><title>Efficient Snapshot Retrieval over Historical Graph Data</title><categories>cs.DB cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of managing historical data for large evolving
information networks like social networks or citation networks, with the goal
to enable temporal and evolutionary queries and analysis. We present the design
and architecture of a distributed graph database system that stores the entire
history of a network and provides support for efficient retrieval of multiple
graphs from arbitrary time points in the past, in addition to maintaining the
current state for ongoing updates. Our system exposes a general programmatic
API to process and analyze the retrieved snapshots. We introduce DeltaGraph, a
novel, extensible, highly tunable, and distributed hierarchical index structure
that enables compactly recording the historical information, and that supports
efficient retrieval of historical graph snapshots for single-site or parallel
processing. Along with the original graph data, DeltaGraph can also maintain
and index auxiliary information; this functionality can be used to extend the
structure to efficiently execute queries like subgraph pattern matching over
historical data. We develop analytical models for both the storage space needed
and the snapshot retrieval times to aid in choosing the right parameters for a
specific scenario. In addition, we present strategies for materializing
portions of the historical graph state in memory to further speed up the
retrieval process. Secondly, we present an in-memory graph data structure
called GraphPool that can maintain hundreds of historical graph instances in
main memory in a non-redundant manner. We present a comprehensive experimental
evaluation that illustrates the effectiveness of our proposed techniques at
managing historical graph information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5781</identifier>
 <datestamp>2014-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5781</id><created>2012-07-24</created><updated>2013-09-28</updated><authors><author><keyname>Rossi</keyname><forenames>Roberto</forenames></author><author><keyname>Prestwich</keyname><forenames>Steven</forenames></author><author><keyname>Tarim</keyname><forenames>S. Armagan</forenames></author><author><keyname>Hnich</keyname><forenames>Brahim</forenames></author></authors><title>Confidence-based Optimization for the Newsvendor Problem</title><categories>math.OC cs.SY stat.OT</categories><comments>Working draft</comments><journal-ref>European Journal of Operational Research, Elsevier, Vol.
  239(3):674-684, 2014</journal-ref><doi>10.1016/j.ejor.2014.06.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel strategy to address the issue of demand estimation in
single-item single-period stochastic inventory optimisation problems. Our
strategy analytically combines confidence interval analysis and inventory
optimisation. We assume that the decision maker is given a set of past demand
samples and we employ confidence interval analysis in order to identify a range
of candidate order quantities that, with prescribed confidence probability,
includes the real optimal order quantity for the underlying stochastic demand
process with unknown stationary parameter(s). In addition, for each candidate
order quantity that is identified, our approach can produce an upper and a
lower bound for the associated cost. We apply our novel approach to three
demand distribution in the exponential family: binomial, Poisson, and
exponential. For two of these distributions we also discuss the extension to
the case of unobserved lost sales. Numerical examples are presented in which we
show how our approach complements existing frequentist - e.g. based on maximum
likelihood estimators - or Bayesian strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5810</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5810</id><created>2012-07-24</created><updated>2012-10-30</updated><authors><author><keyname>Starnini</keyname><forenames>Michele</forenames></author><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author><author><keyname>Pastor-Satorras</keyname><forenames>Romualdo</forenames></author></authors><title>Ordering dynamics of the multi-state voter model</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><journal-ref>J. Stat. Mech. (2012) P10027</journal-ref><doi>10.1088/1742-5468/2012/10/P10027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The voter model is a paradigm of ordering dynamics. At each time step, a
random node is selected and copies the state of one of its neighbors.
Traditionally, this state has been considered as a binary variable. Here, we
relax this assumption and address the case in which the number of states is a
parameter that can assume any value, from 2 to \infty, in the thermodynamic
limit. We derive mean-field analytical expressions for the exit probability and
the consensus time for the case of an arbitrary number of states. We then
perform a numerical study of the model in low dimensional lattices, comparing
the case of multiple states with the usual binary voter model. Our work
generalizes the well-known results for the voter model, and sheds light on the
role of the so far almost neglected parameter accounting for the number of
states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5813</identifier>
 <datestamp>2014-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5813</id><created>2012-07-24</created><updated>2014-01-23</updated><authors><author><keyname>Chandrasekaran</keyname><forenames>Karthekeyan</forenames></author><author><keyname>Vegh</keyname><forenames>Laszlo A.</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>The Cutting Plane Method is Polynomial for Perfect Matchings</title><categories>cs.DS cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cutting plane approach to optimal matchings has been discussed by several
authors over the past decades (e.g., Padberg and Rao '82, Grotschel and Holland
'85, Lovasz and Plummer '86, Trick '87, Fischetti and Lodi '07) and its
convergence has been an open question. We give a cutting plane algorithm that
converges in polynomial-time using only Edmonds' blossom inequalities; it
maintains half-integral intermediate LP solutions supported by a disjoint union
of odd cycles and edges. Our main insight is a method to retain only a subset
of the previously added cutting planes based on their dual values. This allows
us to quickly find violated blossom inequalities and argue convergence by
tracking the number of odd cycles in the support of intermediate solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5827</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5827</id><created>2012-07-24</created><authors><author><keyname>Ghosh</keyname><forenames>Satrajit S.</forenames></author></authors><title>Algorithm to suppress scanner noise in recorded speech during functional
  magnetic resonance imaging</title><categories>cs.SD</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The high-intensity, repetitive noise associated with functional magnetic
resonance imaging hinders on-line monitoring of subjects' speech and/or
recording speech signals suitable for off-line analysis. The proposed algorithm
enhances the speech signal by suppressing the scanner noise in the signal
recorded by a single-channel microphone. Significant increases in
signal-to-noise ratio are achieved using an adaptive filter that combines time
and frequency domain elements. In addition to providing a recording suitable
for speech analysis, such a real-time system provides an alternative means (to,
e.g., the &quot;panic ball&quot;) for communication between the patient and the operator
during image acquisition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5830</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5830</id><created>2012-07-24</created><updated>2012-11-29</updated><authors><author><keyname>Parsani</keyname><forenames>M.</forenames></author><author><keyname>Ketcheson</keyname><forenames>D. I.</forenames></author><author><keyname>Deconinck</keyname><forenames>W.</forenames></author></authors><title>Optimized explicit Runge-Kutta schemes for the spectral difference
  method applied to wave propagation problems</title><categories>math.NA cs.NA physics.flu-dyn</categories><comments>37 pages, 3 pages of appendix</comments><journal-ref>SIAM J. on Sci. Comp. (SISC), 35(2):A957-A986, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Explicit Runge-Kutta schemes with large stable step sizes are developed for
integration of high order spectral difference spatial discretization on
quadrilateral grids. The new schemes permit an effective time step that is
substantially larger than the maximum admissible time step of standard explicit
Runge-Kutta schemes available in literature. Furthermore, they have a small
principal error norm and admit a low-storage implementation. The advantages of
the new schemes are demonstrated through application to the Euler equations and
the linearized Euler equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5839</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5839</id><created>2012-07-24</created><authors><author><keyname>Tsianos</keyname><forenames>Konstantinos I.</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>The Impact of Communication Delays on Distributed Consensus Algorithms</title><categories>cs.DC</categories><comments>15 pages double column, 5 figures, Submitted to Transactions on
  Automatic Control, Preliminary results published at the 49th Allerton</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the effect of communication delays on distributed consensus
algorithms. Two ways to model delays on a network are presented. The first
model assumes that each link delivers messages with a fixed (constant) amount
of delay, and the second model is more realistic, allowing for i.i.d.
time-varying bounded delays. In contrast to previous work studying the effects
of delays on consensus algorithms, the models studied here allow for a node to
receive multiple messages from the same neighbor in one iteration. The analysis
of the fixed delay model shows that convergence to a consensus is guaranteed
and the rate of convergence is reduced by no more than a factor O(B^2) where B
is the maximum delay on any link. For the time-varying delay model we also give
a convergence proof which, for row-stochastic consensus protocols, is not a
trivial consequence of ergodic matrix products. In both delay models, the
consensus value is no longer the average, even if the original protocol was an
averaging protocol. For this reason, we propose the use of a different
consensus algorithm called Push-Sum [Kempe et al. 2003]. We model delays in the
Push-Sum framework and show that convergence to the average consensus is
guaranteed. This suggests that Push-Sum might be a better choice from a
practical standpoint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5844</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5844</id><created>2012-07-24</created><authors><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Clark</keyname><forenames>Andrew</forenames></author><author><keyname>Poovendran</keyname><forenames>Radha</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>SODEXO: A System Framework for Deployment and Exploitation of Deceptive
  Honeybots in Social Networks</title><categories>cs.SI cs.CR cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As social networking sites such as Facebook and Twitter are becoming
increasingly popular, a growing number of malicious attacks, such as phishing
and malware, are exploiting them. Among these attacks, social botnets have
sophisticated infrastructure that leverages compromised users accounts, known
as bots, to automate the creation of new social networking accounts for
spamming and malware propagation. Traditional defense mechanisms are often
passive and reactive to non-zero-day attacks. In this paper, we adopt a
proactive approach for enhancing security in social networks by infiltrating
botnets with honeybots. We propose an integrated system named SODEXO which can
be interfaced with social networking sites for creating deceptive honeybots and
leveraging them for gaining information from botnets. We establish a
Stackelberg game framework to capture strategic interactions between honeybots
and botnets, and use quantitative methods to understand the tradeoffs of
honeybots for their deployment and exploitation in social networks. We design a
protection and alert system that integrates both microscopic and macroscopic
models of honeybots and optimally determines the security strategies for
honeybots. We corroborate the proposed mechanism with extensive simulations and
comparisons with passive defenses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5847</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5847</id><created>2012-07-24</created><authors><author><keyname>Fotouhi</keyname><forenames>Babak</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author></authors><title>Growing a Network on a Given Substrate</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><journal-ref>50th Annual Allerton Conference on Communication, Control, and
  Computing (Allerton), 2012, Page(s): 2018 - 2023</journal-ref><doi>10.1109/Allerton.2012.6483470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional studies of network growth models mainly look at the steady state
degree distribution of the graph. Often long time behavior is considered, hence
the initial condition is ignored. In this contribution, the time evolution of
the degree distribution is the center of attention. We consider two specific
growth models; incoming nodes with uniform and preferential attachment, and the
degree distribution of the graph for arbitrary initial condition is obtained as
a function of time. This allows us to characterize the transient behavior of
the degree distribution, as well as to quantify the rate of convergence to the
steady-state limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5849</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5849</id><created>2012-07-24</created><authors><author><keyname>Fotouhi</keyname><forenames>Babak</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>Migration in a Small World: A Network Approach to Modeling Immigration
  Processes</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><journal-ref>50th Annual Allerton Conference on Communication, Control, and
  Computing (Allerton), 2012, Page(s): 136 - 143</journal-ref><doi>10.1109/Allerton.2012.6483210</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing theories of migration either focus on micro- or macroscopic behavior
of populations; that is, either the average behavior of entire population is
modeled directly, or decisions of individuals are modeled directly. In this
work, we seek to bridge these two perspectives by modeling individual agents
decisions to migrate while accounting for the social network structure that
binds individuals into a population. Pecuniary considerations combined with the
decisions of peers are the primary elements of the model, being the main
driving forces of migration. People of the home country are modeled as nodes on
a small-world network. A dichotomous state is associated with each node,
indicating whether it emigrates to the destination country or it stays in the
home country. We characterize the emigration rate in terms of the relative
welfare and population of the home and destination countries. The time
evolution and the steady-state fraction of emigrants are also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5850</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5850</id><created>2012-07-24</created><authors><author><keyname>Andrews</keyname><forenames>Kenneth</forenames></author><author><keyname>Dolinar</keyname><forenames>Sam</forenames></author></authors><title>Performance of the Bounded Distance Decoder on the AWGN Channel</title><categories>cs.IT math.IT</categories><comments>International Symposium on Information Theory (ISIT), July 2012,
  Recent Results session, 2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast to a maximum-likelihood decoder, it is often desirable to use an
incomplete decoder that can detect its decoding errors with high probability.
One common choice is the bounded distance decoder. Bounds are derived for the
total word error rate, Pw, and the undetected error rate, Pu. Excellent
agreement is found with simulation results for a small code, and the bounds are
shown to be tractable for a larger code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5853</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5853</id><created>2012-07-24</created><updated>2014-08-13</updated><authors><author><keyname>Haddad</keyname><forenames>Majed</forenames></author><author><keyname>Hayel</keyname><forenames>Yezekael</forenames></author><author><keyname>Habachi</keyname><forenames>Oussama</forenames></author></authors><title>Spectrum Coordination in Energy Efficient Cognitive Radio Networks</title><categories>cs.GT cs.IT math.IT math.OC</categories><comments>12 pages, 10 figures, to appear in IEEE Transactions on Vehicular
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device coordination in open spectrum systems is a challenging problem,
particularly since users experience varying spectrum availability over time and
location. In this paper, we propose a game theoretical approach that allows
cognitive radio pairs, namely the primary user (PU) and the secondary user
(SU), to update their transmission powers and frequencies simultaneously.
Specifically, we address a Stackelberg game model in which individual users
attempt to hierarchically access to the wireless spectrum while maximizing
their energy efficiency. A thorough analysis of the existence, uniqueness and
characterization of the Stackelberg equilibrium is conducted. In particular, we
show that a spectrum coordination naturally occurs when both actors in the
system decide sequentially about their powers and their transmitting carriers.
As a result, spectrum sensing in such a situation turns out to be a simple
detection of the presence/absence of a transmission on each sub-band. We also
show that when users experience very different channel gains on their two
carriers, they may choose to transmit on the same carrier at the Stackelberg
equilibrium as this contributes enough energy efficiency to outweigh the
interference degradation caused by the mutual transmission. Then, we provide an
algorithmic analysis on how the PU and the SU can reach such a spectrum
coordination using an appropriate learning process. We validate our results
through extensive simulations and compare the proposed algorithm to some
typical scenarios including the non-cooperative case and the
throughput-based-utility systems. Typically, it is shown that the proposed
Stackelberg decision approach optimizes the energy efficiency while still
maximizing the throughput at the equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5856</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5856</id><created>2012-07-24</created><authors><author><keyname>Wu</keyname><forenames>Yue</forenames></author><author><keyname>Agaian</keyname><forenames>Sos S.</forenames></author><author><keyname>Noonan</keyname><forenames>Joseph P.</forenames></author></authors><title>Sudoku Associated Two Dimensional Bijections for Image Scrambling</title><categories>cs.CR</categories><comments>30 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sudoku puzzles are now popular among people in many countries across the
world with simple constraints that no repeated digits in each row, each column,
or each block. In this paper, we demonstrate that the Sudoku configuration
provides us a new alternative way of matrix element representation by using
block-grid pair besides the conventional row-column pair. Moreover, we discover
six more matrix element representations by using row-digit pair, digit-row
pair, column-digit pair, digit-column pair, block-digit pair, and digit-block
pair associated with a Sudoku matrix. These parametric Sudoku associated matrix
element representations not only allow us to denote matrix elements in secret
ways, but also provide us new parametric two-dimensional bijective mappings. We
study these two-dimensional bijections in the problem of image scrambling and
propose a simple but effective Sudoku Associated Image Scrambler only using
Sudoku associated two dimensional bijections for image scrambling without
bandwidth expansion. Our simulation results over a wide collection of image
types and contents demonstrate the effectiveness and robustness of the proposed
method. Scrambler performance analysis with comparisons to peer algorithms
under various investigation methods, including human visual inspections, gray
degree of scrambling, autocorrelation coefficient of adjacent pixels, and key
space and key sensitivities, suggest that the proposed method outperforms or at
least reaches state-of-the-art. Similar scrambling ideas are also applicable to
other digital data forms such as audio and video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5857</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5857</id><created>2012-07-24</created><updated>2013-06-25</updated><authors><author><keyname>Khalid</keyname><forenames>Zubair</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author></authors><title>Distance Distributions in Regular Polygons</title><categories>cs.IT math.IT</categories><comments>13 pages, 5 figures</comments><journal-ref>IEEE Transactions on Vehicular Technology, vol. 62, no. 5, pp.
  2363-2368, June 2013</journal-ref><doi>10.1109/TVT.2013.2241092</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives the exact cumulative density function of the distance
between a randomly located node and any arbitrary reference point inside a
regular $\el$-sided polygon. Using this result, we obtain the closed-form
probability density function (PDF) of the Euclidean distance between any
arbitrary reference point and its $n$-th neighbour node, when $N$ nodes are
uniformly and independently distributed inside a regular $\ell$-sided polygon.
First, we exploit the rotational symmetry of the regular polygons and quantify
the effect of polygon sides and vertices on the distance distributions. Then we
propose an algorithm to determine the distance distributions given any
arbitrary location of the reference point inside the polygon. For the special
case when the arbitrary reference point is located at the center of the
polygon, our framework reproduces the existing result in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5871</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5871</id><created>2012-07-24</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Zhang</keyname><forenames>Haizhang</forenames></author></authors><title>Optimal Sampling Points in Reproducing Kernel Hilbert Spaces</title><categories>cs.IT math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent developments of basis pursuit and compressed sensing seek to
extract information from as few samples as possible. In such applications,
since the number of samples is restricted, one should deploy the sampling
points wisely. We are motivated to study the optimal distribution of finite
sampling points. Formulation under the framework of optimal reconstruction
yields a minimization problem. In the discrete case, we estimate the distance
between the optimal subspace resulting from a general Karhunen-Loeve transform
and the kernel space to obtain another algorithm that is computationally
favorable. Numerical experiments are then presented to illustrate the
performance of the algorithms for the searching of optimal sampling points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5879</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5879</id><created>2012-07-24</created><authors><author><keyname>Hay</keyname><forenames>Nicholas</forenames></author><author><keyname>Russell</keyname><forenames>Stuart</forenames></author><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>Selecting Computations: Theory and Applications</title><categories>cs.AI</categories><comments>10 pages, UAI 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential decision problems are often approximately solvable by simulating
possible future action sequences. {\em Metalevel} decision procedures have been
developed for selecting {\em which} action sequences to simulate, based on
estimating the expected improvement in decision quality that would result from
any particular simulation; an example is the recent work on using bandit
algorithms to control Monte Carlo tree search in the game of Go. In this paper
we develop a theoretical basis for metalevel decisions in the statistical
framework of Bayesian {\em selection problems}, arguing (as others have done)
that this is more appropriate than the bandit framework. We derive a number of
basic results applicable to Monte Carlo selection problems, including the first
finite sampling bounds for optimal policies in certain cases; we also provide a
simple counterexample to the intuitive conjecture that an optimal policy will
necessarily reach a decision in all cases. We then derive heuristic
approximations in both Bayesian and distribution-free settings and demonstrate
their superiority to bandit-based heuristics in one-shot decision problems and
in Go.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5884</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5884</id><created>2012-07-25</created><authors><author><keyname>Huang</keyname><forenames>Jinyu</forenames></author></authors><title>Black-box Identity Testing for Low Degree Unmixed
  $\Sigma\Pi\Sigma\Pi(k)$ Circuits</title><categories>cs.CC math.RA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $\Sigma\Pi\Sigma\Pi(k)$ circuit
$C=\sum_{i=1}^kF_i=\sum_{i=1}^k\prod_{j=1}^{d_i}f_{ij}$ is unmixed if for each
$i\in[k]$, $F_i=f_{i1}(x_1)... f_{in}(x_n)$, where each $f_{ij}$ is a
univariate polynomial given in the sparse representation. In this paper, we
give a polynomial time black-box algorithm of identity testing for the low
degree unmixed $\Sigma\Pi\Sigma\Pi(k)$ circuits. In order to obtain the
black-box algorithm, we first show that a special class of low degree unmixed
$\Sigma\Pi\Sigma\Pi(k)$ circuits of size $s$ is $s^{O(k^2)}$-sparse. Then we
construct a hitting set $\mathcal{H}$ in polynomial time for the low degree
unmixed $\Sigma\Pi\Sigma\Pi(k)$ circuits from the sparsity result above. The
constructed hitting set is polynomial size. Thus we can test whether the
circuit or the polynomial $C$ is identically zero by checking whether $C(a)=0$
for each $a\in\mathcal{H}$. This is the first polynomial time black-box
algorithm for the low degree unmixed $\Sigma\Pi\Sigma\Pi(k)$ circuits, which
also partly answers a question of Saxena \cite{SAX}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5917</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5917</id><created>2012-07-25</created><authors><author><keyname>Mairesse</keyname><forenames>Jean</forenames></author><author><keyname>Marcovici</keyname><forenames>Irene</forenames></author></authors><title>Probabilistic cellular automata and random fields with i.i.d. directions</title><categories>math.PR cs.DM nlin.CG</categories><msc-class>60J05, 60G60, 37B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let us consider the simplest model of one-dimensional probabilistic cellular
automata (PCA). The cells are indexed by the integers, the alphabet is {0, 1},
and all the cells evolve synchronously. The new content of a cell is randomly
chosen, independently of the others, according to a distribution depending only
on the content of the cell itself and of its right neighbor. There are
necessary and sufficient conditions on the four parameters of such a PCA to
have a Bernoulli product invariant measure. We study the properties of the
random field given by the space-time diagram obtained when iterating the PCA
starting from its Bernoulli product invariant measure. It is a non-trivial
random field with very weak dependences and nice combinatorial properties. In
particular, not only the horizontal lines but also the lines in any other
direction consist in i.i.d. random variables. We study extensions of the
results to Markovian invariant measures, and to PCA with larger alphabets and
neighborhoods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5926</identifier>
 <datestamp>2014-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5926</id><created>2012-07-25</created><authors><author><keyname>Demoen</keyname><forenames>Bart</forenames></author><author><keyname>de la Banda</keyname><forenames>Maria Garcia</forenames></author></authors><title>Redundant Sudoku Rules</title><categories>cs.AI</categories><comments>14 pages, 161 figures, to appear in TPLP</comments><doi>10.1017/S1471068412000361</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rules of Sudoku are often specified using twenty seven
\texttt{all\_different} constraints, referred to as the {\em big} \mrules.
Using graphical proofs and exploratory logic programming, the following main
and new result is obtained: many subsets of six of these big \mrules are
redundant (i.e., they are entailed by the remaining twenty one \mrules), and
six is maximal (i.e., removing more than six \mrules is not possible while
maintaining equivalence). The corresponding result for binary inequality
constraints, referred to as the {\em small} \mrules, is stated as a conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5949</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5949</id><created>2012-07-25</created><authors><author><keyname>Harsh</keyname><forenames>Piyush</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Dudouet</keyname><forenames>Florian</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Cascella</keyname><forenames>Roberto G.</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>J&#xe9;gou</keyname><forenames>Yvon</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Morin</keyname><forenames>Christine</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Using Open Standards for Interoperability - Issues, Solutions, and
  Challenges facing Cloud Computing</title><categories>cs.DC</categories><proxy>ccsd</proxy><journal-ref>6th International DMTF Academic Alliance Workshop on Systems and
  Virtualization Management: Standards and the Cloud (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtualization offers several benefits for optimal resource utilization over
traditional non-virtualized server farms. With improvements in internetworking
technologies and increase in network bandwidth speeds, a new era of computing
has been ushered in, that of grids and clouds. With several commercial cloud
providers coming up, each with their own APIs, application description formats,
and varying support for SLAs, vendor lock-in has become a serious issue for end
users. This article attempts to describe the problem, issues, possible
solutions and challenges in achieving cloud interoperability. These issues will
be analyzed in the ambit of the European project Contrail that is trying to
adopt open standards with available virtualization solutions to enhance users'
trust in the clouds by attempting to prevent vendor lock-ins, supporting and
enforcing SLAs together with adequate data protection for sensitive data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5959</identifier>
 <datestamp>2014-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5959</id><created>2012-07-25</created><updated>2014-08-30</updated><authors><author><keyname>Kawahara</keyname><forenames>Jun</forenames></author><author><keyname>Kobayashi</keyname><forenames>Koji M.</forenames></author><author><keyname>Maeda</keyname><forenames>Tomotaka</forenames></author></authors><title>Tight Analysis of Priority Queuing Policy for Egress Traffic</title><categories>cs.DS</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the problems of evaluating performances of switches and routers
have been formulated as online problems, and a great amount of results have
been presented. In this paper, we focus on managing outgoing packets (called
{\em egress traffic}) on switches that support Quality of Service (QoS), and
analyze the performance of one of the most fundamental scheduling policies {\em
Priority Queuing} ($PQ$) using competitive analysis. We formulate the problem
of managing egress queues as follows: An output interface is equipped with $m$
queues, each of which has a buffer of size $B$. The size of a packet is unit,
and each buffer can store up to $B$ packets simultaneously. Each packet is
associated with one of $m$ priority values $\alpha_{j}$ ($1 \leq j \leq m$),
where $\alpha_{1} \leq \alpha_{2} \leq \cdots \leq \alpha_{m}$, $\alpha_{1} =
1$, and $\alpha_{m} = \alpha$ and the task of an online algorithm is to select
one of $m$ queues at each scheduling step. The purpose of this problem is to
maximize the sum of the values of the scheduled packets. For any $B$ and any
$m$, we show that the competitive ratio of $PQ$ is exactly $2 - \min_{x \in [1,
m-1] } \{ \frac{ \alpha_{x+1} }{ \sum_{j = 1}^{x+1} \alpha_{j} } \}$. That is,
we conduct a complete analysis of the performance of $PQ$ using worst case
analysis. Moreover, we show that no deterministic online algorithm can have a
competitive ratio smaller than $1 + \frac{ \alpha^3 + \alpha^2 + \alpha }{
\alpha^4 + 4 \alpha^3 + 3 \alpha^2 + 4 \alpha + 1 }$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.5990</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.5990</id><created>2012-07-25</created><authors><author><keyname>Ahmed-Nacer</keyname><forenames>Mehdi</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Martin</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Urso</keyname><forenames>Pascal</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>File system on CRDT</title><categories>cs.DC cs.DB</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we show how to manage a distributed hierarchical structure
representing a file system. This structure is optimistically replicated, each
user work on his local replica, and updates are sent to other replica. The
different replicas eventually observe same view of file systems. At this stage,
conflicts between updates are very common. We claim that conflict resolution
should rely as little as possible on users. In this report we propose a simple
and modular solution to resolve these problems and maintain data consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6011</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6011</id><created>2012-07-25</created><authors><author><keyname>Mastroeni</keyname><forenames>Loretta</forenames></author><author><keyname>Naldi</keyname><forenames>Maurizio</forenames></author></authors><title>Analysis of cloud storage prices</title><categories>cs.DC</categories><comments>17 pages, 17 figures, 17 references</comments><acm-class>H.3; K.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud storage is fast securing its role as a major repository for both
consumers and business customers. Many companies now offer storage solutions,
sometimes for free for limited amounts of capacity. We have surveyed the
pricing plans of a selection of major cloud providers and compared them using
the unit price as the means of comparison. All the providers, excepting Amazon,
adopt a bundling pricing scheme; Amazon follows instead a block-declining
pricing policy. We compare the pricing plans through a double approach: a
pointwise comparison for each value of capacity, and an overall comparison
using a two-part tariff approximation and a Pareto-dominance criterion. Under
both approaches, most providers appear to offer pricing plans that are more
expensive and can be excluded from a procurement selection in favour of a
limited number of dominant providers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6025</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6025</id><created>2012-07-25</created><authors><author><keyname>Valli</keyname><forenames>Craig</forenames></author><author><keyname>Woodward</keyname><forenames>Andrew</forenames></author></authors><title>The 2008 Australian study of remnant data contained on 2nd hand hard
  disks: the saga continues</title><categories>cs.CR</categories><comments>6th Australian Digital Forensics Conference, 2008</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This study looked for remnant data on enterprise level hard drives that were
purchased through auctions. The drives were analysed for information, be it
topical or formatted. In the event that drives were formatted, forensic tools
were used to recover this data. This years study revealed a high level of not
simply un-erased drives, but drives which contained information that related to
critical infrastructure providers. That such a small sample size yielded such a
high rate of un-erased drives is of considerable concern, and it may be
necessary for the government to become involved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6033</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6033</id><created>2012-07-25</created><authors><author><keyname>Quattrone</keyname><forenames>Giovanni</forenames></author><author><keyname>Capra</keyname><forenames>Licia</forenames></author><author><keyname>De Meo</keyname><forenames>Pasquale</forenames></author><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Ursino</keyname><forenames>Domenico</forenames></author></authors><title>Effective Retrieval of Resources in Folksonomies Using a New Tag
  Similarity Measure</title><categories>cs.IR cs.SI</categories><comments>6 pages, 2 figures, CIKM 2011: 20th ACM Conference on Information and
  Knowledge Management</comments><acm-class>I.5.3</acm-class><journal-ref>Proceedings of the 20th ACM international conference on
  Information and knowledge management, pp. 545-550, 2011</journal-ref><doi>10.1145/2063576.2063657</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social (or folksonomic) tagging has become a very popular way to describe
content within Web 2.0 websites. However, as tags are informally defined,
continually changing, and ungoverned, it has often been criticised for
lowering, rather than increasing, the efficiency of searching. To address this
issue, a variety of approaches have been proposed that recommend users what
tags to use, both when labeling and when looking for resources. These
techniques work well in dense folksonomies, but they fail to do so when tag
usage exhibits a power law distribution, as it often happens in real-life
folksonomies. To tackle this issue, we propose an approach that induces the
creation of a dense folksonomy, in a fully automatic and transparent way: when
users label resources, an innovative tag similarity metric is deployed, so to
enrich the chosen tag set with related tags already present in the folksonomy.
The proposed metric, which represents the core of our approach, is based on the
mutual reinforcement principle. Our experimental evaluation proves that the
accuracy and coverage of searches guaranteed by our metric are higher than
those achieved by applying classical metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6037</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6037</id><created>2012-07-25</created><authors><author><keyname>Quattrone</keyname><forenames>Giovanni</forenames></author><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>De Meo</keyname><forenames>Pasquale</forenames></author><author><keyname>Capra</keyname><forenames>Licia</forenames></author></authors><title>Measuring Similarity in Large-scale Folksonomies</title><categories>cs.IR cs.SI</categories><comments>7 pages, SEKE '11: 23rd International Conference on Software
  Engineering and Knowledge Engineering</comments><journal-ref>SEKE '11: Proceedings of the 23rd International Conference on
  Software Engineering and Knowledge Engineering, pp. 385-391, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social (or folksonomic) tagging has become a very popular way to describe
content within Web 2.0 websites. Unlike taxonomies, which overimpose a
hierarchical categorisation of content, folksonomies enable end-users to freely
create and choose the categories (in this case, tags) that best describe some
content. However, as tags are informally defined, continually changing, and
ungoverned, social tagging has often been criticised for lowering, rather than
increasing, the efficiency of searching, due to the number of synonyms,
homonyms, polysemy, as well as the heterogeneity of users and the noise they
introduce. To address this issue, a variety of approaches have been proposed
that recommend users what tags to use, both when labelling and when looking for
resources.
  As we illustrate in this paper, real world folksonomies are characterized by
power law distributions of tags, over which commonly used similarity metrics,
including the Jaccard coefficient and the cosine similarity, fail to compute.
We thus propose a novel metric, specifically developed to capture similarity in
large-scale folksonomies, that is based on a mutual reinforcement principle:
that is, two tags are deemed similar if they have been associated to similar
resources, and vice-versa two resources are deemed similar if they have been
labelled by similar tags. We offer an efficient realisation of this similarity
metric, and assess its quality experimentally, by comparing it against cosine
similarity, on three large-scale datasets, namely Bibsonomy, MovieLens and
CiteULike.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6045</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6045</id><created>2012-07-25</created><authors><author><keyname>M&#xe9;ndez</keyname><forenames>Agust&#xed;n Santos</forenames></author><author><keyname>Anta</keyname><forenames>Antonio Fern&#xe1;ndez</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Luis L&#xf3;pez</forenames></author></authors><title>Quid Pro Quo: A Mechanism for Fair Collaboration in Networked Systems</title><categories>cs.GT cs.DC cs.NI</categories><comments>23 pages, 5 figures, 3 algorithms</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Collaboration may be understood as the execution of coordinated tasks (in the
most general sense) by groups of users, who cooperate for achieving a common
goal. Collaboration is a fundamental assumption and requirement for the correct
operation of many communication systems. The main challenge when creating
collaborative systems in a decentralized manner is dealing with the fact that
users may behave in selfish ways, trying to obtain the benefits of the tasks
but without participating in their execution. In this context, Game Theory has
been instrumental to model collaborative systems and the task allocation
problem, and to design mechanisms for optimal allocation of tasks. In this
paper, we revise the classical assumptions and propose a new approach to this
problem. First, we establish a system model based on heterogenous nodes (users,
players), and propose a basic distributed mechanism so that, when a new task
appears, it is assigned to the most suitable node. The classical technique for
compensating a node that executes a task is the use of payments (which in most
networks are hard or impossible to implement). Instead, we propose a
distributed mechanism for the optimal allocation of tasks without payments. We
prove this mechanism to be robust event in the presence of independent selfish
or rationally limited players. Additionally, our model is based on very weak
assumptions, which makes the proposed mechanisms susceptible to be implemented
in networked systems (e.g., the Internet).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6051</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6051</id><created>2012-07-25</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Composition of Modular Telemetry System with Interval Multiset Estimates</title><categories>cs.SY cs.AI math.OC</categories><comments>9 pages, 9 figures, 6 tables</comments><msc-class>68T20, 90B40, 90C27, 90C59</msc-class><acm-class>J.6; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes combinatorial synthesis approach with interval multset
estimates of system elements for modeling, analysis, design, and improvement of
a modular telemetry system. Morphological (modular) system design and
improvement are considered as composition of the telemetry system elements
(components) configuration. The solving process is based on Hierarchical
Morphological Multicriteria Design (HMMD): (i) multicriteria selection of
alternatives for system components, (ii) synthesis of the selected alternatives
into a resultant combination (while taking into account quality of the
alternatives above and their compatibility). Interval multiset estimates are
used for assessment of design alternatives for telemetry system elements. Two
additional systems problems are examined: (a) improvement of the obtained
solutions, (b) aggregation of the obtained solutions into a resultant system
configuration. The improvement and aggregation processes are based on multiple
choice problem with interval multiset estimates. Numerical examples for an
on-board telemetry subsystem illustrate the design and improvement processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6052</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6052</id><created>2012-07-25</created><authors><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Coding Delay Analysis of Dense and Chunked Network Codes over Line
  Networks</title><categories>cs.IT math.IT</categories><comments>28 pages, 1 figure, 2 tables; Submitted to IEEE Trans. on Info.
  Theory. arXiv admin note: substantial text overlap with arXiv:1203.1643,
  arXiv:1202.0343</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the coding delay and the average coding delay of
random linear network codes (a.k.a. dense codes) and chunked codes (CC), which
are an attractive alternative to dense codes due to their lower complexity,
over line networks with Bernoulli losses and deterministic regular or Poisson
transmissions. Our results, which include upper bounds on the delay and the
average delay, are (i) for dense codes, in some cases more general, and in some
other cases tighter, than the existing bounds, and provide a more clear picture
of the speed of convergence of dense codes to the (min-cut) capacity of line
networks; and (ii) the first of their kind for CC over networks with such
probabilistic traffics. In particular, these results demonstrate that a
stand-alone CC or a precoded CC provide a better tradeoff between the
computational complexity and the convergence speed to the network capacity over
the probabilistic traffics compared to arbitrary deterministic traffics which
have previously been studied in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6053</identifier>
 <datestamp>2013-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6053</id><created>2012-07-25</created><updated>2013-07-10</updated><authors><author><keyname>Tang</keyname><forenames>Gongguo</forenames></author><author><keyname>Bhaskar</keyname><forenames>Badri Narayan</forenames></author><author><keyname>Shah</keyname><forenames>Parikshit</forenames></author><author><keyname>Recht</keyname><forenames>Benjamin</forenames></author></authors><title>Compressed Sensing off the Grid</title><categories>cs.IT math.IT</categories><comments>47 pages, 16 figures. Modified Section 2.2 on frequency localization
  via convex programming duality. Minor typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating the frequency components of a mixture
of s complex sinusoids from a random subset of n regularly spaced samples.
Unlike previous work in compressed sensing, the frequencies are not assumed to
lie on a grid, but can assume any values in the normalized frequency domain
[0,1]. We propose an atomic norm minimization approach to exactly recover the
unobserved samples. We reformulate this atomic norm minimization as an exact
semidefinite program. Even with this continuous dictionary, we show that most
sampling sets of size O(s log s log n) are sufficient to guarantee the exact
frequency estimation with high probability, provided the frequencies are well
separated. Numerical experiments are performed to illustrate the effectiveness
of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6076</identifier>
 <datestamp>2013-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6076</id><created>2012-07-25</created><updated>2013-11-12</updated><authors><author><keyname>Sejdinovic</keyname><forenames>Dino</forenames></author><author><keyname>Sriperumbudur</keyname><forenames>Bharath</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author></authors><title>Equivalence of distance-based and RKHS-based statistics in hypothesis
  testing</title><categories>stat.ME cs.LG math.ST stat.ML stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/13-AOS1140 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS1140</report-no><journal-ref>Annals of Statistics 2013, Vol. 41, No. 5, 2263-2291</journal-ref><doi>10.1214/13-AOS1140</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a unifying framework linking two classes of statistics used in
two-sample and independence testing: on the one hand, the energy distances and
distance covariances from the statistics literature; on the other, maximum mean
discrepancies (MMD), that is, distances between embeddings of distributions to
reproducing kernel Hilbert spaces (RKHS), as established in machine learning.
In the case where the energy distance is computed with a semimetric of negative
type, a positive definite kernel, termed distance kernel, may be defined such
that the MMD corresponds exactly to the energy distance. Conversely, for any
positive definite kernel, we can interpret the MMD as energy distance with
respect to some negative-type semimetric. This equivalence readily extends to
distance covariance using kernels on the product space. We determine the class
of probability distributions for which the test statistics are consistent
against all alternatives. Finally, we investigate the performance of the family
of distance kernels in two-sample and independence tests: we show in particular
that the energy distance most commonly employed in statistics is just one
member of a parametric family of kernels, and that other choices from this
family can yield more powerful tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6083</identifier>
 <datestamp>2013-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6083</id><created>2012-07-25</created><updated>2013-01-10</updated><authors><author><keyname>Kulesza</keyname><forenames>Alex</forenames></author><author><keyname>Taskar</keyname><forenames>Ben</forenames></author></authors><title>Determinantal point processes for machine learning</title><categories>stat.ML cs.IR cs.LG</categories><comments>120 pages</comments><journal-ref>Foundations and Trends in Machine Learning: Vol. 5: No 2-3, pp
  123-286</journal-ref><doi>10.1561/2200000044</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Determinantal point processes (DPPs) are elegant probabilistic models of
repulsion that arise in quantum physics and random matrix theory. In contrast
to traditional structured models like Markov random fields, which become
intractable and hard to approximate in the presence of negative correlations,
DPPs offer efficient and exact algorithms for sampling, marginalization,
conditioning, and other inference tasks. We provide a gentle introduction to
DPPs, focusing on the intuitions, algorithms, and extensions that are most
relevant to the machine learning community, and show how DPPs can be applied to
real-world applications like finding diverse sets of high-quality search
results, building informative summaries by selecting diverse sentences from
documents, modeling non-overlapping human poses in images or video, and
automatically building timelines of important news stories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6084</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6084</id><created>2012-07-25</created><authors><author><keyname>Ahmadi</keyname><forenames>Behzad</forenames></author><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Permuter</keyname><forenames>Haim H.</forenames></author></authors><title>Information Embedding on Actions</title><categories>cs.IT math.IT</categories><comments>36 pages, 11 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of optimal actuation for channel and source coding was recently
formulated and solved in a number of relevant scenarios. In this class of
models, actions are taken at encoders or decoders, either to acquire side
information in an efficient way or to control or probe effectively the channel
state. In this paper, the problem of embedding information on the actions is
studied for both the source and the channel coding set-ups. In both cases, a
decoder is present that observes only a function of the actions taken by an
encoder or a decoder of an action-dependent point-to-point link. For the source
coding model, this decoder wishes to reconstruct a lossy version of the source
being transmitted over the point-to-point link, while for the channel coding
problem the decoder wishes to retrieve a portion of the message conveyed over
the link. For the problem of source coding with actions taken at the decoder, a
single letter characterization of the set of all achievable tuples of rate,
distortions at the two decoders and action cost is derived, under the
assumption that the mentioned decoder observes a function of the actions
non-causally, strictly causally or causally. A special case of the problem in
which the actions are taken by the encoder is also solved. A single-letter
characterization of the achievable capacity-cost region is then obtained for
the channel coding set-up with actions. Examples are provided that shed light
into the effect of information embedding on the actions for the
action-dependent source and channel coding problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6087</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6087</id><created>2012-07-25</created><updated>2013-08-21</updated><authors><author><keyname>Haddad</keyname><forenames>Majed</forenames></author><author><keyname>Sidi</keyname><forenames>Habib</forenames></author><author><keyname>Wiecek</keyname><forenames>Piotr</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author></authors><title>Automated Dynamic Offset Applied to Cell Association</title><categories>cs.GT cs.IT math.IT</categories><comments>12 pages, 3 figures, technical report. arXiv admin note: text overlap
  with arXiv:1002.3931, arXiv:0903.2966 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a hierarchical Bayesian game framework for
automated dynamic offset selection. Users compete to maximize their throughput
by picking the best locally serving radio access network (RAN) with respect to
their own measurement, their demand and a partial statistical channel state
information (CSI) of other users. In particular, we investigate the properties
of a Stackelberg game, in which the base station is a player on its own. We
derive analytically the utilities related to the channel quality perceived by
users to obtain the equilibria. We study the Price of Anarchy (PoA) of such
system, where the PoA is the ratio of the social welfare attained when a
network planner chooses policies to maximize social welfare versus the social
welfare attained in Nash/Stackeleberg equilibrium when users choose their
policies strategically. We show by means of a Stackelberg formulation, how the
operator, by sending appropriate information about the state of the channel,
can configure a dynamic offset that optimizes its global utility while users
maximize their individual utilities. The proposed hierarchical decision
approach for wireless networks can reach a good trade-off between the global
network performance at the equilibrium and the requested amount of signaling.
Typically, it is shown that when the network goal is orthogonal to user's goal,
this can lead the users to a misleading association problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6096</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6096</id><created>2012-07-25</created><authors><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Procopiuc</keyname><forenames>Cecilia M.</forenames></author><author><keyname>Srivastava</keyname><forenames>Divesh</forenames></author><author><keyname>Yaroslavtsev</keyname><forenames>Grigory</forenames></author></authors><title>Accurate and Efficient Private Release of Datacubes and Contingency
  Tables</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central problem in releasing aggregate information about sensitive data is
to do so accurately while providing a privacy guarantee on the output. Recent
work focuses on the class of linear queries, which include basic counting
queries, data cubes, and contingency tables. The goal is to maximize the
utility of their output, while giving a rigorous privacy guarantee. Most
results follow a common template: pick a &quot;strategy&quot; set of linear queries to
apply to the data, then use the noisy answers to these queries to reconstruct
the queries of interest. This entails either picking a strategy set that is
hoped to be good for the queries, or performing a costly search over the space
of all possible strategies.
  In this paper, we propose a new approach that balances accuracy and
efficiency: we show how to improve the accuracy of a given query set by
answering some strategy queries more accurately than others. This leads to an
efficient optimal noise allocation for many popular strategies, including
wavelets, hierarchies, Fourier coefficients and more. For the important case of
marginal queries we show that this strictly improves on previous methods, both
analytically and empirically. Our results also extend to ensuring that the
returned query answers are consistent with an (unknown) data set at minimal
extra cost in terms of time and noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6103</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6103</id><created>2012-07-24</created><updated>2013-07-30</updated><authors><author><keyname>Hasan</keyname><forenames>Cengis</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames></author><author><keyname>Tsilimantos</keyname><forenames>Dimitrios</forenames></author><author><keyname>Hanawal</keyname><forenames>Manjesh K.</forenames></author></authors><title>The Coalitional Switch off Game of Service Providers</title><categories>cs.GT cs.CG math.OC</categories><comments>This paper has been withdrawn by the author since it was published
  partly</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a significant problem in green networking called switching
off base stations in case of cooperating service providers by means of
stochastic geometric and coalitional game tools. The coalitional game herein
considered is played by service providers who cooperate in switching off base
stations. When they cooperate, any mobile is associated to the nearest BS of
any service provider. Given a Poisson point process deployment model of nodes
over an area and switching off base stations with some probability, it is
proved that the distribution of signal to interference plus noise ratio remains
unchanged while the transmission power is increased up to preserving the
quality of service. The coalitional game behavior of a typical player is called
to be \emph{hedonic} if the gain of any player depends solely on the members of
the coalition to which the player belongs, thus, the coalitions form as a
result of the preferences of the players over their possible coalitions' set.
We also introduce a novel concept which is called the Nash-stable core
containing those gain allocation methods that result in Nash-stable partitions.
By this way, we always guarantee Nash stability. We study the non-emptiness of
the Nash-stable core. Assuming the choice of a coalition is performed only by
one player in a point of time, we prove that the Nash-stable core is non-empty
when a player chooses its coalition in its turn, the player gains zero utility
if the chosen coalition is visited before by itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6137</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6137</id><created>2012-07-25</created><updated>2013-08-21</updated><authors><author><keyname>Sun</keyname><forenames>Hua</forenames></author><author><keyname>Geng</keyname><forenames>Chunhua</forenames></author><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Degrees of Freedom of MIMO X Networks: Spatial Scale Invariance,
  One-Sided Decomposability and Linear Feasibility</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that an M X N user MIMO X network with A antennas at each node has
AMN/(M+N-1) degrees of freedom (DoF), thus resolving in this case a discrepancy
between the spatial scale invariance conjecture (scaling the number of antennas
at each node by a constant factor will scale the total DoF by the same factor)
and a decomposability property of overconstrained wireless networks. While the
best previously-known general DoF outer bound is consistent with the spatial
invariance conjecture, the best previously-known general DoF inner bound,
inspired by the K user MIMO interference channel, was based on the
decomposition of every transmitter and receiver into multiple single antenna
nodes, transforming the network into an AM X AN user SISO X network. While such
a decomposition is DoF optimal for the K user MIMO interference channel, a gap
remained between the best inner and outer bound for the MIMO X channel. Here we
close this gap with the new insight that the MIMO X network is only one-sided
decomposable, i.e., either all the transmitters or all the receivers (but not
both) can be decomposed by splitting multiple antenna nodes into multiple
single antenna nodes without loss of DoF. The result is extended to SIMO and
MISO X networks as well and in each case the DoF results satisfy the spatial
scale invariance property. In addition, the feasibility of linear interference
alignment is investigated based only on spatial beamforming without symbol
extensions. Similar to MIMO interference networks, we show that when the
problem is improper, it is infeasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6146</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6146</id><created>2012-07-25</created><updated>2013-08-17</updated><authors><author><keyname>Vaezi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Labeau</keyname><forenames>Fabrice</forenames></author></authors><title>Systematic DFT Frames: Principle, Eigenvalues Structure, and
  Applications</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Signal Processing, vol. 61, no. 15, pp.
  3774-3885, August 2013</journal-ref><doi>10.1109/TSP.2013.2264812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a host of recent applications requiring some amount of
redundancy, frames are becoming a standard tool in the signal processing
toolbox. In this paper, we study a specific class of frames, known as discrete
Fourier transform (DFT) codes, and introduce the notion of systematic frames
for this class. This is encouraged by a new application of frames, namely,
distributed source coding that uses DFT codes for compression. Studying their
extreme eigenvalues, we show that, unlike DFT frames, systematic DFT frames are
not necessarily tight. Then, we come up with conditions for which these frames
can be tight. In either case, the best and worst systematic frames are
established in the minimum mean-squared reconstruction error sense. Eigenvalues
of DFT frames and their subframes play a pivotal role in this work.
Particularly, we derive some bounds on the extreme eigenvalues DFT subframes
which are used to prove most of the results; these bounds are valuable
independently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6164</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6164</id><created>2012-07-26</created><authors><author><keyname>Anshari</keyname><forenames>Muhammad</forenames></author><author><keyname>Almunawar</keyname><forenames>Mohammad N.</forenames></author><author><keyname>Low</keyname><forenames>Patrick K. C.</forenames></author><author><keyname>Wint</keyname><forenames>Zaw</forenames></author></authors><title>Customer Empowerment in Healthcare Organisations Through CRM 2.0: Survey
  Results from Brunei Tracking a Future Path in E-Health Research</title><categories>cs.CY cs.SI</categories><comments>ASEAS -- Austrian Journal of South-East Asian Studies</comments><journal-ref>ASEAS -- Austrian Journal of South-East Asian Studies, 2012 5(1),
  139-151</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Customer Relationship Management (CRM) with the Web technology provides
healthcare organizations the ability to broaden services beyond its usual
practices, and thus provides a particular advantageous environment to achieve
complex e-health goals. This paper discusses and demonstrates how a new
approach in CRM based on Web 2.0 namely CRM 2.0 will help customers to have
greater control in the sense of controlling the process of interaction
(empowerment) between healthcare organizations with its customers, and among
customers themselves. A survey was conducted to gather preliminary requirements
and expectations on empowerment in Brunei. The survey revealed that there is a
high demand for empowering customers in Brunei through the Web. Regardless of
the limitations of the survey, the general public has responded with a great
support for the capabilities of empowerment listed from the questionnaires. The
data were analyzed to provide initial ideas and recommendation to a future
direction on research for customers' empowerment in e-health services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6174</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6174</id><created>2012-07-26</created><authors><author><keyname>Mao</keyname><forenames>Wenguang</forenames></author><author><keyname>Wang</keyname><forenames>Xudong</forenames></author></authors><title>A++ Random Access for Two-way Relaying in Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-way relaying can significantly improve performance of next generation
wireless networks. However, due to its dependence on multi-node cooperation and
transmission coordination, applying this technique to a wireless network in an
effective and scalable manner poses a challenging problem. To tackle this
problem without relying on complicated scheduling or network optimization
algorithms, we propose a scalable random access scheme that takes measures in
both the physical layer and the medium access control layer. Specifically, we
propose a two-way relaying technique that supports fully asynchronous
transmission and is modulation-independent. It also assumes no priori knowledge
of channel conditions. On the top of this new physical layer technique, a
random access MAC protocol is designed to dynamically form two-way relaying
cooperation in a wireless network. To evaluate the scalable random access
scheme, both theoretical analysis and simulations are carried out. Performance
results illustrate that our scheme has achieved the goal of scalable two-way
relaying in a wireless network and significantly outperforms CSMA/CA protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6175</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6175</id><created>2012-07-26</created><updated>2012-07-31</updated><authors><author><keyname>Backman</keyname><forenames>Spencer</forenames></author></authors><title>A Bijection Between the Recurrent Configurations of a Hereditary
  Chip-Firing Model and Spanning Trees</title><categories>math.CO cond-mat.stat-mech cs.DM math-ph math.MP</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hereditary chip-firing models generalize the Abelian sandpile model and the
cluster firing model to an exponential family of games induced by covers of the
vertex set. This generalization retains some desirable properties, e.g.
stabilization is independent of firings chosen and each chip-firing equivalence
class contains a unique recurrent configuration. In this paper we present an
explicit bijection between the recurrent configurations of a hereditary
chip-firing model on a graph and its spanning trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6178</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6178</id><created>2012-07-26</created><authors><author><keyname>Stauffer</keyname><forenames>Dietrich</forenames></author></authors><title>A Biased Review of Sociophysics</title><categories>physics.soc-ph cs.SI</categories><comments>16 pages for J. Stat. Phys. including 2 figures and numerous
  references</comments><doi>10.1007/s10955-012-0604-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various aspects of recent sociophysics research are shortly reviewed:
Schelling model as an example for lack of interdisciplinary cooperation,
opinion dynamics, combat, and citation statistics as an example for strong
interdisciplinarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6179</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6179</id><created>2012-07-26</created><authors><author><keyname>Anshari</keyname><forenames>Muhammad</forenames></author><author><keyname>Almunawar</keyname><forenames>Mohammad Nabil</forenames></author></authors><title>Framework of Social Customer Relationship Management in E-Health
  Services</title><categories>cs.CY</categories><comments>15 pages. arXiv admin note: substantial text overlap with
  arXiv:1204.3689, arXiv:1203.3919, arXiv:1204.3685, arXiv:1203.4309,
  arXiv:1204.3691, arXiv:1203.3923</comments><journal-ref>Journal of e-Health Management Vol. 2012 (2012)Article ID 766268</journal-ref><doi>10.5171/2012.766268</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Healthcare organization is implementing Customer Relationship Management
(CRM) as a strategy for managing interactions with patients involving
technology to organize, automate, and coordinate business processes. Web-based
CRM provides healthcare organization with the ability to broaden service beyond
its usual practices in achieving a complex patient care goal, and this paper
discusses and demonstrates how a new approach in CRM based on Web 2.0 or Social
CRM helps healthcare organizations to improve their customer support, and at
the same time avoiding possible conflicts, and promoting better healthcare to
patients. A conceptual framework of the new approach will be proposed and
highlighted. The framework includes some important features of Social CRM such
as customer's empowerment, social interactivity between healthcare
organization-patients, and patients-patients. The framework offers new
perspective in building relationships between healthcare organizations and
customers and among customers in e-health scenario. It is developed based on
the latest development of CRM literatures and case studies analysis. In
addition, customer service paradigm in social network's era, the important of
online health education, and empowerment in healthcare organization will be
taken into consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6180</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6180</id><created>2012-07-26</created><authors><author><keyname>Fang</keyname><forenames>Qiang</forenames></author><author><keyname>Huang</keyname><forenames>Xinsheng</forenames></author></authors><title>A Unified Approach of Observability Analysis for Airborne SLAM</title><categories>cs.RO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Observability is a key aspect of the state estimation problem of SLAM,
However, the dimension and variables of SLAM system might be changed with new
features, to which little attention is paid in the previous work. In this
paper, a unified approach of observability analysis for SLAM system is
provided, whether the dimension and variables of SLAM system are changed or
not, we can use this approach to analyze the local or total observability of
the SLAM system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6185</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6185</id><created>2012-07-26</created><authors><author><keyname>Yussoff</keyname><forenames>Yusnani Mohd</forenames></author><author><keyname>Hashim</keyname><forenames>Habibah</forenames></author><author><keyname>Baba</keyname><forenames>Mohd Dani</forenames></author></authors><title>Identity-based Trusted Authentication in Wireless Sensor Network</title><categories>cs.NI cs.CR</categories><comments>10 pages, 5 figures, 4 tables; IJCSI International Journal of
  Computer Science Issues, Vol. 9, Issue 3, No 2, May 2012 ISSN (Online):
  1694-0814</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure communication mechanisms in Wireless Sensor Networks (WSNs) have been
widely deployed to ensure confidentiality, authenticity and integrity of the
nodes and data. Recently many WSNs applications rely on trusted communication
to ensure large user acceptance. Indeed, the trusted relationship thus far can
only be achieved through Trust Management System (TMS) or by adding external
security chip on the WSN platform. In this study an alternative mechanism is
proposed to accomplish trusted communication between sensors based on the
principles defined by Trusted Computing Group (TCG). The results of other
related study have also been analyzed to validate and support our findings.
Finally the proposed trusted mechanism is evaluated for the potential
application on resource constraint devices by quantifying their power
consumption on selected major processes. The result proved the proposed scheme
can establish trust in WSN with less computation and communication and most
importantly eliminating the need for neighboring evaluation for TMS or relying
on external security chip.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6188</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6188</id><created>2012-07-26</created><authors><author><keyname>Nasution</keyname><forenames>Mahyuddin K. M.</forenames></author></authors><title>Kolmogorov Complexity: Clustering Objects and Similarity</title><categories>cs.CC cs.DC</categories><comments>13 pages; Bulletin of Mathematics, Vol. 3 (2011), No. 1: 1-16</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The clustering objects has become one of themes in many studies, and do not
few researchers use the similarity to cluster the instances automatically.
However, few research consider using Kommogorov Complexity to get information
about objects from documents, such as Web pages, where the rich information
from an approach proved to be difficult to. In this paper, we proposed a
similarity measure from Kolmogorov Complexity, and we demonstrate the
possibility of exploiting features from Web based on hit counts for objects of
Indonesia Intellectual.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6199</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6199</id><created>2012-07-26</created><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Krishnan</keyname><forenames>Shankar</forenames></author></authors><title>Achieving Approximate Soft Clustering in Data Streams</title><categories>cs.DS cs.AI</categories><comments>8 page. arXiv admin note: text overlap with arXiv:1004.4864 by other
  authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, data streaming has gained prominence due to advances in
technologies that enable many applications to generate continuous flows of
data. This increases the need to develop algorithms that are able to
efficiently process data streams. Additionally, real-time requirements and
evolving nature of data streams make stream mining problems, including
clustering, challenging research problems.
  In this paper, we propose a one-pass streaming soft clustering (membership of
a point in a cluster is described by a distribution) algorithm which
approximates the &quot;soft&quot; version of the k-means objective function. Soft
clustering has applications in various aspects of databases and machine
learning including density estimation and learning mixture models. We first
achieve a simple pseudo-approximation in terms of the &quot;hard&quot; k-means algorithm,
where the algorithm is allowed to output more than $k$ centers. We convert this
batch algorithm to a streaming one (using an extension of the k-means++
algorithm recently proposed) in the &quot;cash register&quot; model. We also extend this
algorithm when the clustering is done over a moving window in the data stream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6200</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6200</id><created>2012-07-26</created><authors><author><keyname>Komenda</keyname><forenames>Jan</forenames></author><author><keyname>Masopust</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>van Schuppen</keyname><forenames>Jan H.</forenames></author></authors><title>On Algorithms and Extensions of Coordination Control of Discrete-Event
  Systems</title><categories>math.OC cs.FL</categories><comments>WODES 2012, Guadalajara, Mexico</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we further develop the coordination control scheme for
discrete-event systems based on the Ramadge-Wonham framework. The notions of
conditional decomposability, conditional controllability, and conditional
closedness are revised and simplified, supremal conditionally controllable
sublanguages of general non-prefix-closed languages are discussed, and a
procedure for the computation of a coordinator for nonblockingness is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6202</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6202</id><created>2012-07-26</created><authors><author><keyname>Liu</keyname><forenames>Huaping</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>de Carvalho</keyname><forenames>Elisabeth</forenames></author><author><keyname>Zhao</keyname><forenames>Yuping</forenames></author></authors><title>Sum-Rate Optimization in a Two-Way Relay Network with Buffering</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Relay Station (RS) uses a buffer to store and process the received data
packets before forwarding them. Recently, the buffer has been exploited in
one-way relaying to opportunistically schedule the two different links
according to their channel quality. The intuition is that, if the channel to
the destination is poor, then RS stores more data from the source, in order to
use it when the channel to the destination is good. We apply this intuition to
the case of half-duplex two-way relaying, where the interactions among the
buffers and the links become more complex. We investigate the sum-rate
maximization problem in the Time Division Broadcast (TDBC): the users send
signals to the RS in different time slots, the RS decodes and stores messages
in the buffers. For downlink transmission, the RS re-encodes and sends using
the optimal broadcast strategy. The operation in each time slot is not
determined in advance, but depends on the channel state information (CSI). We
derive the decision function for adaptive link selection with respect to CSI
using the Karush-Kuhn-Tucker (KKT) conditions. The thresholds of the decision
function are obtained under Rayleigh fading channel conditions. The numerical
results show that the sum-rate of the adaptive link selection protocol with
buffering is significantly larger compared to the reference protocol with fixed
transmission schedule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6224</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6224</id><created>2012-07-26</created><authors><author><keyname>Euzenat</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author></authors><title>Evolving knowledge through negotiation</title><categories>cs.AI cs.HC</categories><report-no>DPA-12221</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Semantic web information is at the extremities of long pipelines held by
human beings. They are at the origin of information and they will consume it
either explicitly because the information will be delivered to them in a
readable way, or implicitly because the computer processes consuming this
information will affect them. Computers are particularly capable of dealing
with information the way it is provided to them. However, people may assign to
the information they provide a narrower meaning than semantic technologies may
consider. This is typically what happens when people do not think their
assertions as ambiguous. Model theory, used to provide semantics to the
information on the semantic web, is particularly apt at preserving ambiguity
and delivering it to the other side of the pipeline. Indeed, it preserves as
much interpretations as possible. This quality for reasoning efficiency,
becomes a deficiency for accurate communication and meaning preservation.
Overcoming it may require either interactive feedback or preservation of the
source context. Work from social science and humanities may help solving this
particular problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6231</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6231</id><created>2012-07-26</created><updated>2012-10-08</updated><authors><author><keyname>Frank</keyname><forenames>Mario</forenames></author><author><keyname>Biedert</keyname><forenames>Ralf</forenames></author><author><keyname>Ma</keyname><forenames>Eugene</forenames></author><author><keyname>Martinovic</keyname><forenames>Ivan</forenames></author><author><keyname>Song</keyname><forenames>Dawn</forenames></author></authors><title>Touchalytics: On the Applicability of Touchscreen Input as a Behavioral
  Biometric for Continuous Authentication</title><categories>cs.CR cs.LG</categories><comments>to appear at IEEE Transactions on Information Forensics &amp; Security;
  Download data from http://www.mariofrank.net/touchalytics/</comments><journal-ref>IEEE Transactions on Information Forensics and Security (Vol. 8,
  No. 1), pages 136-148, 2013</journal-ref><doi>10.1109/TIFS.2012.2225048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate whether a classifier can continuously authenticate users based
on the way they interact with the touchscreen of a smart phone. We propose a
set of 30 behavioral touch features that can be extracted from raw touchscreen
logs and demonstrate that different users populate distinct subspaces of this
feature space. In a systematic experiment designed to test how this behavioral
pattern exhibits consistency over time, we collected touch data from users
interacting with a smart phone using basic navigation maneuvers, i.e., up-down
and left-right scrolling. We propose a classification framework that learns the
touch behavior of a user during an enrollment phase and is able to accept or
reject the current user by monitoring interaction with the touch screen. The
classifier achieves a median equal error rate of 0% for intra-session
authentication, 2%-3% for inter-session authentication and below 4% when the
authentication test was carried out one week after the enrollment phase. While
our experimental findings disqualify this method as a standalone authentication
mechanism for long-term authentication, it could be implemented as a means to
extend screen-lock time or as a part of a multi-modal biometric authentication
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6246</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6246</id><created>2012-07-26</created><authors><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author><author><keyname>Rika</keyname><forenames>Inbal</forenames></author></authors><title>Mimicking Networks and Succinct Representations of Terminal Cuts</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a large edge-weighted network $G$ with $k$ terminal vertices, we wish
to compress it and store, using little memory, the value of the minimum cut (or
equivalently, maximum flow) between every bipartition of terminals. One
appealing methodology to implement a compression of $G$ is to construct a
\emph{mimicking network}: a small network $G'$ with the same $k$ terminals, in
which the minimum cut value between every bipartition of terminals is the same
as in $G$. This notion was introduced by Hagerup, Katajainen, Nishimura, and
Ragde [JCSS '98], who proved that such $G'$ of size at most $2^{2^k}$ always
exists. Obviously, by having access to the smaller network $G'$, certain
computations involving cuts can be carried out much more efficiently.
  We provide several new bounds, which together narrow the previously known gap
from doubly-exponential to only singly-exponential, both for planar and for
general graphs. Our first and main result is that every $k$-terminal planar
network admits a mimicking network $G'$ of size $O(k^2 2^{2k})$, which is
moreover a minor of $G$. On the other hand, some planar networks $G$ require
$|E(G')| \ge \Omega(k^2)$. For general networks, we show that certain bipartite
graphs only admit mimicking networks of size $|V(G')| \geq 2^{\Omega(k)}$, and
moreover, every data structure that stores the minimum cut value between all
bipartitions of the terminals must use $2^{\Omega(k)}$ machine words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6253</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6253</id><created>2012-07-26</created><authors><author><keyname>Henriques</keyname><forenames>Rui</forenames></author><author><keyname>Lynce</keyname><forenames>In&#xea;s</forenames></author><author><keyname>Manquinho</keyname><forenames>Vasco</forenames></author></authors><title>On When and How to use SAT to Mine Frequent Itemsets</title><categories>cs.AI cs.DB cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new stream of research was born in the last decade with the goal of mining
itemsets of interest using Constraint Programming (CP). This has promoted a
natural way to combine complex constraints in a highly flexible manner.
Although CP state-of-the-art solutions formulate the task using Boolean
variables, the few attempts to adopt propositional Satisfiability (SAT)
provided an unsatisfactory performance. This work deepens the study on when and
how to use SAT for the frequent itemset mining (FIM) problem by defining
different encodings with multiple task-driven enumeration options and search
strategies. Although for the majority of the scenarios SAT-based solutions
appear to be non-competitive with CP peers, results show a variety of
interesting cases where SAT encodings are the best option.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6255</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6255</id><created>2012-07-26</created><authors><author><keyname>Bak&#x131;m</keyname><forenames>Sezi</forenames></author><author><keyname>Kaya</keyname><forenames>Onur</forenames></author></authors><title>Power Control for Two User Cooperative OFDMA Channels</title><categories>cs.IT math.IT</categories><comments>Revision submitted to IEEE Transactions on Wireless Communications,
  June 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a two user cooperative orthogonal frequency division multiple access
(OFDMA) system with full channel state information (CSI), we obtain the optimal
power allocation (PA) policies which maximize the rate region achievable by a
channel adaptive implementation of inter-subchannel block Markov superposition
encoding (BMSE), used in conjunction with backwards decoding. We provide the
optimality conditions that need to be satisfied by the powers associated with
the users' codewords and derive the closed form expressions for the optimal
powers. We propose two algorithms that can be used to optimize the powers to
achieve any desired rate pair on the rate region boundary: a projected
subgradient algorithm, and an iterative waterfilling-like algorithm based on
Karush-Kuhn-Tucker (KKT) conditions for optimality, which operates one user at
a time and converges much faster. We observe that, utilization of power control
to take advantage of the diversity offered by the cooperative OFDMA system, not
only leads to a remarkable improvement in achievable rates, but also may help
determine how the subchannels have to be instantaneously allocated to various
tasks in cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6260</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6260</id><created>2012-07-26</created><authors><author><keyname>Bogdanov</keyname><forenames>Andrej</forenames></author><author><keyname>Guo</keyname><forenames>Siyao</forenames></author></authors><title>Sparse extractor families for all the entropy</title><categories>cs.CC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of extracting entropy by sparse transformations,
namely functions with a small number of overall input-output dependencies. In
contrast to previous works, we seek extractors for essentially all the entropy
without any assumption on the underlying distribution beyond a min-entropy
requirement. We give two simple constructions of sparse extractor families,
which are collections of sparse functions such that for any distribution X on
inputs of sufficiently high min-entropy, the output of most functions from the
collection on a random input chosen from X is statistically close to uniform.
  For strong extractor families (i.e., functions in the family do not take
additional randomness) we give upper and lower bounds on the sparsity that are
tight up to a constant factor for a wide range of min-entropies. We then prove
that for some min-entropies weak extractor families can achieve better
sparsity.
  We show how this construction can be used towards more efficient parallel
transformation of (non-uniform) one-way functions into pseudorandom generators.
More generally, sparse extractor families can be used instead of pairwise
independence in various randomized or nonuniform settings where preserving
locality (i.e., parallelism) is of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6267</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6267</id><created>2012-07-26</created><updated>2012-10-16</updated><authors><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames><affiliation>INRIA Rennes - Bretagne Atlantique</affiliation></author><author><keyname>J&#xe9;ron</keyname><forenames>Thierry</forenames><affiliation>INRIA Rennes - Bretagne Atlantique</affiliation></author><author><keyname>Stainer</keyname><forenames>Am&#xe9;lie</forenames><affiliation>University of Rennes 1</affiliation></author><author><keyname>Krichen</keyname><forenames>Moez</forenames><affiliation>Institute of Computer Science and Multimedia, Sfax</affiliation></author></authors><title>Off-line test selection with test purposes for non-deterministic timed
  automata</title><categories>cs.FL</categories><comments>33 pages; Logical Methods in Computer Science 2002; 10.2168/LMCS-???</comments><proxy>LMCS</proxy><acm-class>D.2.4; D.2.5; D.4.7; F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 4 (October
  17, 2012) lmcs:1037</journal-ref><doi>10.2168/LMCS-8(4:8)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article proposes novel off-line test generation techniques from
non-deterministic timed automata with inputs and outputs (TAIOs) in the formal
framework of the tioco conformance theory. In this context, a fi?rst problem is
the determinization of TAIOs, which is necessary to foresee next enabled
actions after an observable trace, but is in general impossible because not all
timed automata are determinizable. This problem is solved thanks to an
approximate determinization using a game approach. The algorithm performs an
io-abstraction which preserves the tioco conformance relation and thus
guarantees the soundness of generated test cases. A second problem is the
selection of test cases from a TAIO speci?fication. The selection here relies
on a precise description of timed behaviors to be tested which is carried out
by expressive test purposes modeled by a generalization of TAIOs. Finally, an
algorithm is described which generates test cases in the form of TAIOs equipped
with verdicts, using a symbolic co-reachability analysis guided by the test
purpose. Properties of test cases are then analyzed with respect to the
precision of the approximate determinization: when determinization is exact,
which is the case on known determinizable classes, in addition to soundness,
properties characterizing the adequacy of test cases verdicts are also
guaranteed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6269</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6269</id><created>2012-07-26</created><authors><author><keyname>Prat-P&#xe9;rez</keyname><forenames>Arnau</forenames></author><author><keyname>Dominguez-Sal</keyname><forenames>David</forenames></author><author><keyname>Brunat</keyname><forenames>Josep M.</forenames></author><author><keyname>Larriba-Pey</keyname><forenames>Josep-Lluis</forenames></author></authors><title>Shaping Communities out of Triangles</title><categories>cs.SI physics.soc-ph</categories><comments>10 pages, 6 figures, CIKM 2012</comments><acm-class>H.3.3; H.3.4; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection has arisen as one of the most relevant topics in the
field of graph data mining due to its importance in many fields such as
biology, social networks or network traffic analysis. The metrics proposed to
shape communities are generic and follow two approaches: maximizing the
internal density of such communities or reducing the connectivity of the
internal vertices with those outside the community. However, these metrics take
the edges as a set and do not consider the internal layout of the edges in the
community. We define a set of properties oriented to social networks that
ensure that communities are cohesive, structured and well defined. Then, we
propose the Weighted Community Clustering (WCC), which is a community metric
based on triangles. We proof that analyzing communities by triangles gives
communities that fulfill the listed set of properties, in contrast to previous
metrics. Finally, we experimentally show that WCC correctly captures the
concept of community in social networks using real and syntethic datasets, and
compare statistically some of the most relevant community detection algorithms
in the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6282</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6282</id><created>2012-07-26</created><authors><author><keyname>D&#xfc;rr</keyname><forenames>Oliver</forenames></author><author><keyname>Brandenburg</keyname><forenames>Arnd</forenames></author></authors><title>Using Community Structure for Complex Network Layout</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new layout algorithm for complex networks that combines a
multi-scale approach for community detection with a standard force-directed
design. Since community detection is computationally cheap, we can exploit the
multi-scale approach to generate network configurations with close-to-minimal
energy very fast. As a further asset, we can use the knowledge of the community
structure to facilitate the interpretation of large networks, for example the
network defined by protein-protein interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6295</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6295</id><created>2012-07-26</created><updated>2014-05-11</updated><authors><author><keyname>Wang</keyname><forenames>Kai</forenames></author><author><keyname>Lin</keyname><forenames>Minghong</forenames></author><author><keyname>Ciucu</keyname><forenames>Florin</forenames></author><author><keyname>Wierman</keyname><forenames>Adam</forenames></author><author><keyname>Lin</keyname><forenames>Chuang</forenames></author></authors><title>Characterizing the Impact of the Workload on the Value of Dynamic
  Resizing in Data Centers</title><categories>cs.PF</categories><comments>24 pages, 27 fugures</comments><acm-class>C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy consumption imposes a significant cost for data centers; yet much of
that energy is used to maintain excess service capacity during periods of
predictably low load. Resultantly, there has recently been interest in
developing designs that allow the service capacity to be dynamically resized to
match the current workload. However, there is still much debate about the value
of such approaches in real settings. In this paper, we show that the value of
dynamic resizing is highly dependent on statistics of the workload process. In
particular, both slow time-scale non-stationarities of the workload (e.g., the
peak-to-mean ratio) and the fast time-scale stochasticity (e.g., the burstiness
of arrivals) play key roles. To illustrate the impact of these factors, we
combine optimization-based modeling of the slow time-scale with stochastic
modeling of the fast time scale. Within this framework, we provide both
analytic and numerical results characterizing when dynamic resizing does (and
does not) provide benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6307</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6307</id><created>2012-07-26</created><authors><author><keyname>Kanchu</keyname><forenames>Krishnama Raju</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>On Randomness of Goldbach Sequences</title><categories>cs.CR</categories><comments>10 pages, 5 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the use of Goldbach numbers as random sequences. The randomness
is analyzed in terms of the autocorrelation function of the sequence of number
of partitions. The distinct representations of an even number n as the sum of
two primes is a local maximum for multiples of the product of the consecutive
smallest primes less than the number. Specific partitions, which we call
Goldbach ellipses, are examined. It is shown that such ellipse sequences also
have excellent randomness property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6313</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6313</id><created>2012-07-26</created><authors><author><keyname>Rubio</keyname><forenames>Francisco</forenames></author><author><keyname>Mestre</keyname><forenames>Xavier</forenames></author><author><keyname>Hachem</keyname><forenames>Walid</forenames></author></authors><title>A CLT on the SNR of Diagonally Loaded MVDR Filters</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>This is a corrected version of the paper that will appear at IEEE
  Transactions on Signal Processing September 2012</comments><msc-class>94A12</msc-class><doi>10.1109/TSP.2012.2197396</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the fluctuations of the signal-to-noise ratio (SNR) of
minimum variance distorsionless response (MVDR) filters implementing diagonal
loading in the estimation of the covariance matrix. Previous results in the
signal processing literature are generalized and extended by considering both
spatially as well as temporarily correlated samples. Specifically, a central
limit theorem (CLT) is established for the fluctuations of the SNR of the
diagonally loaded MVDR filter, under both supervised and unsupervised training
settings in adaptive filtering applications. Our second-order analysis is based
on the Nash-Poincar\'e inequality and the integration by parts formula for
Gaussian functionals, as well as classical tools from statistical asymptotic
theory. Numerical evaluations validating the accuracy of the CLT confirm the
asymptotic Gaussianity of the fluctuations of the SNR of the MVDR filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6318</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6318</id><created>2012-07-26</created><authors><author><keyname>Sinha</keyname><forenames>Abhishek</forenames></author><author><keyname>Chattopadhyay</keyname><forenames>Arpan</forenames></author><author><keyname>Naveen</keyname><forenames>K. P.</forenames></author><author><keyname>Coupechoux</keyname><forenames>Marceau</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Optimal Sequential Wireless Relay Placement on a Random Lattice Path</title><categories>cs.NI</categories><comments>12 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work is motivated by the need for impromptu (or &quot;as-you-go&quot;) deployment
of relay nodes (for establishing a packet communication path with a control
centre) by fire-men/commandos while operating in an unknown environment. We
consider a model, where a deployment operative steps along a random lattice
path whose evolution is Markov. At each step, the path can randomly either
continue in the same direction or take a turn &quot;North&quot; or &quot;East,&quot; or come to an
end, at which point a data source (e.g., a temperature sensor) has to be placed
that will send packets to a control centre at the origin of the path. A
decision has to be made at each step whether or not to place a wireless relay
node. Assuming that the packet generation rate by the source is very low, and
simple link-by-link scheduling, we consider the problem of relay placement so
as to minimize the expectation of an end-to-end cost metric (a linear
combination of the sum of convex hop costs and the number of relays placed).
This impromptu relay placement problem is formulated as a total cost Markov
decision process. First, we derive the optimal policy in terms of an optimal
placement set and show that this set is characterized by a boundary beyond
which it is optimal to place. Next, based on a simpler alternative
one-step-look-ahead characterization of the optimal policy, we propose an
algorithm which is proved to converge to the optimal placement set in a finite
number of steps and which is faster than the traditional value iteration. We
show by simulations that the distance based heuristic, usually assumed in the
literature, is close to the optimal provided that the threshold distance is
carefully chosen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6324</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6324</id><created>2012-07-26</created><authors><author><keyname>Blockeel</keyname><forenames>Hendrik</forenames></author><author><keyname>Kersting</keyname><forenames>Kristian</forenames></author><author><keyname>Nijssen</keyname><forenames>Siegfried</forenames></author><author><keyname>Zelezny</keyname><forenames>Filip</forenames></author></authors><title>A Revised Publication Model for ECML PKDD</title><categories>cs.DL</categories><comments>13 pages</comments><acm-class>A.0; I.2; H.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ECML PKDD is the main European conference on machine learning and data
mining. Since its foundation it implemented the publication model common in
computer science: there was one conference deadline; conference submissions
were reviewed by a program committee; papers were accepted with a low
acceptance rate. Proceedings were published in several Springer Lecture Notes
in Artificial (LNAI) volumes, while selected papers were invited to special
issues of the Machine Learning and Data Mining and Knowledge Discovery
journals. In recent years, this model has however come under stress. Problems
include: reviews are of highly variable quality; the purpose of bringing the
community together is lost; reviewing workloads are high; the information
content of conferences and journals decreases; there is confusion among
scientists in interdisciplinary contexts. In this paper, we present a new
publication model, which will be adopted for the ECML PKDD 2013 conference, and
aims to solve some of the problems of the traditional model. The key feature of
this model is the creation of a journal track, which is open to submissions all
year long and allows for revision cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6328</identifier>
 <datestamp>2014-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6328</id><created>2012-07-26</created><updated>2013-01-10</updated><authors><author><keyname>Amodio</keyname><forenames>Pierluigi</forenames></author><author><keyname>Brugnano</keyname><forenames>Luigi</forenames></author></authors><title>Recent advances in bibliometric indexes and the PaperRank problem</title><categories>cs.DL math.NA</categories><msc-class>65F15</msc-class><journal-ref>Journal of Computational and Applied Mathematics 267 (2014), pp.
  182-194</journal-ref><doi>10.1016/j.cam.2014.02.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bibliometric indexes are customary used in evaluating the impact of
scientific research, even though it is very well known that in different
research areas they may range in very different intervals. Sometimes, this is
evident even within a single given field of investigation making very difficult
(and inaccurate) the assessment of scientific papers. On the other hand, the
problem can be recast in the same framework which has allowed to efficiently
cope with the ordering of web-pages, i.e., to formulate the PageRank of Google.
For this reason, we call such problem the PaperRank problem, here solved by
using a similar approach to that employed by PageRank. The obtained solution,
which is mathematically grounded, will be used to compare the usual heuristics
of the number of citations with a new one here proposed. Some numerical tests
show that the new heuristics is much more reliable than the currently used
ones, based on the bare number of citations. Moreover, we show that our model
improves on recently proposed ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6329</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6329</id><created>2012-07-26</created><authors><author><keyname>Chester</keyname><forenames>Sean</forenames></author><author><keyname>Thomo</keyname><forenames>Alex</forenames></author><author><keyname>Venkatesh</keyname><forenames>S.</forenames></author><author><keyname>Whitesides</keyname><forenames>Sue</forenames></author></authors><title>Computing optimal k-regret minimizing sets with top-k depth contours</title><categories>cs.DB cs.CG</categories><comments>10 pages, 9 figures</comments><acm-class>H.3.3; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regret minimizing sets are a very recent approach to representing a dataset D
with a small subset S of representative tuples. The set S is chosen such that
executing any top-1 query on S rather than D is minimally perceptible to any
user. To discover an optimal regret minimizing set of a predetermined
cardinality is conjectured to be a hard problem. In this paper, we generalize
the problem to that of finding an optimal k$regret minimizing set, wherein the
difference is computed over top-k queries, rather than top-1 queries.
  We adapt known geometric ideas of top-k depth contours and the reverse top-k
problem. We show that the depth contours themselves offer a means of comparing
the optimality of regret minimizing sets using L2 distance. We design an
O(cn^2) plane sweep algorithm for two dimensions to compute an optimal regret
minimizing set of cardinality c. For higher dimensions, we introduce a greedy
algorithm that progresses towards increasingly optimal solutions by exploiting
the transitivity of L2 distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6331</identifier>
 <datestamp>2014-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6331</id><created>2012-07-26</created><updated>2014-02-17</updated><authors><author><keyname>Franek</keyname><forenames>Peter</forenames></author><author><keyname>Ratschan</keyname><forenames>Stefan</forenames></author></authors><title>Effective Topological Degree Computation Based on Interval Arithmetic</title><categories>cs.CG math.AT</categories><msc-class>55-04, 57R19, 68-04</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new algorithm for calculating the topological degree deg (f, B,
0) where B \subseteq Rn is a product of closed real intervals and f : B
\rightarrow Rn is a real-valued continuous function given in the form of
arithmetical expressions. The algorithm cleanly separates numerical from
combinatorial computation. Based on this, the numerical part provably computes
only the information that is strictly necessary for the following combinatorial
part, and the combinatorial part may optimize its computation based on the
numerical information computed before. We also present computational
experiments based on an implementation of the algorithm. Also, in contrast to
previous work, the algorithm does not assume knowledge of a Lipschitz constant
of the function f, and works for arbitrary continuous functions for which some
notion of interval arithmetic can be defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6353</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6353</id><created>2012-07-26</created><updated>2013-01-11</updated><authors><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>PETRELS: Parallel Subspace Estimation and Tracking by Recursive Least
  Squares from Partial Observations</title><categories>stat.ME cs.IT math.IT</categories><comments>submitted to IEEE Trans. Signal Processing. Part of the result was
  reported at ICASSP 2012 and won the best student paper award</comments><doi>10.1109/TSP.2013.2282910</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real world data sets exhibit an embedding of low-dimensional structure
in a high-dimensional manifold. Examples include images, videos and internet
traffic data. It is of great significance to reduce the storage requirements
and computational complexity when the data dimension is high. Therefore we
consider the problem of reconstructing a data stream from a small subset of its
entries, where the data is assumed to lie in a low-dimensional linear subspace,
possibly corrupted by noise. We further consider tracking the change of the
underlying subspace, which can be applied to applications such as video
denoising, network monitoring and anomaly detection. Our problem can be viewed
as a sequential low-rank matrix completion problem in which the subspace is
learned in an on-line fashion. The proposed algorithm, dubbed Parallel
Estimation and Tracking by REcursive Least Squares (PETRELS), first identifies
the underlying low-dimensional subspace via a recursive procedure for each row
of the subspace matrix in parallel with discounting for previous observations,
and then reconstructs the missing entries via least-squares estimation if
required. Numerical examples are provided for direction-of-arrival estimation
and matrix completion, comparing PETRELS with state of the art batch
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6355</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6355</id><created>2012-07-26</created><authors><author><keyname>Jog</keyname><forenames>Varun</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author></authors><title>The Entropy Power Inequality and Mrs. Gerber's Lemma for Abelian Groups
  of Order 2^n</title><categories>cs.IT math.CO math.GR math.IT math.PR</categories><comments>37 pages, 5 figures. Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shannon's Entropy Power Inequality can be viewed as characterizing the
minimum differential entropy achievable by the sum of two independent random
variables with fixed differential entropies. The entropy power inequality has
played a key role in resolving a number of problems in information theory. It
is therefore interesting to examine the existence of a similar inequality for
discrete random variables. In this paper we obtain an entropy power inequality
for random variables taking values in an abelian group of order 2^n, i.e. for
such a group G we explicitly characterize the function f_G(x,y) giving the
minimum entropy of the sum of two independent G-valued random variables with
respective entropies x and y. Random variables achieving the extremum in this
inequality are thus the analogs of Gaussians in this case, and these are also
determined. It turns out that f_G(x,y) is convex in x for fixed y and, by
symmetry, convex in y for fixed x. This is a generalization to abelian groups
of order 2^n of the result known as Mrs. Gerber's Lemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6365</identifier>
 <datestamp>2013-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6365</id><created>2012-07-26</created><updated>2013-04-05</updated><authors><author><keyname>Clarkson</keyname><forenames>Kenneth L.</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>Low Rank Approximation and Regression in Input Sparsity Time</title><categories>cs.DS</categories><comments>Included optimization of subspace embedding dimension from (d/eps)^4
  to O~(d/eps)^2 in Section 4, by more careful analysis of perfect hashing, and
  minor improvements to regression / low rank approximation because of it</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a new distribution over $\poly(r \eps^{-1}) \times n$ matrices $S$
so that for any fixed $n \times d$ matrix $A$ of rank $r$, with probability at
least 9/10, $\norm{SAx}_2 = (1 \pm \eps)\norm{Ax}_2$ simultaneously for all $x
\in \mathbb{R}^d$. Such a matrix $S$ is called a \emph{subspace embedding}.
Furthermore, $SA$ can be computed in $\nnz(A) + \poly(d \eps^{-1})$ time, where
$\nnz(A)$ is the number of non-zero entries of $A$. This improves over all
previous subspace embeddings, which required at least $\Omega(nd \log d)$ time
to achieve this property. We call our matrices $S$ \emph{sparse embedding
matrices}.
  Using our sparse embedding matrices, we obtain the fastest known algorithms
for $(1+\eps)$-approximation for overconstrained least-squares regression,
low-rank approximation, approximating all leverage scores, and
$\ell_p$-regression. The leading order term in the time complexity of our
algorithms is $O(\nnz(A))$ or $O(\nnz(A)\log n)$.
  We optimize the low-order $\poly(d/\eps)$ terms in our running times (or for
rank-$k$ approximation, the $n*\poly(k/eps)$ term), and show various tradeoffs.
For instance, we also use our methods to design new preconditioners that
improve the dependence on $\eps$ in least squares regression to $\log 1/\eps$.
Finally, we provide preliminary experimental results which suggest that our
algorithms are competitive in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6368</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6368</id><created>2012-07-26</created><authors><author><keyname>Lawlor</keyname><forenames>David</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Christlieb</keyname><forenames>Andrew</forenames></author></authors><title>Adaptive sub-linear Fourier algorithms</title><categories>math.NA cs.DS</categories><comments>24 pages, 3 figures</comments><msc-class>65T50, 68W25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new deterministic algorithm for the sparse Fourier transform
problem, in which we seek to identify k &lt;&lt; N significant Fourier coefficients
from a signal of bandwidth N. Previous deterministic algorithms exhibit
quadratic runtime scaling, while our algorithm scales linearly with k in the
average case. Underlying our algorithm are a few simple observations relating
the Fourier coefficients of time-shifted samples to unshifted samples of the
input function. This allows us to detect when aliasing between two or more
frequencies has occurred, as well as to determine the value of unaliased
frequencies. We show that empirically our algorithm is orders of magnitude
faster than competing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6369</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6369</id><created>2012-07-26</created><authors><author><keyname>Gregorics</keyname><forenames>T.</forenames></author></authors><title>Concept of the abstract program</title><categories>cs.PL</categories><msc-class>68N30</msc-class><acm-class>F.3.1</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 4, 1 (2012) 7-16</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to alter the abstract definition of the program of
the theoretical programming model which has been developed at Eotvos Lorand
University for many years in order to investigate methods that support
designing correct programs. The motivation of this modi?cation was that the
dynamic properties of programs appear in the model. This new definition of the
program gives a hand to extend the model with the concept of subprograms while
the earlier results of the original programming model are preserved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6371</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6371</id><created>2012-07-26</created><authors><author><keyname>Khan</keyname><forenames>Arindam</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author><author><keyname>V&#xe9;gh</keyname><forenames>L&#xe1;szl&#xf3; A.</forenames></author></authors><title>On Mimicking Networks Representing Minimum Terminal Cuts</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a capacitated undirected graph $G=(V,E)$ with a set of terminals $K
\subset V$, a mimicking network is a smaller graph $H=(V_H,E_H)$ that exactly
preserves all the minimum cuts between the terminals. Specifically, the vertex
set of the sparsifier $V_H$ contains the set of terminals $K$ and for every
bipartition $U, K-U $ of the terminals $K$, the size of the minimum cut
separating $U$ from $K-U$ in $G$ is exactly equal to the size of the minimum
cut separating $U$ from $K-U$ in $H$.
  This notion of a mimicking network was introduced by Hagerup, Katajainen,
Nishimura and Ragde (1995) who also exhibited a mimicking network of size
$2^{2^{k}}$ for every graph with $k$ terminals. The best known lower bound on
the size of a mimicking network is linear in the number of terminals. More
precisely, the best known lower bound is $k+1$ for graphs with $k$ terminals
(Chaudhuri et al. 2000).
  In this work, we improve both the upper and lower bounds reducing the
doubly-exponential gap between them to a single-exponential gap. Specifically,
we obtain the following upper and lower bounds on mimicking networks: 1) Given
a graph $G$, we exhibit a construction of mimicking network with at most
$(|K|-1)$'th Dedekind number ($\approx 2^{{(k-1)} \choose {\lfloor {{(k-1)}/2}
\rfloor}}$) of vertices (independent of size of $V$). Furthermore, we show that
the construction is optimal among all {\it restricted mimicking networks} -- a
natural class of mimicking networks that are obtained by clustering vertices
together. 2) There exists graphs with $k$ terminals that have no mimicking
network of size smaller than $2^{\frac{k-1}{2}}$.
  We also exhibit improved constructions of mimicking networks for trees and
graphs of bounded tree-width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6372</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6372</id><created>2012-07-26</created><authors><author><keyname>L&#xe1;szl&#xf3;</keyname><forenames>Lajos</forenames></author></authors><title>Sum of squares representation for the B\&quot;ottcher-Wenzel biquadratic form</title><categories>cs.DM math.CO</categories><msc-class>90C22, 15A45, 65F15</msc-class><acm-class>G.2.2</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 4, 1 (2012) 17-32</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We find the minimum scale factor, for which the nonnegative B\&quot;ottcher-Wenzel
biquadratic form becomes a sum of squares (sos). To this we give the primal and
dual solutions for the underlying semide ?nite program. Moreover, for special
matrix classes (tridiagonal, backward tridiagonal and cyclic Hankel matrices)
we show that the above form is sos. Finally, we conjecture sos representability
for Toeplitz matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6374</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6374</id><created>2012-07-26</created><authors><author><keyname>Sargsyan</keyname><forenames>V.</forenames></author></authors><title>Counting (k,l)-sumsets in groups of prime order</title><categories>cs.DM math.NT</categories><msc-class>68R05</msc-class><acm-class>G.2.1</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 4, 1 (2012) 33-47</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset $A$ of a group $G$ is called $(k, l)$-{\it sumset}, if $A= kB-lB$
for some $B\subseteq G$, where $kB-lB={x_1+...+x_k-x_{k+1}-...-x_{k+l} :
x_1,..., x_{k+l}\in B}.$ Upper and lower bounds for the number $(k, l)$-sumsets
in groups of prime order are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6379</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6379</id><created>2012-07-26</created><authors><author><keyname>Bento</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Ioannidis</keyname><forenames>Stratis</forenames></author></authors><title>Identifying Users From Their Rating Patterns</title><categories>cs.IR cs.LG stat.ML</categories><comments>Winner of the 2011 Challenge on Context-Aware Movie Recommendation
  (RecSys 2011 - CAMRa2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports on our analysis of the 2011 CAMRa Challenge dataset (Track
2) for context-aware movie recommendation systems. The train dataset comprises
4,536,891 ratings provided by 171,670 users on 23,974$ movies, as well as the
household groupings of a subset of the users. The test dataset comprises 5,450
ratings for which the user label is missing, but the household label is
provided. The challenge required to identify the user labels for the ratings in
the test set. Our main finding is that temporal information (time labels of the
ratings) is significantly more useful for achieving this objective than the
user preferences (the actual ratings). Using a model that leverages on this
fact, we are able to identify users within a known household with an accuracy
of approximately 96% (i.e. misclassification rate around 4%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6380</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6380</id><created>2012-07-26</created><authors><author><keyname>Edemskiy</keyname><forenames>Vladimir</forenames></author></authors><title>About the Linear Complexity of Ding-Hellesth Generalized Cyclotomic
  Binary Sequences of Any Period</title><categories>cs.IT cs.CR math.IT</categories><msc-class>11B50, 94A55, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We defined sufficient conditions for designing Ding-Helleseth sequences with
arbitrary period and high linear complexity for generalized cyclotomies. Also
we discuss the method of computing the linear complexity of Ding-Helleseth
sequences in the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6381</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6381</id><created>2012-07-26</created><authors><author><keyname>Kir&#xe1;ly</keyname><forenames>Z.</forenames></author><author><keyname>Kov&#xe1;cs</keyname><forenames>P.</forenames></author></authors><title>Efficient implementations of minimum-cost flow algorithms</title><categories>cs.DM cs.DS</categories><msc-class>05C21</msc-class><acm-class>G.2.2</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 4, 1 (2012) 67-118</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents efficient implementations of several algorithms for
solving the minimum-cost network flow problem. Various practical heuristics and
other important implementation aspects are also discussed. A novel result of
this work is the application of Goldberg's recent partial augment-relabel
method in the cost-scaling algorithm. The presented implementations are
available as part of the LEMON open source C++ optimization library
(\url{http://lemon.cs.elte.hu/}). The performance of these codes is compared to
well-known and efficient minimum-cost flow solvers, namely CS2, RelaxIV, MCF,
and the corresponding method of the LEDA library. According to thorough
experimental analysis, the presented cost-scaling and network simplex
implementations turned out to be more efficient than LEDA and MCF. Furthermore,
the cost-scaling implementation is competitive with CS2. The RelaxIV algorithm
is often much slower than the other codes, although it is quite efficient on
particular problem instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6383</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6383</id><created>2012-07-26</created><authors><author><keyname>Burcsi</keyname><forenames>P.</forenames></author></authors><title>Analysis of the picture cube puzzle</title><categories>cs.DM math.CO</categories><msc-class>05C25, 05C12</msc-class><acm-class>G.2.0</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 4, 1 (2012) 119-129</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give a mathematical model for a game that we call picture
cube puzzle and investigate its properties. The central question is the number
of moves required to solve the puzzle. A mathematical discussion is followed by
the description of computational results. We also give a generalization of the
problem for finite groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6384</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6384</id><created>2012-07-26</created><authors><author><keyname>Iv&#xe1;nyi</keyname><forenames>A.</forenames></author><author><keyname>Schoenfield</keyname><forenames>J. E.</forenames></author></authors><title>Deciding football sequences</title><categories>cs.DM</categories><msc-class>05C85, 68R10</msc-class><acm-class>G.2.2</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 4, 1 (2012) 130-183</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An open problem posed by the first author is the complexity to decide whether
a sequence of nonnegative integer numbers can be the final score of a football
tournament. In this paper we propose polynomial time approximate and
exponential time exact algorithms which solve the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6409</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6409</id><created>2012-07-26</created><updated>2015-06-23</updated><authors><author><keyname>Chen</keyname><forenames>Danny Z.</forenames></author><author><keyname>Gu</keyname><forenames>Yan</forenames></author><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Wang</keyname><forenames>Haitao</forenames></author></authors><title>Algorithms on Minimizing the Maximum Sensor Movement for Barrier
  Coverage of a Linear Domain</title><categories>cs.CG cs.DS</categories><comments>This version corrected an error in the proof of Lemma 2 in the
  previous version and the version published in DCG 2013. Lemma 2 is for
  proving the correctness of an algorithm (see the footnote of Page 9 for why
  the previous proof is incorrect). Everything else of the paper does not
  change. All algorithms in the paper are exactly the same as before and their
  time complexities do not change either</comments><journal-ref>Discrete &amp; Computational Geometry, Vol. 50(2), pages 374-408, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of moving $n$ sensors on a line to form a
barrier coverage of a specified segment of the line such that the maximum
moving distance of the sensors is minimized. Previously, it was an open
question whether this problem on sensors with arbitrary sensing ranges is
solvable in polynomial time. We settle this open question positively by giving
an $O(n^2 \log n)$ time algorithm. For the special case when all sensors have
the same-size sensing range, the previously best solution takes $O(n^2)$ time.
We present an $O(n \log n)$ time algorithm for this case; further, if all
sensors are initially located on the coverage segment, our algorithm takes
$O(n)$ time. Also, we extend our techniques to the cycle version of the problem
where the barrier coverage is for a simple cycle and the sensors are allowed to
move only along the cycle. For sensors with the same-size sensing range, we
solve the cycle version in $O(n)$ time, improving the previously best $O(n^2)$
time solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6416</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6416</id><created>2012-07-26</created><updated>2013-01-19</updated><authors><author><keyname>Bardoscia</keyname><forenames>Marco</forenames></author><author><keyname>De Luca</keyname><forenames>Giancarlo</forenames></author><author><keyname>Livan</keyname><forenames>Giacomo</forenames></author><author><keyname>Marsili</keyname><forenames>Matteo</forenames></author><author><keyname>Tessone</keyname><forenames>Claudio J.</forenames></author></authors><title>The Social Climbing Game</title><categories>physics.soc-ph cs.SI</categories><comments>14 pages, 9 figures</comments><journal-ref>Journal of Statistical Physics 151 (2013), pp. 440-457</journal-ref><doi>10.1007/s10955-013-0693-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The structure of a society depends, to some extent, on the incentives of the
individuals they are composed of. We study a stylized model of this interplay,
that suggests that the more individuals aim at climbing the social hierarchy,
the more society's hierarchy gets strong. Such a dependence is sharp, in the
sense that a persistent hierarchical order emerges abruptly when the preference
for social status gets larger than a threshold. This phase transition has its
origin in the fact that the presence of a well defined hierarchy allows agents
to climb it, thus reinforcing it, whereas in a &quot;disordered&quot; society it is
harder for agents to find out whom they should connect to in order to become
more central. Interestingly, a social order emerges when agents strive harder
to climb society and it results in a state of reduced social mobility, as a
consequence of ergodicity breaking, where climbing is more difficult.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6430</identifier>
 <datestamp>2014-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6430</id><created>2012-07-26</created><updated>2014-06-04</updated><authors><author><keyname>Osting</keyname><forenames>Braxton</forenames></author><author><keyname>Brune</keyname><forenames>Christoph</forenames></author><author><keyname>Osher</keyname><forenames>Stanley J.</forenames></author></authors><title>Optimal Data Collection For Informative Rankings Expose Well-Connected
  Graphs</title><categories>stat.ML cs.LG stat.AP</categories><comments>31 pages, 10 figures, 3 tables</comments><report-no>UCLA CAM report 12-32</report-no><msc-class>62F07, 05C40, 49N45,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph where vertices represent alternatives and arcs represent
pairwise comparison data, the statistical ranking problem is to find a
potential function, defined on the vertices, such that the gradient of the
potential function agrees with the pairwise comparisons. Our goal in this paper
is to develop a method for collecting data for which the least squares
estimator for the ranking problem has maximal Fisher information. Our approach,
based on experimental design, is to view data collection as a bi-level
optimization problem where the inner problem is the ranking problem and the
outer problem is to identify data which maximizes the informativeness of the
ranking. Under certain assumptions, the data collection problem decouples,
reducing to a problem of finding multigraphs with large algebraic connectivity.
This reduction of the data collection problem to graph-theoretic questions is
one of the primary contributions of this work. As an application, we study the
Yahoo! Movie user rating dataset and demonstrate that the addition of a small
number of well-chosen pairwise comparisons can significantly increase the
Fisher informativeness of the ranking. As another application, we study the
2011-12 NCAA football schedule and propose schedules with the same number of
games which are significantly more informative. Using spectral clustering
methods to identify highly-connected communities within the division, we argue
that the NCAA could improve its notoriously poor rankings by simply scheduling
more out-of-conference games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6435</identifier>
 <datestamp>2013-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6435</id><created>2012-07-26</created><updated>2013-02-15</updated><authors><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Shapiro</keyname><forenames>Jeffrey H.</forenames></author></authors><title>Capacity of optical reading, Part 1: Reading boundless error-free bits
  using a single photon</title><categories>quant-ph cs.IT math.IT</categories><comments>11 pages, 12 figures, v3 includes a new plot characterizing the
  photon efficiency vs. encoding efficiency tradeoff for optical reading. The
  main technical body of the paper remains unaltered</comments><journal-ref>Phys. Rev. A 87, 062306 (2013)</journal-ref><doi>10.1103/PhysRevA.87.062306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that nature imposes no fundamental upper limit to the number of
information bits per expended photon that can, in principle, be read reliably
when classical data is encoded in a medium that can only passively modulate the
amplitude and phase of the probe light. We show that with a coherent-state
(laser) source, an on-off (amplitude-modulation) pixel encoding, and
shot-noise-limited direct detection (an overly-optimistic model for commercial
CD/DVD drives), the highest photon information efficiency achievable in
principle is about 0.5 bit per transmitted photon. We then show that a
coherent-state probe can read unlimited bits per photon when the receiver is
allowed to make joint (inseparable) measurements on the reflected light from a
large block of phase-modulated memory pixels. Finally, we show an example of a
spatially-entangled non-classical light probe and a receiver
design---constructable using a single-photon source, beam splitters, and
single-photon detectors---that can in principle read any number of error-free
bits of information. The probe is a single photon prepared in a uniform
coherent superposition of multiple orthogonal spatial modes, i.e., a W-state.
The code, target, and joint-detection receiver complexity required by a
coherent-state transmitter to achieve comparable photon efficiency performance
is shown to be much higher in comparison to that required by the W-state
transceiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6437</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6437</id><created>2012-07-26</created><updated>2015-01-23</updated><authors><author><keyname>Bubenik</keyname><forenames>Peter</forenames></author></authors><title>Statistical topological data analysis using persistence landscapes</title><categories>math.AT cs.CG math.MG math.ST stat.TH</categories><comments>26 pages, final version, to appear in Journal of Machine Learning
  Research, includes two additional examples not in the journal version: random
  geometric complexes and Erdos-Renyi random clique complexes</comments><msc-class>55N99, 68W30, 62G99, 54E35</msc-class><journal-ref>Journal of Machine Learning Research, 16 (2015), 77-102</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a new topological summary for data that we call the persistence
landscape. Since this summary lies in a vector space, it is easy to combine
with tools from statistics and machine learning, in contrast to the standard
topological summaries. Viewed as a random variable with values in a Banach
space, this summary obeys a strong law of large numbers and a central limit
theorem. We show how a number of standard statistical tests can be used for
statistical inference using this summary. We also prove that this summary is
stable and that it can be used to provide lower bounds for the bottleneck and
Wasserstein distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6438</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6438</id><created>2012-07-26</created><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Product Superposition for MIMO Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>14 pages, 7 figures, accepted by IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the multiantenna broadcast channel without transmit-side
channel state information (CSIT). For this channel, it has been known that when
all receivers have channel state information (CSIR), the degrees of freedom
(DoF) cannot be improved beyond what is available via TDMA. The same is true if
none of the receivers possess CSIR. This paper shows that an entirely new
scenario emerges when receivers have unequal CSIR. In particular, orthogonal
transmission is no longer DoF-optimal when one receiver has CSIR and the other
does not. A multiplicative superposition is proposed for this scenario and
shown to attain the optimal degrees of freedom under a wide set of antenna
configurations and coherence lengths. Two signaling schemes are constructed
based on the multiplicative superposition. In the first method, the messages of
the two receivers are carried in the row and column spaces of a matrix,
respectively. This method works better than orthogonal transmission while
reception at each receiver is still interference free. The second method uses
coherent signaling for the receiver with CSIR, and Grassmannian signaling for
the receiver without CSIR. This second method requires interference
cancellation at the receiver with CSIR, but achieves higher DoF than the first
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6445</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6445</id><created>2012-07-27</created><authors><author><keyname>Sheng</keyname><forenames>Shang-Pin</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Profit Incentive In A Secondary Spectrum Market: A Contract Design
  Approach</title><categories>cs.CE cs.GT</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we formulate a contract design problem where a primary license
holder wishes to profit from its excess spectrum capacity by selling it to
potential secondary users/buyers. It needs to determine how to optimally price
the excess spectrum so as to maximize its profit, knowing that this excess
capacity is stochastic in nature, does not come with exclusive access, and
cannot provide deterministic service guarantees to a buyer. At the same time,
buyers are of different {\em types}, characterized by different communication
needs, tolerance for the channel uncertainty, and so on, all of which a buyer's
private information. The license holder must then try to design different
contracts catered to different types of buyers in order to maximize its profit.
We address this problem by adopting as a reference a traditional spectrum
market where the buyer can purchase exclusive access with fixed/deterministic
guarantees. We fully characterize the optimal solution in the cases where there
is a single buyer type, and when multiple types of buyers share the same, known
channel condition as a result of the primary user activity. In the most general
case we construct an algorithm that generates a set of contracts in a
computationally efficient manner, and show that this set is optimal when the
buyer types satisfy a monotonicity condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6448</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6448</id><created>2012-07-27</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Chandarana</keyname><forenames>Dhaval</forenames></author><author><keyname>Dave</keyname><forenames>Rutvi</forenames></author><author><keyname>Page</keyname><forenames>Sharyu</forenames></author><author><keyname>Gupta</keyname><forenames>Shikha</forenames></author></authors><title>Query Optimization Over Web Services Using A Mixed Approach</title><categories>cs.DB cs.IR</categories><comments>10 pages, 1 figure</comments><journal-ref>Advances in Computing &amp; Inf. Technology, AISC 178, pp.381-389,
  2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Web Service Management System (WSMS) can be well-thought-out as a
consistent and a secure way of managing the web services. Web Service has
become a quintessential part of the web world, managing and sharing the
resources of the business it is associated with. In this paper, we focus on the
query optimization aspect of handling the &quot;natural language&quot; query, queried to
the WSMS. The map-select-composite operations are piloted to select specific
web services. The main aftermath of our research is ensued in an algorithm
which uses cost-based as well as heuristic based approach for query
optimization. Query plan is formed after cost-based evaluation and using Greedy
algorithm. The heuristic based approach further optimizes the evaluation plan.
This scheme not only guarantees an optimal solution, which has a minimum
diversion from the ideal solution, but also saves time which is otherwise
utilized in generating various query plans using many mathematical models and
then evaluating each one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6452</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6452</id><created>2012-07-27</created><authors><author><keyname>Mamakani</keyname><forenames>Khalegh</forenames></author><author><keyname>Ruskey</keyname><forenames>Frank</forenames></author></authors><title>A New Rose : The First Simple Symmetric 11-Venn Diagram</title><categories>cs.CG math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A symmetric Venn diagram is one that is invariant under rotation, up to a
relabeling of curves. A simple Venn diagram is one in which at most two curves
intersect at any point. In this paper we introduce a new property of Venn
diagrams called crosscut symmetry, which is related to dihedral symmetry.
Utilizing a computer search restricted to crosscut symmetry we found many
simple symmetric Venn diagrams with 11 curves. This answers an existence
question that has been open since the 1960's. The first such diagram that was
discovered is shown here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6465</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6465</id><created>2012-07-27</created><authors><author><keyname>Anceaume</keyname><forenames>Emmanuelle</forenames><affiliation>IRISA</affiliation></author><author><keyname>Busnel</keyname><forenames>Yann</forenames><affiliation>LINA</affiliation></author></authors><title>Sketch \star-metric: Comparing Data Streams via Sketching</title><categories>cs.DS cs.DM cs.IT math.IT</categories><comments>12 pages, double colonnes</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of estimating the distance between any
two large data streams in small- space constraint. This problem is of utmost
importance in data intensive monitoring applications where input streams are
generated rapidly. These streams need to be processed on the fly and accurately
to quickly determine any deviance from nominal behavior. We present a new
metric, the Sketch \star-metric, which allows to define a distance between
updatable summaries (or sketches) of large data streams. An important feature
of the Sketch \star-metric is that, given a measure on the entire initial data
streams, the Sketch \star-metric preserves the axioms of the latter measure on
the sketch (such as the non-negativity, the identity, the symmetry, the
triangle inequality but also specific properties of the f-divergence).
Extensive experiments conducted on both synthetic traces and real data allow us
to validate the robustness and accuracy of the Sketch \star-metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6474</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6474</id><created>2012-07-27</created><authors><author><keyname>Edelsbrunner</keyname><forenames>Herbert</forenames></author><author><keyname>Heisenberg</keyname><forenames>Carl-Philipp</forenames></author><author><keyname>Kerber</keyname><forenames>Michael</forenames></author><author><keyname>Krens</keyname><forenames>Gabriel</forenames></author></authors><title>The Medusa of Spatial Sorting: Topological Construction</title><categories>cs.CG math.AT q-bio.CB q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the simultaneous movement of finitely many colored points in
space, calling it a spatial sorting process. The name suggests a purpose that
drives the collection to a configuration of increased or decreased order.
Mapping such a process to a subset of space-time, we use persistent homology
measurements of the time function to characterize the process topologically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6475</identifier>
 <datestamp>2012-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6475</id><created>2012-07-27</created><updated>2012-12-09</updated><authors><author><keyname>Coviello</keyname><forenames>Lorenzo</forenames></author><author><keyname>Franceschetti</keyname><forenames>Massimo</forenames></author></authors><title>Distributed team formation in multi-agent systems: stability and
  approximation</title><categories>cs.MA cs.SI</categories><comments>30 pages, 11 figures, 2 tables, a short version will appear in IEEE
  CDC 2012</comments><msc-class>91D30</msc-class><acm-class>I.2.11; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a scenario in which leaders are required to recruit teams of
followers. Each leader cannot recruit all followers, but interaction is
constrained according to a bipartite network. The objective for each leader is
to reach a state of local stability in which it controls a team whose size is
equal to a given constraint. We focus on distributed strategies, in which
agents have only local information of the network topology and propose a
distributed algorithm in which leaders and followers act according to simple
local rules. The performance of the algorithm is analyzed with respect to the
convergence to a stable solution.
  Our results are as follows. For any network, the proposed algorithm is shown
to converge to an approximate stable solution in polynomial time, namely the
leaders quickly form teams in which the total number of additional followers
required to satisfy all team size constraints is an arbitrarily small fraction
of the entire population. In contrast, for general graphs there can be an
exponential time gap between convergence to an approximate solution and to a
stable solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6509</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6509</id><created>2012-07-27</created><updated>2012-12-15</updated><authors><author><keyname>Zheng</keyname><forenames>Guanbo</forenames></author><author><keyname>Hua</keyname><forenames>Cunqing</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author><author><keyname>Wang</keyname><forenames>Qixin</forenames></author></authors><title>A Robust Relay Placement Framework for 60GHz mmWave Wireless Personal
  Area Networks</title><categories>cs.NI</categories><comments>Updated conference version, 10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimedia streaming applications with stringent QoS requirements in 60GHz
mmWave wireless personal area networks (WPANs) demand high rate and low latency
data transfer as well as low service disruption. In this paper, we consider the
problem of robust relay placement in 60GHz WPANs. Relays forward traffic from
transmitter devices to receiver devices facilitating i) the primary
communication path for non-line-of-sight (NLOS) transceiver pairs, and ii)
secondary (backup) communication path for line-of-sight (LOS) transceiver
pairs. We formulate the robust minimum relay placement problem and the robust
maximum utility relay placement problem with the objective to minimize the
number of relays deployed and maximize the network utility, respectively.
Efficient algorithms are developed to solve both problems and have been shown
to incur less service disruption in presence of moving subjects that may block
the LOS paths in the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6512</identifier>
 <datestamp>2014-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6512</id><created>2012-07-27</created><updated>2013-07-03</updated><authors><author><keyname>Ezerman</keyname><forenames>Martianus Frederic</forenames></author><author><keyname>Jitman</keyname><forenames>Somphong</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Pasechnik</keyname><forenames>Dmitrii V.</forenames></author></authors><title>CSS-like Constructions of Asymmetric Quantum Codes</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Trans. Information Theory in June 2013, to appear</comments><journal-ref>IEEE Transactions on Information Theory 59(2013), 6732-6754</journal-ref><doi>10.1109/TIT.2013.2272575</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymmetric quantum error-correcting codes (AQCs) may offer some advantage
over their symmetric counterparts by providing better error-correction for the
more frequent error types. The well-known CSS construction of $q$-ary AQCs is
extended by removing the $\F_{q}$-linearity requirement as well as the
limitation on the type of inner product used. The proposed constructions are
called CSS-like constructions and utilize pairs of nested subfield linear codes
under one of the Euclidean, trace Euclidean, Hermitian, and trace Hermitian
inner products.
  After establishing some theoretical foundations, best-performing CSS-like
AQCs are constructed. Combining some constructions of nested pairs of classical
codes and linear programming, many optimal and good pure $q$-ary CSS-like codes
for $q \in {2,3,4,5,7,8,9}$ up to reasonable lengths are found. In many
instances, removing the $\F_{q}$-linearity and using alternative inner products
give us pure AQCs with improved parameters than relying solely on the standard
CSS construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6514</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6514</id><created>2012-07-27</created><authors><author><keyname>Prestwich</keyname><forenames>Steven</forenames></author></authors><title>Earthquake Scenario Reduction by Symmetry Reasoning</title><categories>cs.AI</categories><comments>Abstract presented at EURO conference, Vilnius, Lithuania, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recently identified problem is that of finding an optimal investment plan
for a transportation network, given that a disaster such as an earthquake may
destroy links in the network. The aim is to strengthen key links to preserve
the expected network connectivity. A network based on the Istanbul highway
system has thirty links and therefore a billion scenarios, but it has been
estimated that sampling a million scenarios gives reasonable accuracy. In this
paper we use symmetry reasoning to reduce the number of scenarios to a much
smaller number, making sampling unnecessary. This result can be used to
facilitate metaheuristic and exact approaches to the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6528</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6528</id><created>2012-07-27</created><updated>2012-12-27</updated><authors><author><keyname>Cohn</keyname><forenames>Henry</forenames></author><author><keyname>Umans</keyname><forenames>Christopher</forenames></author></authors><title>Fast matrix multiplication using coherent configurations</title><categories>math.NA cs.DS</categories><comments>14 pages, Society for Industrial and Applied Mathematics</comments><proxy>Henry Cohn</proxy><journal-ref>Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on
  Discrete Algorithms (New Orleans, Louisiana, USA, January 6-8, 2013), 2013,
  pages 1074-1087</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a relaxation of the notion of tensor rank, called s-rank, and
show that upper bounds on the s-rank of the matrix multiplication tensor imply
upper bounds on the ordinary rank. In particular, if the &quot;s-rank exponent of
matrix multiplication&quot; equals 2, then omega = 2. This connection between the
s-rank exponent and the ordinary exponent enables us to significantly
generalize the group-theoretic approach of Cohn and Umans, from group algebras
to general algebras. Embedding matrix multiplication into general algebra
multiplication yields bounds on s-rank (not ordinary rank) and, prior to this
paper, that had been a barrier to working with general algebras.
  We identify adjacency algebras of coherent configurations as a promising
family of algebras in the generalized framework. Coherent configurations are
combinatorial objects that generalize groups and group actions; adjacency
algebras are the analogue of group algebras and retain many of their important
features. As with groups, coherent configurations support matrix multiplication
when a natural combinatorial condition is satisfied, involving triangles of
points in their underlying geometry.
  Finally, we prove a closure property involving symmetric powers of adjacency
algebras, which enables us to prove nontrivial bounds on omega using
commutative coherent configurations and suggests that commutative coherent
configurations may be sufficient to prove omega = 2. Altogether, our results
show that bounds on omega can be established by embedding large matrix
multiplication instances into small commutative coherent configurations, while
avoiding the representation-theoretic complications that were present in the
group-theoretic approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6536</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6536</id><created>2012-07-27</created><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Liu</keyname><forenames>Yuansheng</forenames></author><author><keyname>Zhang</keyname><forenames>Leo Yu</forenames></author><author><keyname>Chen</keyname><forenames>Michael Z. Q.</forenames></author></authors><title>Breaking a chaotic image encryption algorithm based on modulo addition
  and XOR operation</title><categories>cs.CR</categories><comments>11 pages, 2 figures</comments><doi>10.1142/S0218127413500752</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper re-evaluates the security of a chaotic image encryption algorithm
called MCKBA/HCKBA and finds that it can be broken efficiently with two known
plain-images and the corresponding cipher-images. In addition, it is reported
that a previously proposed breaking on MCKBA/HCKBA can be further improved by
reducing the number of chosen plain-images to two from four. The two attacks
are both based on some properties of solving a composite function involving
carry bit, which is composed of modulo addition and bitwise OR operations. Both
rigorous theoretical analysis and detailed experimental results are provided to
support the found points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6540</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6540</id><created>2012-07-27</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>Achieving Net Feedback Gain in the Butterfly Network with a Full-Duplex
  Bidirectional Relay</title><categories>cs.IT math.IT</categories><comments>27 pages, 23 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A symmetric butterfly network (BFN) with a full-duplex relay operating in a
bi-directional fashion for feedback is considered. This network is relevant for
a variety of wireless networks, including cellular systems dealing with
cell-edge users. Upper bounds on the capacity region of the general memoryless
BFN with feedback are derived based on cut-set and cooperation arguments and
then specialized to the linear deterministic BFN with really-source feedback.
It is shown that the upper bounds are achievable using combinations of the
compute-forward strategy and the classical decode-and-forward strategy, thus
fully characterizing the capacity region. It is shown that net rate gains are
possible in certain parameter regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6541</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6541</id><created>2012-07-27</created><authors><author><keyname>Zaytsev</keyname><forenames>Vadim</forenames></author></authors><title>Guided Grammar Convergence. Full Case Study Report. Generated by
  converge::Guided</title><categories>cs.PL cs.FL</categories><acm-class>F.4.2; F.4.3; I.2.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This report is meant to be used as auxiliary material for the guided grammar
convergence technique proposed earlier as problem-specific improvement in the
topic of convergence of grammars. It contains a narrated MegaL megamodel, as
well as full results of the guided grammar convergence experiment on the
Factorial Language, with details about each grammar source packaged in a
readable form. All formulae used within this document, are generated
automatically by the convergence infrastructure in order to avoid any mistakes.
The generator source code and the source of the introduction text can be found
publicly available in the Software Language Processing Suite repository.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6549</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6549</id><created>2012-07-27</created><authors><author><keyname>Banderier</keyname><forenames>Cyril</forenames></author><author><keyname>Hwang</keyname><forenames>Hsien-Kuei</forenames></author><author><keyname>Ravelomanana</keyname><forenames>Vlady</forenames></author><author><keyname>Zacharovas</keyname><forenames>Vytas</forenames></author></authors><title>Analysis of an exhaustive search algorithm in random graphs and the
  n^{c\log n} -asymptotics</title><categories>math.PR cs.DM cs.DS math.CO</categories><comments>35 pages</comments><msc-class>05C80, 05C85 (Primary) 65Q30 (Secondary)</msc-class><journal-ref>SIAM J. Discrete Math., 28(1), 342-371, 2014</journal-ref><doi>10.1137/130916357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the cost used by a naive exhaustive search algorithm for finding a
maximum independent set in random graphs under the usual G_{n,p} -model where
each possible edge appears independently with the same probability p. The
expected cost turns out to be of the less common asymptotic order n^{c\log n},
which we explore from several different perspectives. Also we collect many
instances where such an order appears, from algorithmics to analysis, from
probability to algebra. The limiting distribution of the cost required by the
algorithm under a purely idealized random model is proved to be normal. The
approach we develop is of some generality and is amenable for other graph
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6560</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6560</id><created>2012-07-27</created><authors><author><keyname>Thuan</keyname><forenames>Nguyen Duc</forenames></author></authors><title>Covering Rough Sets From a Topological Point of View</title><categories>cs.DB</categories><comments>4 pages</comments><journal-ref>International Journal of Computer Theory and Engineering, Vol. 1,
  No. 5, December, 2009, 606-609</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Covering-based rough set theory is an extension to classical rough set. The
main purpose of this paper is to study covering rough sets from a topological
point of view. The relationship among upper approximations based on topological
spaces are explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6563</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6563</id><created>2012-07-27</created><updated>2013-08-18</updated><authors><author><keyname>Lerner</keyname><forenames>Vladimir S.</forenames></author></authors><title>Hidden information and regularities of information dynamics IIR</title><categories>nlin.AO cs.IT math.IT</categories><comments>48 pages, 10 figures</comments><msc-class>58J65, 60J65, 93B52, 93E02, 93E15, 93E30</msc-class><acm-class>H.1.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Part 1 has studied the conversion of observed random process with its hidden
information to related dynamic process, applying entropy functional measure
(EF) of the random process and path functional information measure (IPF) of the
dynamic conversion process. The variation principle, satisfying the EF-IPF
equivalence along shortest path-trajectory, leads to information dual
complementary maxmin-minimax law, which creates mechanism of arising
information regularities from stochastic process(Lerner 2012). This Part 2
studies mechanism of cooperation of the observed multiple hidden information
process, which follows from the law and produces cooperative structures,
concurrently assembling in hierarchical information network (IN) and generating
the IN digital genetic code. We analyze the interactive information
contributions, information quality, inner time scale, information geometry of
the cooperative structures, evaluate curvature of these geometrical forms and
their cooperative information complexities. The law information mechanisms
operate in information observer. The observer, acting according the law,
selects random information, converts it in information dynamics, builds the IN
cooperatives, which generate the genetic code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6575</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6575</id><created>2012-07-26</created><authors><author><keyname>Sellier</keyname><forenames>Jean Michel D.</forenames></author></authors><title>Archimedes, the Free Monte Carlo simulator</title><categories>physics.comp-ph cs.SE</categories><comments>The source code can be found at:
  http://www.gnu.org/software/archimedes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Archimedes is the GNU package for Monte Carlo simulations of electron
transport in semiconductor devices. The first release appeared in 2004 and
since then it has been improved with many new features like quantum
corrections, magnetic fields, new materials, GUI, etc. This document represents
the first attempt to have a complete manual. Many of the Physics models
implemented are described and a detailed description is presented to make the
user able to write his/her own input deck. Please, feel free to contact the
author if you want to contribute to the project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6588</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6588</id><created>2012-07-27</created><updated>2013-03-03</updated><authors><author><keyname>Traag</keyname><forenames>V. A.</forenames></author><author><keyname>Van Dooren</keyname><forenames>P.</forenames></author><author><keyname>De Leenheer</keyname><forenames>P.</forenames></author></authors><title>Dynamical Models Explaining Social Balance and Evolution of Cooperation</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>8 pages, SI 9 pages</comments><journal-ref>PLoS ONE 8(4): e60063 (2013)</journal-ref><doi>10.1371/journal.pone.0060063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks with positive and negative links often split into two
antagonistic factions. Examples of such a split abound: revolutionaries versus
an old regime, Republicans versus Democrats, Axis versus Allies during the
second world war, or the Western versus the Eastern bloc during the Cold War.
Although this structure, known as social balance, is well understood, it is not
clear how such factions emerge. An earlier model could explain the formation of
such factions if reputations were assumed to be symmetric. We show this is not
the case for non-symmetric reputations, and propose an alternative model which
(almost) always leads to social balance, thereby explaining the tendency of
social networks to split into two factions. In addition, the alternative model
may lead to cooperation when faced with defectors, contrary to the earlier
model. The difference between the two models may be understood in terms of the
underlying gossiping mechanism: whereas the earlier model assumed that an
individual adjusts his opinion about somebody by gossiping about that person
with everybody in the network, we assume instead that the individual gossips
with that person about everybody. It turns out that the alternative model is
able to lead to cooperative behaviour, unlike the previous model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6600</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6600</id><created>2012-07-27</created><authors><author><keyname>Badrinath</keyname><forenames>Rama</forenames></author><author><keyname>Madhavan</keyname><forenames>C. E. Veni</forenames></author></authors><title>Diversity in Ranking using Negative Reinforcement</title><categories>cs.IR cs.AI cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of diversity in ranking of the nodes
in a graph. The task is to pick the top-k nodes in the graph which are both
'central' and 'diverse'. Many graph-based models of NLP like text
summarization, opinion summarization involve the concept of diversity in
generating the summaries. We develop a novel method which works in an iterative
fashion based on random walks to achieve diversity. Specifically, we use
negative reinforcement as a main tool to introduce diversity in the
Personalized PageRank framework. Experiments on two benchmark datasets show
that our algorithm is competitive to the existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6603</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6603</id><created>2012-07-27</created><authors><author><keyname>Li</keyname><forenames>Shuang</forenames></author><author><keyname>Zheng</keyname><forenames>Zizhan</forenames></author><author><keyname>Ekici</keyname><forenames>Eylem</forenames></author><author><keyname>Shroff</keyname><forenames>Ness</forenames></author></authors><title>Maximizing Social Welfare in Operator-based Cognitive Radio Networks
  under Spectrum Uncertainty and Sensing Inaccuracy</title><categories>cs.NI</categories><comments>submitted to Infocom 2013</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In Cognitive Radio Networks (CRNs), secondary users (SUs) are allowed to
opportunistically access the unused/under-utilized channels of primary users
(PUs). To utilize spectrum resources efficiently, an auction scheme is often
applied where an operator serves as an auctioneer and accepts spectrum requests
from SUs. Most existing works on spectrum auctions assume that the operator has
perfect knowledge of PU activities. In practice, however, it is more likely
that the operator only has statistical information of the PU traffic when it is
trading a spectrum hole, and it is acquiring more accurate information in real
time. In this paper, we distinguish PU channels that are under the control of
the operator, where accurate channel states are revealed in real-time, and
channels that the operator acquires from PUs out of its control, where a
sense-before-use paradigm has to be followed. Considering both spectrum
uncertainty and sensing inaccuracy, we study the social welfare maximization
problem for serving SUs with various levels of delay tolerance. We first model
the problem as a finite horizon Markov decision process when the operator knows
all spectrum requests in advance, and propose an optimal dynamic programming
based algorithm. We then investigate the case when spectrum requests are
submitted online, and propose a greedy algorithm that is 1/2-competitive for
homogeneous channels and is comparable to the offline algorithm for more
general settings. We further show that the online algorithm together with a
payment scheme achieves incentive compatibility for the SUs while guaranteeing
a non-negative revenue for the operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6607</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6607</id><created>2012-07-27</created><updated>2012-12-31</updated><authors><author><keyname>Lee</keyname><forenames>Joohyun</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author><author><keyname>Chong</keyname><forenames>Song</forenames></author><author><keyname>Jin</keyname><forenames>Youngmi</forenames></author></authors><title>Economics of WiFi Offloading: Trading Delay for Cellular Capacity</title><categories>cs.NI cs.GT</categories><comments>15 pages, 11 figures, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular networks are facing severe traffic overloads due to the
proliferation of smart handheld devices and traffic-hungry applications. A
cost-effective and practical solution is to offload cellular data through WiFi.
Recent theoretical and experimental studies show that a scheme, referred to as
delayed WiFi offloading, can significantly save the cellular capacity by
delaying users' data and exploiting mobility and thus increasing chance of
meeting WiFi APs (Access Points). Despite a huge potential of WiFi offloading
in alleviating mobile data explosion, its success largely depends on the
economic incentives provided to users and operators to deploy and use delayed
offloading. In this paper, we study how much economic benefits can be generated
due to delayed WiFi offloading, by modeling a market based on a two-stage
sequential game between a monopoly provider and users. We also provide
extensive numerical results computed using a set of parameters from the real
traces and Cisco's projection of traffic statistics in year 2015. In both
analytical and numerical results, we model a variety of practical scenarios and
control knobs in terms of traffic demand and willingness to pay of users,
spatio-temporal dependence of pricing and traffic, and diverse pricing and
delay tolerance. We demonstrate that delayed WiFi offloading has considerable
economic benefits, where the increase ranges from 21% to 152% in the provider's
revenue, and from 73% to 319% in the users' surplus, compared to on-the-spot
WiFi offloading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6617</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6617</id><created>2012-07-27</created><authors><author><keyname>Zhao</keyname><forenames>Yue</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On PMU Location Selection for Line Outage Detection in Wide-area
  Transmission Networks</title><categories>math.OC cs.NI</categories><comments>In Proc. of IEEE PES general meeting, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal PMU locations to collect voltage phase angle measurements for
detecting line outages in wide-area transmission networks are investigated. The
problem is established as one of maximizing the minimum distance among the
voltage phase angle signatures of the outages, which can be equivalently
formulated as an integer programming problem. Based on a greedy heuristic and a
linear programming relaxation, a branch and bound algorithm is proposed to find
the globally optimal PMU locations. Using this algorithm, the optimal tradeoff
between the number of PMUs and the outage detection performance is
characterized for IEEE 14, 24 and 30 bus systems. The algorithm is shown to
find the globally optimal PMU locations in a small number of iterations. It is
observed that it is sufficient to have roughly one third of the buses providing
PMU measurements in order to achieve the same outage detection performance as
with all the buses providing PMU measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6630</identifier>
 <datestamp>2012-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6630</id><created>2012-07-27</created><authors><author><keyname>Al-Zubaidy</keyname><forenames>Hussein</forenames></author><author><keyname>Liebeherr</keyname><forenames>Jorg</forenames></author><author><keyname>Burchard</keyname><forenames>Almut</forenames></author></authors><title>A Network Calculus Approach for the Analysis of Multi-Hop Fading
  Channels</title><categories>cs.NI</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in the delay and backlog analysis across multi-hop
paths in wireless networks is how to account for the random properties of the
wireless channel. Since the usual statistical models for radio signals in a
propagation environment do not lend themselves easily to a description of the
available service rate on a wireless link, the performance analysis of wireless
networks has resorted to higher-layer abstractions, e.g., using Markov chain
models. In this work, we propose a network calculus that can incorporate common
statistical models of fading channels and obtain statistical bounds on delay
and backlog across multiple nodes. We conduct the analysis in a transfer
domain, which we refer to as the `SNR domain', where the service process at a
link is characterized by the instantaneous signal-to-noise ratio at the
receiver. We discover that, in the transfer domain, the network model is
governed by a dioid algebra, which we refer to as (min,x)-algebra. Using this
algebra we derive the desired delay and backlog bounds. An application of the
analysis is demonstrated for a simple multi-hop network with Rayleigh fading
channels and for a network with cross traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6644</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6644</id><created>2012-07-27</created><authors><author><keyname>Luckow</keyname><forenames>Andre</forenames></author><author><keyname>Santcroos</keyname><forenames>Mark</forenames></author><author><keyname>Weidner</keyname><forenames>Ole</forenames></author><author><keyname>Merzky</keyname><forenames>Andre</forenames></author><author><keyname>Mantha</keyname><forenames>Pradeep</forenames></author><author><keyname>Jha</keyname><forenames>Shantenu</forenames></author></authors><title>P*: A Model of Pilot-Abstractions</title><categories>cs.DC</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pilot-Jobs support effective distributed resource utilization, and are
arguably one of the most widely-used distributed computing abstractions - as
measured by the number and types of applications that use them, as well as the
number of production distributed cyberinfrastructures that support them. In
spite of broad uptake, there does not exist a well-defined, unifying conceptual
model of Pilot-Jobs which can be used to define, compare and contrast different
implementations. Often Pilot-Job implementations are strongly coupled to the
distributed cyber-infrastructure they were originally designed for. These
factors present a barrier to extensibility and interoperability. This pa- per
is an attempt to (i) provide a minimal but complete model (P*) of Pilot-Jobs,
(ii) establish the generality of the P* Model by mapping various existing and
well known Pilot-Job frameworks such as Condor and DIANE to P*, (iii) derive an
interoperable and extensible API for the P* Model (Pilot-API), (iv) validate
the implementation of the Pilot-API by concurrently using multiple distinct
Pilot-Job frameworks on distinct production distributed cyberinfrastructures,
and (v) apply the P* Model to Pilot-Data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6650</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6650</id><created>2012-07-27</created><authors><author><keyname>Wu</keyname><forenames>Shanshan</forenames></author><author><keyname>Wang</keyname><forenames>Xudong</forenames></author></authors><title>Information-Theoretic Study on Routing Path Selection in Two-Way Relay
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-way relaying is a promising technique to improve network throughput.
However, how to apply it to a wireless network remains an unresolved issue.
Particularly, challenges lie in the joint design between the physical layer and
the routing protocol. Applying an existing routing protocol to a two-way relay
network can easily compromise the advantages of two-way relaying. Considering
routing path selection and two-way relaying together can be formulated as a
network optimization problem, but it is usually NP-hard. In this paper, we take
a different approach to study routing path selection for two-way relay
networks. Instead of solving the joint optimization problem, we study the
fundamental characteristics of a routing path consisting of multihop two-way
relaying nodes. Information theoretical analysis is carried out to derive
bandwidth efficiency and energy efficiency of a routing path in a two-way relay
network. Such analysis provides a framework of routing path selection by
considering bandwidth efficiency, energy efficiency and latency subject to
physical layer constraints such as the transmission rate, transmission power,
path loss exponent, path length, and the number of relays. This framework
provides insightful guidelines on routing protocol design of a two-way relay
network. Our analytical framework and insights are illustrated by extensive
numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6655</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6655</id><created>2012-07-27</created><updated>2013-04-22</updated><authors><author><keyname>Pham</keyname><forenames>Paul</forenames></author><author><keyname>Svore</keyname><forenames>Krysta M.</forenames></author></authors><title>A 2D Nearest-Neighbor Quantum Architecture for Factoring in
  Polylogarithmic Depth</title><categories>quant-ph cs.DS cs.ET</categories><comments>29 pages, 14 figures, 3 tables, presented at Reversible Computation
  Workshop 2012 in Copenhagen. Updated with numerical circuit resource upper
  bounds and constant-depth quantum unfanout</comments><journal-ref>Quantum Information &amp; Computation 13(11 &amp; 12): 937-962(2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We contribute a 2D nearest-neighbor quantum architecture for Shor's algorithm
to factor an $n$-bit number in $O(\log^2(n))$ depth. Our implementation uses
parallel phase estimation, constant-depth fanout and teleportation, and
constant-depth carry-save modular addition. We derive upper bounds on the
circuit resources of our architecture under a new 2D nearest-neighbor model
which allows a classical controller and parallel, communicating modules. We
also contribute a novel constant-depth circuit for unbounded quantum unfanout
in our new model. Finally, we provide a comparison to all previous
nearest-neighbor factoring implementations. Our circuit results in an
exponential improvement in nearest-neighbor circuit depth at the cost of a
polynomial increase in circuit size and width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6656</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6656</id><created>2012-07-27</created><updated>2013-03-22</updated><authors><author><keyname>Amoretti</keyname><forenames>Michele</forenames></author><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author></authors><title>Measuring the Complexity of Ultra-Large-Scale Adaptive Systems</title><categories>cs.NE cs.NI nlin.AO</categories><comments>highly extended version, 28 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultra-large scale (ULS) systems are becoming pervasive. They are inherently
complex, which makes their design and control a challenge for traditional
methods. Here we propose the design and analysis of ULS systems using measures
of complexity, emergence, self-organization, and homeostasis based on
information theory. These measures allow the evaluation of ULS systems and thus
can be used to guide their design. We evaluate the proposal with a ULS
computing system provided with adaptation mechanisms. We show the evolution of
the system with stable and also changing workload, using different fitness
functions. When the adaptive plan forces the system to converge to a predefined
performance level, the nodes may result in highly unstable configurations, that
correspond to a high variance in time of the measured complexity. Conversely,
if the adaptive plan is less &quot;aggressive&quot;, the system may be more stable, but
the optimal performance may not be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6667</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6667</id><created>2012-07-27</created><updated>2013-04-28</updated><authors><author><keyname>Hasan</keyname><forenames>Ziaul</forenames></author><author><keyname>Bhargava</keyname><forenames>Vijay K.</forenames></author></authors><title>Relay Selection for OFDM Wireless Systems under Asymmetric Information:
  A Contract-Theory Based Approach</title><categories>cs.NI cs.MA</categories><comments>30 Pages, 8 figures, 3 tables, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User cooperation although improves performance of wireless systems, it
requires incentives for the potential cooperating nodes to spend their energy
acting as relays. Moreover, these potential relays are better informed than the
source about their transmission costs, which depend on the exact channel
conditions on their relay-destination links. This results in asymmetry of
available information between the source and the relays. In this paper, we use
contract theory to tackle the problem of relay selection under asymmetric
information in OFDM-based cooperative wireless system that employs
decode-and-forward (DF) relaying. We first design incentive compatible
offers/contracts, consisting of a menu of payments and desired
signal-to-noise-ratios (SNR)s at the destination and then the source broadcasts
this menu to nearby mobile nodes. The nearby mobile nodes who are willing to
relay notify back the source with the contracts they are willing to accept in
each subcarrier. We show that when the source is under a budget constraint, the
problem of relay selection in each subcarrier in order to maximize the capacity
is a nonlinear non-separable knapsack problem. We propose a heuristic relay
selection scheme to solve this problem. We compare the performance of our
overall mechanism and the heuristic solution with a simple relay selection
scheme and selected numerical results showed that our solution performs better
and is close to optimal. The overall mechanism introduced in this paper is
simple to implement, requires limited interaction with potential relays and
hence requires minimal signalling overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6677</identifier>
 <datestamp>2012-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6677</id><created>2012-07-27</created><updated>2012-09-20</updated><authors><author><keyname>Basnayaka</keyname><forenames>Dushyantha A.</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author><author><keyname>Martin</keyname><forenames>Phillipa A.</forenames></author></authors><title>Ergodic Sum Capacity of Macrodiversity MIMO Systems in Flat Rayleigh
  Fading</title><categories>cs.IT math.IT</categories><comments>29 single column pages, 7 figures Corrected typos</comments><journal-ref>2012 IEEE Transaction of Information Theory</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prospect of base station (BS) cooperation leading to joint combining at
widely separated antennas has led to increased interest in macrodiversity
systems, where both sources and receive antennas are geographically
distributed. In this scenario, little is known analytically about channel
capacity since the channel matrices have a very general form where each path
may have a different power. Hence, in this paper we consider the ergodic sum
capacity of a macrodiversity MIMO system with arbitrary numbers of sources and
receive antennas operating over Rayleigh fading channels. For this system, we
compute the exact ergodic capacity for a two-source system and a compact
approximation for the general system, which is shown to be very accurate over a
wide range of cases. Finally, we develop a highly simplified upper-bound which
leads to insights into the relationship between capacity and the channel
powers. Results are verified by Monte Carlo simulations and the impact on
capacity of various channel power profiles is investigated
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6678</identifier>
 <datestamp>2013-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6678</id><created>2012-07-27</created><updated>2013-01-24</updated><authors><author><keyname>Basnayaka</keyname><forenames>Dushyantha A.</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author><author><keyname>Martin</keyname><forenames>Phillipa A.</forenames></author></authors><title>Performance Analysis of Macrodiversity MIMO Systems with MMSE and ZF
  Receivers in Flat Rayleigh Fading</title><categories>cs.IT math.IT</categories><comments>12 pages, 9 figures Revised text in Introduction and Section VII,
  main results unchanged; 2012 IEEE Transaction of Wireless Communication</comments><report-no>ISSN: 1536-1276</report-no><journal-ref>IEEE Transaction on Wireless Communication, Vol. 12, Issue 5,
  2240-2251, May 2013</journal-ref><doi>10.1109/TWC.2013.032113.120798</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a multiuser system where an arbitrary number of users communicate
with a distributed receive array over independent Rayleigh fading paths. The
receive array performs minimum mean squared error (MMSE) or zero forcing (ZF)
combining and perfect channel state information is assumed at the receiver.
This scenario is well-known and exact analysis is possible when the receive
antennas are located in a single array. However, when the antennas are
distributed, the individual links all have different average signal to noise
ratio (SNRs) and this is a much more challenging problem. In this paper, we
provide approximate distributions for the output SNR of a ZF receiver and the
output signal to interference plus noise ratio (SINR) of an MMSE receiver. In
addition, simple high SNR approximations are provided for the symbol error rate
(SER) of both receivers assuming M-PSK or M-QAM modulations. These high SNR
results provide array gain and diversity gain information as well as a
remarkably simple functional link between performance and the link powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6682</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6682</id><created>2012-07-27</created><authors><author><keyname>Woolley</keyname><forenames>Brian G.</forenames></author><author><keyname>Stanley</keyname><forenames>Kenneth O.</forenames></author></authors><title>Exploring Promising Stepping Stones by Combining Novelty Search with
  Interactive Evolution</title><categories>cs.NE</categories><comments>15 pages, 7 figures</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of evolutionary computation is inspired by the achievements of
natural evolution, in which there is no final objective. Yet the pursuit of
objectives is ubiquitous in simulated evolution. A significant problem is that
objective approaches assume that intermediate stepping stones will increasingly
resemble the final objective when in fact they often do not. The consequence is
that while solutions may exist, searching for such objectives may not discover
them. This paper highlights the importance of leveraging human insight during
search as an alternative to articulating explicit objectives. In particular, a
new approach called novelty-assisted interactive evolutionary computation
(NA-IEC) combines human intuition with novelty search for the first time to
facilitate the serendipitous discovery of agent behaviors. In this approach,
the human user directs evolution by selecting what is interesting from the
on-screen population of behaviors. However, unlike in typical IEC, the user can
now request that the next generation be filled with novel descendants. The
experimental results demonstrate that combining human insight with novelty
search finds solutions significantly faster and at lower genomic complexities
than fully-automated processes, including pure novelty search, suggesting an
important role for human users in the search for solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6683</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6683</id><created>2012-07-28</created><authors><author><keyname>Koenemann</keyname><forenames>Jochen</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author><author><keyname>Steiner</keyname><forenames>David</forenames></author></authors><title>Network Bargaining: Using Approximate Blocking Sets to Stabilize
  Unstable Instances</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a network extension to the Nash bargaining game, as introduced by
Kleinberg and Tardos (STOC'08), where the set of players corresponds to
vertices in a graph $G=(V,E)$ and each edge $ij\in E$ represents a possible
deal between players $i$ and $j$. We reformulate the problem as a cooperative
game and study the following question: Given a game with an empty core (i.e. an
unstable game) is it possible, through minimal changes in the underlying
network, to stabilize the game? We show that by removing edges in the network
that belong to a blocking set we can find a stable solution in polynomial time.
This motivates the problem of finding small blocking sets. While it has been
previously shown that finding the smallest blocking set is NP-hard
(Biro,Kern,Paulusma, TAMC'10), we show that it is possible to efficiently find
approximate blocking sets in sparse graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6685</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6685</id><created>2012-07-28</created><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author><author><keyname>Raths</keyname><forenames>Thomas</forenames></author></authors><title>FMLtoHOL (version 1.0): Automating First-order Modal Logics with LEO-II
  and Friends</title><categories>cs.LO cs.AI</categories><comments>4 pages</comments><msc-class>03B60, 03B15, 68T27, 68T30, 68T15</msc-class><acm-class>I.2.4; I.2.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A converter from first-order modal logics to classical higher- order logic is
presented. This tool enables the application of off-the-shelf higher-order
theorem provers and model finders for reasoning within first- order modal
logics. The tool supports logics K, K4, D, D4, T, S4, and S5 with respect to
constant, varying and cumulative domain semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6692</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6692</id><created>2012-07-28</created><authors><author><keyname>Cohen</keyname><forenames>David A.</forenames></author><author><keyname>Cooper</keyname><forenames>Martin C.</forenames></author><author><keyname>Creed</keyname><forenames>Paidi</forenames></author><author><keyname>Jeavons</keyname><forenames>Peter G.</forenames></author><author><keyname>Zivny</keyname><forenames>Stanislav</forenames></author></authors><title>An Algebraic Theory of Complexity for Discrete Optimisation</title><categories>cs.CC cs.DM</categories><comments>26 pages, full version of three conference papers: CP'06, MFCS'11,
  and CP'11</comments><acm-class>F.2.0</acm-class><journal-ref>SIAM Journal on Computing 42(5) 1915-1939 (2013)</journal-ref><doi>10.1137/130906398</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete optimisation problems arise in many different areas and are studied
under many different names. In many such problems the quantity to be optimised
can be expressed as a sum of functions of a restricted form. Here we present a
unifying theory of complexity for problems of this kind. We show that the
complexity of a finite-domain discrete optimisation problem is determined by
certain algebraic properties of the objective function, which we call weighted
polymorphisms. We define a Galois connection between sets of rational-valued
functions and sets of weighted polymorphisms and show how the closed sets of
this Galois connection can be characterised.
  These results provide a new approach to studying the complexity of discrete
optimisation. We use this approach to identify certain maximal tractable
subproblems of the general problem, and hence derive a complete classification
of complexity for the Boolean case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6696</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6696</id><created>2012-07-28</created><updated>2013-03-27</updated><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames><affiliation>Univ. Pompeu Fabra</affiliation></author><author><keyname>M&#xfc;ller</keyname><forenames>Moritz</forenames><affiliation>Kurt G&#xf6;del Research Center, Universit&#xe4;t Wien</affiliation></author></authors><title>An Algebraic Preservation Theorem for Aleph-Zero Categorical Quantified
  Constraint Satisfaction</title><categories>cs.LO cs.CC math.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 1 (March 29,
  2013) lmcs:1009</journal-ref><doi>10.2168/LMCS-9(1:15)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an algebraic preservation theorem for positive Horn definability in
aleph-zero categorical structures. In particular, we define and study a
construction which we call the periodic power of a structure, and define a
periomorphism of a structure to be a homomorphism from the periodic power of
the structure to the structure itself. Our preservation theorem states that,
over an aleph-zero categorical structure, a relation is positive Horn definable
if and only if it is preserved by all periomorphisms of the structure. We give
applications of this theorem, including a new proof of the known complexity
classification of quantified constraint satisfaction on equality templates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6706</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6706</id><created>2012-07-28</created><updated>2013-02-23</updated><authors><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Wireless MIMO Switching: Weighted Sum Mean Square Error and Sum Rate
  Optimization</title><categories>cs.IT math.IT</categories><comments>This manuscript is under 2nd review of IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses joint transceiver and relay design for a wireless
multiple-input-multiple-output (MIMO) switching scheme that enables data
exchange among multiple users. Here, a multi-antenna relay linearly precodes
the received (uplink) signals from multiple users before forwarding the signal
in the downlink, where the purpose of precoding is to let each user receive its
desired signal with interference from other users suppressed. The problem of
optimizing the precoder based on various design criteria is typically
non-convex and difficult to solve. The main contribution of this paper is a
unified approach to solve the weighted sum mean square error (MSE) minimization
and weighted sum rate maximization problems in MIMO switching. Specifically, an
iterative algorithm is proposed for jointly optimizing the relay's precoder and
the users' receive filters to minimize the weighted sum MSE. It is also shown
that the weighted sum rate maximization problem can be reformulated as an
iterated weighted sum MSE minimization problem and can therefore be solved
similarly to the case of weighted sum MSE minimization. With properly chosen
initial values, the proposed iterative algorithms are asymptotically optimal in
both high and low signal-to-noise ratio (SNR) regimes for MIMO switching,
either with or without self-interference cancellation (a.k.a., physical-layer
network coding). Numerical results show that the optimized MIMO switching
scheme based on the proposed algorithms significantly outperforms existing
approaches in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6713</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6713</id><created>2012-07-28</created><authors><author><keyname>Zhuo</keyname><forenames>Hankz Hankui</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author><author><keyname>Nguyen</keyname><forenames>Tuan</forenames></author></authors><title>Model-Lite Case-Based Planning</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is increasing awareness in the planning community that depending on
complete models impedes the applicability of planning technology in many real
world domains where the burden of specifying complete domain models is too
high. In this paper, we consider a novel solution for this challenge that
combines generative planning on incomplete domain models with a library of plan
cases that are known to be correct. While this was arguably the original
motivation for case-based planning, most existing case-based planners assume
(and depend on) from-scratch planners that work on complete domain models. In
contrast, our approach views the plan generated with respect to the incomplete
model as a &quot;skeletal plan&quot; and augments it with directed mining of plan
fragments from library cases. We will present the details of our approach and
present an empirical evaluation of our method in comparison to a
state-of-the-art case-based planner that depends on complete domain models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6732</identifier>
 <datestamp>2013-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6732</id><created>2012-07-28</created><updated>2013-02-17</updated><authors><author><keyname>Jurdzinski</keyname><forenames>Tomasz</forenames></author><author><keyname>Kowalski</keyname><forenames>Dariusz R.</forenames></author><author><keyname>Maciejewski</keyname><forenames>Tomasz</forenames></author><author><keyname>Stachowiak</keyname><forenames>Grzegorz</forenames></author></authors><title>Distributed Broadcasting in Wireless Networks under the SINR Model</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the advent of large-scale multi-hop wireless technologies, such as MANET,
VANET, iThings, it is of utmost importance to devise efficient distributed
protocols to maintain network architecture and provide basic communication
tools. One of such fundamental communication tasks is broadcast, also known as
a 1-to-all communication. We propose several new efficient distributed
algorithms and evaluate their time performance both theoretically and by
simulations. First randomized algorithm accomplishes broadcast in O(D+log(1/d))
rounds with probability at least 1-d on any uniform-power network of n nodes
and diameter D, when equipped with local estimate of network density.
Additionally, we evaluate average performance of this protocols by simulations
on two classes of generated networks - uniform and social - and compare the
results with performance of exponential backoff heuristic. Ours is the first
provably efficient and well-scalable distributed solution for the (global)
broadcast task. The second randomized protocol developed in this paper does not
rely on the estimate of local density, and achieves only slightly higher time
performance O((D+log(1/d))log n). Finally, we provide a deterministic algorithm
achieving similar time O(D log^2 n), supported by theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6742</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6742</id><created>2012-07-28</created><authors><author><keyname>Gui</keyname><forenames>Guan</forenames></author><author><keyname>Kuang</keyname><forenames>Aihua</forenames></author><author><keyname>Wang</keyname><forenames>Ling</forenames></author></authors><title>Low-Speed ADC Sampling Based High-Resolution Compressive Channel
  Estimation</title><categories>cs.IT math.IT</categories><comments>5pages,10figures,WPMC2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Broadband channel is often characterized by a sparse multipath channel where
dominant multipath taps are widely separated in time, thereby resulting in a
large delay spread. Traditionally, accurate channel estimation is done by
sampling received signal by analog-to-digital converter (ADC) at Nyquist rate
(high-speed ADC sampling) and then estimate all channel taps with
high-resolution. However, traditional linear estimation methods have two mainly
disadvantages: 1) demand of the high-speed ADC sampling rate which already
exceeds the capability of current ADC and also the high-speed ADC is very
expensive for regular wireless communications; 2) neglect the inherent channel
sparsity and the low spectral efficiency wireless communication is unavoidable.
To solve these challenges, in this paper, we propose a high-resolution
compressive channel estimation method by using low-speed ADC sampling. Our
proposed method can achieve close performance comparing with traditional sparse
channel estimation methods. At the same time, the proposed method has following
advantages: 1) reduce communication cost by utilizing cheap low-speed ADC; 2)
improve spectral efficiency by extracting potential training signal resource.
Numerical simulations confirm our proposed method using low-speed ADC sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6744</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6744</id><created>2012-07-29</created><updated>2012-08-03</updated><authors><author><keyname>Pamies-Juarez</keyname><forenames>Lluis</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author></authors><title>RapidRAID: Pipelined Erasure Codes for Fast Data Archival in Distributed
  Storage Systems</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To achieve reliability in distributed storage systems, data has usually been
replicated across different nodes. However the increasing volume of data to be
stored has motivated the introduction of erasure codes, a storage efficient
alternative to replication, particularly suited for archival in data centers,
where old datasets (rarely accessed) can be erasure encoded, while replicas are
maintained only for the latest data. Many recent works consider the design of
new storage-centric erasure codes for improved repairability. In contrast, this
paper addresses the migration from replication to encoding: traditionally
erasure coding is an atomic operation in that a single node with the whole
object encodes and uploads all the encoded pieces. Although large datasets can
be concurrently archived by distributing individual object encodings among
different nodes, the network and computing capacity of individual nodes
constrain the archival process due to such atomicity.
  We propose a new pipelined coding strategy that distributes the network and
computing load of single-object encodings among different nodes, which also
speeds up multiple object archival. We further present RapidRAID codes, an
explicit family of pipelined erasure codes which provides fast archival without
compromising either data reliability or storage overheads. Finally, we provide
a real implementation of RapidRAID codes and benchmark its performance using
both a cluster of 50 nodes and a set of Amazon EC2 instances. Experiments show
that RapidRAID codes reduce a single object's coding time by up to 90%, while
when multiple objects are encoded concurrently, the reduction is up to 20%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6751</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6751</id><created>2012-07-29</created><authors><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author><author><keyname>Bouk</keyname><forenames>S. H.</forenames></author><author><keyname>Javaid</keyname><forenames>A.</forenames></author><author><keyname>Sasase</keyname><forenames>I.</forenames></author></authors><title>Modeling Enhancements in DSR, FSR, OLSR under Mobility and Scalability
  Constraints in VANETs</title><categories>cs.NI</categories><journal-ref>3rd International Workshop on Towards Samart Communications and
  Networks Technologies (SaCoNet2012) in conjunction with 48th IEEE
  International Conference on Communications (ICC2012), Ottawa, Canada, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequent topological changes due to high mobility is one of the main issues
in Vehicular Ad-hoc NETworks (VANETs). In this paper, we model transmission
probabilities of 802.11p for VANETs and effect of these probabilities on
average transmission time. To evaluate the effect of these probabilities of
VANETs in routing protocols, we select Dynamic Source Routing (DSR), Fish-eye
State Routing (FSR) and Optimized Link State Routing (OLSR). Framework of these
protocols with respect to their packet cost is also presented in this work. A
novel contribution of this work is enhancement of chosen protocols to obtain
efficient behavior. Extensive simulation work is done to prove and compare the
efficiency in terms of high throughput of enhanced versions with default
versions of protocols in NS-2. For this comparison, we choose three performance
metrics; throughput, End-to-End Delay (E2ED) and Normalized Routing Load (NRL)
in different mobilities and scalabilities. Finally, we deduce that enhanced DSR
(DSR-mod) outperforms other protocols by achieving 16% more packet delivery for
all scalabilities and 28% more throughput in selected mobilities than original
version of DSR (DSR-orig).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6760</identifier>
 <datestamp>2013-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6760</id><created>2012-07-29</created><updated>2013-04-10</updated><authors><author><keyname>Sidi</keyname><forenames>Habib B. A.</forenames></author><author><keyname>Chahin</keyname><forenames>Wissam</forenames></author><author><keyname>El-Azouzi</keyname><forenames>Rachid</forenames></author><author><keyname>De Pellegrini</keyname><forenames>Francesco</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>Incentive Mechanisms based on Minority Game in Heterogeneous DTNs</title><categories>cs.GT</categories><comments>Technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we design an incentive mechanism for heterogeneous Delay
Tolerant Networks (DTNs). The proposed mechanism tackles a core problem of such
systems: how to induce coordination of DTN relays in order to achieve a target
performance figure, e.g., delivery probability or end-to-end delay, under a
given constraint in term of network resources, e.g., number of active nodes or
energy consumption. Also, we account for the realistic case when the cost for
taking part in the forwarding process varies with the devices' technology or
the users' habits. Finally, the scheme is truly applicable to DTNs since it
works with no need for end-to-end connectivity.
  In this context, we first introduce the basic coordination mechanism
leveraging the notion of a Minority Game. In this game, relays compete to be in
the population minority and their utility is defined in combination with a
rewarding mechanism. The rewards in turn configure as a control by which the
network operator controls the desired operating point for the DTN. To this aim,
we provide a full characterization of the equilibria of the game in the case of
heterogeneous DTNs. Finally, a learning algorithm based on stochastic
approximations provably drives the system to the equilibrium solution without
requiring perfect state information at relay nodes or at the source node and
without using end-to-end communications to implement the rewarding scheme. We
provide extensive numerical results to validate the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6762</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6762</id><created>2012-07-29</created><updated>2013-07-18</updated><authors><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Hu</keyname><forenames>Yuchong</forenames></author></authors><title>Cooperative Regenerating Codes</title><categories>cs.IT math.IT</categories><comments>29 pages, 13 figures, submitted to IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the design objectives in distributed storage system is the
minimization of the data traffic during the repair of failed storage nodes. By
repairing multiple failures simultaneously and cooperatively, further reduction
of repair traffic is made possible. A closed-form expression of the optimal
tradeoff between the repair traffic and the amount of storage in each node for
cooperative repair is given. We show that the points on the tradeoff curve can
be achieved by linear cooperative regenerating codes, with an explicit bound on
the required finite field size. The proof relies on a max-flow-min-cut-type
theorem for submodular flow from combinatorial optimization. Two families of
explicit constructions are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6774</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6774</id><created>2012-07-29</created><authors><author><keyname>Revathi</keyname><forenames>A. R.</forenames></author><author><keyname>Kumar</keyname><forenames>Dhananjay</forenames></author></authors><title>A Survey Of Activity Recognition And Understanding The Behavior In Video
  Survelliance</title><categories>cs.CV</categories><comments>14 pages, 5 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a review of human activity recognition and behaviour
understanding in video sequence. The key objective of this paper is to provide
a general review on the overall process of a surveillance system used in the
current trend. Visual surveillance system is directed on automatic
identification of events of interest, especially on tracking and classification
of moving objects. The processing step of the video surveillance system
includes the following stages: Surrounding model, object representation, object
tracking, activity recognition and behaviour understanding. It describes
techniques that use to define a general set of activities that are applicable
to a wide range of scenes and environments in video sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6778</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6778</id><created>2012-07-29</created><authors><author><keyname>Kolipaka</keyname><forenames>Parikshit</forenames></author><author><keyname>Govindarajan</keyname><forenames>Sathish</forenames></author></authors><title>Two player game variant of the Erdos-Szekeres problem</title><categories>cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical Erdos-Szekeres theorem states that a convex $k$-gon exists in
every sufficiently large point set. This problem has been well studied and
finding tight asymptotic bounds is considered a challenging open problem.
Several variants of the Erdos-Szekeres problem have been posed and studied in
the last two decades. The well studied variants include the empty convex
$k$-gon problem, convex $k$-gon with specified number of interior points and
the chromatic variant.
  In this paper, we introduce the following two player game variant of the
Erdos-Szekeres problem: Consider a two player game where each player playing in
alternate turns, place points in the plane. The objective of the game is to
avoid the formation of the convex k-gon among the placed points. The game ends
when a convex k-gon is formed and the player who placed the last point loses
the game.
  In our paper we show a winning strategy for the player who plays second in
the convex 5-gon game and the empty convex 5-gon game by considering convex
layer configurations at each step. We prove that the game always ends in the
9th step by showing that the game reaches a specific set of configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6788</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6788</id><created>2012-07-29</created><authors><author><keyname>Alsan</keyname><forenames>Mine</forenames></author><author><keyname>Telatar</keyname><forenames>Emre</forenames></author></authors><title>Submartingale Property of E_0 Under The Polarization Transformations</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the relation $E_0(\rho, W^{-}) + E_0(\rho, W^{+}) \geq 2
E_0(\rho, W)$ holds for any binary input discrete memoryless channel $W$, and
$\rho \geq 0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6805</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6805</id><created>2012-07-29</created><authors><author><keyname>Di Clemente</keyname><forenames>Riccardo</forenames></author><author><keyname>Pietronero</keyname><forenames>Luciano</forenames></author></authors><title>Statistical Agent Based Modelization of the Phenomenon of Drug Abuse</title><categories>physics.soc-ph cs.CY cs.SI</categories><comments>12 pages, 5 figures</comments><journal-ref>Scientific Reports 2, 532 (2012)</journal-ref><doi>10.1038/srep00532</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We introduce a statistical agent based model to describe the phenomenon of
drug abuse and its dynamical evolution at the individual and global level. The
agents are heterogeneous with respect to their intrinsic inclination to drugs,
to their budget attitude and social environment. The various levels of drug use
were inspired by the professional description of the phenomenon and this
permits a direct comparison with all available data. We show that certain
elements have a great importance to start the use of drugs, for example the
rare events in the personal experiences which permit to overcame the barrier of
drug use occasionally. The analysis of how the system reacts to perturbations
is very important to understand its key elements and it provides strategies for
effective policy making. The present model represents the first step of a
realistic description of this phenomenon and can be easily generalized in
various directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6808</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6808</id><created>2012-07-29</created><authors><author><keyname>Akdeniz</keyname><forenames>Mustafa Riza</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Wireless Scheduling with Dominant Interferers and Applications to
  Femtocellular Interference Cancellation</title><categories>cs.IT cs.NI math.IT</categories><comments>9 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general class of wireless scheduling and resource allocation
problems where the received rate in each link is determined by the actions of
the transmitter in that link along with a single dominant interferer. Such
scenarios arise in a range of scenarios, particularly in emerging femto- and
picocellular networks with strong, localized interference. For these networks,
a utility maximizing scheduler based on loopy belief propagation is presented
that enables computationally-efficient local processing and low communication
overhead. Our main theoretical result shows that the fixed points of the method
are provably globally optimal for arbitrary (potentially non-convex) rate and
utility functions. The methodology thus provides globally optimal solutions to
a large class of inter-cellular interference coordination problems including
subband scheduling, dynamic orthogonalization and beamforming whenever the
dominant interferer assumption is valid. The paper focuses on applications for
systems with interference cancellation (IC) and suggests a new scheme on
optimal rate control, as opposed to traditional power control. Simulations are
presented in industry standard femtocellular network models demonstrate
significant improvements in rates over simple reuse 1 without IC, and near
optimal performance of loopy belief propagation for rate selection in only one
or two iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6814</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6814</id><created>2012-07-29</created><authors><author><keyname>Hayashi</keyname><forenames>Yukio</forenames></author></authors><title>Adaptive Fractal-like Network Structure for Efficient Search of
  Inhomogeneously Distributed Targets at Unknown Positions</title><categories>physics.soc-ph cs.SI math-ph math.MP</categories><comments>6 pages, 6 figures</comments><journal-ref>Proc. of the the 4th International Conference on Adaptive and
  Self-adaptive Systems and Applications, pp.63-68, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since a spatial distribution of communication requests is inhomogeneous and
related to a population, in constructing a network, it is crucial for
delivering packets on short paths through the links between proximity nodes and
for distributing the load of nodes how to locate the nodes as base-stations on
a realistic wireless environment. In this paper, from viewpoints of complex
network science and biological foraging, we propose a scalably self-organized
geographical network, in which the proper positions of nodes and the network
topology are simultaneously determined according to the population, by
iterative divisions of rectangles for load balancing of nodes in the adaptive
change of their territories. In particular, we consider a decentralized routing
by using only local information,and show that, for searching targets around
high population areas, the routing on the naturally embedded fractal-like
structure by population has higher efficiency than the conventionally optimal
strategy on a square lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6816</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6816</id><created>2012-07-29</created><authors><author><keyname>Naish</keyname><forenames>Lee</forenames></author></authors><title>Transforming floundering into success</title><categories>cs.PL</categories><comments>Number of pages: 24 Number of figures: 9 Number of tables: none</comments><doi>10.1017/S147106841200035X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how logic programs with &quot;delays&quot; can be transformed to programs
without delays in a way which preserves information concerning floundering
(also known as deadlock). This allows a declarative (model-theoretic),
bottom-up or goal independent approach to be used for analysis and debugging of
properties related to floundering. We rely on some previously introduced
restrictions on delay primitives and a key observation which allows properties
such as groundness to be analysed by approximating the (ground) success set.
This paper is to appear in Theory and Practice of Logic Programming (TPLP).
  Keywords: Floundering, delays, coroutining, program analysis, abstract
interpretation, program transformation, declarative debugging
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6819</identifier>
 <datestamp>2012-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6819</id><created>2012-07-29</created><updated>2012-12-13</updated><authors><author><keyname>Manipatruni</keyname><forenames>Sasikanth</forenames></author><author><keyname>Lipson</keyname><forenames>Michal</forenames></author><author><keyname>Young</keyname><forenames>Ian A.</forenames></author></authors><title>Device Considerations for Nanophotonic CMOS Global Interconnects</title><categories>physics.optics cs.ET</categories><comments>Accepted to IEEE Journal of Special Topics in Quantum Electronics</comments><acm-class>C.1.4; B.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an analytical framework to understand the path for scaling
nanophotonic interconnects to meet the energy and footprint requirements of
CMOS global interconnects. We derive the device requirements for sub 100
fJ/cm/bit interconnects including tuning power, serialization-deserialization
energy, optical insertion losses, extinction ratio and bit error rates. Using
CMOS with integrated nanophotonics as an example platform, we derive the
energy/bit, linear and areal bandwidth density of optical interconnects. We
also derive the targets for device performance which indicate the need for
continued improvements in insertion losses (&lt;8dB), laser efficiency,
operational speeds (&gt;40 Gb/s), tuning power (&lt;100 {\mu}W/nm),
serialization-deserialization (&lt; 10 fJ/bit/Operation) and necessity for
spectrally selective devices with wavelength multiplexing (&gt; 6 channels).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6821</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6821</id><created>2012-07-29</created><authors><author><keyname>Kashefi</keyname><forenames>Elham</forenames><affiliation>University of Edinburgh, UK</affiliation></author><author><keyname>Krivine</keyname><forenames>Jean</forenames><affiliation>University Paris Diderot, France</affiliation></author><author><keyname>van Raamsdonk</keyname><forenames>Femke</forenames><affiliation>VU University Amsterdam, The Netherlands</affiliation></author></authors><title>Proceedings 7th International Workshop on Developments of Computational
  Methods</title><categories>cs.CE cs.ET</categories><comments>EPTCS 88, 2012</comments><proxy>EPTCS</proxy><acm-class>F3.1, F4.2</acm-class><doi>10.4204/EPTCS.88</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 7th International Workshop on
Developments in Computational Models (DCM 2011) which was held on Sunday July
3, 2011, in Zurich, Switzerland, as a satelite workshop of ICALP 2011.
  Recently several new models of computation have emerged, for instance for
bio-computing and quantum-computing, and in addition traditional models of
computation have been adapted to accommodate new demands or capabilities of
computer systems. The aim of DCM is to bring together researchers who are
currently developing new computational models or new features for traditional
computational models, in order to foster their interaction, to provide a forum
for presenting new ideas and work in progress, and to enable newcomers to learn
about current activities in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6830</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6830</id><created>2012-07-29</created><authors><author><keyname>Ebrahim</keyname><forenames>Ale</forenames></author><author><keyname>Ahmed</keyname><forenames>Nader</forenames></author><author><keyname>Rashid</keyname><forenames>Shamsuddin Abdul</forenames></author><author><keyname>Hanim</keyname><forenames>Salwa</forenames></author><author><keyname>Taha</keyname><forenames>Zahari</forenames></author></authors><title>Technology Use in the Virtual R&amp;D Teams</title><categories>cs.CY</categories><acm-class>F.2.2</acm-class><journal-ref>American Journal of Engineering and Applied Sciences, 2012, 5(1),
  Pages 9-14</journal-ref><doi>10.3844/ajeassp.2012.9.14</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Problem statement: Although, literature proves the importance of the
technology role in the effectiveness of virtual Research and Development (R&amp;D)
teams for new product development. However, the factors that make technology
construct in a virtual R&amp;D team are still ambiguous. The manager of virtual R&amp;D
teams for new product development does not know which type of technology should
be used. Approach: To address the gap and answer the question, the study
presents a set of factors that make a technology construct. The proposed
construct modified by finding of the field survey (N = 240). We empirically
examine the relationship between construct and its factors by employing the
Structural Equation Modeling (SEM). A measurement model built base on the 19
preliminary factors that extracted from literature review. The result shows 10
factors out of 19 factors maintaining to make technology construct. Results:
These 10 technology factors can be grouped into two constructs namely Web base
communication and Web base data sharing. The findings can help new product
development managers of enterprises to concentrate in the main factors for
leading an effective virtual R&amp;D team. In addition, it provides a guideline for
software developers as well. Conclusion: The second and third generation
technologies are now more suitable for developing new products through virtual
R&amp;D teams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6831</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6831</id><created>2012-07-10</created><authors><author><keyname>Farah</keyname><forenames>Fourati</forenames></author></authors><title>Une approche IDM de transformation exog\`ene de Wright vers Ada</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The formal ADL Wright allows to describe the structural and behavioral
aspects of abstract software architecture. The behavioral aspects are described
in CSP and checked using the model-checker FDR. While the ADL Wright does not
offer any means to realize such architectures abstract. The objective of this
work is to open up the ADL Wright for Ada through an automated approach based
on MDE. To achieve this, we have developed two Ecore meta-models: the
meta-model Wright and the partial meta-model of Ada. Moreover, we have
designed, built and tested our program Wright2Ada written in ATL to transform
software architecture described in Wright to a concurrent program in Ada.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6832</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6832</id><created>2012-07-29</created><authors><author><keyname>Ebrahim</keyname><forenames>Nader Ale</forenames></author><author><keyname>Rashid</keyname><forenames>Salwa Hanim Abdul</forenames></author><author><keyname>Ahmed</keyname><forenames>Shamsuddin</forenames></author><author><keyname>Taha</keyname><forenames>Zahari</forenames></author></authors><title>The Effectiveness of Virtual R&amp;D Teams in SMEs: Experiences of Malaysian
  SMEs</title><categories>cs.OH</categories><acm-class>A.0</acm-class><journal-ref>Industrial Engineering and Management Systems, 2011, 10(2), Pages
  109-114</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The number of small and medium enterprises (SMEs), especially those involved
with research and development (R&amp;D) programs and employed virtual teams to
create the greatest competitive advantage from limited labor are increasing.
Global and localized virtual R&amp;D teams are believed to have high potential for
the growth of SMEs. Due to the fast-growing complexity of new products coupled
with new emerging opportunities of virtual teams, a collaborative approach is
believed to be the future trend. This research explores the effectiveness of
virtuality in SMEs' virtual R&amp;D teams. Online questionnaires were emailed to
Malaysian manufacturing SMEs and 74 usable questionnaires were received,
representing a 20.8 percent return rate. In order to avoid biases which may
result from pre-suggested answers, a series of open-ended questions were
retrieved from the experts. This study was focused on analyzing an open-ended
question, whereby four main themes were extracted from the experts'
recommendations regarding the effectiveness of virtual teams for the growth and
performance of SMEs. The findings of this study would be useful to product
design managers of SMEs in order to realize the key advantages and significance
of virtual R&amp;D teams during the new product development (NPD) process. This in
turn, leads to increased effectiveness in new product development's procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6839</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6839</id><created>2012-07-30</created><updated>2012-07-31</updated><authors><author><keyname>Fabrega</keyname><forenames>Jorge</forenames></author><author><keyname>Paredes</keyname><forenames>Pablo</forenames></author></authors><title>Three Degrees of Distance on Twitter</title><categories>cs.SI physics.soc-ph</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has found that the propagation of behaviors and sentiments
through networks extends in ranges up to 2 to 4 degrees of distance. The
regularity with which the same observation is found in dissimilar phenomena has
been associated with friction in the propagation process and the instability of
link structure that emerges in the dynamic of social networks. We study a
contagious behavior, the practice of retweeting, in a setting where neither of
those restrictions is present and still found the same result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6862</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6862</id><created>2012-07-30</created><authors><author><keyname>Gui</keyname><forenames>Guan</forenames></author><author><keyname>Peng</keyname><forenames>Wei</forenames></author></authors><title>Improved Channel Estimation with Partial Sparse Constraint for AF
  Cooperative Communication Systems</title><categories>cs.IT math.IT</categories><comments>6pages,7figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate channel state information (CSI) is necessary for coherent detection
in amplify and forward (AF) broadband cooperative communication systems. Based
on the assumption of ordinary sparse channel, efficient sparse channel
estimation methods have been investigated in our previous works. However, when
the cooperative channel exhibits partial sparse structure rather than ordinary
sparsity, our previous method cannot take advantage of the prior information.
In this paper, we propose an improved channel estimation method with partial
sparse constraint on cooperative channel. At first, we formulate channel
estimation as a compressive sensing problem and utilize sparse decomposition
theory. Secondly, the cooperative channel is reconstructed by LASSO with
partial sparse constraint. Finally, numerical simulations are carried out to
confirm the superiority of proposed methods over ordinary sparse channel
estimation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6864</identifier>
 <datestamp>2015-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6864</id><created>2012-07-30</created><updated>2013-05-24</updated><authors><author><keyname>Peng</keyname><forenames>Junhao</forenames></author><author><keyname>Xu</keyname><forenames>Guoai</forenames></author></authors><title>Tutte polynomial of pseudofractal scale-free web</title><categories>math-ph cs.CC math.MP</categories><comments>19pages,7figures. arXiv admin note: text overlap with arXiv:1006.5333</comments><report-no>159:1196--1215</report-no><journal-ref>Journal of Statistical Physics, 2015</journal-ref><doi>10.1007/s10955-015-1225-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Tutte polynomial of a graph is a 2-variable polynomial which is quite
important in both combinatorics and statistical physics. It contains various
numerical invariants and polynomial invariants, such as the number of spanning
trees, the number of spanning forests, the number of acyclic orientations, the
reliability polynomial, chromatic polynomial and flow polynomial. In this
paper, we study and gain recursive formulas for the Tutte polynomial of
pseudofractal scale-free web (PSW) which implies logarithmic complexity
algorithm is obtained to calculate the Tutte polynomial of PSW although it is
NP-hard for general graph. We also obtain the rigorous solution for the the
number of spanning trees of PSW by solving the recurrence relations derived
from Tutte polynomial, which give an alternative approach for explicitly
determining the number of spanning trees of PSW. Further more, we analysis the
all-terminal reliability of PSW and compare the results with that of Sierpinski
gasket which has the same number of nodes and edges with PSW. In contrast with
the well-known conclusion that scale-free networks are more robust against
removal of nodes than homogeneous networks (e.g., exponential networks and
regular networks). Our results show that Sierpinski gasket (which is a regular
network) are more robust against random edge failures than PSW (which is a
scale-free network). Whether it is true for any regular networks and scale-free
networks, is still a unresolved problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6873</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6873</id><created>2012-07-30</created><updated>2012-08-06</updated><authors><author><keyname>Chandra</keyname><forenames>Surendranath Chowdary</forenames></author><author><keyname>C</keyname><forenames>Ravindranath Chowdary</forenames></author></authors><title>JASF: Jasta Security Framework</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  JASM is a model designed to increase the security level in authentication
systems. It uses IP Address of the user in the authentication process to
enhance the security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6889</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6889</id><created>2012-07-30</created><authors><author><keyname>Panahi</keyname><forenames>Ashkan</forenames></author><author><keyname>Viberg</keyname><forenames>Mats</forenames></author></authors><title>A robust l_1 penalized DOA estimator</title><categories>cs.IT math.IT</categories><comments>The paper is going to appear on the Asilomar 2012 proceeding</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The SPS-LASSO has recently been introduced as a solution to the problem of
regularization parameter selection in the complex-valued LASSO problem. Still,
the dependence on the grid size and the polynomial time of performing convex
optimization technique in each iteration, in addition to the deficiencies in
the low noise regime, confines its performance for Direction of Arrival (DOA)
estimation. This work presents methods to apply LASSO without grid size
limitation and with less complexity. As we show by simulations, the proposed
methods loose a negligible performance compared to the Maximum Likelihood (ML)
estimator, which needs a combinatorial search We also show by simulations that
compared to practical implementations of ML, the proposed techniques are less
sensitive to the source power difference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6902</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6902</id><created>2012-07-30</created><updated>2015-02-15</updated><authors><author><keyname>Rezaee</keyname><forenames>Mohsen</forenames></author><author><keyname>Guillaud</keyname><forenames>Maxime</forenames></author></authors><title>Interference Alignment with Quantized Grassmannian Feedback in the
  K-user Constant MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>Added the analysis of the feedback real dimension (Section III.B),
  and generally improved exposition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple channel state information (CSI) feedback scheme is proposed for
interference alignment (IA) over the K-user constant
Multiple-Input-Multiple-Output Interference Channel (MIMO IC). The proposed
technique relies on the identification of invariants in the IA equations, which
enables the reformulation of the CSI quantization problem as a single
quantization on the Grassmann manifold at each receiver. The scaling of the
number of feedback bits with the transmit power sufficient to preserve the
multiplexing gain that can be achieved under perfect CSI is established. We
show that the CSI feedback requirements of the proposed technique are better
(lower) than what is required when using previously published methods, for
system dimensions (number of users and antennas) of practical interest.
Furthermore, we show through simulations that this advantage persists at low
SNR, in the sense that the proposed technique yields a higher sum-rate
performance for a given number of feedback bits. Finally, to complement our
analysis, we introduce a statistical model that faithfully captures the
properties of the quantization error obtained for random vector quantization
(RVQ) on the Grassmann manifold for large codebooks; this enables the numerical
(Monte-Carlo) analysis of general Grassmannian RVQ schemes for codebook sizes
that would be impractically large to simulate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6910</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6910</id><created>2012-07-30</created><updated>2013-05-08</updated><authors><author><keyname>Tomczak</keyname><forenames>Jakub M.</forenames></author><author><keyname>Swiatek</keyname><forenames>Jerzy</forenames></author><author><keyname>Latawiec</keyname><forenames>Krzysztof</forenames></author></authors><title>Gaussian process regression as a predictive model for Quality-of-Service
  in Web service systems</title><categories>cs.NI cs.LG</categories><comments>9 pages, 4 figures, technical report</comments><msc-class>60G15, 68M11, 97R40</msc-class><acm-class>G.3; H.3.5; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the Gaussian process regression as the predictive
model for Quality-of-Service (QoS) attributes in Web service systems. The goal
is to predict performance of the execution system expressed as QoS attributes
given existing execution system, service repository, and inputs, e.g., streams
of requests. In order to evaluate the performance of Gaussian process
regression the simulation environment was developed. Two quality indexes were
used, namely, Mean Absolute Error and Mean Squared Error. The results obtained
within the experiment show that the Gaussian process performed the best with
linear kernel and statistically significantly better comparing to
Classification and Regression Trees (CART) method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6928</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6928</id><created>2012-07-30</created><authors><author><keyname>Gale</keyname><forenames>Ella</forenames></author><author><keyname>Costello</keyname><forenames>Ben de Lacy</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Filamentary Extension of the Mem-Con theory of Memristance and its
  Application to Titanium Dioxide Sol-Gel Memristors</title><categories>cond-mat.mtrl-sci cs.ET physics.chem-ph</categories><comments>6 pages, 4 figures, submitted for a conference</comments><msc-class>94.C.06, 92.E.06, 68.Q.06</msc-class><acm-class>C.1.3; I.6.1; I.6.5; B.1.2; I.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Titanium dioxide sol-gel memristors have two different modes of operation,
believed to be dependent on whether there is bulk memristance, i.e. memristance
throughout the whole volume or filamentary memristance, i.e. memristance caused
by the connection of conducting filaments. The mem-con theory of memristance is
based on the drift of oxygen vacancies rather than that of conducting electrons
and has been previously used to describe bulk memristance in several devices.
Here, the mem-con theory is extended to model memristance caused by small
filaments of low resistance titanium dioxide and it compares favorably to
experimental results for filamentary memristance in sol-gel devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6933</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6933</id><created>2012-07-30</created><authors><author><keyname>Gale</keyname><forenames>Ella</forenames></author><author><keyname>Costello</keyname><forenames>Ben de Lacy</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>The Effect of Electrode Size on Memristor Properties: An Experimental
  and Theoretical Study</title><categories>cond-mat.mtrl-sci cs.ET physics.chem-ph</categories><comments>6 pages, 9 figures, submitted for a conference</comments><msc-class>92E06, 68Q06</msc-class><acm-class>I.6.4; C.1.3; I.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The width of the electrodes is not included in the current phenomenological
models of memristance, but is included in the memory-conservation (mem-con)
theory of memristance. An experimental study of the effect of changing the top
electrode width was performed on titanium dioxide sol-gel memristors. It was
demonstrated that both the on resistance, Ron, and the off resistance, Roff,
decreased with increasing electrode size. The memory function part of the
mem-con model could fit the relationship between Ron and electrode size.
Similarly, the conservation function fits the change in Roff. The
experimentally measured hysteresis did not fit the phenomenological model's
predictions. Instead the size of the hysteresis increased with increasing
electrode size, and correlated well to decreasing Ron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6936</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6936</id><created>2012-07-30</created><updated>2012-10-09</updated><authors><author><keyname>Aupy</keyname><forenames>Guillaume</forenames></author><author><keyname>Robert</keyname><forenames>Yves</forenames></author><author><keyname>Vivien</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Zaidouni</keyname><forenames>Dounia</forenames></author></authors><title>Impact of fault prediction on checkpointing strategies</title><categories>cs.DC cs.DS</categories><comments>20 pages</comments><report-no>INRIA Report 8023</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the impact of fault prediction techniques on
checkpointing strategies. We extend the classical analysis of Young and Daly in
the presence of a fault prediction system, which is characterized by its recall
and its precision, and which provides either exact or window-based time
predictions. We succeed in deriving the optimal value of the checkpointing
period (thereby minimizing the waste of resource usage due to checkpoint
overhead) in all scenarios. These results allow to analytically assess the key
parameters that impact the performance of fault predictors at very large scale.
In addition, the results of this analytical evaluation are nicely corroborated
by a comprehensive set of simulations, thereby demonstrating the validity of
the model and the accuracy of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6944</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6944</id><created>2012-07-30</created><updated>2012-08-09</updated><authors><author><keyname>Laun</keyname><forenames>J&#xfc;rn</forenames></author></authors><title>Efficient algorithms for highly compressed data: The Word Problem in
  Generalized Higman Groups is in P</title><categories>math.GR cs.DS</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper continues the 2012 STACS contribution by Diekert, Ushakov, and the
author. We extend the results published in the proceedings in two ways.
  First, we show that the data structure of power circuits can be generalized
to work with arbitrary bases q&gt;=2. This results in a data structure that can
hold huge integers, arising by iteratively forming powers of q. We show that
the properties of power circuits known for q=2 translate to the general case.
This generalization is non-trivial and additional techniques are required to
preserve the time bounds of arithmetic operations that were shown for the case
q=2.
  The extended power circuit model permits us to conduct operations in the
Baumslag-Solitar group BS(1,q) as efficiently as in BS(1,2). This allows us to
solve the word problem in the generalization H_4(1,q) of Higman's group, which
is an amalgamated product of four copies of the Baumslag-Solitar group BS(1,q)
rather than BS(1,2) in the original form.
  As a second result, we allow arbitrary numbers f&gt;=4 of copies of BS(1,q),
leading to an even more generalized notion of Higman groups H_f(1,q). We prove
that the word problem of the latter can still be solved within the O(n^6) time
bound that was shown for H_4(1,2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6945</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6945</id><created>2012-07-30</created><updated>2013-10-01</updated><authors><author><keyname>Ullman</keyname><forenames>Jonathan</forenames></author></authors><title>Answering n^{2+o(1)} Counting Queries with Differential Privacy is Hard</title><categories>cs.CR cs.CC</categories><comments>Full version of our STOC'13 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central problem in differentially private data analysis is how to design
efficient algorithms capable of answering large numbers of counting queries on
a sensitive database. Counting queries of the form &quot;What fraction of individual
records in the database satisfy the property q?&quot; We prove that if one-way
functions exist, then there is no algorithm that takes as input a database D in
({0,1}^d)^n, and k = n^{2+o(1)} arbitrary efficiently computable counting
queries, runs in time poly(d, n), and returns an approximate answer to each
query, while satisfying differential privacy. We also consider the complexity
of answering &quot;simple&quot; counting queries, and make some progress in this
direction by showing that the above result holds even when we require that the
queries are computable by constant depth (AC-0) circuits.
  Our result is almost tight in the sense that nearly n^2 counting queries can
be answered efficiently while satisfying differential privacy. Moreover,
super-polynomially many queries can be answered in exponential time.
  We prove our results by extending the connection between differentially
private counting query release and cryptographic traitor-tracing schemes to the
setting where the queries are given to the sanitizer as input, and by
constructing a traitor-tracing scheme that is secure in this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6960</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6960</id><created>2012-07-30</created><updated>2014-08-25</updated><authors><author><keyname>Klav&#xed;k</keyname><forenames>Pavel</forenames></author><author><keyname>Kratochv&#xed;l</keyname><forenames>Jan</forenames></author><author><keyname>Otachi</keyname><forenames>Yota</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author><author><keyname>Saitoh</keyname><forenames>Toshiki</forenames></author><author><keyname>Saumell</keyname><forenames>Maria</forenames></author><author><keyname>Vysko&#x10d;il</keyname><forenames>Tom&#xe1;&#x161;</forenames></author></authors><title>Extending Partial Representations of Proper and Unit Interval Graphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently introduced problem of extending partial interval representations
asks, for an interval graph with some intervals pre-drawn by the input, whether
the partial representation can be extended to a representation of the entire
graph. In this paper, we give a linear-time algorithm for extending proper
interval representations and an almost quadratic-time algorithm for extending
unit interval representations.
  We also introduce the more general problem of bounded representations of unit
interval graphs, where the input constrains the positions of some intervals by
lower and upper bounds. We show that this problem is NP-complete for
disconnected input graphs and give a polynomial-time algorithm for the special
class of instances, where the ordering of the connected components of the input
graph along the real line is prescribed. This includes the case of partial
representation extension.
  The hardness result sharply contrasts the recent polynomial-time algorithm
for bounded representations of proper interval graphs [Balko et al. ISAAC'13].
So unless $\text{P} = \text{NP}$, proper and unit interval representations have
vastly different structure. This explains why partial representation extension
problems for these different types of representations require substantially
different techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6986</identifier>
 <datestamp>2012-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6986</id><created>2012-07-30</created><updated>2012-10-15</updated><authors><author><keyname>Lim</keyname><forenames>Fabian</forenames></author></authors><title>Two Embedding Theorems for Data with Equivalences under Finite Group
  Action</title><categories>cs.DS cs.IT math.IT</categories><comments>10 page extended abstract plus two sets of supplementary material. 1
  figure. Preliminary report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is recent interest in compressing data sets for non-sequential
settings, where lack of obvious orderings on their data space, require notions
of data equivalences to be considered. For example, Varshney &amp; Goyal (DCC,
2006) considered multiset equivalences, while Choi &amp; Szpankowski (IEEE Trans.
IT, 2012) considered isomorphic equivalences in graphs. Here equivalences are
considered under a relatively broad framework - finite-dimensional,
non-sequential data spaces with equivalences under group action, for which
analogues of two well-studied embedding theorems are derived: the Whitney
embedding theorem and the Johnson-Lindenstrauss lemma. Only the canonical data
points need to be carefully embedded, each such point representing a set of
data points equivalent under group action. Two-step embeddings are considered.
First, a group invariant is applied to account for equivalences, and then
secondly, a linear embedding takes it down to low-dimensions. Our results
require hypotheses on discriminability of the applied invariant, such notions
related to seperating invariants (Dufresne, 2008), and completeness in pattern
recognition (Kakarala, 1992). In the latter theorem, the embedding complexity
depends on the size of the canonical part, which may be significantly smaller
than the whole data set, up to a factor equal to the size the group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6991</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6991</id><created>2012-07-30</created><authors><author><keyname>Schreiber</keyname><forenames>Alex</forenames></author></authors><title>The probability of finding a fixed pattern in random data depends
  monotonically on the bifix indicator</title><categories>math.PR cs.IT math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding a fixed L-ary sequence in a stream of
random L-ary data. It is known that the expected search time is a strictly
increasing function of the lengths of the bifices of the pattern. In this paper
we prove the related statement that the probability of finding the pattern in a
finite random word is a strictly decreasing function of the lengths of the
bifices of the pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.6994</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.6994</id><created>2012-07-30</created><authors><author><keyname>Lancaster</keyname><forenames>David</forenames></author></authors><title>Random Walks between Leaves of Random Networks</title><categories>cond-mat.dis-nn cs.CY</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider random walks that start and are absorbed on the leaves of random
networks and study the length of such walks. For the networks we investigate,
Erdos-Renyi random graphs and Barabasi-Albert scale free networks, these walks
are not transient and we consider various approaches to computing the
probability of a given length walk.One approach is to label nodes according to
both their total degree and the number of links connected to leaf nodes, and as
a byproduct we compute the probability of a random node of a scale free network
having such a label.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7010</identifier>
 <datestamp>2012-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7010</id><created>2012-07-30</created><updated>2012-10-16</updated><authors><author><keyname>Brinkmann</keyname><forenames>Gunnar</forenames></author><author><keyname>Goedgebeur</keyname><forenames>Jan</forenames></author><author><keyname>McKay</keyname><forenames>Brendan D.</forenames></author></authors><title>The Generation of Fullerenes</title><categories>math.CO cs.DM physics.comp-ph</categories><comments>21 pages; added a note</comments><journal-ref>J. Chem. Inf. Model. (2012)</journal-ref><doi>10.1021/ci3003107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an efficient new algorithm for the generation of fullerenes. Our
implementation of this algorithm is more than 3.5 times faster than the
previously fastest generator for fullerenes -- fullgen -- and the first program
since fullgen to be useful for more than 100 vertices. We also note a
programming error in fullgen that caused problems for 136 or more vertices. We
tabulate the numbers of fullerenes and IPR fullerenes up to 400 vertices. We
also check up to 316 vertices a conjecture of Barnette that cubic planar graphs
with maximum face size 6 are hamiltonian and verify that the smallest
counterexample to the spiral conjecture has 380 vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7019</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7019</id><created>2012-07-30</created><updated>2012-08-13</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Prabhu</keyname><forenames>Vinayak S.</forenames></author></authors><title>Finite Automata with Time-Delay Blocks (Extended Version)</title><categories>cs.FL cs.SY</categories><comments>Full version</comments><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of delays arises naturally in many computational models, such as,
in the design of circuits, control systems, and dataflow languages. In this
work, we introduce \emph{automata with delay blocks} (ADBs), extending finite
state automata with variable time delay blocks, for deferring individual
transition output symbols, in a discrete-time setting. We show that the ADB
languages strictly subsume the regular languages, and are incomparable in
expressive power to the context-free languages. We show that ADBs are closed
under union, concatenation and Kleene star, and under intersection with regular
languages, but not closed under complementation and intersection with other ADB
languages. We show that the emptiness and the membership problems are decidable
in polynomial time for ADBs, whereas the universality problem is undecidable.
Finally we consider the linear-time model checking problem, i.e., whether the
language of an ADB is contained in a regular language, and show that the model
checking problem is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7033</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7033</id><created>2012-07-30</created><updated>2012-08-01</updated><authors><author><keyname>Quader</keyname><forenames>Saad</forenames></author></authors><title>A Beginner's Guide to Counting Spanning Trees in a Graph</title><categories>cs.DM math.CO math.SP</categories><comments>(DRAFT VERSION) This paper has been withdrawn by the author because
  -- section 4.3 has major errors -- section 2.1 needs to be more rigorous --
  there are many typographical errors 34 pages, Monograph, proof of every
  argument, even elementary ones. Please send your comments to saad0105050 AT
  gmail DOT com</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (DRAFT VERSION) In this article we present a proof of the famous Kirchoff's
Matrix-Tree theorem, which relates the number of spanning trees in a connected
graph with the cofactors (and eigenvalues) of its combinatorial Laplacian
matrix. This is a 165 year old result in graph theory and the proof is
conceptually simple. However, the elegance of this result is it connects many
apparently unrelated concepts in linear algebra and graph theory. Our
motivation behind this work was to make the proof accessible to anyone with
beginner\slash intermediate grasp of linear algebra. Therefore in this paper we
present proof of every single argument leading to the final result. For
example, we prove the elementary properties of determinants, relationship
between the roots of characteristic polynomial (that is, eigenvalues) and the
minors, the Cauchy-Binet formula, the Laplace expansion of determinant, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7034</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7034</id><created>2012-07-30</created><updated>2012-08-02</updated><authors><author><keyname>Kelk</keyname><forenames>Steven</forenames></author><author><keyname>Scornavacca</keyname><forenames>Celine</forenames></author></authors><title>Towards the fixed parameter tractability of constructing minimal
  phylogenetic networks from arbitrary sets of nonbinary trees</title><categories>q-bio.PE cs.CC</categories><comments>have fixed a number of small typo's etc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has remained an open question for some time whether, given a set of not
necessarily binary (i.e. &quot;nonbinary&quot;) trees T on a set of taxa X, it is
possible to determine in time f(r).poly(m) whether there exists a phylogenetic
network that displays all the trees in T, where r refers to the reticulation
number of the network and m=|X|+|T|. Here we show that this holds if one or
both of the following conditions holds: (1) |T| is bounded by a function of r;
(2) the maximum degree of the nodes in T is bounded by a function of r. These
sufficient conditions absorb and significantly extend known special cases,
namely when all the trees in T are binary, or T contains exactly two nonbinary
trees. We believe this result is an important step towards settling the issue
for an arbitrarily large and complex set of nonbinary trees. For completeness
we show that the problem is certainly solveable in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7035</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7035</id><created>2012-07-27</created><authors><author><keyname>Perry</keyname><forenames>Thomas</forenames></author><author><keyname>Zha</keyname><forenames>Hongyuan</forenames></author><author><keyname>Frias</keyname><forenames>Patricio</forenames></author><author><keyname>Zeng</keyname><forenames>Dadan</forenames></author><author><keyname>Braunstein</keyname><forenames>Mark</forenames></author></authors><title>Supervised Laplacian Eigenmaps with Applications in Clinical Diagnostics
  for Pediatric Cardiology</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic health records contain rich textual data which possess critical
predictive information for machine-learning based diagnostic aids. However many
traditional machine learning methods fail to simultaneously integrate both
vector space data and text. We present a supervised method using Laplacian
eigenmaps to augment existing machine-learning methods with low-dimensional
representations of textual predictors which preserve the local similarities.
The proposed implementation performs alternating optimization using gradient
descent. For the evaluation we applied our method to over 2,000 patient records
from a large single-center pediatric cardiology practice to predict if patients
were diagnosed with cardiac disease. Our method was compared with latent
semantic indexing, latent Dirichlet allocation, and local Fisher discriminant
analysis. The results were assessed using AUC, MCC, specificity, and
sensitivity. Results indicate supervised Laplacian eigenmaps was the highest
performing method in our study, achieving 0.782 and 0.374 for AUC and MCC
respectively. SLE showed an increase in 8.16% in AUC and 20.6% in MCC over the
baseline which excluded textual data and a 2.69% and 5.35% increase in AUC and
MCC respectively over unsupervised Laplacian eigenmaps. This method allows many
existing machine learning predictors to effectively and efficiently utilize the
potential of textual predictors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7036</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7036</id><created>2012-07-11</created><authors><author><keyname>Meko</keyname><forenames>Sultan F.</forenames></author></authors><title>Impact of channel partitioning and relay placement on resource
  allocation in OFDMA Cellular networks</title><categories>cs.NI</categories><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  4, No. 3, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tremendous growth in the demand for wireless applications such as streaming
audio/videos, Skype and video games require high data rate irrespective of
user's location in the cellular network. However, the Quality of Service (QoS)
of users degrades at the cell boundary. Relay enhanced multi-hop cellular
network is one of the cost effective solution to improve the performance of
cell edge users. Optimal deployment of Fixed Relay Nodes (FRNs) is essential to
satisfy the QoS requirement of edge users. We propose new schemes for channel
partitioning and FRN placement in cellular networks. Path-loss, Signal to
Interference and Noise Ratio (SINR) experienced by users, and effects of
shadowing have been considered. The analysis gives more emphasis on the
cell-edge users (worst case scenario). The results show that these schemes
achieve higher system performance in terms of spectral efficiency and also
increase the user data rate at the cell edge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7040</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7040</id><created>2012-07-30</created><updated>2012-12-27</updated><authors><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>Fault-Tolerant Spanners for Doubling Metrics: Better and Simpler</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In STOC'95 Arya et al. (1995) conjectured that for any constant dimensional
$n$-point Euclidean space, a $(1+\eps)$-spanner with constant degree,
hop-diameter $O(\log n)$ and weight $O(\log n) \cdot \omega(MST)$ can be built
in $O(n \log n)$ time. Recently Elkin and Solomon (technical report, April
2012) proved this conjecture of Arya et al. in the affirmative. In fact, the
proof of Elkin and Solomon is more general in two ways. First, it applies to
arbitrary doubling metrics. Second, it provides a complete tradeoff between the
three involved parameters that is tight (up to constant factors) in the entire
range.
  Subsequently, Chan et al. (technical report, July 2012) provided another
proof for Arya et al.'s conjecture, which is simpler than the proof of Elkin
and Solomon. Moreover, Chan et al. (2012) also showed that one can build a
fault-tolerant (FT) spanner with similar properties. Specifically, they showed
that there exists a $k$-FT $(1+\eps)$-spanner with degree $O(k^2)$,
hop-diameter $O(\log n)$ and weight $O(k^3 \cdot \log n) \cdot \omega(MST)$.
The running time of the construction of Chan et al. was not analyzed.
  In this work we improve the results of Chan et al., using a simpler proof.
Specifically, we present a simple proof which shows that a $k$-FT
$(1+\eps)$-spanner with degree $O(k^2)$, hop-diameter $O(\log n)$ and weight
$O(k^2 \cdot \log n) \cdot \omega(MST)$ can be built in $O(n \cdot (\log n +
k^2))$ time. Similarly to the constructions of Elkin and Solomon and Chan et
al., our construction applies to arbitrary doubling metrics. However, in
contrast to the construction of Elkin and Solomon, our construction fails to
provide a complete (and tight) tradeoff between the three involved parameters.
The construction of Chan et al. has this drawback too.
  For random point sets in $\mathbb R^d$, we &quot;shave&quot; a factor of $\log n$ from
the weight bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7055</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7055</id><created>2012-07-30</created><authors><author><keyname>Heintz</keyname><forenames>Benjamin</forenames></author><author><keyname>Chandra</keyname><forenames>Abhishek</forenames></author><author><keyname>Sitaraman</keyname><forenames>Ramesh K.</forenames></author></authors><title>Optimizing MapReduce for Highly Distributed Environments</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MapReduce, the popular programming paradigm for large-scale data processing,
has traditionally been deployed over tightly-coupled clusters where the data is
already locally available. The assumption that the data and compute resources
are available in a single central location, however, no longer holds for many
emerging applications in commercial, scientific and social networking domains,
where the data is generated in a geographically distributed manner. Further,
the computational resources needed for carrying out the data analysis may be
distributed across multiple data centers or community resources such as Grids.
In this paper, we develop a modeling framework to capture MapReduce execution
in a highly distributed environment comprising distributed data sources and
distributed computational resources. This framework is flexible enough to
capture several design choices and performance optimizations for MapReduce
execution. We propose a model-driven optimization that has two key features:
(i) it is end-to-end as opposed to myopic optimizations that may only make
locally optimal but globally suboptimal decisions, and (ii) it can control
multiple MapReduce phases to achieve low runtime, as opposed to single-phase
optimizations that may control only individual phases. Our model results show
that our optimization can provide nearly 82% and 64% reduction in execution
time over myopic and single-phase optimizations, respectively. We have modified
Hadoop to implement our model outputs, and using three different MapReduce
applications over an 8-node emulated PlanetLab testbed, we show that our
optimized Hadoop execution plan achieves 31-41% reduction in runtime over a
vanilla Hadoop execution. Our model-driven optimization also provides several
insights into the choice of techniques and execution parameters based on
application and platform characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7067</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7067</id><created>2012-07-29</created><authors><author><keyname>Torres-Salinas</keyname><forenames>Daniel</forenames></author><author><keyname>Robinson-Garcia</keyname><forenames>Nicolas</forenames></author><author><keyname>Lopez-Cozar</keyname><forenames>Emilio Delgado</forenames></author></authors><title>Towards a Book Publishers Citation Reports. First approach using the
  Book Citation Index</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The absence of books and book chapters in the Web of Science Citation Indexes
(SCI, SSCI and A&amp;HCI) has always been considered an important flaw but the
Thomson Reuters 'Book Citation Index' database was finally available in October
of 2010 indexing 29,618 books and 379,082 book chapters. The Book Citation
Index opens a new window of opportunities for analyzing these fields from a
bibliometric point of view. The main objective of this article is to analyze
different impact indicators referred to the scientific publishers included in
the Book Citation Index for the Social Sciences and Humanities fields during
2006-2011. This way we construct what we have called the 'Book Publishers
Citation Reports'. For this, we present a total of 19 rankings according to the
different disciplines in Humanities &amp; Arts and Social Sciences &amp; Law with six
indicators for scientific publishers
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7079</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7079</id><created>2012-07-30</created><authors><author><keyname>Kuipers</keyname><forenames>J.</forenames></author><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author><author><keyname>Plaat</keyname><forenames>A.</forenames></author><author><keyname>Herik</keyname><forenames>H. J. van den</forenames></author></authors><title>Improving multivariate Horner schemes with Monte Carlo tree search</title><categories>cs.SC cs.AI math-ph math.MP</categories><comments>5 pages</comments><doi>10.1016/j.cpc.2013.05.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimizing the cost of evaluating a polynomial is a classic problem in
computer science. For polynomials in one variable, Horner's method provides a
scheme for producing a computationally efficient form. For multivariate
polynomials it is possible to generalize Horner's method, but this leaves
freedom in the order of the variables. Traditionally, greedy schemes like
most-occurring variable first are used. This simple textbook algorithm has
given remarkably efficient results. Finding better algorithms has proved
difficult. In trying to improve upon the greedy scheme we have implemented
Monte Carlo tree search, a recent search method from the field of artificial
intelligence. This results in better Horner schemes and reduces the cost of
evaluating polynomials, sometimes by factors up to two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7085</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7085</id><created>2012-07-30</created><authors><author><keyname>Almishari</keyname><forenames>Mishari</forenames></author><author><keyname>Gasti</keyname><forenames>Paolo</forenames></author><author><keyname>Nathan</keyname><forenames>Naveen</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author></authors><title>Optimizing Bi-directional Low-Latency Communication in Named Data
  Networking</title><categories>cs.NI</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Content-Centric Networking (CCN) is a concept being considered as a potential
future alternative to, or replacement for, today's Internet IP-style
packet-switched host-centric networking. One factor making CCN attractive is
its focus on content distribution, which dominates current Internet traffic and
which is arguably not well-served by IP. Named Data Networking (NDN) is a
prominent example of CCN. It is also one of several on-going research efforts
aiming to design and develop a full-blown candidate future Internet
architecture. Although NDN's primary motivation is content distribution, it is
envisioned to support other types of traffic, such as conferencing (audio,
video) as well as more historical applications, such as remote login. However,
it is unclear how suitable NDN is for applications that are not obviously
content-centric. In this paper, we explore NDN in the context of a class of
applications that involve low- latency bidirectional communication.
Specifically, we propose a few architectural amendments to NDN that provide
significantly better throughput and lower latency for this class of
applications. The proposed approach is validated via both simulations and
testbed experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7103</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7103</id><created>2012-07-30</created><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>Guillaume</keyname><forenames>Jean-Loup</forenames></author></authors><title>Temporal Reachability Graphs</title><categories>cs.NI</categories><comments>In proceedings ACM Mobicom 2012</comments><acm-class>C.2.1; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While a natural fit for modeling and understanding mobile networks,
time-varying graphs remain poorly understood. Indeed, many of the usual
concepts of static graphs have no obvious counterpart in time-varying ones. In
this paper, we introduce the notion of temporal reachability graphs. A
(tau,delta)-reachability graph} is a time-varying directed graph derived from
an existing connectivity graph. An edge exists from one node to another in the
reachability graph at time t if there exists a journey (i.e., a spatiotemporal
path) in the connectivity graph from the first node to the second, leaving
after t, with a positive edge traversal time tau, and arriving within a maximum
delay delta. We make three contributions. First, we develop the theoretical
framework around temporal reachability graphs. Second, we harness our
theoretical findings to propose an algorithm for their efficient computation.
Finally, we demonstrate the analytic power of the temporal reachability graph
concept by applying it to synthetic and real-life datasets. On top of defining
clear upper bounds on communication capabilities, reachability graphs highlight
asymmetric communication opportunities and offloading potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7109</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7109</id><created>2012-07-30</created><authors><author><keyname>Chetioui</keyname><forenames>Kaouthar</forenames></author><author><keyname>Orhanou</keyname><forenames>Ghizlane</forenames></author><author><keyname>Hajji</keyname><forenames>Said El</forenames></author><author><keyname>Lakbabi</keyname><forenames>Abdelmajid</forenames></author></authors><title>Security of the DNS Protocol - Implementation and Weaknesses Analyses of
  DNSSEC</title><categories>cs.CR</categories><comments>6 pages, 13 figures; IJCSI International Journal of Computer Science
  Issues, Vol. 9, Issue 2, No 3, March 2012;
  http://www.ijcsi.org/articles/Security-of-the-dns-protocol--implementation-and-weaknesses-analyses-of-dnssec.php</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, Internet offers many critical applications. So, it becomes very
crucial for Internet service providers to ensure traceability of operations and
to secure data exchange. Since all these communications are based on the use of
the Domain Name System (DNS) protocol, it becomes necessary to think to enhance
and secure it by proposing a secure version of this protocol that can correct
the whole or a part of the DNS protocol weaknesses and vulnerabilities. In this
context, DNSsec was created by the IETF to ensure the integrity of DNS data and
authentication of the source of such data. DNSsec is based on the key
cryptography public to provide different security services. In the present
paper, we will present first the DNS protocol and its weaknesses. After that,
we will be interested in studying the DNSsec implementation and data exchange,
and then give a deep analysis of its weaknesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7121</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7121</id><created>2012-07-09</created><authors><author><keyname>Kmimech</keyname><forenames>Mourad</forenames></author></authors><title>V\'erification d'assemblages de composants logiciels : Application aux
  mod\`eles de composants UML2.0 et Ugatze</title><categories>cs.SE</categories><comments>arXiv admin note: substantial text overlap with arXiv:1207.6831 by
  different author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The component approach aims for the reuse by a coherent and easy components
assembly. But obtaining a coherent components assembly is not an easy exercise.
To achieve this, we advocate a contractual approach distinguishing different
syntactic, structural, semantic, synchronization and service quality contracts.
We have successfully applied this approach on two models of semi-formal
contractual components: UML2.0 and Ugatze. Indeed, we propose two approaches:
VerifComponentUML2.0 and VerifComponentUgatze. The VerifComponentUML2.0
approach aims the verification of syntactic, structural, synchronization and
quality service contracts on a UML2.0 component assembly through two formal
component models Acme/Armani and Wright. VerifComponentUML2.0 has two tools:
Wr2fdr and Wright2Ada. The tool Wr2fdr allows translating Wright expression to
CSP contracts in order to verify synchronization using the model checker FDR.
It is a IDM tool Wright2Ada which allow is transforming Wright code to Ada, in
order to open UML2.0 on static analysis and dynamic tools associated with Ada.
VerifComponentUgatze approach provides a frame allowing to check syntactic and
structural contracts of an Ugatze component assembly through Acme/Armani.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7125</identifier>
 <datestamp>2013-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7125</id><created>2012-07-30</created><authors><author><keyname>Durak</keyname><forenames>Nurcan</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author><author><keyname>Kolda</keyname><forenames>Tamara G.</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>Degree Relations of Triangles in Real-world Networks and Models</title><categories>cs.SI physics.soc-ph</categories><journal-ref>CIKM '12: Proceedings of the 21st ACM International Conference on
  Information and Knowledge Management, ACM, pp. 1712-1716, 2012</journal-ref><doi>10.1145/2396761.2398503</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Triangles are an important building block and distinguishing feature of
real-world networks, but their structure is still poorly understood. Despite
numerous reports on the abundance of triangles, there is very little
information on what these triangles look like. We initiate the study of
degree-labeled triangles -- specifically, degree homogeneity versus
heterogeneity in triangles. This yields new insight into the structure of
real-world graphs. We observe that networks coming from social and
collaborative situations are dominated by homogeneous triangles, i.e., degrees
of vertices in a triangle are quite similar to each other. On the other hand,
information networks (e.g., web graphs) are dominated by heterogeneous
triangles, i.e., the degrees in triangles are quite disparate. Surprisingly,
nodes within the top 1% of degrees participate in the vast majority of
triangles in heterogeneous graphs. We also ask the question of whether or not
current graph models reproduce the types of triangles that are observed in real
data and showed that most models fail to accurately capture these salient
features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7134</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7134</id><created>2012-07-30</created><authors><author><keyname>Bonchis</keyname><forenames>Cosmin</forenames></author><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>Improved approximation algorithms for low-density instances of the
  Minimum Entropy Set Cover Problem</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the approximability of instances of the minimum entropy set cover
problem, parameterized by the average frequency of a random element in the
covering sets. We analyze an algorithm combining a greedy approach with another
one biased towards large sets. The algorithm is controled by the percentage of
elements to which we apply the biased approach. The optimal parameter choice
has a phase transition around average density $e$ and leads to improved
approximation guarantees when average element frequency is less than $e$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7139</identifier>
 <datestamp>2012-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7139</id><created>2012-07-30</created><updated>2012-11-28</updated><authors><author><keyname>Christin</keyname><forenames>Nicolas</forenames></author></authors><title>Traveling the Silk Road: A measurement analysis of a large anonymous
  online marketplace</title><categories>cs.CY cs.CR</categories><comments>26 pages, 13 figures, 4 tables; changes to v1 include revised sales
  volume and commission estimates (Sec. 5) and slightly expanded discussion</comments><report-no>CMU-Cylab-12-018</report-no><acm-class>K.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform a comprehensive measurement analysis of Silk Road, an anonymous,
international online marketplace that operates as a Tor hidden service and uses
Bitcoin as its exchange currency. We gather and analyze data over eight months
between the end of 2011 and 2012, including daily crawls of the marketplace for
nearly six months in 2012. We obtain a detailed picture of the type of goods
being sold on Silk Road, and of the revenues made both by sellers and Silk Road
operators. Through examining over 24,400 separate items sold on the site, we
show that Silk Road is overwhelmingly used as a market for controlled
substances and narcotics, and that most items sold are available for less than
three weeks. The majority of sellers disappears within roughly three months of
their arrival, but a core of 112 sellers has been present throughout our
measurement interval. We evaluate the total revenue made by all sellers, from
public listings, to slightly over USD 1.2 million per month; this corresponds
to about USD 92,000 per month in commissions for the Silk Road operators. We
further show that the marketplace has been operating steadily, with daily sales
and number of sellers overall increasing over our measurement interval. We
discuss economic and policy implications of our analysis and results, including
ethical considerations for future research in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7144</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7144</id><created>2012-07-30</created><authors><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Information and Estimation over Binomial and Negative Binomial Models</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, a number of results have been developed which connect
information measures and estimation measures under various models, including,
predominently, Gaussian and Poisson models. More recent results due to Taborda
and Perez-Cruz relate the relative entropy to certain mismatched estimation
errors in the context of binomial and negative binomial models, where, unlike
in the case of Gaussian and Poisson models, the conditional mean estimates
concern models of different parameters than those of the original model. In
this note, a different set of results in simple forms are developed for
binomial and negative binomial models, where the conditional mean estimates are
produced through the original models. The new results are more consistent with
existing results for Gaussian and Poisson models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7146</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7146</id><created>2012-07-30</created><authors><author><keyname>Assaf</keyname><forenames>Ali</forenames><affiliation>LIG, Universit&#xe9; Joseh Fourier and &#xc9;cole Polytechnique, France</affiliation></author><author><keyname>Perdrix</keyname><forenames>Simon</forenames><affiliation>CNRS, LIG, Universit&#xe9; de Grenoble, France</affiliation></author></authors><title>Completeness of algebraic CPS simulations</title><categories>cs.LO quant-ph</categories><comments>In Proceedings DCM 2011, arXiv:1207.6821</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 88, 2012, pp. 16-27</journal-ref><doi>10.4204/EPTCS.88.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The algebraic lambda calculus and the linear algebraic lambda calculus are
two extensions of the classical lambda calculus with linear combinations of
terms. They arise independently in distinct contexts: the former is a fragment
of the differential lambda calculus, the latter is a candidate lambda calculus
for quantum computation. They differ in the handling of application arguments
and algebraic rules. The two languages can simulate each other using an
algebraic extension of the well-known call-by-value and call-by-name CPS
translations. These simulations are sound, in that they preserve reductions. In
this paper, we prove that the simulations are actually complete, strengthening
the connection between the two languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7147</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7147</id><created>2012-07-30</created><authors><author><keyname>Bioglio</keyname><forenames>Livio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Dezani-Ciancaglini</keyname><forenames>Mariangiola</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Giannini</keyname><forenames>Paola</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Troina</keyname><forenames>Angelo</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author></authors><title>A Calculus of Looping Sequences with Local Rules</title><categories>cs.CE cs.FL</categories><comments>In Proceedings DCM 2011, arXiv:1207.6821</comments><proxy>EPTCS</proxy><acm-class>F.4.2; F.4.3</acm-class><journal-ref>EPTCS 88, 2012, pp. 43-58</journal-ref><doi>10.4204/EPTCS.88.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a variant of the Calculus of Looping Sequences (CLS
for short) with global and local rewrite rules. While global rules, as in CLS,
are applied anywhere in a given term, local rules can only be applied in the
compartment on which they are defined. Local rules are dynamic: they can be
added, moved and erased. We enrich the new calculus with a parallel semantics
where a reduction step is lead by any number of global and local rules that
could be performed in parallel. A type system is developed to enforce the
property that a compartment must contain only local rules with specific
features. As a running example we model some interactions happening in a cell
starting from its nucleus and moving towards its mitochondria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7148</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7148</id><created>2012-07-30</created><authors><author><keyname>Dershowitz</keyname><forenames>Nachum</forenames><affiliation>Tel Aviv University</affiliation></author><author><keyname>Falkovich</keyname><forenames>Evgenia</forenames><affiliation>Tel Aviv University</affiliation></author></authors><title>A Formalization and Proof of the Extended Church-Turing Thesis -Extended
  Abstract-</title><categories>cs.LO cs.CC</categories><comments>In Proceedings DCM 2011, arXiv:1207.6821</comments><proxy>EPTCS</proxy><acm-class>F.1.1; F.3.1</acm-class><journal-ref>EPTCS 88, 2012, pp. 72-78</journal-ref><doi>10.4204/EPTCS.88.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the Extended Church-Turing Thesis: Every effective algorithm can be
efficiently simulated by a Turing machine. This is accomplished by emulating an
effective algorithm via an abstract state machine, and simulating such an
abstract state machine by a random access machine, representing data as a
minimal term graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7149</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7149</id><created>2012-07-30</created><authors><author><keyname>Kudlek</keyname><forenames>Manfred</forenames><affiliation>Universit&#xe4;t Hamburg</affiliation></author></authors><title>On the Existence of Universal Finite or Pushdown Automata</title><categories>cs.FL</categories><comments>In Proceedings DCM 2011, arXiv:1207.6821. Sadly, Manfred Kudlek
  passed away June 18, 2012, before publication of this paper</comments><proxy>EPTCS</proxy><acm-class>F.1.1</acm-class><journal-ref>EPTCS 88, 2012, pp. 79-86</journal-ref><doi>10.4204/EPTCS.88.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the (non)-existence of universal automata for some classes of
automata, such as finite automata and pushdown automata, and in particular the
influence of the representation and encoding function. An alternative approach,
using transition systems, is presented too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7150</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7150</id><created>2012-07-30</created><authors><author><keyname>Mislove</keyname><forenames>Michael</forenames><affiliation>Tulane University</affiliation></author></authors><title>Probabilistic Monads, Domains and Classical Information</title><categories>cs.PL cs.DM cs.IT math.IT</categories><comments>In Proceedings DCM 2011, arXiv:1207.6821</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 88, 2012, pp. 87-100</journal-ref><doi>10.4204/EPTCS.88.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shannon's classical information theory uses probability theory to analyze
channels as mechanisms for information flow. In this paper, we generalize
results of Martin, Allwein and Moskowitz for binary channels to show how some
more modern tools - probabilistic monads and domain theory in particular - can
be used to model classical channels. As initiated Martin, et al., the point of
departure is to consider the family of channels with fixed inputs and outputs,
rather than trying to analyze channels one at a time. The results show that
domain theory has a role to play in the capacity of channels; in particular,
the (n x n)-stochastic matrices, which are the classical channels having the
same sized input as output, admit a quotient compact ordered space which is a
domain, and the capacity map factors through this quotient via a
Scott-continuous map that measures the quotient domain. We also comment on how
some of our results relate to recent discoveries about quantum channels and
free affine monoids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7167</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7167</id><created>2012-07-31</created><updated>2012-09-28</updated><authors><author><keyname>Lee</keyname><forenames>Wonchan</forenames><affiliation>Seoul National University</affiliation></author><author><keyname>Jung</keyname><forenames>Yungbum</forenames><affiliation>Seoul National University</affiliation></author><author><keyname>Wang</keyname><forenames>Bow-yaw</forenames><affiliation>Academia Sinica</affiliation></author><author><keyname>Yi</keyname><forenames>Kwangkuen</forenames><affiliation>Seoul National University</affiliation></author></authors><title>Predicate Generation for Learning-Based Quantifier-Free Loop Invariant
  Inference</title><categories>cs.LO cs.LG</categories><proxy>LMCS</proxy><acm-class>F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (September
  29, 2012) lmcs:1035</journal-ref><doi>10.2168/LMCS-8(3:25)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the predicate generation problem in the context of loop invariant
inference. Motivated by the interpolation-based abstraction refinement
technique, we apply the interpolation theorem to synthesize predicates
implicitly implied by program texts. Our technique is able to improve the
effectiveness and efficiency of the learning-based loop invariant inference
algorithm in [14]. We report experiment results of examples from Linux,
SPEC2000, and Tar utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7179</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7179</id><created>2012-07-31</created><authors><author><keyname>Kim</keyname><forenames>Na-Rae</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author></authors><title>Novel Modulation Techniques using Isomers as Messenger Molecules for
  Nano Communication Networks via Diffusion</title><categories>cs.IT math.IT q-bio.QM</categories><comments>10 pages and 15 figures. arXiv admin note: substantial text overlap
  with arXiv:1201.0913</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose three novel modulation techniques, i.e.,
concentration-based, molecular-type-based, and molecular-ratio-based, using
isomers as messenger molecules for nano communication networks via diffusion.
To evaluate achievable rate performance, we compare the proposed tech- niques
with conventional insulin based concepts under practical scenarios. Analytical
and numerical results confirm that the proposed modulation techniques using
isomers achieve higher data transmission rate performance (max 7.5 dB
signal-to-noise ratio gain) than the insulin based concepts. We also
investigate the tradeoff between messenger sizes and modulation orders and
provide guidelines for selecting from among several possible candidates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7184</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7184</id><created>2012-07-31</created><authors><author><keyname>Milani&#x10d;</keyname><forenames>Martin</forenames></author><author><keyname>Rizzi</keyname><forenames>Romeo</forenames></author><author><keyname>Tomescu</keyname><forenames>Alexandru I.</forenames></author></authors><title>Set graphs. II. Complexity of set graph recognition and similar problems</title><categories>cs.DM cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is said to be a `set graph' if it admits an acyclic orientation
that is also `extensional', in the sense that the out-neighborhoods of its
vertices are pairwise distinct. Equivalently, a set graph is the underlying
graph of the digraph representation of a hereditarily finite set. In this
paper, we continue the study of set graphs and related topics, focusing on
computational complexity aspects. We prove that set graph recognition is
NP-complete, even when the input is restricted to bipartite graphs with exactly
two leaves. The problem remains NP-complete if, in addition, we require that
the extensional acyclic orientation be also `slim', that is, that the digraph
obtained by removing any arc from it is not extensional. We also show that the
counting variants of the above problems are #P-complete, and prove similar
complexity results for problems related to a generalization of extensional
acyclic digraphs, the so-called `hyper-extensional digraphs', which were
proposed by Aczel to describe hypersets. Our proofs are based on reductions
from variants of the Hamiltonian Path problem. We also consider a variant of
the well-known notion of a separating code in a digraph, the so-called
`open-out-separating code', and show that it is NP-complete to determine
whether an input extensional acyclic digraph contains an open-out-separating
code of given size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7193</identifier>
 <datestamp>2012-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7193</id><created>2012-07-31</created><updated>2012-11-05</updated><authors><author><keyname>Klotz</keyname><forenames>Johannes Georg</forenames></author><author><keyname>Kracht</keyname><forenames>David</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Schober</keyname><forenames>Steffen</forenames></author></authors><title>Canalizing Boolean Functions Maximize the Mutual Information</title><categories>cs.IT math.IT nlin.AO q-bio.MN</categories><comments>Accepted at SCC 2013, Munich, Germany, www.scc2013.net</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability of information processing in biologically motivated Boolean
networks is of interest in recent information theoretic research. One measure
to quantify this ability is the well known mutual information. Using Fourier
analysis we show that canalizing functions maximize the mutual information
between an input variable and the outcome of the function. We proof our result
for Boolean functions with uniform distributed as well as product distributed
input variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7199</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7199</id><created>2012-07-31</created><authors><author><keyname>Zhang</keyname><forenames>Lan</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author></authors><title>Message in a Sealed Bottle: Privacy Preserving Friending in Social
  Networks</title><categories>cs.SI cs.CR</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many proximity-based mobile social networks are developed to facilitate
connections between any two people, or to help a user to find people with
matched profile within a certain distance. A challenging task in these
applications is to protect the privacy the participants' profiles and personal
interests.
  In this paper, we design novel mechanisms, when given a preference-profile
submitted by a user, that search a person with matching-profile in
decentralized multi-hop mobile social networks. Our mechanisms are
privacy-preserving: no participants' profile and the submitted
preference-profile are exposed. Our mechanisms establish a secure communication
channel between the initiator and matching users at the time when the matching
user is found. Our rigorous analysis shows that our mechanism is secure,
privacy-preserving, verifiable, and efficient both in communication and
computation. Extensive evaluations using real social network data, and actual
system implementation on smart phones show that our mechanisms are
significantly more efficient then existing solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7208</identifier>
 <datestamp>2013-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7208</id><created>2012-07-31</created><updated>2013-01-18</updated><authors><author><keyname>Blaszczyszyn</keyname><forenames>Bartlomiej</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Karray</keyname><forenames>Mohamed Kadhem</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Keeler</keyname><forenames>Holger Paul</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Using Poisson processes to model lattice cellular networks</title><categories>math.PR cs.NI</categories><proxy>ccsd</proxy><journal-ref>INFOCOM - The 32nd IEEE International Conference on Computer
  Communications (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An almost ubiquitous assumption made in the stochastic-analytic study of the
quality of service in cellular networks is Poisson distribution of base
stations. It is usually justified by various irregularities in the real
placement of base stations, which ideally should form the hexagonal pattern. We
provide a different and rigorous argument justifying the Poisson assumption
under sufficiently strong log-normal shadowing observed in the network, in the
evaluation of a natural class of the typical-user service-characteristics
including its SINR. Namely, we present a Poisson-convergence result for a broad
range of stationary (including lattice) networks subject to log-normal
shadowing of increasing variance. We show also for the Poisson model that the
distribution of all these characteristics does not depend on the particular
form of the additional fading distribution. Our approach involves a mapping of
2D network model to 1D image of it &quot;perceived&quot; by the typical user. For this
image we prove our convergence result and the invariance of the Poisson limit
with respect to the distribution of the additional shadowing or fading.
Moreover, we present some new results for Poisson model allowing one to
calculate the distribution function of the SINR in its whole domain. We use
them to study and optimize the mean energy efficiency in cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7213</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7213</id><created>2012-07-31</created><updated>2012-11-26</updated><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author></authors><title>The power of linear programming for valued CSPs: a constructive
  characterization</title><categories>cs.CC</categories><comments>added Remark 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of valued constraint satisfaction problems (VCSPs) is characterised
by a valued constraint language, a fixed set of cost functions on a finite
domain. An instance of the problem is specified by a sum of cost functions from
the language with the goal to minimise the sum.
  We study which classes of finite-valued languages can be solved exactly by
the basic linear programming relaxation (BLP). Thapper and Zivny showed [20]
that if BLP solves the language then the language admits a binary commutative
fractional polymorphism. We prove that the converse is also true. This leads to
a necessary and a sufficient condition which can be checked in polynomial time
for a given language. In contrast, the previous necessary and sufficient
condition due to [20] involved infinitely many inequalities.
  More recently, Thapper and Zivny [21] showed (using, in particular, a
technique introduced in this paper) that core languages that do not satisfy our
condition are NP-hard. Taken together, these results imply that a finite-valued
language can either be solved using Linear Programming or is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7219</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7219</id><created>2012-07-31</created><updated>2015-03-19</updated><authors><author><keyname>Blaszczyszyn</keyname><forenames>Bartlomiej</forenames><affiliation>INRIA Paris-Rocquencourt</affiliation></author><author><keyname>Muhlethaler</keyname><forenames>Paul</forenames><affiliation>INRIA Paris-Rocquencourt</affiliation></author></authors><title>Random linear multihop relaying in a general field of interferers using
  spatial Aloha</title><categories>cs.NI math.PR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our basic model, we study a stationary Poisson pattern of nodes on a line
embedded in an independent planar Poisson field of interfering nodes. Assuming
slotted Aloha and the signal-to-interference-and-noise ratio capture condition,
with the usual power-law path loss model and Rayleigh fading, we explicitly
evaluate several local and end-to-end performance characteristics related to
the nearest-neighbor packet relaying on this line, and study their dependence
on the model parameters (the density of relaying and interfering nodes, Aloha
tuning and the external noise power). Our model can be applied in two cases:
the first use is for vehicular ad-hoc networks, where vehicles are randomly
located on a straight road. The second use is to study a typical route traced
in a (general) planar ad-hoc network by some routing mechanism. The approach we
have chosen allows us to quantify the non-efficiency of long-distance routing
in pure ad-hoc networks and evaluate a possible remedy for it in the form of
additional fixed relaying nodes, called road-side units in a vehicular network.
It also allows us to consider a more general field of interfering nodes and
study the impact of the clustering of its nodes the routing performance. As a
special case of a field with more clustering than the Poison field, we consider
a Poisson-line field of interfering nodes, in which all the nodes are randomly
located on random straight lines. The comparison to our basic model reveals a
paradox: clustering of interfering nodes decreases the outage probability of a
single (typical) transmission on the route, but increases the mean end-to-end
delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7222</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7222</id><created>2012-07-31</created><authors><author><keyname>Shiozaki</keyname><forenames>Akira</forenames></author></authors><title>Multi-Dimensional Nonsystematic Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new class of multi-dimensional nonsystematic
Reed-Solomon codes that are constructed based on the multi-dimensional Fourier
transform over a finite field. The proposed codes are the extension of the
nonsystematic Reed-Solomon codes to multi-dimension. This paper also discusses
the performance of the multi-dimensional nonsystematic Reed-Solomon codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7241</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7241</id><created>2012-06-17</created><authors><author><keyname>Kamei</keyname><forenames>Sayaka</forenames><affiliation>MIS</affiliation></author><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>MIS</affiliation></author><author><keyname>Ooshita</keyname><forenames>Fukuhito</forenames></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>Gathering an even number of robots in an odd ring without global
  multiplicity detection</title><categories>cs.DC cs.RO</categories><comments>arXiv admin note: text overlap with arXiv:1104.5660</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a gathering protocol for an even number of robots in a ring-shaped
network that allows symmetric but not periodic configurations as initial
configurations, yet uses only local weak multiplicity detection. Robots are
assumed to be anonymous and oblivious, and the execution model is the non-
atomic CORDA model with asynchronous fair scheduling. In our scheme, the number
of robots k must be greater than 8, the number of nodes n on a network must be
odd and greater than k+3. The running time of our protocol is O(n2)
asynchronous rounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7242</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7242</id><created>2012-06-07</created><authors><author><keyname>Al-Karkhi</keyname><forenames>Ameera</forenames></author><author><keyname>Al-Yasiri</keyname><forenames>Adil</forenames></author><author><keyname>Linge</keyname><forenames>Nigel</forenames></author></authors><title>Privacy, Trust and Identity in Pervasive Computing: A Review of
  Technical Challenges and Future Research Directions</title><categories>cs.CR</categories><comments>published 2012</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Developments in pervasive computing introduced a new world of computing where
networked processors embedded and distributed in everyday objects communicating
with each other over wireless links. Computers in such environments work in the
background while establishing connections among them dynamically and hence will
be less visible and intrusive. Such a vision raises questions about how to
manage issues like privacy, trust and identity in those environments. In this
paper, we review the technical challenges that face pervasive computing
environments in relation to each of these issues. We then present a number of
security related considerations and use them as a basis for comparison between
pervasive and traditional computing. We will argue that these considerations
pose particular concerns and challenges to the design and implementation of
pervasive environments which are different to those usually found in
traditional computing environments. To address these concerns and challenges,
further research is needed. We will present a number of directions and topics
for possible future research with respect to each of the three issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7244</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7244</id><created>2012-06-29</created><authors><author><keyname>Cao</keyname><forenames>Liujuan</forenames></author></authors><title>Visual Vocabulary Learning and Its Application to 3D and Mobile Visual
  Search</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this technical report, we review related works and recent trends in visual
vocabulary based web image search, object recognition, mobile visual search,
and 3D object retrieval. Especial focuses would be also given for the recent
trends in supervised/unsupervised vocabulary optimization, compact descriptor
for visual search, as well as in multi-view based 3D object representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7245</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7245</id><created>2012-07-16</created><authors><author><keyname>Mao</keyname><forenames>Xinhua</forenames></author><author><keyname>Zhu</keyname><forenames>Daiyin</forenames></author><author><keyname>Zhu</keyname><forenames>Zhaoda</forenames></author></authors><title>Autofocus Correction of Azimuth Phase Error and Residual Range Cell
  Migration in Spotlight SAR Polar Format Imagery</title><categories>astro-ph.IM cs.CV</categories><comments>29 pages, 14 figures</comments><journal-ref>Aerospace and Electronic Systems, IEEE Transactions on (Volume:49
  , Issue: 4 ), 2013</journal-ref><doi>10.1109/TAES.2013.6621846</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthetic aperture radar (SAR) images are often blurred by phase
perturbations induced by uncompensated sensor motion and /or unknown
propagation effects caused by turbulent media. To get refocused images,
autofocus proves to be useful post-processing technique applied to estimate and
compensate the unknown phase errors. However, a severe drawback of the
conventional autofocus algorithms is that they are only capable of removing
one-dimensional azimuth phase errors (APE). As the resolution becomes finer,
residual range cell migration (RCM), which makes the defocus inherently
two-dimensional, becomes a new challenge. In this paper, correction of APE and
residual RCM are presented in the framework of polar format algorithm (PFA).
First, an insight into the underlying mathematical mechanism of polar
reformatting is presented. Then based on this new formulation, the effect of
polar reformatting on the uncompensated APE and residual RCM is investigated in
detail. By using the derived analytical relationship between APE and residual
RCM, an efficient two-dimensional (2-D) autofocus method is proposed.
Experimental results indicate the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7251</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7251</id><created>2012-07-31</created><updated>2013-06-10</updated><authors><author><keyname>Fotouhi</keyname><forenames>Babak</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>Dynamics of Influence on Hierarchical Structures</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><journal-ref>Physical Review E 88 (2013) 022105</journal-ref><doi>10.1103/PhysRevE.88.022105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dichotomous spin dynamics on a pyramidal hierarchical structure (the Bethe
lattice) are studied. The system embodies a number of \emph{classes}, where a
class comprises of nodes that are equidistant from the root (head node).
Weighted links exist between nodes from the same and different classes. The
spin (hereafter, \emph{state}) of the head node is fixed. We solve for the
dynamics of the system for different boundary conditions. We find necessary
conditions so that the classes eventually repudiate or acquiesce in the state
imposed by the head node. The results indicate that to reach unanimity across
the hierarchy, it suffices that the bottom-most class adopts the same state as
the head node. Then the rest of the hierarchy will inevitably comply. This also
sheds light on the importance of mass media as a means of synchronization
between the top-most and bottom-most classes. Surprisingly, in the case of
discord between the head node and the bottom-most classes, the average state
over all nodes inclines towards that of the bottom-most class regardless of the
link weights and intra-class configurations. Hence the role of the bottom-most
class is signified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7253</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7253</id><created>2012-07-31</created><authors><author><keyname>Gigu&#xe8;re</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Marchand</keyname><forenames>Mario</forenames></author><author><keyname>Laviolette</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Drouin</keyname><forenames>Alexandre</forenames></author><author><keyname>Corbeil</keyname><forenames>Jacques</forenames></author></authors><title>Learning a peptide-protein binding affinity predictor with kernel ridge
  regression</title><categories>q-bio.QM cs.LG q-bio.BM stat.ML</categories><comments>22 pages, 4 figures, 5 tables</comments><msc-class>92B05</msc-class><acm-class>I.2.6; J.3; G.3; G.4; I.5.2</acm-class><journal-ref>BMC Bioinformatics 2013, 14:82</journal-ref><doi>10.1186/1471-2105-14-82</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a specialized string kernel for small bio-molecules, peptides and
pseudo-sequences of binding interfaces. The kernel incorporates
physico-chemical properties of amino acids and elegantly generalize eight
kernels, such as the Oligo, the Weighted Degree, the Blended Spectrum, and the
Radial Basis Function. We provide a low complexity dynamic programming
algorithm for the exact computation of the kernel and a linear time algorithm
for it's approximation. Combined with kernel ridge regression and SupCK, a
novel binding pocket kernel, the proposed kernel yields biologically relevant
and good prediction accuracy on the PepX database. For the first time, a
machine learning predictor is capable of accurately predicting the binding
affinity of any peptide to any protein. The method was also applied to both
single-target and pan-specific Major Histocompatibility Complex class II
benchmark datasets and three Quantitative Structure Affinity Model benchmark
datasets.
  On all benchmarks, our method significantly (p-value &lt; 0.057) outperforms the
current state-of-the-art methods at predicting peptide-protein binding
affinities. The proposed approach is flexible and can be applied to predict any
quantitative biological activity. The method should be of value to a large
segment of the research community with the potential to accelerate
peptide-based drug and vaccine development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7255</identifier>
 <datestamp>2012-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7255</id><created>2012-07-30</created><updated>2012-10-17</updated><authors><author><keyname>Han</keyname><forenames>Jingjun</forenames></author></authors><title>A Simple Quantifier-free Formula of Positive Semidefinite Cyclic Ternary
  Quartic Forms</title><categories>cs.LO math.AG</categories><comments>12 pages</comments><msc-class>68W30, 14Q20</msc-class><acm-class>B.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantifier elimination of positive semidefinite cyclic ternary quartic forms
is studied in this paper. We solve the problem by the theory of complete
discrimination systems, function \RealTriangularize in Maple15 and the
so-called Criterions on Equality of Symmetric Inequalities method. The
equivalent simple quantifier-free formula is proposed and is difficult to
obtain automatically by previous methods or quantifier elimination tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7261</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7261</id><created>2012-07-31</created><authors><author><keyname>Chmiel</keyname><forenames>Anna</forenames></author><author><keyname>Ho&#x142;yst</keyname><forenames>Janusz A.</forenames></author></authors><title>Dynamical phase transition due to preferential cluster growth of
  collective emotions in online communities</title><categories>physics.soc-ph cs.SI</categories><comments>7 pages,7 figures</comments><doi>10.1103/PhysRevE.87.022808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a preferential cluster growth in a one-dimensional stochastic
model describing the dynamics of a binary chain with long-range memory. The
model is driven by data corresponding to emotional patterns observed during
online communities' discussions. The system undergoes a dynamical phase
transition. For low values of the preference exponent, both states are observed
during the string evolution in the majority of simulated discussion threads.
When the exponent crosses a critical value, in the majority of threads an
ordered phase emerges, i.e. from a certain time moment only one state is
represented. The transition becomes discontinuous in the thermodynamical limit
when the discussions are infinitely long and even an infinitely small
preference exponent leads to the ordering behavior in every discussion thread.
Numerical simulations are in a good agreement with approximated analytical
formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7264</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7264</id><created>2012-07-30</created><authors><author><keyname>Alglave</keyname><forenames>Jade</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author><author><keyname>Nimal</keyname><forenames>Vincent</forenames></author><author><keyname>Tautschnig</keyname><forenames>Michael</forenames></author></authors><title>Software Verification for Weak Memory via Program Transformation</title><categories>cs.LO cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite multiprocessors implementing weak memory models, verification methods
often assume Sequential Consistency (SC), thus may miss bugs due to weak
memory. We propose a sound transformation of the program to verify, enabling SC
tools to perform verification w.r.t. weak memory. We present experiments for a
broad variety of models (from x86/TSO to Power/ARM) and a vast range of
verification tools, quantify the additional cost of the transformation and
highlight the cases when we can drastically reduce it. Our benchmarks include
work-queue management code from PostgreSQL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7274</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7274</id><created>2012-07-31</created><authors><author><keyname>Salath&#xe9;</keyname><forenames>Marcel</forenames></author><author><keyname>Vu</keyname><forenames>Duy Q.</forenames></author><author><keyname>Khandelwal</keyname><forenames>Shashank</forenames></author><author><keyname>Hunter</keyname><forenames>David R.</forenames></author></authors><title>The Dynamics of Health Behavior Sentiments on a Large Online Social
  Network</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modifiable health behaviors, a leading cause of illness and death in many
countries, are often driven by individual beliefs and sentiments about health
and disease. Individual behaviors affecting health outcomes are increasingly
modulated by social networks, for example through the associations of
like-minded individuals - homophily - or through peer influence effects. Using
a statistical approach to measure the individual temporal effects of a large
number of variables pertaining to social network statistics, we investigate the
spread of a health sentiment towards a new vaccine on Twitter, a large online
social network. We find that the effects of neighborhood size and exposure
intensity are qualitatively very different depending on the type of sentiment.
Generally, we find that larger numbers of opinionated neighbors inhibit the
expression of sentiments. We also find that exposure to negative sentiment is
contagious - by which we merely mean predictive of future negative sentiment
expression - while exposure to positive sentiments is generally not. In fact,
exposure to positive sentiments can even predict increased negative sentiment
expression. Our results suggest that the effects of peer influence and social
contagion on the dynamics of behavioral spread on social networks are strongly
content-dependent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7281</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7281</id><created>2012-07-28</created><authors><author><keyname>Chitikela</keyname><forenames>Sindhu</forenames></author></authors><title>Noise Analysis for two Quantum Cryptography Protocols</title><categories>quant-ph cs.CR</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents noise analysis for the two-stage and the three-stage
quantum cryptographic protocols based on random polarization rotations. The
noise model used is that of uniform distribution of error over a certain small
range that is associated with each link without regard for the source of the
error. The noise in different links is taken to be independent. Advantages of
the use of these protocols in low intensity laser systems are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7298</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7298</id><created>2012-07-31</created><authors><author><keyname>Yang</keyname><forenames>Yang</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Throughput of Rateless Codes over Broadcast Erasure Channels</title><categories>cs.NI cs.IT math.IT</categories><comments>Submitted to IEEE/ACM Transactions on Networking (July 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we characterize the throughput of a broadcast network with n
receivers using rateless codes with block size K. We assume that the underlying
channel is a Markov modulated erasure channel that is i.i.d. across users, but
can be correlated in time. We characterize the system throughput asymptotically
in n. Specifically, we explicitly show how the throughput behaves for different
values of the coding block size K as a function of n, as n approaches infinity.
For finite values of K and n, under the more restrictive assumption of
Gilbert-Elliott channels, we are able to provide a lower bound on the maximum
achievable throughput. Using simulations we show the tightness of the bound
with respect to system parameters n and K, and find that its performance is
significantly better than the previously known lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7304</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7304</id><created>2012-07-31</created><authors><author><keyname>Idoudi</keyname><forenames>Hanen</forenames></author><author><keyname>Houaidia</keyname><forenames>Chiraz</forenames></author><author><keyname>Saidane</keyname><forenames>Leila Azouz</forenames></author><author><keyname>Minet</keyname><forenames>Pascale</forenames></author></authors><title>Robots-Assisted Redeployment in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>Journal of Networking Technology, Dline, Vol. 3, No. 1, March 2012</comments><journal-ref>Journal of Networking Technology, Dline, Vol. 3, No. 1, March 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectivity and coverage are two crucial problems for wireless sensor
networks. Several studies have focused on proposing solutions for improving and
adjusting the initial deployment of a wireless sensor network to meet these two
criteria. In our work, we propose a new hierarchical architecture for sensor
networks that facilitates the gathering of redundancy information of the
topology. Several mobile robots must then relocate, in an optimized way,
redundant sensors to achieve optimal connectivity and coverage of the network.
Mobile robots have to cooperate and coordinate their movement. A performance
evaluation is conducted to study the trade-off between the number of required
robots and its impact on the rate of network connectivity and coverage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7321</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7321</id><created>2012-07-31</created><updated>2015-03-17</updated><authors><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Lelarge</keyname><forenames>Marc</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Universality in polytope phase transitions and message passing
  algorithms</title><categories>math.PR cs.IT math.IT</categories><comments>Published in at http://dx.doi.org/10.1214/14-AAP1010 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP1010</report-no><journal-ref>Annals of Applied Probability 2015, Vol. 25, 753-822</journal-ref><doi>10.1214/14-AAP1010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of nonlinear mappings $\mathsf{F}_{A,N}$ in
$\mathbb{R}^N$ indexed by symmetric random matrices $A\in\mathbb{R}^{N\times
N}$ with independent entries. Within spin glass theory, special cases of these
mappings correspond to iterating the TAP equations and were studied by
Bolthausen [Comm. Math. Phys. 325 (2014) 333-366]. Within information theory,
they are known as &quot;approximate message passing&quot; algorithms. We study the
high-dimensional (large $N$) behavior of the iterates of $\mathsf{F}$ for
polynomial functions $\mathsf{F}$, and prove that it is universal; that is, it
depends only on the first two moments of the entries of $A$, under a
sub-Gaussian tail condition. As an application, we prove the universality of a
certain phase transition arising in polytope geometry and compressed sensing.
This solves, for a broad class of random projections, a conjecture by David
Donoho and Jared Tanner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.7347</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.7347</id><created>2012-07-31</created><authors><author><keyname>Maleh</keyname><forenames>Ray</forenames></author><author><keyname>Fudge</keyname><forenames>Gerald L.</forenames></author></authors><title>RIP Analysis of Modulated Sampling Schemes for Recovering Spectrally
  Sparse Signals</title><categories>cs.IT cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we analyze modulated sampling schemes, such as the Nyquist
Folding Receiver, which are highly efficient, readily implementable,
non-uniform sampling schemes that allows for the blind estimation of a
narrow-band signal's spectral content and location in a wide-band environment.
This non-uniform sampling, achieved by narrow-band modulation of the RF
instantaneous sample rate, results in a frequency domain point spread function
that is between the extremes obtained by uniform sampling and totally random
sampling. As a result, while still preserving structured aliasing, the
modulated sampling scheme is also useful in a compressive sensing (CS) setting.
We estimate restricted isometry property (RIP) constants for CS matrices
induced by such modulated sampling schemes and use those estimates to determine
the amount of sparsity needed for signal recovery. This is followed by a
demonstration and analysis of Orthogonal Matching Pursuit's ability to
reconstruct signals from noisy non-uniform samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0044</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0044</id><created>2012-07-09</created><authors><author><keyname>Hammami</keyname><forenames>Mouti</forenames></author></authors><title>Maintenance de l'outil Wr2fdr de traduction de Wright vers CSP</title><categories>cs.SE</categories><comments>arXiv admin note: substantial text overlap with arXiv:1207.7121,
  arXiv:1207.6831 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of formal ADL like Wright is critically dependent on the tools that
are made available to architects. The Wr2fdr tools accompanying the formal
Wright ADL provides translation to Wright to CSP. Wr2fdr automates four
standard properties concerning consistency Connectors (properties 2 and 3),
Component (a property 1) and Configuration Management (Property 8) Wright using
the model checker FDR. After conducting an audit activity of this tool, we were
able to correct errors related to both properties 2 and 3. In addition, we
proposed an implementation of both properties 1 and 8. Finally, we added the
tool Wr2fdr with a semantic analyzer of Wright.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0053</identifier>
 <datestamp>2014-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0053</id><created>2012-07-31</created><updated>2014-06-16</updated><authors><author><keyname>Sharir</keyname><forenames>Micha</forenames></author><author><keyname>Sheffer</keyname><forenames>Adam</forenames></author><author><keyname>Zahl</keyname><forenames>Joshua</forenames></author></authors><title>Improved bounds for incidences between points and circles</title><categories>math.CO cs.CG</categories><doi>10.1017/S0963548314000534</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish an improved upper bound for the number of incidences between m
points and n circles in three dimensions. The previous best known bound,
originally established for the planar case and later extended to any dimension
$\ge 2$, is $O*(m^{2/3}n^{2/3} + m^{6/11}n^{9/11}+m+n)$, where the $O*(\cdot)$
notation hides sub-polynomial factors. Since all the points and circles may lie
on a common plane (or sphere), it is impossible to improve the bound in R^3
without first improving it in the plane.
  Nevertheless, we show that if the set of circles is required to be &quot;truly
three-dimensional&quot; in the sense that no sphere or plane contains more than $q$
of the circles, for some $q &lt;&lt; n$, then the bound can be improved to
\[O*(m^{3/7}n^{6/7} + m^{2/3}n^{1/2}q^{1/6} + m^{6/11}n^{15/22}q^{3/22} + m +
n). \]
  For various ranges of parameters (e.g., when $m=\Theta(n)$ and $q =
o(n^{7/9})$), this bound is smaller than the lower bound
$\Omega*(m^{2/3}n^{2/3}+m+n)$, which holds in two dimensions.
  We present several extensions and applications of the new bound: (i) For the
special case where all the circles have the same radius, we obtain the improved
bound $O*(m^{5/11}n^{9/11} + m^{2/3}n^{1/2}q^{1/6} + m + n$. (ii) We present an
improved analysis that removes the subpolynomial factors from the bound when
$m=O(n^{3/2-\eps})$ for any fixed $\varepsilon &gt;0$. (iii) We use our results to
obtain the improved bound $O(m^{15/7})$ for the number of mutually similar
triangles determined by any set of $m$ points in R^3.
  Our result is obtained by applying the polynomial partitioning technique of
Guth and Katz using a constant-degree partitioning polynomial (as was also
recently used by Solymosi and Tao). We also rely on various additional tools
from analytic, algebraic, and combinatorial geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0054</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0054</id><created>2012-07-31</created><authors><author><keyname>Han</keyname><forenames>JunZe</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author></authors><title>Network Agile Preference-Based Prefetching for Mobile Devices</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For mobile devices, communication via cellular networks consumes more energy,
and has a lower data rate than WiFi networks, and suffers an expensive limited
data plan. However the WiFi network coverage range and density are smaller than
those of the cellular networks. In this work, we present a behavior-aware and
preference-based approach to prefetch news webpages that a user will be
interested in and access, by exploiting the WiFi network connections to reduce
the energy and monetary cost. In our solution, we first design an efficient
preference learning algorithm based on keywords and URLs visited, which will
keep track of the user's changing interests. By predicting the appearance and
durations of the WiFi network connections, our prefetch approach then optimizes
when to prefetch what webpages to maximize the user experience while lowing the
prefetch cost. Our prefetch approach exploits the idle period of WiFi
connections to reduce the tail-energy consumption. We implement our approach in
iPhone. Our extensive evaluations show that our system achieves about 60% hit
ratio, saves about 50% cellular data usage, and reduces the energy cost by 9%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0055</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0055</id><created>2012-07-31</created><authors><author><keyname>Choudhury</keyname><forenames>Sutanay</forenames></author><author><keyname>Holder</keyname><forenames>Lawrence</forenames></author><author><keyname>Chin</keyname><forenames>George</forenames></author><author><keyname>Feo</keyname><forenames>John</forenames></author></authors><title>Large-scale continuous subgraph queries on streams</title><categories>cs.DB cs.DC</categories><journal-ref>In Proceedings of the first annual workshop on High performance
  computing meets databases (HPCDB 2011). ACM, New York, NY, USA, 29-32</journal-ref><doi>10.1145/2125636.2125647</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Graph pattern matching involves finding exact or approximate matches for a
query subgraph in a larger graph. It has been studied extensively and has
strong applications in domains such as computer vision, computational biology,
social networks, security and finance. The problem of exact graph pattern
matching is often described in terms of subgraph isomorphism which is
NP-complete. The exponential growth in streaming data from online social
networks, news and video streams and the continual need for situational
awareness motivates a solution for finding patterns in streaming updates. This
is also the prime driver for the real-time analytics market. Development of
incremental algorithms for graph pattern matching on streaming inputs to a
continually evolving graph is a nascent area of research. Some of the
challenges associated with this problem are the same as found in continuous
query (CQ) evaluation on streaming databases. This paper reviews some of the
representative work from the exhaustively researched field of CQ systems and
identifies important semantics, constraints and architectural features that are
also appropriate for HPC systems performing real-time graph analytics. For each
of these features we present a brief discussion of the challenge encountered in
the database realm, the approach to the solution and state their relevance in a
high-performance, streaming graph processing framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0063</identifier>
 <datestamp>2013-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0063</id><created>2012-07-31</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author></authors><title>Capacity Results for Two Classes of Three-Way Channels</title><categories>cs.IT math.IT</categories><comments>Author's final version (accepted for presentation at IEEE 12th
  International Symposium on Communications and Information Technologies [ISCIT
  2012])</comments><journal-ref>Proceedings of the 12th International Symposium on Communications
  &amp; Information Technologies (ISCIT 2012), Gold Coast, Australia, pp. 471-476,
  2012</journal-ref><doi>10.1109/ISCIT.2012.6380944</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the three-way channel, consisting of three nodes, where
each node broadcasts a message to the two other nodes. The capacity of the
finite-field three-way channel is derived, and is shown to be achievable using
a non-cooperative scheme without feedback. The same scheme is also shown to
achieve the equal-rate capacity (when all nodes transmit at the same rate) of
the sender-symmetrical (each node receives the same SNR from the other two
nodes) phase-fading AWGN channel. In the light that the non-cooperative scheme
is not optimal in general, a cooperative feedback scheme that utilizes relaying
and network coding is proposed and is shown to achieve the equal-rate capacity
of the reciprocal (each pair of nodes has the same forward and backward SNR)
phase-fading AWGN three-way channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0070</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0070</id><created>2012-07-31</created><authors><author><keyname>Dara</keyname><forenames>Sashank</forenames></author></authors><title>Confidentiality without Encryption For Cloud Computational Privacy</title><categories>cs.CR</categories><comments>3 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Advances in technology has given rise to new computing models where any
individual/organization (Cloud Service Consumers here by denoted as CSC's) can
outsource their computational intensive tasks on their data to a remote Cloud
Service Provider (CSP) for many advantages like lower costs, scalability etc.
But such advantages come for a bigger cost &quot;Security and Privacy of data&quot; for
this very reason many CSC's are skeptical to move towards cloud computing
models. While the advances in cryptography research are promising, there are no
practical solutions yet for performing any operations on encrypted data [1].
For this very reason there is strong need for finding alternative viable
solutions for us to benefit from Cloud Computing. A technique to provide
confidentiality without encryption was proposed in the past namely &quot;Chaffing
and Winnowing: Confidentiality without Encryption&quot; by Ronald L. Rivest [2].
While this technique has been proposed for packet based communication system,
its not adaptable in all cloud service models like Software-as-Service,
Platform-as-Service or Infrastructure-as-Service [3]. In this paper we propose
an adaptation of this technique in a cloud computational setup where CSC's
outsource computational intensive tasks like web log parsing, DNA Sequencing
etc to a MapReduce like CSP service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0072</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0072</id><created>2012-07-31</created><authors><author><keyname>Badr</keyname><forenames>Ahmed</forenames></author><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Tan</keyname><forenames>Wai-Tian</forenames></author><author><keyname>Apostolopoulos</keyname><forenames>John</forenames></author></authors><title>Streaming Codes for Channels with Burst and Isolated Erasures</title><categories>cs.IT cs.MM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study low-delay error correction codes for streaming recovery over a class
of packet-erasure channels that introduce both burst-erasures and isolated
erasures. We propose a simple, yet effective class of codes whose parameters
can be tuned to obtain a tradeoff between the capability to correct burst and
isolated erasures. Our construction generalizes previously proposed low-delay
codes which are effective only against burst erasures. We establish an
information theoretic upper bound on the capability of any code to
simultaneously correct burst and isolated erasures and show that our proposed
constructions meet the upper bound in some special cases. We discuss the
operational significance of column-distance and column-span metrics and
establish that the rate 1/2 codes discovered by Martinian and Sundberg [IT
Trans.\, 2004] through a computer search indeed attain the optimal
column-distance and column-span tradeoff. Numerical simulations over a
Gilbert-Elliott channel model and a Fritchman model show significant
performance gains over previously proposed low-delay codes and random linear
codes for certain range of channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0073</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0073</id><created>2012-07-31</created><authors><author><keyname>Choi</keyname><forenames>Dong-Wan</forenames></author><author><keyname>Chung</keyname><forenames>Chin-Wan</forenames></author><author><keyname>Tao</keyname><forenames>Yufei</forenames></author></authors><title>A Scalable Algorithm for Maximizing Range Sum in Spatial Databases</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1088-1099 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the MaxRS problem in spatial databases. Given a set O
of weighted points and a rectangular region r of a given size, the goal of the
MaxRS problem is to find a location of r such that the sum of the weights of
all the points covered by r is maximized. This problem is useful in many
location-based applications such as finding the best place for a new franchise
store with a limited delivery range and finding the most attractive place for a
tourist with a limited reachable range. However, the problem has been studied
mainly in theory, particularly, in computational geometry. The existing
algorithms from the computational geometry community are in-memory algorithms
which do not guarantee the scalability. In this paper, we propose a scalable
external-memory algorithm (ExactMaxRS) for the MaxRS problem, which is optimal
in terms of the I/O complexity. Furthermore, we propose an approximation
algorithm (ApproxMaxCRS) for the MaxCRS problem that is a circle version of the
MaxRS problem. We prove the correctness and optimality of the ExactMaxRS
algorithm along with the approximation bound of the ApproxMaxCRS algorithm.
From extensive experimental results, we show that the ExactMaxRS algorithm is
two orders of magnitude faster than methods adapted from existing algorithms,
and the approximation bound in practice is much better than the theoretical
bound of the ApproxMaxCRS algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0074</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0074</id><created>2012-07-31</created><authors><author><keyname>Aly</keyname><forenames>Ahmed M.</forenames></author><author><keyname>Aref</keyname><forenames>Walid G.</forenames></author><author><keyname>Ouzzani</keyname><forenames>Mourad</forenames></author></authors><title>Spatial Queries with Two kNN Predicates</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1100-1111 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread use of location-aware devices has led to countless
location-based services in which a user query can be arbitrarily complex, i.e.,
one that embeds multiple spatial selection and join predicates. Amongst these
predicates, the k-Nearest-Neighbor (kNN) predicate stands as one of the most
important and widely used predicates. Unlike related research, this paper goes
beyond the optimization of queries with single kNN predicates, and shows how
queries with two kNN predicates can be optimized. In particular, the paper
addresses the optimization of queries with: (i) two kNN-select predicates, (ii)
two kNN-join predicates, and (iii) one kNN-join predicate and one kNN-select
predicate. For each type of queries, conceptually correct query evaluation
plans (QEPs) and new algorithms that optimize the query execution time are
presented. Experimental results demonstrate that the proposed algorithms
outperform the conceptually correct QEPs by orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0075</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0075</id><created>2012-07-31</created><authors><author><keyname>Sheng</keyname><forenames>Cheng</forenames></author><author><keyname>Zhang</keyname><forenames>Nan</forenames></author><author><keyname>Tao</keyname><forenames>Yufei</forenames></author><author><keyname>Jin</keyname><forenames>Xin</forenames></author></authors><title>Optimal Algorithms for Crawling a Hidden Database in the Web</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1112-1123 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hidden database refers to a dataset that an organization makes accessible
on the web by allowing users to issue queries through a search interface. In
other words, data acquisition from such a source is not by following static
hyper-links. Instead, data are obtained by querying the interface, and reading
the result page dynamically generated. This, with other facts such as the
interface may answer a query only partially, has prevented hidden databases
from being crawled effectively by existing search engines. This paper remedies
the problem by giving algorithms to extract all the tuples from a hidden
database. Our algorithms are provably efficient, namely, they accomplish the
task by performing only a small number of queries, even in the worst case. We
also establish theoretical results indicating that these algorithms are
asymptotically optimal -- i.e., it is impossible to improve their efficiency by
more than a constant factor. The derivation of our upper and lower bound
results reveals significant insight into the characteristics of the underlying
problem. Extensive experiments confirm the proposed techniques work very well
on all the real datasets examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0076</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0076</id><created>2012-07-31</created><authors><author><keyname>Qin</keyname><forenames>Lu</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author><author><keyname>Chang</keyname><forenames>Lijun</forenames></author></authors><title>Diversifying Top-K Results</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1124-1135 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Top-k query processing finds a list of k results that have largest scores
w.r.t the user given query, with the assumption that all the k results are
independent to each other. In practice, some of the top-k results returned can
be very similar to each other. As a result some of the top-k results returned
are redundant. In the literature, diversified top-k search has been studied to
return k results that take both score and diversity into consideration. Most
existing solutions on diversified top-k search assume that scores of all the
search results are given, and some works solve the diversity problem on a
specific problem and can hardly be extended to general cases. In this paper, we
study the diversified top-k search problem. We define a general diversified
top-k search problem that only considers the similarity of the search results
themselves. We propose a framework, such that most existing solutions for top-k
query processing can be extended easily to handle diversified top-k search, by
simply applying three new functions, a sufficient stop condition sufficient(),
a necessary stop condition necessary(), and an algorithm for diversified top-k
search on the current set of generated results, div-search-current(). We
propose three new algorithms, namely, div-astar, div-dp, and div-cut to solve
the div-search-current() problem. div-astar is an A* based algorithm, div-dp is
an algorithm that decomposes the results into components which are searched
using div-astar independently and combined using dynamic programming. div-cut
further decomposes the current set of generated results using cut points and
combines the results using sophisticated operations. We conducted extensive
performance studies using two real datasets, enwiki and reuters. Our div-cut
algorithm finds the optimal solution for diversified top-k search problem in
seconds even for k as large as 2,000.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0077</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0077</id><created>2012-07-31</created><authors><author><keyname>Cao</keyname><forenames>Xin</forenames></author><author><keyname>Chen</keyname><forenames>Lisi</forenames></author><author><keyname>Cong</keyname><forenames>Gao</forenames></author><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author></authors><title>Keyword-aware Optimal Route Search</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1136-1147 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying a preferable route is an important problem that finds
applications in map services. When a user plans a trip within a city, the user
may want to find &quot;a most popular route such that it passes by shopping mall,
restaurant, and pub, and the travel time to and from his hotel is within 4
hours.&quot; However, none of the algorithms in the existing work on route planning
can be used to answer such queries. Motivated by this, we define the problem of
keyword-aware optimal route query, denoted by KOR, which is to find an optimal
route such that it covers a set of user-specified keywords, a specified budget
constraint is satisfied, and an objective score of the route is optimal. The
problem of answering KOR queries is NP-hard. We devise an approximation
algorithm OSScaling with provable approximation bounds. Based on this
algorithm, another more efficient approximation algorithm BucketBound is
proposed. We also design a greedy approximation algorithm. Results of empirical
studies show that all the proposed algorithms are capable of answering KOR
queries efficiently, while the BucketBound and Greedy algorithms run faster.
The empirical studies also offer insight into the accuracy of the proposed
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0078</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0078</id><created>2012-07-31</created><authors><author><keyname>Cautis</keyname><forenames>Bogdan</forenames></author><author><keyname>Kharlamov</keyname><forenames>Evgeny</forenames></author></authors><title>Answering Queries using Views over Probabilistic XML: Complexity and
  Tractability</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1148-1159 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of query answering using views in a probabilistic XML
setting, identifying large classes of XPath queries -- with child and
descendant navigation and predicates -- for which there are efficient (PTime)
algorithms. We consider this problem under the two possible semantics for XML
query results: with persistent node identifiers and in their absence.
Accordingly, we consider rewritings that can exploit a single view, by means of
compensation, and rewritings that can use multiple views, by means of
intersection. Since in a probabilistic setting queries return answers with
probabilities, the problem of rewriting goes beyond the classic one of
retrieving XML answers from views. For both semantics of XML queries, we show
that, even when XML answers can be retrieved from views, their probabilities
may not be computable. For rewritings that use only compensation, we describe a
PTime decision procedure, based on easily verifiable criteria that distinguish
between the feasible cases -- when probabilistic XML results are computable --
and the unfeasible ones. For rewritings that can use multiple views, with
compensation and intersection, we identify the most permissive conditions that
make probabilistic rewriting feasible, and we describe an algorithm that is
sound in general, and becomes complete under fairly permissive restrictions,
running in PTime modulo worst-case exponential time equivalence tests. This is
the best we can hope for since intersection makes query equivalence intractable
already over deterministic data. Our algorithm runs in PTime whenever
deterministic rewritings can be found in PTime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0079</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0079</id><created>2012-07-31</created><authors><author><keyname>Jha</keyname><forenames>Abhay</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Probabilistic Databases with MarkoViews</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1160-1171 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the work on query evaluation in probabilistic databases has focused
on the simple tuple-independent data model, where tuples are independent random
events. Several efficient query evaluation techniques exists in this setting,
such as safe plans, algorithms based on OBDDs, tree-decomposition and a variety
of approximation algorithms. However, complex data analytics tasks often
require complex correlations, and query evaluation then is significantly more
expensive, or more restrictive. In this paper, we propose MVDB as a framework
both for representing complex correlations and for efficient query evaluation.
An MVDB specifies correlations by views, called MarkoViews, on the
probabilistic relations and declaring the weights of the view's outputs. An
MVDB is a (very large) Markov Logic Network. We make two sets of contributions.
First, we show that query evaluation on an MVDB is equivalent to evaluating a
Union of Conjunctive Query(UCQ) over a tuple-independent database. The
translation is exact (thus allowing the techniques developed for tuple
independent databases to be carried over to MVDB), yet it is novel and quite
non-obvious (some resulting probabilities may be negative!). This translation
in itself though may not lead to much gain since the translated query gets
complicated as we try to capture more correlations. Our second contribution is
to propose a new query evaluation strategy that exploits offline compilation to
speed up online query evaluation. Here we utilize and extend our prior work on
compilation of UCQ. We validate experimentally our techniques on a large
probabilistic database with MarkoViews inferred from the DBLP data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0080</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0080</id><created>2012-07-31</created><authors><author><keyname>Mamouras</keyname><forenames>Konstantinos</forenames></author><author><keyname>Oren</keyname><forenames>Sigal</forenames></author><author><keyname>Seeman</keyname><forenames>Lior</forenames></author><author><keyname>Kot</keyname><forenames>Lucja</forenames></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames></author></authors><title>The Complexity of Social Coordination</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1172-1183 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordination is a challenging everyday task; just think of the last time you
organized a party or a meeting involving several people. As a growing part of
our social and professional life goes online, an opportunity for an improved
coordination process arises. Recently, Gupta et al. proposed entangled queries
as a declarative abstraction for data-driven coordination, where the difficulty
of the coordination task is shifted from the user to the database.
Unfortunately, evaluating entangled queries is very hard, and thus previous
work considered only a restricted class of queries that satisfy safety (the
coordination partners are fixed) and uniqueness (all queries need to be
satisfied). In this paper we significantly extend the class of feasible
entangled queries beyond uniqueness and safety. First, we show that we can
simply drop uniqueness and still efficiently evaluate a set of safe entangled
queries. Second, we show that as long as all users coordinate on the same set
of attributes, we can give an efficient algorithm for coordination even if the
set of queries does not satisfy safety. In an experimental evaluation we show
that our algorithms are feasible for a wide spectrum of coordination scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0081</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0081</id><created>2012-07-31</created><authors><author><keyname>Zhang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Chen</keyname><forenames>Lei</forenames></author><author><keyname>Wang</keyname><forenames>Min</forenames></author></authors><title>Efficient Multi-way Theta-Join Processing Using MapReduce</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1184-1195 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-way Theta-join queries are powerful in describing complex relations and
therefore widely employed in real practices. However, existing solutions from
traditional distributed and parallel databases for multi-way Theta-join queries
cannot be easily extended to fit a shared-nothing distributed computing
paradigm, which is proven to be able to support OLAP applications over immense
data volumes. In this work, we study the problem of efficient processing of
multi-way Theta-join queries using MapReduce from a cost-effective perspective.
Although there have been some works using the (key,value) pair-based
programming model to support join operations, efficient processing of multi-way
Theta-join queries has never been fully explored. The substantial challenge
lies in, given a number of processing units (that can run Map or Reduce tasks),
mapping a multi-way Theta-join query to a number of MapReduce jobs and having
them executed in a well scheduled sequence, such that the total processing time
span is minimized. Our solution mainly includes two parts: 1) cost metrics for
both single MapReduce job and a number of MapReduce jobs executed in a certain
order; 2) the efficient execution of a chain-typed Theta-join with only one
MapReduce job. Comparing with the query evaluation strategy proposed in [23]
and the widely adopted Pig Latin and Hive SQL solutions, our method achieves
significant improvement of the join processing efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0082</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0082</id><created>2012-07-31</created><authors><author><keyname>Lim</keyname><forenames>Harold</forenames></author><author><keyname>Herodotou</keyname><forenames>Herodotos</forenames></author><author><keyname>Babu</keyname><forenames>Shivnath</forenames></author></authors><title>Stubby: A Transformation-based Optimizer for MapReduce Workflows</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1196-1207 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing trend of performing analysis on large datasets using
workflows composed of MapReduce jobs connected through producer-consumer
relationships based on data. This trend has spurred the development of a number
of interfaces--ranging from program-based to query-based interfaces--for
generating MapReduce workflows. Studies have shown that the gap in performance
can be quite large between optimized and unoptimized workflows. However,
automatic cost-based optimization of MapReduce workflows remains a challenge
due to the multitude of interfaces, large size of the execution plan space, and
the frequent unavailability of all types of information needed for
optimization. We introduce a comprehensive plan space for MapReduce workflows
generated by popular workflow generators. We then propose Stubby, a cost-based
optimizer that searches selectively through the subspace of the full plan space
that can be enumerated correctly and costed based on the information available
in any given setting. Stubby enumerates the plan space based on plan-to-plan
transformations and an efficient search algorithm. Stubby is designed to be
extensible to new interfaces and new types of optimizations, which is a
desirable feature given how rapidly MapReduce systems are evolving. Stubby's
efficiency and effectiveness have been evaluated using representative workflows
from many domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0083</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0083</id><created>2012-07-31</created><authors><author><keyname>Bao</keyname><forenames>Zhuowei</forenames></author><author><keyname>Davidson</keyname><forenames>Susan B.</forenames></author><author><keyname>Milo</keyname><forenames>Tova</forenames></author></authors><title>Labeling Workflow Views with Fine-Grained Dependencies</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1208-1219 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of efficiently answering reachability
queries over views of provenance graphs, derived from executions of workflows
that may include recursion. Such views include composite modules and model
fine-grained dependencies between module inputs and outputs. A novel
view-adaptive dynamic labeling scheme is developed for efficient query
evaluation, in which view specifications are labeled statically (i.e. as they
are created) and data items are labeled dynamically as they are produced during
a workflow execution. Although the combination of fine-grained dependencies and
recursive workflows entail, in general, long (linear-size) data labels, we show
that for a large natural class of workflows and views, labels are compact
(logarithmic-size) and reachability queries can be evaluated in constant time.
Experimental results demonstrate the benefit of this approach over the
state-of-the-art technique when applied for labeling multiple views.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0084</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0084</id><created>2012-07-31</created><authors><author><keyname>Szlichta</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Godfrey</keyname><forenames>Parke</forenames></author><author><keyname>Gryz</keyname><forenames>Jarek</forenames></author></authors><title>Fundamentals of Order Dependencies</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1220-1231 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dependencies have played a significant role in database design for many
years. They have also been shown to be useful in query optimization. In this
paper, we discuss dependencies between lexicographically ordered sets of
tuples. We introduce formally the concept of order dependency and present a set
of axioms (inference rules) for them. We show how query rewrites based on these
axioms can be used for query optimization. We present several interesting
theorems that can be derived using the inference rules. We prove that
functional dependencies are subsumed by order dependencies and that our set of
axioms for order dependencies is sound and complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0086</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0086</id><created>2012-07-31</created><authors><author><keyname>Cao</keyname><forenames>Yu</forenames></author><author><keyname>Chan</keyname><forenames>Chee-Yong</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Tan</keyname><forenames>Kian-Lee</forenames></author></authors><title>Optimization of Analytic Window Functions</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1244-1255 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analytic functions represent the state-of-the-art way of performing complex
data analysis within a single SQL statement. In particular, an important class
of analytic functions that has been frequently used in commercial systems to
support OLAP and decision support applications is the class of window
functions. A window function returns for each input tuple a value derived from
applying a function over a window of neighboring tuples. However, existing
window function evaluation approaches are based on a naive sorting scheme. In
this paper, we study the problem of optimizing the evaluation of window
functions. We propose several efficient techniques, and identify optimization
opportunities that allow us to optimize the evaluation of a set of window
functions. We have integrated our scheme into PostgreSQL. Our comprehensive
experimental study on the TPC-DS datasets as well as synthetic datasets and
queries demonstrate significant speedup over existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0087</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0087</id><created>2012-07-31</created><authors><author><keyname>Hueske</keyname><forenames>Fabian</forenames></author><author><keyname>Peters</keyname><forenames>Mathias</forenames></author><author><keyname>Sax</keyname><forenames>Matthias</forenames></author><author><keyname>Rheinl&#xe4;nder</keyname><forenames>Astrid</forenames></author><author><keyname>Bergmann</keyname><forenames>Rico</forenames></author><author><keyname>Krettek</keyname><forenames>Aljoscha</forenames></author><author><keyname>Tzoumas</keyname><forenames>Kostas</forenames></author></authors><title>Opening the Black Boxes in Data Flow Optimization</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1256-1267 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many systems for big data analytics employ a data flow abstraction to define
parallel data processing tasks. In this setting, custom operations expressed as
user-defined functions are very common. We address the problem of performing
data flow optimization at this level of abstraction, where the semantics of
operators are not known. Traditionally, query optimization is applied to
queries with known algebraic semantics. In this work, we find that a handful of
properties, rather than a full algebraic specification, suffice to establish
reordering conditions for data processing operators. We show that these
properties can be accurately estimated for black box operators by statically
analyzing the general-purpose code of their user-defined functions. We design
and implement an optimizer for parallel data flows that does not assume
knowledge of semantics or algebraic properties of operators. Our evaluation
confirms that the optimizer can apply common rewritings such as selection
reordering, bushy join-order enumeration, and limited forms of aggregation
push-down, hence yielding similar rewriting power as modern relational DBMS
optimizers. Moreover, it can optimize the operator order of non-relational data
flows, a unique feature among today's systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0088</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0088</id><created>2012-07-31</created><authors><author><keyname>Ewen</keyname><forenames>Stephan</forenames></author><author><keyname>Tzoumas</keyname><forenames>Kostas</forenames></author><author><keyname>Kaufmann</keyname><forenames>Moritz</forenames></author><author><keyname>Markl</keyname><forenames>Volker</forenames></author></authors><title>Spinning Fast Iterative Data Flows</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1268-1279 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel dataflow systems are a central part of most analytic pipelines for
big data. The iterative nature of many analysis and machine learning
algorithms, however, is still a challenge for current systems. While certain
types of bulk iterative algorithms are supported by novel dataflow frameworks,
these systems cannot exploit computational dependencies present in many
algorithms, such as graph algorithms. As a result, these algorithms are
inefficiently executed and have led to specialized systems based on other
paradigms, such as message passing or shared memory. We propose a method to
integrate incremental iterations, a form of workset iterations, with parallel
dataflows. After showing how to integrate bulk iterations into a dataflow
system and its optimizer, we present an extension to the programming model for
incremental iterations. The extension alleviates for the lack of mutable state
in dataflows and allows for exploiting the sparse computational dependencies
inherent in many iterative algorithms. The evaluation of a prototypical
implementation shows that those aspects lead to up to two orders of magnitude
speedup in algorithm runtime, when exploited. In our experiments, the improved
dataflow system is highly competitive with specialized systems while
maintaining a transparent and unified dataflow abstraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0089</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0089</id><created>2012-07-31</created><authors><author><keyname>Mihaylov</keyname><forenames>Svilen R.</forenames></author><author><keyname>Ives</keyname><forenames>Zachary G.</forenames></author><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author></authors><title>REX: Recursive, Delta-Based Data-Centric Computation</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1280-1291 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's Web and social network environments, query workloads include ad
hoc and OLAP queries, as well as iterative algorithms that analyze data
relationships (e.g., link analysis, clustering, learning). Modern DBMSs support
ad hoc and OLAP queries, but most are not robust enough to scale to large
clusters. Conversely, &quot;cloud&quot; platforms like MapReduce execute chains of batch
tasks across clusters in a fault tolerant way, but have too much overhead to
support ad hoc queries.
  Moreover, both classes of platform incur significant overhead in executing
iterative data analysis algorithms. Most such iterative algorithms repeatedly
refine portions of their answers, until some convergence criterion is reached.
However, general cloud platforms typically must reprocess all data in each
step. DBMSs that support recursive SQL are more efficient in that they
propagate only the changes in each step -- but they still accumulate each
iteration's state, even if it is no longer useful. User-defined functions are
also typically harder to write for DBMSs than for cloud platforms.
  We seek to unify the strengths of both styles of platforms, with a focus on
supporting iterative computations in which changes, in the form of deltas, are
propagated from iteration to iteration, and state is efficiently updated in an
extensible way. We present a programming model oriented around deltas, describe
how we execute and optimize such programs in our REX runtime system, and
validate that our platform also handles failures gracefully. We experimentally
validate our techniques, and show speedups over the competing methods ranging
from 2.5 to nearly 100 times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0090</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0090</id><created>2012-07-31</created><authors><author><keyname>Cheng</keyname><forenames>James</forenames></author><author><keyname>Shang</keyname><forenames>Zechao</forenames></author><author><keyname>Cheng</keyname><forenames>Hong</forenames></author><author><keyname>Wang</keyname><forenames>Haixun</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author></authors><title>K-Reach: Who is in Your Small World</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1292-1303 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of answering k-hop reachability queries in a directed
graph, i.e., whether there exists a directed path of length k, from a source
query vertex to a target query vertex in the input graph. The problem of k-hop
reachability is a general problem of the classic reachability (where
k=infinity). Existing indexes for processing classic reachability queries, as
well as for processing shortest path queries, are not applicable or not
efficient for processing k-hop reachability queries. We propose an index for
processing k-hop reachability queries, which is simple in design and efficient
to construct. Our experimental results on a wide range of real datasets show
that our index is more efficient than the state-of-the-art indexes even for
processing classic reachability queries, for which these indexes are primarily
designed. We also show that our index is efficient in answering k-hop
reachability queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0091</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0091</id><created>2012-07-31</created><authors><author><keyname>Fan</keyname><forenames>Wenfei</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Wu</keyname><forenames>Yinghui</forenames></author></authors><title>Performance Guarantees for Distributed Reachability Queries</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1304-1315 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the real world a graph is often fragmented and distributed across
different sites. This highlights the need for evaluating queries on distributed
graphs. This paper proposes distributed evaluation algorithms for three classes
of queries: reachability for determining whether one node can reach another,
bounded reachability for deciding whether there exists a path of a bounded
length between a pair of nodes, and regular reachability for checking whether
there exists a path connecting two nodes such that the node labels on the path
form a string in a given regular expression. We develop these algorithms based
on partial evaluation, to explore parallel computation. When evaluating a query
Q on a distributed graph G, we show that these algorithms possess the following
performance guarantees, no matter how G is fragmented and distributed: (1) each
site is visited only once; (2) the total network traffic is determined by the
size of Q and the fragmentation of G, independent of the size of G; and (3) the
response time is decided by the largest fragment of G rather than the entire G.
In addition, we show that these algorithms can be readily implemented in the
MapReduce framework. Using synthetic and real-life data, we experimentally
verify that these algorithms are scalable on large graphs, regardless of how
the graphs are distributed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0092</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0092</id><created>2012-07-31</created><authors><author><keyname>Chubak</keyname><forenames>Pirooz</forenames></author><author><keyname>Rafiei</keyname><forenames>Davood</forenames></author></authors><title>Efficient Indexing and Querying over Syntactically Annotated Trees</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1316-1327 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural language text corpora are often available as sets of syntactically
parsed trees. A wide range of expressive tree queries are possible over such
parsed trees that open a new avenue in searching over natural language text.
They not only allow for querying roles and relationships within sentences, but
also improve search effectiveness compared to flat keyword queries. One major
drawback of current systems supporting querying over parsed text is the
performance of evaluating queries over large data. In this paper we propose a
novel indexing scheme over unique subtrees as index keys. We also propose a
novel root-split coding scheme that stores subtree structural information only
partially, thus reducing index size and improving querying performance. Our
extensive set of experiments show that root-split coding reduces the index size
of any interval coding which stores individual node numbers by a factor of 50%
to 80%, depending on the sizes of subtrees indexed. Moreover, We show that our
index using root-split coding, outperforms previous approaches by at least an
order of magnitude in terms of the response time of queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0093</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0093</id><created>2012-07-31</created><authors><author><keyname>Li</keyname><forenames>Ninghui</forenames></author><author><keyname>Qardaji</keyname><forenames>Wahbeh</forenames></author><author><keyname>Su</keyname><forenames>Dong</forenames></author><author><keyname>Cao</keyname><forenames>Jianneng</forenames></author></authors><title>PrivBasis: Frequent Itemset Mining with Differential Privacy</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1340-1351 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discovery of frequent itemsets can serve valuable economic and research
purposes. Releasing discovered frequent itemsets, however, presents privacy
challenges. In this paper, we study the problem of how to perform frequent
itemset mining on transaction databases while satisfying differential privacy.
We propose an approach, called PrivBasis, which leverages a novel notion called
basis sets. A theta-basis set has the property that any itemset with frequency
higher than theta is a subset of some basis. We introduce algorithms for
privately constructing a basis set and then using it to find the most frequent
itemsets. Experiments show that our approach greatly outperforms the current
state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0094</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0094</id><created>2012-07-31</created><authors><author><keyname>Yuan</keyname><forenames>Ganzhao</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenjie</forenames></author><author><keyname>Winslett</keyname><forenames>Marianne</forenames></author><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Yang</keyname><forenames>Yin</forenames></author><author><keyname>Hao</keyname><forenames>Zhifeng</forenames></author></authors><title>Low-Rank Mechanism: Optimizing Batch Queries under Differential Privacy</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1352-1363 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a promising privacy-preserving paradigm for
statistical query processing over sensitive data. It works by injecting random
noise into each query result, such that it is provably hard for the adversary
to infer the presence or absence of any individual record from the published
noisy results. The main objective in differentially private query processing is
to maximize the accuracy of the query results, while satisfying the privacy
guarantees. Previous work, notably the matrix mechanism, has suggested that
processing a batch of correlated queries as a whole can potentially achieve
considerable accuracy gains, compared to answering them individually. However,
as we point out in this paper, the matrix mechanism is mainly of theoretical
interest; in particular, several inherent problems in its design limit its
accuracy in practice, which almost never exceeds that of naive methods. In
fact, we are not aware of any existing solution that can effectively optimize a
query batch under differential privacy. Motivated by this, we propose the
Low-Rank Mechanism (LRM), the first practical differentially private technique
for answering batch queries with high accuracy, based on a low rank
approximation of the workload matrix. We prove that the accuracy provided by
LRM is close to the theoretical lower bound for any mechanism to answer a batch
of queries under differential privacy. Extensive experiments using real data
demonstrate that LRM consistently outperforms state-of-the-art query processing
solutions under differential privacy, by large margins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0095</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0095</id><created>2012-08-01</created><authors><author><keyname>Krawczyk</keyname><forenames>M. J.</forenames></author><author><keyname>Dydejczyk</keyname><forenames>A.</forenames></author><author><keyname>Kulakowski</keyname><forenames>K.</forenames></author></authors><title>The Simmel effect and babies names</title><categories>physics.soc-ph cs.SI</categories><comments>11 pages, 7 figures</comments><journal-ref>Physica A 395 (2014) 384</journal-ref><doi>10.1016/j.physa.2013.10.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulations of the Simmel effect are performed for agents in a scale-free
social network. The social hierarchy of an agent is determined by the degree of
her node. Particular features, once selected by a highly connected agent,
became common in lower class but soon fall out of fashion and extinct.
Numerical results reflect the dynamics of frequency of American babies names in
1880-2011.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0107</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0107</id><created>2012-08-01</created><updated>2013-04-11</updated><authors><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Jung</keyname><forenames>Taeho</forenames></author></authors><title>Search Me If You Can: Privacy-preserving Location Query Service</title><categories>cs.CR cs.SI</categories><comments>9 pages, 1 figure, 2 tables, IEEE INFOCOM 2013</comments><journal-ref>INFOCOM, 2013 Proceedings IEEE (pp. 2760-2768). IEEE</journal-ref><doi>10.1109/INFCOM.2013.6567085</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Location-Based Service (LBS) becomes increasingly popular with the dramatic
growth of smartphones and social network services (SNS), and its context-rich
functionalities attract considerable users. Many LBS providers use users'
location information to offer them convenience and useful functions. However,
the LBS could greatly breach personal privacy because location itself contains
much information. Hence, preserving location privacy while achieving utility
from it is still an challenging question now. This paper tackles this
non-trivial challenge by designing a suite of novel fine-grained
Privacy-preserving Location Query Protocol (PLQP). Our protocol allows
different levels of location query on encrypted location information for
different users, and it is efficient enough to be applied in mobile platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0108</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0108</id><created>2012-08-01</created><authors><author><keyname>Brechka</keyname><forenames>Denis</forenames></author></authors><title>Analysis of access in the Take-Grant model</title><categories>cs.CR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article discribe methods of verifing the conditions of access in computer
systems based on Take-Grant protection model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0129</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0129</id><created>2012-08-01</created><authors><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Bartlett</keyname><forenames>Peter L.</forenames></author><author><keyname>Duchi</keyname><forenames>John C.</forenames></author></authors><title>Oracle inequalities for computationally adaptive model selection</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze general model selection procedures using penalized empirical loss
minimization under computational constraints. While classical model selection
approaches do not consider computational aspects of performing model selection,
we argue that any practical model selection procedure must not only trade off
estimation and approximation error, but also the computational effort required
to compute empirical minimizers for different function classes. We provide a
framework for analyzing such problems, and we give algorithms for model
selection under a computational budget. These algorithms satisfy oracle
inequalities that show that the risk of the selected model is not much worse
than if we had devoted all of our omputational budget to the optimal function
class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0133</identifier>
 <datestamp>2014-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0133</id><created>2012-08-01</created><updated>2012-10-22</updated><authors><author><keyname>Aganezov,</keyname><forenames>Sergey</forenames><suffix>Jr.</suffix></author><author><keyname>Alekseyev</keyname><forenames>Max A.</forenames></author></authors><title>On pairwise distances and median score of three genomes under DCJ</title><categories>q-bio.GN cs.DM q-bio.PE</categories><comments>Proceedings of the 10-th Annual RECOMB Satellite Workshop on
  Comparative Genomics (RECOMB-CG), 2012. (to appear)</comments><journal-ref>BMC Bioinformatics 2012, 13(Suppl 19):S1</journal-ref><doi>10.1186/1471-2105-13-S19-S1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In comparative genomics, the rearrangement distance between two genomes
(equal the minimal number of genome rearrangements required to transform them
into a single genome) is often used for measuring their evolutionary
remoteness. Generalization of this measure to three genomes is known as the
median score (while a resulting genome is called median genome). In contrast to
the rearrangement distance between two genomes which can be computed in linear
time, computing the median score for three genomes is NP-hard. This inspires a
quest for simpler and faster approximations for the median score, the most
natural of which appears to be the halved sum of pairwise distances which in
fact represents a lower bound for the median score.
  In this work, we study relationship and interplay of pairwise distances
between three genomes and their median score under the model of
Double-Cut-and-Join (DCJ) rearrangements. Most remarkably we show that while a
rearrangement may change the sum of pairwise distances by at most 2 (and thus
change the lower bound by at most 1), even the most &quot;powerful&quot; rearrangements
in this respect that increase the lower bound by 1 (by moving one genome
farther away from each of the other two genomes), which we call strong, do not
necessarily affect the median score. This observation implies that the two
measures are not as well-correlated as one's intuition may suggest.
  We further prove that the median score attains the lower bound exactly on the
triples of genomes that can be obtained from a single genome with strong
rearrangements. While the sum of pairwise distances with the factor 2/3
represents an upper bound for the median score, its tightness remains unclear.
Nonetheless, we show that the difference of the median score and its lower
bound is not bounded by a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0142</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0142</id><created>2012-08-01</created><updated>2012-08-02</updated><authors><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author><author><keyname>Schweitzer</keyname><forenames>Pascal</forenames></author></authors><title>Graph Isomorphism for Graph Classes Characterized by two Forbidden
  Induced Subgraphs</title><categories>cs.DS cs.CC cs.DM math.CO</categories><comments>22 pages, 4 figures. To appear in the proceedings of WG 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of the Graph Isomorphism problem on graph classes
that are characterized by a finite number of forbidden induced subgraphs,
focusing mostly on the case of two forbidden subgraphs. We show hardness
results and develop techniques for the structural analysis of such graph
classes, which applied to the case of two forbidden subgraphs give the
following results: A dichotomy into isomorphism complete and polynomial-time
solvable graph classes for all but finitely many cases, whenever neither of the
forbidden graphs is a clique, a pan, or a complement of these graphs. Further
reducing the remaining open cases we show that (with respect to graph
isomorphism) forbidding a pan is equivalent to forbidding a clique of size
three.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0144</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0144</id><created>2012-08-01</created><authors><author><keyname>Huang</keyname><forenames>He</forenames></author><author><keyname>Sun</keyname><forenames>Yu-e</forenames></author><author><keyname>Li</keyname><forenames>Xiang-yang</forenames></author><author><keyname>Xu</keyname><forenames>Hongli</forenames></author><author><keyname>Zhou</keyname><forenames>Yousong</forenames></author><author><keyname>Huang</keyname><forenames>Liusheng</forenames></author></authors><title>Truthful Auction Mechanism for Heterogeneous Spectrum Allocation in
  Wireless Networks</title><categories>cs.GT cs.DS</categories><comments>9 pages, 7 figures</comments><msc-class>68M12</msc-class><acm-class>K.6.2; C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secondary spectrum auction is widely applied in wireless networks for
mitigating the spectrum scarcity. In a realistic spectrum trading market, the
requests from secondary users often specify the usage of a fixed spectrum
frequency band in a certain geographical region and require a duration time in
a fixed available time interval. Considering the selfish behaviors of secondary
users, it is imperative to design a truthful auction which matches the
available spectrums and requests of secondary users optimally. Unfortunately,
existing designs either do not consider spectrum heterogeneity or ignore the
differences of required time among secondary users. In this paper, we address
this problem by investigating how to use auction mechanisms to allocate and
price spectrum resources so that the social efficiency can be maximized. We
begin by classifying the spectrums and requests from secondary users into
different local markets which ensures there is no interference between local
markets, and then we can focus on the auction in a single local market. We
first design an optimal auction based on the Vickrey-Clarke-Groves (VCG)
mechanism to maximize the social efficiency while enforcing truthfulness. To
reduce the computational complexity, we further propose a truthful sub-optimal
auction with polynomial time complexity, which yields an approximation factor
6+4\surd2. Our extensive simulation results using real spectrum availability
data show that the social efficiency ratio of the sub-optimal auction is always
above 70% compared with the optimal auction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0153</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0153</id><created>2012-08-01</created><authors><author><keyname>Aissi</keyname><forenames>Saida</forenames></author><author><keyname>Gouider</keyname><forenames>Mohamed Salah</forenames></author></authors><title>Personalization in Geographic information systems: A survey</title><categories>cs.IR cs.DB</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 4, No 3, July 2012 , pp 291-298</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geographic Information Systems (GIS) are widely used in different domains of
applications, such as maritime navigation, museums visits and route planning,
as well as ecological, demographical and economical applications. Nowadays,
organizations need sophisticated and adapted GIS-based Decision Support System
(DSS) to get quick access to relevant information and to analyze data with
respect to geographic information, represented not only as spatial objects, but
also as maps.
  Several research works on GIS personalization was proposed: Face the great
challenge of developing both the theory and practice to provide personalization
GIS visualization systems. This paper aims to provide a comprehensive review of
literature on presented GIS personalization approaches. A benchmarking study of
GIS personalization methods is proposed. Several evaluation criteria are used
to identify the existence of trends as well as potential needs for further
investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0163</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0163</id><created>2012-08-01</created><authors><author><keyname>Aissi</keyname><forenames>Saida</forenames></author><author><keyname>Gouider</keyname><forenames>Mohamed Salah</forenames></author></authors><title>Spatial and Spatio-Temporal Multidimensional Data Modelling: A Survey</title><categories>cs.DB</categories><acm-class>H.2.7</acm-class><journal-ref>International Journal of Advanced Research in Computer Science and
  Software (IJARCCE), Volume 1, Issue 1, March 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data warehouse store and provide access to large volume of historical data
supporting the strategic decisions of organisations. Data warehouse is based on
a multidimensional model which allow to express user's needs for supporting the
decision making process. Since it is estimated that 80% of data used for
decision making has a spatial or location component [1, 2], spatial data have
been widely integrated in Data Warehouses and in OLAP systems. Extending a
multidimensional data model by the inclusion of spatial data provides a concise
and organised spatial datawarehouse representation. This paper aims to provide
a comprehensive review of litterature on developed and suggested spatial and
spatio-temporel multidimensional models. A benchmarking study of the proposed
models is presented. Several evaluation criterias are used to identify the
existence of trends as well as potential needs for further investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0176</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0176</id><created>2012-08-01</created><authors><author><keyname>Kontinen</keyname><forenames>Juha</forenames></author><author><keyname>V&#xe4;&#xe4;n&#xe4;nen</keyname><forenames>Jouko</forenames></author></authors><title>Axiomatizing first order consequences in dependence logic</title><categories>math.LO cs.LO</categories><msc-class>03C80</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dependence logic, introduced in [8], cannot be axiomatized. However,
first-order consequences of dependence logic sentences can be axiomatized, and
this is what we shall do in this paper. We give an explicit axiomatization and
prove the respective Completeness Theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0180</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0180</id><created>2012-08-01</created><authors><author><keyname>Michail</keyname><forenames>Othon</forenames></author><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>Naming and Counting in Anonymous Unknown Dynamic Networks</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the fundamental naming and counting problems (and some
variations) in networks that are anonymous, unknown, and possibly dynamic. In
counting, nodes must determine the size of the network n and in naming they
must end up with unique identities. By anonymous we mean that all nodes begin
from identical states apart possibly from a unique leader node and by unknown
that nodes have no a priori knowledge of the network (apart from some minimal
knowledge when necessary) including ignorance of n. Network dynamicity is
modeled by the 1-interval connectivity model, in which communication is
synchronous and a worst-case adversary chooses the edges of every round subject
to the condition that each instance is connected. We first focus on static
networks with broadcast where we prove that, without a leader, counting is
impossible to solve and that naming is impossible to solve even with a leader
and even if nodes know n. These impossibilities carry over to dynamic networks
as well. We also show that a unique leader suffices in order to solve counting
in linear time. Then we focus on dynamic networks with broadcast. We conjecture
that dynamicity renders nontrivial computation impossible. In view of this, we
let the nodes know an upper bound on the maximum degree that will ever appear
and show that in this case the nodes can obtain an upper bound on n. Finally,
we replace broadcast with one-to-each, in which a node may send a different
message to each of its neighbors. Interestingly, this natural variation is
proved to be computationally equivalent to a full-knowledge model, in which
unique names exist and the size of the network is known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0186</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0186</id><created>2012-08-01</created><authors><author><keyname>Yuan</keyname><forenames>Peiyan</forenames></author><author><keyname>Ma</keyname><forenames>Huadong</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Tang</keyname><forenames>Shaojie</forenames></author><author><keyname>Mao</keyname><forenames>Xufei</forenames></author></authors><title>Opportunistic Forwarding with Partial Centrality</title><categories>cs.NI cs.SI</categories><comments>9 pages and 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In opportunistic networks, the use of social metrics (e.g., degree, closeness
and betweenness centrality) of human mobility network, has recently been shown
to be an effective solution to improve the performance of opportunistic
forwarding algorithms. Most of the current social-based forwarding schemes
exploit some globally defined node centrality, resulting in a bias towards the
most popular nodes. However, these nodes may not be appropriate relay
candidates for some target nodes, because they may have low importance relative
to these subsets of target nodes. In this paper, to improve the opportunistic
forwarding efficiency, we exploit the relative importance (called partial
centrality) of a node with respect to a group of nodes. We design a new
opportunistic forwarding scheme, opportunistic forwarding with partial
centrality (OFPC), and theoretically quantify the influence of the partial
centrality on the data forwarding performance using graph spectrum. By applying
our scheme on three real opportunistic networking scenarios, our extensive
evaluations show that our scheme achieves significantly better mean delivery
delay and cost compared to the state-of-the-art works, while achieving delivery
ratios sufficiently close to those by Epidemic under different TTL
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0193</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0193</id><created>2012-08-01</created><authors><author><keyname>Schuh</keyname><forenames>Fabian</forenames></author><author><keyname>Schenk</keyname><forenames>Andreas</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author></authors><title>Matched Decoding for Punctured Convolutional Encoded Transmission Over
  ISI-Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 9 figures, submitted to SCC 13</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Matched decoding is a technique that enables the efficient maximum-likelihood
sequence estimation of convolutionally encoded PAM-transmission over
ISI-channels. Recently, we have shown that the super-trellis of encoder and
channel can be described with significantly fewer states without loss in
Euclidean distance, by introducing a non-linear representation of the trellis.
This paper extends the matched decoding concept to punctured convolutional
codes and introduces a time-variant, non-linear trellis description.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0200</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0200</id><created>2012-08-01</created><authors><author><keyname>Boudhief</keyname><forenames>Asma</forenames></author><author><keyname>Maraoui</keyname><forenames>Mohsen</forenames></author><author><keyname>Zrigui</keyname><forenames>Mounir</forenames></author></authors><title>Adaptation of pedagogical resources description standard (LOM) with the
  specificity of Arabic language</title><categories>cs.CL</categories><comments>8 pages,10 figures. arXiv admin note: substantial text overlap with
  arXiv:1206.2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we focus firstly on the principle of pedagogical indexing and
characteristics of Arabic language and secondly on the possibility of adapting
the standard for describing learning resources used (the LOM and its
Application Profiles) with learning conditions such as the educational levels
of students and their levels of understanding,... the educational context with
taking into account the representative elements of text, text length, ... in
particular, we put in relief the specificity of the Arabic language which is a
complex language, characterized by its flexion, its voyellation and
agglutination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0202</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0202</id><created>2012-08-01</created><authors><author><keyname>Fekete</keyname><forenames>S&#xe1;ndor P.</forenames></author></authors><title>The Complexity of MaxMin Length Triangulation</title><categories>cs.CG cs.DS</categories><comments>7 pages, 3 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1991, Edelsbrunner and Tan gave an O(n^2) algorithm for finding the MinMax
Length triangulation of a set of points in the plane. In this paper we resolve
one of the open problems stated in that paper, by showing that finding a MaxMin
Length triangulation is an NP-complete problem. The proof implies that (unless
P=NP), there is no polynomial-time approximation algorithm that can approximate
the problem within any polynomial factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0203</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0203</id><created>2012-08-01</created><authors><author><keyname>Aissi</keyname><forenames>Saida</forenames></author><author><keyname>Gouider</keyname><forenames>Mohamed Salah</forenames></author></authors><title>Towards the Next Generation of Data Warehouse Personalization System: A
  Survey and a Comparative Study</title><categories>cs.DB</categories><comments>8 pages</comments><acm-class>H.2.7</acm-class><journal-ref>IJCSI International Journal of Computer Science Issues, Vol 9,
  Issue 3, No 2, May 2012, pages 561-568</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional databases are a great asset for decision making. Their users
express complex OLAP (On-Line Analytical Processing) queries, often returning
huge volumes of facts, sometimes providing little or no information.
Furthermore, due to the huge volume of historical data stored in DWs, the OLAP
applications may return a big amount of irrelevant information that could make
the data exploration process not efficient and tardy. OLAP personalization
systems play a major role in reducing the effort of decision-makers to find the
most interesting information. Several works dealing with OLAP personalization
were presented in the last few years. This paper aims to provide a
comprehensive review of literature on OLAP personalization approaches. A
benchmarking study of OLAP personalization methods is proposed. Several
evaluation criteria are used to identify the existence of trends as well as
potential needs for further investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0219</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0219</id><created>2012-08-01</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenjie</forenames></author><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Yang</keyname><forenames>Yin</forenames></author><author><keyname>Winslett</keyname><forenames>Marianne</forenames></author></authors><title>Functional Mechanism: Regression Analysis under Differential Privacy</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1364-1375 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  \epsilon-differential privacy is the state-of-the-art model for releasing
sensitive information while protecting privacy. Numerous methods have been
proposed to enforce epsilon-differential privacy in various analytical tasks,
e.g., regression analysis. Existing solutions for regression analysis, however,
are either limited to non-standard types of regression or unable to produce
accurate regression results. Motivated by this, we propose the Functional
Mechanism, a differentially private method designed for a large class of
optimization-based analyses. The main idea is to enforce epsilon-differential
privacy by perturbing the objective function of the optimization problem,
rather than its results. As case studies, we apply the functional mechanism to
address two most widely used regression models, namely, linear regression and
logistic regression. Both theoretical analysis and thorough experimental
evaluations show that the functional mechanism is highly effective and
efficient, and it significantly outperforms existing solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0220</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0220</id><created>2012-08-01</created><authors><author><keyname>Cao</keyname><forenames>Jianneng</forenames></author><author><keyname>Karras</keyname><forenames>Panagiotis</forenames></author></authors><title>Publishing Microdata with a Robust Privacy Guarantee</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1388-1399 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, the publication of microdata poses a privacy threat. Vast research has
striven to define the privacy condition that microdata should satisfy before it
is released, and devise algorithms to anonymize the data so as to achieve this
condition. Yet, no method proposed to date explicitly bounds the percentage of
information an adversary gains after seeing the published data for each
sensitive value therein. This paper introduces beta-likeness, an appropriately
robust privacy model for microdata anonymization, along with two anonymization
schemes designed therefor, the one based on generalization, and the other based
on perturbation. Our model postulates that an adversary's confidence on the
likelihood of a certain sensitive-attribute (SA) value should not increase, in
relative difference terms, by more than a predefined threshold. Our techniques
aim to satisfy a given beta threshold with little information loss. We
experimentally demonstrate that (i) our model provides an effective privacy
guarantee in a way that predecessor models cannot, (ii) our generalization
scheme is more effective and efficient in its task than methods adapting
algorithms for the k-anonymity model, and (iii) our perturbation method
outperforms a baseline approach. Moreover, we discuss in detail the resistance
of our model and methods to attacks proposed in previous research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0221</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0221</id><created>2012-08-01</created><authors><author><keyname>Guan</keyname><forenames>Ziyu</forenames></author><author><keyname>Yan</keyname><forenames>Xifeng</forenames></author><author><keyname>Kaplan</keyname><forenames>Lance M.</forenames></author></authors><title>Measuring Two-Event Structural Correlations on Graphs</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1400-1411 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-life graphs usually have various kinds of events happening on them,
e.g., product purchases in online social networks and intrusion alerts in
computer networks. The occurrences of events on the same graph could be
correlated, exhibiting either attraction or repulsion. Such structural
correlations can reveal important relationships between different events.
Unfortunately, correlation relationships on graph structures are not well
studied and cannot be captured by traditional measures. In this work, we design
a novel measure for assessing two-event structural correlations on graphs.
Given the occurrences of two events, we choose uniformly a sample of &quot;reference
nodes&quot; from the vicinity of all event nodes and employ the Kendall's tau rank
correlation measure to compute the average concordance of event density
changes. Significance can be efficiently assessed by tau's nice property of
being asymptotically normal under the null hypothesis. In order to compute the
measure in large scale networks, we develop a scalable framework using
different sampling strategies. The complexity of these strategies is analyzed.
Experiments on real graph datasets with both synthetic and real events
demonstrate that the proposed framework is not only efficacious, but also
efficient and scalable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0222</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0222</id><created>2012-08-01</created><authors><author><keyname>Jestes</keyname><forenames>Jeffrey</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Li</keyname><forenames>Feifei</forenames></author><author><keyname>Tang</keyname><forenames>Mingwang</forenames></author></authors><title>Ranking Large Temporal Data</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1412-1423 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ranking temporal data has not been studied until recently, even though
ranking is an important operator (being promoted as a firstclass citizen) in
database systems. However, only the instant top-k queries on temporal data were
studied in, where objects with the k highest scores at a query time instance t
are to be retrieved. The instant top-k definition clearly comes with
limitations (sensitive to outliers, difficult to choose a meaningful query time
t). A more flexible and general ranking operation is to rank objects based on
the aggregation of their scores in a query interval, which we dub the aggregate
top-k query on temporal data. For example, return the top-10 weather stations
having the highest average temperature from 10/01/2010 to 10/07/2010; find the
top-20 stocks having the largest total transaction volumes from 02/05/2011 to
02/07/2011. This work presents a comprehensive study to this problem by
designing both exact and approximate methods (with approximation quality
guarantees). We also provide theoretical analysis on the construction cost, the
index size, the update and the query costs of each approach. Extensive
experiments on large real datasets clearly demonstrate the efficiency, the
effectiveness, and the scalability of our methods compared to the baseline
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0223</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0223</id><created>2012-08-01</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Fournier-Prunaret</keyname><forenames>Daniele</forenames></author></authors><title>The bistable brain: a neuronal model with symbiotic interactions</title><categories>nlin.CD cs.NE math.DS</categories><comments>20 pages, 20 figures; Chapter to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general, the behavior of large and complex aggregates of elementary
components can not be understood nor extrapolated from the properties of a few
components. The brain is a good example of this type of networked systems where
some patterns of behavior are observed independently of the topology and of the
number of coupled units. Following this insight, we have studied the dynamics
of different aggregates of logistic maps according to a particular {\it
symbiotic} coupling scheme that imitates the neuronal excitation coupling. All
these aggregates show some common dynamical properties, concretely a bistable
behavior that is reported here with a certain detail. Thus, the qualitative
relationship with neural systems is suggested through a naive model of many of
such networked logistic maps whose behavior mimics the waking-sleeping
bistability displayed by brain systems. Due to its relevance, some regions of
multistability are determined and sketched for all these logistic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0224</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0224</id><created>2012-08-01</created><authors><author><keyname>Funke</keyname><forenames>Florian</forenames></author><author><keyname>Kemper</keyname><forenames>Alfons</forenames></author><author><keyname>Neumann</keyname><forenames>Thomas</forenames></author></authors><title>Compacting Transactional Data in Hybrid OLTP &amp; OLAP Databases</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1424-1435 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Growing main memory sizes have facilitated database management systems that
keep the entire database in main memory. The drastic performance improvements
that came along with these in-memory systems have made it possible to reunite
the two areas of online transaction processing (OLTP) and online analytical
processing (OLAP): An emerging class of hybrid OLTP and OLAP database systems
allows to process analytical queries directly on the transactional data. By
offering arbitrarily current snapshots of the transactional data for OLAP,
these systems enable real-time business intelligence. Despite memory sizes of
several Terabytes in a single commodity server, RAM is still a precious
resource: Since free memory can be used for intermediate results in query
processing, the amount of memory determines query performance to a large
extent. Consequently, we propose the compaction of memory-resident databases.
Compaction consists of two tasks: First, separating the mutable working set
from the immutable &quot;frozen&quot; data. Second, compressing the immutable data and
optimizing it for efficient, memory-consumption-friendly snapshotting. Our
approach reorganizes and compresses transactional data online and yet hardly
affects the mission-critical OLTP throughput. This is achieved by unburdening
the OLTP threads from all additional processing and performing these tasks
asynchronously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0225</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0225</id><created>2012-08-01</created><authors><author><keyname>Hall</keyname><forenames>Alexander</forenames></author><author><keyname>Bachmann</keyname><forenames>Olaf</forenames></author><author><keyname>B&#xfc;ssow</keyname><forenames>Robert</forenames></author><author><keyname>G&#x103;nceanu</keyname><forenames>Silviu</forenames></author><author><keyname>Nunkesser</keyname><forenames>Marc</forenames></author></authors><title>Processing a Trillion Cells per Mouse Click</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1436-1446 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Column-oriented database systems have been a real game changer for the
industry in recent years. Highly tuned and performant systems have evolved that
provide users with the possibility of answering ad hoc queries over large
datasets in an interactive manner. In this paper we present the column-oriented
datastore developed as one of the central components of PowerDrill. It combines
the advantages of columnar data layout with other known techniques (such as
using composite range partitions) and extensive algorithmic engineering on key
data structures. The main goal of the latter being to reduce the main memory
footprint and to increase the efficiency in processing typical user queries. In
this combination we achieve large speed-ups. These enable a highly interactive
Web UI where it is common that a single mouse click leads to processing a
trillion values in the underlying dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0227</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0227</id><created>2012-08-01</created><authors><author><keyname>Porobic</keyname><forenames>Danica</forenames></author><author><keyname>Pandis</keyname><forenames>Ippokratis</forenames></author><author><keyname>Branco</keyname><forenames>Miguel</forenames></author><author><keyname>T&#xf6;z&#xfc;n</keyname><forenames>P\inar</forenames></author><author><keyname>Ailamaki</keyname><forenames>Anastasia</forenames></author></authors><title>OLTP on Hardware Islands</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1447-1458 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern hardware is abundantly parallel and increasingly heterogeneous. The
numerous processing cores have non-uniform access latencies to the main memory
and to the processor caches, which causes variability in the communication
costs. Unfortunately, database systems mostly assume that all processing cores
are the same and that microarchitecture differences are not significant enough
to appear in critical database execution paths. As we demonstrate in this
paper, however, hardware heterogeneity does appear in the critical path and
conventional database architectures achieve suboptimal and even worse,
unpredictable performance. We perform a detailed performance analysis of OLTP
deployments in servers with multiple cores per CPU (multicore) and multiple
CPUs per server (multisocket). We compare different database deployment
strategies where we vary the number and size of independent database instances
running on a single server, from a single shared-everything instance to
fine-grained shared-nothing configurations. We quantify the impact of
non-uniform hardware on various deployments by (a) examining how efficiently
each deployment uses the available hardware resources and (b) measuring the
impact of distributed transactions and skewed requests on different workloads.
Finally, we argue in favor of shared-nothing deployments that are topology- and
workload-aware and take advantage of fast on-chip communication between islands
of cores on the same socket.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0228</identifier>
 <datestamp>2012-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0228</id><created>2012-08-01</created><updated>2012-09-12</updated><authors><author><keyname>Zhou</keyname><forenames>Xiaojun</forenames></author><author><keyname>Yang</keyname><forenames>Chunhua</forenames></author><author><keyname>Gui</keyname><forenames>Weihua</forenames></author></authors><title>Initial Version of State Transition Algorithm</title><categories>math.OC cs.NE</categories><journal-ref>Second International Conference on Digital Manufacturing and
  Automation (ICDMA), 2011, 644 - 647</journal-ref><doi>10.1109/ICDMA.2011.160</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In terms of the concepts of state and state transition, a new algorithm-State
Transition Algorithm (STA) is proposed in order to probe into classical and
intelligent optimization algorithms. On the basis of state and state
transition, it becomes much simpler and easier to understand. As for continuous
function optimization problems, three special operators named rotation,
translation and expansion are presented. While for discrete function
optimization problems, an operator called general elementary transformation is
introduced. Finally, with 4 common benchmark continuous functions and a
discrete problem used to test the performance of STA, the experiment shows that
STA is a promising algorithm due to its good search capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0257</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0257</id><created>2012-08-01</created><updated>2013-07-19</updated><authors><author><keyname>Sheldon</keyname><forenames>Daniel</forenames></author><author><keyname>Young</keyname><forenames>Neal E.</forenames></author></authors><title>Hamming Approximation of NP Witnesses</title><categories>cs.CC cs.DS</categories><msc-class>03D15, 68Q25, 90C59</msc-class><acm-class>F.1.3; F.2.2</acm-class><journal-ref>Theory of Computing 9(22), 2013, pp. 685-702</journal-ref><doi>10.4086/toc.2013.v009a022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a satisfiable 3-SAT formula, how hard is it to find an assignment to
the variables that has Hamming distance at most n/2 to a satisfying assignment?
More generally, consider any polynomial-time verifier for any NP-complete
language. A d(n)-Hamming-approximation algorithm for the verifier is one that,
given any member x of the language, outputs in polynomial time a string a with
Hamming distance at most d(n) to some witness w, where (x,w) is accepted by the
verifier. Previous results have shown that, if P != NP, then every NP-complete
language has a verifier for which there is no
(n/2-n^(2/3+d))-Hamming-approximation algorithm, for various constants d &gt; 0.
  Our main result is that, if P != NP, then every paddable NP-complete language
has a verifier that admits no (n/2+O(sqrt(n log n)))-Hamming-approximation
algorithm. That is, one cannot get even half the bits right. We also consider
natural verifiers for various well-known NP-complete problems. They do have
n/2-Hamming-approximation algorithms, but, if P != NP, have no
(n/2-n^epsilon)-Hamming-approximation algorithms for any constant epsilon &gt; 0.
  We show similar results for randomized algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0259</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0259</id><created>2012-08-01</created><authors><author><keyname>Munoz-Canavate</keyname><forenames>Antonio</forenames></author><author><keyname>Hipola</keyname><forenames>Pedro</forenames></author></authors><title>Electronic administration in Spain: from its beginnings to the present</title><categories>cs.CY cs.DL</categories><journal-ref>Government Information Quarterly, vol 28, 1, January 2011, pp.
  74-90</journal-ref><doi>10.1016/j.giq.2010.05.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents the basic lines of electronic administration in Spain.
The complexity of the Spanish political-administrative system makes such a
study challenging, in view of the considerable degree of autonomy and
competences of the regional administrative bodies and local agencies with
respect to the central government, the former being more visible in the 17
regions of Spain. Nonetheless, the central government maintains a series of
legal instruments that allow a certain common framework of action to be
imposed, aside from what is put into effect through diverse programs aimed
precisely to develop common tools for the regions and municipalities of Spain.
  After an introduction that provides some necessary background, this study
describes the legislative framework in which Spain's electronic administrative
system has developed. The data included in the study refer to investment in
information and communication technologies (ICT) and the services offered by
the different Administrations on the internet; internet access by citizens,
homes, businesses, and employees, as well as the interactivity existing with
administrations by means of the internet; the origins and rise of various
political initiatives of the Central Government involving electronic
administration; and finally, the situation of civil service personnel, as
catalysts of the success of Information Society in the Public Administration
within Spain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0270</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0270</id><created>2012-08-01</created><authors><author><keyname>Patterson</keyname><forenames>Stacy</forenames></author><author><keyname>Elmore</keyname><forenames>Aaron J.</forenames></author><author><keyname>Nawab</keyname><forenames>Faisal</forenames></author><author><keyname>Agrawal</keyname><forenames>Divyakant</forenames></author><author><keyname>Abbadi</keyname><forenames>Amr El</forenames></author></authors><title>Serializability, not Serial: Concurrency Control and Availability in
  Multi-Datacenter Datastores</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1459-1470 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework for concurrency control and availability in
multi-datacenter datastores. While we consider Google's Megastore as our
motivating example, we define general abstractions for key components, making
our solution extensible to any system that satisfies the abstraction
properties. We first develop and analyze a transaction management and
replication protocol based on a straightforward implementation of the Paxos
algorithm. Our investigation reveals that this protocol acts as a concurrency
prevention mechanism rather than a concurrency control mechanism. We then
propose an enhanced protocol called Paxos with Combination and Promotion
(Paxos-CP) that provides true transaction concurrency while requiring the same
per instance message complexity as the basic Paxos protocol. Finally, we
compare the performance of Paxos and Paxos-CP in a multi-datacenter
experimental study, and we demonstrate that Paxos-CP results in significantly
fewer aborted transactions than basic Paxos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0271</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0271</id><created>2012-08-01</created><authors><author><keyname>Cheung</keyname><forenames>Alvin</forenames></author><author><keyname>Arden</keyname><forenames>Owen</forenames></author><author><keyname>Madden</keyname><forenames>Samuel</forenames></author><author><keyname>Myers</keyname><forenames>Andrew C.</forenames></author></authors><title>Automatic Partitioning of Database Applications</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1471-1482 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Database-backed applications are nearly ubiquitous in our daily lives.
Applications that make many small accesses to the database create two
challenges for developers: increased latency and wasted resources from numerous
network round trips. A well-known technique to improve transactional database
application performance is to convert part of the application into stored
procedures that are executed on the database server. Unfortunately, this
conversion is often difficult. In this paper we describe Pyxis, a system that
takes database-backed applications and automatically partitions their code into
two pieces, one of which is executed on the application server and the other on
the database server. Pyxis profiles the application and server loads,
statically analyzes the code's dependencies, and produces a partitioning that
minimizes the number of control transfers as well as the amount of data sent
during each transfer. Our experiments using TPC-C and TPC-W show that Pyxis is
able to generate partitions with up to 3x reduction in latency and 1.7x
improvement in throughput when compared to a traditional non-partitioned
implementation and has comparable performance to that of a custom stored
procedure implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0273</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0273</id><created>2012-08-01</created><authors><author><keyname>Cao</keyname><forenames>Caleb Chen</forenames></author><author><keyname>She</keyname><forenames>Jieying</forenames></author><author><keyname>Tong</keyname><forenames>Yongxin</forenames></author><author><keyname>Chen</keyname><forenames>Lei</forenames></author></authors><title>Whom to Ask? Jury Selection for Decision Making Tasks on Micro-blog
  Services</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1495-1506 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is universal to see people obtain knowledge on micro-blog services by
asking others decision making questions. In this paper, we study the Jury
Selection Problem(JSP) by utilizing crowdsourcing for decision making tasks on
micro-blog services. Specifically, the problem is to enroll a subset of crowd
under a limited budget, whose aggregated wisdom via Majority Voting scheme has
the lowest probability of drawing a wrong answer(Jury Error Rate-JER). Due to
various individual error-rates of the crowd, the calculation of JER is
non-trivial. Firstly, we explicitly state that JER is the probability when the
number of wrong jurors is larger than half of the size of a jury. To avoid the
exponentially increasing calculation of JER, we propose two efficient
algorithms and an effective bounding technique. Furthermore, we study the Jury
Selection Problem on two crowdsourcing models, one is for altruistic
users(AltrM) and the other is for incentive-requiring users(PayM) who require
extra payment when enrolled into a task. For the AltrM model, we prove the
monotonicity of JER on individual error rate and propose an efficient exact
algorithm for JSP. For the PayM model, we prove the NP-hardness of JSP on PayM
and propose an efficient greedy-based heuristic algorithm. Finally, we conduct
a series of experiments to investigate the traits of JSP, and validate the
efficiency and effectiveness of our proposed algorithms on both synthetic and
real micro-blog data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0274</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0274</id><created>2012-08-01</created><authors><author><keyname>Yang</keyname><forenames>Xiaochun</forenames></author><author><keyname>Liu</keyname><forenames>Honglei</forenames></author><author><keyname>Wang</keyname><forenames>Bin</forenames></author></authors><title>ALAE: Accelerating Local Alignment with Affine Gap Exactly in
  Biosequence Databases</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1507-1518 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of local alignment, which is finding pairs of similar
subsequences with gaps. The problem exists in biosequence databases. BLAST is a
typical software for finding local alignment based on heuristic, but could miss
results. Using the Smith-Waterman algorithm, we can find all local alignments
in O(mn) time, where m and n are lengths of a query and a text, respectively. A
recent exact approach BWT-SW improves the complexity of the Smith-Waterman
algorithm under constraints, but still much slower than BLAST. This paper takes
on the challenge of designing an accurate and efficient algorithm for
evaluating local-alignment searches, especially for long queries. In this
paper, we propose an efficient software called ALAE to speed up BWT-SW using a
compressed suffix array. ALAE utilizes a family of filtering techniques to
prune meaningless calculations and an algorithm for reusing score calculations.
We also give a mathematical analysis and show that the upper bound of the total
number of calculated entries using ALAE could vary from 4.50mn0.520 to
9.05mn0.896 for random DNA sequences and vary from 8.28mn0.364 to 7.49mn0.723
for random protein sequences. We demonstrate the significant performance
improvement of ALAE on BWT-SW using a thorough experimental study on real
biosequences. ALAE guarantees correctness and accelerates BLAST for most of
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0275</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0275</id><created>2012-08-01</created><authors><author><keyname>Candan</keyname><forenames>K. Sel&#xe7;uk</forenames></author><author><keyname>Rossini</keyname><forenames>Rosaria</forenames></author><author><keyname>Sapino</keyname><forenames>Maria Luisa</forenames></author><author><keyname>Wang</keyname><forenames>Xiaolan</forenames></author></authors><title>sDTW: Computing DTW Distances using Locally Relevant Constraints based
  on Salient Feature Alignments</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1519-1530 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications generate and consume temporal data and retrieval of time
series is a key processing step in many application domains. Dynamic time
warping (DTW) distance between time series of size N and M is computed relying
on a dynamic programming approach which creates and fills an NxM grid to search
for an optimal warp path. Since this can be costly, various heuristics have
been proposed to cut away the potentially unproductive portions of the DTW
grid. In this paper, we argue that time series often carry structural features
that can be used for identifying locally relevant constraints to eliminate
redundant work. Relying on this observation, we propose salient feature based
sDTW algorithms which first identify robust salient features in the given time
series and then find a consistent alignment of these to establish the
boundaries for the warp path search. More specifically, we propose alternative
fixed core&amp;adaptive width, adaptive core&amp;fixed width, and adaptive
core&amp;adaptive width strategies which enforce different constraints reflecting
the high level structural characteristics of the series in the data set.
Experiment results show that the proposed sDTW algorithms help achieve much
higher accuracy in DTWcomputation and time series retrieval than fixed core &amp;
fixed width algorithms that do not leverage local features of the given time
series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0276</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0276</id><created>2012-08-01</created><authors><author><keyname>Tauheed</keyname><forenames>Farhan</forenames></author><author><keyname>Heinis</keyname><forenames>Thomas</forenames></author><author><keyname>Sh&#xfc;rmann</keyname><forenames>Felix</forenames></author><author><keyname>Markram</keyname><forenames>Henry</forenames></author><author><keyname>Ailamaki</keyname><forenames>Anastasia</forenames></author></authors><title>SCOUT: Prefetching for Latent Feature Following Queries</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1531-1542 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's scientists are quickly moving from in vitro to in silico
experimentation: they no longer analyze natural phenomena in a petri dish, but
instead they build models and simulate them. Managing and analyzing the massive
amounts of data involved in simulations is a major task. Yet, they lack the
tools to efficiently work with data of this size. One problem many scientists
share is the analysis of the massive spatial models they build. For several
types of analysis they need to interactively follow the structures in the
spatial model, e.g., the arterial tree, neuron fibers, etc., and issue range
queries along the way. Each query takes long to execute, and the total time for
executing a sequence of queries significantly delays data analysis. Prefetching
the spatial data reduces the response time considerably, but known approaches
do not prefetch with high accuracy. We develop SCOUT, a structure-aware method
for prefetching data along interactive spatial query sequences. SCOUT uses an
approximate graph model of the structures involved in past queries and attempts
to identify what particular structure the user follows. Our experiments with
neuroscience data show that SCOUT prefetches with an accuracy from 71% to 92%,
which translates to a speedup of 4x-15x. SCOUT also improves the prefetching
accuracy on datasets from other scientific domains, such as medicine and
biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0277</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0277</id><created>2012-08-01</created><authors><author><keyname>Wang</keyname><forenames>Kaibo</forenames></author><author><keyname>Huai</keyname><forenames>Yin</forenames></author><author><keyname>Lee</keyname><forenames>Rubao</forenames></author><author><keyname>Wang</keyname><forenames>Fusheng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaodong</forenames></author><author><keyname>Saltz</keyname><forenames>Joel H.</forenames></author></authors><title>Accelerating Pathology Image Data Cross-Comparison on CPU-GPU Hybrid
  Systems</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1543-1554 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an important application of spatial databases in pathology imaging
analysis, cross-comparing the spatial boundaries of a huge amount of segmented
micro-anatomic objects demands extremely data- and compute-intensive
operations, requiring high throughput at an affordable cost. However, the
performance of spatial database systems has not been satisfactory since their
implementations of spatial operations cannot fully utilize the power of modern
parallel hardware. In this paper, we provide a customized software solution
that exploits GPUs and multi-core CPUs to accelerate spatial cross-comparison
in a cost-effective way. Our solution consists of an efficient GPU algorithm
and a pipelined system framework with task migration support. Extensive
experiments with real-world data sets demonstrate the effectiveness of our
solution, which improves the performance of spatial cross-comparison by over 18
times compared with a parallelized spatial database approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0278</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0278</id><created>2012-08-01</created><authors><author><keyname>Li</keyname><forenames>Jiexing</forenames></author><author><keyname>K&#xf6;nig</keyname><forenames>Arnd Christian</forenames></author><author><keyname>Narasayya</keyname><forenames>Vivek</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Surajit</forenames></author></authors><title>Robust Estimation of Resource Consumption for SQL Queries using
  Statistical Techniques</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1555-1566 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to estimate resource consumption of SQL queries is crucial for a
number of tasks in a database system such as admission control, query
scheduling and costing during query optimization. Recent work has explored the
use of statistical techniques for resource estimation in place of the manually
constructed cost models used in query optimization. Such techniques, which
require as training data examples of resource usage in queries, offer the
promise of superior estimation accuracy since they can account for factors such
as hardware characteristics of the system or bias in cardinality estimates.
However, the proposed approaches lack robustness in that they do not generalize
well to queries that are different from the training examples, resulting in
significant estimation errors. Our approach aims to address this problem by
combining knowledge of database query processing with statistical models. We
model resource-usage at the level of individual operators, with different
models and features for each operator type, and explicitly model the asymptotic
behavior of each operator. This results in significantly better estimation
accuracy and the ability to estimate resource usage of arbitrary plans, even
when they are very different from the training instances. We validate our
approach using various large scale real-life and benchmark workloads on
Microsoft SQL Server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0283</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0283</id><created>2012-08-01</created><authors><author><keyname>Bonchis</keyname><forenames>Cosmin</forenames></author><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>A Parametric Worst-Case Approach to Fairness in TU-Cooperative Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a parametric family of measures of fairness in allocations of
TU-cooperative games. Their definition is based on generalized Renyi Entropy,
is related to the Cowell-Kuga generalized entropy indices in welfare economics,
and aims to parallel the spirit of the notion of price of anarchy in the case
of convex TU-cooperative games.
  Since computing these indices is NP-complete in general, we first upper bound
the performance of a &quot;reverse greedy&quot; algorithm for approximately computing
worst-case fairness. The result provides a general additive error guarantee in
terms of two (problem dependent) packing constants. We then particularize this
result to the class of induced subset games. For such games computing
worst-case fairness is NP-complete, and the additive guarantee constant can be
explicitly computed. We compare this result to the performance of an alternate
algorithm based on &quot;biased orientations&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0285</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0285</id><created>2012-08-01</created><authors><author><keyname>Das</keyname><forenames>Mahashweta</forenames></author><author><keyname>Thirumuruganathan</keyname><forenames>Saravanan</forenames></author><author><keyname>Amer-Yahia</keyname><forenames>Sihem</forenames></author><author><keyname>Das</keyname><forenames>Gautam</forenames></author><author><keyname>Yu</keyname><forenames>Cong</forenames></author></authors><title>Who Tags What? An Analysis Framework</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1567-1578 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rise of Web 2.0 is signaled by sites such as Flickr, del.icio.us, and
YouTube, and social tagging is essential to their success. A typical tagging
action involves three components, user, item (e.g., photos in Flickr), and tags
(i.e., words or phrases). Analyzing how tags are assigned by certain users to
certain items has important implications in helping users search for desired
information. In this paper, we explore common analysis tasks and propose a dual
mining framework for social tagging behavior mining. This framework is centered
around two opposing measures, similarity and diversity, being applied to one or
more tagging components, and therefore enables a wide range of analysis
scenarios such as characterizing similar users tagging diverse items with
similar tags, or diverse users tagging similar items with diverse tags, etc. By
adopting different concrete measures for similarity and diversity in the
framework, we show that a wide range of concrete analysis problems can be
defined and they are NP-Complete in general. We design efficient algorithms for
solving many of those problems and demonstrate, through comprehensive
experiments over real data, that our algorithms significantly out-perform the
exact brute-force approach without compromising analysis result quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0286</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0286</id><created>2012-08-01</created><authors><author><keyname>Zhu</keyname><forenames>Haohan</forenames></author><author><keyname>Kollios</keyname><forenames>George</forenames></author><author><keyname>Athitsos</keyname><forenames>Vassilis</forenames></author></authors><title>A Generic Framework for Efficient and Effective Subsequence Retrieval</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1579-1590 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a general framework for matching similar subsequences in
both time series and string databases. The matching results are pairs of query
subsequences and database subsequences. The framework finds all possible pairs
of similar subsequences if the distance measure satisfies the &quot;consistency&quot;
property, which is a property introduced in this paper. We show that most
popular distance functions, such as the Euclidean distance, DTW, ERP, the
Frechet distance for time series, and the Hamming distance and Levenshtein
distance for strings, are all &quot;consistent&quot;. We also propose a generic index
structure for metric spaces named &quot;reference net&quot;. The reference net occupies
O(n) space, where n is the size of the dataset and is optimized to work well
with our framework. The experiments demonstrate the ability of our method to
improve retrieval performance when combined with diverse distance measures. The
experiments also illustrate that the reference net scales well in terms of
space overhead and query time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0287</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0287</id><created>2012-08-01</created><authors><author><keyname>Dittrich</keyname><forenames>Jens</forenames></author><author><keyname>Quian&#xe9;-Ruiz</keyname><forenames>Jorge-Arnulfo</forenames></author><author><keyname>Richter</keyname><forenames>Stefan</forenames></author><author><keyname>Schuh</keyname><forenames>Stefan</forenames></author><author><keyname>Jindal</keyname><forenames>Alekh</forenames></author><author><keyname>Schad</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>Only Aggressive Elephants are Fast Elephants</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1591-1602 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Yellow elephants are slow. A major reason is that they consume their inputs
entirely before responding to an elephant rider's orders. Some clever riders
have trained their yellow elephants to only consume parts of the inputs before
responding. However, the teaching time to make an elephant do that is high. So
high that the teaching lessons often do not pay off. We take a different
approach. We make elephants aggressive; only this will make them very fast. We
propose HAIL (Hadoop Aggressive Indexing Library), an enhancement of HDFS and
Hadoop MapReduce that dramatically improves runtimes of several classes of
MapReduce jobs. HAIL changes the upload pipeline of HDFS in order to create
different clustered indexes on each data block replica. An interesting feature
of HAIL is that we typically create a win-win situation: we improve both data
upload to HDFS and the runtime of the actual Hadoop MapReduce job. In terms of
data upload, HAIL improves over HDFS by up to 60% with the default replication
factor of three. In terms of query execution, we demonstrate that HAIL runs up
to 68x faster than Hadoop. In our experiments, we use six clusters including
physical and EC2 clusters of up to 100 nodes. A series of scalability
experiments also demonstrates the superiority of HAIL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0288</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0288</id><created>2012-08-01</created><authors><author><keyname>Li</keyname><forenames>Rui</forenames></author><author><keyname>Wang</keyname><forenames>Shengjie</forenames></author><author><keyname>Chang</keyname><forenames>Kevin Chen-Chuan</forenames></author></authors><title>Multiple Location Profiling for Users and Relationships from Social
  Network and Content</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1603-1614 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Users' locations are important for many applications such as personalized
search and localized content delivery. In this paper, we study the problem of
profiling Twitter users' locations with their following network and tweets. We
propose a multiple location profiling model (MLP), which has three key
features: 1) it formally models how likely a user follows another user given
their locations and how likely a user tweets a venue given his location, 2) it
fundamentally captures that a user has multiple locations and his following
relationships and tweeted venues can be related to any of his locations, and
some of them are even noisy, and 3) it novelly utilizes the home locations of
some users as partial supervision. As a result, MLP not only discovers users'
locations accurately and completely, but also &quot;explains&quot; each following
relationship by revealing users' true locations in the relationship.
Experiments on a large-scale data set demonstrate those advantages.
Particularly, 1) for predicting users' home locations, MLP successfully places
62% users and outperforms two state-of-the-art methods by 10% in accuracy, 2)
for discovering users' multiple locations, MLP improves the baseline methods by
14% in recall, and 3) for explaining following relationships, MLP achieves 57%
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0289</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0289</id><created>2012-08-01</created><authors><author><keyname>Kang</keyname><forenames>Woon-Hak</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Won</forenames></author><author><keyname>Moon</keyname><forenames>Bongki</forenames></author></authors><title>Flash-based Extended Cache for Higher Throughput and Faster Recovery</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1615-1626 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the current price gap between disk and flash memory drives, for
applications dealing with large scale data, it will be economically more
sensible to use flash memory drives to supplement disk drives rather than to
replace them. This paper presents FaCE, which is a new low-overhead caching
strategy that uses flash memory as an extension to the DRAM buffer. FaCE aims
at improving the transaction throughput as well as shortening the recovery time
from a system failure. To achieve the goals, we propose two novel algorithms
for flash cache management, namely, Multi-Version FIFO replacement and Group
Second Chance. One striking result from FaCE is that using a small flash memory
drive as a caching device could deliver even higher throughput than using a
large flash memory drive to store the entire database tables. This was possible
due to flash write optimization as well as disk access reduction obtained by
the FaCE caching methods. In addition, FaCE takes advantage of the
non-volatility of flash memory to fully support database recovery by extending
the scope of a persistent database to include the data pages stored in the
flash cache. We have implemented FaCE in the PostgreSQL open source database
server and demonstrated its effectiveness for TPC-C benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0290</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0290</id><created>2012-08-01</created><authors><author><keyname>Bender</keyname><forenames>Michael A.</forenames></author><author><keyname>Farach-Colton</keyname><forenames>Martin</forenames></author><author><keyname>Johnson</keyname><forenames>Rob</forenames></author><author><keyname>Kraner</keyname><forenames>Russell</forenames></author><author><keyname>Kuszmaul</keyname><forenames>Bradley C.</forenames></author><author><keyname>Medjedovic</keyname><forenames>Dzejla</forenames></author><author><keyname>Montes</keyname><forenames>Pablo</forenames></author><author><keyname>Shetty</keyname><forenames>Pradeep</forenames></author><author><keyname>Spillane</keyname><forenames>Richard P.</forenames></author><author><keyname>Zadok</keyname><forenames>Erez</forenames></author></authors><title>Don't Thrash: How to Cache Your Hash on Flash</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1627-1637 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new alternatives to the well-known Bloom filter data
structure. The Bloom filter, a compact data structure supporting set insertion
and membership queries, has found wide application in databases, storage
systems, and networks. Because the Bloom filter performs frequent random reads
and writes, it is used almost exclusively in RAM, limiting the size of the sets
it can represent. This paper first describes the quotient filter, which
supports the basic operations of the Bloom filter, achieving roughly comparable
performance in terms of space and time, but with better data locality.
Operations on the quotient filter require only a small number of contiguous
accesses. The quotient filter has other advantages over the Bloom filter: it
supports deletions, it can be dynamically resized, and two quotient filters can
be efficiently merged. The paper then gives two data structures, the buffered
quotient filter and the cascade filter, which exploit the quotient filter
advantages and thus serve as SSD-optimized alternatives to the Bloom filter.
The cascade filter has better asymptotic I/O performance than the buffered
quotient filter, but the buffered quotient filter outperforms the cascade
filter on small to medium data sets. Both data structures significantly
outperform recently-proposed SSD-optimized Bloom filter variants, such as the
elevator Bloom filter, buffered Bloom filter, and forest-structured Bloom
filter. In experiments, the cascade filter and buffered quotient filter
performed insertions 8.6-11 times faster than the fastest Bloom filter variant
and performed lookups 0.94-2.56 times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0291</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0291</id><created>2012-08-01</created><authors><author><keyname>Isele</keyname><forenames>Robert</forenames></author><author><keyname>Bizer</keyname><forenames>Christian</forenames></author></authors><title>Learning Expressive Linkage Rules using Genetic Programming</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1638-1649 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central problem in data integration and data cleansing is to find entities
in different data sources that describe the same real-world object. Many
existing methods for identifying such entities rely on explicit linkage rules
which specify the conditions that entities must fulfill in order to be
considered to describe the same real-world object. In this paper, we present
the GenLink algorithm for learning expressive linkage rules from a set of
existing reference links using genetic programming. The algorithm is capable of
generating linkage rules which select discriminative properties for comparison,
apply chains of data transformations to normalize property values, choose
appropriate distance measures and thresholds and combine the results of
multiple comparisons using non-linear aggregation functions. Our experiments
show that the GenLink algorithm outperforms the state-of-the-art genetic
programming approach to learning linkage rules recently presented by Carvalho
et. al. and is capable of learning linkage rules which achieve a similar
accuracy as human written rules for the same problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0292</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0292</id><created>2012-08-01</created><authors><author><keyname>Tong</keyname><forenames>Yongxin</forenames></author><author><keyname>Chen</keyname><forenames>Lei</forenames></author><author><keyname>Cheng</keyname><forenames>Yurong</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author></authors><title>Mining Frequent Itemsets over Uncertain Databases</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1650-1661 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, due to the wide applications of uncertain data, mining
frequent itemsets over uncertain databases has attracted much attention. In
uncertain databases, the support of an itemset is a random variable instead of
a fixed occurrence counting of this itemset. Thus, unlike the corresponding
problem in deterministic databases where the frequent itemset has a unique
definition, the frequent itemset under uncertain environments has two different
definitions so far. The first definition, referred as the expected
support-based frequent itemset, employs the expectation of the support of an
itemset to measure whether this itemset is frequent. The second definition,
referred as the probabilistic frequent itemset, uses the probability of the
support of an itemset to measure its frequency. Thus, existing work on mining
frequent itemsets over uncertain databases is divided into two different groups
and no study is conducted to comprehensively compare the two different
definitions. In addition, since no uniform experimental platform exists,
current solutions for the same definition even generate inconsistent results.
In this paper, we firstly aim to clarify the relationship between the two
different definitions. Through extensive experiments, we verify that the two
definitions have a tight connection and can be unified together when the size
of data is large enough. Secondly, we provide baseline implementations of eight
existing representative algorithms and test their performances with uniform
measures fairly. Finally, according to the fair tests over many different
benchmark data sets, we clarify several existing inconsistent conclusions and
discuss some new findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0293</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0293</id><created>2012-08-01</created><authors><author><keyname>Lange</keyname><forenames>Christoph</forenames></author><author><keyname>Mossakowski</keyname><forenames>Till</forenames></author><author><keyname>Kutz</keyname><forenames>Oliver</forenames></author><author><keyname>Galinski</keyname><forenames>Christian</forenames></author><author><keyname>Gr&#xfc;ninger</keyname><forenames>Michael</forenames></author><author><keyname>Vale</keyname><forenames>Daniel Couto</forenames></author></authors><title>The Distributed Ontology Language (DOL): Use Cases, Syntax, and
  Extensibility</title><categories>cs.AI cs.DL cs.LO</categories><comments>Terminology and Knowledge Engineering Conference (TKE) 2012-06-20 to
  2012-06-21 Madrid, Spain</comments><msc-class>68T30, 68T35</msc-class><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Distributed Ontology Language (DOL) is currently being standardized
within the OntoIOp (Ontology Integration and Interoperability) activity of
ISO/TC 37/SC 3. It aims at providing a unified framework for (1) ontologies
formalized in heterogeneous logics, (2) modular ontologies, (3) links between
ontologies, and (4) annotation of ontologies. This paper presents the current
state of DOL's standardization. It focuses on use cases where distributed
ontologies enable interoperability and reusability. We demonstrate relevant
features of the DOL syntax and semantics and explain how these integrate into
existing knowledge engineering environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0296</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0296</id><created>2012-08-01</created><updated>2012-09-03</updated><authors><author><keyname>Br&#xe2;nzei</keyname><forenames>Simina</forenames></author><author><keyname>Forero</keyname><forenames>Clara</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author></authors><title>Equilibria of Chinese Auctions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chinese auctions are a combination between a raffle and an auction and are
held in practice at charity events or festivals. In a Chinese auction, multiple
players compete for several items by buying tickets, which can be used to win
the items. In front of each item there is a basket, and the players can bid by
placing tickets in the basket(s) corresponding to the item(s) they are trying
to win. After all the players have placed their tickets, a ticket is drawn at
random from each basket and the item is given to the owner of the winning
ticket. While a player is never guaranteed to win an item, they can improve
their chances of getting it by increasing the number of tickets for that item.
  In this paper we investigate the existence of pure Nash equilibria in both
the continuous and discrete settings. When the players have continuous budgets,
we show that a pure Nash equilibrium may not exist for asymmetric games when
some valuations are zero. In that case we prove that the auctioneer can
stabilize the game by placing his own ticket in each basket. On the other hand,
when all the valuations are strictly positive, a pure Nash equilibrium is
guaranteed to exist, and the equilibrium strategies are symmetric when both
valuations and budgets are symmetric. We also study Chinese auctions with
discrete budgets, for which we give both existence results and counterexamples.
While the literature on rent-seeking contests traditionally focuses on
continuous costly tickets, the discrete variant is very natural and more
closely models the version of the auction held in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0312</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0312</id><created>2012-08-01</created><authors><author><keyname>Chang</keyname><forenames>Jessica</forenames></author><author><keyname>Gabow</keyname><forenames>Harold N.</forenames></author><author><keyname>Khuller</keyname><forenames>Samir</forenames></author></authors><title>A Model for Minimizing Active Processor Time</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the following elementary scheduling problem. We are given a
collection of n jobs, where each job has an integer length as well as a set Ti
of time intervals in which it can be feasibly scheduled. Given a parameter B,
the processor can schedule up to B jobs at a timeslot t so long as it is
&quot;active&quot; at t. The goal is to schedule all the jobs in the fewest number of
active timeslots. The machine consumes a fixed amount of energy per active
timeslot, regardless of the number of jobs scheduled in that slot (as long as
the number of jobs is non-zero). In other words, subject to all units of each
job being scheduled in its feasible region and at each slot at most B jobs
being scheduled, we are interested in minimizing the total time during which
the machine is active. We present a linear time algorithm for the case where
jobs are unit length and each Ti is a single interval. For general Ti, we show
that the problem is NP-complete even for B = 3. However when B = 2, we show
that it can be efficiently solved. In addition, we consider a version of the
problem where jobs have arbitrary lengths and can be preempted at any point in
time. For general B, the problem can be solved by linear programming. For B =
2, the problem amounts to finding a triangle-free 2-matching on a special
graph. We extend the algorithm of Babenko et. al. to handle our variant, and
also to handle non-unit length jobs. This yields an O(sqrt(L)m) time algorithm
to solve the preemptive scheduling problem for B = 2, where L is the sum of the
job lengths. We also show that for B = 2 and unit length jobs, the optimal
non-preemptive schedule has at most 4/3 times the active time of the optimal
preemptive schedule; this bound extends to several versions of the problem when
jobs have arbitrary length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0318</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0318</id><created>2012-08-01</created><authors><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Sur</keyname><forenames>Khrist</forenames></author><author><keyname>Das</keyname><forenames>Shantanu</forenames></author></authors><title>Artificial Neural Network Based Prediction of Optimal Pseudo-Damping and
  Meta-Damping in Oscillatory Fractional Order Dynamical Systems</title><categories>cs.SY cs.NE</categories><comments>7 pages, 9 figures</comments><journal-ref>2012 International Conference on Advances in Engineering, Science
  and Management (ICAESM), art. no. 6216029 , pp. 350-356</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates typical behaviors like damped oscillations in
fractional order (FO) dynamical systems. Such response occurs due to the
presence of, what is conceived as, pseudo-damping and meta-damping in some
special class of FO systems. Here, approximation of such damped oscillation in
FO systems with the conventional notion of integer order damping and time
constant has been carried out using Genetic Algorithm (GA). Next, a multilayer
feed-forward Artificial Neural Network (ANN) has been trained using the GA
based results to predict the optimal pseudo and meta-damping from knowledge of
the maximum order or number of terms in the FO dynamical system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0326</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0326</id><created>2012-08-01</created><updated>2012-08-02</updated><authors><author><keyname>Aminzare</keyname><forenames>Zahra</forenames></author><author><keyname>Sontag</keyname><forenames>Eduardo D.</forenames></author></authors><title>Logarithmic Lipschitz norms and diffusion-induced instability</title><categories>cs.SY math.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proves that contractive ordinary differential equation systems
remain contractive when diffusion is added. Thus, diffusive instabilities, in
the sense of the Turing phenomenon, cannot arise for such systems. An important
biochemical system is shown to satisfy the required conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0353</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0353</id><created>2012-08-01</created><updated>2013-06-21</updated><authors><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author><author><keyname>Wakin</keyname><forenames>Michael B.</forenames></author></authors><title>Signal Space CoSaMP for Sparse Recovery with Redundant Dictionaries</title><categories>cs.IT math.IT</categories><msc-class>41A46, 68Q25, 68W20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) has recently emerged as a powerful framework for
acquiring sparse signals. The bulk of the CS literature has focused on the case
where the acquired signal has a sparse or compressible representation in an
orthonormal basis. In practice, however, there are many signals that cannot be
sparsely represented or approximated using an orthonormal basis, but that do
have sparse representations in a redundant dictionary. Standard results in CS
can sometimes be extended to handle this case provided that the dictionary is
sufficiently incoherent or well-conditioned, but these approaches fail to
address the case of a truly redundant or overcomplete dictionary. In this paper
we describe a variant of the iterative recovery algorithm CoSaMP for this more
challenging setting. We utilize the D-RIP, a condition on the sensing matrix
analogous to the well-known restricted isometry property. In contrast to prior
work, the method and analysis are &quot;signal-focused&quot;; that is, they are oriented
around recovering the signal rather than its dictionary coefficients. Under the
assumption that we have a near-optimal scheme for projecting vectors in signal
space onto the model family of candidate sparse signals, we provide provable
recovery guarantees. Developing a practical algorithm that can provably compute
the required near-optimal projections remains a significant open problem, but
we include simulation results using various heuristics that empirically exhibit
superior performance to traditional recovery algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0359</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0359</id><created>2012-08-01</created><authors><author><keyname>Leiva-Mederos</keyname><forenames>Amed</forenames></author><author><keyname>Senso</keyname><forenames>Jose A.</forenames></author><author><keyname>Dominguez-Velasco</keyname><forenames>Sandor</forenames></author><author><keyname>Hipola</keyname><forenames>Pedro</forenames></author></authors><title>An Automat for the Semantic Processing of Structured Information</title><categories>cs.IR cs.DL</categories><comments>IEEE Intelligent Systems Design and Applications, 2009. ISDA '09.
  Ninth International Conference on Date of Conference: Nov. 30 2009-Dec. 2
  2009, Page(s): 85 - 89</comments><journal-ref>IEEE Intelligent Systems Design and Applications, 2009. ISDA '09.
  Ninth International Conference on Date of Conference: Nov. 30 2009-Dec. 2
  2009, Page(s): 85 - 89</journal-ref><doi>10.1109/ISDA.2009.120</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the database of the PuertoTerm project, an indexing system based on the
cognitive model of Brigitte Enders was built. By analyzing the cognitive
strategies of three abstractors, we built an automat that serves to simulate
human indexing processes. The automat allows the texts integrated in the system
to be assessed, evaluated and grouped by means of the bipartite spectral graph
partitioning algorithm, which also permits visualization of the terms and the
documents. The system features an ontology and a database to enhance its
operativity. As a result of the application, we achieved better rates of
exhaustivity in the indexing of documents, as well as greater precision and
retrieval of information, with high levels of efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0370</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0370</id><created>2012-08-01</created><authors><author><keyname>Ercsey-Ravasz</keyname><forenames>Maria</forenames></author><author><keyname>Toroczkai</keyname><forenames>Zoltan</forenames></author></authors><title>The Chaos Within Sudoku</title><categories>nlin.CD cs.DS physics.comp-ph</categories><comments>9 pages, 4 color figures</comments><msc-class>37D45, 90C27, 68Q10, 68Q17, 34G20</msc-class><acm-class>F.2.3; F.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mathematical structure of the widely popular Sudoku puzzles is akin to
typical hard constraint satisfaction problems that lie at the heart of many
applications, including protein folding and the general problem of finding the
ground state of a glassy spin system. Via an exact mapping of Sudoku into a
deterministic, continuous-time dynamical system, here we show that the
difficulty of Sudoku translates into transient chaotic behavior exhibited by
the dynamical system. In particular, we show that the escape rate $\kappa$, an
invariant characteristic of transient chaos, provides a single scalar measure
of the puzzle's hardness, which correlates well with human difficulty level
ratings. Accordingly, $\eta = -\log_{10}{\kappa}$ can be used to define a
&quot;Richter&quot;-type scale for puzzle hardness, with easy puzzles falling in the
range $0 &lt; \eta \leq 1$, medium ones within $1 &lt; \eta \leq 2$, hard in $2 &lt;
\eta \leq 3$ and ultra-hard with $\eta &gt; 3$. To our best knowledge, there are
no known puzzles with $\eta &gt; 4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0378</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0378</id><created>2012-08-01</created><authors><author><keyname>Yarkony</keyname><forenames>Julian</forenames></author><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author><author><keyname>Fowlkes</keyname><forenames>Charless C.</forenames></author></authors><title>Fast Planar Correlation Clustering for Image Segmentation</title><categories>cs.CV cs.DS cs.LG stat.ML</categories><comments>This is the extended version of a paper to appear at the 12th
  European Conference on Computer Vision (ECCV 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new optimization scheme for finding high-quality correlation
clusterings in planar graphs that uses weighted perfect matching as a
subroutine. Our method provides lower-bounds on the energy of the optimal
correlation clustering that are typically fast to compute and tight in
practice. We demonstrate our algorithm on the problem of image segmentation
where this approach outperforms existing global optimization techniques in
minimizing the objective and is competitive with the state of the art in
producing high-quality segmentations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0383</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0383</id><created>2012-08-01</created><authors><author><keyname>Feigenbaum</keyname><forenames>Joan</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Zervas</keyname><forenames>Georgios</forenames></author></authors><title>An Economic Analysis of User-Privacy Options in Ad-Supported Services</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the value to e-commerce website operators of offering privacy
options to users, e.g., of allowing users to opt out of ad targeting. In
particular, we assume that site operators have some control over the cost that
a privacy option imposes on users and ask when it is to their advantage to make
such costs low. We consider both the case of a single site and the case of
multiple sites that compete both for users who value privacy highly and for
users who value it less. One of our main results in the case of a single site
is that, under normally distributed utilities, if a privacy-sensitive user is
worth at least $\sqrt{2} - 1$ times as much to advertisers as a
privacy-insensitive user, the site operator should strive to make the cost of a
privacy option as low as possible. In the case of multiple sites, we show how a
Prisoner's-Dilemma situation can arise: In the equilibrium in which both sites
are obliged to offer a privacy option at minimal cost, both sites obtain lower
revenue than they would if they colluded and neither offered a privacy option.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0384</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0384</id><created>2012-08-01</created><authors><author><keyname>Liu</keyname><forenames>Shaoli</forenames></author><author><keyname>Chen</keyname><forenames>Yunji</forenames></author><author><keyname>Chen</keyname><forenames>Tianshi</forenames></author><author><keyname>Li</keyname><forenames>Ling</forenames></author><author><keyname>Lu</keyname><forenames>Chao</forenames></author></authors><title>Global Adaptive Routing Algorithm Without Additional Congestion
  Propagation Network</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Adaptive routing algorithm has been employed in multichip interconnection
networks in order to improve network performance. Does a algorithm use local or
global network state? This is the key question in adaptive routing. In many
traffic patterns, the ignorance of global network state, leading to routing
selection based only on local congestion information, tends to violate global
load balance. To attack the load balance issue in adapting routing, some global
adaptive routing algorithms introduce a congestion propagation network to
obtain global network status information, such as Regional Congestion Awareness
(RCA) and Destination Based Adaptive Routing (DBAR).
  However, the congestion propagation network leads to additional power and
area consumption which cannot be ignored. From another view, if we just
increase the bandwidth between neighbor nodes with the wires used to build the
congestion propagation network, the network performance could be improved as
well. In this paper, we propose a global adaptive routing algorithm without
employing the additional congestion propagation network. Our algorithm obtains
the global network state in a novel way, and can offer significant improvement
than the base-line local adaptive routing algorithm (xy-adaptive algorithm
which selects routing based on local congestion information in each hop) for
both medium and high injection rates.
  In wormhole flow control, all the routing information (flit id, source node
id, destination node id, vc id and address) is contained in head flit, and data
is carried in body flits. As a result, there are always many free bits in the
head flit, especially when the bandwidth is 128-bits which is normal in
interconnection network design. Then, we can use these free bits in the head
flit to propagate global congestion information but not increase the number of
flits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0385</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0385</id><created>2012-08-01</created><updated>2012-08-03</updated><authors><author><keyname>Kakarala</keyname><forenames>Ramakrishna</forenames></author><author><keyname>Ogunbona</keyname><forenames>Philip</forenames></author></authors><title>A phase-sensitive method for filtering on the sphere</title><categories>math.RT cs.CV</categories><doi>10.1109/TSP.2012.2213083</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines filtering on a sphere, by first examining the roles of
spherical harmonic magnitude and phase. We show that phase is more important
than magnitude in determining the structure of a spherical function. We examine
the properties of linear phase shifts in the spherical harmonic domain, which
suggest a mechanism for constructing finite-impulse-response (FIR) filters. We
show that those filters have desirable properties, such as being associative,
mapping spherical functions to spherical functions, allowing directional
filtering, and being defined by relatively simple equations. We provide
examples of the filters for both spherical and manifold data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0393</identifier>
 <datestamp>2012-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0393</id><created>2012-08-01</created><updated>2012-10-26</updated><authors><author><keyname>Gillespie</keyname><forenames>Neil I.</forenames></author><author><keyname>Giudici</keyname><forenames>Michael</forenames></author><author><keyname>Praeger</keyname><forenames>Cheryl E.</forenames></author></authors><title>Classification of a family of completely transitive codes</title><categories>math.CO cs.IT math.IT</categories><comments>16 pages</comments><msc-class>05C25, 20B25, 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The completely regular codes in Hamming graphs have a high degree of
combinatorial symmetry and have attracted a lot of interest since their
introduction in 1973 by Delsarte. This paper studies the subfamily of
completely transitive codes, those in which an automorphism group is transitive
on each part of the distance partition. This family is a natural generalisation
of the binary completely transitive codes introduced by Sole in 1990. We take
the first step towards a classification of these codes, determining those for
which the automorphism group is faithful on entries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0395</identifier>
 <datestamp>2013-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0395</id><created>2012-08-02</created><updated>2013-07-29</updated><authors><author><keyname>Savi&#x107;</keyname><forenames>Marko</forenames></author><author><keyname>Stojakovi&#x107;</keyname><forenames>Milo&#x161;</forenames></author></authors><title>Linear Time Algorithm for Optimal Feed-link Placement</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a polygon representing a transportation network together with a point p
in its interior, we aim to extend the network by inserting a line segment,
called a feed-link, which connects p to the boundary of the polygon. Once a
feed link is fixed, the geometric dilation of some point q on the boundary is
the ratio between the length of the shortest path from p to q through the
extended network, and their Euclidean distance. The utility of a feed-link is
inversely proportional to the maximal dilation over all boundary points.
  We give a linear time algorithm for computing the feed-link with the minimum
overall dilation, thus improving upon the previously known algorithm of
complexity that is roughly O(n log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0396</identifier>
 <datestamp>2012-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0396</id><created>2012-08-02</created><updated>2012-08-15</updated><authors><author><keyname>Nguyen</keyname><forenames>Andy</forenames></author></authors><title>Solving Cyclic Longest Common Subsequence in Quadratic Time</title><categories>cs.DS</categories><comments>Updated references; an O(n^2) solution already exists, though it is
  terribly unwieldy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a practical algorithm for the cyclic longest common subsequence
(CLCS) problem that runs in O(mn) time, where m and n are the lengths of the
two input strings. While this is not necessarily an asymptotic improvement over
the existing record, it is far simpler to understand and to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0400</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0400</id><created>2012-08-02</created><authors><author><keyname>Sharma</keyname><forenames>Shrutivandana</forenames></author><author><keyname>Teneketzis</keyname><forenames>Demosthenis</forenames></author></authors><title>Local public good provisioning in networks: A Nash implementation
  mechanism</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study resource allocation in decentralized information local
public good networks. A network is a local public good network if each user's
actions directly affect the utility of an arbitrary subset of network users. We
consider networks where each user knows only that part of the network that
either affects or is affected by it. Furthermore, each user's utility and
action space are its private information, and each user is a self utility
maximizer. This network model is motivated by several applications including
wireless communications and online advertising. For this network model we
formulate a decentralized resource allocation problem and develop a
decentralized resource allocation mechanism (game form) that possesses the
following properties: (i) All Nash equilibria of the game induced by the
mechanism result in allocations that are optimal solutions of the corresponding
centralized resource allocation problem (Nash implementation). (ii) All users
voluntarily participate in the allocation process specified by the mechanism
(individual rationality). (iii) The mechanism results in budget balance at all
Nash equilibria and off equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0402</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0402</id><created>2012-08-02</created><authors><author><keyname>Jiang</keyname><forenames>Yun</forenames></author><author><keyname>Lim</keyname><forenames>Marcus</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Multidimensional Membership Mixture Models</title><categories>cs.LG stat.ML</categories><comments>9 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the multidimensional membership mixture (M3) models where every
dimension of the membership represents an independent mixture model and each
data point is generated from the selected mixture components jointly. This is
helpful when the data has a certain shared structure. For example, three unique
means and three unique variances can effectively form a Gaussian mixture model
with nine components, while requiring only six parameters to fully describe it.
In this paper, we present three instantiations of M3 models (together with the
learning and inference algorithms): infinite, finite, and hybrid, depending on
whether the number of mixtures is fixed or not. They are built upon Dirichlet
process mixture models, latent Dirichlet allocation, and a combination
respectively. We then consider two applications: topic modeling and learning 3D
object arrangements. Our experiments show that our M3 models achieve better
performance using fewer topics than many classic topic models. We also observe
that topics from the different dimensions of M3 models are meaningful and
orthogonal to each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0403</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0403</id><created>2012-08-02</created><authors><author><keyname>Alomari</keyname><forenames>Esraa</forenames></author><author><keyname>Manickam</keyname><forenames>Selvakumar</forenames></author><author><keyname>Gupta</keyname><forenames>B. B.</forenames></author><author><keyname>Karuppayah</keyname><forenames>Shankar</forenames></author><author><keyname>Alfaris</keyname><forenames>Rafeef</forenames></author></authors><title>Botnet-based Distributed Denial of Service (DDoS) Attacks on Web
  Servers: Classification and Art</title><categories>cs.CR</categories><doi>10.5120/7640-0724</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Botnets are prevailing mechanisms for the facilitation of the distributed
denial of service (DDoS) attacks on computer networks or applications.
Currently, Botnet-based DDoS attacks on the application layer are latest and
most problematic trends in network security threats. Botnet-based DDoS attacks
on the application layer limits resources, curtails revenue, and yields
customer dissatisfaction, among others. DDoS attacks are among the most
difficult problems to resolve online, especially, when the target is the Web
server. In this paper, we present a comprehensive study to show the danger of
Botnet-based DDoS attacks on application layer, especially on the Web server
and the increased incidents of such attacks that has evidently increased
recently. Botnet-based DDoS attacks incidents and revenue losses of famous
companies and government websites are also described. This provides better
understanding of the problem, current solution space, and future research scope
to defend against such attacks efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0407</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0407</id><created>2012-08-02</created><authors><author><keyname>Chen</keyname><forenames>Zhili</forenames></author><author><keyname>Huang</keyname><forenames>He</forenames></author><author><keyname>Huang</keyname><forenames>Liusheng</forenames></author></authors><title>True-MCSA: A Framework for Truthful Double Multi-Channel Spectrum
  Auctions</title><categories>cs.NI cs.GT</categories><comments>12pages, 7figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a framework for truthful double multi-channel spectrum auctions
where each seller (or buyer) can sell (or buy) multiple spectrum channels based
on their individual needs. Open, market-based spectrum trading motivates
existing spectrum owners (as sellers) to lease their selected idle spectrum
channels to new spectrum users (as buyers) who need the spectrum desperately.
The most significant requirement is how to make the auction economic-robust
(truthful in particular) while enabling spectrum reuse to improve spectrum
utilization. Additionally, in practice, both sellers and buyers would require
to trade multiple channels at one time, while guaranteeing their individual
profitability. Unfortunately, none of the existing designs can meet all these
requirements simultaneously. We address these requirements by proposing
True-MCSA, a framework for truthful double multi-channel spectrum auctions.
True-MCSA takes as input any reusability-driven spectrum allocation algorithm,
introduces novel virtual buyer group (VBG) splitting and bidding algorithms,
and applies a winner determination and pricing mechanism to achieve
truthfulness and other economic properties while improving spectrum utilization
and successfully dealing with multi-channel requests from both buyers and
sellers. Our results show that the auction efficiency is impacted by the
economic factors with efficiency degradations within 30%, under different
experimental settings. Furthermore, the experimental results indicate that we
can improve the auction efficiency by choosing a proper bidding algorithm and
using a base bid. True-MCSA makes an important contribution on enabling
spectrum reuse to improve auction efficiency in multi-channel cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0408</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0408</id><created>2012-08-02</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>Fixed Interfaces, Adaptive Interfaces... What is next? Total movability
  - a new paradigm for the user interface</title><categories>cs.HC</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Users can't talk with computers in their natural language (machine codes), so
there are interfaces that allow such communication. 40 years ago the outcome of
computer programs was in the form of long listings covered by numbers and even
the format of those numbers was determined by developers. Throughout the latest
25 years: program views and results are shown in a wide variety of shapes and
variants, but all these possibilities are predefined and fixed in code by
developers; nothing outside of their approved solutions is allowed. My vision
from now on into the future: developers are responsible only for correct work
of a program (calculations, link with the database, etc.) and suggest a good
default interface, but not determine all possible scenarios; only users decide
WHAT, WHEN, and HOW to show. This will be a revolution in our dealing with
computers, but there are obvious questions. How this step can be made? Do all
users need such change? Is it going to be a burden for users or a welcome
revolution?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0412</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0412</id><created>2012-08-02</created><updated>2013-05-22</updated><authors><author><keyname>Jiang</keyname><forenames>Zhiping</forenames></author><author><keyname>Zhao</keyname><forenames>Jizhong</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Han</keyname><forenames>JinSong</forenames></author><author><keyname>Xi</keyname><forenames>Wei</forenames></author></authors><title>Rejecting the Attack: Source Authentication for Wi-Fi Management Frames
  using CSI Information</title><categories>cs.NI cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comparing to well protected data frames, Wi-Fi management frames (MFs) are
extremely vulnerable to various attacks. Since MFs are transmitted without
encryption, attackers can forge them easily. Such attacks can be detected in
cooperative environment such as Wireless Intrusion Detection System (WIDS).
However, in non-cooperative environment it is difficult for a single station to
identify these spoofing attacks using Received Signal Strength (RSS)-based
detection, due to the strong correlation of RSS to both the transmission power
(Txpower) and the location of the sender.
  By exploiting some unique characteristics (i.e., rapid spatial decorrelation,
independence of Txpower, and much richer dimensions) of the Channel State
Information (CSI), a standard feature in 802.11n Specification, we design a
prototype, called CSITE, to authenticate the Wi-Fi management frames by a
single station without external support. Our design CSITE, built upon
off-the-shelf hardware, achieves precise spoofing detection without
collaboration and in-advance finger-print. Several novel techniques are
designed to address the challenges caused by user mobility and channel
dynamics. To verify the performances of our solution, we implement a prototype
of our design and conduct extensive evaluations in various scenarios. Our test
results show that our design significantly outperforms the RSS-based method in
terms of accuracy, robustness, and efficiency: we observe about 8 times
improvement by CSITE over RSS-based method on the falsely accepted attacking
frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0414</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0414</id><created>2012-08-02</created><authors><author><keyname>Jong</keyname><forenames>Yun-Chol</forenames></author></authors><title>Grey Power Models Based on Optimization of Initial Condition and Model
  Parameters</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel approach to improve prediction accuracy of grey power
models including GM(1,1) and grey Verhulst model through optimization of the
initial condition and model parameters in this paper. And we propose a modified
grey Verhulst model. The new initial condition consists of the first item and
the last item of a sequence generated from applying the first-order
accumulative generation operator on the sequence of raw data. Weighted
coefficients of the first item and the last item in the combination as the
initial condition are derived from a method of minimizing error summation of
square. We shows that the newly modified grey power model is an extension of
the previous optimized GM(1,1) models and grey Verhulst models. The new
optimized initial condition can express the principle of new information
priority emphasized on in grey systems theory fully. The result of a numerical
example indicates that the modified grey model presented in this paper can
obtain a better prediction performance than that from the original grey model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0432</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0432</id><created>2012-08-02</created><updated>2014-03-06</updated><authors><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Zhang</keyname><forenames>Yuqian</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>Efficient Point-to-Subspace Query in $\ell^1$ with Application to Robust
  Object Instance Recognition</title><categories>cs.CV cs.LG stat.ML</categories><comments>Revised based on reviewers' feedback; one new experiment on
  synthesized data added; one section discussing the speed up added</comments><journal-ref>SIAM Journal on Imaging Sciences, 7(4):2105 - 2138, 2014</journal-ref><doi>10.1137/130936166</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by vision tasks such as robust face and object recognition, we
consider the following general problem: given a collection of low-dimensional
linear subspaces in a high-dimensional ambient (image) space, and a query point
(image), efficiently determine the nearest subspace to the query in $\ell^1$
distance. In contrast to the naive exhaustive search which entails large-scale
linear programs, we show that the computational burden can be cut down
significantly by a simple two-stage algorithm: (1) projecting the query and
data-base subspaces into lower-dimensional space by random Cauchy matrix, and
solving small-scale distance evaluations (linear programs) in the projection
space to locate candidate nearest; (2) with few candidates upon independent
repetition of (1), getting back to the high-dimensional space and performing
exhaustive search. To preserve the identity of the nearest subspace with
nontrivial probability, the projection dimension typically is low-order
polynomial of the subspace dimension multiplied by logarithm of number of the
subspaces (Theorem 2.1). The reduced dimensionality and hence complexity
renders the proposed algorithm particularly relevant to vision application such
as robust face and object instance recognition that we investigate empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0435</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0435</id><created>2012-08-02</created><authors><author><keyname>Zhong</keyname><forenames>Caijun</forenames></author><author><keyname>Suraweera</keyname><forenames>Himal A.</forenames></author><author><keyname>Huang</keyname><forenames>Aiping</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>Outage Probability of Dual-Hop Multiple Antenna AF Relaying Systems with
  Interference</title><categories>cs.IT math.IT</categories><comments>Accepted to appear in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analytical investigation on the outage performance of
dual-hop multiple antenna amplify-and-forward relaying systems in the presence
of interference. For both the fixed-gain and variable-gain relaying schemes,
exact analytical expressions for the outage probability of the systems are
derived. Moreover, simple outage probability approximations at the high signal
to noise ratio regime are provided, and the diversity order achieved by the
systems are characterized. Our results suggest that variable-gain relaying
systems always outperform the corresponding fixed-gain relaying systems. In
addition, the fixed-gain relaying schemes only achieve diversity order of one,
while the achievable diversity order of the variable-gain relaying scheme
depends on the location of the multiple antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0446</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0446</id><created>2012-08-02</created><authors><author><keyname>Akian</keyname><forenames>Marianne</forenames></author><author><keyname>Cochet-Terrasson</keyname><forenames>Jean</forenames></author><author><keyname>Detournay</keyname><forenames>Sylvie</forenames></author><author><keyname>Gaubert</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Policy iteration algorithm for zero-sum multichain stochastic games with
  mean payoff and perfect information</title><categories>math.OC cs.GT</categories><comments>34pages</comments><msc-class>91A20, 31C45, 47H09, 91A15, 91A43, 90C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider zero-sum stochastic games with finite state and action spaces,
perfect information, mean payoff criteria, without any irreducibility
assumption on the Markov chains associated to strategies (multichain games).
The value of such a game can be characterized by a system of nonlinear
equations, involving the mean payoff vector and an auxiliary vector (relative
value or bias). We develop here a policy iteration algorithm for zero-sum
stochastic games with mean payoff, following an idea of two of the authors
(Cochet-Terrasson and Gaubert, C. R. Math. Acad. Sci. Paris, 2006). The
algorithm relies on a notion of nonlinear spectral projection (Akian and
Gaubert, Nonlinear Analysis TMA, 2003), which is analogous to the notion of
reduction of super-harmonic functions in linear potential theory. To avoid
cycling, at each degenerate iteration (in which the mean payoff vector is not
improved), the new relative value is obtained by reducing the earlier one. We
show that the sequence of values and relative values satisfies a
lexicographical monotonicity property, which implies that the algorithm does
terminate. We illustrate the algorithm by a mean-payoff version of Richman
games (stochastic tug-of-war or discrete infinity Laplacian type equation), in
which degenerate iterations are frequent. We report numerical experiments on
large scale instances, arising from the latter games, as well as from monotone
discretizations of a mean-payoff pursuit-evasion deterministic differential
game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0451</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0451</id><created>2012-08-02</created><authors><author><keyname>Martinez-Martinez</keyname><forenames>Ismael</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author></authors><title>Directed Random Markets: Connectivity determines Money</title><categories>nlin.AO cs.MA q-fin.TR</categories><comments>14 pages, 6 figures</comments><doi>10.1142/S012918311250088X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boltzmann-Gibbs distribution arises as the statistical equilibrium
probability distribution of money among the agents of a closed economic system
where random and undirected exchanges are allowed. When considering a model
with uniform savings in the exchanges, the final distribution is close to the
gamma family. In this work, we implement these exchange rules on networks and
we find that these stationary probability distributions are robust and they are
not affected by the topology of the underlying network. We introduce a new
family of interactions: random but directed ones. In this case, it is found the
topology to be determinant and the mean money per economic agent is related to
the degree of the node representing the agent in the network. The relation
between the mean money per economic agent and its degree is shown to be linear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0460</identifier>
 <datestamp>2013-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0460</id><created>2012-08-02</created><updated>2012-08-22</updated><authors><author><keyname>Miller</keyname><forenames>Alice</forenames></author><author><keyname>Prosser</keyname><forenames>Patrick</forenames></author></authors><title>Diamond-free Degree Sequences</title><categories>cs.DM cs.DS</categories><comments>8 pages, 2 figures, 2 algorithms, 2 models, 1 table</comments><report-no>TR-2010-318</report-no><journal-ref>Acta Univ. Sapientiae, Informatica, 4(2): 189-200, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new problem, CSPLib problem number 50, to generate all degree
sequences that have a corresponding diamond-free graph with secondary
properties. This problem arises naturally from a problem in mathematics to do
with balanced incomplete block designs; we devote a section of this paper to
this. The problem itself is challenging with respect to computational effort
arising from the large number of symmetries within the models. We introduce two
models for this problem. The second model is an improvement on the first, and
this improvement largely consists of breaking the problem into two stages, the
first stage producing graphical degree sequences that satisfy arithmetic
constraints and the second part testing that there exists a graph with that
degree sequence that is diamond-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0468</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0468</id><created>2012-08-02</created><updated>2012-11-03</updated><authors><author><keyname>Wang</keyname><forenames>Baokui</forenames></author><author><keyname>Chen</keyname><forenames>Xiaojie</forenames></author><author><keyname>Wang</keyname><forenames>Long</forenames></author></authors><title>Probabilistic interconnection between interdependent networks promotes
  cooperation in the public goods game</title><categories>physics.soc-ph cond-mat.stat-mech cs.GT cs.SI</categories><comments>12 pages, 6 figures, submitted to Journal of Statistical Mechanics:
  Theory and Experiment(JSTAT)</comments><msc-class>06B30</msc-class><doi>10.1088/1742-5468/2012/11/P11017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most previous works study the evolution of cooperation in a structured
population by commonly employing an isolated single network. However, realistic
systems are composed of many interdependent networks coupled with each other,
rather than the isolated single one. In this paper, we consider a system
including two interacting networks with the same size, entangled with each
other by the introduction of probabilistic interconnections. We introduce the
public goods game into such system, and study how the probabilistic
interconnection influences the evolution of cooperation of the whole system and
the coupling effect between two layers of interdependent networks. Simulation
results show that there exists an intermediate region of interconnection
probability leading to the maximum cooperation level in the whole system.
Interestingly, we find that at the optimal interconnection probability the
fraction of internal links between cooperators in two layers is maximal. Also,
even if initially there are no cooperators in one layer of interdependent
networks, cooperation can still be promoted by probabilistic interconnection,
and the cooperation levels in both layers can more easily reach an agreement at
the intermediate interconnection probability. Our results may be helpful in
understanding the cooperative behavior in some realistic interdependent
networks and thus highlight the importance of probabilistic interconnection on
the evolution of cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0482</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0482</id><created>2012-08-02</created><authors><author><keyname>Powers</keyname><forenames>Simon T.</forenames></author><author><keyname>Penn</keyname><forenames>Alexandra S.</forenames></author><author><keyname>Watson</keyname><forenames>Richard A.</forenames></author></authors><title>The concurrent evolution of cooperation and the population structures
  that support it</title><categories>q-bio.PE cs.SI physics.soc-ph</categories><comments>Post-print of accepted manuscript, 6 figures</comments><journal-ref>Evolution 65(6), pp. 1527-1543, June 2011</journal-ref><doi>10.1111/j.1558-5646.2011.01250.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of cooperation often depends upon population structure, yet
nearly all models of cooperation implicitly assume that this structure remains
static. This is a simplifying assumption, because most organisms possess
genetic traits that affect their population structure to some degree. These
traits, such as a group size preference, affect the relatedness of interacting
individuals and hence the opportunity for kin or group selection. We argue that
models that do not explicitly consider their evolution cannot provide a
satisfactory account of the origin of cooperation, because they cannot explain
how the prerequisite population structures arise. Here, we consider the
concurrent evolution of genetic traits that affect population structure, with
those that affect social behavior. We show that not only does population
structure drive social evolution, as in previous models, but that the
opportunity for cooperation can in turn drive the creation of population
structures that support it. This occurs through the generation of linkage
disequilibrium between socio-behavioral and population-structuring traits, such
that direct kin selection on social behavior creates indirect selection
pressure on population structure. We illustrate our argument with a model of
the concurrent evolution of group size preference and social behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0501</identifier>
 <datestamp>2012-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0501</id><created>2012-08-02</created><updated>2012-11-26</updated><authors><author><keyname>Brinkmann</keyname><forenames>Gunnar</forenames></author><author><keyname>Goedgebeur</keyname><forenames>Jan</forenames></author><author><keyname>Schlage-Puchta</keyname><forenames>Jan-Christoph</forenames></author></authors><title>Ramsey numbers R(K3,G) for graphs of order 10</title><categories>math.CO cs.DM</categories><comments>24 pages, submitted for publication; added some comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we give the generalized triangle Ramsey numbers R(K3,G) of 12
005 158 of the 12 005 168 graphs of order 10. There are 10 graphs remaining for
which we could not determine the Ramsey number. Most likely these graphs need
approaches focusing on each individual graph in order to determine their
triangle Ramsey number. The results were obtained by combining new
computational and theoretical results. We also describe an optimized algorithm
for the generation of all maximal triangle-free graphs and triangle Ramsey
graphs. All Ramsey numbers up to 30 were computed by our implementation of this
algorithm. We also prove some theoretical results that are applied to determine
several triangle Ramsey numbers larger than 30. As not only the number of
graphs is increasing very fast, but also the difficulty to determine Ramsey
numbers, we consider it very likely that the table of all triangle Ramsey
numbers for graphs of order 10 is the last complete table that can possibly be
determined for a very long time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0505</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0505</id><created>2012-08-02</created><authors><author><keyname>Hyyti&#xe4;</keyname><forenames>Esa</forenames></author><author><keyname>Ott</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>Criticality of Large Delay Tolerant Networks via Directed Continuum
  Percolation in Space-Time</title><categories>cs.PF cs.NI</categories><acm-class>C.4; C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study delay tolerant networking (DTN) and in particular, its capacity to
store, carry and forward messages so that the messages eventually reach their
final destinations. We approach this broad question in the framework of
percolation theory. To this end, we assume an elementary mobility model, where
nodes arrive to an infinite plane according to a Poisson point process, move a
certain distance L, and then depart. In this setting, we characterize the mean
density of nodes required to support DTN style networking. In particular, under
the given assumptions, we show that DTN is feasible when the mean node degree
is greater than 4 e(g), where parameter g=L/d is the ratio of the distance L to
the transmission range d, and e(g) is the critical reduced number density of
tilted cylinders in a directed continuum percolation model. By means of Monte
Carlo simulations, we give numerical values for e(g). The asymptotic behavior
of e(g) when g tends to infinity is also derived from a fluid flow analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0515</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0515</id><created>2012-08-02</created><updated>2012-08-11</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames><affiliation>Universit&#xe0; di Bologna - Dipartimento di Scienze dell'Informazione</affiliation></author><author><keyname>Martini</keyname><forenames>Simone</forenames><affiliation>Universit&#xe0; di Bologna - Dipartimento di Scienze dell'Informazione</affiliation></author></authors><title>On Constructor Rewrite Systems and the Lambda Calculus</title><categories>cs.PL</categories><comments>27 pages. arXiv admin note: substantial text overlap with
  arXiv:0904.4120</comments><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 14,
  2012) lmcs:1213</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that orthogonal constructor term rewrite systems and lambda-calculus
with weak (i.e., no reduction is allowed under the scope of a
lambda-abstraction) call-by-value reduction can simulate each other with a
linear overhead. In particular, weak call-by- value beta-reduction can be
simulated by an orthogonal constructor term rewrite system in the same number
of reduction steps. Conversely, each reduction in a term rewrite system can be
simulated by a constant number of beta-reduction steps. This is relevant to
implicit computational complexity, because the number of beta steps to normal
form is polynomially related to the actual cost (that is, as performed on a
Turing machine) of normalization, under weak call-by-value reduction.
Orthogonal constructor term rewrite systems and lambda-calculus are thus both
polynomially related to Turing machines, taking as notion of cost their natural
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0525</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0525</id><created>2012-08-02</created><updated>2013-05-17</updated><authors><author><keyname>Shang</keyname><forenames>Shang</forenames></author><author><keyname>Cuff</keyname><forenames>Paul W.</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author></authors><title>An Upper Bound on the Convergence Time for Distributed Binary Consensus</title><categories>cs.PF</categories><comments>15th International Conference on Information Fusion, July 2012, 7
  pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The problem addressed in this paper is the analysis of a distributed
consensus algorithm for arbitrary networks, proposed by B\'en\'ezit et al.. In
the initial setting, each node in the network has one of two possible states
(&quot;yes&quot; or &quot;no&quot;). Nodes can update their states by communicating with their
neighbors via a 2-bit message in an asynchronous clock setting. Eventually, all
nodes reach consensus on the majority states. We use the theory of electric
networks, random walks, and couplings of Markov chains to derive an O(N4 logN)
upper bound for the expected convergence time on an arbitrary graph of size N.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0526</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0526</id><created>2012-08-02</created><authors><author><keyname>Ercsey-Ravasz</keyname><forenames>Maria</forenames></author><author><keyname>Toroczkai</keyname><forenames>Zoltan</forenames></author></authors><title>Optimization hardness as transient chaos in an analog approach to
  constraint satisfaction</title><categories>cs.CC cs.NE math.DS nlin.CD physics.comp-ph</categories><comments>27 pages, 14 figures</comments><msc-class>37D45, 90C27, 68Q10, 68Q17, 34G20</msc-class><acm-class>F.2.3; F.1.0</acm-class><journal-ref>Nature Physics, vol. 7, p. 966-970, 2011</journal-ref><doi>10.1038/NPHYS2105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boolean satisfiability [1] (k-SAT) is one of the most studied optimization
problems, as an efficient (that is, polynomial-time) solution to k-SAT (for
$k\geq 3$) implies efficient solutions to a large number of hard optimization
problems [2,3]. Here we propose a mapping of k-SAT into a deterministic
continuous-time dynamical system with a unique correspondence between its
attractors and the k-SAT solution clusters. We show that beyond a constraint
density threshold, the analog trajectories become transiently chaotic [4-7],
and the boundaries between the basins of attraction [8] of the solution
clusters become fractal [7-9], signaling the appearance of optimization
hardness [10]. Analytical arguments and simulations indicate that the system
always finds solutions for satisfiable formulae even in the frozen regimes of
random 3-SAT [11] and of locked occupation problems [12] (considered among the
hardest algorithmic benchmarks); a property partly due to the system's
hyperbolic [4,13] character. The system finds solutions in polynomial
continuous-time, however, at the expense of exponential fluctuations in its
energy function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0535</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0535</id><created>2012-08-02</created><authors><author><keyname>Schwaab</keyname><forenames>Christopher</forenames></author><author><keyname>Siek</keyname><forenames>Jeremy G.</forenames></author></authors><title>Modular Type-Safety Proofs using Dependant Types</title><categories>cs.PL</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While methods of code abstraction and reuse are widespread and well
researched, methods of proof abstraction and reuse are still emerging. We
consider the use of dependent types for this purpose, introducing a completely
mechanical approach to proof composition. We show that common techniques for
abstracting algorithms over data structures naturally translate to abstractions
over proofs. We first introduce a language composed of a series of smaller
language components tied together by standard techniques from Malcom (1990). We
proceed by giving proofs of type preservation for each language component and
show that the basic ideas used in composing the syntactic data structures can
be applied to their semantics as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0539</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0539</id><created>2012-08-02</created><authors><author><keyname>Briet</keyname><forenames>Jop</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author><author><keyname>Regev</keyname><forenames>Oded</forenames></author></authors><title>Locally decodable codes and the failure of cotype for projective tensor
  products</title><categories>math.FA cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that for every $p\in (1,\infty)$ there exists a Banach space $X$
of finite cotype such that the projective tensor product $\ell_p\tp X$ fails to
have finite cotype. More generally, if $p_1,p_2,p_3\in (1,\infty)$ satisfy
$\frac{1}{p_1}+\frac{1}{p_2}+\frac{1}{p_3}\le 1$ then
$\ell_{p_1}\tp\ell_{p_2}\tp\ell_{p_3}$ does not have finite cotype. This is a
proved via a connection to the theory of locally decodable codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0541</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0541</id><created>2012-08-02</created><authors><author><keyname>Powers</keyname><forenames>Simon T.</forenames></author><author><keyname>He</keyname><forenames>Jun</forenames></author></authors><title>A hybrid artificial immune system and Self Organising Map for network
  intrusion detection</title><categories>cs.NE cs.CR</categories><comments>Post-print of accepted manuscript. 32 pages and 3 figures</comments><journal-ref>Information Sciences 178(15), pp. 3024-3042, August 2008</journal-ref><doi>10.1016/j.ins.2007.11.028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network intrusion detection is the problem of detecting unauthorised use of,
or access to, computer systems over a network. Two broad approaches exist to
tackle this problem: anomaly detection and misuse detection. An anomaly
detection system is trained only on examples of normal connections, and thus
has the potential to detect novel attacks. However, many anomaly detection
systems simply report the anomalous activity, rather than analysing it further
in order to report higher-level information that is of more use to a security
officer. On the other hand, misuse detection systems recognise known attack
patterns, thereby allowing them to provide more detailed information about an
intrusion. However, such systems cannot detect novel attacks.
  A hybrid system is presented in this paper with the aim of combining the
advantages of both approaches. Specifically, anomalous network connections are
initially detected using an artificial immune system. Connections that are
flagged as anomalous are then categorised using a Kohonen Self Organising Map,
allowing higher-level information, in the form of cluster membership, to be
extracted. Experimental results on the KDD 1999 Cup dataset show a low false
positive rate and a detection and classification rate for Denial-of-Service and
User-to-Root attacks that is higher than those in a sample of other works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0542</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0542</id><created>2012-07-31</created><authors><author><keyname>Duan</keyname><forenames>Wen-Qi</forenames></author></authors><title>A Constructive Algorithm to Prove P=NP</title><categories>cs.DS</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After reducing the undirected Hamiltonian cycle problem into the TSP problem
with cost 0 or 1, we developed an effective algorithm to compute the optimal
tour of the transformed TSP. Our algorithm is described as a growth process:
initially, constructing 4-vertexes optimal tour; next, one new vertex being
added into the optimal tour in such a way to obtain the new optimal tour; then,
repeating the previous step until all vertexes are included into the optimal
tour. This paper has shown that our constructive algorithm can solve the
undirected Hamiltonian cycle problem in polynomial time. According to
Cook-Levin theorem, we argue that we have provided a constructive proof of
P=NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0554</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0554</id><created>2012-08-02</created><authors><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author><author><keyname>Korhonen</keyname><forenames>Janne H.</forenames></author></authors><title>Fast Monotone Summation over Disjoint Sets</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of computing an ensemble of multiple sums where the
summands in each sum are indexed by subsets of size $p$ of an $n$-element
ground set. More precisely, the task is to compute, for each subset of size $q$
of the ground set, the sum over the values of all subsets of size $p$ that are
disjoint from the subset of size $q$. We present an arithmetic circuit that,
without subtraction, solves the problem using $O((n^p+n^q)\log n)$ arithmetic
gates, all monotone; for constant $p$, $q$ this is within the factor $\log n$
of the optimal. The circuit design is based on viewing the summation as a &quot;set
nucleation&quot; task and using a tree-projection approach to implement the
nucleation. Applications include improved algorithms for counting heaviest
$k$-paths in a weighted graph, computing permanents of rectangular matrices,
and dynamic feature selection in machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0561</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0561</id><created>2012-08-02</created><authors><author><keyname>Huang</keyname><forenames>Longbo</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>A Benes Packet Network</title><categories>math.OC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Benes networks are constructed with simple switch modules and have many
advantages, including small latency and requiring only an almost linear number
of switch modules. As circuit-switches, Benes networks are rearrangeably
non-blocking, which implies that they are full-throughput as packet switches,
with suitable routing.
  Routing in Benes networks can be done by time-sharing permutations. However,
this approach requires centralized control of the switch modules and
statistical knowledge of the traffic arrivals. We propose a backpressure-based
routing scheme for Benes networks, combined with end-to-end congestion control.
This approach achieves the maximal utility of the network and requires only
four queues per module, independently of the size of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0562</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0562</id><created>2012-08-02</created><authors><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Draper</keyname><forenames>Stark</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>Learning the Interference Graph of a Wireless Network</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key challenge in wireless networking is the management of interference
between transmissions. Identifying which transmitters interfere with each other
is a crucial first step. Complicating the task is the fact that the topology of
wireless networks changes with time, and so identification may need to be
performed on a regular basis. Injecting probing traffic to assess interference
can lead to unacceptable overhead, and so this paper focuses on interference
estimation based on passive traffic monitoring. We concentrate on networks that
use the CSMA/CA protocol, although our model is more general.
  We cast the task of estimating the interference environment as a graph
learning problem. Nodes represent transmitters and edges represent the presence
of interference between pairs of transmitters. We passively observe network
traffic transmission patterns and collect information on transmission successes
and failures. We establish bounds on the number of observations required to
identify the interference graph reliably with high probability.
  Our main results are scaling laws telling us how the number of observations
must grow in terms of the total number of nodes $n$ in the network and the
maximum number of interfering transmitters $d$ per node (maximum node degree).
The effects of hidden terminal interference on the observation requirements are
also quantified. We show that it is necessary and sufficient that the
observation period grows like $d^2 \log n$, and we propose a practical
algorithm that reliably identifies the graph from this length of observation.
The observation requirements scale quite mildly with network size, and networks
with sparse interference (small $d$) can be identified more rapidly.
Computational experiments based on a realistic simulations of the traffic and
protocol lend additional support to these conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0564</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0564</id><created>2012-07-27</created><updated>2012-08-05</updated><authors><author><keyname>Chekina</keyname><forenames>L.</forenames></author><author><keyname>Mimran</keyname><forenames>D.</forenames></author><author><keyname>Rokach</keyname><forenames>L.</forenames></author><author><keyname>Elovici</keyname><forenames>Y.</forenames></author><author><keyname>Shapira</keyname><forenames>B.</forenames></author></authors><title>Detection of Deviations in Mobile Applications Network Behavior</title><categories>cs.CR cs.LG</categories><comments>Length of 10 pages, submitted to Annual Computer Security
  Applications Conference, ACSAC'2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel system for detecting meaningful deviations in a mobile
application's network behavior is proposed. The main goal of the proposed
system is to protect mobile device users and cellular infrastructure companies
from malicious applications. The new system is capable of: (1) identifying
malicious attacks or masquerading applications installed on a mobile device,
and (2) identifying republishing of popular applications injected with a
malicious code. The detection is performed based on the application's network
traffic patterns only. For each application two types of models are learned.
The first model, local, represents the personal traffic pattern for each user
using an application and is learned on the device. The second model,
collaborative, represents traffic patterns of numerous users using an
application and is learned on the system server. Machine-learning methods are
used for learning and detection purposes. This paper focuses on methods
utilized for local (i.e., on mobile device) learning and detection of
deviations from the normal application's behavior. These methods were
implemented and evaluated on Android devices. The evaluation experiments
demonstrate that: (1) various applications have specific network traffic
patterns and certain application categories can be distinguishable by their
network patterns, (2) different levels of deviations from normal behavior can
be detected accurately, and (3) local learning is feasible and has a low
performance overhead on mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0569</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0569</id><created>2012-07-23</created><authors><author><keyname>Ahmad</keyname><forenames>Anzar</forenames></author><author><keyname>Gowri</keyname><forenames>Prof. R.</forenames></author><author><keyname>Gupta</keyname><forenames>Prof. SC</forenames></author></authors><title>Simulation Study For Performance Comparison in Hierarchical Network With
  CHG Approach in MANET</title><categories>cs.NI</categories><comments>14 pages,8 figures, International journal of computer engineering
  science(IJCES)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The implementation of MANET for commercial purposes is not an easy task.
Unlike other wireless technologies such as cellular networks, MANET face more
difficult problems concerning management functions, routing and scalability .
As a solution to these complications, clustering schemes are proposed for MANET
in order to organize the network topology in a hierarchical manner. Many
clustering techniques have been developed. Clustering is a method which
aggregates nodes into groups. These groups are contained by the network and
they are known as clusters. By Increasing network capacity and reducing the
routing overhead through clustering brings more efficiency and effectiveness to
scalability in relation to node numbers and the necessity for high mobility.
The manager node in clustering has responsibility for many functions such as
cluster maintenance, routing table updates, and the discovery of new routes
within the network. The other node named as gateway node communicate to the
other cluster. In this paper we remove the cluster head (CH) and given a new
approach in which cluster head and gateway will be same and that node is known
as cluster head gateway (CHG), in which all the responsibilities of cluster
head and gateway will be perform by the Cluster head gateway(CHG) itself. By
applying this approach we reduce of overheads and improve the over all
performance of the network while throughput will be same in both condition with
the help of Exata simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0573</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0573</id><created>2012-08-02</created><authors><author><keyname>Bhattacharya</keyname><forenames>Subhrajit</forenames></author><author><keyname>Lipsky</keyname><forenames>David</forenames></author><author><keyname>Ghrist</keyname><forenames>Robert</forenames></author><author><keyname>Kumar</keyname><forenames>Vijay</forenames></author></authors><title>Invariants for Homology Classes with Application to Optimal Search and
  Planning Problem in Robotics</title><categories>math.AT cs.RO</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider planning problems on a punctured Euclidean spaces, $\mathbb{R}^D
- \widetilde{\mathcal{O}}$, where $\widetilde{\mathcal{O}}$ is a collection of
obstacles. Such spaces are of frequent occurrence as configuration spaces of
robots, where $\widetilde{\mathcal{O}}$ represent either physical obstacles
that the robots need to avoid (e.g., walls, other robots, etc.) or illegal
states (e.g., all legs off-the-ground). As state-planning is translated to
path-planning on a configuration space, we collate equivalent plannings via
topologically-equivalent paths. This prompts finding or exploring the different
homology classes in such environments and finding representative optimal
trajectories in each such class.
  In this paper we start by considering the problem of finding a complete set
of easily computable homology class invariants for $(N-1)$-cycles in
$(\mathbb{R}^D - \widetilde{\mathcal{O}})$. We achieve this by finding explicit
generators of the $(N-1)^{st}$ de Rham cohomology group of this punctured
Euclidean space, and using their integrals to define cocycles. The action of
those dual cocycles on $(N-1)$-cycles gives the desired complete set of
invariants. We illustrate the computation through examples.
  We further show that, due to the integral approach, this complete set of
invariants is well-suited for efficient search-based planning of optimal robot
trajectories with topological constraints. Finally we extend this approach to
computation of invariants in spaces derived from $(\mathbb{R}^D -
\widetilde{\mathcal{O}})$ by collapsing subspace, thereby permitting
application to a wider class of non-Euclidean ambient spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0577</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0577</id><created>2012-08-02</created><authors><author><keyname>Kharitonov</keyname><forenames>Daniel</forenames></author></authors><title>Green Telecom Metrics in Perspective</title><categories>cs.NI</categories><comments>Preprint submitted to APCC 2012 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fast and parallel evolution of ways to measure and assess energy efficiency
in telecom has resulted in an entangled web of drafts and recommendations
originating from government, research, and standards organizations. This paper
focuses primarily on so-called &quot;large network equipment&quot; metrics and intends to
capture state-of-the-art in this area of green communications. Competing
approaches towards efficiency assessment are studied for their applicability
and completeness, with special emphasis on topics relevant to future subject
studies
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0581</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0581</id><created>2012-08-02</created><authors><author><keyname>Menne</keyname><forenames>Ulrich</forenames></author><author><keyname>Raack</keyname><forenames>Christian</forenames></author><author><keyname>Wessaly</keyname><forenames>Roland</forenames></author><author><keyname>Kharitonov</keyname><forenames>Daniel</forenames></author></authors><title>Optimal Degree of Optical Circuit Switching in IP-over-WDM Networks</title><categories>cs.NI</categories><comments>Long version of a manuscript originally submitted to ONDM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the influence of technology, traffic properties and
price trends on optimized design of a reference IP-over-WDM network with rich
underlying fiber topology. In each network node, we investigate the optimal
degree of traffic switching in an optical (lambda) domain versus an electrical
(packet) domain, also known as measure of node transparency. This measure is
studied in connection to changes in traffic volume, demand affinity, optical
circuit speeds and equipment cost. By applying variable design constraints, we
assess the relative roles of the two distinct equipment groups, IP routers and
optical cross-connects, with respect to resulting changes in cost-sensitive
network architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0588</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0588</id><created>2012-08-02</created><updated>2013-05-02</updated><authors><author><keyname>Pfitzner</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Scholtes</keyname><forenames>Ingo</forenames></author><author><keyname>Garas</keyname><forenames>Antonios</forenames></author><author><keyname>Tessone</keyname><forenames>Claudio J.</forenames></author><author><keyname>Schweitzer</keyname><forenames>Frank</forenames></author></authors><title>Betweenness Preference: Quantifying Correlations in the Topological
  Dynamics of Temporal Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages, 4 figures</comments><journal-ref>Phys. Rev. Lett. 110, 198701 (2013)</journal-ref><doi>10.1103/PhysRevLett.110.198701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study correlations in temporal networks and introduce the notion of
betweenness preference. It allows to quantify to what extent paths, existing in
time-aggregated representations of temporal networks, are actually realizable
based on the sequence of interactions. We show that betweenness preference is
present in empirical temporal network data and that it influences the length of
shortest time-respecting paths. Using four different data sets, we further
argue that neglecting betweenness preference leads to wrong conclusions about
dynamical processes on temporal networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0590</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0590</id><created>2012-08-02</created><authors><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author></authors><title>Translation of Bengali Terms in Mobile Phones: a Simplified Approach
  Based on the Prescriptions of Conventional Accent Understand Ability</title><categories>cs.HC</categories><comments>ISSN 2249-2593</comments><journal-ref>International Journal of Computer and Organization Trends (IJCOT)
  2(1) 33-38 (2012)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Technology is the making, usage and knowledge of tools, techniques, crafts,
systems or methods of organization in order to solve a problem or serve some
purpose. This is true for humanitarian issues also. Such as the issue of
language and its primitive attraction for its native speakers which is visible
in the cases of the language spoken at home, outside home, in its choice of
newspapers, and TV channels. Everyone finds to accomplish its need by the same
way. Example includes the preference of using mobile phones in English. The
satisfactory answer to this tendency may be the lack of finding the
translations in native language---Bengali terms used in current mobile phones
are hard to understand by users. I have investigated various mobile phone
models available in Indian market which have lot of problems in Bengali
interpretation. I have sort out the root cause of this problem to be the
conventional accent understand ability. Depending on this I have created a set
of equivalent terms that I hope to be simpler in use. In this paper I have
performed experiments to compare the new terms to the available ones. Our
findings show that the newly derived terms do better in term of performance
than to current ones. It has also been seen that acceptance of Bengali terms in
mobile phones might grow if the parameter of simpler and conventional accent
understand ability are met while designing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0591</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0591</id><created>2012-08-02</created><updated>2012-08-06</updated><authors><author><keyname>Majumder</keyname><forenames>Poulami</forenames></author><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author></authors><title>Hatch-Sens: a Theoretical Bio-Inspired Model to Monitor the Hatching of
  Plankton Culture in the Vicinity of Wireless Sensor Network</title><categories>cs.NI</categories><comments>ISSN 0975-9646</comments><journal-ref>International Journal of Computer Science and Information
  Technologies (IJCSIT) 3(4) 4764-4769 (2012)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Plankton research has always been an important area of biology. Due to
various environmental issues and other research interests, plankton hatching
and harnessing has been extremely red-marked zone for bio-aqua scientists
recently. To counter this problem, no wireless sensor assisted technique or
mechanism has yet not been devised. In this literature, we propose a novel
approach to pursue this task by the virtue of a theoretical Bio-inspired model
named Hatch-Sens, to automatically monitor different parameters of plankton
hatching in laboratory environment. This literature illustrates the concepts
and detailed mechanisms to accumulate this given problem. Hatch-Sens is a novel
idea which combines the biology with computer in its sensing network to monitor
hatching parameters of Artemia salina. This model reduces the manual tiresome
monitoring of hatching of plankton culture by wireless sensor network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0592</identifier>
 <datestamp>2012-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0592</id><created>2012-08-02</created><updated>2012-09-13</updated><authors><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author><author><keyname>Banerjee</keyname><forenames>Ansuman</forenames></author><author><keyname>Bag</keyname><forenames>Banibrata</forenames></author></authors><title>Debugging Invariant Issues in Pseudo Embedded Program: an Analytical
  Approach</title><categories>cs.SE</categories><comments>This paper has been withdrawn by the author due to a crucial error in
  fig 1o</comments><journal-ref>International Journal of Computer Science and Information
  Technologies (IJCSIT) 2(2) 780-785, 2011,</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Debugging is an unavoidable and most crucial aspect of software development
life cycle. Especially when it comes the turn of embedded one. Due to the
requirements of low code size and less resource consumption, the embedded
softwares need to be upgraded all the time involving obvious change of code
during development phase. This leads the huge risk of intrusion of bugs into
the code at production time. In this paper we propose an approach of debugging
embedded program in pseudo format, incorporating invariant analysis. Our
methodology works on top of Daikon, a popular invariant analyzer. We have
experimented with a simplified code snippet [1], used during debugging a
reported error in BusyBox which is a de-facto standard for Linux in embedded
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0593</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0593</id><created>2012-08-02</created><authors><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author></authors><title>The green grid saga - a green initiative to data centers: a review</title><categories>cs.SY cs.DC</categories><comments>ISSN 0976-5166</comments><journal-ref>Indian Journal of Computer Science and Engineering (IJCSE) 1(4),
  2010, 333-339</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Information Technology (IT) significantly impacts the environment throughout
its life cycle. Most enterprises have not paid enough attention to this until
recently. IT's environmental impact can be significantly reduced by behavioral
changes, as well as technology changes. Given the relative energy and materials
inefficiency of most IT infrastructures today, many green IT initiatives can be
easily tackled at no incremental cost. The Green Grid - a non-profit trade
organization of IT professionals is such an initiative, formed to initiate the
issues of power and cooling in data centers, scattered world-wide. The Green
Grid seeks to define best practices for optimizing the efficient consumption of
power at IT equipment and facility levels, as well as the manner in which
cooling is delivered at these levels hence, providing promising attitude in
bringing down the environmental hazards, as well as proceeding to the new era
of green computing. In this paper we review the various analytical aspects of
The Green Grid upon the data centers and found green facts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0594</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0594</id><created>2012-08-02</created><authors><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author><author><keyname>Banerjee</keyname><forenames>Ansuman</forenames></author></authors><title>Debugging Memory Issues In Embedded Linux: A Case Study</title><categories>cs.SE</categories><comments>In proceedings of IEEE TechSym 2011, 14-16 January, 2011, IIT
  kharagpur, India</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Debugging denotes the process of detecting root causes of unexpected
observable behaviors in programs, such as a program crash, an unexpected output
value being produced or an assertion violation. Debugging of program errors is
a difficult task and often takes a significant amount of time in the software
development life cycle. In the context of embedded software, the probability of
bugs is quite high. Due to requirements of low code size and less resource
consumption, embedded softwares typically do away with a lot of sanity checks
during development time. This leads to high chance of errors being uncovered in
the production code at run time. In this paper we propose a methodology for
debugging errors in BusyBox, a de-facto standard for Linux in embedded systems.
Our methodology works on top of Valgrind, a popular memory error detector and
Daikon, an invariant analyzer. We have experimented with two published errors
in BusyBox and report our findings in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0615</identifier>
 <datestamp>2012-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0615</id><created>2012-08-02</created><updated>2012-11-21</updated><authors><author><keyname>Afrati</keyname><forenames>Foto N.</forenames></author><author><keyname>Fotakis</keyname><forenames>Dimitris</forenames></author><author><keyname>Ullman</keyname><forenames>Jeffrey D.</forenames></author></authors><title>Enumerating Subgraph Instances Using Map-Reduce</title><categories>cs.DC</categories><comments>37 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theme of this paper is how to find all instances of a given &quot;sample&quot;
graph in a larger &quot;data graph,&quot; using a single round of map-reduce. For the
simplest sample graph, the triangle, we improve upon the best known such
algorithm. We then examine the general case, considering both the communication
cost between mappers and reducers and the total computation cost at the
reducers. To minimize communication cost, we exploit the techniques of (Afrati
and Ullman, TKDE 2011)for computing multiway joins (evaluating conjunctive
queries) in a single map-reduce round. Several methods are shown for
translating sample graphs into a union of conjunctive queries with as few
queries as possible. We also address the matter of optimizing computation cost.
Many serial algorithms are shown to be &quot;convertible,&quot; in the sense that it is
possible to partition the data graph, explore each partition in a separate
reducer, and have the total computation cost at the reducers be of the same
order as the computation cost of the serial algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0627</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0627</id><created>2012-08-02</created><authors><author><keyname>Xu</keyname><forenames>Xiaohua</forenames></author><author><keyname>Cao</keyname><forenames>Jiannong</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author></authors><title>MLLS: Minimum Length Link Scheduling Under Physical Interference Model</title><categories>cs.NI cs.GT</categories><comments>8 pages, 1 figure, 2 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We study a fundamental problem called Minimum Length Link Scheduling (MLLS)
which is crucial to the efficient operations of wireless networks. Given a set
of communication links of arbitrary length spread and assume each link has one
unit of traffic demand in wireless networks, the problem MLLS seeks a schedule
for all links (to satisfy all demands) of minimum number of time-slots such
that the links assigned to the same time-slot do not conflict with each other
under the physical interference model. In this paper, we will explore this
problem under three important transmission power control settings: linear power
control, uniform power control and arbitrary power control. We design a suite
of new and novel scheduling algorithms and conduct explicit complexity analysis
to demonstrate their efficiency. Our algorithms can account for the presence of
background noises in wireless networks. We also investigate the fractional case
of the problem MLLS where each link has a fractional demand. We propose an
efficient greedy algorithm of the approximation ratio at most
$(K+1)^{2}\omega$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0631</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0631</id><created>2012-08-02</created><authors><author><keyname>Tushar</keyname><forenames>Wayes</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Smith</keyname><forenames>David. B.</forenames></author></authors><title>Economics of Electric Vehicle Charging: A Game Theoretic Approach</title><categories>cs.GT cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of grid-to-vehicle energy exchange between a smart
grid and plug-in electric vehicle groups (PEVGs) is studied using a
noncooperative Stackelberg game. In this game, on the one hand, the smart grid
that acts as a leader, needs to decide on its price so as to optimize its
revenue while ensuring the PEVGs' participation. On the other hand, the PEVGs,
which act as followers, need to decide on their charging strategies so as to
optimize a tradeoff between the benefit from battery charging and the
associated cost. Using variational inequalities, it is shown that the proposed
game possesses a socially optimal Stackelberg equilibrium in which the grid
optimizes its price while the PEVGs choose their equilibrium strategies. A
distributed algorithm that enables the PEVGs and the smart grid to reach this
equilibrium is proposed and assessed by extensive simulations. Further, the
model is extended to a time-varying case that can incorporate and handle slowly
varying environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0645</identifier>
 <datestamp>2014-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0645</id><created>2012-08-02</created><updated>2014-07-02</updated><authors><author><keyname>Gao</keyname><forenames>Wei</forenames></author><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author></authors><title>On the Consistency of AUC Pairwise Optimization</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AUC (area under ROC curve) is an important evaluation criterion, which has
been popularly used in many learning tasks such as class-imbalance learning,
cost-sensitive learning, learning to rank, etc. Many learning approaches try to
optimize AUC, while owing to the non-convexity and discontinuousness of AUC,
almost all approaches work with surrogate loss functions. Thus, the consistency
of AUC is crucial; however, it has been almost untouched before. In this paper,
we provide a sufficient condition for the asymptotic consistency of learning
approaches based on surrogate loss functions. Based on this result, we prove
that exponential loss and logistic loss are consistent with AUC, but hinge loss
is inconsistent. Then, we derive the $q$-norm hinge loss and general hinge loss
that are consistent with AUC. We also derive the consistent bounds for
exponential loss and logistic loss, and obtain the consistent bounds for many
surrogate loss functions under the non-noise setting. Further, we disclose an
equivalence between the exponential surrogate loss of AUC and exponential
surrogate loss of accuracy, and one straightforward consequence of such finding
is that AdaBoost and RankBoost are equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0651</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0651</id><created>2012-08-03</created><authors><author><keyname>Asif</keyname><forenames>M. Salman</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author></authors><title>Fast and Accurate Algorithms for Re-Weighted L1-Norm Minimization</title><categories>stat.CO cs.IT math.IT stat.ML</categories><comments>Submitted to IEEE Trans. Signal Process</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  To recover a sparse signal from an underdetermined system, we often solve a
constrained L1-norm minimization problem. In many cases, the signal sparsity
and the recovery performance can be further improved by replacing the L1 norm
with a &quot;weighted&quot; L1 norm. Without any prior information about nonzero elements
of the signal, the procedure for selecting weights is iterative in nature.
Common approaches update the weights at every iteration using the solution of a
weighted L1 problem from the previous iteration.
  In this paper, we present two homotopy-based algorithms that efficiently
solve reweighted L1 problems. First, we present an algorithm that quickly
updates the solution of a weighted L1 problem as the weights change. Since the
solution changes only slightly with small changes in the weights, we develop a
homotopy algorithm that replaces the old weights with the new ones in a small
number of computationally inexpensive steps. Second, we propose an algorithm
that solves a weighted L1 problem by adaptively selecting the weights while
estimating the signal. This algorithm integrates the reweighting into every
step along the homotopy path by changing the weights according to the changes
in the solution and its support, allowing us to achieve a high quality signal
reconstruction by solving a single homotopy problem. We compare the performance
of both algorithms, in terms of reconstruction accuracy and computational
complexity, against state-of-the-art solvers and show that our methods have
smaller computational cost. In addition, we will show that the adaptive
selection of the weights inside the homotopy often yields reconstructions of
higher quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0659</identifier>
 <datestamp>2012-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0659</id><created>2012-08-03</created><updated>2012-12-05</updated><authors><author><keyname>Crosswhite</keyname><forenames>Gregory</forenames></author></authors><title>Embracing divergence: a formalism for when your semiring is simply not
  complete, with applications in quantum simulation</title><categories>cs.FL</categories><comments>54 pages, 5 figures; submitted to the special issue of Theoretical
  Computer Science A for the 2012 workshop Weighted Automata: Theory and
  Applications; v2 simplifies the formalism allowing the presentation to be
  streamlined, and fixes some problems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a fundamental difficulty in generalizing weighted automata to the
case of infinite words: in general the infinite sum-of-products from which the
weight of a given word is derived will diverge. Many solutions to this problem
have been proposed, including restricting the type of weights used and
employing a different valuation function that forces convergence. In this paper
we describe an alternative approach that, rather than seeking to avoid the
inevitable divergences, instead embraces them as a source of useful
information. Specifically, rather than taking coefficients from an arbitrary
semiring S we instead take them from S^N. Doing this is useful because it gives
us information about how the weight of an infinite word does or does not
diverge, and if it does diverge what form the divergence takes --- e.g.,
polynomial, exponential, etc. This approach has proved to be incredibly useful
in the field of quantum simulation because when studying infinite systems,
information about how quantities of interest, such as energy or magnetization,
diverge is exactly what we want.
  In this paper we introduce a new kind of automaton which we call a diverging
automaton that maps infinite words to sequences of weights from a semiring and
which employs a Buchi-like boundary condition. We then develop a theory for
diverging power series and prove a Kleene Theorem connecting rational diverging
power series to diverging automata. Afterward we repeat this process by
introducing bidiverging automata which map biinfinite words to elements in S^(Z
x N), developing a theory for bidiverging power series, and proving another
Kleene Theorem. We conclude by describing how bidiverging automata are applied
to simulate biinfinite quantum systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0661</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0661</id><created>2012-08-03</created><updated>2013-05-26</updated><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Private Quantum Coding for Quantum Relay Networks</title><categories>quant-ph cs.IT math.IT</categories><comments>15 pages, 3 figures, Journal-ref: Lecture Notes in Computer Science,
  Vol. 7479, pp. 239-250. Springer-Verlag, 2012, presented in part at the 11th
  Intl. Conference on Quantum Communication, Measurement and Computing
  (QCMC2012), v2: minor formatting changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relay encoder is an unreliable probabilistic device which is aimed at
helping the communication between the sender and the receiver. In this work we
show that in the quantum setting the probabilistic behavior can be completely
eliminated. We also show how to combine quantum polar encoding with
superactivation-assistance in order to achieve reliable and capacity-achieving
private communication over noisy quantum relay channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0664</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0664</id><created>2012-08-03</created><authors><author><keyname>Wang</keyname><forenames>Yin</forenames></author><author><keyname>He</keyname><forenames>Yuan</forenames></author><author><keyname>Cheng</keyname><forenames>Dapeng</forenames></author><author><keyname>Liu</keyname><forenames>Yunhao</forenames></author><author><keyname>Li</keyname><forenames>Xiang-yang</forenames></author></authors><title>Triggercast: Enabling Wireless Collisions Constructive</title><categories>cs.DC cs.NI</categories><comments>10 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is generally considered that concurrent transmissions should be avoided in
order to reduce collisions in wireless sensor networks. Constructive
interference (CI) envisions concurrent transmissions to positively interfere at
the receiver. CI potentially allows orders of magnitude reductions in energy
consumptions and improvements on link quality. In this paper, we theoretically
introduce a sufficient condition to construct CI with IEEE 802.15.4 radio for
the first time. Moreover, we propose Triggercast, a distributed middleware, and
show it is feasible to generate CI in TMote Sky sensor nodes. To synchronize
transmissions of multiple senders at the chip level, Triggercast effectively
compensates propagation and radio processing delays, and has $95^{th}$
percentile synchronization errors of at most 250ns. Triggercast also
intelligently decides which co-senders to participate in simultaneous
transmissions, and aligns their transmission time to maximize the overall link
PRR, under the condition of maximal system robustness. Extensive experiments in
real testbeds reveal that Triggercast significantly improves PRR from 5% to 70%
with 7 concurrent senders. We also demonstrate that Triggercast provides on
average $1.3\times$ PRR performance gains, when integrated with existing data
forwarding protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0682</identifier>
 <datestamp>2014-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0682</id><created>2012-08-03</created><updated>2014-02-12</updated><authors><author><keyname>Stephan</keyname><forenames>Frank</forenames></author><author><keyname>Teutsch</keyname><forenames>Jason</forenames></author></authors><title>Things that can be made into themselves</title><categories>cs.LO math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One says that a property $P$ of sets of natural numbers can be made into
itself iff there is a numbering $\alpha_0,\alpha_1,\ldots$ of all left-r.e.
sets such that the index set $\{e: \alpha_e$ satisfies $P\}$ has the property
$P$ as well. For example, the property of being Martin-L\&quot;of random can be made
into itself. Herein we characterize those singleton properties which can be
made into themselves. A second direction of the present work is the
investigation of the structure of left-r.e. sets under inclusion modulo a
finite set. In contrast to the corresponding structure for r.e. sets, which has
only maximal but no minimal members, both minimal and maximal left-r.e. sets
exist. Moreover, our construction of minimal and maximal left-r.e. sets greatly
differs from Friedberg's classical construction of maximal r.e. sets. Finally,
we investigate whether the properties of minimal and maximal left-r.e. sets can
be made into themselves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0684</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0684</id><created>2012-08-03</created><authors><author><keyname>Kholghi</keyname><forenames>Mahnoosh</forenames></author><author><keyname>Keyvanpour</keyname><forenames>MohammadReza</forenames></author></authors><title>Comparative Evaluation of Data Stream Indexing Models</title><categories>cs.DB</categories><journal-ref>International Journal of Machine Learning and Computing vol. 2,
  no. 3, pp. 257-260, 2012</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent years, the management and processing of data streams has become a
topic of active research in several fields of computer science such as,
distributed systems, database systems, and data mining. A data stream can be
thought of as a transient, continuously increasing sequence of data. In data
streams' applications, because of online monitoring, answering to the user's
queries should be time and space efficient. In this paper, we consider the
special requirements of indexing to determine the performance of different
techniques in data stream processing environments. Stream indexing has main
differences with approaches in traditional databases. Also, we compare data
stream indexing models analytically that can provide a suitable method for
stream indexing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0688</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0688</id><created>2012-08-03</created><authors><author><keyname>Zhao</keyname><forenames>Jizhong</forenames></author><author><keyname>Xi</keyname><forenames>Wei</forenames></author><author><keyname>Han</keyname><forenames>Jinsong</forenames></author><author><keyname>Tang</keyname><forenames>Shaojie</forenames></author><author><keyname>Li</keyname><forenames>Xiangyang</forenames></author><author><keyname>Liu</keyname><forenames>Yunhao</forenames></author><author><keyname>Gong</keyname><forenames>Yihong</forenames></author><author><keyname>Zhou</keyname><forenames>Zehua</forenames></author></authors><title>Efficient and Secure Key Extraction using CSI without Chasing down
  Errors</title><categories>cs.CR</categories><comments>Submitted to INFOCOM 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generating keys and keeping them secret is critical in secure communications.
Due to the &quot;open-air&quot; nature, key distribution is more susceptible to attacks
in wireless communications. An ingenious solution is to generate common secret
keys by two communicating parties separately without the need of key exchange
or distribution, and regenerate them on needs. Recently, it is promising to
extract keys by measuring the random variation in wireless channels, e.g., RSS.
In this paper, we propose an efficient Secret Key Extraction protocol without
Chasing down Errors, SKECE. It establishes common cryptographic keys for two
communicating parties in wireless networks via the realtime measurement of
Channel State Information (CSI). It outperforms RSS-based approaches for key
generation in terms of multiple subcarriers measurement, perfect symmetry in
channel, rapid decorrelation with distance, and high sensitivity towards
environments. In the SKECE design, we also propose effective mechanisms such as
the adaptive key stream generation, leakage resilient consistence validation,
and weighted key recombination, to fully exploit the excellent properties of
CSI. We implement SKECE on off-the-shelf 802.11n devices and evaluate its
performance via extensive experiments. The results demonstrate that SKECE
achieves a more than 3x throughput gain in the key generation from one
subcarrier in static scenarios, and due to its high efficiency, a 50% reduction
on the communication overhead compared to the state-of-the-art RSS based
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0690</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0690</id><created>2012-08-03</created><authors><author><keyname>Hassanzadeh</keyname><forenames>Hamed</forenames></author><author><keyname>Keyvanpour</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Semantic Web Requirements through Web Mining Techniques</title><categories>cs.IR cs.DL</categories><comments>arXiv admin note: text overlap with arXiv:cs/0011033 by other authors</comments><journal-ref>International Journal of Computer Theory and Engineering vol. 4,
  no. 4, pp. 616-620, 2012</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent years, Semantic web has become a topic of active research in
several fields of computer science and has applied in a wide range of domains
such as bioinformatics, life sciences, and knowledge management. The two
fast-developing research areas semantic web and web mining can complement each
other and their different techniques can be used jointly or separately to solve
the issues in both areas. In addition, since shifting from current web to
semantic web mainly depends on the enhancement of knowledge, web mining can
play a key role in facing numerous challenges of this changing. In this paper,
we analyze and classify the application of divers web mining techniques in
different challenges of the semantic web in form of an analytical framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0699</identifier>
 <datestamp>2014-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0699</id><created>2012-08-03</created><updated>2014-01-31</updated><authors><author><keyname>Ferraioli</keyname><forenames>Diodato</forenames></author><author><keyname>Penna</keyname><forenames>Paolo</forenames></author></authors><title>Imperfect best-response mechanisms</title><categories>cs.GT cs.CC</categories><comments>In the conference version of this work, we claimed that in a modified
  version of PageRank games, there exists a subgame which is a potential game
  and thus our results can be used to obtain a good approximation of the logit
  dynamics for these games. Unfortunately, this claim was wrong and the logit
  dynamics for this subgame is in general not easy to analyze</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Best-response mechanisms (Nisan, Schapira, Valiant, Zohar, 2011) provide a
unifying framework for studying various distributed protocols in which the
participants are instructed to repeatedly best respond to each others'
strategies. Two fundamental features of these mechanisms are convergence and
incentive compatibility.
  This work investigates convergence and incentive compatibility conditions of
such mechanisms when players are not guaranteed to always best respond but they
rather play an imperfect best-response strategy. That is, at every time step
every player deviates from the prescribed best-response strategy according to
some probability parameter. The results explain to what extent convergence and
incentive compatibility depend on the assumption that players never make
mistakes, and how robust such protocols are to &quot;noise&quot; or &quot;mistakes&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0701</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0701</id><created>2012-08-03</created><updated>2014-09-22</updated><authors><author><keyname>Xie</keyname><forenames>Pith</forenames></author></authors><title>Numerical Computations For Operator Axiom</title><categories>cs.NA</categories><comments>39 pages, 2 figures</comments><msc-class>11Y16 (Primary) 65H05, 49M25, 11B85, 03D05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operator Axiom produces new real numbers with new operators. New operators
naturally produce new equations and thus extend the traditional mathematical
models which are selected to describe various scientific rules. So new
operators help to describe complex scientific rules which are difficult
described by traditional equations and have an enormous application potential.
As to the equations including new operators, engineering computation often need
the approximate solutions reflecting an intuitive order relation and
equivalence relation. However, the order relation and equivalence relation of
real numbers are not as intuitive as those of base-b expansions. Thus, this
paper introduces numerical computations to approximate all real numbers with
base-b expansions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0712</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0712</id><created>2012-08-03</created><updated>2013-09-23</updated><authors><author><keyname>Marinkovi&#x107;</keyname><forenames>Bojan</forenames></author><author><keyname>Glavan</keyname><forenames>Paola</forenames></author><author><keyname>Ognjanovi&#x107;</keyname><forenames>Zoran</forenames></author></authors><title>Description of the Chord Protocol using ASMs Formalism</title><categories>cs.DC</categories><acm-class>C.2.4; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the overlay protocol Chord using the formalism of
Abstract State Machines. The formalization concerns Chord actions that maintain
ring topology and manipulate distributed keys. We define a class of runs and
prove the correctness of our formalization with respect to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0713</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0713</id><created>2012-08-03</created><updated>2012-08-14</updated><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames><affiliation>Institut f</affiliation></author><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI, Universit&#xe9; de Bordeaux and CNRS</affiliation></author></authors><title>On logical hierarchies within FO^2-definable languages</title><categories>cs.LO cs.FL</categories><comments>arXiv admin note: text overlap with arXiv:0904.2894</comments><proxy>Logical Methods In Computer Science</proxy><acm-class>F.4.3; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 14,
  2012) lmcs:1212</journal-ref><doi>10.2168/LMCS-8(3:11)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class of languages defined in the 2-variable fragment of the
first-order logic of the linear order. Many interesting characterizations of
this class are known, as well as the fact that restricting the number of
quantifier alternations yields an infinite hierarchy whose levels are varieties
of languages (and hence admit an algebraic characterization). Using this
algebraic approach, we show that the quantifier alternation hierarchy inside
FO^{2}[&lt;] is decidable within one unit. For this purpose, we relate each level
of the hierarchy with decidable varieties of languages, which can be defined in
terms of iterated deterministic and co-deterministic products. A crucial notion
in this process is that of condensed rankers, a refinement of the rankers of
Weis and Immerman and the turtle languages of Schwentick, Th\'erien and
Vollmer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0722</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0722</id><created>2012-08-03</created><authors><author><keyname>Duch&#xea;ne</keyname><forenames>Eric</forenames></author><author><keyname>Renault</keyname><forenames>Gabriel</forenames></author></authors><title>Vertex Nim played on graphs</title><categories>cs.DM cs.GT math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph G with positive integer weights on the vertices, and a token
placed on some current vertex u, two players alternately remove a positive
integer weight from u and then move the token to a new current vertex adjacent
to u. When the weight of a vertex is set to 0, it is removed and its
neighborhood becomes a clique. The player making the last move wins. This
adaptation of Nim on graphs is called Vertexnim, and slightly differs from the
game Vertex NimG introduced by Stockman in 2004. Vertexnim can be played on
both directed or undirected graphs. In this paper, we study the complexity of
deciding whether a given game position of Vertexnim is winning for the first or
second player. In particular, we show that for undirected graphs, this problem
can be solved in quadratic time. Our algorithm is also available for the game
Vertex NimG, thus improving Stockman's exptime algorithm. In the directed case,
we are able to compute the winning strategy in polynomial time for several
instances, including circuits or digraphs with self loops.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0745</identifier>
 <datestamp>2014-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0745</id><created>2012-08-03</created><updated>2014-01-17</updated><authors><author><keyname>Kent</keyname><forenames>Adrian</forenames></author><author><keyname>Massar</keyname><forenames>Serge</forenames></author><author><keyname>Silman</keyname><forenames>Jonathan</forenames></author></authors><title>Secure and Robust Transmission and Verification of Unknown Quantum
  States in Minkowski Space</title><categories>quant-ph cs.CR</categories><comments>Reformatted for journal. Minor explanatory additions</comments><journal-ref>Sci. Rep. 4, 3901 (2014)</journal-ref><doi>10.1038/srep03901</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important class of cryptographic applications of relativistic quantum
information work as follows. B generates a random qudit and supplies it to A at
point P. A is supposed to transmit it at near light speed c to to one of a
number of possible pairwise spacelike separated points Q1; : : : ;Qn. A's
transmission is supposed to be secure, in the sense that B cannot tell in
advance which Qj will be chosen. This poses signi?ficant practical challenges,
since secure reliable long-range transmission of quantum data at speeds near to
c is presently not easy. Here we propose di?fferent techniques to overcome
these diffi?culties. We introduce protocols that allow secure long-range
implementations even when both parties control only widely separated
laboratories of small size. In particular we introduce a protocol in which A
needs send the qudit only over a short distance, and securely transmits
classical information (for instance using a one time pad) over the remaining
distance. We further show that by using parallel implementations of the
protocols security can be maintained in the presence of moderate amounts of
losses and errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0755</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0755</id><created>2012-08-02</created><authors><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author></authors><title>Universal Numeric Segment Display for Indian Scheduled Languages: an
  Architectural View</title><categories>cs.OH</categories><comments>ISSN 2231-2803. arXiv admin note: text overlap with arXiv:1009.4977
  by other authors</comments><journal-ref>International Journal of Computer Trends and Technology (IJCTT)
  2(2/2) 161-166 (2011)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  India is country of several hundred different languages. Though twenty two
languages have only been devised as scheduled to the Eighth Schedule of Indian
Constitution in 2007. But as there is yet no proposed compact display
architecture to display all the scheduled language numerals at a time, this
paper proposes a uniform display architecture to display all twenty two
different language digits with higher accuracy and simplicity by using a
17-segment display, which is an improvement over the 16-segment display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0770</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0770</id><created>2012-08-02</created><authors><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author></authors><title>Web based e-learning in india: the cumulative views of different aspects</title><categories>cs.CY</categories><comments>ISSN 0976-5166</comments><journal-ref>Indian Journal of Computer Science and Engineering 1(4), 2010,
  340-352</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the presence of great social diversity in India, it is difficult to change
the social background of students, parents and their economical conditions.
Therefore the only option left for us is to provide uniform or standardize
teaching learning resources or methods. For high quality education throughout
India there must be some nation-wide network, which provides equal quality
education to all students, including the student from the rural areas and
villages. The one and only simple solution to this is Web Based e-Learning. In
this paper we try to give some innovative ideas to spread the Web Based
e-Learning (WBeL) concept in to the minds of young India along with various
approaches taken or to be taken, associated to it till date besides of
instructional design models, different course developmental models, the role of
technical writing and merit-demerit of WBeL till date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0782</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0782</id><created>2012-08-03</created><updated>2013-05-17</updated><authors><author><keyname>Shang</keyname><forenames>Shang</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Cuff</keyname><forenames>Paul W.</forenames></author></authors><title>Wisdom of the Crowd: Incorporating Social Influence in Recommendation
  Models</title><categories>cs.IR cs.LG cs.SI physics.soc-ph</categories><comments>HotPost 2011, 6 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recommendation systems have received considerable attention recently.
However, most research has been focused on improving the performance of
collaborative filtering (CF) techniques. Social networks, indispensably,
provide us extra information on people's preferences, and should be considered
and deployed to improve the quality of recommendations. In this paper, we
propose two recommendation models, for individuals and for groups respectively,
based on social contagion and social influence network theory. In the
recommendation model for individuals, we improve the result of collaborative
filtering prediction with social contagion outcome, which simulates the result
of information cascade in the decision-making process. In the recommendation
model for groups, we apply social influence network theory to take
interpersonal influence into account to form a settled pattern of disagreement,
and then aggregate opinions of group members. By introducing the concept of
susceptibility and interpersonal influence, the settled rating results are
flexible, and inclined to members whose ratings are &quot;essential&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0787</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0787</id><created>2012-08-03</created><updated>2013-05-17</updated><authors><author><keyname>Shang</keyname><forenames>Shang</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Cuff</keyname><forenames>Paul W.</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author></authors><title>A Random Walk Based Model Incorporating Social Information for
  Recommendations</title><categories>cs.IR cs.LG</categories><comments>2012 IEEE Machine Learning for Signal Processing Workshop (MLSP), 6
  pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Collaborative filtering (CF) is one of the most popular approaches to build a
recommendation system. In this paper, we propose a hybrid collaborative
filtering model based on a Makovian random walk to address the data sparsity
and cold start problems in recommendation systems. More precisely, we construct
a directed graph whose nodes consist of items and users, together with item
content, user profile and social network information. We incorporate user's
ratings into edge settings in the graph model. The model provides personalized
recommendations and predictions to individuals and groups. The proposed
algorithms are evaluated on MovieLens and Epinions datasets. Experimental
results show that the proposed methods perform well compared with other
graph-based methods, especially in the cold start case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0788</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0788</id><created>2012-08-03</created><updated>2013-05-17</updated><authors><author><keyname>Shang</keyname><forenames>Shang</forenames></author><author><keyname>Cuff</keyname><forenames>Paul W.</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author></authors><title>An Upper Bound on the Convergence Time for Quantized Consensus</title><categories>stat.AP cs.DC cs.PF math.OC</categories><comments>submitted to IEEE Transactions on Automatic Control, 23 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We analyze a class of distributed quantized consen- sus algorithms for
arbitrary networks. In the initial setting, each node in the network has an
integer value. Nodes exchange their current estimate of the mean value in the
network, and then update their estimation by communicating with their neighbors
in a limited capacity channel in an asynchronous clock setting. Eventually, all
nodes reach consensus with quantized precision. We start the analysis with a
special case of a distributed binary voting algorithm, then proceed to the
expected convergence time for the general quantized consensus algorithm
proposed by Kashyap et al. We use the theory of electric networks, random
walks, and couplings of Markov chains to derive an O(N^3log N) upper bound for
the expected convergence time on an arbitrary graph of size N, improving on the
state of art bound of O(N^4logN) for binary consensus and O(N^5) for quantized
consensus algorithms. Our result is not dependent on graph topology.
Simulations on special graphs such as star networks, line graphs, lollipop
graphs, and Erd\&quot;os-R\'enyi random graphs are performed to validate the
analysis. This work has applications to load balancing, coordination of
autonomous agents, estimation and detection, decision-making networks,
peer-to-peer systems, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0798</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0798</id><created>2012-08-03</created><authors><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Varghese</keyname><forenames>George</forenames></author></authors><title>Biff (Bloom Filter) Codes : Fast Error Correction for Large Data Sets</title><categories>cs.DS</categories><comments>5 pages, Corrected typos from ISIT 2012 conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large data sets are increasingly common in cloud and virtualized
environments. For example, transfers of multiple gigabytes are commonplace, as
are replicated blocks of such sizes. There is a need for fast error-correction
or data reconciliation in such settings even when the expected number of errors
is small.
  Motivated by such cloud reconciliation problems, we consider error-correction
schemes designed for large data, after explaining why previous approaches
appear unsuitable. We introduce Biff codes, which are based on Bloom filters
and are designed for large data. For Biff codes with a message of length $L$
and $E$ errors, the encoding time is $O(L)$, decoding time is $O(L + E)$ and
the space overhead is $O(E)$. Biff codes are low-density parity-check codes;
they are similar to Tornado codes, but are designed for errors instead of
erasures. Further, Biff codes are designed to be very simple, removing any
explicit graph structures and based entirely on hash tables. We derive Biff
codes by a simple reduction from a set reconciliation algorithm for a recently
developed data structure, invertible Bloom lookup tables. While the underlying
theory is extremely simple, what makes this code especially attractive is the
ease with which it can be implemented and the speed of decoding. We present
results from a prototype implementation that decodes messages of 1 million
words with thousands of errors in well under a second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0803</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0803</id><created>2012-08-03</created><authors><author><keyname>Dey</keyname><forenames>Nilanjan</forenames></author><author><keyname>Roy</keyname><forenames>Anamitra Bardhan</forenames></author><author><keyname>Dey</keyname><forenames>Sayantan</forenames></author></authors><title>A Novel Approach of Color Image Hiding using RGB Color planes and DWT</title><categories>cs.CR cs.CV</categories><comments>6 pages, 14 figures, Published with International Journal of Computer
  Applications (IJCA)</comments><journal-ref>International Journal of Computer Applications 36(5):19-24,
  December 2011</journal-ref><doi>10.5120/4487-6316</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a wavelet based Steganographic technique for the color
image. The true color cover image and the true color secret image both are
decomposed into three separate color planes namely R, G and B. Each plane of
the images is decomposed into four sub bands using DWT. Each color plane of the
secret image is hidden by alpha blending technique in the corresponding sub
bands of the respective color planes of the original image. During embedding,
secret image is dispersed within the original image depending upon the alpha
value. Extraction of the secret image varies according to the alpha value. In
this approach the stego image generated is of acceptable level of
imperceptibility and distortion compared to the cover image and the overall
security is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0805</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0805</id><created>2012-08-03</created><authors><author><keyname>Arpasi</keyname><forenames>Jorge P.</forenames></author></authors><title>On the control of abelian group codes with information group of prime
  order</title><categories>cs.IT math.GR math.IT</categories><comments>12 pages, 2 figures</comments><msc-class>94b12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite State Machine (FSM) model is widely used in the construction of binary
convolutional codes. If Z_2={0,1} is the binary mod-2 addition group and
(Z_2)^n is the n-times direct product of Z_2, then a binary convolutional
encoder, with rate (k/n)&lt; 1 and memory m, is a FSM with (Z_2)^k as inputs
group, (Z_2)^n as outputs group and (Z_2)^m as states group. The next state
mapping nu:[(Z_2)^k x (Z_2)^m] --&gt; (Z_2)^m is a surjective group homomorphism.
The encoding mapping omega:[(Z_2)^k x (Z_2)^m] --&gt; (Z_2)^n is a homomorphism
adequately restricted by the trellis graph produced by nu. The binary
convolutional code is the family of bi-infinite sequences produced by the
binary convolutional encoder. Thus, a convolutional code can be considered as a
dynamical system and it is known that well behaved dynamical systems must be
necessarily controllable. The generalization of binary convolutional encoders
over arbitrary finite groups is made by using the extension of groups, instead
of direct product. In this way, given finite groups U,S and Y, a wide-sense
homomorphic encoder (WSHE) is a FSM with U as inputs group, S as states group,
and Y as outputs group. By denoting (U x S) as the extension of U by S, the
next state homomorphism nu:(U x S) --&gt; S needs to be surjective and the
encoding homomorphism omega:(U x S) --&gt; Y has restrictions given by the trellis
graph produced by nu. The code produced by a WSHE is known as group code. In
this work we will study the case when the extension (U x S) is abelian with U
being Z_p, p a positive prime number. We will show that this class of WSHEs
will produce controllable codes only if the states group S is isomorphic with
(Z_p)^j, for some positive integer j.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0806</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0806</id><created>2012-08-03</created><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Cross-conformal predictors</title><categories>stat.ML cs.LG</categories><comments>10 pages, 2 figures, 1 table</comments><msc-class>62G15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note introduces the method of cross-conformal prediction, which is a
hybrid of the methods of inductive conformal prediction and cross-validation,
and studies its validity and predictive efficiency empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0811</identifier>
 <datestamp>2012-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0811</id><created>2012-08-03</created><updated>2012-11-16</updated><authors><author><keyname>Pei</keyname><forenames>Guanhong</forenames></author><author><keyname>Vullikanti</keyname><forenames>Anil Kumar S.</forenames></author></authors><title>Efficient Algorithms for Maximum Link Scheduling in Distributed
  Computing Models with SINR Constraints</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in wireless networks is the maximum link scheduling
problem: given a set $L$ of links, compute the largest possible subset
$L'\subseteq L$ of links that can be scheduled simultaneously without
interference. This problem is particularly challenging in the physical
interference model based on SINR constraints (referred to as the SINR model),
which has gained a lot of interest in recent years. Constant factor
approximation algorithms have been developed for this problem, but low
complexity distributed algorithms that give the same approximation guarantee in
the SINR model are not known. Distributed algorithms are especially challenging
in this model, because of its non-locality.
  In this paper, we develop a set of fast distributed algorithms in the SINR
model, providing constant approximation for the maximum link scheduling problem
under uniform power assignment. We find that different aspects of available
technology, such as full/half-duplex communication, and non-adaptive/adaptive
power control, have a significant impact on the performance of the algorithm;
these issues have not been explored in the context of distributed algorithms in
the SINR model before. Our algorithms' running time is $O(g(L) \log^c m)$,
where $c=1,2,3$ for different problem instances, and $g(L)$ is the &quot;link
diversity&quot; determined by the logarithmic scale of a communication link length.
Since $g(L)$ is small and remains in a constant range in most cases, our
algorithms serve as the first set of &quot;sublinear&quot; time distributed solution. The
algorithms are randomized and crucially use physical carrier sensing in
distributed communication steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0812</identifier>
 <datestamp>2015-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0812</id><created>2012-08-03</created><updated>2015-01-04</updated><authors><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Greenhill</keyname><forenames>Catherine</forenames></author></authors><title>On the chromatic number of a random hypergraph</title><categories>cs.DM math.CO</categories><comments>45 pages, 2 figures, revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of $k$-colouring a random $r$-uniform hypergraph with
$n$ vertices and $cn$ edges, where $k$, $r$, $c$ remain constant as $n$ tends
to infinity. Achlioptas and Naor showed that the chromatic number of a random
graph in this setting, the case $r=2$, must have one of two easily computable
values as $n$ tends to infinity. We give a complete generalisation of this
result to random uniform hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0813</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0813</id><created>2012-08-03</created><authors><author><keyname>Afek</keyname><forenames>Yehuda</forenames></author><author><keyname>Babichenko</keyname><forenames>Yakov</forenames></author><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Gafni</keyname><forenames>Eli</forenames></author><author><keyname>Linial</keyname><forenames>Nati</forenames></author><author><keyname>Sudakov</keyname><forenames>Benny</forenames></author></authors><title>Musical chairs</title><categories>math.CO cs.GT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1106.2065</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the {\em Musical Chairs} game $MC(n,m)$ a team of $n$ players plays
against an adversarial {\em scheduler}. The scheduler wins if the game proceeds
indefinitely, while termination after a finite number of rounds is declared a
win of the team. At each round of the game each player {\em occupies} one of
the $m$ available {\em chairs}. Termination (and a win of the team) is declared
as soon as each player occupies a unique chair. Two players that simultaneously
occupy the same chair are said to be {\em in conflict}. In other words,
termination (and a win for the team) is reached as soon as there are no
conflicts. The only means of communication throughout the game is this: At
every round of the game, the scheduler selects an arbitrary nonempty set of
players who are currently in conflict, and notifies each of them separately
that it must move. A player who is thus notified changes its chair according to
its deterministic program. As we show, for $m\ge 2n-1$ chairs the team has a
winning strategy. Moreover, using topological arguments we show that this bound
is tight. For $m\leq 2n-2$ the scheduler has a strategy that is guaranteed to
make the game continue indefinitely and thus win. We also have some results on
additional interesting questions. For example, if $m \ge 2n-1$ (so that the
team can win), how quickly can they achieve victory?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0848</identifier>
 <datestamp>2013-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0848</id><created>2012-08-03</created><updated>2013-02-22</updated><authors><author><keyname>Hu</keyname><forenames>Ting</forenames></author><author><keyname>Fan</keyname><forenames>Jun</forenames></author><author><keyname>Wu</keyname><forenames>Qiang</forenames></author><author><keyname>Zhou</keyname><forenames>Ding-Xuan</forenames></author></authors><title>Learning Theory Approach to Minimum Error Entropy Criterion</title><categories>cs.LG stat.ML</categories><msc-class>68T05, 68Q32, 62B10</msc-class><journal-ref>JMLR 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the minimum error entropy (MEE) criterion and an empirical risk
minimization learning algorithm in a regression setting. A learning theory
approach is presented for this MEE algorithm and explicit error bounds are
provided in terms of the approximation ability and capacity of the involved
hypothesis space when the MEE scaling parameter is large. Novel asymptotic
analysis is conducted for the generalization error associated with Renyi's
entropy and a Parzen window function, to overcome technical difficulties arisen
from the essential differences between the classical least squares problems and
the MEE setting. A semi-norm and the involved symmetrized least squares error
are introduced, which is related to some ranking algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0861</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0861</id><created>2012-08-03</created><authors><author><keyname>Mints</keyname><forenames>Grigori</forenames></author></authors><title>Intuitionistic Existential Instantiation and Epsilon Symbol</title><categories>math.LO cs.LO</categories><msc-class>03F05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural deduction system for intuitionistic predicate logic with
existential \ instantiation rule presented here uses Hilbert's $\e$-symbol. It
is conservative over intuitionistic predicate logic. We provide a completeness
proof for a suitable Kripke semantics, sketch an approach to a normalization
proof, survey related work and state some open problems. Our system extends
intuitionistic systems with $\e$-symbol due to A. Dragalin and Sh. Maehara.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0864</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0864</id><created>2012-08-03</created><authors><author><keyname>Aswani</keyname><forenames>Anil</forenames></author><author><keyname>Gonzalez</keyname><forenames>Humberto</forenames></author><author><keyname>Sastry</keyname><forenames>S. Shankar</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire</forenames></author></authors><title>Statistical Results on Filtering and Epi-convergence for Learning-Based
  Model Predictive Control</title><categories>math.OC cs.LG cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning-based model predictive control (LBMPC) is a technique that provides
deterministic guarantees on robustness, while statistical identification tools
are used to identify richer models of the system in order to improve
performance. This technical note provides proofs that elucidate the reasons for
our choice of measurement model, as well as giving proofs concerning the
stochastic convergence of LBMPC. The first part of this note discusses
simultaneous state estimation and statistical identification (or learning) of
unmodeled dynamics, for dynamical systems that can be described by ordinary
differential equations (ODE's). The second part provides proofs concerning the
epi-convergence of different statistical estimators that can be used with the
learning-based model predictive control (LBMPC) technique. In particular, we
prove results on the statistical properties of a nonparametric estimator that
we have designed to have the correct deterministic and stochastic properties
for numerical implementation when used in conjunction with LBMPC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0874</identifier>
 <datestamp>2013-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0874</id><created>2012-08-03</created><updated>2013-03-26</updated><authors><author><keyname>Gopalkrishnan</keyname><forenames>Manoj</forenames></author><author><keyname>Miller</keyname><forenames>Ezra</forenames></author><author><keyname>Shiu</keyname><forenames>Anne</forenames></author></authors><title>A Projection Argument for Differential Inclusions, with Applications to
  Persistence of Mass-Action Kinetics</title><categories>math.DS cs.SY q-bio.MN</categories><comments>v5: published version; v3 and v4: minor additional edits; v2:
  contains more general version of main theorem on vertexical families,
  including its accompanying corollaries -- some of them new; final section
  contains new results relating to prior and future research on persistence of
  mass-action systems; improved exposition throughout</comments><proxy>Sigma</proxy><journal-ref>SIGMA 9 (2013), 025, 25 pages</journal-ref><doi>10.3842/SIGMA.2013.025</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Motivated by questions in mass-action kinetics, we introduce the notion of
vertexical family of differential inclusions. Defined on open hypercubes, these
families are characterized by particular good behavior under projection maps.
The motivating examples are certain families of reaction networks -- including
reversible, weakly reversible, endotactic, and strongly endotactic reaction
networks -- that give rise to vertexical families of mass-action differential
inclusions. We prove that vertexical families are amenable to structural
induction. Consequently, a trajectory of a vertexical family approaches the
boundary if and only if either the trajectory approaches a vertex of the
hypercube, or a trajectory in a lower-dimensional member of the family
approaches the boundary. With this technology, we make progress on the global
attractor conjecture, a central open problem concerning mass-action kinetics
systems. Additionally, we phrase mass-action kinetics as a functor on reaction
networks with variable rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0887</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0887</id><created>2012-08-04</created><authors><author><keyname>Al-Debei</keyname><forenames>Mutaz M.</forenames></author><author><keyname>Al-Lozi</keyname><forenames>Enas M.</forenames></author></authors><title>Implementations of ICT Innovations: A Comparative Analysis in terms of
  Challenges between Developed and Developing Countries</title><categories>cs.CY</categories><journal-ref>International Journal of Information, Business and Management,
  4(1), 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main aim of this paper is to achieve a depth of understanding of the
various similarities and differences in terms of challenges between developed
and developing countries and in regards to the implementation of ICT
innovations. Indeed, advances in Information and Communication Technologies
(ICTs) have brought many innovations to the field of Information Systems (IS).
Despite agreements on their importance to the success of organizations, the
implementation processes of such innovations are multifaceted and require
proper addressing of a wide-spread issues and challenges. In this study, we
address this matter by first; synthesizing a comprehensive body of recent and
classified literature concerningfive ICTinitiatives,second;analyzing and
classifying ICTs challenges forboth developed and developing countries as well
as justifying their similarities and differences following thematic analysis
qualitative methods, and third; presenting the study conclusions and
identifying future research areas drawn upon theconducted comparative analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0891</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0891</id><created>2012-08-04</created><authors><author><keyname>Al-Lozi</keyname><forenames>Enas M.</forenames></author><author><keyname>Al-Debei</keyname><forenames>Mutaz M.</forenames></author></authors><title>A Framework of Value Exchange and Role Playing in Web 2.0 WebSites</title><categories>cs.CY</categories><journal-ref>European, Mediterranean &amp; Middle Eastern Conference on Information
  Systems (EMCIS 2012), 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digitally engaged communities can be described as communities created and
evolved within Web 2.0 Websites such as Facebook, Bebo, and Twitter. The
growing importance of digitally engaged communities calls for the need to
efficiently manage the building blocks of sustaining a healthy community. The
initial operation of any digitally-engaged community depends on the existence
of its own members, the beneficial values created and exchanged, and the
relationships interlinking both. However, the level of contribution and
involvement might vary depending on the benefits being gratified from engaging
in such communities. In other words, motivations for participating and getting
involved are purposive; individuals are driven into joining and /or taking part
in any digitallyengaged network for capturing and purtaining certain beneficial
values. Accordingly, this paper proposes a framework that classifies the values
created and exchanged within these communities as well as the roles adopted and
played by users of these communities. Utilizing ethnography as the primay
methodological strategy to study Bebo digitally-engaged community, this
research identifies five different roles of users: Newbie, Lurker, Novice,
Insider, and Leader. Moreover, the research also identifies five value elements
that could be captured by different users: Social, Hedonic, Epistemic, Gift,
and Utilitarian. The results of this study provides insights for decision and
policy makers, service providers, and developers; as it inspires them in
knowing and meeting the needs and values of participants based on the roles
adopted by users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0892</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0892</id><created>2012-08-04</created><authors><author><keyname>Jalal</keyname><forenames>Dima</forenames></author><author><keyname>Al-Debei</keyname><forenames>Mutaz M.</forenames></author></authors><title>Portals and Task Innovation: A Theoretical Framework Founded on Business
  Intelligence Thinking</title><categories>cs.OH</categories><journal-ref>The Eleventh Annual International Conference on Business
  Intelligenece and Knowledge Economy, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main aim of this study is to develop a theoretical framework for the
success of Web portals in promoting task innovation. This is deemed significant
as yet little research has tackled this important domain from the business
intelligence perspective. The D&amp;M IS Success Model was used as a foundational
theory and then was refined to match the context of the current research.
Importantly, in this study, system quality and information quality constructs
were defined on the basis of portals' characteristics since a mapping was
conducted between the most significant functions and features of Web portals
and quality constructs. The developed framework is deemed useful for theory and
practice. From theoretical perspective, the dimensions that affect the
perceived quality of Web portals are identified, and the measures that affect
each quality dimension are also defined. On the practical level, contributions
gained by this study can be observed in terms of the benefits decision makers,
strategists, operational employees and IT developers can gain. Assessing
portals success in improving task innovation is important to help managers
(i.e. decision makers) in making appropriate decisions concerning the adoption
of portals' technology, by weighing its benefits against the costs needed to
establish and run such a technology. Moreover, assessing Web portals' success
gives some insight to IT developers and designers concerning what aspects
should be taken when designing and establishing high quality portals, and what
functions and features should be contained that would affect the perceived
quality of portals and therefore users' intention to use portals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0902</identifier>
 <datestamp>2013-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0902</id><created>2012-08-04</created><updated>2013-04-15</updated><authors><author><keyname>Zhou</keyname><forenames>Yaqin</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Liu</keyname><forenames>Min</forenames></author><author><keyname>Li</keyname><forenames>Zhongcheng</forenames></author><author><keyname>Xu</keyname><forenames>Xiaohua</forenames></author></authors><title>Link Scheduling for Throughput Maximization in Multihop Wireless
  Networks Under Physical Interference</title><categories>cs.NI</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of link scheduling for throughput maximization in
multihop wireless networks. Majority of previous methods are restricted to
graph-based interference models. In this paper we study the link scheduling
problem using a more realistic physical interference model. Through some key
observations about this model, we develop efficient link scheduling algorithms
by exploiting the intrinsic connections between the physical interference model
and the graph-based interference model. For one variant of the problem where
each node can dynamically adjust its transmission power, we design a scheduling
method with O(g(E)) approximation to the optimal throughput capacity where g(E)
denotes length diversity. For the other variant where each node has a fixed but
possible different transmission powers for different nodes, we design a method
with O(g(E))-approximation ratio when the transmission powers of all nodes are
within a constant factor of each other, and in general with an approximation
ratio of O(g(E)log\rho) where log\rho is power diversity.
  We further prove that our algorithm for fixed transmission power case retains
O(g(E)) approximation for any length-monotone, sub-linear fixed power setting.
Furthermore, all these approximation factors are independent of network size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0944</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0944</id><created>2012-08-04</created><authors><author><keyname>Ebrahim</keyname><forenames>Nader Ale</forenames></author><author><keyname>Ahmed</keyname><forenames>Shamsuddin</forenames></author><author><keyname>Taha</keyname><forenames>Zahari</forenames></author></authors><title>Establishing Virtual R&amp;D Teams: Obliged Policy</title><categories>cs.OH</categories><comments>6th IMC (International Management Conference). Tehran, Iran 2008</comments><acm-class>A.0</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In a global and technology oriented world the requirements that products and
services have to fulfill are increasing and are getting more complicated.
Research and development (R&amp;D) is becoming increasingly important in creating
the knowledge that makes research and business more competitive. Companies are
obliged to produce more rapidly, more effectively and more efficiently. In
order to meet these requirements and to secure the viability of business
processes, services and products R&amp;D teams need to access and retrieve
information from as many sources as possible. From the other perspective
virtual teams are important mechanisms for organizations seeking to leverage
scarce resources across geographic and other boundaries moreover; virtual
collaboration has become vital for most organizations. This is particularly
true in the context of designing new product and service innovation. Such
collaboration often involves a network of partners located around the world.
However at the R&amp;D project level, dealing with such distributed teams
challenges both managers and specialists. In new product development, it is
necessary to put together the growing different capabilities and services with
the goal, through cooperation between suppliers and customers, service
providers and scientific institutions to achieve innovations of high quality.
In this paper based on comprehensive literature review of recent articles, at
the first step provides an primary definition and characterization of virtual
R&amp;D team; next, the potential value created by virtual R&amp;D teams for new
product development is explored and lastly along with a guide line for future
study, it is argued that the establishing of virtual R&amp;D teams should be given
consideration in the management of R&amp;D projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0946</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0946</id><created>2012-08-04</created><authors><author><keyname>Clark</keyname><forenames>Andrew</forenames></author><author><keyname>Bushnell</keyname><forenames>Linda</forenames></author><author><keyname>Poovendran</keyname><forenames>Radha</forenames></author></authors><title>A Supermodular Optimization Framework for Leader Selection under Link
  Noise in Linear Multi-Agent Systems</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications of multi-agent systems (MAS), a set of leader agents
acts as a control input to the remaining follower agents. In this paper, we
introduce an analytical approach to selecting leader agents in order to
minimize the total mean-square error of the follower agent states from their
desired value in steady-state in the presence of noisy communication links. We
show that the problem of choosing leaders in order to minimize this error can
be solved using supermodular optimization techniques, leading to efficient
algorithms that are within a provable bound of the optimum. We formulate two
leader selection problems within our framework, namely the problem of choosing
a fixed number of leaders to minimize the error, as well as the problem of
choosing the minimum number of leaders to achieve a tolerated level of error.
We study both leader selection criteria for different scenarios, including MAS
with static topologies, topologies experiencing random link or node failures,
switching topologies, and topologies that vary arbitrarily in time due to node
mobility. In addition to providing provable bounds for all these cases,
simulation results demonstrate that our approach outperforms other leader
selection methods, such as node degree-based and random selection methods, and
provides comparable performance to current state of the art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0950</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0950</id><created>2012-08-04</created><authors><author><keyname>Bhattacharya</keyname><forenames>Tanmay</forenames></author><author><keyname>Dey</keyname><forenames>Nilanjan</forenames></author><author><keyname>Chaudhuri</keyname><forenames>S. R. Bhadra</forenames></author></authors><title>A Session based Multiple Image Hiding Technique using DWT and DCT</title><categories>cs.CR cs.MM</categories><comments>4 pages,16 figures, &quot;Published with International Journal of Computer
  Applications (IJCA)&quot;</comments><journal-ref>Tanmay Bhattacharya,Nilanjan Dey,Bhadra S R Chaudhuri. Article:A
  Session Based Multiple Image Hiding Technique using DWT&amp;DCT.International
  Journal of Computer Applications 38(5):18-21,January 2012.Published by
  Foundation of Computer Science</journal-ref><doi>10.5120/4684-6808 10.5120/4684-6808 10.5120/4684-6808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes Steganographic technique for hiding multiple images in a
color image based on DWT and DCT. The cover image is decomposed into three
separate color planes namely R, G and B. Individual planes are decomposed into
subbands using DWT. DCT is applied in HH component of each plane. Secret images
are dispersed among the selected DCT coefficients using a pseudo random
sequence and a Session key. Secret images are extracted using the session key
and the size of the images from the planer decomposed stego image. In this
approach the stego image generated is of acceptable level of imperceptibility
and distortion compared to the cover image and the overall security is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0952</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0952</id><created>2012-08-04</created><updated>2012-08-07</updated><authors><author><keyname>Gasti</keyname><forenames>Paolo</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author><author><keyname>Uzun</keyname><forenames>Ersin</forenames></author><author><keyname>Zhang</keyname><forenames>Lixia</forenames></author></authors><title>DoS and DDoS in Named-Data Networking</title><categories>cs.NI cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing realization that current Internet protocols are reaching the
limits of their senescence, a number of on-going research efforts aim to design
potential next-generation Internet architectures. Although they vary in
maturity and scope, in order to avoid past pitfalls, these efforts seek to
treat security and privacy as fundamental requirements. Resilience to
Denial-of-Service (DoS) attacks that plague today's Internet is a major issue
for any new architecture and deserves full attention.
  In this paper, we focus on DoS in a specific candidate next-generation
Internet architecture called Named-Data Networking (NDN) -- an instantiation of
Information-Centric Networking approach. By stressing content dissemination,
NDN appears to be attractive and viable approach to many types of current and
emerging communication models. It also incorporates some basic security
features that mitigate certain attacks. However, NDN's resilience to DoS
attacks has not been analyzed to-date. This paper represents the first step
towards assessment and possible mitigation of DoS in NDN. After identifying and
analyzing several new types of attacks, it investigates their variations,
effects and counter-measures. This paper also sheds some light on the
long-standing debate about relative virtues of self-certifying, as opposed to
human-readable, names.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0954</identifier>
 <datestamp>2015-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0954</id><created>2012-08-04</created><updated>2015-10-18</updated><authors><author><keyname>Yakhontov</keyname><forenames>Sergey V.</forenames></author></authors><title>P = NP</title><categories>cs.CC</categories><comments>55 pages. Complete solution (but without reviews applied)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work proves that P=NP. The proof, presented in this work, is a
constructive one: the program of a polynomial time deterministic multi-tape
Turing machine M_ExistsAcceptingPath, that determines if there exists an
accepting computational path of a polynomial time non-deterministic single-tape
Turing machine M_NP, is constructed (machine M_ExistsAcceptingPath is different
for each Turing machine M_NP). Machine M_ExistsAcceptingPath is based on
reduction to problem LP (linear programming) instead of reduction to problem
3-CNF-SAT which is commonly used. The time complexity of machine
M_ExistsAcceptingPath is O(t(n)^{272}) wherein t(n) is an upper bound of the
time complexity of machine M_NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0959</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0959</id><created>2012-08-04</created><updated>2013-01-06</updated><authors><author><keyname>Denil</keyname><forenames>Misha</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Recklessly Approximate Sparse Coding</title><categories>cs.LG cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has recently been observed that certain extremely simple feature encoding
techniques are able to achieve state of the art performance on several standard
image classification benchmarks including deep belief networks, convolutional
nets, factored RBMs, mcRBMs, convolutional RBMs, sparse autoencoders and
several others. Moreover, these &quot;triangle&quot; or &quot;soft threshold&quot; encodings are
ex- tremely efficient to compute. Several intuitive arguments have been put
forward to explain this remarkable performance, yet no mathematical
justification has been offered.
  The main result of this report is to show that these features are realized as
an approximate solution to the a non-negative sparse coding problem. Using this
connection we describe several variants of the soft threshold features and
demonstrate their effectiveness on two image classification benchmark tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0967</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0967</id><created>2012-08-04</created><authors><author><keyname>Koppula</keyname><forenames>Hema Swetha</forenames></author><author><keyname>Gupta</keyname><forenames>Rudhir</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Human Activity Learning using Object Affordances from RGB-D Videos</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human activities comprise several sub-activities performed in a sequence and
involve interactions with various objects. This makes reasoning about the
object affordances a central task for activity recognition. In this work, we
consider the problem of jointly labeling the object affordances and human
activities from RGB-D videos. We frame the problem as a Markov Random Field
where the nodes represent objects and sub-activities, and the edges represent
the relationships between object affordances, their relations with
sub-activities, and their evolution over time. We formulate the learning
problem using a structural SVM approach, where labeling over various alternate
temporal segmentations are considered as latent variables. We tested our method
on a dataset comprising 120 activity videos collected from four subjects, and
obtained an end-to-end precision of 81.8% and recall of 80.0% for labeling the
activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0984</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0984</id><created>2012-08-05</created><authors><author><keyname>Akrour</keyname><forenames>Riad</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LRI</affiliation></author></authors><title>APRIL: Active Preference-learning based Reinforcement Learning</title><categories>cs.LG</categories><proxy>ccsd</proxy><journal-ref>ECML PKDD 2012 7524 (2012) 116-131</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on reinforcement learning (RL) with limited prior
knowledge. In the domain of swarm robotics for instance, the expert can hardly
design a reward function or demonstrate the target behavior, forbidding the use
of both standard RL and inverse reinforcement learning. Although with a limited
expertise, the human expert is still often able to emit preferences and rank
the agent demonstrations. Earlier work has presented an iterative
preference-based RL framework: expert preferences are exploited to learn an
approximate policy return, thus enabling the agent to achieve direct policy
search. Iteratively, the agent selects a new candidate policy and demonstrates
it; the expert ranks the new demonstration comparatively to the previous best
one; the expert's ranking feedback enables the agent to refine the approximate
policy return, and the process is iterated. In this paper, preference-based
reinforcement learning is combined with active ranking in order to decrease the
number of ranking queries to the expert needed to yield a satisfactory policy.
Experiments on the mountain car and the cancer treatment testbeds witness that
a couple of dozen rankings enable to learn a competent policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0995</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0995</id><created>2012-08-05</created><authors><author><keyname>Muslim</keyname><forenames>Nasif</forenames></author><author><keyname>Adnan</keyname><forenames>Md. Tanvir</forenames></author><author><keyname>Kabir</keyname><forenames>Mohammad Zahidul</forenames></author><author><keyname>Kabir</keyname><forenames>Md. Humayun</forenames></author><author><keyname>Islam</keyname><forenames>Sheikh Mominul</forenames></author></authors><title>Design and implementation of a digital clock showing digits in Bangla
  font using microcontroller AT89C4051</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a digital clock is designed where the microcontroller is used
for timing controller and the font of the Bangla digits are designed, and
programmed within the microcontroller. The design is cost effective, simple and
easy for maintenance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0996</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0996</id><created>2012-08-05</created><authors><author><keyname>Reynaud</keyname><forenames>Laurent</forenames></author><author><keyname>Rasheed</keyname><forenames>Tinku</forenames></author><author><keyname>Kandeepan</keyname><forenames>Sithamparanathan</forenames></author></authors><title>An Integrated Aerial Telecommunications Network that Supports Emergency
  Traffic</title><categories>cs.NI</categories><journal-ref>Proceedings of the 2011 14th International Symposium on Wireless
  Personal Multimedia Communications (WPMC '11)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper outlines how an aerial telecommunications network can optimally
meet the stringent needs of emergency relief and recovery operations. We
propose a novel architecture, made of an integrated and highly dynamic
multi-purpose aerial telecommunications infrastructure that can be contextually
extended with fast-deploying high or low altitude platforms. In particular, we
analyze the interest and challenges of adapting core concepts from substitution
networks and controlled mobility mechanisms, so that a base network can be
seamlessly augmented, both in terms of capacity and functions. We give an
estimation of the emergency traffic supported by the lower altitude platforms
in an example scenario and discuss the challenges posed by this architecture,
notably in terms of disaster resilience and ability to efficiently provide
sustained first responder communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0997</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0997</id><created>2012-08-05</created><authors><author><keyname>Reynaud</keyname><forenames>Laurent</forenames></author><author><keyname>Za&#xef;mi</keyname><forenames>Salim</forenames></author><author><keyname>Gourhant</keyname><forenames>Yvon</forenames></author></authors><title>Competitive Assessments for HAP Delivery of Mobile Services in Emerging
  Countries</title><categories>cs.NI</categories><journal-ref>Proceedings of the 2011 15th International Conference on
  Intelligence in Next Generation Networks (ICIN '11)</journal-ref><doi>10.1109/ICIN.2011.6081095</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, network deployment based on High Altitude Platforms (HAPs)
has gained momentum through several initiatives where air vehicles and
telecommunications payloads have been adapted and refined, resulting in more
efficient and less expensive platforms. In this paper, we study HAP as an
alternative or complementary fast-evolving technology to provide mobile
services in rural areas of emerging countries, where business models need to be
carefully tailored to the reality of their related markets. In these large
areas with low user density, mobile services uptake is likely to be slowed by a
service profitability which is in turn limited by a relatively low average
revenue per user. Through three architectures enabling different business roles
and using different terrestrial, HAP and satellite backhaul solutions, we
devise how to use in an efficient and profitable fashion these multi-purpose
aerial platforms, in complement to existing access and backhauling satellite or
terrestrial technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.0999</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.0999</id><created>2012-08-05</created><authors><author><keyname>Ji</keyname><forenames>Shiyu</forenames></author><author><keyname>Tong</keyname><forenames>Xiaojun</forenames></author><author><keyname>Zhang</keyname><forenames>Miao</forenames></author></authors><title>Image encryption schemes for JPEG and GIF formats based on 3D baker with
  compound chaotic sequence generator</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposed several methods to transplant the compound chaotic image
encryption scheme with permutation based on 3D baker into image formats as
Joint Photographic Experts Group (JPEG) and Graphics Interchange Format (GIF).
The new method averts the lossy Discrete Cosine Transform and quantization and
can encrypt and decrypt JPEG images lossless. Our proposed method for GIF keeps
the property of animation successfully. The security test results indicate the
proposed methods have high security. Since JPEG and GIF image formats are
popular contemporarily, this paper shows that the prospect of chaotic image
encryption is promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1004</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1004</id><created>2012-08-05</created><authors><author><keyname>Pitsilis</keyname><forenames>Georgios</forenames></author><author><keyname>Knapskog</keyname><forenames>Svein J.</forenames></author></authors><title>Social Trust as a solution to address sparsity-inherent problems of
  Recommender systems</title><categories>cs.SI cs.IR</categories><comments>ACM RecSys 2009, Workshop on Recommender Systems &amp; The Social Web,
  Oct. 2009, ISSN:1613-0073, New York, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trust has been explored by many researchers in the past as a successful
solution for assisting recommender systems. Even though the approach of using a
web-of-trust scheme for assisting the recommendation production is well
adopted, issues like the sparsity problem have not been explored adequately so
far with regard to this. In this work we are proposing and testing a scheme
that uses the existing ratings of users to calculate the hypothetical trust
that might exist between them. The purpose is to demonstrate how some basic
social networking when applied to an existing system can help in alleviating
problems of traditional recommender system schemes. Interestingly, such schemes
are also alleviating the cold start problem from which mainly new users are
suffering. In order to show how good the system is in that respect, we measure
the performance at various times as the system evolves and we also contrast the
solution with existing approaches. Finally, we present the results which
justify that such schemes undoubtedly work better than a system that makes no
use of trust at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1011</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1011</id><created>2012-08-05</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>Credibility in Web Search Engines</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web search engines apply a variety of ranking signals to achieve user
satisfaction, i.e., results pages that provide the best-possible results to the
user. While these ranking signals implicitly consider credibility (e.g., by
measuring popularity), explicit measures of credibility are not applied. In
this chapter, credibility in Web search engines is discussed in a broad
context: credibility as a measure for including documents in a search engine's
index, credibility as a ranking signal, credibility in the context of universal
search results, and the possibility of using credibility as an explicit measure
for ranking purposes. It is found that while search engines-at least to a
certain extent-show credible results to their users, there is no fully
integrated credibility framework for Web search engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1035</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1035</id><created>2012-08-05</created><authors><author><keyname>Savar&#xe8;</keyname><forenames>Giuseppe</forenames></author><author><keyname>Toscani</keyname><forenames>Giuseppe</forenames></author></authors><title>The concavity of R\`enyi entropy power</title><categories>cs.IT math.FA math.IT</categories><journal-ref>IEEE Trans. Inform. Theory 60 (2014), 2687-2693</journal-ref><doi>10.1109/TIT.2014.2309341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We associate to the p-th R\'enyi entropy a definition of entropy power, which
is the natural extension of Shannon's entropy power and exhibits a nice
behaviour along solutions to the p-nonlinear heat equation in $R^n$. We show
that the R\'enyi entropy power of general probability densities solving such
equations is always a concave function of time, whereas it has a linear
behaviour in correspondence to the Barenblatt source-type solutions. We then
shown that the p-th R\'enyi entropy power of a probability density which solves
the nonlinear diffusion of order p, is a concave function of time. This result
extends Costa's concavity inequality for Shannon's entropy power to R\'enyi
entropies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1045</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1045</id><created>2012-08-05</created><updated>2012-10-05</updated><authors><author><keyname>Aminzare</keyname><forenames>Zahra</forenames></author></authors><title>Remarks on contractions of reaction-diffusion PDE's on weighted L^2
  norms</title><categories>cs.SY math.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [1], we showed contractivity of reaction-diffusion PDE: \frac{\partial
u}{\partial t}({\omega},t) = F(u({\omega},t)) + D\Delta u({\omega},t) with
Neumann boundary condition, provided \mu_{p,Q}(J_F (u)) &lt; 0 (uniformly on u),
for some 1 \leq p \leq \infty and some positive, diagonal matrix Q, where J_F
is the Jacobian matrix of F. This note extends the result for Q weighted L_2
norms, where Q is a positive, symmetric (not merely diagonal) matrix and
Q^2D+DQ^2&gt;0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1056</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1056</id><created>2012-08-05</created><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>Sequential Estimation Methods from Inclusion Principle</title><categories>math.ST cs.LG math.PR stat.TH</categories><comments>28 pages, no figure; in proceedings of SPIE conference, Baltimore,
  Maryland, April 24-27, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose new sequential estimation methods based on
inclusion principle. The main idea is to reformulate the estimation problems as
constructing sequential random intervals and use confidence sequences to
control the associated coverage probabilities. In contrast to existing
asymptotic sequential methods, our estimation procedures rigorously guarantee
the pre-specified levels of confidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1061</identifier>
 <datestamp>2013-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1061</id><created>2012-08-05</created><authors><author><keyname>Beezley</keyname><forenames>Jonathan</forenames></author><author><keyname>Martin</keyname><forenames>Mavin</forenames></author><author><keyname>Rosen</keyname><forenames>Paul</forenames></author><author><keyname>Mandel</keyname><forenames>Jan</forenames></author><author><keyname>Kochanski</keyname><forenames>Adam K.</forenames></author></authors><title>Data management and analysis with WRF and SFIRE</title><categories>physics.ao-ph cs.SE</categories><comments>Submitted to proceedings of IGARSS 2012, 4 papers, 1 figure</comments><report-no>UCD CCM Report 312</report-no><doi>10.1109/IGARSS.2012.6352419</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce several useful utilities in development for the creation and
analysis of real wildland fire simulations using WRF and SFIRE. These utilities
exist as standalone programs and scripts as well as extensions to other well
known software. Python web scrapers automate the process of downloading and
preprocessing atmospheric and surface data from common sources. Other scripts
simplify the domain setup by creating parameter files automatically.
Integration with Google Earth allows users to explore the simulation in a 3D
environment along with real surface imagery. Postprocessing scripts provide the
user with a number of output data formats compatible with many commonly used
visualization suites allowing for the creation of high quality 3D renderings.
As a whole, these improvements build toward a unified web application that
brings a sophisticated wildland fire modeling environment to scientists and
users alike.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1070</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1070</id><created>2012-08-05</created><authors><author><keyname>Rose</keyname><forenames>Christopher</forenames></author><author><keyname>Mian</keyname><forenames>I. Saira</forenames></author><author><keyname>Song</keyname><forenames>Ruochen</forenames></author></authors><title>Timing Channels with Multiple Identical Quanta</title><categories>cs.IT math.IT q-bio.MN</categories><comments>24 pages, 3 figures, Submitted to JSAC Special Issue on Nanoscale and
  Molecular Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider mutual information between release times and capture times for a
set of M identical quanta traveling independently from a source to a target.
The quanta are immediately captured upon arrival, ?first-passage times are
assumed independent and identically distributed and the quantum emission times
are constrained by a deadline. The primary application area is intended to be
inter/intracellular molecular signaling in biological systems whereby an
organelle, cell or group of cells must deliver some message (such as
transcription or developmental instructions) over distance with reasonable
certainty to another organelles, cells or group of cells. However, the model
can also be applied to communications systems wherein indistinguishable signals
have random transit latencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1103</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1103</id><created>2012-08-06</created><authors><author><keyname>Bhuvaneswari</keyname><forenames>N. S.</forenames></author><author><keyname>Praveena</keyname><forenames>R.</forenames></author><author><keyname>Divya</keyname><forenames>R.</forenames></author></authors><title>System identification and modeling for interacting and non-interacting
  tank systems using intelligent techniques</title><categories>cs.AI cs.SY</categories><comments>13 pages,8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System identification from the experimental data plays a vital role for model
based controller design. Derivation of process model from first principles is
often difficult due to its complexity. The first stage in the development of
any control and monitoring system is the identification and modeling of the
system. Each model is developed within the context of a specific control
problem. Thus, the need for a general system identification framework is
warranted. The proposed framework should be able to adapt and emphasize
different properties based on the control objective and the nature of the
behavior of the system. Therefore, system identification has been a valuable
tool in identifying the model of the system based on the input and output data
for the design of the controller. The present work is concerned with the
identification of transfer function models using statistical model
identification, process reaction curve method, ARX model, genetic algorithm and
modeling using neural network and fuzzy logic for interacting and non
interacting tank process. The identification technique and modeling used is
prone to parameter change &amp; disturbance. The proposed methods are used for
identifying the mathematical model and intelligent model of interacting and non
interacting process from the real time experimental data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1111</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1111</id><created>2012-08-06</created><authors><author><keyname>Altenbach</keyname><forenames>Fabian</forenames></author><author><keyname>Corroy</keyname><forenames>Steven</forenames></author><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>Strategies for Distributed Sensor Selection Using Convex Optimization</title><categories>cs.IT math.IT</categories><comments>6 pages, to be presented at GLOBECOM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the estimation of an unknown parameter vector in a linear
measurement model. Centralized sensor selection consists in selecting a set of
k_s sensor measurements, from a total number of m potential measurements. The
performance of the corresponding selection is measured by the volume of an
estimation error covariance matrix. In this work, we consider the problem of
selecting these sensors in a distributed or decentralized fashion. In
particular, we study the case of two leader nodes that perform naive
decentralized selections. We demonstrate that this can degrade the performance
severely. Therefore, two heuristics based on convex optimization methods are
introduced, where we first allow one leader to make a selection, and then to
share a modest amount of information about his selection with the remaining
node. We will show that both heuristics clearly outperform the naive
decentralized selection, and achieve a performance close to the centralized
selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1116</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1116</id><created>2012-08-06</created><updated>2014-07-07</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author></authors><title>Optimal Non-Uniform Mapping for Probabilistic Shaping</title><categories>cs.IT math.IT</categories><comments>6 pages. Compared to v2, the former Section IV.B is removed because
  the statement was wrong. A formatting problem is resolved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The construction of optimal non-uniform mappings for discrete input
memoryless channels (DIMCs) is investigated. An efficient algorithm to find
optimal mappings is proposed and the rate by which a target distribution is
approached is investigated. The results are applied to non-uniform mappings for
additive white Gaussian noise (AWGN) channels with finite signal
constellations. The mappings found by the proposed methods outperform those
obtained via a central limit theorem approach as suggested in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1136</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1136</id><created>2012-08-06</created><authors><author><keyname>De Bock</keyname><forenames>Jasper</forenames></author><author><keyname>de Cooman</keyname><forenames>Gert</forenames></author></authors><title>Credal nets under epistemic irrelevance</title><categories>cs.AI math.PR</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to credal nets, which are graphical models that
generalise Bayesian nets to imprecise probability. Instead of applying the
commonly used notion of strong independence, we replace it by the weaker notion
of epistemic irrelevance. We show how assessments of epistemic irrelevance
allow us to construct a global model out of given local uncertainty models and
mention some useful properties. The main results and proofs are presented using
the language of sets of desirable gambles, which provides a very general and
expressive way of representing imprecise probability models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1149</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1149</id><created>2012-08-06</created><authors><author><keyname>P&#x142;aczek</keyname><forenames>Bart&#x142;omiej</forenames></author></authors><title>Uncertainty-dependent data collection in vehicular sensor networks</title><categories>cs.NI cs.SY</categories><comments>10 pages, 6 figures</comments><journal-ref>Communications in Computer and Information Science, vol. 291, pp.
  430-439, 2012</journal-ref><doi>10.1007/978-3-642-31217-5_45</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular sensor networks (VSNs) are built on top of vehicular ad-hoc
networks (VANETs) by equipping vehicles with sensing devices. These new
technologies create a huge opportunity to extend the sensing capabilities of
the existing road traffic control systems and improve their performance.
Efficient utilisation of wireless communication channel is one of the basic
issues in the vehicular networks development. This paper presents and evaluates
data collection algorithms that use uncertainty estimates to reduce data
transmission in a VSN-based road traffic control system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1151</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1151</id><created>2012-08-06</created><updated>2012-10-15</updated><authors><author><keyname>Blinovsky</keyname><forenames>Vladimir</forenames></author><author><keyname>Cai</keyname><forenames>Minglai</forenames></author></authors><title>Classical-Quantum Arbitrarily Varying Wiretap Channel</title><categories>cs.IT math.IT quant-ph</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We derive a lower bound on the capacity of classical-quantum arbitrarily
varying wiretap channel and determine the capacity of the classicalquantum
arbitrarily varying wiretap channel with channel state information at the
transmitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1157</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1157</id><created>2012-08-06</created><updated>2012-09-24</updated><authors><author><keyname>Dindar</keyname><forenames>Saleh</forenames></author><author><keyname>Ford</keyname><forenames>Eric B.</forenames></author><author><keyname>Juric</keyname><forenames>Mario</forenames></author><author><keyname>Yeo</keyname><forenames>Young In</forenames></author><author><keyname>Gao</keyname><forenames>Jianwei</forenames></author><author><keyname>Boley</keyname><forenames>Aaron C.</forenames></author><author><keyname>Nelson</keyname><forenames>Benjamin</forenames></author><author><keyname>Peters</keyname><forenames>Jorg</forenames></author></authors><title>Swarm-NG: a CUDA Library for Parallel n-body Integrations with focus on
  Simulations of Planetary Systems</title><categories>astro-ph.EP astro-ph.IM cs.DC cs.MS physics.comp-ph</categories><comments>Submitted to New Astronomy</comments><doi>10.1016/j.newast.2013.01.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Swarm-NG, a C++ library for the efficient direct integration of
many n-body systems using highly-parallel Graphics Processing Unit (GPU), such
as NVIDIA's Tesla T10 and M2070 GPUs. While previous studies have demonstrated
the benefit of GPUs for n-body simulations with thousands to millions of
bodies, Swarm-NG focuses on many few-body systems, e.g., thousands of systems
with 3...15 bodies each, as is typical for the study of planetary systems.
Swarm-NG parallelizes the simulation, including both the numerical integration
of the equations of motion and the evaluation of forces using NVIDIA's &quot;Compute
Unified Device Architecture&quot; (CUDA) on the GPU. Swarm-NG includes optimized
implementations of 4th order time-symmetrized Hermite integration and mixed
variable symplectic integration, as well as several sample codes for other
algorithms to illustrate how non-CUDA-savvy users may themselves introduce
customized integrators into the Swarm-NG framework. To optimize performance, we
analyze the effect of GPU-specific parameters on performance under double
precision.
  Applications of Swarm-NG include studying the late stages of planet
formation, testing the stability of planetary systems and evaluating the
goodness-of-fit between many planetary system models and observations of
extrasolar planet host stars (e.g., radial velocity, astrometry, transit
timing). While Swarm-NG focuses on the parallel integration of many planetary
systems,the underlying integrators could be applied to a wide variety of
problems that require repeatedly integrating a set of ordinary differential
equations many times using different initial conditions and/or parameter
values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1172</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1172</id><created>2012-07-31</created><authors><author><keyname>Herman</keyname><forenames>G. T.</forenames></author><author><keyname>Gardu&#xf1;o</keyname><forenames>E.</forenames></author><author><keyname>Davidi</keyname><forenames>R.</forenames></author><author><keyname>Censor</keyname><forenames>Y.</forenames></author></authors><title>Superiorization: An optimization heuristic for medical physics</title><categories>math.OC cs.NA physics.med-ph</categories><comments>Accepted for publication in: Medical Physics</comments><doi>10.1118/1.4745566</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To describe and mathematically validate the superiorization
methodology, which is a recently-developed heuristic approach to optimization,
and to discuss its applicability to medical physics problem formulations that
specify the desired solution (of physically given or otherwise obtained
constraints) by an optimization criterion. Methods: The underlying idea is that
many iterative algorithms for finding such a solution are perturbation
resilient in the sense that, even if certain kinds of changes are made at the
end of each iterative step, the algorithm still produces a
constraints-compatible solution. This property is exploited by using permitted
changes to steer the algorithm to a solution that is not only
constraints-compatible, but is also desirable according to a specified
optimization criterion. The approach is very general, it is applicable to many
iterative procedures and optimization criteria used in medical physics.
Results: The main practical contribution is a procedure for automatically
producing from any given iterative algorithm its superiorized version, which
will supply solutions that are superior according to a given optimization
criterion. It is shown that if the original iterative algorithm satisfies
certain mathematical conditions, then the output of its superiorized version is
guaranteed to be as constraints-compatible as the output of the original
algorithm, but it is superior to the latter according to the optimization
criterion. This intuitive description is made precise in the paper and the
stated claims are rigorously proved. Superiorization is illustrated on
simulated computerized tomography data of a head cross-section and, in spite of
its generality, superiorization is shown to be competitive to an optimization
algorithm that is specifically designed to minimize total variation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1176</identifier>
 <datestamp>2014-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1176</id><created>2012-08-06</created><updated>2014-11-21</updated><authors><author><keyname>Hoang</keyname><forenames>Viet Tung</forenames></author><author><keyname>Morris</keyname><forenames>Ben</forenames></author><author><keyname>Rogaway</keyname><forenames>Phillip</forenames></author></authors><title>An Enciphering Scheme Based on a Card Shuffle</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the swap-or-not shuffle and show that the technique gives rise
to a new method to convert a pseudorandom function (PRF) into a pseudorandom
permutation (PRP) (or, alternatively, to directly build a confusion/diffusion
blockcipher). We then prove that swap-or-not has excellent quantitative
security bounds, giving a Luby-Rackoff type result that ensures security
(assuming an ideal round function) to a number of adversarial queries that is
nearly the size of the construction's domain. Swap-or-not provides a direct
solution for building a small-domain cipher and achieving format-preserving
encryption, yielding the best bounds known for a practical scheme for
enciphering credit-card numbers. The analysis of swap-or-not is based on the
theory of mixing times of Markov chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1180</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1180</id><created>2012-08-06</created><authors><author><keyname>Simonetto</keyname><forenames>Andrea</forenames></author><author><keyname>Keviczky</keyname><forenames>Tamas</forenames></author><author><keyname>Johansson</keyname><forenames>Mikael</forenames></author></authors><title>A Regularized Saddle-Point Algorithm for Networked Optimization with
  Resource Allocation Constraints</title><categories>cs.SY math.OC</categories><comments>This is an extended version of a paper accepted for CDC 2012 with
  identical title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a regularized saddle-point algorithm for convex networked
optimization problems with resource allocation constraints. Standard
distributed gradient methods suffer from slow convergence and require excessive
communication when applied to problems of this type. Our approach offers an
alternative way to address these problems, and ensures that each iterative
update step satisfies the resource allocation constraints. We derive step-size
conditions under which the distributed algorithm converges geometrically to the
regularized optimal value, and show how these conditions are affected by the
underlying network topology. We illustrate our method on a robotic network
application example where a group of mobile agents strive to maintain a moving
target in the barycenter of their positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1184</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1184</id><created>2012-08-06</created><authors><author><keyname>Duetting</keyname><forenames>Paul</forenames></author><author><keyname>Fischer</keyname><forenames>Felix</forenames></author><author><keyname>Jirapinyo</keyname><forenames>Pitchayut</forenames></author><author><keyname>Lai</keyname><forenames>John K.</forenames></author><author><keyname>Lubin</keyname><forenames>Benjamin</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author></authors><title>Payment Rules through Discriminant-Based Classifiers</title><categories>cs.GT cs.AI</categories><journal-ref>Proceedings of the 13th ACM Conference on Electronic Commerce (EC
  '12), pages 477-494, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mechanism design it is typical to impose incentive compatibility and then
derive an optimal mechanism subject to this constraint. By replacing the
incentive compatibility requirement with the goal of minimizing expected ex
post regret, we are able to adapt statistical machine learning techniques to
the design of payment rules. This computational approach to mechanism design is
applicable to domains with multi-dimensional types and situations where
computational efficiency is a concern. Specifically, given an outcome rule and
access to a type distribution, we train a support vector machine with a special
discriminant function structure such that it implicitly establishes a payment
rule with desirable incentive properties. We discuss applications to a
multi-minded combinatorial auction with a greedy winner-determination algorithm
and to an assignment problem with egalitarian outcome rule. Experimental
results demonstrate both that the construction produces payment rules with low
ex post regret, and that penalizing classification errors is effective in
preventing failures of ex post individual rationality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1187</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1187</id><created>2012-08-06</created><authors><author><keyname>Thomaidou</keyname><forenames>Stamatina</forenames></author><author><keyname>Vazirgiannis</keyname><forenames>Michalis</forenames></author><author><keyname>Liakopoulos</keyname><forenames>Kyriakos</forenames></author></authors><title>Toward an Integrated Framework for Automated Development and
  Optimization of Online Advertising Campaigns</title><categories>cs.IR cs.AI</categories><comments>Submitted to ACM Transactions on the Web (TWEB) Journal - July 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creating and monitoring competitive and cost-effective pay-per-click
advertisement campaigns through the web-search channel is a resource demanding
task in terms of expertise and effort. Assisting or even automating the work of
an advertising specialist will have an unrivaled commercial value. In this
paper we propose a methodology, an architecture, and a fully functional
framework for semi- and fully- automated creation, monitoring, and optimization
of cost-efficient pay-per-click campaigns with budget constraints. The campaign
creation module generates automatically keywords based on the content of the
web page to be advertised extended with corresponding ad-texts. These keywords
are used to create automatically the campaigns fully equipped with the
appropriate values set. The campaigns are uploaded to the auctioneer platform
and start running. The optimization module focuses on the learning process from
existing campaign statistics and also from applied strategies of previous
periods in order to invest optimally in the next period. The objective is to
maximize the performance (i.e. clicks, actions) under the current budget
constraint. The fully functional prototype is experimentally evaluated on real
world Google AdWords campaigns and presents a promising behavior with regards
to campaign performance statistics as it outperforms systematically the
competing manually maintained campaigns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1207</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1207</id><created>2012-08-06</created><authors><author><keyname>Farahbakhsh</keyname><forenames>Reza</forenames></author><author><keyname>Movahhedinia</keyname><forenames>Naser</forenames></author></authors><title>Seamless Handover for IMS over Mobile-IPv6 Using Context Transfer</title><categories>cs.NI</categories><comments>ISSN 1673-5447</comments><journal-ref>China Communications, Vol. 6 Issue (3): 122-133, 2009</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Mobility support for the next generation IPv6 networks has been one of the
recent research issues due to the growing demand for wireless services over
internet. In the other hand, 3GPP has introduced IP Multimedia Subsystem as the
next generation IP based infrastructure for wireless and wired multimedia
services. In this paper we present two context transfer mechanisms based on
predictive and reactive schemes, to support seamless handover in IMS over
Mobile IPv6. Those schemes reduce handover latency by transferring appropriate
session information between the old and the new access networks. Moreover, we
present two methods for QoS parameters negotiations to preserve service quality
along the mobile user movement path. The performances of the proposed
mechanisms are evaluated by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1217</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1217</id><created>2012-08-06</created><authors><author><keyname>Aouinatou</keyname><forenames>Rkia</forenames></author><author><keyname>Belkasmi</keyname><forenames>Mostafa</forenames></author></authors><title>An efficient classification in IBE Provide with an improvement of BB2 to
  an efficient Commutative Blinding scheme</title><categories>cs.CR</categories><comments>Pages: 34 No figures 6 Tales</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Because of the revolution and the success of the technique IBE
(Identification Based Encryption) in the recent years. The need is growing to
have a standardization to this technology to streamline communication based on
it. But this requires a thorough study to extract the strength and weakness of
the most recognized cryptosystems. Our first goal in this work is to approach
to this standardization, by applying a study which permit to extract the best
cryptosystems. As we will see in this work and as Boneh and Boyen said in 2011
(Journal of Cryptology) the BB1 and BB2 are the most efficient schemes in the
model selective ID and without random oracle (they are the only schemes traced
in this model). This is right as those schemes are secure (under this model),
efficient and useful for some applications. Our second goal behind this work is
to make an approvement in BB2 to admit a more efficient schemes. We will study
the security of our schemes, which is basing on an efficient strong
Diffie-Hellman problem compared to BB1 and BB2. More than that our HIBE support
s+ID-HIBE compared to BBG (Boneh Boyen Goh). Additionally the ID in our scheme
will be in Zp instead of Zp* as with BBG. We will cite more clearly all these
statements in in this article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1225</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1225</id><created>2012-08-06</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author><author><keyname>Szpankowski</keyname><forenames>Wojciech</forenames></author></authors><title>Average redundancy of the Shannon code for Markov sources</title><categories>cs.IT math.IT</categories><comments>25 pages; submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that for memoryless sources, the average and maximal redundancy
of fixed-to-variable length codes, such as the Shannon and Huffman codes,
exhibit two modes of behavior for long blocks. It either converges to a limit
or it has an oscillatory pattern, depending on the irrationality or
rationality, respectively, of certain parameters that depend on the source. In
this paper, we extend these findings, concerning the Shannon code, to the case
of a Markov source, which is considerably more involved. While this dichotomy,
of convergent vs. oscillatory behavior, is well known in other contexts
(including renewal theory, ergodic theory, local limit theorems and large
deviations of discrete distributions), in information theory (e.g., in
redundancy analysis) it was recognized relatively recently. To the best of our
knowledge, no results of this type were reported thus far for Markov sources.
We provide a precise characterization of the convergent vs. oscillatory
behavior of the Shannon code redundancy for a class of irreducible, periodic
and aperiodic, Markov sources. These findings are obtained by analytic methods,
such as Fourier/Fejer series analysis and spectral analysis of matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1230</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1230</id><created>2012-08-06</created><authors><author><keyname>Briat</keyname><forenames>Corentin</forenames></author><author><keyname>Yavuz</keyname><forenames>Emre Altug</forenames></author><author><keyname>Karlsson</keyname><forenames>Gunnar</forenames></author></authors><title>A conservation-law-based modular fluid-flow model for network congestion
  modeling</title><categories>cs.NI cs.SY math.CA math.DS math.OC</categories><comments>17 pages, 28 figures. Published at the 31st IEEE International
  Conference on Computer Communications (INFOCOM'12)</comments><doi>10.1109/INFCOM.2012.6195586</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A modular fluid-flow model for network congestion analysis and control is
proposed. The model is derived from an information conservation law stating
that the information is either in transit, lost or received. Mathematical
models of network elements such as queues, users, and transmission channels,
and network description variables, including sending/acknowledgement rates and
delays, are inferred from this law and obtained by applying this principle
locally. The modularity of the devised model makes it sufficiently generic to
describe any network topology, and appealing for building simulators. Previous
models in the literature are often not capable of capturing the transient
behavior of the network precisely, making the resulting analysis inaccurate in
practice. Those models can be recovered from exact reduction or approximation
of this new model. An important aspect of this particular modeling approach is
the introduction of new tight building blocks that implement mechanisms ignored
by the existing ones, notably at the queue and user levels. Comparisons with
packet-level simulations corroborate the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1231</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1231</id><created>2012-08-06</created><authors><author><keyname>Alvanaki</keyname><forenames>Foteini</forenames></author><author><keyname>Michel</keyname><forenames>Sebastian</forenames></author><author><keyname>Stupar</keyname><forenames>Aleksandar</forenames></author></authors><title>Building and Maintaining Halls of Fame over a Database</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Halls of Fame are fascinating constructs. They represent the elite of an
often very large amount of entities---persons, companies, products, countries
etc. Beyond their practical use as static rankings, changes to them are
particularly interesting---for decision making processes, as input to common
media or novel narrative science applications, or simply consumed by users. In
this work, we aim at detecting events that can be characterized by changes to a
Hall of Fame ranking in an automated way. We describe how the schema and data
of a database can be used to generate Halls of Fame. In this database scenario,
by Hall of Fame we refer to distinguished tuples; entities, whose
characteristics set them apart from the majority. We define every Hall of Fame
as one specific instance of an SQL query, such that a change in its result is
considered a noteworthy event. Identified changes (i.e., events) are ranked
using lexicographic tradeoffs over event and query properties and presented to
users or fed in higher-level applications. We have implemented a full-fledged
prototype system that uses either database triggers or a Java based middleware
for event identification. We report on an experimental evaluation using a
real-world dataset of basketball statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1237</identifier>
 <datestamp>2014-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1237</id><created>2012-08-06</created><updated>2013-10-07</updated><authors><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author><author><keyname>Vavasis</keyname><forenames>Stephen A.</forenames></author></authors><title>Fast and Robust Recursive Algorithms for Separable Nonnegative Matrix
  Factorization</title><categories>stat.ML cs.LG math.OC</categories><comments>30 pages, 2 figures, 7 tables. Main change: Improvement of the bound
  of the main theorem (Th. 3), replacing r with sqrt(r)</comments><journal-ref>IEEE Trans. on Pattern Analysis and Machine Intelligence 36 (4),
  pp. 698-714, 2014</journal-ref><doi>10.1109/TPAMI.2013.226</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the nonnegative matrix factorization problem under
the separability assumption (that is, there exists a cone spanned by a small
subset of the columns of the input nonnegative data matrix containing all
columns), which is equivalent to the hyperspectral unmixing problem under the
linear mixing model and the pure-pixel assumption. We present a family of fast
recursive algorithms, and prove they are robust under any small perturbations
of the input data matrix. This family generalizes several existing
hyperspectral unmixing algorithms and hence provides for the first time a
theoretical justification of their better practical performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1248</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1248</id><created>2012-08-06</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author></authors><title>On fixed-parameter algorithms for Split Vertex Deletion</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Split Vertex Deletion problem, given a graph G and an integer k, we
ask whether one can delete k vertices from the graph G to obtain a split graph
(i.e., a graph, whose vertex set can be partitioned into two sets: one inducing
a clique and the second one inducing an independent set). In this paper we
study fixed-parameter algorithms for Split Vertex Deletion parameterized by k:
we show that, up to a factor quasipolynomial in k and polynomial in n, the
Split Vertex Deletion problem can be solved in the same time as the
well-studied Vertex Cover problem. Plugging the currently best fixed-parameter
algorithm for Vertex Cover due to Chen et al. [TCS 2010], we obtain an
algorithm that solves Split Vertex Deletion in time O(1.2738^k * k^O(log k) +
n^O(1)).
  To achieve our goal, we prove the following structural result that may be of
independent interest: for any graph G we may compute a family P of size n^O(log
n) containing partitions of V(G) into two parts, such for any two disjoint
subsets X_C, X_I of V(G) where G[X_C] is a clique and G[X_I] is an independent
set, there is a partition in P which contains all vertices of X_C on one side
and all vertices of X_I on the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1259</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1259</id><created>2012-08-06</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Owen</keyname><forenames>Art</forenames></author><author><keyname>Zhang</keyname><forenames>Cun-Hui</forenames></author></authors><title>One Permutation Hashing for Efficient Search and Learning</title><categories>cs.LG cs.IR cs.IT math.IT stat.CO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the method of b-bit minwise hashing has been applied to large-scale
linear learning and sublinear time near-neighbor search. The major drawback of
minwise hashing is the expensive preprocessing cost, as the method requires
applying (e.g.,) k=200 to 500 permutations on the data. The testing time can
also be expensive if a new data point (e.g., a new document or image) has not
been processed, which might be a significant issue in user-facing applications.
  We develop a very simple solution based on one permutation hashing.
Conceptually, given a massive binary data matrix, we permute the columns only
once and divide the permuted columns evenly into k bins; and we simply store,
for each data vector, the smallest nonzero location in each bin. The
interesting probability analysis (which is validated by experiments) reveals
that our one permutation scheme should perform very similarly to the original
(k-permutation) minwise hashing. In fact, the one permutation scheme can be
even slightly more accurate, due to the &quot;sample-without-replacement&quot; effect.
  Our experiments with training linear SVM and logistic regression on the
webspam dataset demonstrate that this one permutation hashing scheme can
achieve the same (or even slightly better) accuracies compared to the original
k-permutation scheme. To test the robustness of our method, we also experiment
with the small news20 dataset which is very sparse and has merely on average
500 nonzeros in each data vector. Interestingly, our one permutation scheme
noticeably outperforms the k-permutation scheme when k is not too small on the
news20 dataset. In summary, our method can achieve at least the same accuracy
as the original k-permutation scheme, at merely 1/k of the original
preprocessing cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1270</identifier>
 <datestamp>2012-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1270</id><created>2012-08-06</created><updated>2012-09-29</updated><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Properties of the Quantum Channel</title><categories>quant-ph cs.IT math.IT</categories><comments>Review paper: A tribute to the inventors of the various capacity
  formulas of quantum channels. 304 pages, 5 tables, 106 figures; added new
  section</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum information processing exploits the quantum nature of information. It
offers fundamentally new solutions in the field of computer science and extends
the possibilities to a level that cannot be imagined in classical communication
systems. For quantum communication channels, many new capacity definitions were
developed in comparison to classical counterparts. A quantum channel can be
used to realize classical information transmission or to deliver quantum
information, such as quantum entanglement. In this paper we overview the
properties of the quantum communication channel, the various capacity measures
and the fundamental differences between the classical and quantum channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1272</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1272</id><created>2012-08-06</created><authors><author><keyname>Chuzhoy</keyname><forenames>Julia</forenames></author><author><keyname>Li</keyname><forenames>Shi</forenames></author></authors><title>A Polylogarithimic Approximation Algorithm for Edge-Disjoint Paths with
  Congestion 2</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Edge-Disjoint Paths with Congestion problem (EDPwC), we are given an
undirected n-vertex graph G, a collection M={(s_1,t_1),...,(s_k,t_k)} of demand
pairs and an integer c. The goal is to connect the maximum possible number of
the demand pairs by paths, so that the maximum edge congestion - the number of
paths sharing any edge - is bounded by c. When the maximum allowed congestion
is c=1, this is the classical Edge-Disjoint Paths problem (EDP).
  The best current approximation algorithm for EDP achieves an $O(\sqrt
n)$-approximation, by rounding the standard multi-commodity flow relaxation of
the problem. This matches the $\Omega(\sqrt n)$ lower bound on the integrality
gap of this relaxation. We show an $O(poly log k)$-approximation algorithm for
EDPwC with congestion c=2, by rounding the same multi-commodity flow
relaxation. This gives the best possible congestion for a sub-polynomial
approximation of EDPwC via this relaxation. Our results are also close to
optimal in terms of the number of pairs routed, since EDPwC is known to be hard
to approximate to within a factor of $\tilde{\Omega}((\log n)^{1/(c+1)})$ for
any constant congestion c. Prior to our work, the best approximation factor for
EDPwC with congestion 2 was $\tilde O(n^{3/7})$, and the best algorithm
achieving a polylogarithmic approximation required congestion 14.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1275</identifier>
 <datestamp>2013-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1275</id><created>2012-08-06</created><authors><author><keyname>Nadakuditi</keyname><forenames>Raj Rao</forenames></author><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>Spectra of random graphs with arbitrary expected degrees</title><categories>cs.SI cond-mat.stat-mech physics.soc-ph</categories><comments>14 pages, 5 figures</comments><journal-ref>Phys. Rev. E 87, 012803 (2013)</journal-ref><doi>10.1103/PhysRevE.87.012803</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study random graphs with arbitrary distributions of expected degree and
derive expressions for the spectra of their adjacency and modularity matrices.
We give a complete prescription for calculating the spectra that is exact in
the limit of large network size and large vertex degrees. We also study the
effect on the spectra of hubs in the network, vertices of unusually high
degree, and show that these produce isolated eigenvalues outside the main
spectral band, akin to impurity states in condensed matter systems, with
accompanying eigenvectors that are strongly localized around the hubs. We also
give numerical results that confirm our analytic expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1283</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1283</id><created>2012-08-06</created><updated>2012-08-13</updated><authors><author><keyname>Petersen</keyname><forenames>Holger</forenames></author></authors><title>The Power of Centralized PC Systems of Pushdown Automata</title><categories>cs.FL</categories><doi>10.1007/978-3-642-39310-5_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel communicating systems of pushdown automata (PCPA) were introduced in
(Csuhaj-Varj{\'u} et. al. 2000) and in their centralized variants shown to be
able to simulate nondeterministic one-way multi-head pushdown automata. A
claimed converse simulation for returning mode (Balan 2009) turned out to be
incomplete (Otto 2012) and a language was suggested for separating these PCPA
of degree two (number of pushdown automata) from nondeterministic one-way
two-head pushdown automata. We show that the suggested language can be accepted
by the latter computational model. We present a different example over a single
letter alphabet indeed ruling out the possibility of a simulation between the
models. The open question about the power of centralized PCPA working in
returning mode is then settled by showing them to be universal. Since the
construction is possible using systems of degree two, this also improves the
previous bound three for generating all recursively enumerable languages.
Finally PCPAs are restricted in such a way that a simulation by multi-head
automata is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1290</identifier>
 <datestamp>2012-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1290</id><created>2012-08-06</created><authors><author><keyname>Golrezaei</keyname><forenames>Negin</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author></authors><title>Scaling Behaviors of Wireless Device-to-Device Communications with
  Distributed Caching</title><categories>cs.NI cs.IT math.IT</categories><comments>12 pages, 5 figures. arXiv admin note: substantial text overlap with
  arXiv:1205.7044</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a novel architecture for caching popular video content to enable
wireless device-to-device collaboration. We focus on the asymptotic scaling
characteristics and show how they depends on video content popularity
statistics. We identify a fundamental conflict between collaboration distance
and interference and show how to optimize the transmission power to maximize
frequency reuse. Our main result is a closed form expression of the optimal
collaboration distance as a function of the model parameters. Under the common
assumption of a Zipf distribution for content reuse, we show that if the Zipf
exponent is greater than 1, it is possible to have a number of D2D
interference-free collaboration pairs that scales linearly in the number of
nodes. If the Zipf exponent is smaller than 1, we identify the best possible
scaling in the number of D2D collaborating links. Surprisingly, a very simple
distributed caching policy achieves the optimal scaling behavior and therefore
there is no need to centrally coordinate what each node is caching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1315</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1315</id><created>2012-08-06</created><authors><author><keyname>Parsazad</keyname><forenames>Shafigh</forenames></author><author><keyname>Saboori</keyname><forenames>Ehsan</forenames></author><author><keyname>Allahyar</keyname><forenames>Amin</forenames></author></authors><title>Data Selection for Semi-Supervised Learning</title><categories>cs.LG</categories><comments>6 Pages</comments><journal-ref>International Journal of Computer Science Issues, Vol. 9, Issue 2,
  No 3, pp. 195-200, March 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The real challenge in pattern recognition task and machine learning process
is to train a discriminator using labeled data and use it to distinguish
between future data as accurate as possible. However, most of the problems in
the real world have numerous data, which labeling them is a cumbersome or even
an impossible matter. Semi-supervised learning is one approach to overcome
these types of problems. It uses only a small set of labeled with the company
of huge remain and unlabeled data to train the discriminator. In
semi-supervised learning, it is very essential that which data is labeled and
depend on position of data it effectiveness changes. In this paper, we proposed
an evolutionary approach called Artificial Immune System (AIS) to determine
which data is better to be labeled to get the high quality data. The
experimental results represent the effectiveness of this algorithm in finding
these data points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1326</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1326</id><created>2012-08-06</created><authors><author><keyname>Butler</keyname><forenames>Brian K.</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Numerical Issues Affecting LDPC Error Floors</title><categories>cs.IT cs.NA math.IT math.NA</categories><comments>7 pages, 5 figures. Submitted to IEEE Globecom (Selected Area of
  Communications Data Storage Track)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical issues related to the occurrence of error floors in floating-point
simulations of belief propagation (BP) decoders are examined. Careful
processing of messages corresponding to highly-certain bit values can sometimes
reduce error floors by several orders of magnitude. Computational solutions for
properly handling such messages are provided for the sum-product algorithm
(SPA) and several variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1329</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1329</id><created>2012-08-06</created><authors><author><keyname>Morrison</keyname><forenames>Kent E.</forenames></author></authors><title>The multiplication game</title><categories>cs.GT math.PR</categories><comments>14 pages</comments><msc-class>91A05</msc-class><journal-ref>Mathematics Magazine 83 (2010) 100-110</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiplication game is a two-person game in which each player chooses a
positive integer without knowledge of the other player's number. The two
numbers are then multiplied together and the first digit of the product
determines the winner. Rather than analyzing this game directly, we consider a
closely related game in which the players choose positive real numbers between
1 and 10, multiply them together, and move the decimal point, if necessary, so
that the result is between 1 and 10. The mixed strategies are probability
distributions on this interval, and it is shown that for both players it is
optimal to choose their numbers from the Benford distribution. Furthermore,
this strategy is optimal for any winning set, and the probability of winning is
the Benford measure of the player's winning set. Using these results we prove
that the original game in which the players choose integers has a well-defined
value and that strategies exist that are arbitrarily close to optimal. Finally,
we consider generalizations of the game in which players choose elements from a
compact topological group and show that choosing them according to Haar measure
is an optimal strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1336</identifier>
 <datestamp>2012-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1336</id><created>2012-08-07</created><authors><author><keyname>Burke</keyname><forenames>Jeff</forenames></author><author><keyname>Gasti</keyname><forenames>Paolo</forenames></author><author><keyname>Nathan</keyname><forenames>Naveen</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author></authors><title>Securing Instrumented Environments over Content-Centric Networking: the
  Case of Lighting Control</title><categories>cs.CR</categories><comments>arXiv admin note: text overlap with arXiv:1208.0952</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instrumented environments, such as modern building automation systems (BAS),
are becoming commonplace and are increasingly interconnected with (and
sometimes by) enterprise networks and the Internet. Regardless of the
underlying communication platform, secure control of devices in such
environments is a challenging task. The current trend is to move from
proprietary communication media and protocols to IP over Ethernet. While the
move to IP represents progress, new and different Internet architectures might
be better-suited for instrumented environments. In this paper, we consider
security of instrumented environments in the context of Content-Centric
Networking (CCN). In particular, we focus on building automation over
Named-Data Networking (NDN), a prominent instance of CCN. After identifying
security requirements in a specific BAS sub-domain (lighting control), we
construct a concrete NDN-based security architecture, analyze its properties
and report on preliminary implementation and experimental results. We believe
in securing a communication paradigm well outside of its claimed forte of
content distribution. At the same time, we provide a viable (secure and
efficient) communication platform for a class of instrumented environments
exemplified by lighting control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1346</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1346</id><created>2012-08-07</created><authors><author><keyname>Brechka</keyname><forenames>Denis</forenames></author></authors><title>Algorithm for searching bridges of specified types in the protection
  graph for Take-Grant protection model</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article contains the algorithm for searching a certain kind of bridges in
the protection graph of Take-Grant model. The proposed algorithm is based on a
classical breadth-first search algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1349</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1349</id><created>2012-08-07</created><updated>2012-12-13</updated><authors><author><keyname>Wang</keyname><forenames>Xianwen</forenames></author><author><keyname>Wang</keyname><forenames>Zhi</forenames></author><author><keyname>Xu</keyname><forenames>Shenmeng</forenames></author></authors><title>Tracing scientist's research trends realtimely</title><categories>cs.DL</categories><comments>13 pages, 7 figures</comments><journal-ref>Scientometrics. 2013, 95(2): 717-729</journal-ref><doi>10.1007/s11192-012-0884-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research, we propose a method to trace scientists' research trends
realtimely. By monitoring the downloads of scientific articles in the journal
of Scientometrics for 744 hours, namely one month, we investigate the download
statistics. Then we aggregate the keywords in these downloaded research papers,
and analyze the trends of article downloading and keyword downloading.
Furthermore, taking both the download of keywords and articles into
consideration, we design a method to detect the emerging research trends. We
find that in scientometrics field, social media, new indices to quantify
scientific productivity (g-index), webometrics, semantic, text mining, open
access are emerging fields that scientometrics researchers are focusing on.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1350</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1350</id><created>2012-08-07</created><authors><author><keyname>Fang</keyname><forenames>Yi</forenames></author><author><keyname>Xu</keyname><forenames>Jing</forenames></author><author><keyname>Wang</keyname><forenames>Lin</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author></authors><title>Performance of MIMO Relay DCSK-CD Systems over Nakagami Fading Channels</title><categories>cs.OH</categories><comments>11 pages, 15 figures. IEEE Transactions on Circuits and System-I</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multi-access multiple-input multiple-output (MIMO) relay differential chaos
shift keying cooperative diversity (DCSK-CD) system is proposed in this paper
as a comprehensive cooperation scheme, in which the relay and destination both
employ multiple antennas to strengthen the robustness against signal fading in
a wireless network. It is shown that, with spatial diversity gains, the bit
error rate (BER) performance of the proposed system is remarkably better than
the conventional DCSK non-cooperation (DCSK-NC) and DCSK cooperative
communication (DCSK-CC) systems. Moreover, the exact BER and close-form
expressions of the proposed system are derived over Nakagami fading channels
through the moment generating function (MGF), which is shown to be highly
consistent with the simulation results. Meanwhile, this paper illustrates a
trade-off between the performance and the complexity, and provides a threshold
for the number of relay antennas keeping the user consumed energy constant. Due
to the above-mentioned advantages, the proposed system stands out as a good
candidate or alternative for energy-constrained wireless communications based
on chaotic modulation, especially for low-power and low-cost wireless personal
area networks (WPANs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1353</identifier>
 <datestamp>2013-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1353</id><created>2012-08-07</created><authors><author><keyname>Zhao</keyname><forenames>Junhua</forenames></author><author><keyname>Wang</keyname><forenames>Lifeng</forenames></author><author><keyname>Jiang</keyname><forenames>Jin-Wu</forenames></author><author><keyname>Wang</keyname><forenames>Zhengzhong</forenames></author><author><keyname>Guo</keyname><forenames>Wanlin</forenames></author><author><keyname>Rabczuk</keyname><forenames>Timon</forenames></author></authors><title>A comparative study of two molecular mechanics models based on harmonic
  potentials</title><categories>cond-mat.mtrl-sci cs.CE</categories><comments>40 pages, 21 figures</comments><report-no>113</report-no><doi>10.1063/1.4791579</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the two molecular mechanics models, the stick-spiral and the
beam models, predict considerably different mechanical properties of materials
based on energy equivalence. The difference between the two models is
independent of the materials since all parameters of the beam model are
obtained from the harmonic potentials. We demonstrate this difference for
finite width graphene nanoribbons and a single polyethylene chain comparing
results of the molecular dynamics (MD) simulations with harmonic potentials and
the finite element method with the beam model. We also find that the difference
strongly depends on the loading modes, chirality and width of the graphene
nanoribbons, and it increases with decreasing width of the nanoribbons under
pure bending condition. The maximum difference of the predicted mechanical
properties using the two models can exceed 300% in different loading modes.
Comparing the two models with the MD results of AIREBO potential, we find that
the stick-spiral model overestimates and the beam model underestimates the
mechanical properties in narrow armchair graphene nanoribbons under pure
bending condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1366</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1366</id><created>2012-08-07</created><authors><author><keyname>Sternagel</keyname><forenames>Christian</forenames></author></authors><title>A Locale for Minimal Bad Sequences</title><categories>cs.LO</categories><comments>7 pages, Isabelle Users Workshop 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a locale that abstracts over the necessary ingredients for
constructing a minimal bad sequence, as required in classical proofs of
Higman's lemma and Kruskal's tree theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1368</identifier>
 <datestamp>2013-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1368</id><created>2012-08-07</created><updated>2013-01-31</updated><authors><author><keyname>Sternagel</keyname><forenames>Christian</forenames></author></authors><title>Getting Started with Isabelle/jEdit</title><categories>cs.LO</categories><comments>6 pages, Isabelle Users Workshop 2012 (updated)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a beginner-oriented introduction to Isabelle/jEdit, providing
motivation for using it as well as pointing at some differences to the
traditional Proof General interface and current limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1376</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1376</id><created>2012-08-07</created><authors><author><keyname>Portillo</keyname><forenames>Ignacio Gomez</forenames></author></authors><title>Building Cooperative Networks</title><categories>cs.GT physics.soc-ph</categories><comments>24 pages, 8 figures</comments><doi>10.1103/PhysRevE.86.051108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the cooperation problem in the framework of evolutionary game theory
using the prisoner's dilemma as metaphor of the problem. Considering the
growing process of the system and individuals with imitation capacity, we show
conditions that allow to form highly cooperative networks of any size and
topology. Introducing general considerations of real systems, we reduce the
required conditions for cooperation to evolve approaching the benefit-cost
ratio r to the theoretical minimum r=1, when the mean connectivity of the
individuals is increased. Through the paper, we distinguish different
mechanisms that allow the system to maintain high levels of cooperation when
the system grows by incorporation of defectors. These mechanisms require
heterogeneity among individuals for cooperation to evolve. However, the
required conditions and heterogeneities are drastically reduced as compared to
those required for static networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1400</identifier>
 <datestamp>2014-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1400</id><created>2012-08-07</created><updated>2014-02-27</updated><authors><author><keyname>Li</keyname><forenames>Ke</forenames></author></authors><title>Second-order asymptotics for quantum hypothesis testing</title><categories>quant-ph cs.IT math.IT math.ST stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/13-AOS1185 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS1185</report-no><journal-ref>Annals of Statistics 2014, Vol. 42, No. 1, 171-189</journal-ref><doi>10.1214/13-AOS1185</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the asymptotic theory of quantum hypothesis testing, the minimal error
probability of the first kind jumps sharply from zero to one when the error
exponent of the second kind passes by the point of the relative entropy of the
two states in an increasing way. This is well known as the direct part and
strong converse of quantum Stein's lemma. Here we look into the behavior of
this sudden change and have make it clear how the error of first kind grows
smoothly according to a lower order of the error exponent of the second kind,
and hence we obtain the second-order asymptotics for quantum hypothesis
testing. This actually implies quantum Stein's lemma as a special case.
Meanwhile, our analysis also yields tight bounds for the case of finite sample
size. These results have potential applications in quantum information theory.
Our method is elementary, based on basic linear algebra and probability theory.
It deals with the achievability part and the optimality part in a unified
fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1401</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1401</id><created>2012-08-07</created><updated>2013-01-16</updated><authors><author><keyname>Smiljani&#x107;</keyname><forenames>Jelena</forenames></author><author><keyname>Stankovi&#x107;</keyname><forenames>Igor</forenames></author></authors><title>Study of dynamic and static routing for improvement of the
  transportation efficiency on small complex networks</title><categories>physics.soc-ph cs.NI cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we are exploring strategies for the reduction of the
congestion in the complex networks. The nodes without buffers are considered,
so, if the congestion occurs, the information packets will be dropped. The
focus is on the efficient routing. The routing strategies are compared using
two generic models, i.e., Barab\`asi-Albert scale-free network and scale-free
network on lattice, and the academic router networks of the Netherlands and
France. We propose a dynamic deflection routing algorithm which automatically
extends path of the packet before it arrives at congested node. The simulation
results indicate that the dynamic routing strategy can further reduce number of
dropped packets in a combination with the efficient path routing proposed by
Yan et al. [Phys. Rev. E 73, 046108 (2006)].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1410</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1410</id><created>2012-08-07</created><authors><author><keyname>Kaneko</keyname><forenames>Megumi</forenames></author><author><keyname>Agha</keyname><forenames>Khaldoun Al</forenames></author></authors><title>Compressed Sensing based Protocol for Efficient Reconstruction of Sparse
  Superimposed Data in a Multi-Hop Wireless Sensor Network</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-hop wireless sensor network that measures sparse events
and propose a simple forwarding protocol based on Compressed Sensing (CS) which
does not need any sophisticated Media Access Control (MAC) scheduling, neither
a routing protocol, thereby making significant overhead and energy savings. By
means of flooding, multiple packets with different superimposed measurements
are received simultaneously at any node. Thanks to our protocol, each node is
able to recover each measurement and forward it while avoiding cycles.
Numerical results show that our protocol achieves close to zero reconstruction
errors at the sink, while greatly reducing overhead. This initial research
reveals a new and promising approach to protocol design through CS for wireless
mesh and sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1418</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1418</id><created>2012-08-07</created><authors><author><keyname>Chadha</keyname><forenames>Aman</forenames></author><author><keyname>Savardekar</keyname><forenames>Bharatraaj</forenames></author><author><keyname>Padhya</keyname><forenames>Jay</forenames></author></authors><title>Analysis of a Modern Voice Morphing Approach using Gaussian Mixture
  Models for Laryngectomees</title><categories>cs.SD</categories><comments>6 pages, 4 figures, 4 tables; International Journal of Computer
  Applications Volume 49, Number 21, July 2012</comments><doi>10.5120/7896-1235</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a voice morphing system for people suffering from
Laryngectomy, which is the surgical removal of all or part of the larynx or the
voice box, particularly performed in cases of laryngeal cancer. A primitive
method of achieving voice morphing is by extracting the source's vocal
coefficients and then converting them into the target speaker's vocal
parameters. In this paper, we deploy Gaussian Mixture Models (GMM) for mapping
the coefficients from source to destination. However, the use of the
traditional/conventional GMM-based mapping approach results in the problem of
over-smoothening of the converted voice. Thus, we hereby propose a unique
method to perform efficient voice morphing and conversion based on GMM,which
overcomes the traditional-method effects of over-smoothening. It uses a
technique of glottal waveform separation and prediction of excitations and
hence the result shows that not only over-smoothening is eliminated but also
the transformed vocal tract parameters match with the target. Moreover, the
synthesized speech thus obtained is found to be of a sufficiently high quality.
Thus, voice morphing based on a unique GMM approach has been proposed and also
critically evaluated based on various subjective and objective evaluation
parameters. Further, an application of voice morphing for Laryngectomees which
deploys this unique approach has been recommended by this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1429</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1429</id><created>2012-08-07</created><authors><author><keyname>Mishra</keyname><forenames>Geetishree</forenames></author><author><keyname>Hegde</keyname><forenames>Rajeshwari</forenames></author><author><keyname>Gurumurthy</keyname><forenames>K. S.</forenames></author></authors><title>Deploying Health Monitoring ECU Towards Enhancing the Performance of
  In-Vehicle Network</title><categories>cs.OH</categories><comments>7 pages, 4 figures, FCST 2012</comments><doi>10.5121/csit.2012.2348</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic Control Units (ECUs) are the fundamental electronic building
blocks of any automotive system. They are multi-purpose, multi-chip and
multicore computer systems where more functionality is delivered in software
rather than hardware. ECUs are valuable assets for the vehicles as critical
time bounded messages are communicated through. Looking into the safety
criticality, already developed mission critical systems such as ABS, ESP etc,
rely fully on electronic components leading to increasing requirements of more
reliable and dependable electronic systems in vehicles. Hence it is inevitable
to maintain and monitor the health of an ECU which will enable the ECUs to be
followed, assessed and improved throughout their life-cycle starting from their
inception into the vehicle. In this paper, we propose a Health monitoring ECU
that enables the early trouble shooting and servicing of the vehicle prior to
any catastrophic failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1448</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1448</id><created>2012-08-07</created><updated>2013-01-05</updated><authors><author><keyname>Chen</keyname><forenames>Cheng</forenames></author><author><keyname>Wu</keyname><forenames>Kui</forenames></author><author><keyname>Srinivasan</keyname><forenames>Venkatesh</forenames></author><author><keyname>R</keyname><forenames>Kesav Bharadwaj</forenames></author></authors><title>The Best Answers? Think Twice: Online Detection of Commercial Campaigns
  in the CQA Forums</title><categories>cs.IR cs.SI</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an emerging trend, more and more Internet users search for information
from Community Question and Answer (CQA) websites, as interactive communication
in such websites provides users with a rare feeling of trust. More often than
not, end users look for instant help when they browse the CQA websites for the
best answers. Hence, it is imperative that they should be warned of any
potential commercial campaigns hidden behind the answers. However, existing
research focuses more on the quality of answers and does not meet the above
need. In this paper, we develop a system that automatically analyzes the hidden
patterns of commercial spam and raises alarms instantaneously to end users
whenever a potential commercial campaign is detected. Our detection method
integrates semantic analysis and posters' track records and utilizes the
special features of CQA websites largely different from those in other types of
forums such as microblogs or news reports. Our system is adaptive and
accommodates new evidence uncovered by the detection algorithms over time.
Validated with real-world trace data from a popular Chinese CQA website over a
period of three months, our system shows great potential towards adaptive
online detection of CQA spams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1454</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1454</id><created>2012-08-07</created><authors><author><keyname>Sarma</keyname><forenames>Atish Das</forenames></author><author><keyname>Lall</keyname><forenames>Ashwin</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>Dense Subgraphs on Dynamic Networks</title><categories>cs.DC cs.DS</categories><comments>To appear in the 26th International Symposium on Distributed
  Computing (DISC 2012)</comments><acm-class>C.2.4; F.0; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In distributed networks, it is often useful for the nodes to be aware of
dense subgraphs, e.g., such a dense subgraph could reveal dense subtructures in
otherwise sparse graphs (e.g. the World Wide Web or social networks); these
might reveal community clusters or dense regions for possibly maintaining good
communication infrastructure. In this work, we address the problem of
self-awareness of nodes in a dynamic network with regards to graph density,
i.e., we give distributed algorithms for maintaining dense subgraphs that the
member nodes are aware of. The only knowledge that the nodes need is that of
the dynamic diameter $D$, i.e., the maximum number of rounds it takes for a
message to traverse the dynamic network. For our work, we consider a model
where the number of nodes are fixed, but a powerful adversary can add or remove
a limited number of edges from the network at each time step. The communication
is by broadcast only and follows the CONGEST model. Our algorithms are
continuously executed on the network, and at any time (after some
initialization) each node will be aware if it is part (or not) of a particular
dense subgraph. We give algorithms that ($2 + \epsilon$)-approximate the
densest subgraph and ($3 + \epsilon$)-approximate the at-least-$k$-densest
subgraph (for a given parameter $k$). Our algorithms work for a wide range of
parameter values and run in $O(D\log_{1+\epsilon} n)$ time. Further, a special
case of our results also gives the first fully decentralized approximation
algorithms for densest and at-least-$k$-densest subgraph problems for static
distributed graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1458</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1458</id><created>2012-08-07</created><authors><author><keyname>Croke</keyname><forenames>Sarah</forenames></author><author><keyname>Kent</keyname><forenames>Adrian</forenames></author></authors><title>Security Details for Bit Commitment by Transmitting Measurement Outcomes</title><categories>quant-ph cs.CR</categories><comments>arXiv admin note: text overlap with arXiv:1108.2879</comments><journal-ref>Phys. Rev. A 86, 052309 (2012)</journal-ref><doi>10.1103/PhysRevA.86.052309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We spell out details of a simple argument for a security bound for the secure
relativistic quantum bit commitment protocol of Ref. [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1476</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1476</id><created>2012-08-07</created><authors><author><keyname>Schmidt</keyname><forenames>Renate A.</forenames></author><author><keyname>Tishkovsky</keyname><forenames>Dmitry</forenames></author></authors><title>Using Tableau to Decide Description Logics with Full Role Negation and
  Identity</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a tableau approach for deciding expressive description
logics with full role negation and role identity. We consider the description
logic ALBOid, which is the extension of ALC with the Boolean role operators,
inverse of roles, the identity role, and includes full support for individuals
and singleton concepts. ALBOid is expressively equivalent to the two-variable
fragment of first-order logic with equality and subsumes Boolean modal logic.
In this paper we define a sound and complete tableau calculus for the ALBOid
that provides a basis for decision procedures for this logic and all its
sublogics. An important novelty of our approach is the use of a generic
unrestricted blocking mechanism. Being based on a conceptually simple rule,
unrestricted blocking performs case distinctions over whether two individuals
are equal or not and equality reasoning to find finite models. The blocking
mechanism ties the proof of termination of tableau derivations to the finite
model property of ALBOid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1532</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1532</id><created>2012-08-07</created><authors><author><keyname>Denton</keyname><forenames>Daniel</forenames></author></authors><title>Methods of computing deque sortable permutations given complete and
  incomplete information</title><categories>math.CO cs.DS</categories><comments>dartmouth senior honors thesis advised by Peter Doyle and Scot
  Drysdale 45 pages, 9 figures</comments><report-no>Dartmouth Computer Science Technical Report TR2012-719</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of determining which permutations can be sorted using certain
switchyard networks dates back to Knuth in 1968. In this work, we are
interested in permutations which are sortable on a double-ended queue (called a
deque), or on two parallel stacks. In 1982, Rosenstiehl and Tarjan presented an
O(n) algorithm for testing whether a given permutation was sortable on parallel
stacks. In the same paper, they also presented a modification giving O(n) test
for sortability on a deque. We demonstrate a slight error in the version of
their algorithm for testing deque sortability, and present a fix for this
problem.
  The general enumeration problem for both of these classes of permutations
remains unsolved. What is known is that the growth rate of both classes is
approximately Theta(8^n), so computing the number of sortable permutations of
length n, even for small values of n, is difficult to do using any method that
must evaluate each sortable permutation individually. As far as we know, the
number of deque sortable permutations was known only up to n=14. This was
computed using algorithms which effectively generate all sortable permutations.
By using the symmetries inherent in the execution of Tarjan's algorithm, we
have developed a new dynamic programming algorithm which can count the number
of sortable permutations in both classes in O(n^5 2^n) time, allowing the
calculation of the number of deque and parallel stack sortable permutation for
much higher values of n than was previously possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1544</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1544</id><created>2012-08-07</created><authors><author><keyname>Zhang</keyname><forenames>Amy</forenames></author><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>Ioannidis</keyname><forenames>Stratis</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Guess Who Rated This Movie: Identifying Users Through Subspace
  Clustering</title><categories>cs.LG</categories><comments>10 pages</comments><journal-ref>28th Conference on Uncertainty in Artificial Intelligence (UAI
  2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is often the case that, within an online recommender system, multiple
users share a common account. Can such shared accounts be identified solely on
the basis of the user- provided ratings? Once a shared account is identified,
can the different users sharing it be identified as well? Whenever such user
identification is feasible, it opens the way to possible improvements in
personalized recommendations, but also raises privacy concerns. We develop a
model for composite accounts based on unions of linear subspaces, and use
subspace clustering for carrying out the identification task. We show that a
significant fraction of such accounts is identifiable in a reliable manner, and
illustrate potential uses for personalized recommendation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1565</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1565</id><created>2012-08-07</created><authors><author><keyname>Schweller</keyname><forenames>Robert</forenames></author><author><keyname>Sherman</keyname><forenames>Michael</forenames></author></authors><title>Fuel Efficient Computation in Passive Self-Assembly</title><categories>cs.DS cs.CC cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that passive self-assembly in the context of the tile
self-assembly model is capable of performing fuel efficient, universal
computation. The tile self-assembly model is a premiere model of self-assembly
in which particles are modeled by four-sided squares with glue types assigned
to each tile edge. The assembly process is driven by positive and negative
force interactions between glue types, allowing for tile assemblies floating in
the plane to combine and break apart over time. We refer to this type of
assembly model as passive in that the constituent parts remain unchanged
throughout the assembly process regardless of their interactions. A
computationally universal system is said to be fuel efficient if the number of
tiles used up per computation step is bounded by a constant. Work within this
model has shown how fuel guzzling tile systems can perform universal
computation with only positive strength glue interactions. Recent work has
introduced space-efficient, fuel-guzzling universal computation with the
addition of negative glue interactions and the use of a powerful non-diagonal
class of glue interactions. Other recent work has shown how to achieve fuel
efficient computation within active tile self-assembly. In this paper we
utilize negative interactions in the tile self-assembly model to achieve the
first computationally universal passive tile self-assembly system that is both
space and fuel-efficient. In addition, we achieve this result using a limited
diagonal class of glue interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1569</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1569</id><created>2012-08-07</created><authors><author><keyname>Shvartzshnaider</keyname><forenames>Yan</forenames></author><author><keyname>Ott</keyname><forenames>Maximilian</forenames></author></authors><title>Design For Change: Information-Centric Architecture to Support Agile
  Disaster Response</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a case for the adoption of an information-centric
architecture for a global disaster management system. Drawing from a case study
of the 2010/2011 Queensland floods, we describe the challenges in providing
every participant with relevant and actionable information. We use various
examples to argue for a more flexible information dissemination framework which
is designed from the ground up to minimise the effort needed to fix the
unexpected and unavoidable information acquisition, quality, and dissemination
challenges posed by any real disaster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1574</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1574</id><created>2012-08-08</created><authors><author><keyname>Barahim</keyname><forenames>Zaafir</forenames></author><author><keyname>Doomun</keyname><forenames>M. Razvi</forenames></author><author><keyname>Joomun</keyname><forenames>Nazrana</forenames></author></authors><title>Low-Cost Bluetooth Mobile Positioning for Location-based Application</title><categories>cs.NI</categories><comments>4 pages 3rd IEEE/IFIP International Conference in Central Asia on
  Internet 2007, ICI 2007</comments><doi>10.1109/CANET.2007.4401707</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Bluetooth is a promising short-range radio network technology. We present a
low cost and easily deployed, scalable infrastructure for indoor location-based
computing of mobile devices based on Bluetooth technology. The system consists
of 2 main components, namely the Bluetooth (BT) Sensor System and the Central
Navigation System which have been developed using the JDK 6.0. The Bluetooth
Sensor System allows mobile devices whose Bluetooth mode is set to
discoverable, to be scanned and detected, and they receive customizable text
message of their positioning information, e.g. room identity. The positioning
information is also sent to the Central Navigation System which in turn
displays and updates the navigation map. The system is also used to track the
movement of different BT mobile devices within the implemented environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1591</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1591</id><created>2012-08-08</created><authors><author><keyname>Sternagel</keyname><forenames>Christian</forenames></author><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Winkler</keyname><forenames>Sarah</forenames></author><author><keyname>Zankl</keyname><forenames>Harald</forenames></author></authors><title>CeTA - A Tool for Certified Termination Analysis</title><categories>cs.LO</categories><comments>4 pages, International Workshop on Termination 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the first termination competition in 2004 it is of great interest,
whether a proof that has been automatically generated by a termination tool, is
indeed correct. The increasing number of termination proving techniques as well
as the increasing complexity of generated proofs (e.g., combinations of several
techniques, exhaustive labelings, tree automata, etc.), make certifying (i.e.,
checking the correctness of) such proofs more and more tedious for humans.
Hence the interest in automated certification of termination proofs. This led
to the general approach of using proof assistants (like Coq and Isabelle) for
certification. We present the latest developments for IsaFoR/CeTA (version
1.03) which is the certifier CeTA, based on the Isabelle/HOL formalization of
rewriting IsaFoR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1592</identifier>
 <datestamp>2012-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1592</id><created>2012-08-08</created><updated>2012-12-11</updated><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Improved Perfect Space-Time Block Codes</title><categories>cs.IT math.IT</categories><comments>9 pages, 1 figure, 1 table, a few minor corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The perfect space-time block codes (STBCs) are based on four design criteria
- full-rateness, non-vanishing determinant, cubic shaping and uniform average
transmitted energy per antenna per time slot. Cubic shaping and transmission at
uniform average energy per antenna per time slot are important from the
perspective of energy efficiency of STBCs. The shaping criterion demands that
the {\it generator matrix} of the lattice from which each layer of the perfect
STBC is carved be unitary. In this paper, it is shown that unitariness is not a
necessary requirement for energy efficiency in the context of space-time coding
with finite input constellations, and an alternative criterion is provided that
enables one to obtain full-rate (rate of $n_t$ complex symbols per channel use
for an $n_t$ transmit antenna system) STBCs with larger {\it normalized minimum
determinants} than the perfect STBCs. Further, two such STBCs, one each for 4
and 6 transmit antennas, are presented and they are shown to have larger
normalized minimum determinants than the comparable perfect STBCs which
hitherto had the best known normalized minimum determinants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1593</identifier>
 <datestamp>2013-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1593</id><created>2012-08-08</created><updated>2013-04-23</updated><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Fast-Decodable MIDO Codes with Large Coding Gain</title><categories>cs.IT math.IT</categories><comments>16 pages, 2 figures, 1 table, revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new method is proposed to obtain full-diversity, rate-2
(rate of 2 complex symbols per channel use) space-time block codes (STBCs) that
are full-rate for multiple input, double output (MIDO) systems. Using this
method, rate-2 STBCs for $4\times2$, $6 \times 2$, $8\times2$ and $12 \times 2$
systems are constructed and these STBCs are fast ML-decodable, have large
coding gains, and STBC-schemes consisting of these STBCs have a non-vanishing
determinant (NVD) so that they are DMT-optimal for their respective MIDO
systems. It is also shown that the SR-code [R. Vehkalahti, C. Hollanti, and F.
Oggier, &quot;Fast-Decodable Asymmetric Space-Time Codes from Division Algebras,&quot;
IEEE Trans. Inf. Theory, Apr. 2012] for the $4\times2$ system, which has the
lowest ML-decoding complexity among known rate-2 STBCs for the $4\times2$ MIDO
system with a large coding gain for 4-/16-QAM, has the same algebraic structure
as the STBC constructed in this paper for the $4\times2$ system. This also
settles in positive a previous conjecture that the STBC-scheme that is based on
the SR-code has the NVD property and hence is DMT-optimal for the $4\times2$
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1594</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1594</id><created>2012-08-08</created><authors><author><keyname>Sternagel</keyname><forenames>Christian</forenames></author><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>Certification extends Termination Techniques</title><categories>cs.LO</categories><comments>5 pages, International Workshop on Termination 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are termination proofs that are produced by termination tools for which
certifiers are not powerful enough. However, a similar situation also occurs in
the other direction. We have formalized termination techniques in a more
general setting as they have been introduced. Hence, we can certify proofs
using techniques that no termination tool supports so far. In this paper we
shortly present two of these formalizations: Polynomial orders with negative
constants and Arctic termination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1595</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1595</id><created>2012-08-08</created><authors><author><keyname>Sternagel</keyname><forenames>Christian</forenames></author><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>A Relative Dependency Pair Framework</title><categories>cs.LO</categories><comments>5 pages, International Workshop on Termination 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we generalize the DP framework to a relative DP framework,
where a so called split is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1597</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1597</id><created>2012-08-08</created><authors><author><keyname>Sternagel</keyname><forenames>Thomas</forenames></author><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Zankl</keyname><forenames>Harald</forenames></author><author><keyname>Sternagel</keyname><forenames>Christian</forenames></author></authors><title>Recording Completion for Finding and Certifying Proofs in Equational
  Logic</title><categories>cs.LO</categories><comments>pages 6, International Workshop on Confluence 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When we want to answer/certify whether a given equation is entailed by an
equational system we face the following problems: (1) It is hard to find a
conversion (but easy to certify a given one). (2) Under the assumption that
Knuth-Bendix completion is successful, it is easy to decide the existence of a
conversion but hard to certify this decision. In this paper we introduce
recording completion, which overcomes both problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1609</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1609</id><created>2012-08-08</created><authors><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>Towards the Certification of Complexity Proofs</title><categories>cs.LO</categories><comments>Isabelle Users Workshop 2012, Associated with ITP 2012,
  http://www4.in.tum.de/~nipkow/Isabelle2012/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on our formalization of matrix-interpretation in Isabelle/HOL.
Matrices are required to certify termination proofs and we wish to utilize them
for complexity proofs, too. For the latter aim, only basic methods have already
been integrated, and we discuss some upcoming problems which arise when
formalizing more complicated results on matrix-interpretations, which are based
on Cayley-Hamilton's theorem or joint-spectral radius theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1613</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1613</id><created>2012-08-08</created><authors><author><keyname>Chen</keyname><forenames>Jingchao</forenames></author></authors><title>A Dynamic Phase Selection Strategy for Satisfiability Solvers</title><categories>cs.LO cs.AI</categories><comments>10 pages, 2 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The phase selection is an important of a SAT Solver based on conflict-driven
DPLL. This paper presents a new phase selection strategy, in which the weight
of each literal is defined as the sum of its implied-literals static weights.
The implied literals of each literal is computed dynamically during the search.
Therefore, it is call a dynamic phase selection strategy. In general, computing
dynamically a weight is time-consuming. Hence, so far no SAT solver applies
successfully a dynamic phase selection. Since the implied literal of our
strategy conforms to that of the search process, the usual two watched-literals
scheme can be applied here. Thus, the cost of our dynamic phase selection is
very low. To improve Glucose 2.0 which won a Gold Medal for application
category at SAT 2011 competition, we build five phase selection schemes using
the dynamic phase selection policy. On application instances of SAT 2011,
Glucose improved by the dynamic phase selection is significantly better than
the original Glucose. We conduct also experiments on Lingeling, using the
dynamic phase selection policy, and build two phase selection schemes.
Experimental results show that the improved Lingeling is better than the
original Lingeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1639</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1639</id><created>2012-08-08</created><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames></author><author><keyname>Novotn&#xfd;</keyname><forenames>Petr</forenames></author></authors><title>Determinacy in Stochastic Games with Unbounded Payoff Functions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider infinite-state turn-based stochastic games of two players, Box
and Diamond, who aim at maximizing and minimizing the expected total reward
accumulated along a run, respectively. Since the total accumulated reward is
unbounded, the determinacy of such games cannot be deduced directly from
Martin's determinacy result for Blackwell games. Nevertheless, we show that
these games are determined both for unrestricted (i.e., history-dependent and
randomized) strategies and deterministic strategies, and the equilibrium value
is the same. Further, we show that these games are generally not determined for
memoryless strategies. Then, we consider a subclass of
Diamond-finitely-branching games and show that they are determined for all of
the considered strategy types, where the equilibrium value is always the same.
We also examine the existence and type of (epsilon-)optimal strategies for both
players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1640</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1640</id><created>2012-08-08</created><authors><author><keyname>Dittmann</keyname><forenames>Christoph</forenames></author><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author><author><keyname>Tomescu</keyname><forenames>Alexandru I.</forenames></author></authors><title>Graph Operations on Parity Games and Polynomial-Time Algorithms</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parity games are games that are played on directed graphs whose vertices are
labeled by natural numbers, called priorities. The players push a token along
the edges of the digraph. The winner is determined by the parity of the
greatest priority occurring infinitely often in this infinite play.
  A motivation for studying parity games comes from the area of formal
verification of systems by model checking. Deciding the winner in a parity game
is polynomial time equivalent to the model checking problem of the modal
mu-calculus. Another strong motivation lies in the fact that the exact
complexity of solving parity games is a long-standing open problem, the
currently best known algorithm being subexponential. It is known that the
problem is in the complexity classes UP and coUP.
  In this paper we identify restricted classes of digraphs where the problem is
solvable in polynomial time, following an approach from structural graph
theory. We consider three standard graph operations: the join of two graphs,
repeated pasting along vertices, and the addition of a vertex. Given a class C
of digraphs on which we can solve parity games in polynomial time, we show that
the same holds for the class obtained from C by applying once any of these
three operations to its elements.
  These results provide, in particular, polynomial time algorithms for parity
games whose underlying graph is an orientation of a complete graph, a complete
bipartite graph, a block graph, or a block-cactus graph. These are classes
where the problem was not known to be efficiently solvable.
  Previous results concerning restricted classes of parity games which are
solvable in polynomial time include classes of bounded tree-width, bounded
DAG-width, and bounded clique-width.
  We also prove that recognising the winning regions of a parity game is not
easier than computing them from scratch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1649</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1649</id><created>2012-08-08</created><authors><author><keyname>Martin</keyname><forenames>James</forenames></author></authors><title>Berlekamp's Switching Game on Finite Projective and Affine Planes</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I adapt Berlekamp's light bulb switching game to finite projective plans and
finite affine planes, then find the worst arrangement of lit bulbs for planes
of even and odd orders. The results are then extended from the planes to spaces
of higher dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1661</identifier>
 <datestamp>2013-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1661</id><created>2012-08-08</created><updated>2013-01-27</updated><authors><author><keyname>Skowron</keyname><forenames>Piotr</forenames></author><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Slinko</keyname><forenames>Arkadii</forenames></author></authors><title>Fully Proportional Representation as Resource Allocation:
  Approximability Results</title><categories>cs.GT cs.MA</categories><comments>26 pages, 1 figure</comments><msc-class>68Q17</msc-class><acm-class>I.2.11; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model Monroe's and Chamberlin and Courant's multiwinner voting systems as
a certain resource allocation problem. We show that for many restricted
variants of this problem, under standard complexity-theoretic assumptions,
there are no constant-factor approximation algorithms. Yet, we also show cases
where good approximation algorithms exist (briefly put, these variants
correspond to optimizing total voter satisfaction under Borda scores, within
Monroe's and Chamberlin and Courant's voting systems).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1670</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1670</id><created>2012-08-08</created><authors><author><keyname>Ramakrishnan</keyname><forenames>Josphineleela</forenames></author><author><keyname>Malaisamy</keyname><forenames>Ramakrishnan</forenames></author></authors><title>Performance Measurement and Method Analysis (PMMA) for Fingerprint
  Reconstruction</title><categories>cs.CV</categories><comments>4pages,1 figure,1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fingerprint reconstruction is one of the most well-known and publicized
biometrics. Because of their uniqueness and consistency over time, fingerprints
have been used for identification over a century, more recently becoming
automated due to advancements in computed capabilities. Fingerprint
reconstruction is popular because of the inherent ease of acquisition, the
numerous sources (e.g. ten fingers) available for collection, and their
established use and collections by law enforcement and immigration.
Fingerprints have always been the most practical and positive means of
identification. Offenders, being well aware of this, have been coming up with
ways to escape identification by that means. Erasing left over fingerprints,
using gloves, fingerprint forgery; are certain examples of methods tried by
them, over the years. Failing to prevent themselves, they moved to an extent of
mutilating their finger skin pattern, to remain unidentified. This article is
based upon obliteration of finger ridge patterns and discusses some known cases
in relation to the same, in chronological order; highlighting the reasons why
offenders go to an extent of performing such act. The paper gives an overview
of different methods and performance measurement of the fingerprint
reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1672</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1672</id><created>2012-08-08</created><authors><author><keyname>Ramakrishnan</keyname><forenames>Josphineleela</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>M.</forenames></author></authors><title>An Efficient Automatic Attendance System Using Fingerprint
  Reconstruction Technique</title><categories>cs.CV</categories><comments>6pages,5figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometric time and attendance system is one of the most successful
applications of biometric technology. One of the main advantage of a biometric
time and attendance system is it avoids &quot;buddy-punching&quot;. Buddy punching was a
major loophole which will be exploiting in the traditional time attendance
systems. Fingerprint recognition is an established field today, but still
identifying individual from a set of enrolled fingerprints is a time taking
process. Most fingerprint-based biometric systems store the minutiae template
of a user in the database. It has been traditionally assumed that the minutiae
template of a user does not reveal any information about the original
fingerprint. This belief has now been shown to be false; several algorithms
have been proposed that can reconstruct fingerprint images from minutiae
templates. In this paper, a novel fingerprint reconstruction algorithm is
proposed to reconstruct the phase image, which is then converted into the
grayscale image. The proposed reconstruction algorithm reconstructs the phase
image from minutiae. The proposed reconstruction algorithm is used to automate
the whole process of taking attendance, manually which is a laborious and
troublesome work and waste a lot of time, with its managing and maintaining the
records for a period of time is also a burdensome task. The proposed
reconstruction algorithm has been evaluated with respect to the success rates
of type-I attack (match the reconstructed fingerprint against the original
fingerprint) and type-II attack (match the reconstructed fingerprint against
different impressions of the original fingerprint) using a commercial
fingerprint recognition system. Given the reconstructed image from our
algorithm, we show that both types of attacks can be effectively launched
against a fingerprint recognition system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1676</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1676</id><created>2012-08-08</created><authors><author><keyname>Nath</keyname><forenames>Swaprava</forenames></author><author><keyname>Dayama</keyname><forenames>Pankaj</forenames></author><author><keyname>Garg</keyname><forenames>Dinesh</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author><author><keyname>Zou</keyname><forenames>James</forenames></author></authors><title>Mechanism Design for Time Critical and Cost Critical Task Execution via
  Crowdsourcing</title><categories>cs.GT cs.MA</categories><comments>17 pages, 2 figures, submitted to WINE 2012</comments><acm-class>I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An exciting application of crowdsourcing is to use social networks in complex
task execution. In this paper, we address the problem of a planner who needs to
incentivize agents within a network in order to seek their help in executing an
{\em atomic task} as well as in recruiting other agents to execute the task. We
study this mechanism design problem under two natural resource optimization
settings: (1) cost critical tasks, where the planner's goal is to minimize the
total cost, and (2) time critical tasks, where the goal is to minimize the
total time elapsed before the task is executed. We identify a set of desirable
properties that should ideally be satisfied by a crowdsourcing mechanism. In
particular, {\em sybil-proofness} and {\em collapse-proofness} are two
complementary properties in our desiderata. We prove that no mechanism can
satisfy all the desirable properties simultaneously. This leads us naturally to
explore approximate versions of the critical properties. We focus our attention
on approximate sybil-proofness and our exploration leads to a parametrized
family of payment mechanisms which satisfy collapse-proofness. We characterize
the approximate versions of the desirable properties in cost critical and time
critical domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1679</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1679</id><created>2012-08-06</created><authors><author><keyname>Wu</keyname><forenames>Ou</forenames></author></authors><title>Color Assessment and Transfer for Web Pages</title><categories>cs.HC cs.CV cs.GR</categories><comments>10pages</comments><acm-class>H.4.m; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colors play a particularly important role in both designing and accessing Web
pages. A well-designed color scheme improves Web pages' visual aesthetic and
facilitates user interactions. As far as we know, existing color assessment
studies focus on images; studies on color assessment and editing for Web pages
are rare. This paper investigates color assessment for Web pages based on
existing online color theme-rating data sets and applies this assessment to Web
color edit. This study consists of three parts. First, we study the extraction
of a Web page's color theme. Second, we construct color assessment models that
score the color compatibility of a Web page by leveraging machine learning
techniques. Third, we incorporate the learned color assessment model into a new
application, namely, color transfer for Web pages. Our study combines
techniques from computer graphics, Web mining, computer vision, and machine
learning. Experimental results suggest that our constructed color assessment
models are effective, and useful in the color transfer for Web pages, which has
received little attention in both Web mining and computer graphics communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1688</identifier>
 <datestamp>2012-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1688</id><created>2012-08-08</created><updated>2012-08-17</updated><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Ordyniak</keyname><forenames>Sebastian</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Don't Be Strict in Local Search!</title><categories>cs.DS</categories><comments>(author's self-archived copy)</comments><journal-ref>Proc. AAAI'12, pp. 486-492 (AAAI Press 2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Local Search is one of the fundamental approaches to combinatorial
optimization and it is used throughout AI. Several local search algorithms are
based on searching the k-exchange neighborhood. This is the set of solutions
that can be obtained from the current solution by exchanging at most k
elements. As a rule of thumb, the larger k is, the better are the chances of
finding an improved solution. However, for inputs of size n, a na\&quot;ive
brute-force search of the k-exchange neighborhood requires n to the power of
O(k) time, which is not practical even for very small values of k.
  Fellows et al. (IJCAI 2009) studied whether this brute-force search is
avoidable and gave positive and negative answers for several combinatorial
problems. They used the notion of local search in a strict sense. That is, an
improved solution needs to be found in the k-exchange neighborhood even if a
global optimum can be found efficiently.
  In this paper we consider a natural relaxation of local search, called
permissive local search (Marx and Schlotter, IWPEC 2009) and investigate
whether it enhances the domain of tractable inputs. We exemplify this approach
on a fundamental combinatorial problem, Vertex Cover. More precisely, we show
that for a class of inputs, finding an optimum is hard, strict local search is
hard, but permissive local search is tractable.
  We carry out this investigation in the framework of parameterized complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1692</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1692</id><created>2012-08-08</created><updated>2012-08-10</updated><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author><author><keyname>Liedloff</keyname><forenames>Mathieu</forenames></author><author><keyname>Ordyniak</keyname><forenames>Sebastian</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>On Finding Optimal Polytrees</title><categories>cs.DS cs.AI cs.CC</categories><comments>(author's self-archived copy)</comments><journal-ref>Proc. AAAI'12, pp. 750-756 (AAAI Press 2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring probabilistic networks from data is a notoriously difficult task.
Under various goodness-of-fit measures, finding an optimal network is NP-hard,
even if restricted to polytrees of bounded in-degree. Polynomial-time
algorithms are known only for rare special cases, perhaps most notably for
branchings, that is, polytrees in which the in-degree of every node is at most
one. Here, we study the complexity of finding an optimal polytree that can be
turned into a branching by deleting some number of arcs or nodes, treated as a
parameter.
  We show that the problem can be solved via a matroid intersection formulation
in polynomial time if the number of deleted arcs is bounded by a constant. The
order of the polynomial time bound depends on this constant, hence the
algorithm does not establish fixed-parameter tractability when parameterized by
the number of deleted arcs. We show that a restricted version of the problem
allows fixed-parameter tractability and hence scales well with the parameter.
We contrast this positive result by showing that if we parameterize by the
number of deleted nodes, a somewhat more powerful parameter, the problem is not
fixed-parameter tractable, subject to a complexity-theoretic assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1697</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1697</id><created>2012-08-08</created><updated>2012-12-28</updated><authors><author><keyname>Dai</keyname><forenames>Bin</forenames></author><author><keyname>Vinck</keyname><forenames>A. J. Han</forenames></author><author><keyname>Zhuang</keyname><forenames>Zhuojun</forenames></author><author><keyname>Luo</keyname><forenames>Yuan</forenames></author></authors><title>Information-Theoretical Security for Several Models of Multiple-Access
  Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory. arXiv admin note:
  text overlap with arXiv:1201.2859</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several security models of multiple-access channel (MAC) are investigated.
First, we study the degraded MAC with confidential messages, where two users
transmit their confidential messages (no common message) to a destination, and
each user obtains a degraded version of the output of the MAC. Each user views
the other user as a eavesdropper, and wishes to keep its confidential message
as secret as possible from the other user. Measuring each user's uncertainty
about the other user's confidential message by equivocation, the inner and
outer bounds on the capacity-equivocation region for this model have been
provided. The result is further explained via the binary and Gaussian examples.
  Second, the discrete memoryless multiple-access wiretap channel (MAC-WT) is
studied, where two users transmit their corresponding confidential messages (no
common message) to a legitimate receiver, while an additional wiretapper wishes
to obtain the messages via a wiretap channel. This new model is considered into
two cases: the general MAC-WT with cooperative encoders, and the degraded
MAC-WT with non-cooperative encoders. The capacity-equivocation region is
totally determined for the cooperative case, and inner and outer bounds on the
capacity-equivocation region are provided for the non-cooperative case. For
both cases, the results are further explained via the binary examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1712</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1712</id><created>2012-08-08</created><authors><author><keyname>H</keyname><forenames>radeep B.</forenames></author><author><keyname>Singh</keyname><forenames>Sanjay</forenames></author></authors><title>Ownership Authentication Transfer Protocol for Ubiquitous Computing
  Devices</title><categories>cs.CR</categories><comments>12 pages, 4 figures, submitted to the second world congress on
  information and communication technology (WICT 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In ubiquitous computing devices, users tend to store some valuable
information in their device. Even though the device can be borrowed by the
other user temporarily, it is not safe for any user to borrow or lend the
device as it may result the private data of the user to be public. To safeguard
the user data and also to preserve user privacy we propose the technique of
ownership authentication transfer. The user who is willing to sell the device
has to transfer the ownership of the device under sale. Once the device is sold
and the ownership has been transferred, the old owner will not be able to use
that device at any cost. Either of the users will not be able to use the device
if the process of ownership has not been carried out properly. This also takes
care of the scenario when the device has been stolen or lost, avoiding the
impersonation attack. The proposed protocol has been modeled and verified using
Automated Validation of Internet Security Protocols and Applications (AVISPA)
and is found to be safe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1718</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1718</id><created>2012-08-08</created><updated>2013-11-18</updated><authors><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author><author><keyname>Turrini</keyname><forenames>Paolo</forenames></author></authors><title>Non-cooperative games with preplay negotiations</title><categories>cs.GT</categories><comments>40pages, under submission</comments><msc-class>91A05, 91A06, 91A10, 91A18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an extension of strategic normal form games with a phase of
negotiations before the actual play of the game, where players can make binding
offers for transfer of utilities to other players after the play of the game,
in order to provide additional incentives for each other to play designated
strategies. Such offers are conditional on the recipients playing the specified
strategies and they effect transformations of the payoff matrix of the game by
accordingly transferring payoffs between players. We introduce and analyze
solution concepts for 2-player normal form games with such preplay offers under
various assumptions for the preplay negotiation phase and obtain results for
existence of efficient negotiation strategies of the players. Then we extend
the framework to coalitional preplay offers in N-player games, as well as to
extensive form games with inter-play offers for side payments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1723</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1723</id><created>2012-08-08</created><authors><author><keyname>Pareek</keyname><forenames>Abhijeet</forenames></author><author><keyname>Woelfel</keyname><forenames>Philipp</forenames></author></authors><title>RMR-Efficient Randomized Abortable Mutual Exclusion</title><categories>cs.DC cs.DS</categories><comments>Extended abstract will appear at DISC 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research on mutual exclusion for shared-memory systems has focused on
&quot;local spin&quot; algorithms. Performance is measured using the &quot;remote memory
references&quot; (RMRs) metric. As common in recent literature, we consider a
standard asynchronous shared memory model with N processes, which allows atomic
read, write and compare-and-swap (short: CAS) operations.
  In such a model, the asymptotically tight upper and lower bound on the number
of RMRs per passage through the Critical Section is Theta(log N) for the
optimal deterministic algorithms (see Yang and Anderson,1995, and Attiya,
Hendler and Woelfel, 2008). Recently, several randomized algorithms have been
devised that break the Omega(log N) barrier and need only o(log N) RMRs per
passage in expectation (see Hendler and Woelfel, 2010, Hendler and Woelfel,
2011, and Bender and Gilbert, 2011). In this paper we present the first
randomized &quot;abortable&quot; mutual exclusion algorithm that achieves a
sub-logarithmic expected RMR complexity. More precisely, against a weak
adversary (which can make scheduling decisions based on the entire past
history, but not the latest coin-flips of each process) every process needs an
expected number of O(log N/ log log N) RMRs to enter end exit the critical
section. If a process receives an abort-signal, it can abort an attempt to
enter the critical section within a finite number of its own steps and by
incurring O(log N/ log log N) RMRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1740</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1740</id><created>2012-08-08</created><authors><author><keyname>Noori</keyname><forenames>Amir</forenames></author></authors><title>On the Relation between Centrality Measures and Consensus Algorithms</title><categories>cs.SY cs.SI math.OC</categories><comments>2011 International Conference on High Performance Computing and
  Simulation (HPCS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces some tools from graph theory and distributed consensus
algorithms to construct an optimal, yet robust, hierarchical information
sharing structure for large-scale decision making and control problems. The
proposed method is motivated by the robustness and optimality of leaf-venation
patterns. We introduce a new class of centrality measures which are built based
on the degree distribution of nodes within network graph. Furthermore, the
proposed measure is used to select the appropriate weight of the corresponding
consensus algorithm. To this end, an implicit hierarchical structure is derived
that control the flow of information in different situations. In addition, the
performance analysis of the proposed measure with respect to other standard
measures is performed to investigate the convergence and asymptotic behavior of
the measure. Gas Transmission Network is served as our test-bed to demonstrate
the applicability and the efficiently of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1743</identifier>
 <datestamp>2012-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1743</id><created>2012-08-08</created><updated>2012-09-28</updated><authors><author><keyname>Noori</keyname><forenames>Amir</forenames></author><author><keyname>Menhaj</keyname><forenames>Mohammad Bagher</forenames></author><author><keyname>Shafiee</keyname><forenames>Masoud</forenames></author></authors><title>Hybrid systems modeling for gas transmission network</title><categories>cs.AI</categories><comments>This paper has been withdrawn by the author due to a crucial citation
  error in introduction section</comments><journal-ref>The 4th IFAC Conference on Management and Control of Production
  and Logistics, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gas Transmission Networks are large-scale complex systems, and corresponding
design and control problems are challenging. In this paper, we consider the
problem of control and management of these systems in crisis situations. We
present these networks by a hybrid systems framework that provides required
analysis models. Further, we discuss decision-making using computational
discrete and hybrid optimization methods. In particular, several reinforcement
learning methods are employed to explore decision space and achieve the best
policy in a specific crisis situation. Simulations are presented to illustrate
the efficiency of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1750</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1750</id><created>2012-08-08</created><authors><author><keyname>Pittet</keyname><forenames>Perrine</forenames><affiliation>Le2i</affiliation></author><author><keyname>Nicolle</keyname><forenames>Christophe</forenames><affiliation>Le2i</affiliation></author><author><keyname>Cruz</keyname><forenames>Christophe</forenames><affiliation>Le2i</affiliation></author></authors><title>Guidelines for a Dynamic Ontology - Integrating Tools of Evolution and
  Versioning in Ontology</title><categories>cs.SE cs.AI</categories><proxy>ccsd</proxy><journal-ref>KMIS 2011 - International Conference on Knowledge Management and
  Information Sharing is part of 3rd International Joint Conference on
  Knowledge Discovery, Knowledge Engineering and Knowledge Management., Paris :
  France (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontologies are built on systems that conceptually evolve over time. In
addition, techniques and languages for building ontologies evolve too. This has
led to numerous studies in the field of ontology versioning and ontology
evolution. This paper presents a new way to manage the lifecycle of an ontology
incorporating both versioning tools and evolution process. This solution,
called VersionGraph, is integrated in the source ontology since its creation in
order to make it possible to evolve and to be versioned. Change management is
strongly related to the model in which the ontology is represented. Therefore,
we focus on the OWL language in order to take into account the impact of the
changes on the logical consistency of the ontology like specified in OWL DL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1758</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1758</id><created>2012-08-08</created><authors><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author></authors><title>Transformations of normal form games by preplay offers for payments
  among players</title><categories>cs.GT</categories><comments>17 pages, under submission</comments><msc-class>91A05, 91A06, 91A10</msc-class><acm-class>I.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider transformations of normal form games by binding preplay offers of
players for payments of utility to other players conditional on them playing
designated in the offers strategies. The game-theoretic effect of such preplay
offers is transformation of the payoff matrix of the game by transferring
payoffs between players. Here we analyze and completely characterize the
possible transformations of the payoff matrix of a normal form game by sets of
preplay offers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1774</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1774</id><created>2012-08-08</created><authors><author><keyname>Litinskii</keyname><forenames>L. B.</forenames></author><author><keyname>Kryzhanovsky</keyname><forenames>B. V.</forenames></author><author><keyname>Fonarev</keyname><forenames>A.</forenames></author></authors><title>Operator formalism for optical neural network based on the parametrical
  four-wave mixing process</title><categories>cs.ET cond-mat.dis-nn</categories><comments>5 pages,without figures</comments><msc-class>60, 94</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a formalism allowing us to describe operating of a
network based on the parametrical four-wave mixing process that is well-known
in nonlinear optics. The recognition power of a network using parametric
neurons operating with q different frequencies is considered. It is shown that
the storage capacity of such a network is higher compared with the Potts-glass
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1783</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1783</id><created>2012-08-08</created><updated>2014-05-29</updated><authors><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author><author><keyname>McQuillan</keyname><forenames>Colin</forenames></author><author><keyname>Richerby</keyname><forenames>David</forenames></author></authors><title>The complexity of approximating conservative counting CSPs</title><categories>cs.CC</categories><comments>Minor revision</comments><doi>10.1016/j.jcss.2014.06.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of approximately solving the weighted counting
constraint satisfaction problem #CSP(F). In the conservative case, where F
contains all unary functions, there is a classification known for the case in
which the domain of functions in F is Boolean. In this paper, we give a
classification for the more general problem where functions in F have an
arbitrary finite domain. We define the notions of weak log-modularity and weak
log-supermodularity. We show that if F is weakly log-modular, then #CSP(F)is in
FP. Otherwise, it is at least as difficult to approximate as #BIS, the problem
of counting independent sets in bipartite graphs. #BIS is complete with respect
to approximation-preserving reductions for a logically-defined complexity class
#RHPi1, and is believed to be intractable. We further sub-divide the #BIS-hard
case. If F is weakly log-supermodular, then we show that #CSP(F) is as easy as
a (Boolean) log-supermodular weighted #CSP. Otherwise, we show that it is
NP-hard to approximate. Finally, we give a full trichotomy for the arity-2
case, where #CSP(F) is in FP, or is #BIS-equivalent, or is equivalent in
difficulty to #SAT, the problem of approximately counting the satisfying
assignments of a Boolean formula in conjunctive normal form. We also discuss
the algorithmic aspects of our classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1784</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1784</id><created>2012-08-08</created><authors><author><keyname>Shomorony</keyname><forenames>Ilan</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Worst-Case Source for Distributed Compression with Quadratic Distortion</title><categories>cs.IT math.IT</categories><comments>To be presented at the IEEE Information Theory Workshop (ITW) 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the k-encoder source coding problem with a quadratic distortion
measure. We show that among all source distributions with a given covariance
matrix K, the jointly Gaussian source requires the highest rates in order to
meet a given set of distortion constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1793</identifier>
 <datestamp>2013-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1793</id><created>2012-08-08</created><updated>2013-08-02</updated><authors><author><keyname>Xu</keyname><forenames>Xiaohua</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Song</keyname><forenames>Min</forenames></author></authors><title>Real-time Data Collection Scheduling in Multi-hop Wireless Sensor
  Networks</title><categories>cs.DC</categories><comments>7 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We study real time periodic query scheduling for data collection in multihop
Wireless Sensor Networks (WSNs). Given a set of heterogenous data collection
queries in WSNs, each query requires the data from the source sensor nodes to
be collected to the control center within a certain end-to-end delay. We first
propose almost-tight necessary conditions for a set of different queries to be
schedulable by a WSN. We then develop a family of efficient and effective data
collection algorithms that can meet the real-time requirement under resource
constraints by addressing three tightly coupled tasks: (1) routing tree
construction for data collection, (2) link activity scheduling, and (3)
packet-level scheduling. Our theoretical analysis for the schedulability of
these algorithms show that they can achieve a constant fraction of the maximum
schedulable load. For the case of overloaded networks where not all queries can
be possibly satisfied, we propose an efficient approximation algorithm to
select queries to maximize the total weight of selected schedulable queries.
The simulations corroborate our theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1794</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1794</id><created>2012-08-08</created><authors><author><keyname>Frankie</keyname><forenames>Tasha</forenames></author><author><keyname>Hughes</keyname><forenames>Gordon</forenames></author><author><keyname>Kreutz-Delgado</keyname><forenames>Ken</forenames></author></authors><title>Analysis of Trim Commands on Overprovisioning and Write Amplification in
  Solid State Drives</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a performance model of the ATA/ATAPI SSD Trim command
under various types of user workloads, including a uniform random workload, a
workload with hot and cold data, and a workload with N temperatures of data. We
first examine the Trim-modified uniform random workload to predict utilization,
then use this result to compute the resultant level of effective
overprovisioning. This allows modification of models previously suggested to
predict write amplification of a non-Trim uniform random workload under greedy
garbage collection. Finally, we expand the theory to cover a workload
consisting of hot and cold data (and also N temperatures of data), providing
formulas to predict write amplification in these scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1819</identifier>
 <datestamp>2014-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1819</id><created>2012-08-09</created><authors><author><keyname>Sarlin</keyname><forenames>Peter</forenames></author></authors><title>Self-Organizing Time Map: An Abstraction of Temporal Multivariate
  Patterns</title><categories>cs.LG cs.DS</categories><journal-ref>Neurocomputing 99(1) (2013), pp. 496-508</journal-ref><doi>10.1016/j.neucom.2012.07.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper adopts and adapts Kohonen's standard Self-Organizing Map (SOM) for
exploratory temporal structure analysis. The Self-Organizing Time Map (SOTM)
implements SOM-type learning to one-dimensional arrays for individual time
units, preserves the orientation with short-term memory and arranges the arrays
in an ascending order of time. The two-dimensional representation of the SOTM
attempts thus twofold topology preservation, where the horizontal direction
preserves time topology and the vertical direction data topology. This enables
discovering the occurrence and exploring the properties of temporal structural
changes in data. For representing qualities and properties of SOTMs, we adapt
measures and visualizations from the standard SOM paradigm, as well as
introduce a measure of temporal structural changes. The functioning of the
SOTM, and its visualizations and quality and property measures, are illustrated
on artificial toy data. The usefulness of the SOTM in a real-world setting is
shown on poverty, welfare and development indicators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1829</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1829</id><created>2012-08-09</created><authors><author><keyname>Qian</keyname><forenames>Qiang</forenames></author><author><keyname>Chen</keyname><forenames>Songcan</forenames></author></authors><title>Metric Learning across Heterogeneous Domains by Respectively Aligning
  Both Priors and Posteriors</title><categories>cs.LG</categories><comments>19 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we attempts to learn a single metric across two heterogeneous
domains where source domain is fully labeled and has many samples while target
domain has only a few labeled samples but abundant unlabeled samples. To the
best of our knowledge, this task is seldom touched. The proposed learning model
has a simple underlying motivation: all the samples in both the source and the
target domains are mapped into a common space, where both their priors
P(sample)s and their posteriors P(label|sample)s are forced to be respectively
aligned as much as possible. We show that the two mappings, from both the
source domain and the target domain to the common space, can be reparameterized
into a single positive semi-definite(PSD) matrix. Then we develop an efficient
Bregman Projection algorithm to optimize the PDS matrix over which a LogDet
function is used to regularize. Furthermore, we also show that this model can
be easily kernelized and verify its effectiveness in crosslanguage retrieval
task and cross-domain object recognition task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1842</identifier>
 <datestamp>2013-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1842</id><created>2012-08-09</created><updated>2013-01-31</updated><authors><author><keyname>Kramer</keyname><forenames>Simon</forenames></author></authors><title>Logic of Non-Monotonic Interactive Proofs (Formal Theory of Temporary
  Knowledge Transfer)</title><categories>cs.LO cs.CR cs.DC cs.MA math.LO</categories><comments>continuation of arXiv:1201.3667 ; published extended abstract:
  DOI:10.1007/978-3-642-36039-8_16 ; related to arXiv:1208.5913</comments><doi>10.1007/978-3-642-36039-8_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a monotonic logic of internalised non-monotonic or instant
interactive proofs (LiiP) and reconstruct an existing monotonic logic of
internalised monotonic or persistent interactive proofs (LiP) as a minimal
conservative extension of LiiP. Instant interactive proofs effect a fragile
epistemic impact in their intended communities of peer reviewers that consists
in the impermanent induction of the knowledge of their proof goal by means of
the knowledge of the proof with the interpreting reviewer: If my peer reviewer
knew my proof then she would at least then (in that instant) know that its
proof goal is true. Their impact is fragile and their induction of knowledge
impermanent in the sense of being the case possibly only at the instant of
learning the proof. This accounts for the important possibility of
internalising proofs of statements whose truth value can vary, which, as
opposed to invariant statements, cannot have persistent proofs. So instant
interactive proofs effect a temporary transfer of certain propositional
knowledge (knowable ephemeral facts) via the transmission of certain individual
knowledge (knowable non-monotonic proofs) in distributed systems of multiple
interacting agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1846</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1846</id><created>2012-08-09</created><authors><author><keyname>Guo</keyname><forenames>Guangxu</forenames></author><author><keyname>Chen</keyname><forenames>Songcan</forenames></author></authors><title>Margin Distribution Controlled Boosting</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schapire's margin theory provides a theoretical explanation to the success of
boosting-type methods and manifests that a good margin distribution (MD) of
training samples is essential for generalization. However the statement that a
MD is good is vague, consequently, many recently developed algorithms try to
generate a MD in their goodness senses for boosting generalization. Unlike
their indirect control over MD, in this paper, we propose an alternative
boosting algorithm termed Margin distribution Controlled Boosting (MCBoost)
which directly controls the MD by introducing and optimizing a key adjustable
margin parameter. MCBoost's optimization implementation adopts the column
generation technique to ensure fast convergence and small number of weak
classifiers involved in the final MCBooster. We empirically demonstrate: 1)
AdaBoost is actually also a MD controlled algorithm and its iteration number
acts as a parameter controlling the distribution and 2) the generalization
performance of MCBoost evaluated on UCI benchmark datasets is validated better
than those of AdaBoost, L2Boost, LPBoost, AdaBoost-CG and MDBoost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1860</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1860</id><created>2012-08-09</created><authors><author><keyname>Negahban</keyname><forenames>Sahand</forenames></author><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Gemmell</keyname><forenames>Jim</forenames></author></authors><title>Scaling Multiple-Source Entity Resolution using Statistically Efficient
  Transfer Learning</title><categories>cs.DB cs.LG</categories><comments>Short version to appear in CIKM'2012; 10 pages, 7 figures</comments><acm-class>H.2; I.2.6; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a serious, previously-unexplored challenge facing almost all
approaches to scaling up entity resolution (ER) to multiple data sources: the
prohibitive cost of labeling training data for supervised learning of
similarity scores for each pair of sources. While there exists a rich
literature describing almost all aspects of pairwise ER, this new challenge is
arising now due to the unprecedented ability to acquire and store data from
online sources, features driven by ER such as enriched search verticals, and
the uniqueness of noisy and missing data characteristics for each source. We
show on real-world and synthetic data that for state-of-the-art techniques, the
reality of heterogeneous sources means that the number of labeled training data
must scale quadratically in the number of sources, just to maintain constant
precision/recall. We address this challenge with a brand new transfer learning
algorithm which requires far less training data (or equivalently, achieves
superior accuracy with the same data) and is trained using fast convex
optimization. The intuition behind our approach is to adaptively share
structure learned about one scoring problem with all other scoring problems
sharing a data source in common. We demonstrate that our theoretically
motivated approach incurs no runtime cost while it can maintain constant
precision/recall with the cost of labeling increasing only linearly with the
number of sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1878</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1878</id><created>2012-08-09</created><updated>2013-10-27</updated><authors><author><keyname>Wang</keyname><forenames>Qi</forenames></author><author><keyname>Zhou</keyname><forenames>Yue</forenames></author></authors><title>Sets of Zero-Difference Balanced Functions and Their Applications</title><categories>cs.IT math.CO math.IT</categories><comments>20 pages</comments><msc-class>05B10, 94A55</msc-class><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zero-difference balanced (ZDB) functions can be employed in many
applications, e.g., optimal constant composition codes, optimal and perfect
difference systems of sets, optimal frequency hopping sequences, etc. In this
paper, two results are summarized to characterize ZDB functions, among which a
lower bound is used to achieve optimality in applications and determine the
size of preimage sets of ZDB functions. As the main contribution, a generic
construction of ZDB functions is presented, and many new classes of ZDB
functions can be generated. This construction is then extended to construct a
set of ZDB functions, in which any two ZDB functions are related uniformly.
Furthermore, some applications of such sets of ZDB functions are also
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1880</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1880</id><created>2012-08-09</created><authors><author><keyname>Rao</keyname><forenames>Supreeth K.</forenames><affiliation>BMS College of Engineering, Bangalore, India</affiliation></author><author><keyname>B.</keyname><forenames>Arpitha Prasad</forenames><affiliation>BMS College of Engineering, Bangalore, India</affiliation></author><author><keyname>Shetty</keyname><forenames>Anushree R.</forenames><affiliation>BMS College of Engineering, Bangalore, India</affiliation></author><author><keyname>Chinmai</keyname><affiliation>BMS College of Engineering, Bangalore, India</affiliation></author><author><keyname>Bhakthavathsalam</keyname><forenames>R.</forenames><affiliation>Indian Institute of Science, Bangalore, India</affiliation></author><author><keyname>Hegde</keyname><forenames>Rajeshwari</forenames><affiliation>BMS College of Engineering, Bangalore, India</affiliation></author></authors><title>Stereo Acoustic Perception based on Real Time Video Acquisition for
  Navigational Assistance</title><categories>cs.CV cs.MM cs.SD</categories><comments>12 pages, 8 figures, 1 table, SIPM-2012, pp. 97-108, 2012;
  http://airccj.org/CSCP/vol2/csit2311.pdf</comments><doi>10.5121/csit.2012.2311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A smart navigation system (an Electronic Travel Aid) based on an object
detection mechanism has been designed to detect the presence of obstacles that
immediately impede the path, by means of real time video processing. The
algorithm can be used for any general purpose navigational aid. This paper is
discussed, keeping in mind the navigation of the visually impaired, and is not
limited to the same. A video camera feeds images of the surroundings to a Da-
Vinci Digital Media Processor, DM642, which works on the video, frame by frame.
The processor carries out image processing techniques whose result contains
information about the object in terms of image pixels. The algorithm aims to
select the object which, among all others, poses maximum threat to the
navigation. A database containing a total of three sounds is constructed.
Hence, each image translates to a beep, where every beep informs the navigator
of the obstacles directly in front of him. This paper implements an algorithm
that is more efficient as compared to its predecessors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1885</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1885</id><created>2012-08-09</created><authors><author><keyname>Abdullah</keyname><forenames>Mohammad Waris</forenames></author><author><keyname>Waheed</keyname><forenames>Nazar</forenames></author></authors><title>Performance and Detection of M-ary Frequency Shift Keying in Triple
  Layer Wireless Sensor Network</title><categories>cs.IT math.IT</categories><comments>13 pages; International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.4, No.4, July 2012</comments><doi>10.5121/ijcnc.2012.4411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an innovative triple layer Wireless Sensor Network (WSN)
system, which monitors M-ary events like temperature, pressure, humidity, etc.
with the help of geographically distributed sensors. The sensors convey signals
to the fusion centre using M-ary Frequency Shift Keying (MFSK)modulation scheme
over independent Rayleigh fading channels. At the fusion centre, detection
takes place with the help of Selection Combining (SC) diversity scheme, which
assures a simple and economical receiver circuitry. With the aid of various
simulations, the performance and efficacy of the system has been analyzed by
varying modulation levels, number of local sensors and probability of correct
detection by the sensors. The study endeavors to prove that triple layer WSN
system is an economical and dependable system capable of correct detection of
M-ary events by integrating frequency diversity together with antenna
diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1886</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1886</id><created>2012-08-09</created><authors><author><keyname>Anantharangachar</keyname><forenames>Raghu</forenames></author><author><keyname>Srinivasan</keyname><forenames>Ramani</forenames></author></authors><title>Semantic Web Techniques for Yellow Page Service Providers</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Use of web pages providing unstructured information poses variety of problems
to the user, such as use of arbitrary formats, unsuitability for machine
processing and likely incompleteness of information. Structured data alleviates
these problems but we require more. Very often yellow page systems are
implemented using a centralized database. In some cases, human intermediaries
accessible over the phone network examine a centralized database and use their
reasoning ability to deal with the user's need for information. Scaling up such
systems is difficult. This paper explores an alternative - a highly distributed
system design meeting a variety of needs - considerably reducing efforts
required at a central organization, enabling large numbers of vendors to enter
information about their own products and services, enabling end-users to
contribute information such as their own ratings, using an ontology to describe
each domain of application in a flexible manner for uses foreseen and
unforeseen, enabling distributed search and mash-ups, use of vendor independent
standards, using reasoning to find the best matches to a given query,
geo-spatial reasoning and a simple, interactive, mobile application/interface.
We give importance to geo-spatial information and mobile applications because
of the very wide-spread use of mobile phones and their inherent ability to
provide some information about the current location of the user. We have
created a prototype using the Jena Toolkit and geo-spatial extensions to
SPARQL. We have tested this prototype by asking a group of typical users to use
it and to provide structured feedback. We have summarized this feedback in the
paper. We believe that the technology can be applied in many contexts in
addition to yellow page systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1896</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1896</id><created>2012-08-09</created><authors><author><keyname>Hoong</keyname><forenames>Poo Kuan</forenames></author><author><keyname>Tan</keyname><forenames>Ian K. T.</forenames></author><author><keyname>Keong</keyname><forenames>Chee Yik</forenames></author></authors><title>Bittorrent Network Traffic Forecasting With ARMA</title><categories>cs.NI</categories><comments>14 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In recent years, there are some major changes in the way content is being
distributed over the network. The content distribution techniques have recently
started to embrace peer-to-peer (P2P) systems as an alternative to the
traditional client-server architecture. P2P systemsthat are based on the
BitTorrent protocol uses end-users' resources to provide a cost effective
distribution of bandwidth intensive content to thousands of users. The
BitTorrent protocol system offers a scalable mechanism for distributing a large
volume of data to a set of peers over the Internet. With the growing demand for
file sharing and content distribution, BitTorrent has become one of the most
popular Internet applications and contributes to a signification fraction of
the Internet traffic. With the wide usage of the BitTorrent protocol system, it
has basically solved one of the major problems where data can be quickly
transferred to a group of interested parties. The strength of the BitTorrent
protocol lies in efficient bandwidth utilization for the downloading and
uploading processes. However, the usage of BitTorrent protocol also causes
latency for other applications in terms of network bandwidth which in turn has
caused concerns for the Internet Service Providers, who strives for quality of
service for all their customers. In this paper, we study the network traffic
patterns of theBitTorrent network traffic and investigate its behavior by
usingthe time series ARMA model. Our experimental results show that BitTorrent
network traffic can be modeled and forecasted by using ARMA models. We compared
and evaluated the forecasted network traffic with the real traffic patterns.
This modeling can be utilized by the Internet Service Providers to manage their
network bandwidth and also detect any abnormality in their network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1900</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1900</id><created>2012-08-09</created><authors><author><keyname>Mishra</keyname><forenames>Mina</forenames></author><author><keyname>Mankar</keyname><forenames>V. H.</forenames></author></authors><title>Message Embedded cipher using 2-D chaotic map</title><categories>cs.CR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper constructs two encryption methods using 2-D chaotic maps, Duffings
and Arnold's cat maps respectively. Both of the methods are designed using
message embedded scheme and are analyzed for their validity, for plaintext
sensitivity, key sensitivity, known plaintext and brute-force attacks. Due to
the less key space generally many chaotic cryptosystem developed are found to
be weak against Brute force attack which is an essential issue to be solved.
For this issue, concept of identifiability proved to be a necessary condition
to be fulfilled by the designed chaotic cipher to resist brute force attack,
which is a basic attack. As 2-D chaotic maps provide more key space than 1-D
maps thus they are considered to be more suitable. This work is accompanied
with analysis results obtained from these developed cipher. Moreover,
identifiable keys are searched for different input texts at various key values.
The methods are found to have good key sensitivity and possess identifiable
keys thus concluding that they can resist linear attacks and brute-force
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1906</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1906</id><created>2012-08-09</created><authors><author><keyname>Perry</keyname><forenames>Richard</forenames></author></authors><title>Batch Spreadsheet for C Programmers</title><categories>cs.SE</categories><comments>(2009) Batch Spreadsheet for C Programmers, International Conference
  on Scientific Computing (CSC'09)</comments><msc-class>CS:se</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computing environment is proposed, based on batch spreadsheet processing,
which produces a spreadsheet display from plain text input files of commands,
similar to the way documents are created using LaTeX. In this environment,
besides the usual spreadsheet rows and columns of cells, variables can be
defined and are stored in a separate symbol table. Cell and symbol formulas may
contain cycles, and cycles which converge can be used to implement iterative
algorithms. Formulas are specified using the syntax of the C programming
language, and all of C's numeric operators are supported, with operators such
as ++, +=, etc. being implicitly cyclic. User-defined functions can be written
in C and are accessed using a dynamic link library. The environment can be
combined with a GUI front-end processor to enable easier interaction and
graphics including plotting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1918</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1918</id><created>2012-08-09</created><authors><author><keyname>Aiash</keyname><forenames>Mahdi</forenames></author><author><keyname>Mapp</keyname><forenames>Glenford</forenames></author><author><keyname>Lasebae</keyname><forenames>Aboubaker</forenames></author></authors><title>A Survey on Authentication and Key Agreement Protocols in Heterogeneous
  Networks</title><categories>cs.CR</categories><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.4, No.4, July 2012, 199-214</journal-ref><doi>10.5121/ijnsa.2012.4413</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike current closed systems such as 2nd and 3rd generations where the core
network is controlled by a sole network operator, multiple network operators
will coexist and manage the core network in Next Generation Networks (NGNs).
This open architecture and the collaboration between different network
operators will support ubiquitous connectivity and thus enhances users'
experience. However, this brings to the fore certain security issues which must
be addressed, the most important of which is the initial Authentication and Key
Agreement (AKA) to identify and authorize mobile nodes on these various
networks. This paper looks at how existing research efforts the HOKEY WG,
Mobile Ethernet and 3GPP frameworks respond to this new environment and provide
security mechanisms. The analysis shows that most of the research had realized
the openness of the core network and tried to deal with it using different
methods. These methods will be extensively analysed in order to highlight their
strengths and weaknesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1921</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1921</id><created>2012-08-09</created><authors><author><keyname>Dessalles</keyname><forenames>Jean-Louis</forenames></author></authors><title>Algorithmic Simplicity and Relevance</title><categories>cs.AI cs.CC</categories><comments>Presented at the Solomonoff 85th Memorial Conference, Monash
  University, Melbourne, December 2011 12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The human mind is known to be sensitive to complexity. For instance, the
visual system reconstructs hidden parts of objects following a principle of
maximum simplicity. We suggest here that higher cognitive processes, such as
the selection of relevant situations, are sensitive to variations of
complexity. Situations are relevant to human beings when they appear simpler to
describe than to generate. This definition offers a predictive (i.e.
falsifiable) model for the selection of situations worth reporting
(interestingness) and for what individuals consider an appropriate move in
conversation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1922</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1922</id><created>2012-08-09</created><authors><author><keyname>Roy</keyname><forenames>Probir</forenames></author><author><keyname>Alam</keyname><forenames>Md. Mejbah Ul</forenames></author><author><keyname>Das</keyname><forenames>Nishita</forenames></author></authors><title>Heuristic based task scheduling in multiprocessor systems with genetic
  algorithm by choosing the eligible processor</title><categories>cs.DC</categories><journal-ref>IJDPS, Vol.3, No.4, (July 2012) 111-121</journal-ref><doi>10.5121/ijdps.2012.3412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multiprocessor systems, one of the main factors of systems' performance is
task scheduling. The well the task be distributed among the processors the well
be the performance. Again finding the optimal solution of scheduling the tasks
into the processors is NP-complete, that is, it will take a lot of time to find
the optimal solution. Many evolutionary algorithms (e.g. Genetic Algorithm,
Simulated annealing) are used to reach the near optimal solution in linear
time. In this paper we propose a heuristic for genetic algorithm based task
scheduling in multiprocessor systems by choosing the eligible processor on
educated guess. From comparison it is found that this new heuristic based GA
takes less computation time to reach the suboptimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1924</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1924</id><created>2012-08-09</created><authors><author><keyname>Altug</keyname><forenames>Yucel</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>Moderate Deviations in Channel Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider block codes whose rate converges to the channel capacity with
increasing block length at a certain speed and examine the best possible decay
of the probability of error. We prove that a moderate deviation principle holds
for all convergence rates between the large deviation and the central limit
theorem regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1926</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1926</id><created>2012-08-09</created><authors><author><keyname>Choudhary</keyname><forenames>Laxmi</forenames></author><author><keyname>Burdak</keyname><forenames>Bhawani Shankar</forenames></author></authors><title>Role of Ranking Algorithms for Information Retrieval</title><categories>cs.IR</categories><comments>Keywords: Page Rank, Web Mining, Web Structured Mining, Web Content
  Mining</comments><doi>10.5121/ijaia.2012.3415</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the use of web is increasing more day by day, the web users get easily
lost in the web's rich hyper structure. The main aim of the owner of the
website is to give the relevant information according their needs to the users.
We explained the Web mining is used to categorize users and pages by analyzing
user's behavior, the content of pages and then describe Web Structure mining.
This paper includes different Page Ranking algorithms and compares those
algorithms used for Information Retrieval. Different Page Rank based algorithms
like Page Rank (PR), WPR (Weighted Page Rank), HITS (Hyperlink Induced Topic
Selection), Distance Rank and EigenRumor algorithms are discussed and compared.
Simulation Interface has been designed for PageRank algorithm and Weighted
PageRank algorithm but PageRank is the only ranking algorithm on which Google
search engine works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1927</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1927</id><created>2012-08-09</created><authors><author><keyname>Wang</keyname><forenames>Jiannan</forenames></author><author><keyname>Kraska</keyname><forenames>Tim</forenames></author><author><keyname>Franklin</keyname><forenames>Michael J.</forenames></author><author><keyname>Feng</keyname><forenames>Jianhua</forenames></author></authors><title>CrowdER: Crowdsourcing Entity Resolution</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1483-1494 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entity resolution is central to data integration and data cleaning.
Algorithmic approaches have been improving in quality, but remain far from
perfect. Crowdsourcing platforms offer a more accurate but expensive (and slow)
way to bring human insight into the process. Previous work has proposed
batching verification tasks for presentation to human workers but even with
batching, a human-only approach is infeasible for data sets of even moderate
size, due to the large numbers of matches to be tested. Instead, we propose a
hybrid human-machine approach in which machines are used to do an initial,
coarse pass over all the data, and people are used to verify only the most
likely matching pairs. We show that for such a hybrid system, generating the
minimum number of verification tasks of a given size is NP-Hard, but we develop
a novel two-tiered heuristic approach for creating batched tasks. We describe
this method, and present the results of extensive experiments on real data sets
using a popular crowdsourcing platform. The experiments show that our hybrid
approach achieves both good efficiency and high accuracy compared to
machine-only or human-only alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1931</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1931</id><created>2012-08-09</created><authors><author><keyname>Dallachiesa</keyname><forenames>Michele</forenames></author><author><keyname>Nushi</keyname><forenames>Besmira</forenames></author><author><keyname>Mirylenka</keyname><forenames>Katsiaryna</forenames></author><author><keyname>Palpanas</keyname><forenames>Themis</forenames></author></authors><title>Uncertain Time-Series Similarity: Return to the Basics</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1662-1673 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last years there has been a considerable increase in the availability
of continuous sensor measurements in a wide range of application domains, such
as Location-Based Services (LBS), medical monitoring systems, manufacturing
plants and engineering facilities to ensure efficiency, product quality and
safety, hydrologic and geologic observing systems, pollution management, and
others. Due to the inherent imprecision of sensor observations, many
investigations have recently turned into querying, mining and storing uncertain
data. Uncertainty can also be due to data aggregation, privacy-preserving
transforms, and error-prone mining algorithms. In this study, we survey the
techniques that have been proposed specifically for modeling and processing
uncertain time series, an important model for temporal data. We provide an
analytical evaluation of the alternatives that have been proposed in the
literature, highlighting the advantages and disadvantages of each approach, and
further compare these alternatives with two additional techniques that were
carefully studied before. We conduct an extensive experimental evaluation with
17 real datasets, and discuss some surprising results, which suggest that a
fruitful research direction is to take into account the temporal correlations
in the time series. Based on our evaluations, we also provide guidelines useful
for the practitioners in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1932</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1932</id><created>2012-08-09</created><authors><author><keyname>Dasu</keyname><forenames>Tamraparni</forenames></author><author><keyname>Loh</keyname><forenames>Ji Meng</forenames></author></authors><title>Statistical Distortion: Consequences of Data Cleaning</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1674-1683 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of statistical distortion as an essential metric for
measuring the effectiveness of data cleaning strategies. We use this metric to
propose a widely applicable yet scalable experimental framework for evaluating
data cleaning strategies along three dimensions: glitch improvement,
statistical distortion and cost-related criteria. Existing metrics focus on
glitch improvement and cost, but not on the statistical impact of data cleaning
strategies. We illustrate our framework on real world data, with a
comprehensive suite of experiments and analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1933</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1933</id><created>2012-08-09</created><authors><author><keyname>Lang</keyname><forenames>Willis</forenames></author><author><keyname>Harizopoulos</keyname><forenames>Stavros</forenames></author><author><keyname>Patel</keyname><forenames>Jignesh M.</forenames></author><author><keyname>Shah</keyname><forenames>Mehul A.</forenames></author><author><keyname>Tsirogiannis</keyname><forenames>Dimitris</forenames></author></authors><title>Towards Energy-Efficient Database Cluster Design</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
  1684-1695 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy is a growing component of the operational cost for many &quot;big data&quot;
deployments, and hence has become increasingly important for practitioners of
large-scale data analysis who require scale-out clusters or parallel DBMS
appliances. Although a number of recent studies have investigated the energy
efficiency of DBMSs, none of these studies have looked at the architectural
design space of energy-efficient parallel DBMS clusters. There are many
challenges to increasing the energy efficiency of a DBMS cluster, including
dealing with the inherent scaling inefficiency of parallel data processing, and
choosing the appropriate energy-efficient hardware. In this paper, we
experimentally examine and analyze a number of key parameters related to these
challenges for designing energy-efficient database clusters. We explore the
cluster design space using empirical results and propose a model that considers
the key bottlenecks to energy efficiency in a parallel DBMS. This paper
represents a key first step in designing energy-efficient database clusters,
which is increasingly important given the trend toward parallel database
appliances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1934</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1934</id><created>2012-08-08</created><authors><author><keyname>Rodriguez</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>SPCMIB</affiliation></author></authors><title>Technical report: CSVM dictionaries</title><categories>cs.CE q-bio.QM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CSVM (CSV with Metadata) is a simple file format for tabular data. The
possible application domain is the same as typical spreadsheets files, but CSVM
is well suited for long term storage and the inter-conversion of RAW data. CSVM
embeds different levels for data, metadata and annotations in human readable
format and flat ASCII files. As a proof of concept, Perl and Python toolkits
were designed in order to handle CSVM data and objects in workflows. These
parsers can process CSVM files independently of data types, so it is possible
to use same data format and parser for a lot of scientific purposes. CSVM-1 is
the first version of CSVM specification, an extension of CSVM-1 for
implementing a translation system between CSVM files is presented in this
paper. The necessary data used to make the translation are also coded in
another CSVM file. This particular kind of CSVM is called a CSVM dictionary, it
is also readable by the current CSVM parser and it is fully supported by the
Python toolkit. This report presents a proposal for CSVM dictionaries, a
working example in chemistry, and some elements of Python toolkit usable to
handle these files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1940</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1940</id><created>2012-08-09</created><authors><author><keyname>Ontanon</keyname><forenames>Santiago</forenames></author></authors><title>Experiments with Game Tree Search in Real-Time Strategy Games</title><categories>cs.AI cs.GT</categories><comments>7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game tree search algorithms such as minimax have been used with enormous
success in turn-based adversarial games such as Chess or Checkers. However,
such algorithms cannot be directly applied to real-time strategy (RTS) games
because a number of reasons. For example, minimax assumes a turn-taking game
mechanics, not present in RTS games. In this paper we present RTMM, a real-time
variant of the standard minimax algorithm, and discuss its applicability in the
context of RTS games. We discuss its strengths and weaknesses, and evaluate it
in two real-time games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1942</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1942</id><created>2012-08-09</created><authors><author><keyname>Rao</keyname><forenames>B. Thirumala</forenames></author><author><keyname>Reddy</keyname><forenames>L. S. S.</forenames></author></authors><title>Scheduling Data Intensive Workloads through Virtualization on MapReduce
  based Clouds</title><categories>cs.DC</categories><journal-ref>International Journal of Distributed and Parallel Systems
  (IJDPS)Vol.3, No.4, Pages 99-110, July 2012</journal-ref><doi>10.5121/ijdps.2012.3411</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  MapReduce has become a popular programming model for running data intensive
applications on the cloud. Completion time goals or deadlines of MapReduce jobs
set by users are becoming crucial in existing cloud-based data processing
environments like Hadoop. There is a conflict between the scheduling MR jobs to
meet deadlines and &quot;data locality&quot; (assigning tasks to nodes that contain their
input data). To meet the deadline a task may be scheduled on a node without
local input data for that task causing expensive data transfer from a remote
node. In this paper, a novel scheduler is proposed to address the above problem
which is primarily based on the dynamic resource reconfiguration approach. It
has two components: 1) Resource Predictor: which dynamically determines the
required number of Map/Reduce slots for every job to meet completion time
guarantee; 2) Resource Reconfigurator: that adjusts the CPU resources while not
violating completion time goals of the users by dynamically increasing or
decreasing individual VMs to maximize data locality and also to maximize the
use of resources within the system among the active jobs. The proposed
scheduler has been evaluated against Fair Scheduler on virtual cluster built on
a physical cluster of 20 machines. The results demonstrate a gain of about 12%
increase in throughput of Jobs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1955</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1955</id><created>2012-08-09</created><authors><author><keyname>Farahbod</keyname><forenames>Fahimeh</forenames></author><author><keyname>Eftekhari</keyname><forenames>Mahdi</forenames></author></authors><title>Comparison of different T-norm operators in classification problems</title><categories>cs.AI</categories><comments>6 pages, 1 figure, 4 tables; International Journal of Fuzzy Logic
  Systems (IJFLS) Vol.2, No.3, July 2012</comments><doi>10.5121/ijfls.2012.2303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy rule based classification systems are one of the most popular fuzzy
modeling systems used in pattern classification problems. This paper
investigates the effect of applying nine different T-norms in fuzzy rule based
classification systems. In the recent researches, fuzzy versions of confidence
and support merits from the field of data mining have been widely used for both
rules selecting and weighting in the construction of fuzzy rule based
classification systems. For calculating these merits the product has been
usually used as a T-norm. In this paper different T-norms have been used for
calculating the confidence and support measures. Therefore, the calculations in
rule selection and rule weighting steps (in the process of constructing the
fuzzy rule based classification systems) are modified by employing these
T-norms. Consequently, these changes in calculation results in altering the
overall accuracy of rule based classification systems. Experimental results
obtained on some well-known data sets show that the best performance is
produced by employing the Aczel-Alsina operator in terms of the classification
accuracy, the second best operator is Dubois-Prade and the third best operator
is Dombi. In experiments, we have used 12 data sets with numerical attributes
from the University of California, Irvine machine learning repository (UCI).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1956</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1956</id><created>2012-08-09</created><authors><author><keyname>Yang</keyname><forenames>Kai</forenames></author><author><keyname>Zhou</keyname><forenames>Xi</forenames></author></authors><title>MIDI-LAB, a Powerful Visual Basic Program for Creating MIDI Music</title><categories>cs.SE cs.SD</categories><comments>12 pages, 10 figures, 2 tables,
  http://www.airccse.org/journal/ijsea/ijsea.html; International Journal of
  Software Engineering &amp; Applications (IJSEA), Vol.3, No.4, July 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creating MIDI music can be a practical challenge. In the past, working with
it was difficult and frustrating to all but the most accomplished and
determined. Now, however, we are offering a powerful Visual Basic program
called MIDI-LAB, that is easy to learn, and instantly rewarding to even the
newest users. MIDI-LAB has been developed to give users the ability to quickly
create music with a limitless variety of tunes, tempos, speeds, volumes,
instruments, rhythms and major scales. This program has a simple, intuitive,
and user-friendly interface, which provides a straightforward way to enter
musical data with Numbered Musical Notation (NMN) and immediately create MIDI
music. The key feature of this program is the digitalization of music input. It
vastly simplifies creating, editing, and saving MIDI music. MIDI-LAB can be
used virtually anywhere to write music for entertainment, teaching, computer
games, and mobile phone ringtones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1959</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1959</id><created>2012-08-09</created><authors><author><keyname>Aggarwal</keyname><forenames>Akshai</forenames></author><author><keyname>Gandhi</keyname><forenames>Savita</forenames></author><author><keyname>Chaubey</keyname><forenames>Nirbhay</forenames></author><author><keyname>Shah</keyname><forenames>Pathik</forenames></author><author><keyname>Sadhwani</keyname><forenames>Madhvi</forenames></author></authors><title>AODVSEC: A Novel Approach to Secure Ad Hoc on-Demand Distance Vector
  (AODV) Routing Protocol from Insider Attacks in MANETs</title><categories>cs.CR cs.NI</categories><comments>20 Pages, 24 Figures</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.4, No.4, July 2012, 191-210</journal-ref><doi>10.5121/ijcnc.2012.4412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad hoc Network (MANET) is a collection of mobile nodes that can
communicate with each other using multihop wireless links without requiring any
fixed based-station infrastructure and centralized management. Each node in the
network acts as both a host and a router. In such scenario, designing of an
efficient, reliable and secure routing protocol has been a major challenging
issue over the last many years. Numerous schemes have been proposed for secure
routing protocols and most of the research work has so far focused on providing
security for routing using cryptography. In this paper, we propose a novel
approach to secure Ad hoc On-demand Distance Vector (AODV) routing protocol
from the insider attacks launched through active forging of its Route Reply
(RREP) control message. AODV routing protocol does not have any security
provision that makes it less reliable in publicly open ad hoc network. To deal
with the concerned security attacks, we have proposed AODV Security Extension
(AODVSEC) which enhances the scope of AODV for the security provision. We have
compared AODVSEC with AODV and Secure AODV (SAODV) in normal situation as well
as in presence of the three concerned attacks viz. Resource Consumption (RC)
attack, Route Disturb (RD) attack, Route Invasion (RI) attack and Blackhole
(BH) attack. To evaluate the performances, we have considered Packet Delivery
Fraction (PDF), Average End-to-End Delay (AED), Average Throughput (AT),
Normalized Routing Load (NRL) and Average Jitter and Accumulated Average
Processing Time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1963</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1963</id><created>2012-08-09</created><authors><author><keyname>K&#xf6;rner</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Muzi</keyname><forenames>Irene</forenames></author></authors><title>Degree-doubling graph families</title><categories>math.CO cs.IT math.IT</categories><comments>9 pages</comments><msc-class>05D99, 05C35, 05C62, 94A24</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a family of n-vertex graphs of uniform degree 2 with the property
that the union of any two member graphs has degree four. We determine the
leading term in the asymptotics of the largest cardinality of such a family.
Several analogous problems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1969</identifier>
 <datestamp>2012-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1969</id><created>2012-08-09</created><authors><author><keyname>Perry</keyname><forenames>Richard</forenames></author></authors><title>An Internet Approach for Engineering Student Exercises</title><categories>cs.CY</categories><comments>Mid-Atlantic ASEE Conference, October 15-16, 2010, Villanova
  University</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approach for engineering student exercises using the Internet is
described. In this approach, for a given exercise, each student receives the
same problem, but with different data. The exercise content can be static or
dynamic, and the dynamic form can be timeless or real-time. The implementation
provides immediate feedback to the students, letting them know if their
submitted answers are correct. Student results for each exercise are recorded
in log files which are available to the instructor. Example exercises from
engineering computer security and cryptography courses are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1975</identifier>
 <datestamp>2013-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1975</id><created>2012-08-09</created><updated>2013-02-11</updated><authors><author><keyname>Rodriguez</keyname><forenames>Manuel Rodriguez</forenames></author><author><keyname>Philip</keyname><forenames>Bobby</forenames></author><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Berrill</keyname><forenames>Mark</forenames></author></authors><title>Block-Relaxation Methods for 3D Constant-Coefficient Stencils on GPUs
  and Multicore CPUs</title><categories>cs.DC</categories><comments>Submitted to Journal of Parallel and Distributed Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Block iterative methods are extremely important as smoothers for multigrid
methods, as preconditioners for Krylov methods, and as solvers for diagonally
dominant linear systems. Developing robust and efficient algorithms suitable
for current and evolving GPU and multicore CPU systems is a significant
challenge. We address this issue in the case of constant-coefficient stencils
arising in the solution of elliptic partial differential equations on
structured 3D uniform and adaptively refined grids. Robust, highly parallel
implementations of block Jacobi and chaotic block Gauss-Seidel algorithms with
exact inversion of the blocks are developed using different parallelization
techniques. Experimental results for NVIDIA Fermi GPUs and AMD multicore
systems are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1977</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1977</id><created>2012-08-09</created><updated>2013-04-14</updated><authors><author><keyname>Singh</keyname><forenames>Sarabjot</forenames></author><author><keyname>Dhillon</keyname><forenames>Harpreet S.</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Offloading in Heterogeneous Networks: Modeling, Analysis, and Design
  Insights</title><categories>cs.IT math.IT</categories><comments>Accepted, IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pushing data traffic from cellular to WiFi is an example of inter radio
access technology (RAT) offloading. While this clearly alleviates congestion on
the over-loaded cellular network, the ultimate potential of such offloading and
its effect on overall system performance is not well understood. To address
this, we develop a general and tractable model that consists of $M$ different
RATs, each deploying up to $K$ different tiers of access points (APs), where
each tier differs in transmit power, path loss exponent, deployment density and
bandwidth. Each class of APs is modeled as an independent Poisson point process
(PPP), with mobile user locations modeled as another independent PPP, all
channels further consisting of i.i.d. Rayleigh fading. The distribution of rate
over the entire network is then derived for a weighted association strategy,
where such weights can be tuned to optimize a particular objective. We show
that the optimum fraction of traffic offloaded to maximize $\SINR$ coverage is
not in general the same as the one that maximizes rate coverage, defined as the
fraction of users achieving a given rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1208.1982</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1208.1982</id><created>2012-08-09</created><authors><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author></authors><title>Determination Of Optimal Number Of Clusters In Wireless Sensor Networks</title><categories>cs.DC cs.NI</categories><comments>18 pages, 14 figures</comments><acm-class>C.2.1</acm-class><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.4, No.4, July 2012, 235-249</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prolonged network lifetime, scalability and efficient load balancing are
essential for optimal performance of a wireless sensor network. Clustering
provides an effective way of extending the lifetime of a sensor network.
Clustering is the process that divides sensor networks into smaller localized
group (called clusters) of members with a cluster head. Clustering protocols
need to elect optimal number of clusters in hierarchically structured wireless
sensor networks. Any clustering scheme that elects clusters uniformly
(irrespective of the distance from Base Station) incurs excessive energy usage
on clusters proximal and distant to Base Station. In single hop networks a
gradual increment in the energy depletion rate is observed as the distance from
the cluster head increases. This work focuses on the analysis of wasteful
energy consumption within a uniform cluster head election model (EPEM) and
provides an analytic solution to reduce the overall consumption of energy usage
amongst the clusters elected in a wireless sensor network. A circular model of
sensor network is considered, where the sensor nodes are deployed around a
centrally located Base Station. The sensor network is divided into several
concentric rings centred at the Base Station. A model, Unequal Probability
Election Model (UEPEM), which elects cluster heads non-uniformly is proposed.
The probability of cluster head election depends on the distance from the Base
Station. UEPEM reduces the overall energy usage by about 21% over EPEM. The
performance of UEPEM improves as the number of rings is increased.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="34000" completeListSize="102538">1122234|35001</resumptionToken>
</ListRecords>
</OAI-PMH>
