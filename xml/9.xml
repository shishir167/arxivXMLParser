<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:40:31Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|8001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4668</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4668</id><created>2009-06-25</created><authors><author><keyname>Chmielewski</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author><author><keyname>van Rossum</keyname><forenames>Peter</forenames></author></authors><title>Client-Server Password Recovery (Extended Abstract)</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human memory is not perfect - people constantly memorize new facts and forget
old ones. One example is forgetting a password, a common problem raised at IT
help desks. We present several protocols that allow a user to automatically
recover a password from a server using partial knowledge of the password. These
protocols can be easily adapted to the personal entropy setting, where a user
can recover a password only if he can answer a large enough subset of personal
questions.
  We introduce client-server password recovery methods, in which the recovery
data are stored at the server, and the recovery procedures are integrated into
the login procedures. These methods apply to two of the most common types of
password based authentication systems. The security of these solutions is
significantly better than the security of presently proposed password recovery
schemes. Our protocols are based on a variation of threshold encryption that
may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4675</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4675</id><created>2009-06-25</created><updated>2010-05-27</updated><authors><author><keyname>Beguerisse-Diaz</keyname><forenames>Mariano</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Onnela</keyname><forenames>Jukka-Pekka</forenames></author></authors><title>Competition for Popularity in Bipartite Networks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>13 Pages, 19 Figures</comments><doi>10.1063/1.3475411</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present a dynamical model for rewiring and attachment in bipartite
networks in which edges are added between nodes that belong to catalogs that
can either be fixed in size or growing in size. The model is motivated by an
empirical study of data from the video rental service Netflix, which invites
its users to give ratings to the videos available in its catalog. We find that
the distribution of the number of ratings given by users and that of the number
of ratings received by videos both follow a power law with an exponential
cutoff. We also examine the activity patterns of Netflix users and find bursts
of intense video-rating activity followed by long periods of inactivity. We
derive ordinary differential equations to model the acquisition of edges by the
nodes over time and obtain the corresponding time-dependent degree
distributions. We then compare our results with the Netflix data and find good
agreement. We conclude with a discussion of how catalog models can be used to
study systems in which agents are forced to choose, rate, or prioritize their
interactions from a very large set of options.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4680</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4680</id><created>2009-06-25</created><authors><author><keyname>Benoit</keyname><forenames>Eric</forenames><affiliation>LISTIC</affiliation></author><author><keyname>Huget</keyname><forenames>Marc-Philippe</forenames><affiliation>LISTIC</affiliation></author><author><keyname>Moreaux</keyname><forenames>Patrice</forenames><affiliation>LISTIC</affiliation></author><author><keyname>Passalacqua</keyname><forenames>Olivier</forenames><affiliation>LISTIC</affiliation></author></authors><title>Reconfiguration of Distributed Information Fusion System ? A case study</title><categories>cs.DC</categories><comments>6 pages - Preprint version</comments><proxy>ccsd hal-00398602</proxy><journal-ref>Workshop on Dependable Control of Discrete Systems, Bari : Italie
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information Fusion Systems are now widely used in different fusion contexts,
like scientific processing, sensor networks, video and image processing. One of
the current trends in this area is to cope with distributed systems. In this
context, we have defined and implemented a Dynamic Distributed Information
Fusion System runtime model. It allows us to cope with dynamic execution
supports while trying to maintain the functionalities of a given Dynamic
Distributed Information Fusion System. The paper presents our system, the
reconfiguration problems we are faced with and our solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4690</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4690</id><created>2009-06-25</created><authors><author><keyname>Suanmali</keyname><forenames>Ladda</forenames></author><author><keyname>Salim</keyname><forenames>Naomie</forenames></author><author><keyname>Binwahlan</keyname><forenames>Mohammed Salem</forenames></author></authors><title>Fuzzy Logic Based Method for Improving Text Summarization</title><categories>cs.IR</categories><comments>6 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text summarization can be classified into two approaches: extraction and
abstraction. This paper focuses on extraction approach. The goal of text
summarization based on extraction approach is sentence selection. One of the
methods to obtain the suitable sentences is to assign some numerical measure of
a sentence for the summary called sentence weighting and then select the best
ones. The first step in summarization by extraction is the identification of
important features. In our experiment, we used 125 test documents in DUC2002
data set. Each document is prepared by preprocessing process: sentence
segmentation, tokenization, removing stop word, and word stemming. Then, we use
8 important features and calculate their score for each sentence. We propose
text summarization based on fuzzy logic to improve the quality of the summary
created by the general statistic method. We compare our results with the
baseline summarizer and Microsoft Word 2007 summarizers. The results show that
the best average precision, recall, and f-measure for the summaries were
obtained by fuzzy method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4692</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4692</id><created>2009-06-25</created><authors><author><keyname>Ferragina</keyname><forenames>Paolo</forenames></author><author><keyname>Nitto</keyname><forenames>Igor</forenames></author><author><keyname>Venturini</keyname><forenames>Rossano</forenames></author></authors><title>On optimally partitioning a text to improve its compression</title><categories>cs.DS cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the problem of partitioning an input string T in
such a way that compressing individually its parts via a base-compressor C gets
a compressed output that is shorter than applying C over the entire T at once.
This problem was introduced in the context of table compression, and then
further elaborated and extended to strings and trees. Unfortunately, the
literature offers poor solutions: namely, we know either a cubic-time algorithm
for computing the optimal partition based on dynamic programming, or few
heuristics that do not guarantee any bounds on the efficacy of their computed
partition, or algorithms that are efficient but work in some specific scenarios
(such as the Burrows-Wheeler Transform) and achieve compression performance
that might be worse than the optimal-partitioning by a $\Omega(\sqrt{\log n})$
factor. Therefore, computing efficiently the optimal solution is still open. In
this paper we provide the first algorithm which is guaranteed to compute in
$O(n \log_{1+\eps}n)$ time a partition of T whose compressed output is
guaranteed to be no more than $(1+\epsilon)$-worse the optimal one, where
$\epsilon$ may be any positive constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4706</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4706</id><created>2009-06-25</created><updated>2009-06-30</updated><authors><author><keyname>Brise</keyname><forenames>Yves</forenames></author><author><keyname>G&#xe4;rtner</keyname><forenames>Bernd</forenames></author></authors><title>Clarksons Algorithm for Violator Spaces</title><categories>cs.CG</categories><comments>21 pages</comments><acm-class>G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clarksons algorithm is a two-staged randomized algorithm for solving linear
programs. This algorithm has been simplified and adapted to fit the framework
of LP-type problems. In this framework we can tackle a number of non-linear
problems such as computing the smallest enclosing ball of a set of points in
R^d . In 2006, it has been shown that the algorithm in its original form works
for violator spaces too, which are a proper general- ization of LP-type
problems. It was not clear, however, whether previous simplifications of the
algorithm carry over to the new setting. In this paper we show the following
theoretical results: (a) It is shown, for the first time, that Clarksons second
stage can be simplified. (b) The previous simplifications of Clarksons first
stage carry over to the violator space setting. (c) Furthermore, we show the
equivalence of violator spaces and partitions of the hypercube by hypercubes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4711</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4711</id><created>2009-06-25</created><updated>2011-06-17</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Spoletini</keyname><forenames>Paola</forenames></author></authors><title>On Relaxing Metric Information in Linear Temporal Logic</title><categories>cs.LO</categories><comments>Minor changes</comments><journal-ref>Proceedings of the 18th International Symposium on Temporal
  Representation and Reasoning (TIME'11). Pgg. 72--79, IEEE Computer Society,
  September 2011</journal-ref><doi>10.1109/TIME.2011.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metric LTL formulas rely on the next operator to encode time distances,
whereas qualitative LTL formulas use only the until operator. This paper shows
how to transform any metric LTL formula M into a qualitative formula Q, such
that Q is satisfiable if and only if M is satisfiable over words with
variability bounded with respect to the largest distances used in M (i.e.,
occurrences of next), but the size of Q is independent of such distances.
Besides the theoretical interest, this result can help simplify the
verification of systems with time-granularity heterogeneity, where large
distances are required to express the coarse-grain dynamics in terms of
fine-grain time units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4725</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4725</id><created>2009-06-25</created><updated>2011-04-21</updated><authors><author><keyname>Coecke</keyname><forenames>Bob</forenames></author><author><keyname>Duncan</keyname><forenames>Ross</forenames></author></authors><title>Interacting Quantum Observables: Categorical Algebra and Diagrammatics</title><categories>quant-ph cs.LO math.CT math.QA</categories><comments>81 pages, many figures. Significant changes from previous version.
  The first sections contain a gentle introduction for physicists to the
  graphical language, and its use in quantum computation</comments><journal-ref>New J. Phys. 13 (2011) 043016</journal-ref><doi>10.1088/1367-2630/13/4/043016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has two tightly intertwined aims: (i) To introduce an intuitive
and universal graphical calculus for multi-qubit systems, the ZX-calculus,
which greatly simplifies derivations in the area of quantum computation and
information. (ii) To axiomatise complementarity of quantum observables within a
general framework for physical theories in terms of dagger symmetric monoidal
categories. We also axiomatize phase shifts within this framework.
  Using the well-studied canonical correspondence between graphical calculi and
symmetric monoidal categories, our results provide a purely graphical
formalisation of complementarity for quantum observables. Each individual
observable, represented by a commutative special dagger Frobenius algebra,
gives rise to an abelian group of phase shifts, which we call the phase group.
We also identify a strong form of complementarity, satisfied by the Z and X
spin observables, which yields a scaled variant of a bialgebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4747</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4747</id><created>2009-06-25</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Hart</keyname><forenames>Vi</forenames></author><author><keyname>Price</keyname><forenames>Gregory N.</forenames></author><author><keyname>Tachi</keyname><forenames>Tomohiro</forenames></author></authors><title>(Non)existence of Pleated Folds: How Paper Folds Between Creases</title><categories>cs.CG</categories><comments>19 pages, 6 figures</comments><acm-class>I.3.5; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the pleated hyperbolic paraboloid, a familiar origami model
known since 1927, in fact cannot be folded with the standard crease pattern in
the standard mathematical model of zero-thickness paper. In contrast, we show
that the model can be folded with additional creases, suggesting that real
paper &quot;folds&quot; into this model via small such creases. We conjecture that the
circular version of this model, consisting simply of concentric circular
creases, also folds without extra creases.
  At the heart of our results is a new structural theorem characterizing
uncreased intrinsically flat surfaces--the portions of paper between the
creases. Differential geometry has much to say about the local behavior of such
surfaces when they are sufficiently smooth, e.g., that they are torsal ruled.
But this classic result is simply false in the context of the whole surface.
Our structural characterization tells the whole story, and even applies to
surfaces with discontinuities in the second derivative. We use our theorem to
prove fundamental properties about how paper folds, for example, that straight
creases on the piece of paper must remain piecewise-straight (polygonal) by
folding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4750</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4750</id><created>2009-06-25</created><authors><author><keyname>Kolpakov</keyname><forenames>Roman</forenames></author><author><keyname>Kucherov</keyname><forenames>Gregory</forenames></author><author><keyname>Ochem</keyname><forenames>Pascal</forenames></author></authors><title>On maximal repetitions of arbitrary exponent</title><categories>cs.DM</categories><comments>8 pages, 1 figure</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first two authors have shown [KK99,KK00] that the sum the exponent (and
thus the number) of maximal repetitions of exponent at least 2 (also called
runs) is linear in the length of the word. The exponent 2 in the definition of
a run may seem arbitrary. In this paper, we consider maximal repetitions of
exponent strictly greater than 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4762</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4762</id><created>2009-06-25</created><authors><author><keyname>Klein</keyname><forenames>Cristian</forenames></author><author><keyname>Cret</keyname><forenames>Octavian</forenames></author><author><keyname>Suciu</keyname><forenames>Alin</forenames></author></authors><title>Design and Implementation of a High Quality and High Throughput TRNG in
  FPGA</title><categories>cs.CR</categories><comments>5 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the design and implementation of a high-quality and
high-throughput true-random number generator (TRNG) in FPGA. Various practical
issues which we encountered are highlighted and the influence of the various
parameters on the functioning of the TRNG are discussed. We also propose a few
values for the parameters which use the minimum amount of the resources but
still pass common random number generator test batteries such as DieHard and
TestU01.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4764</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4764</id><created>2009-06-25</created><updated>2009-06-30</updated><authors><author><keyname>Somanchi</keyname><forenames>Sriram</forenames></author><author><keyname>Nittala</keyname><forenames>Chaitanya</forenames></author><author><keyname>Yadati</keyname><forenames>Narahari</forenames></author></authors><title>A Novel Bid Optimizer for Sponsored Search Auctions based on Cooperative
  Game Theory</title><categories>cs.GT cs.MA</categories><comments>To be published in Proceedings of the 2009 IEEE/WIC/ACM International
  Conference on Intelligent Agent Technology. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a bid optimizer for sponsored keyword search
auctions which leads to better retention of advertisers by yielding attractive
utilities to the advertisers without decreasing the revenue to the search
engine. The bid optimizer is positioned as a key value added tool the search
engine provides to the advertisers. The proposed bid optimizer algorithm
transforms the reported values of the advertisers for a keyword into a
correlated bid profile using many ideas from cooperative game theory. The
algorithm is based on a characteristic form game involving the search engine
and the advertisers. Ideas from Nash bargaining theory are used in formulating
the characteristic form game to provide for a fair share of surplus among the
players involved. The algorithm then computes the nucleolus of the
characteristic form game since we find that the nucleolus is an apt way of
allocating the gains of cooperation among the search engine and the
advertisers. The algorithm next transforms the nucleolus into a correlated bid
profile using a linear programming formulation. This bid profile is input to a
standard generalized second price mechanism (GSP) for determining the
allocation of sponsored slots and the prices to be be paid by the winners. The
correlated bid profile that we determine is a locally envy-free equilibrium and
also a correlated equilibrium of the underlying game. Through detailed
simulation experiments, we show that the proposed bid optimizer retains more
customers than a plain GSP mechanism and also yields better long-run utilities
to the search engine and the advertisers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4779</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4779</id><created>2009-06-25</created><updated>2011-09-24</updated><authors><author><keyname>Sohl-Dickstein</keyname><forenames>Jascha</forenames></author><author><keyname>Battaglino</keyname><forenames>Peter</forenames></author><author><keyname>DeWeese</keyname><forenames>Michael R.</forenames></author></authors><title>Minimum Probability Flow Learning</title><categories>cs.LG physics.data-an stat.ML</categories><comments>Updated to match ICML conference proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fitting probabilistic models to data is often difficult, due to the general
intractability of the partition function and its derivatives. Here we propose a
new parameter estimation technique that does not require computing an
intractable normalization factor or sampling from the equilibrium distribution
of the model. This is achieved by establishing dynamics that would transform
the observed data distribution into the model distribution, and then setting as
the objective the minimization of the KL divergence between the data
distribution and the distribution produced by running the dynamics for an
infinitesimal time. Score matching, minimum velocity learning, and certain
forms of contrastive divergence are shown to be special cases of this learning
technique. We demonstrate parameter estimation in Ising models, deep belief
networks and an independent component analysis model of natural scenes. In the
Ising model case, current state of the art techniques are outperformed by at
least an order of magnitude in learning time, with lower error in recovered
coupling parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4789</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4789</id><created>2009-06-25</created><authors><author><keyname>Azizi</keyname><forenames>Amir</forenames></author><author><keyname>Pourreza</keyname><forenames>Hamid Reza</forenames></author></authors><title>Efficient IRIS Recognition through Improvement of Feature Extraction and
  subset Selection</title><categories>cs.CV</categories><comments>10 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS JUne 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The selection of the optimal feature subset and the classification has become
an important issue in the field of iris recognition. In this paper we propose
several methods for iris feature subset selection and vector creation. The
deterministic feature sequence is extracted from the iris image by using the
contourlet transform technique. Contourlet transform captures the intrinsic
geometrical structures of iris image. It decomposes the iris image into a set
of directional sub-bands with texture details captured in different
orientations at various scales so for reducing the feature vector dimensions we
use the method for extract only significant bit and information from normalized
iris images. In this method we ignore fragile bits. And finally we use SVM
(Support Vector Machine) classifier for approximating the amount of people
identification in our proposed system. Experimental result show that most
proposed method reduces processing time and increase the classification
accuracy and also the iris feature vector length is much smaller versus the
other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4805</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4805</id><created>2009-06-26</created><updated>2009-06-27</updated><authors><author><keyname>Sra</keyname><forenames>Suvrit</forenames></author></authors><title>A Trivial Observation related to Sparse Recovery</title><categories>cs.IT math.IT</categories><comments>Replaces previous correct but useless version with another correct,
  but hopefully somewhat less useless version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We make a trivial modification to the elegant analysis of Garg and Khandekar
  (\emph{Gradient Descent with Sparsification} ICML 2009) that replaces the
standard Restricted Isometry Property (RIP), with another RIP-type property
(which could be simpler than the RIP, but we are not sure; it could be as hard
as the RIP to check, thereby rendering this little writeup totally worthless).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4816</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4816</id><created>2009-06-25</created><authors><author><keyname>Khot</keyname><forenames>Subhash</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>Sharp kernel clustering algorithms and their associated Grothendieck
  inequalities</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the kernel clustering problem we are given a (large) $n\times n$ symmetric
positive semidefinite matrix $A=(a_{ij})$ with $\sum_{i=1}^n\sum_{j=1}^n
a_{ij}=0$ and a (small) $k\times k$ symmetric positive semidefinite matrix
$B=(b_{ij})$. The goal is to find a partition $\{S_1,...,S_k\}$ of $\{1,...
n\}$ which maximizes $ \sum_{i=1}^k\sum_{j=1}^k (\sum_{(p,q)\in S_i\times
S_j}a_{pq})b_{ij}$.
  We design a polynomial time approximation algorithm that achieves an
approximation ratio of $\frac{R(B)^2}{C(B)}$, where $R(B)$ and $C(B)$ are
geometric parameters that depend only on the matrix $B$, defined as follows: if
$b_{ij} = &lt; v_i, v_j&gt;$ is the Gram matrix representation of $B$ for some
$v_1,...,v_k\in \R^k$ then $R(B)$ is the minimum radius of a Euclidean ball
containing the points $\{v_1, ..., v_k\}$. The parameter $C(B)$ is defined as
the maximum over all measurable partitions $\{A_1,...,A_k\}$ of $\R^{k-1}$ of
the quantity $\sum_{i=1}^k\sum_{j=1}^k b_{ij}&lt; z_i,z_j&gt;$, where for $i\in
\{1,...,k\}$ the vector $z_i\in \R^{k-1}$ is the Gaussian moment of $A_i$,
i.e., $z_i=\frac{1}{(2\pi)^{(k-1)/2}}\int_{A_i}xe^{-\|x\|_2^2/2}dx$. We also
show that for every $\eps &gt; 0$, achieving an approximation guarantee of
$(1-\e)\frac{R(B)^2}{C(B)}$ is Unique Games hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4827</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4827</id><created>2009-06-25</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Physical Layer Security: Coalitional Games for Distributed Cooperation</title><categories>cs.IT cs.GT math.IT</categories><comments>Best paper Award at Wiopt 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperation between wireless network nodes is a promising technique for
improving the physical layer security of wireless transmission, in terms of
secrecy capacity, in the presence of multiple eavesdroppers. While existing
physical layer security literature answered the question &quot;what are the
link-level secrecy capacity gains from cooperation?&quot;, this paper attempts to
answer the question of &quot;how to achieve those gains in a practical decentralized
wireless network and in the presence of a secrecy capacity cost for information
exchange?&quot;. For this purpose, we model the physical layer security cooperation
problem as a coalitional game with non-transferable utility and propose a
distributed algorithm for coalition formation. Through the proposed algorithm,
the wireless users can autonomously cooperate and self-organize into disjoint
independent coalitions, while maximizing their secrecy capacity taking into
account the security costs during information exchange. We analyze the
resulting coalitional structures, discuss their properties, and study how the
users can self-adapt the network topology to environmental changes such as
mobility. Simulation results show that the proposed algorithm allows the users
to cooperate and self-organize while improving the average secrecy capacity per
user up to 25.32% relative to the non-cooperative case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4834</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4834</id><created>2009-06-25</created><authors><author><keyname>Rezaie</keyname><forenames>B.</forenames></author><author><keyname>Motlagh</keyname><forenames>MR. Jahed</forenames></author><author><keyname>Analoui</keyname><forenames>M.</forenames></author><author><keyname>Khorsandi</keyname><forenames>S.</forenames></author></authors><title>Global Stability Analysis for an Internet Congestion Control Model with
  a Time-Varying Link Capacity</title><categories>cs.NI cs.PF</categories><comments>5 pages, International Journal of Computer Science and Information
  Security, IJCSIS</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a global stability analysis is given for a rate-based
congestion control system modeled by a nonlinear delayed differential equation.
The model determines the dynamics of a single-source single-link network, with
a time-varying capacity of link and a fixed communication delay. We obtain a
sufficient delay-independent conditions on system parameters under which global
asymptotic stability of the system is guarantied. The proof is based on an
extension of Lyapunov-Krasovskii theorem for a class of nonlinear time-delay
systems. The numerical simulations for a typical scenario justify the
theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4837</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4837</id><created>2009-06-26</created><authors><author><keyname>Han</keyname><forenames>Bin</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author></authors><title>Advances in the Design and Implementation of a Multi-Tier Architecture
  in the GIPSY Environment</title><categories>cs.SE cs.DC cs.PL</categories><comments>11 pages, 3 figures</comments><acm-class>D.2.11; D.3.2; D.3.4</acm-class><doi>10.1109/SERA.2010.40</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present advances in the software engineering design and implementation of
the multi-tier run-time system for the General Intensional Programming System
(GIPSY) by further unifying the distributed technologies used to implement the
Demand Migration Framework (DMF) in order to streamline distributed execution
of hybrid intensional-imperative programs using Java.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4838</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4838</id><created>2009-06-26</created><authors><author><keyname>Kulkarni</keyname><forenames>Siddhivinayak</forenames></author><author><keyname>Haidar</keyname><forenames>Imad</forenames></author></authors><title>Forecasting Model for Crude Oil Price Using Artificial Neural Networks
  and Commodity Futures Prices</title><categories>cs.NE q-fin.PM</categories><comments>8 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a model based on multilayer feedforward neural network to
forecast crude oil spot price direction in the short-term, up to three days
ahead. A great deal of attention was paid on finding the optimal ANN model
structure. In addition, several methods of data pre-processing were tested. Our
approach is to create a benchmark based on lagged value of pre-processed spot
price, then add pre-processed futures prices for 1, 2, 3,and four months to
maturity, one by one and also altogether. The results on the benchmark suggest
that a dynamic model of 13 lags is the optimal to forecast spot price direction
for the short-term. Further, the forecast accuracy of the direction of the
market was 78%, 66%, and 53% for one, two, and three days in future
conclusively. For all the experiments, that include futures data as an input,
the results show that on the short-term, futures prices do hold new information
on the spot price direction. The results obtained will generate comprehensive
understanding of the crude oil dynamic which help investors and individuals for
risk managements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4846</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4846</id><created>2009-06-26</created><authors><author><keyname>Jantschi</keyname><forenames>Lorentz</forenames></author></authors><title>A genetic algorithm for structure-activity relationships: software
  implementation</title><categories>cs.NE</categories><comments>21 pages; 10 figures; 14 tables</comments><acm-class>G.3; I.6.4; J.2; J.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The design and the implementation of a genetic algorithm are described. The
applicability domain is on structure-activity relationships expressed as
multiple linear regressions and predictor variables are from families of
structure-based molecular descriptors. An experiment to compare different
selection and survival strategies was designed and realized. The genetic
algorithm was run using the designed experiment on a set of 206 polychlorinated
biphenyls searching on structure-activity relationships having known the
measured octanol-water partition coefficients and a family of molecular
descriptors. The experiment shows that different selection and survival
strategies create different partitions on the entire population of all possible
genotypes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4900</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4900</id><created>2009-06-26</created><authors><author><keyname>ter Beek</keyname><forenames>Maurice H.</forenames></author></authors><title>Proceedings Fourth European Young Researchers Workshop on Service
  Oriented Computing</title><categories>cs.SE</categories><journal-ref>EPTCS 2, 2009</journal-ref><doi>10.4204/EPTCS.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-Oriented Computing (SOC) is an emerging new paradigm for distributed
and object-oriented computing by allowing autonomous, platform-independent
computational entities (called services) to be built (described, discovered,
composed, orchestrated) within and across organizational boundaries. Like no
other computing paradigm before, SOC is destined to exert a lasting influence
on the business domain, among others (e-commerce, e-government, e-business,
e-learning, e-health, etc.).
  The Young Researchers workshop series on Service-Oriented Computing is meant
to be a platform for junior researchers from industry and academics alike. Its
core objectives are to exchange information regarding advancements in the state
of the art and practice of SOC, as well as to identify emerging research topics
and the future trends in this domain.
  Following the success of the previous three workshops, the 4th European Young
Researchers Workshop on Service-Oriented Computing (YR-SOC 2009) introduced two
novelties: it was organised outside of the UK and it saw the introduction of a
number of tutorials, thus making the workshop a 3-day event. YR-SOC 2009 took
place at the CNR Institute of Information Science and Technologies in Pisa,
Italy, and was organised by Maurice ter Beek, Barry Norton, Stephan
Reiff-Marganiec and Monika Solanki.
  The contributions in this volume cover aspects such as automated service
composition, context-aware SOC, service-oriented programming, QoS-aware SOC,
service-oriented architectures, SOC modelling and analysis, process management,
web services, ontologies and the semantic web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4913</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4913</id><created>2009-06-26</created><updated>2009-10-06</updated><authors><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Explicit Construction of Optimal Exact Regenerating Codes for
  Distributed Storage</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures, in the Proceedings of Allerton Conference on
  Communication, Control and Computing, September 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erasure coding techniques are used to increase the reliability of distributed
storage systems while minimizing storage overhead. Also of interest is
minimization of the bandwidth required to repair the system following a node
failure. In a recent paper, Wu et al. characterize the tradeoff between the
repair bandwidth and the amount of data stored per node. They also prove the
existence of regenerating codes that achieve this tradeoff.
  In this paper, we introduce Exact Regenerating Codes, which are regenerating
codes possessing the additional property of being able to duplicate the data
stored at a failed node. Such codes require low processing and communication
overheads, making the system practical and easy to maintain. Explicit
construction of exact regenerating codes is provided for the minimum bandwidth
point on the storage-repair bandwidth tradeoff, relevant to
distributed-mail-server applications. A subspace based approach is provided and
shown to yield necessary and sufficient conditions on a linear code to possess
the exact regeneration property as well as prove the uniqueness of our
construction.
  Also included in the paper, is an explicit construction of regenerating codes
for the minimum storage point for parameters relevant to storage in
peer-to-peer systems. This construction supports a variable number of nodes and
can handle multiple, simultaneous node failures. All constructions given in the
paper are of low complexity, requiring low field size in particular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4917</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4917</id><created>2009-06-26</created><updated>2010-01-25</updated><authors><author><keyname>Jing-wei</keyname><forenames>Chen</forenames></author><author><keyname>Yong</keyname><forenames>Feng</forenames></author><author><keyname>Xiao-lin</keyname><forenames>Qin</forenames></author><author><keyname>Jing-zhong</keyname><forenames>Zhang</forenames></author></authors><title>Simultaneous Integer Relation Detection and Its an Application</title><categories>cs.SC cs.NA</categories><acm-class>F.2.1; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbf{x_1}, ..., \mathbf{x_t} \in \mathbb{R}^{n}$. A simultaneous
integer relation (SIR) for $\mathbf{x_1}, ..., \mathbf{x_t}$ is a vector
$\mathbf{m} \in \mathbb{Z}^{n}\setminus\{\textbf{0}\}$ such that
$\mathbf{x_i}^T\mathbf{m} = 0$ for $i = 1, ..., t$. In this paper, we propose
an algorithm SIRD to detect an SIR for real vectors, which constructs an SIR
within $\mathcal {O}(n^4 + n^3 \log \lambda(X))$ arithmetic operations, where
$\lambda(X)$ is the least Euclidean norm of SIRs for $\mathbf{x_1}, &gt;...,
\mathbf{x_t}$. One can easily generalize SIRD to complex number field.
Experimental results show that SIRD is practical and better than another
detecting algorithm in the literature. In its application, we present a new
algorithm for finding the minimal polynomial of an arbitrary complex algebraic
number from its an approximation, which is not based on LLL. We also provide a
sufficient condition on the precision of the approximate value, which depends
only on the height and the degree of the algebraic number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4927</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4927</id><created>2009-06-26</created><authors><author><keyname>Chang</keyname><forenames>Lijun</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author><author><keyname>Qin</keyname><forenames>Lu</forenames></author></authors><title>Fast Probabilistic Ranking under x-Relation Model</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The probabilistic top-k queries based on the interplay of score and
probability, under the possible worlds semantic, become an important research
issue that considers both score and uncertainty on the same basis. In the
literature, many different probabilistic top-k queries are proposed. Almost all
of them need to compute the probability of a tuple t_i to be ranked at the j-th
position across the entire set of possible worlds. The cost of such computing
is the dominant cost and is known as O(kn^2), where n is the size of dataset.
In this paper, we propose a new novel algorithm that computes such probability
in O(kn).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4936</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4936</id><created>2009-06-26</created><authors><author><keyname>Alaya</keyname><forenames>Bechir</forenames></author><author><keyname>Duvallet</keyname><forenames>Claude</forenames></author><author><keyname>Sadeg</keyname><forenames>Bruno</forenames></author></authors><title>A New Approach to Manage QoS in Distributed Multimedia Systems</title><categories>cs.MM cs.PF</categories><comments>10 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dealing with network congestion is a criterion used to enhance quality of
service (QoS) in distributed multimedia systems. The existing solutions for the
problem of network congestion ignore scalability considerations because they
maintain a separate classification for each video stream. In this paper, we
propose a new method allowing to control QoS provided to clients according to
the network congestion, by discarding some frames when needed. The technique
proposed, called (m,k)-frame, is scalable with little degradation in
application performances. (m,k)-frame method is issued from the notion of
(m,k)-firm realtime constraints which means that among k invocations of a task,
m invocations must meet their deadline. Our simulation studies show the
usefulness of (m,k)-frame method to adapt the QoS to the real conditions in a
multimedia application, according to the current system load. Notably, the
system must adjust the QoS provided to active clients1 when their number
varies, i.e. dynamic arrival of clients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4973</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4973</id><created>2009-06-26</created><authors><author><keyname>Khan</keyname><forenames>Rizwan A.</forenames></author><author><keyname>Qureshi</keyname><forenames>M. Aasim</forenames></author><author><keyname>Saeed</keyname><forenames>Saqib</forenames></author></authors><title>Vision Based Navigation for a Mobile Robot with Different Field of Views</title><categories>cs.RO</categories><comments>This paper was published in Proceedings of Pak-US International
  Symposium on High Optical Networks and Enabling Technologies (HONET 2005)
  Islamabad, Pakistan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The basic idea behind evolutionary robotics is to evolve a set of neural
controllers for a particular task at hand. It involves use of various input
parameters such as infrared sensors, light sensors and vision based methods.
This paper aims to explore the evolution of vision based navigation in a mobile
robot. It discusses in detail the effect of different field of views for a
mobile robot. The individuals have been evolved using different FOV values and
the results have been recorded and analyzed.The optimum values for FOV have
been proposed after evaluating more than 100 different values. It has been
observed that the optimum FOV value requires lesser number of generations for
evolution and the mobile robot trained with that particular value is able to
navigate well in the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4982</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4982</id><created>2009-06-26</created><authors><author><keyname>Ignatov</keyname><forenames>Dmitry I.</forenames></author><author><keyname>Kuznetsov</keyname><forenames>Sergei O.</forenames></author></authors><title>Concept-based Recommendations for Internet Advertisement</title><categories>cs.AI cs.CY cs.IR stat.ML</categories><comments>D.I.Ignatov, S.O. Kuznetsov. Concept-based Recommendations for
  Internet Advertisement//In proceedings of The Sixth International Conference
  Concept Lattices and Their Applications (CLA'08), Olomouc, Czech Republic,
  2008 ISBN 978-80-244-2111-7</comments><acm-class>I.2.1; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of detecting terms that can be interesting to the advertiser is
considered. If a company has already bought some advertising terms which
describe certain services, it is reasonable to find out the terms bought by
competing companies. A part of them can be recommended as future advertising
terms to the company. The goal of this work is to propose better interpretable
recommendations based on FCA and association rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4995</identifier>
 <datestamp>2009-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4995</id><created>2009-06-26</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP, Ictt</affiliation></author></authors><title>Dispositif de supervision pour les tuteurs impliqu\'es dans un
  apprentissage \`a la gestion de projets</title><categories>cs.CY</categories><comments>11 pages</comments><proxy>ccsd hal-00399584</proxy><journal-ref>Workshop &quot;Instrumentation des activit\'es du tuteur :
  Environnements de supervision, usages et ing\'enierie&quot; de la conf\'erence
  EIAH2009, Le Mans : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents results of the observation of a project management
teaching-by-project course. It describe return of experience not only of
student but also of tutors one years after the course. Many problems are
identified like individual student evaluation, tutor distance, lake of
coordination, lake of communication. We ask tutor about the pertinence of an
instrumental solution, based upon dashboard, to solve problems of coordination
and evaluation identified. We made the hypothese that a cognitive tool will
improve too the knowledge construction and the learning process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5007</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5007</id><created>2009-06-26</created><authors><author><keyname>Acemoglu</keyname><forenames>Daron</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author></authors><title>Spread of Misinformation in Social Networks</title><categories>cs.IT cs.DC math.IT math.PR</categories><comments>Submitted to Games and Economic Behavior</comments><report-no>LIDS report 2812</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a model to investigate the tension between information aggregation
and spread of misinformation in large societies (conceptualized as networks of
agents communicating with each other). Each individual holds a belief
represented by a scalar. Individuals meet pairwise and exchange information,
which is modeled as both individuals adopting the average of their pre-meeting
beliefs. When all individuals engage in this type of information exchange, the
society will be able to effectively aggregate the initial information held by
all individuals. There is also the possibility of misinformation, however,
because some of the individuals are &quot;forceful,&quot; meaning that they influence the
beliefs of (some) of the other individuals they meet, but do not change their
own opinion. The paper characterizes how the presence of forceful agents
interferes with information aggregation. Under the assumption that even
forceful agents obtain some information (however infrequent) from some others
(and additional weak regularity conditions), we first show that beliefs in this
class of societies converge to a consensus among all individuals. This
consensus value is a random variable, however, and we characterize its
behavior. Our main results quantify the extent of misinformation in the society
by either providing bounds or exact results (in some special cases) on how far
the consensus value can be from the benchmark without forceful agents (where
there is efficient information aggregation). The worst outcomes obtain when
there are several forceful agents and forceful agents themselves update their
beliefs only on the basis of information they obtain from individuals most
likely to have received their own information previously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5010</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5010</id><created>2009-06-26</created><authors><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>Testing cycle-freeness: Finding a certificate</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deal with the problem of designing one-sided error property testers for
cycle-freeness in bounded degree graphs. Such a property tester always accepts
forests. Furthermore, when it rejects an input, it provides a short cycle as a
certificate. The problem of testing cycle-freeness in this model was first
considered by Goldreich and Ron \cite{GR97}. They give a constant time tester
with two-sided error (it does not provide certificates for rejection) and prove
a $\Omega(\sqrt{n})$ lower bound for testers with one-sided error. We design a
property tester with one-sided error whose running time matches this lower
bound (upto polylogarithmic factors). Interestingly, this has connections to a
recent conjecture of Benjamini, Schramm, and Shapira \cite{BSS08}. The property
of cycle-freeness is closed under the operation of taking minors. This is the
first example of such a property that has an almost optimal
$\otilde(\sqrt{n})$-time one-sided error tester, but has a constant time
two-sided error tester. It was conjectured in \cite{BSS08} that this happens
for a vast class of minor-closed properties, and this result can seen as the
first indication towards that.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5017</identifier>
 <datestamp>2009-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5017</id><created>2009-06-26</created><updated>2009-10-17</updated><authors><author><keyname>Shang</keyname><forenames>Ming-Sheng</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Collaborative filtering with diffusion-based similarity on tripartite
  graphs</title><categories>cs.IR</categories><comments>8 pages, 4 figures, 1 table</comments><journal-ref>Physica A 389 (2010) 1259-1264</journal-ref><doi>10.1016/j.physa.2009.11.041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative tags are playing more and more important role for the
organization of information systems. In this paper, we study a personalized
recommendation model making use of the ternary relations among users, objects
and tags. We propose a measure of user similarity based on his preference and
tagging information. Two kinds of similarities between users are calculated by
using a diffusion-based process, which are then integrated for recommendation.
We test the proposed method in a standard collaborative filtering framework
with three metrics: ranking score, Recall and Precision, and demonstrate that
it performs better than the commonly used cosine similarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5022</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5022</id><created>2009-06-26</created><authors><author><keyname>Hogg</keyname><forenames>Tad</forenames></author><author><keyname>Freitas</keyname><forenames>Robert A.</forenames><suffix>Jr</suffix></author></authors><title>Chemical Power for Microscopic Robots in Capillaries</title><categories>cs.RO physics.bio-ph</categories><comments>28 pages, 7 figures</comments><journal-ref>Nanomedicine: Nanotechnology, Biology, and Medicine 6:298-317
  (2010)</journal-ref><doi>10.1016/j.nano.2009.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The power available to microscopic robots (nanorobots) that oxidize
bloodstream glucose while aggregated in circumferential rings on capillary
walls is evaluated with a numerical model using axial symmetry and
time-averaged release of oxygen from passing red blood cells. Robots about one
micron in size can produce up to several tens of picowatts, in steady-state, if
they fully use oxygen reaching their surface from the blood plasma. Robots with
pumps and tanks for onboard oxygen storage could collect oxygen to support
burst power demands two to three orders of magnitude larger. We evaluate
effects of oxygen depletion and local heating on surrounding tissue. These
results give the power constraints when robots rely entirely on ambient
available oxygen and identify aspects of the robot design significantly
affecting available power. More generally, our numerical model provides an
approach to evaluating robot design choices for nanomedicine treatments in and
near capillaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5023</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5023</id><created>2009-06-26</created><authors><author><keyname>Harada</keyname><forenames>Masaaki</forenames></author><author><keyname>Miezaki</keyname><forenames>Tsuyoshi</forenames></author></authors><title>An Upper Bound on the Minimum Weight of Type II $\ZZ_{2k}$-Codes</title><categories>math.CO cs.IT math.IT</categories><comments>10 pages, 2 tables</comments><msc-class>94B05, 11F03</msc-class><journal-ref>J. Combin. Theory Ser. A 118 (2010), 190-196</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give a new upper bound on the minimum Euclidean weight of
Type II $\ZZ_{2k}$-codes and the concept of extremality for the Euclidean
weights when $k=3,4,5,6$. Together with the known result, we demonstrate that
there is an extremal Type II $\ZZ_{2k}$-code of length $8m$ $(m \le 8)$ when
$k=3,4,5,6$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5031</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5031</id><created>2009-06-26</created><authors><author><keyname>Singh</keyname><forenames>Ram Kumar</forenames></author><author><keyname>Ramajujam</keyname><forenames>Prof. T.</forenames></author></authors><title>Intrusion Detection System Using Advanced Honeypots</title><categories>cs.CR</categories><comments>9 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exponential growth of Internet traffic has made public servers
increasingly vulnerable to unauthorized accesses and intrusions. In addition to
maintaining low latency for the client, filtering unauthorized accesses has
become one of the major concerns of a server maintainer. This implementation of
an Intrusion Detection System distinguishes between the traffic coming from
clients and the traffic originated from the attackers, in an attempt to
simultaneously mitigate the problems of both latency and security. We then
present the results of a series of stress and scalability tests, and suggest a
number of potential uses for such a system. As computer attacks are becoming
more and more difficult to identify the need for better and more efficient
intrusion detection systems increases. The main problem with current intrusion
detection systems is high rate of false alarms. Using honeypots provides
effective solution to increase the security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5034</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5034</id><created>2009-06-26</created><authors><author><keyname>Pal</keyname><forenames>Anshika</forenames></author><author><keyname>Tomar</keyname><forenames>Deepak Singh</forenames></author><author><keyname>Shrivastava</keyname><forenames>S. C.</forenames></author></authors><title>Effective Focused Crawling Based on Content and Link Structure Analysis</title><categories>cs.IR</categories><comments>5 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A focused crawler traverses the web selecting out relevant pages to a
predefined topic and neglecting those out of concern. While surfing the
internet it is difficult to deal with irrelevant pages and to predict which
links lead to quality pages. In this paper a technique of effective focused
crawling is implemented to improve the quality of web navigation. To check the
similarity of web pages w.r.t. topic keywords a similarity function is used and
the priorities of extracted out links are also calculated based on meta data
and resultant pages generated from focused crawler. The proposed work also uses
a method for traversing the irrelevant pages that met during crawling to
improve the coverage of a specific topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5038</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5038</id><created>2009-06-27</created><authors><author><keyname>Naeem</keyname><forenames>Huma</forenames></author><author><keyname>Masood</keyname><forenames>Asif</forenames></author><author><keyname>Hussain</keyname><forenames>Mukhtar</forenames></author><author><keyname>Khan</keyname><forenames>Shoab A.</forenames></author></authors><title>A Novel Two-Stage Dynamic Decision Support based Optimal Threat
  Evaluation and Defensive Resource Scheduling Algorithm for Multi Air-borne
  threats</title><categories>cs.AI</categories><comments>8 Pages, International Journal of Computer Science and Information
  Security, IJCSIS</comments><journal-ref>IJCSIS June 2009 Issue, Vol.2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel two-stage flexible dynamic decision support based
optimal threat evaluation and defensive resource scheduling algorithm for
multi-target air-borne threats. The algorithm provides flexibility and
optimality by swapping between two objective functions, i.e. the preferential
and subtractive defense strategies as and when required. To further enhance the
solution quality, it outlines and divides the critical parameters used in
Threat Evaluation and Weapon Assignment (TEWA) into three broad categories
(Triggering, Scheduling and Ranking parameters). Proposed algorithm uses a
variant of many-to-many Stable Marriage Algorithm (SMA) to solve Threat
Evaluation (TE) and Weapon Assignment (WA) problem. In TE stage, Threat Ranking
and Threat-Asset pairing is done. Stage two is based on a new flexible dynamic
weapon scheduling algorithm, allowing multiple engagements using
shoot-look-shoot strategy, to compute near-optimal solution for a range of
scenarios. Analysis part of this paper presents the strengths and weaknesses of
the proposed algorithm over an alternative greedy algorithm as applied to
different offline scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5039</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5039</id><created>2009-06-27</created><authors><author><keyname>Jmaa</keyname><forenames>Ahmed Ben</forenames></author><author><keyname>Mahdi</keyname><forenames>Walid</forenames></author><author><keyname>Jemaa</keyname><forenames>Yousra Ben</forenames></author><author><keyname>Hamadou</keyname><forenames>Abdelmajid Ben</forenames></author></authors><title>A new approach for digit recognition based on hand gesture analysis</title><categories>cs.CV</categories><comments>8 Pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper a new approach for hand gesture analysis that allows
digit recognition. The analysis is based on extracting a set of features from a
hand image and then combining them by using an induction graph. The most
important features we extract from each image are the fingers locations, their
heights and the distance between each pair of fingers. Our approach consists of
three steps: (i) Hand detection and localization, (ii) fingers extraction and
(iii) features identification and combination to digit recognition. Each input
image is assumed to contain only one person, thus we apply a fuzzy classifier
to identify the skin pixels. In the finger extraction step, we attempt to
remove all the hand components except the fingers, this process is based on the
hand anatomy properties. The final step consists on representing histogram of
the detected fingers in order to extract features that will be used for digit
recognition. The approach is invariant to scale, rotation and translation of
the hand. Some experiments have been undertaken to show the effectiveness of
the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5040</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5040</id><created>2009-06-27</created><authors><author><keyname>Li</keyname><forenames>Chendong</forenames></author></authors><title>Towards the Patterns of Hard CSPs with Association Rule Mining</title><categories>cs.DB cs.AI</categories><comments>10 pages, 3 figures, submitted to ICDM'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hardness of finite domain Constraint Satisfaction Problems (CSPs) is a
very important research area in Constraint Programming (CP) community. However,
this problem has not yet attracted much attention from the researchers in the
association rule mining community. As a popular data mining technique,
association rule mining has an extremely wide application area and it has
already been successfully applied to many interdisciplines. In this paper, we
study the association rule mining techniques and propose a cascaded approach to
extract the interesting patterns of the hard CSPs. As far as we know, this
problem is investigated with the data mining techniques for the first time.
Specifically, we generate the random CSPs and collect their characteristics by
solving all the CSP instances, and then apply the data mining techniques on the
data set and further to discover the interesting patterns of the hardness of
the randomly generated CSPs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5050</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5050</id><created>2009-06-27</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Levin</keyname><forenames>Asaf</forenames></author></authors><title>AFPTAS results for common variants of bin packing: A new method to
  handle the small items</title><categories>cs.DS</categories><journal-ref>SIAM Journal on Optimization 20(6): 3121-3145 (2010)</journal-ref><doi>10.1137/090767613</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two well-known natural variants of bin packing, and show that
these packing problems admit asymptotic fully polynomial time approximation
schemes (AFPTAS). In bin packing problems, a set of one-dimensional items of
size at most 1 is to be assigned (packed) to subsets of sum at most 1 (bins).
It has been known for a while that the most basic problem admits an AFPTAS. In
this paper, we develop methods that allow to extend this result to other
variants of bin packing. Specifically, the problems which we study in this
paper, for which we design asymptotic fully polynomial time approximation
schemes, are the following. The first problem is &quot;Bin packing with cardinality
constraints&quot;, where a parameter k is given, such that a bin may contain up to k
items. The goal is to minimize the number of bins used. The second problem is
&quot;Bin packing with rejection&quot;, where every item has a rejection penalty
associated with it. An item needs to be either packed to a bin or rejected, and
the goal is to minimize the number of used bins plus the total rejection
penalty of unpacked items. This resolves the complexity of two important
variants of the bin packing problem. Our approximation schemes use a novel
method for packing the small items. This new method is the core of the improved
running times of our schemes over the running times of the previous results,
which are only asymptotic polynomial time approximation schemes (APTAS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5051</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5051</id><created>2009-06-27</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Levin</keyname><forenames>Asaf</forenames></author></authors><title>Bin packing with general cost structures</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following the work of Anily et al., we consider a variant of bin packing,
called &quot;bin packing with general cost structures&quot; (GCBP) and design an
asymptotic fully polynomial time approximation scheme (AFPTAS) for this
problem. In the classic bin packing problem, a set of one-dimensional items is
to be assigned to subsets of total size at most 1, that is, to be packed into
unit sized bins. However, in GCBP, the cost of a bin is not 1 as in classic bin
packing, but it is a non-decreasing and concave function of the number of items
packed in it, where the cost of an empty bin is zero. The construction of the
AFPTAS requires novel techniques for dealing with small items, which are
developed in this work. In addition, we develop a fast approximation algorithm
which acts identically for all non-decreasing and concave functions, and has an
asymptotic approximation ratio of 1.5 for all functions simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5060</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5060</id><created>2009-06-27</created><authors><author><keyname>Kalbande</keyname><forenames>Prof. Dhananjay R.</forenames></author><author><keyname>Thampi</keyname><forenames>Dr. G. T.</forenames></author><author><keyname>Singh</keyname><forenames>Mr. Manish</forenames></author></authors><title>Incidence Handling and Response System</title><categories>cs.CR</categories><comments>8 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computer network can be attacked in a number of ways. The security-related
threats have become not only numerous but also diverse and they may also come
in the form of blended attacks. It becomes difficult for any security system to
block all types of attacks. This gives rise to the need of an incidence
handling capability which is necessary for rapidly detecting incidents,
minimizing loss and destruction, mitigating the weaknesses that were exploited
and restoring the computing services. Incidence response has always been an
important aspect of information security but it is often overlooked by security
administrators. in this paper, we propose an automated system which will handle
the security threats and make the computer network capable enough to withstand
any kind of attack. we also present the state-of-the-art technology in
computer, network and software which is required to build such a system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5062</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5062</id><created>2009-06-29</created><updated>2009-07-01</updated><authors><author><keyname>Dube</keyname><forenames>Simant</forenames></author></authors><title>Geometrical Interpretation of the Master Theorem for Divide-and-conquer
  Recurrences</title><categories>cs.DS</categories><comments>11 pages, 6 figures</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide geometrical interpretation of the Master Theorem to solve
divide-and-conquer recurrences. We show how different cases of the recurrences
correspond to different kinds of fractal images. Fractal dimension and
Hausdorff measure are shown to be closely related to the solution of such
recurrences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5070</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5070</id><created>2009-06-27</created><authors><author><keyname>Thamilselvan</keyname><forenames>R.</forenames></author><author><keyname>Balasubramanie</keyname><forenames>Dr. P.</forenames></author></authors><title>Integrating Genetic Algorithm, Tabu Search Approach for Job Shop
  Scheduling</title><categories>cs.DS</categories><comments>6 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new algorithm based on integrating Genetic Algorithms
and Tabu Search methods to solve the Job Shop Scheduling problem. The idea of
the proposed algorithm is derived from Genetic Algorithms. Most of the
scheduling problems require either exponential time or space to generate an
optimal answer. Job Shop scheduling (JSS) is the general scheduling problem and
it is a NP-complete problem, but it is difficult to find the optimal solution.
This paper applies Genetic Algorithms and Tabu Search for Job Shop Scheduling
problem and compares the results obtained by each. With the implementation of
our approach the JSS problems reaches optimal solution and minimize the
makespan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5073</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5073</id><created>2009-06-27</created><authors><author><keyname>Avudaiammal</keyname><forenames>R.</forenames></author><author><keyname>SivaSubramanian</keyname><forenames>R.</forenames></author><author><keyname>Pandian</keyname><forenames>R.</forenames></author><author><keyname>Seethalakshmi</keyname><forenames>P.</forenames></author></authors><title>TTSS Packet Classification Algorithm to enhance Multimedia Applications
  in Network Processor based Router</title><categories>cs.MM</categories><comments>6 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to implement the Trie based Tuple Space
Search(TTSS) packet classification algorithm for Network Processor(NP) based
router to enhance multimedia applications. The performance is evaluated using
Intel IXP2400 NP Simulator. The results demonstrate that, TTSS has better
performance than Tuple Space Search algorithm and is well suited to achieve
high speed packet classification to support multimedia applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5089</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5089</id><created>2009-06-27</created><authors><author><keyname>Bansal</keyname><forenames>Mukul S.</forenames></author><author><keyname>Dong</keyname><forenames>Jianrong</forenames></author><author><keyname>Fern&#xe1;ndez-Baca</keyname><forenames>David</forenames></author></authors><title>Comparing and Aggregating Partially Resolved Trees</title><categories>cs.DS cs.DM</categories><comments>34 pages</comments><acm-class>F.2.2; G.2; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define, analyze, and give efficient algorithms for two kinds of distance
measures for rooted and unrooted phylogenies. For rooted trees, our measures
are based on the topologies the input trees induce on triplets; that is, on
three-element subsets of the set of species. For unrooted trees, the measures
are based on quartets (four-element subsets). Triplet and quartet-based
distances provide a robust and fine-grained measure of the similarities between
trees. The distinguishing feature of our distance measures relative to
traditional quartet and triplet distances is their ability to deal cleanly with
the presence of unresolved nodes, also called polytomies. For rooted trees,
these are nodes with more than two children; for unrooted trees, they are nodes
of degree greater than three.
  Our first class of measures are parametric distances, where there is a
parameter that weighs the difference between an unresolved triplet/quartet
topology and a resolved one. Our second class of measures are based on
Hausdorff distance. Each tree is viewed as a set of all possible ways in which
the tree could be refined to eliminate unresolved nodes. The distance between
the original (unresolved) trees is then taken to be the Hausdorff distance
between the associated sets of fully resolved trees, where the distance between
trees in the sets is the triplet or quartet distance, as appropriate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5106</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5106</id><created>2009-06-28</created><updated>2009-07-13</updated><authors><author><keyname>Hemmecke</keyname><forenames>Raymond</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author><author><keyname>Weismantel</keyname><forenames>Robert</forenames></author></authors><title>Multicommodity Flow in Polynomial Time</title><categories>math.CO cs.DM cs.DS math.OC</categories><msc-class>05A, 15A, 51M, 52A, 52B, 52C, 62H, 68Q, 68R, 68U, 68W, 90B, 90C</msc-class><journal-ref>Optimization Letters, 5:13--25, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multicommodity flow problem is NP-hard already for two commodities over
bipartite graphs. Nonetheless, using our recent theory of n-fold integer
programming and extensions developed herein, we are able to establish the
surprising polynomial time solvability of the problem in two broad situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5110</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5110</id><created>2009-06-27</created><authors><author><keyname>Jha</keyname><forenames>Susmit</forenames></author></authors><title>Statistical Analysis of Privacy and Anonymity Guarantees in Randomized
  Security Protocol Implementations</title><categories>cs.CR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security protocols often use randomization to achieve probabilistic
non-determinism. This non-determinism, in turn, is used in obfuscating the
dependence of observable values on secret data. Since the correctness of
security protocols is very important, formal analysis of security protocols has
been widely studied in literature. Randomized security protocols have also been
analyzed using formal techniques such as process-calculi and probabilistic
model checking. In this paper, we consider the problem of validating
implementations of randomized protocols. Unlike previous approaches which treat
the protocol as a white-box, our approach tries to verify an implementation
provided as a black box. Our goal is to infer the secrecy guarantees provided
by a security protocol through statistical techniques. We learn the
probabilistic dependency of the observable outputs on secret inputs using
Bayesian network. This is then used to approximate the leakage of secret. In
order to evaluate the accuracy of our statistical approach, we compare our
technique with the probabilistic model checking technique on two examples:
crowds protocol and dining crypotgrapher's protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5112</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5112</id><created>2009-06-28</created><updated>2015-03-14</updated><authors><author><keyname>Aslam</keyname><forenames>Javaid</forenames></author></authors><title>Response to Refutation of Aslam's Proof that NP = P</title><categories>cs.CC</categories><comments>Total 11 pages, including the figures. Have minimized the overlap,
  with only references to the main paper</comments><acm-class>F.2.0; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a further refinement to the previous response by
introducing new structures and algorithms for counting VMPs of common ER and
hence for counting the perfect matchings. The sequential time complexity of
this $\mathbf{\#P}$-complete problem is shown to be $O(n^{33})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5114</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5114</id><created>2009-06-27</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Non-Parametric Bayesian Areal Linguistics</title><categories>cs.CL</categories><journal-ref>Proceedings of the Conference of the North American Association
  for Computational Linguistics, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a statistical model over linguistic areas and phylogeny.
  Our model recovers known areas and identifies a plausible hierarchy of areal
features. The use of areas improves genetic reconstruction of languages both
qualitatively and quantitatively according to a variety of metrics. We model
linguistic areas by a Pitman-Yor process and linguistic phylogeny by Kingman's
coalescent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5119</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5119</id><created>2009-06-28</created><authors><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author><author><keyname>Osswald</keyname><forenames>Christophe</forenames><affiliation>E3I2</affiliation></author><author><keyname>Dezert</keyname><forenames>Jean</forenames><affiliation>ONERA</affiliation></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames><affiliation>UNM</affiliation></author></authors><title>General combination rules for qualitative and quantitative beliefs</title><categories>cs.AI</categories><proxy>ccsd hal-00399662</proxy><journal-ref>Journal of Advances in Information Fusion 3, 2 (2008) 67-89</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Martin and Osswald \cite{Martin07} have recently proposed many
generalizations of combination rules on quantitative beliefs in order to manage
the conflict and to consider the specificity of the responses of the experts.
Since the experts express themselves usually in natural language with
linguistic labels, Smarandache and Dezert \cite{Li07} have introduced a
mathematical framework for dealing directly also with qualitative beliefs. In
this paper we recall some element of our previous works and propose the new
combination rules, developed for the fusion of both qualitative or quantitative
beliefs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5120</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5120</id><created>2009-06-28</created><authors><author><keyname>Dezert</keyname><forenames>Jean</forenames><affiliation>ONERA</affiliation></author><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames><affiliation>UNM</affiliation></author></authors><title>Comments on &quot;A new combination of evidence based on compromise&quot; by K.
  Yamada</title><categories>cs.CV cs.AI</categories><proxy>ccsd hal-00399663</proxy><acm-class>I.4; I.5</acm-class><journal-ref>Fuzzy Sets and Systems 160, 6 (2009) 853-855</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comments on ``A new combination of evidence based on compromise'' by K.
Yamada
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5123</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5123</id><created>2009-06-28</created><authors><author><keyname>Garg</keyname><forenames>Poonam</forenames></author></authors><title>Cryptanalysis of SDES via evolutionary computation techniques</title><categories>cs.CR</categories><comments>7 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS May 2009 Issue, Vol. 1, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cryptanalysis of simplified data encryption standard can be formulated as
NP-Hard combinatorial problem. The goal of this paper is two fold. First we
want to make a study about how evolutionary computation techniques can
efficiently solve the NP-Hard combinatorial problem. For achieving this goal we
test several evolutionary computation techniques like memetic algorithm,
genetic algorithm and simulated annealing for the cryptanalysis of simplified
data encryption standard problem (SDES). And second was a comparison between
memetic algorithm, genetic algorithm and simulated annealing were made in order
to investigate the performance for the cryptanalysis on SDES. The methods were
tested and extensive computational results show that memetic algorithm performs
better than genetic algorithms and simulated annealing for such type of NP-Hard
combinatorial problem. This paper represents our first effort toward efficient
memetic algorithm for the cryptanalysis of SDES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5131</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5131</id><created>2009-06-28</created><updated>2009-06-30</updated><authors><author><keyname>Kafri</keyname><forenames>Oded</forenames></author></authors><title>A Comment on Nonextensive Statistical Mechanics</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a conception that Boltzmann-Gibbs statistics cannot yield the long
tail distribution. This is the justification for the intensive research of
nonextensive entropies (i.e. Tsallis entropy and others). Here the error that
caused this misconception is explained and it is shown that a long tail
distribution exists in equilibrium thermodynamics for more than a century.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5148</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5148</id><created>2009-06-29</created><authors><author><keyname>De Bie</keyname><forenames>Tijl</forenames></author></authors><title>Explicit probabilistic models for databases and networks</title><categories>cs.AI cs.DB cs.IT math.IT</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work in data mining and related areas has highlighted the importance
of the statistical assessment of data mining results. Crucial to this endeavour
is the choice of a non-trivial null model for the data, to which the found
patterns can be contrasted. The most influential null models proposed so far
are defined in terms of invariants of the null distribution. Such null models
can be used by computation intensive randomization approaches in estimating the
statistical significance of data mining results.
  Here, we introduce a methodology to construct non-trivial probabilistic
models based on the maximum entropy (MaxEnt) principle. We show how MaxEnt
models allow for the natural incorporation of prior information. Furthermore,
they satisfy a number of desirable properties of previously introduced
randomization approaches. Lastly, they also have the benefit that they can be
represented explicitly. We argue that our approach can be used for a variety of
data types. However, for concreteness, we have chosen to demonstrate it in
particular for databases and networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5151</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5151</id><created>2009-06-28</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Unsupervised Search-based Structured Prediction</title><categories>cs.LG</categories><journal-ref>Proceedings of the International Conference on Machine Learning,
  2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an adaptation and application of a search-based structured
prediction algorithm &quot;Searn&quot; to unsupervised learning problems. We show that it
is possible to reduce unsupervised learning to supervised learning and
demonstrate a high-quality unsupervised shift-reduce parsing model. We
additionally show a close connection between unsupervised Searn and expectation
maximization. Finally, we demonstrate the efficacy of a semi-supervised
extension. The key idea that enables this is an application of the predict-self
idea for unsupervised learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5181</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5181</id><created>2009-06-28</created><updated>2012-04-26</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author><author><keyname>Debbabi</keyname><forenames>Mourad</forenames></author></authors><title>Reasoning About a Simulated Printer Case Investigation with Forensic
  Lucid</title><categories>cs.LO cs.CR cs.PL</categories><comments>18 pages, 3 figures, 7 listings, TOC, index; this article closely
  relates to arXiv:0906.0049 and arXiv:0904.3789 but to remain stand-alone
  repeats some of the background and introductory content; abstract presented
  at HSC'09 and the full updated paper at ICDF2C'11. This is an updated/edited
  version after ICDF2C proceedings with more references and corrections</comments><acm-class>D.3.1; D.3.2; D.3.3; D.3.4</acm-class><journal-ref>S. A. Mokhov, J. Paquet, and M. Debbabi. Reasoning about a
  simulated printer case investigation with Forensic Lucid. In P. Gladyshev and
  M. K. Rogers, editors, Proceedings of ICDF2C'11, number 0088 in LNICST, pp.
  282-296. Springer, 2012</journal-ref><doi>10.1007/978-3-642-35515-8_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we model the ACME (a fictitious company name) &quot;printer case
incident&quot; and make its specification in Forensic Lucid, a Lucid- and
intensional-logic-based programming language for cyberforensic analysis and
event reconstruction specification. The printer case involves a dispute between
two parties that was previously solved using the finite-state automata (FSA)
approach, and is now re-done in a more usable way in Forensic Lucid. Our
simulation is based on the said case modeling by encoding concepts like
evidence and the related witness accounts as an evidential statement context in
a Forensic Lucid program, which is an input to the transition function that
models the possible deductions in the case. We then invoke the transition
function (actually its reverse) with the evidential statement context to see if
the evidence we encoded agrees with one's claims and then attempt to
reconstruct the sequence of events that may explain the claim or disprove it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5202</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5202</id><created>2009-06-29</created><updated>2009-11-03</updated><authors><author><keyname>Rudoy</keyname><forenames>Daniel</forenames></author><author><keyname>Basu</keyname><forenames>Prabahan</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author></authors><title>Superposition frames for adaptive time-frequency analysis and fast
  reconstruction</title><categories>math.NA cs.SD</categories><comments>16 pages, 6 figures; revised version</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 58, pp. 2581-2596,
  2010</journal-ref><doi>10.1109/TSP.2010.2041604</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we introduce a broad family of adaptive, linear
time-frequency representations termed superposition frames, and show that they
admit desirable fast overlap-add reconstruction properties akin to standard
short-time Fourier techniques. This approach stands in contrast to many
adaptive time-frequency representations in the extant literature, which, while
more flexible than standard fixed-resolution approaches, typically fail to
provide efficient reconstruction and often lack the regular structure necessary
for precise frame-theoretic analysis. Our main technical contributions come
through the development of properties which ensure that this construction
provides for a numerically stable, invertible signal representation. Our
primary algorithmic contributions come via the introduction and discussion of
specific signal adaptation criteria in deterministic and stochastic settings,
based respectively on time-frequency concentration and nonstationarity
detection. We conclude with a short speech enhancement example that serves to
highlight potential applications of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5233</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5233</id><created>2009-06-29</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Restricted Global Grammar Constraints</title><categories>cs.AI cs.FL</categories><comments>Proceedings of the 15th International Conference on Principles and
  Practice of Constraint Programming, Lisbon, Portugal. September 2009</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the global GRAMMAR constraint over restricted classes of
context free grammars like deterministic and unambiguous context-free grammars.
We show that detecting disentailment for the GRAMMAR constraint in these cases
is as hard as parsing an unrestricted context free grammar.We also consider the
class of linear grammars and give a propagator that runs in quadratic time.
Finally, to demonstrate the use of linear grammars, we show that a weighted
linear GRAMMAR constraint can efficiently encode the EDITDISTANCE constraint,
and a conjunction of the EDITDISTANCE constraint and the REGULAR constraint
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5278</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5278</id><created>2009-06-29</created><authors><author><keyname>Vasiloglou</keyname><forenames>Nikolaos</forenames></author><author><keyname>Maragos</keyname><forenames>Petros</forenames></author></authors><title>Spectrum of Fractal Interpolation Functions</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we compute the Fourier spectrum of the Fractal Interpolation
Functions FIFs as introduced by Michael Barnsley. We show that there is an
analytical way to compute them. In this paper we attempt to solve the inverse
problem of FIF by using the spectrum
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5286</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5286</id><created>2009-06-29</created><authors><author><keyname>Gansner</keyname><forenames>Emden</forenames></author><author><keyname>Hu</keyname><forenames>Yifan</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen</forenames></author><author><keyname>Volinsky</keyname><forenames>Chris</forenames></author></authors><title>Putting Recommendations on the Map -- Visualizing Clusters and Relations</title><categories>cs.IR</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For users, recommendations can sometimes seem odd or counterintuitive.
Visualizing recommendations can remove some of this mystery, showing how a
recommendation is grouped with other choices. A drawing can also lead a user's
eye to other options. Traditional 2D-embeddings of points can be used to create
a basic layout, but these methods, by themselves, do not illustrate clusters
and neighborhoods very well. In this paper, we propose the use of geographic
maps to enhance the definition of clusters and neighborhoods, and consider the
effectiveness of this approach in visualizing similarities and recommendations
arising from TV shows and music selections. All the maps referenced in this
paper can be found in http://www.research.att.com/~volinsky/maps
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5289</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5289</id><created>2009-06-29</created><authors><author><keyname>Ezri</keyname><forenames>Doron</forenames></author><author><keyname>Shilo</keyname><forenames>Shimi</forenames></author></authors><title>Green Cellular - Optimizing the Cellular Network for Minimal Emission
  from Mobile Stations</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless systems, which include cellular phones, have become an essential
part of the modern life. However the mounting evidence that cellular radiation
might adversely affect the health of its users, leads to a growing concern
among authorities and the general public. Radiating antennas in the proximity
of the user, such as antennas of mobile phones are of special interest for this
matter. In this paper we suggest a new architecture for wireless networks,
aiming at minimal emission from mobile stations, without any additional
radiation sources. The new architecture, dubbed Green Cellular, abandons the
classical transceiver base station design and suggests the augmentation of
transceiver base stations with receive only devices. These devices, dubbed
Green Antennas, are not aiming at coverage extension but rather at minimizing
the emission from mobile stations. We discuss the implications of the Green
Cellular architecture on 3G and 4G cellular technologies. We conclude by
showing that employing the Green Cellular approach may lead to a significant
decrease in the emission from mobile stations, especially in indoor scenarios.
This is achieved without exposing the user to any additional radiation source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5325</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5325</id><created>2009-06-29</created><authors><author><keyname>Mastronarde</keyname><forenames>Nicholas</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Online Reinforcement Learning for Dynamic Multimedia Systems</title><categories>cs.LG cs.MM</categories><comments>35 pages, 11 figures, 10 tables</comments><journal-ref>IEEE Trans. on Image Processing, vol. 19, no. 2, pp. 290-305, Feb.
  2010</journal-ref><doi>10.1109/TIP.2009.2035228</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our previous work, we proposed a systematic cross-layer framework for
dynamic multimedia systems, which allows each layer to make autonomous and
foresighted decisions that maximize the system's long-term performance, while
meeting the application's real-time delay constraints. The proposed solution
solved the cross-layer optimization offline, under the assumption that the
multimedia system's probabilistic dynamics were known a priori. In practice,
however, these dynamics are unknown a priori and therefore must be learned
online. In this paper, we address this problem by allowing the multimedia
system layers to learn, through repeated interactions with each other, to
autonomously optimize the system's long-term performance at run-time. We
propose two reinforcement learning algorithms for optimizing the system under
different design constraints: the first algorithm solves the cross-layer
optimization in a centralized manner, and the second solves it in a
decentralized manner. We analyze both algorithms in terms of their required
computation, memory, and inter-layer communication overheads. After noting that
the proposed reinforcement learning algorithms learn too slowly, we introduce a
complementary accelerated learning algorithm that exploits partial knowledge
about the system's dynamics in order to dramatically improve the system's
performance. In our experiments, we demonstrate that decentralized learning can
perform as well as centralized learning, while enabling the layers to act
autonomously. Additionally, we show that existing application-independent
reinforcement learning algorithms, and existing myopic learning algorithms
deployed in multimedia systems, perform significantly worse than our proposed
application-aware and foresighted learning methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5339</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5339</id><created>2009-06-29</created><updated>2009-11-29</updated><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>Asymmetric Quantum Cyclic Codes</title><categories>cs.IT cs.MS math.IT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is recently conjectured in quantum information processing that phase-shift
errors occur with high probability than qubit-flip errors, hence the former is
more disturbing to quantum information than the later one. This leads us to
construct asymmetric quantum error controlling codes to protect quantum
information over asymmetric channels, $\Pr Z \geq \Pr X$. In this paper we
present two generic methods to derive asymmetric quantum cyclic codes using the
generator polynomials and defining sets of classical cyclic codes.
Consequently, the methods allow us to construct several families of asymmetric
quantum BCH, RS, and RM codes. Finally, the methods are used to construct
families of asymmetric subsystem codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5393</identifier>
 <datestamp>2009-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5393</id><created>2009-06-29</created><authors><author><keyname>Malik</keyname><forenames>Nasir Mahmood</forenames></author><author><keyname>Mushtaq</keyname><forenames>Arif</forenames></author><author><keyname>Khalid</keyname><forenames>Samina</forenames></author><author><keyname>Khalil</keyname><forenames>Tehmina</forenames></author><author><keyname>Malik</keyname><forenames>Faisal Munir</forenames></author></authors><title>Measurable &amp; Scalable NFRs using Fuzzy Logic and Likert Scale</title><categories>cs.SE</categories><comments>5 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the research related to Non Functional Requirements (NFRs) have
presented NFRs frameworks by integrating non functional requirements with
functional requirements while we proposed that measurement of NFRs is possible
e.g. cost and performance and NFR like usability can be scaled. Our novel
hybrid approach integrates three things rather than two i.e. Functional
Requirements (FRs), Measurable NFRs (M-NFRs) and Scalable NFRs (S-NFRs). We
have also found the use of Fuzzy Logic and Likert Scale effective for handling
of discretely measurable as well as scalable NFRs as these techniques can
provide a simple way to arrive at a discrete or scalable NFR in contrast to
vague, ambiguous, imprecise, noisy or missing NFR. Our approach can act as
baseline for new NFR and aspect oriented frameworks by using all types of UML
diagrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5394</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5394</id><created>2009-06-29</created><updated>2011-02-25</updated><authors><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Wireless Network Information Flow: A Deterministic Approach</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE transactions on Information Theory, Vol 57, No 4,
  April 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a wireless network with a single source and a single destination and an
arbitrary number of relay nodes, what is the maximum rate of information flow
achievable? We make progress on this long standing problem through a two-step
approach. First we propose a deterministic channel model which captures the key
wireless properties of signal strength, broadcast and superposition. We obtain
an exact characterization of the capacity of a network with nodes connected by
such deterministic channels. This result is a natural generalization of the
celebrated max-flow min-cut theorem for wired networks. Second, we use the
insights obtained from the deterministic analysis to design a new
quantize-map-and-forward scheme for Gaussian networks. In this scheme, each
relay quantizes the received signal at the noise level and maps it to a random
Gaussian codeword for forwarding, and the final destination decodes the
source's message based on the received signal. We show that, in contrast to
existing schemes, this scheme can achieve the cut-set upper bound to within a
gap which is independent of the channel parameters. In the case of the relay
channel with a single relay as well as the two-relay Gaussian diamond network,
the gap is 1 bit/s/Hz. Moreover, the scheme is universal in the sense that the
relays need no knowledge of the values of the channel parameters to
(approximately) achieve the rate supportable by the network. We also present
extensions of the results to multicast networks, half-duplex networks and
ergodic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5397</identifier>
 <datestamp>2009-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5397</id><created>2009-06-29</created><authors><author><keyname>Lee</keyname><forenames>Juyul</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Asymptotically Optimal Policies for Hard-deadline Scheduling over Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>24 pages, 9 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hard-deadline, opportunistic scheduling problem in which $B$ bits must be
transmitted within $T$ time-slots over a time-varying channel is studied: the
transmitter must decide how many bits to serve in each slot based on knowledge
of the current channel but without knowledge of the channel in future slots,
with the objective of minimizing expected transmission energy. In order to
focus on the effects of delay and fading, we assume that no other packets are
scheduled simultaneously and no outage is considered. We also assume that the
scheduler can transmit at capacity where the underlying noise channel is
Gaussian such that the energy-bit relation is a Shannon-type exponential
function. No closed form solution for the optimal policy is known for this
problem, which is naturally formulated as a finite-horizon dynamic program, but
three different policies are shown to be optimal in the limiting regimes where
$T$ is fixed and $B$ is large, $T$ is fixed and $B$ is small, and where $B$ and
$T$ are simultaneously taken to infinity. In addition, the advantage of optimal
scheduling is quantified relative to a non-opportunistic (i.e., channel-blind)
equal-bit policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5418</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5418</id><created>2009-06-30</created><updated>2009-11-25</updated><authors><author><keyname>Gentil-Beccot</keyname><forenames>Anne</forenames></author><author><keyname>Mele</keyname><forenames>Salvatore</forenames></author><author><keyname>Brooks</keyname><forenames>Travis</forenames></author></authors><title>Citing and Reading Behaviours in High-Energy Physics. How a Community
  Stopped Worrying about Journals and Learned to Love Repositories</title><categories>cs.DL</categories><comments>Version to be published in Scientometrics</comments><report-no>CERN-OPEN-2009-012, SLAC-PUB-13693</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contemporary scholarly discourse follows many alternative routes in addition
to the three-century old tradition of publication in peer-reviewed journals.
The field of High- Energy Physics (HEP) has explored alternative communication
strategies for decades, initially via the mass mailing of paper copies of
preliminary manuscripts, then via the inception of the first online
repositories and digital libraries.
  This field is uniquely placed to answer recurrent questions raised by the
current trends in scholarly communication: is there an advantage for scientists
to make their work available through repositories, often in preliminary form?
Is there an advantage to publishing in Open Access journals? Do scientists
still read journals or do they use digital repositories?
  The analysis of citation data demonstrates that free and immediate online
dissemination of preprints creates an immense citation advantage in HEP,
whereas publication in Open Access journals presents no discernible advantage.
In addition, the analysis of clickstreams in the leading digital library of the
field shows that HEP scientists seldom read journals, preferring preprints
instead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5446</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5446</id><created>2009-06-30</created><authors><author><keyname>Hirschkoff</keyname><forenames>Daniel</forenames><affiliation>LIP</affiliation></author><author><keyname>Pardon</keyname><forenames>Aur&#xe9;lien</forenames><affiliation>LIP</affiliation></author><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LAMA</affiliation></author><author><keyname>Hym</keyname><forenames>Samuel</forenames><affiliation>LIFL</affiliation></author><author><keyname>Pous</keyname><forenames>Damien</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>Encapsulation and Dynamic Modularity in the Pi-Calculus</title><categories>cs.PL</categories><proxy>ccsd hal-00400159</proxy><journal-ref>PLACES 2008, Oslo : Norv\`ege (2008)</journal-ref><doi>10.1016/j.entcs.2009.06.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a process calculus featuring high level constructs for
component-oriented programming in a distributed setting. We propose an
extension of the higher-order pi-calculus intended to capture several important
mechanisms related to component-based programming, such as dynamic update,
reconfiguration and code migration. In this paper, we are primarily concerned
with the possibility to build a distributed implementation of our calculus.
Accordingly, we define a low-level calculus, that describes how the high-level
constructs are implemented, as well as details of the data structures
manipulated at runtime. We also discuss current and future directions of
research in relation to our analysis of component-based programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5450</identifier>
 <datestamp>2009-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5450</id><created>2009-06-30</created><authors><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author><author><keyname>Hassan</keyname><forenames>Sk. Sarif</forenames></author><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author><author><keyname>Nayak</keyname><forenames>Birendra Kumar</forenames></author></authors><title>Theory of Rule 6 and its Application to Round Robin Tournament</title><categories>cs.DM cs.GT</categories><comments>Related to Scheduling Problems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have used one 2 variable Boolean function called Rule 6 to
define another beautiful transformation named as Extended Rule-6. Using this
function we have explored the algebraic beauties and its application to an
efficient Round Robin Tournament (RRT) routine for 2k (k is any natural number)
number of teams. At the end, we have thrown some light towards any number of
teams of the form nk where n, k are natural numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5475</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5475</id><created>2009-06-30</created><authors><author><keyname>Kim</keyname><forenames>Yong-Hyuk</forenames></author><author><keyname>Yoon</keyname><forenames>Yourim</forenames></author></authors><title>A Note on Mathematical Modelling of Practical Multicampaign Assignment
  and Its Computational Complexity</title><categories>cs.CC cs.OH</categories><comments>14 pages, 1 figure</comments><journal-ref>Proceedings of the 2010 ACM Symposium on Applied Computing (SAC),
  pages 94-98, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within personalized marketing, a recommendation issue known as multicampaign
assignment is to overcome a critical problem, known as the multiple
recommendation problem which occurs when running several personalized campaigns
simultaneously. This paper mainly deals with the hardness of multicampaign
assignment, which is treated as a very challenging problem in marketing. The
objective in this problem is to find a customer-campaign matrix which maximizes
the effectiveness of multiple campaigns under some constraints. We present a
realistic response suppression function, which is designed to be more
practical, and explain how this can be learned from historical data. Moreover,
we provide a proof that this more realistic version of the problem is NP-hard,
thus justifying to use of heuristics presented in previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5485</identifier>
 <datestamp>2009-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5485</id><created>2009-06-30</created><authors><author><keyname>Ojala</keyname><forenames>Markus</forenames></author><author><keyname>Garriga</keyname><forenames>Gemma C.</forenames></author><author><keyname>Gionis</keyname><forenames>Aristides</forenames></author><author><keyname>Mannila</keyname><forenames>Heikki</forenames></author></authors><title>Query Significance in Databases via Randomizations</title><categories>cs.DB cs.AI</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many sorts of structured data are commonly stored in a multi-relational
format of interrelated tables. Under this relational model, exploratory data
analysis can be done by using relational queries. As an example, in the
Internet Movie Database (IMDb) a query can be used to check whether the average
rank of action movies is higher than the average rank of drama movies.
  We consider the problem of assessing whether the results returned by such a
query are statistically significant or just a random artifact of the structure
in the data. Our approach is based on randomizing the tables occurring in the
queries and repeating the original query on the randomized tables. It turns out
that there is no unique way of randomizing in multi-relational data. We propose
several randomization techniques, study their properties, and show how to find
out which queries or hypotheses about our data result in statistically
significant information. We give results on real and generated data and show
how the significance of some queries vary between different randomizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5488</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5488</id><created>2009-06-30</created><updated>2009-08-09</updated><authors><author><keyname>M&#xf8;gelberg</keyname><forenames>Rasmus Ejlers</forenames></author><author><keyname>Simpson</keyname><forenames>Alex</forenames></author></authors><title>Relational Parametricity for Computational Effects</title><categories>cs.PL cs.LO</categories><comments>31 pages, appears in Logical Methods in Computer Science</comments><acm-class>F.3.2; D.3.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (August 9,
  2009) lmcs:1113</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to Strachey, a polymorphic program is parametric if it applies a
uniform algorithm independently of the type instantiations at which it is
applied. The notion of relational parametricity, introduced by Reynolds, is one
possible mathematical formulation of this idea. Relational parametricity
provides a powerful tool for establishing data abstraction properties, proving
equivalences of datatypes, and establishing equalities of programs. Such
properties have been well studied in a pure functional setting. Many programs,
however, exhibit computational effects, and are not accounted for by the
standard theory of relational parametricity. In this paper, we develop a
foundational framework for extending the notion of relational parametricity to
programming languages with effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5561</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5561</id><created>2009-06-30</created><updated>2009-10-20</updated><authors><author><keyname>Lu</keyname><forenames>Hongyu</forenames></author><author><keyname>Wu</keyname><forenames>Chongguang</forenames></author><author><keyname>Bao</keyname><forenames>Shanglian</forenames></author></authors><title>An Improved Algorithm based on Shannon-Happ Formula for Calculating
  Transfer Function from Signal Flow Graph and Its Visualization</title><categories>cs.NA cs.SC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A new method based on Shannon-Happ formula to calculate transfer function
from Signal Flow Graph (SFG) is presented. The algorithm provides an explicit
approach to get the transfer function in a format with both numerical and
symbolic expressions. The adoption of the symbolic variable in SFG, which could
represent the nonlinear item or the independent sub-system, is achieved by
variable separation approach. An investigation is given for the solutions of
several special conditions of SFG. To improve the efficiency of the algorithm,
a new technique combined with Johnson method for generating the combinations of
the non-touching loops is developed. It uses the previous combinations in lower
order to get the ones in higher order. There is an introduction about the
visualization of SFG and the subroutines for system performance analysis in the
software, AVANT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5596</identifier>
 <datestamp>2009-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5596</id><created>2009-06-30</created><authors><author><keyname>Mehmood</keyname><forenames>Zaigham</forenames></author><author><keyname>Saeed</keyname><forenames>Saqib</forenames></author></authors><title>Teaching Quality Assurance and Project Management to Undergraduate
  Computing Students in Pakistan</title><categories>cs.CY cs.SE</categories><comments>This paper was published in the proceedings of 4th International
  Conference on Business Management and Economics 2008 Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software Project Management (SPM) and Software Quality Assurance (SQA) are
key components of undergraduate Computing programmes at educational
establishments in Pakistan. Because of the nature of these subjects, there are
a number of issues that need to be discussed and resolved so that the teaching
becomes more effective, students learning experience is more enjoyable and
their ability to be actively involved in SPM and SQA, after the completion of
their studies, becomes further improved. In this paper, we discuss experience
of teaching SPM and SQA at one particular institution in Islamabad Pakistan.
Using this as a case study, we underline the students perspective, highlight
the inherent issues and suggest ways to improve the delivery of these subjects.
Since, the issues are mainly generic, the aim is to provide discussion and
recommendations to benefit a wider computing community in academia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.5608</identifier>
 <datestamp>2012-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.5608</id><created>2009-06-30</created><authors><author><keyname>Saeed</keyname><forenames>Saqib</forenames></author><author><keyname>Kunz</keyname><forenames>Christoph</forenames></author></authors><title>Loading Arbitrary Knowledge Bases in Matrix Browser</title><categories>cs.IR cs.DB</categories><comments>This paper was published in the proceedings of IEEE International
  Multi Topic Conference (INMIC 2004) Lahore, Pakistan 24th- 26th December 2004</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the work done on Matrix Browser, which is a recently
developed graphical user interface to explore and navigate complex networked
information spaces. This approach presents a new way of navigating information
nets in windows explorer like widget. The problem on hand was how to export
arbitrary knowledge bases in Matrix Browser. This was achieved by identifying
the relationships present in knowledge bases and then by forming the
hierarchies from this data and these hierarchies are being exported to matrix
browser. This paper gives solution to this problem and informs about
implementation work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0001</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0001</id><created>2009-06-30</created><updated>2011-05-02</updated><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author></authors><title>On weight distributions of perfect colorings and completely regular
  codes</title><categories>math.CO cs.IT math.IT</categories><comments>17pp; partially presented at &quot;Optimal Codes and Related Topics&quot;
  OC2009, Varna (Bulgaria). V.2: the title was changed (old: &quot;On weight
  distributions of perfect structures&quot;), Sect.5 &quot;Weight enumerators ...&quot; was
  added</comments><msc-class>05B99</msc-class><journal-ref>Des. Codes Cryptogr. 61(3) 2011, 315-329</journal-ref><doi>10.1007/s10623-010-9479-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vertex coloring of a graph is called &quot;perfect&quot; if for any two colors $a$
and $b$, the number of the color-$b$ neighbors of a color-$a$ vertex $x$ does
not depend on the choice of $x$, that is, depends only on $a$ and $b$ (the
corresponding partition of the vertex set is known as &quot;equitable&quot;). A set of
vertices is called &quot;completely regular&quot; if the coloring according to the
distance from this set is perfect. By the &quot;weight distribution&quot; of some
coloring with respect to some set we mean the information about the number of
vertices of every color at every distance from the set. We study the weight
distribution of a perfect coloring (equitable partition) of a graph with
respect to a completely regular set (in particular, with respect to a vertex if
the graph is distance-regular). We show how to compute this distribution by the
knowledge of the color composition over the set. For some partial cases of
completely regular sets, we derive explicit formulas of weight distributions.
Since any (other) completely regular set itself generates a perfect coloring,
this gives universal formulas for calculating the weight distribution of any
completely regular set from its parameters. In the case of Hamming graphs, we
prove a very simple formula for the weight enumerator of an arbitrary perfect
coloring. Codewords: completely regular code; equitable partition; partition
design; perfect coloring; perfect structure; regular partition; weight
distribution; weight enumerator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0002</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0002</id><created>2009-07-01</created><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author></authors><title>On the binary codes with parameters of doubly-shortened 1-perfect codes</title><categories>math.CO cs.IT math.IT</categories><comments>12pp</comments><msc-class>94B25</msc-class><journal-ref>Des. Codes Cryptogr. 57(2) 2010, 181-194</journal-ref><doi>10.1007/s10623-009-9360-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any binary $(n=2^m-3, 2^{n-m}, 3)$ code $C_1$ is a part of an
equitable partition (perfect coloring) $\{C_1,C_2,C_3,C_4\}$ of the $n$-cube
with the parameters $((0,1,n-1,0)(1,0,n-1,0)(1,1,n-4,2)(0,0,n-1,1))$. Now the
possibility to lengthen the code $C_1$ to a 1-perfect code of length $n+2$ is
equivalent to the possibility to split the part $C_4$ into two distance-3 codes
or, equivalently, to the biparticity of the graph of distances 1 and 2 of
$C_4$. In any case, $C_1$ is uniquely embeddable in a twofold 1-perfect code of
length $n+2$ with some structural restrictions, where by a twofold 1-perfect
code we mean that any vertex of the space is within radius 1 from exactly two
codewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0049</identifier>
 <datestamp>2009-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0049</id><created>2009-06-30</created><authors><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>Xing</keyname><forenames>Lijuan</forenames></author></authors><title>No More Perfect Codes: Classification of Perfect Quantum Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>3 pages, no figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the problem of the classification of perfect quantum codes. We prove
that the only nontrivial perfect quantum codes are those with the parameters .
There exist no other nontrivial perfect quantum codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0067</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0067</id><created>2009-07-01</created><authors><author><keyname>Naeem</keyname><forenames>Huma</forenames></author><author><keyname>Masood</keyname><forenames>Asif</forenames></author><author><keyname>Hussain</keyname><forenames>Mukhtar</forenames></author><author><keyname>Khan</keyname><forenames>Shoab A.</forenames></author></authors><title>A Novel Two-Staged Decision Support based Threat Evaluation and Weapon
  Assignment Algorithm, Asset-based Dynamic Weapon Scheduling using Artificial
  Intelligence Techinques</title><categories>cs.AI</categories><comments>7 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surveillance control and reporting (SCR) system for air threats play an
important role in the defense of a country. SCR system corresponds to air and
ground situation management/processing along with information fusion,
communication, coordination, simulation and other critical defense oriented
tasks. Threat Evaluation and Weapon Assignment (TEWA) sits at the core of SCR
system. In such a system, maximal or near maximal utilization of constrained
resources is of extreme importance. Manual TEWA systems cannot provide
optimality because of different limitations e.g.surface to air missile (SAM)
can fire from a distance of 5Km, but manual TEWA systems are constrained by
human vision range and other constraints. Current TEWA systems usually work on
target-by-target basis using some type of greedy algorithm thus affecting the
optimality of the solution and failing in multi-target scenario. his paper
relates to a novel two-staged flexible dynamic decision support based optimal
threat evaluation and weapon assignment algorithm for multi-target air-borne
threats.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0075</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0075</id><created>2009-07-01</created><authors><author><keyname>Mahini</keyname><forenames>Hamidreza</forenames></author><author><keyname>Mahini</keyname><forenames>Alireza</forenames></author><author><keyname>Ghofrani</keyname><forenames>Javad</forenames></author></authors><title>XDANNG: XML based Distributed Artificial Neural Network with Globus
  Toolkit</title><categories>cs.NE</categories><comments>8 pages, international journal of computer science and information
  security</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2 No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial Neural Network is one of the most common AI application fields.
This field has direct and indirect usages most sciences. The main goal of ANN
is to imitate biological neural networks for solving scientific problems. But
the level of parallelism is the main problem of ANN systems in comparison with
biological systems. To solve this problem, we have offered a XML-based
framework for implementing ANN on the Globus Toolkit Platform. Globus Toolkit
is well known management software for multipurpose Grids. Using the Grid for
simulating the neuron network will lead to a high degree of parallelism in the
implementation of ANN. We have used the XML for improving flexibility and
scalability in our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0088</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0088</id><created>2009-07-01</created><authors><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author><author><keyname>Mehrabi</keyname><forenames>Ali D.</forenames></author><author><keyname>B</keyname><forenames>Fatemeh Raee</forenames></author></authors><title>On Unique Independence Weighted Graphs</title><categories>cs.CC cs.DM</categories><comments>9 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An independent set in a graph G is a set of vertices no two of which are
joined by an edge. A vertex-weighted graph associates a weight with every
vertex in the graph. A vertex-weighted graph G is called a unique independence
vertex-weighted graph if it has a unique independent set with maximum sum of
weights. Although, in this paper we observe that the problem of recognizing
unique independence vertex-weighted graphs is NP-hard in general and therefore
no efficient characterization can be expected in general; we give, however,
some combinatorial characterizations of unique independence vertex-weighted
graphs. This paper introduces a motivating application of this problem in the
area of combinatorial auctions, as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0138</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0138</id><created>2009-07-01</created><updated>2010-03-11</updated><authors><author><keyname>Engelbeen</keyname><forenames>Celine</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Kiesel</keyname><forenames>Antje</forenames></author></authors><title>A closest vector problem arising in radiation therapy planning</title><categories>cs.DM math.OC</categories><comments>Major revision.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of finding a vector that can be written
as a nonnegative integer linear combination of given 0-1 vectors, the
generators, such that the l_1-distance between this vector and a given target
vector is minimized. We prove that this closest vector problem is NP-hard to
approximate within a O(d) additive error, where d is the dimension of the
ambient vector space. We show that the problem can be approximated within a
O(d^{3/2}) additive error in polynomial time, by rounding an optimal solution
of a natural LP relaxation for the problem. We also observe that in the
particular case where the target vector is integer and the generators form a
totally unimodular matrix, the problem can be solved in polynomial time.
  The closest vector problem arises in the elaboration of radiation therapy
plans. In this context, the target is a nonnegative integer matrix and the
generators are certain 0-1 matrices whose rows satisfy the consecutive ones
property. Here we mainly consider the version of the problem in which the set
of generators comprises all those matrices that have on each nonzero row a
number of ones that is at least a certain constant. This set of generators
encodes the so-called minimum separation constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0159</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0159</id><created>2009-07-01</created><updated>2009-07-03</updated><authors><author><keyname>Rampersad</keyname><forenames>N.</forenames></author><author><keyname>Shallit</keyname><forenames>J.</forenames></author><author><keyname>Xu</keyname><forenames>Z.</forenames></author></authors><title>The computational complexity of universality problems for prefixes,
  suffixes, factors, and subwords of regular languages</title><categories>cs.FL cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the computational complexity of the following
problems: given a DFA or NFA representing a regular language L over a finite
alphabet Sigma is the set of all prefixes (resp., suffixes, factors, subwords)
of all words of L equal to Sigma*? In the case of testing universality for
factors of languages represented by DFA's, we find an interesting connection to
Cerny's conjecture on synchronizing words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0204</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0204</id><created>2009-07-01</created><authors><author><keyname>Hamarneh</keyname><forenames>Ghassan</forenames></author></authors><title>Multi-Label MRF Optimization via Least Squares s-t Cuts</title><categories>cs.CV</categories><report-no>SFU-CMPT-TR 2009-08</report-no><acm-class>I.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many applications of graph cuts in computer vision, e.g.
segmentation. We present a novel method to reformulate the NP-hard, k-way graph
partitioning problem as an approximate minimal s-t graph cut problem, for which
a globally optimal solution is found in polynomial time. Each non-terminal
vertex in the original graph is replaced by a set of ceil(log_2(k)) new
vertices. The original graph edges are replaced by new edges connecting the new
vertices to each other and to only two, source s and sink t, terminal nodes.
The weights of the new edges are obtained using a novel least squares solution
approximating the constraints of the initial k-way setup. The minimal s-t cut
labels each new vertex with a binary (s vs t) &quot;Gray&quot; encoding, which is then
decoded into a decimal label number that assigns each of the original vertices
to one of k classes. We analyze the properties of the approximation and present
quantitative as well as qualitative segmentation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0229</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0229</id><created>2009-07-01</created><authors><author><keyname>Polikarpov</keyname><forenames>S. V.</forenames></author><author><keyname>Dergachev</keyname><forenames>V. S.</forenames></author><author><keyname>Rumyantsev</keyname><forenames>K. E.</forenames></author><author><keyname>Golubchikov</keyname><forenames>D. M.</forenames></author></authors><title>A new model of artificial neuron: cyberneuron and its use</title><categories>cs.NE cs.LG</categories><comments>23 pages, 23 figures, in Russian</comments><acm-class>C.1.3; I.2.6; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a new type of artificial neuron, called the authors
&quot;cyberneuron&quot;. Unlike classical models of artificial neurons, this type of
neuron used table substitution instead of the operation of multiplication of
input values for the weights. This allowed to significantly increase the
information capacity of a single neuron, but also greatly simplify the process
of learning. Considered an example of the use of &quot;cyberneuron&quot; with the task of
detecting computer viruses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0255</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0255</id><created>2009-07-01</created><authors><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A Cut-off Phenomenon in Location Based Random Access Games with
  Imperfect Information</title><categories>cs.IT cs.GT math.IT math.PR</categories><comments>Presented in the Fourth International Wireless Internet Conference</comments><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the behavior of selfish transmitters under imperfect
location information. The scenario considered is that of a wireless network
consisting of selfish nodes that are randomly distributed over the network
domain according to a known probability distribution, and that are interested
in communicating with a common sink node using common radio resources. In this
scenario, the wireless nodes do not know the exact locations of their
competitors but rather have belief distributions about these locations.
Firstly, properties of the packet success probability curve as a function of
the node-sink separation are obtained for such networks. Secondly, a
monotonicity property for the best-response strategies of selfish nodes is
identified. That is, for any given strategies of competitors of a node, there
exists a critical node-sink separation for this node such that its
best-response is to transmit when its distance to the sink node is smaller than
this critical threshold, and to back off otherwise. Finally, necessary and
sufficient conditions for a given strategy profile to be a Nash equilibrium are
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0288</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0288</id><created>2009-07-02</created><authors><author><keyname>Dube</keyname><forenames>Simant</forenames></author></authors><title>An Iterative Fingerprint Enhancement Algorithm Based on Accurate
  Determination of Orientation Flow</title><categories>cs.CV</categories><comments>10 pages, 4 figures. Ongoing work. To be submitted to appropriate
  conference/journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm to enhance and binarize a fingerprint image. The
algorithm is based on accurate determination of orientation flow of the ridges
of the fingerprint image by computing variance of the neighborhood pixels
around a pixel in different directions. We show that an iterative algorithm
which captures the mutual interdependence of orientation flow computation,
enhancement and binarization gives very good results on poor quality images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0291</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0291</id><created>2009-07-02</created><updated>2009-11-25</updated><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Tran</keyname><forenames>Khang</forenames></author></authors><title>Generating functions of Chebyshev-like polynomials</title><categories>cs.SC</categories><proxy>ccsd inria-00400839</proxy><doi>10.1142/S1793042110003691</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short note, we give simple proofs of several results and conjectures
formulated by Stolarsky and Tran concerning generating functions of some
families of Chebyshev-like polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0305</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0305</id><created>2009-07-02</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Levin</keyname><forenames>Asaf</forenames></author><author><keyname>Mestre</keyname><forenames>Julian</forenames></author><author><keyname>Segev</keyname><forenames>Danny</forenames></author></authors><title>Improved approximation guarantees for weighted matching in the
  semi-streaming model</title><categories>cs.DS</categories><journal-ref>SIAM J. Discrete Math. 25(3): 1251-1265 (2011)</journal-ref><doi>10.1137/100801901</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the maximum weight matching problem in the semi-streaming model, and
improve on the currently best one-pass algorithm due to Zelke (Proc. of
STACS2008, pages 669-680) by devising a deterministic approach whose
performance guarantee is 4.91+epsilon. In addition, we study preemptive online
algorithms, a sub-class of one-pass algorithms where we are only allowed to
maintain a feasible matching in memory at any point in time. All known results
prior to Zelke's belong to this sub-class. We provide a lower bound of 4.967 on
the competitive ratio of any such deterministic algorithm, and hence show that
future improvements will have to store in memory a set of edges which is not
necessarily a feasible matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0313</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0313</id><created>2009-07-02</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Steganography in Handling Oversized IP Packets</title><categories>cs.CR</categories><comments>10 pages, 7 figures, paper submitted to First International Workshop
  on Network Steganography - IWNS 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper identifies new class of network steganography methods that utilize
mechanisms to handle oversized packets in IP networks: IP fragmentation, PMTUD
(Path MTU Discovery) and PLPMTUD (Packetization Layer Path MTU Discovery). In
particular, we propose two new steganographic methods and two extensions of
existing ones. We show how IP fragmentation simplifies utilizing steganographic
methods which requires transmitter-receiver synchronization. We present how
mentioned mechanisms can be used to enable hidden communication for both
versions of IP protocol: 4 and 6. Also the detection of the proposed methods is
enclosed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0328</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0328</id><created>2009-07-02</created><authors><author><keyname>Whitacre</keyname><forenames>James M</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author></authors><title>Degenerate neutrality creates evolvable fitness landscapes</title><categories>cs.NE cs.AI cs.MA</categories><journal-ref>WorldComp 2009, Las Vegas, NV, USA</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Understanding how systems can be designed to be evolvable is fundamental to
research in optimization, evolution, and complex systems science. Many
researchers have thus recognized the importance of evolvability, i.e. the
ability to find new variants of higher fitness, in the fields of biological
evolution and evolutionary computation. Recent studies by Ciliberti et al
(Proc. Nat. Acad. Sci., 2007) and Wagner (Proc. R. Soc. B., 2008) propose a
potentially important link between the robustness and the evolvability of a
system. In particular, it has been suggested that robustness may actually lead
to the emergence of evolvability. Here we study two design principles,
redundancy and degeneracy, for achieving robustness and we show that they have
a dramatically different impact on the evolvability of the system. In
particular, purely redundant systems are found to have very little evolvability
while systems with degeneracy, i.e. distributed robustness, can be orders of
magnitude more evolvable. These results offer insights into the general
principles for achieving evolvability and may prove to be an important step
forward in the pursuit of evolvable representations in evolutionary
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0329</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0329</id><created>2009-07-02</created><authors><author><keyname>Whitacre</keyname><forenames>James M</forenames></author></authors><title>Evidence of coevolution in multi-objective evolutionary algorithms</title><categories>cs.NE cs.AI</categories><journal-ref>WorldComp 2009, Las Vegas, NV, USA</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper demonstrates that simple yet important characteristics of
coevolution can occur in evolutionary algorithms when only a few conditions are
met. We find that interaction-based fitness measurements such as fitness
(linear) ranking allow for a form of coevolutionary dynamics that is observed
when 1) changes are made in what solutions are able to interact during the
ranking process and 2) evolution takes place in a multi-objective environment.
This research contributes to the study of simulated evolution in a at least two
ways. First, it establishes a broader relationship between coevolution and
multi-objective optimization than has been previously considered in the
literature. Second, it demonstrates that the preconditions for coevolutionary
behavior are weaker than previously thought. In particular, our model indicates
that direct cooperation or competition between species is not required for
coevolution to take place. Moreover, our experiments provide evidence that
environmental perturbations can drive coevolutionary processes; a conclusion
that mirrors arguments put forth in dual phase evolution theory. In the
discussion, we briefly consider how our results may shed light onto this and
other recent theories of evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0332</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0332</id><created>2009-07-02</created><updated>2011-01-21</updated><authors><author><keyname>Whitacre</keyname><forenames>James M</forenames></author></authors><title>Survival of the flexible: explaining the recent dominance of
  nature-inspired optimization within a rapidly evolving world</title><categories>cs.NE cs.AI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Although researchers often comment on the rising popularity of
nature-inspired meta-heuristics (NIM), there has been a paucity of data to
directly support the claim that NIM are growing in prominence compared to other
optimization techniques. This study presents evidence that the use of NIM is
not only growing, but indeed appears to have surpassed mathematical
optimization techniques (MOT) in several important metrics related to academic
research activity (publication frequency) and commercial activity (patenting
frequency). Motivated by these findings, this article discusses some of the
possible origins of this growing popularity. I review different explanations
for NIM popularity and discuss why some of these arguments remain unsatisfying.
I argue that a compelling and comprehensive explanation should directly account
for the manner in which most NIM success has actually been achieved, e.g.
through hybridization and customization to different problem environments. By
taking a problem lifecycle perspective, this paper offers a fresh look at the
hypothesis that nature-inspired meta-heuristics derive much of their utility
from being flexible. I discuss global trends within the business environments
where optimization algorithms are applied and I speculate that highly flexible
algorithm frameworks could become increasingly popular within our diverse and
rapidly changing world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0334</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0334</id><created>2009-07-02</created><authors><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Sarker</keyname><forenames>Ruhul A.</forenames></author><author><keyname>Pham</keyname><forenames>Q. Tuan</forenames></author></authors><title>The Self-Organization of Interaction Networks for Nature-Inspired
  Optimization</title><categories>cs.NE cs.AI</categories><journal-ref>IEEE Transactions on Evolutionary Computation, Volume 12, Issue 2,
  April 2008 Page(s):220 - 230</journal-ref><doi>10.1109/TEVC.2007.900327</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Over the last decade, significant progress has been made in understanding
complex biological systems, however there have been few attempts at
incorporating this knowledge into nature inspired optimization algorithms. In
this paper, we present a first attempt at incorporating some of the basic
structural properties of complex biological systems which are believed to be
necessary preconditions for system qualities such as robustness. In particular,
we focus on two important conditions missing in Evolutionary Algorithm
populations; a self-organized definition of locality and interaction epistasis.
We demonstrate that these two features, when combined, provide algorithm
behaviors not observed in the canonical Evolutionary Algorithm or in
Evolutionary Algorithms with structured populations such as the Cellular
Genetic Algorithm. The most noticeable change in algorithm behavior is an
unprecedented capacity for sustainable coexistence of genetically distinct
individuals within a single population. This capacity for sustained genetic
diversity is not imposed on the population but instead emerges as a natural
consequence of the dynamics of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0340</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0340</id><created>2009-07-02</created><authors><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Abbass</keyname><forenames>Hussein A.</forenames></author><author><keyname>Sarker</keyname><forenames>Ruhul</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author><author><keyname>Baker</keyname><forenames>Stephen</forenames></author></authors><title>Strategic Positioning in Tactical Scenario Planning</title><categories>cs.NE cs.AI</categories><journal-ref>Genetic And Evolutionary Computation Conference 2008, Pages
  1081-1088</journal-ref><doi>10.1145/1389095.1389293</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Capability planning problems are pervasive throughout many areas of human
interest with prominent examples found in defense and security. Planning
provides a unique context for optimization that has not been explored in great
detail and involves a number of interesting challenges which are distinct from
traditional optimization research. Planning problems demand solutions that can
satisfy a number of competing objectives on multiple scales related to
robustness, adaptiveness, risk, etc. The scenario method is a key approach for
planning. Scenarios can be defined for long-term as well as short-term plans.
This paper introduces computational scenario-based planning problems and
proposes ways to accommodate strategic positioning within the tactical planning
domain. We demonstrate the methodology in a resource planning problem that is
solved with a multi-objective evolutionary algorithm. Our discussion and
results highlight the fact that scenario-based planning is naturally framed
within a multi-objective setting. However, the conflicting objectives occur on
different system levels rather than within a single system alone. This paper
also contends that planning problems are of vital interest in many human
endeavors and that Evolutionary Computation may be well positioned for this
problem domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0375</identifier>
 <datestamp>2010-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0375</id><created>2009-07-02</created><updated>2010-04-22</updated><authors><author><keyname>Leskel&#xe4;</keyname><forenames>L.</forenames><affiliation>MSA</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames><affiliation>INRIA</affiliation></author><author><keyname>Simatos</keyname><forenames>Florian</forenames></author></authors><title>Interacting branching processes and linear file-sharing networks</title><categories>math.PR cs.NI</categories><proxy>ccsd inria-00401104</proxy><journal-ref>Advances in Applied Probability, 42(3), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  File-sharing networks are distributed systems used to disseminate files among
nodes of a communication network. The general simple principle of these systems
is that once a node has retrieved a file, it may become a server for this file.
In this paper, the capacity of these networks is analyzed with a stochastic
model when there is a constant flow of incoming requests for a given file. It
is shown that the problem can be solved by analyzing the asymptotic behavior of
a class of interacting branching processes. Several results of independent
interest concerning these branching processes are derived and then used to
study the file-sharing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0403</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0403</id><created>2009-07-02</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Witzel</keyname><forenames>Andreas</forenames></author><author><keyname>Zvesper</keyname><forenames>Jonathan A.</forenames></author></authors><title>Common Knowledge in Interaction Structures</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two simple variants of a framework for reasoning about knowledge
amongst communicating groups of players. Our goal is to clarify the resulting
epistemic issues. In particular, we investigate what is the impact of common
knowledge of the underlying hypergraph connecting the players, and under what
conditions common knowledge distributes over disjunction. We also obtain two
versions of the classic result that common knowledge cannot be achieved in the
absence of a simultaneous event (here a message sent to the whole group).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0404</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0404</id><created>2009-07-02</created><authors><author><keyname>Safdar</keyname><forenames>Sohail</forenames></author><author><keyname>Ahmad</keyname><forenames>Jamil</forenames></author><author><keyname>Ahmed</keyname><forenames>Shaftab</forenames></author><author><keyname>Asghar</keyname><forenames>M. Tayyab</forenames></author><author><keyname>Saeed</keyname><forenames>Saqib</forenames></author></authors><title>Agent based Model for providing optimized, synchronized and failure free
  execution of workflow process</title><categories>cs.SE</categories><comments>This paper was published in the proceedings of 4th International
  Conference on New Exploratory Technology (NEXT 2007) Seoul, Korea 25-27
  October 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of this paper is to provide an optimized solution and
algorithm for the execution of a workflow process by ensuring the data
consistency, correctness, completeness among various tasks involved. The
solution proposed provides a synchronized and failure free flow of execution
among various tasks involved in a workflow process. A synchronizing agent is
bound at a very low level, i.e. with the workflow activity or task to get the
desired goals to be done and an algorithm is provided to show the execution of
workflow process completely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0418</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0418</id><created>2009-07-02</created><authors><author><keyname>Kae</keyname><forenames>Andrew</forenames></author><author><keyname>Huang</keyname><forenames>Gary B.</forenames></author><author><keyname>Learned-Miller</keyname><forenames>Erik</forenames></author></authors><title>Bounding the Probability of Error for High Precision Recognition</title><categories>cs.CV</categories><report-no>UM-CS-2009-031</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider models for which it is important, early in processing, to
estimate some variables with high precision, but perhaps at relatively low
rates of recall. If some variables can be identified with near certainty, then
they can be conditioned upon, allowing further inference to be done
efficiently. Specifically, we consider optical character recognition (OCR)
systems that can be bootstrapped by identifying a subset of correctly
translated document words with very high precision. This &quot;clean set&quot; is
subsequently used as document-specific training data. While many current OCR
systems produce measures of confidence for the identity of each letter or word,
thresholding these confidence values, even at very high values, still produces
some errors.
  We introduce a novel technique for identifying a set of correct words with
very high precision. Rather than estimating posterior probabilities, we bound
the probability that any given word is incorrect under very general
assumptions, using an approximate worst case analysis. As a result, the
parameters of the model are nearly irrelevant, and we are able to identify a
subset of words, even in noisy documents, of which we are highly confident. On
our set of 10 documents, we are able to identify about 6% of the words on
average without making a single error. This ability to produce word lists with
very high precision allows us to use a family of models which depends upon such
clean word lists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0453</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0453</id><created>2009-07-02</created><updated>2009-07-20</updated><authors><author><keyname>Kontorovich</keyname><forenames>Leonid Aryeh</forenames></author></authors><title>Random DFAs are Efficiently PAC Learnable</title><categories>cs.LG</categories><comments>withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn due to an error found by Dana Angluin and Lev
Reyzin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0455</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0455</id><created>2009-07-02</created><updated>2009-10-29</updated><authors><author><keyname>Pluchino</keyname><forenames>Alessandro</forenames></author><author><keyname>Rapisarda</keyname><forenames>Andrea</forenames></author><author><keyname>Garofalo</keyname><forenames>Cesare</forenames></author></authors><title>The Peter Principle Revisited: A Computational Study</title><categories>physics.soc-ph cs.GT nlin.AO physics.pop-ph</categories><comments>final version published on Physica A, 10 pages, 4 figures, 1 table
  (for on-line supplementary material see the link:
  http://www.ct.infn.it/cactus/peter-links.html)</comments><journal-ref>Physica A 389 (2010) 467-472</journal-ref><doi>10.1016/j.physa.2009.09.045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the late sixties the Canadian psychologist Laurence J. Peter advanced an
apparently paradoxical principle, named since then after him, which can be
summarized as follows: {\it 'Every new member in a hierarchical organization
climbs the hierarchy until he/she reaches his/her level of maximum
incompetence'}. Despite its apparent unreasonableness, such a principle would
realistically act in any organization where the mechanism of promotion rewards
the best members and where the mechanism at their new level in the hierarchical
structure does not depend on the competence they had at the previous level,
usually because the tasks of the levels are very different to each other. Here
we show, by means of agent based simulations, that if the latter two features
actually hold in a given model of an organization with a hierarchical
structure, then not only is the Peter principle unavoidable, but also it yields
in turn a significant reduction of the global efficiency of the organization.
Within a game theory-like approach, we explore different promotion strategies
and we find, counterintuitively, that in order to avoid such an effect the best
ways for improving the efficiency of a given organization are either to promote
each time an agent at random or to promote randomly the best and the worst
members in terms of competence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0472</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0472</id><created>2009-07-02</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Capacity Regions and Sum-Rate Capacities of Vector Gaussian Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>33 pages, 1 figure, submitted to IEEE trans. on Information theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity regions of vector, or multiple-input multiple-output, Gaussian
interference channels are established for very strong interference and aligned
strong interference. Furthermore, the sum-rate capacities are established for Z
interference, noisy interference, and mixed (aligned weak/intermediate and
aligned strong) interference. These results generalize known results for scalar
Gaussian interference channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0499</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0499</id><created>2009-07-03</created><authors><author><keyname>Kebair</keyname><forenames>Fahem</forenames></author><author><keyname>Serin</keyname><forenames>Frederic</forenames></author></authors><title>Agent-Oriented Approach for Detecting and Managing Risks in Emergency
  Situations</title><categories>cs.AI cs.MA</categories><comments>5</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents an agent-oriented approach to build a decision support
system aimed at helping emergency managers to detect and to manage risks. We
stress the flexibility and the adaptivity characteristics that are crucial to
build a robust and efficient system, able to resolve complex problems. The
system should be independent as much as possible from the subject of study.
Thereby, an original approach based on a mechanism of perception,
representation, characterisation and assessment is proposed. The work described
here is applied on the RoboCupRescue application. Experimentations and results
are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0505</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0505</id><created>2009-07-02</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Multi-User MISO Interference Channels with Single-User Detection:
  Optimality of Beamforming and the Achievable Rate Region</title><categories>cs.IT math.IT</categories><comments>41 pages, 7 figures, submitted to IEEE trans. on Information Theory
  in Apr. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a multi-user interference channel with multi-antenna transmitters and
single-antenna receivers, by restricting each transmitter to Gaussian input and
each receiver to a single-user detector, computing the largest achievable rate
region amounts to solving a family of non-convex optimization problems.
Recognizing the intrinsic connection between the signal power at the intended
receiver and the interference power at the unintended receiver, the original
family of non-convex optimization problems is converted into a new family of
convex optimization problems. It is shown that, for such interference channels
with each receiver implementing single-user detection, transmitter beamforming
can achieve all boundary points of the achievable rate region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0507</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0507</id><created>2009-07-02</created><updated>2011-02-05</updated><authors><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Sarker</keyname><forenames>Ruhul A.</forenames></author><author><keyname>Pham</keyname><forenames>Q. Tuan</forenames></author></authors><title>Spontaneous organization leads to robustness in evolutionary algorithms</title><categories>cs.NE cs.AI</categories><comments>This paper has been withdrawn so that it can be published in IJAIT
  (International Journal of Artificial Intelligence Tools)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interaction networks of biological systems are known to take on several
non-random structural properties, some of which are believed to positively
influence system robustness. Researchers are only starting to understand how
these structural properties emerge, however suggested roles for component
fitness and community development (modularity) have attracted interest from the
scientific community. In this study, we apply some of these concepts to an
evolutionary algorithm and spontaneously organize its population using
information that the population receives as it moves over a fitness landscape.
More precisely, we employ fitness and clustering based driving forces for
guiding network structural dynamics, which in turn are controlled by the
population dynamics of an evolutionary algorithm. To evaluate the effect this
has on evolution, experiments are conducted on six engineering design problems
and six artificial test functions and compared against cellular genetic
algorithms and 16 other evolutionary algorithm designs. Our results indicate
that a self-organizing topology evolutionary algorithm exhibits surprisingly
robust search behavior with promising performance observed over short and long
time scales. After a careful analysis of these results, we conclude that the
coevolution between a population and its topology represents a powerful new
paradigm for designing robust search heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0516</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0516</id><created>2009-07-02</created><authors><author><keyname>Whitacre</keyname><forenames>James M</forenames></author></authors><title>Adaptation and Self-Organization in Evolutionary Algorithms</title><categories>cs.NE</categories><comments>PhD Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abbreviated Abstract: The objective of Evolutionary Computation is to solve
practical problems (e.g. optimization, data mining) by simulating the
mechanisms of natural evolution. This thesis addresses several topics related
to adaptation and self-organization in evolving systems with the overall aims
of improving the performance of Evolutionary Algorithms (EA), understanding its
relation to natural evolution, and incorporating new mechanisms for mimicking
complex biological systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0520</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0520</id><created>2009-07-02</created><authors><author><keyname>Abbass</keyname><forenames>Hussein</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author><author><keyname>Dam</keyname><forenames>Helen</forenames></author><author><keyname>Baker</keyname><forenames>Stephen</forenames></author><author><keyname>Whitacre</keyname><forenames>James M</forenames></author><author><keyname>Sarker</keyname><forenames>Ruhul</forenames></author></authors><title>Computational Scenario-based Capability Planning</title><categories>cs.NE cs.AI</categories><comments>GECCO-2008, Atlanta, GA, USA</comments><doi>10.1145/1389095.1389378</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scenarios are pen-pictures of plausible futures, used for strategic planning.
The aim of this investigation is to expand the horizon of scenario-based
planning through computational models that are able to aid the analyst in the
planning process. The investigation builds upon the advances of Information and
Communication Technology (ICT) to create a novel, flexible and customizable
computational capability-based planning methodology that is practical and
theoretically sound. We will show how evolutionary computation, in particular
evolutionary multi-objective optimization, can play a central role - both as an
optimizer and as a source for innovation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0540</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0540</id><created>2009-07-03</created><updated>2010-11-02</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Inversive Meadows and Divisive Meadows</title><categories>math.RA cs.LO</categories><comments>18 pages; error corrected; 29 pages, combined with arXiv:0909.2088
  [math.RA] and arXiv:0909.5271 [math.RA]</comments><msc-class>12E12, 12L05, 12L12, 16E50, 68Q65</msc-class><journal-ref>Journal of Applied Logic, 9(3):203--220, 2011</journal-ref><doi>10.1016/j.jal.2011.03.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inversive meadows are commutative rings with a multiplicative identity
element and a total multiplicative inverse operation whose value at 0 is 0.
Divisive meadows are inversive meadows with the multiplicative inverse
operation replaced by a division operation. We give finite equational
specifications of the class of all inversive meadows and the class of all
divisive meadows. It depends on the angle from which they are viewed whether
inversive meadows or divisive meadows must be considered more basic. We show
that inversive and divisive meadows of rational numbers can be obtained as
initial algebras of finite equational specifications. In the spirit of
Peacock's arithmetical algebra, we study variants of inversive and divisive
meadows without an additive identity element and/or an additive inverse
operation. We propose simple constructions of variants of inversive and
divisive meadows with a partial multiplicative inverse or division operation
from inversive and divisive meadows. Divisive meadows are more basic if these
variants are considered as well. We give a simple account of how mathematicians
deal with 1 / 0, in which meadows and a customary convention among
mathematicians play prominent parts, and we make plausible that a convincing
account, starting from the popular computer science viewpoint that 1 / 0 is
undefined, by means of some logic of partial functions is not attainable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0542</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0542</id><created>2009-07-03</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP, ICTT</affiliation></author><author><keyname>Bobillier-Chaumon</keyname><forenames>Marc-Eric</forenames><affiliation>ICTT</affiliation></author><author><keyname>Cohen-Montandreau</keyname><forenames>V&#xe9;ronique</forenames><affiliation>ICTT</affiliation></author><author><keyname>Tarpin-Bernard</keyname><forenames>Franck</forenames><affiliation>LIESP, ICTT</affiliation></author></authors><title>D\'emarche d'\'evaluation de l'usage et des r\'epercussions
  psychosociales d'un environnement STIC sur une population de personnes
  \^ag\'ees en r\'esidence m\'edicalis\'ee</title><categories>cs.CY</categories><proxy>ccsd hal-00197097</proxy><journal-ref>17 \`eme conf\'erence francophone sur l'Interaction Homme-Machine,
  Toulouse : France (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MNESIS Project aims to see whether the use of computerized environment by
elderly people in medicalized residences stimulates their cognitive capacities
and contributes to a better integration, recognition or acceptance within their
social environment (friends, family, medical staff). In this paper we present
the protocol of evaluation that is defined to check this assumption. This
protocol is between users' centred traditional protocols (built on
investigations and indirect observation) and studies of Web Usage Mining (where
knowledge databases about the uses are built from traces of use). It allows
collecting direct and indirect information on a large scale and over long
periods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0589</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0589</id><created>2009-07-03</created><updated>2009-07-07</updated><authors><author><keyname>Gupta</keyname><forenames>Rahul</forenames></author><author><keyname>Sarawagi</keyname><forenames>Sunita</forenames></author><author><keyname>Diwan</keyname><forenames>Ajit A.</forenames></author></authors><title>Generalized Collective Inference with Symmetric Clique Potentials</title><categories>cs.AI</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collective graphical models exploit inter-instance associative dependence to
output more accurate labelings. However existing models support very limited
kind of associativity which restricts accuracy gains. This paper makes two
major contributions. First, we propose a general collective inference framework
that biases data instances to agree on a set of {\em properties} of their
labelings. Agreement is encouraged through symmetric clique potentials. We show
that rich properties leads to bigger gains, and present a systematic inference
procedure for a large class of such properties. The procedure performs message
passing on the cluster graph, where property-aware messages are computed with
cluster specific algorithms. This provides an inference-only solution for
domain adaptation. Our experiments on bibliographic information extraction
illustrate significant test error reduction over unseen domains. Our second
major contribution consists of algorithms for computing outgoing messages from
clique clusters with symmetric clique potentials. Our algorithms are exact for
arbitrary symmetric potentials on binary labels and for max-like and
majority-like potentials on multiple labels. For majority potentials, we also
provide an efficient Lagrangian Relaxation based algorithm that compares
favorably with the exact algorithm. We present a 13/15-approximation algorithm
for the NP-hard Potts potential, with runtime sub-quadratic in the clique size.
In contrast, the best known previous guarantee for graphs with Potts potentials
is only 1/2. We empirically show that our method for Potts potentials is an
order of magnitude faster than the best alternatives, and our Lagrangian
Relaxation based algorithm for majority potentials beats the best applicable
heuristic -- ICM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0592</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0592</id><created>2009-07-03</created><authors><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Pham</keyname><forenames>Tuan Q.</forenames></author><author><keyname>Sarker</keyname><forenames>Ruhul A.</forenames></author></authors><title>Credit Assignment in Adaptive Evolutionary Algorithms</title><categories>cs.NE cs.AI</categories><journal-ref>Genetic And Evolutionary Computation Conference, 2006</journal-ref><doi>10.1145/1143997.1144206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new method for assigning credit to search operators is
presented. Starting with the principle of optimizing search bias, search
operators are selected based on an ability to create solutions that are
historically linked to future generations. Using a novel framework for defining
performance measurements, distributing credit for performance, and the
statistical interpretation of this credit, a new adaptive method is developed
and shown to outperform a variety of adaptive and non-adaptive competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0595</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0595</id><created>2009-07-03</created><authors><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Pham</keyname><forenames>Tuan Q.</forenames></author><author><keyname>Sarker</keyname><forenames>Ruhul A.</forenames></author></authors><title>Use of statistical outlier detection method in adaptive evolutionary
  algorithms</title><categories>cs.NE cs.AI</categories><journal-ref>Genetic And Evolutionary Computation Conference, 2006</journal-ref><doi>10.1145/1143997.1144205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the issue of adapting probabilities for Evolutionary Algorithm
(EA) search operators is revisited. A framework is devised for distinguishing
between measurements of performance and the interpretation of those
measurements for purposes of adaptation. Several examples of measurements and
statistical interpretations are provided. Probability value adaptation is
tested using an EA with 10 search operators against 10 test problems with
results indicating that both the type of measurement and its statistical
interpretation play significant roles in EA performance. We also find that
selecting operators based on the prevalence of outliers rather than on average
performance is able to provide considerable improvements to adaptive methods
and soundly outperforms the non-adaptive case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0597</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0597</id><created>2009-07-03</created><authors><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author><author><keyname>Baker</keyname><forenames>Stephen</forenames></author><author><keyname>Fan</keyname><forenames>Qi</forenames></author><author><keyname>Sarker</keyname><forenames>Ruhul A.</forenames></author><author><keyname>Abbass</keyname><forenames>Hussein</forenames></author></authors><title>Network Topology and Time Criticality Effects in the Modularised Fleet
  Mix Problem</title><categories>cs.NE cs.AI</categories><journal-ref>SimTecT 2007 conference, Melbourne Australia</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore the interplay between network topology and time
criticality in a military logistics system. A general goal of this work (and
previous work) is to evaluate land transportation requirements or, more
specifically, how to design appropriate fleets of military general service
vehicles that are tasked with the supply and re-supply of military units
dispersed in an area of operation. The particular focus of this paper is to
gain a better understanding of how the logistics environment changes when
current Army vehicles with fixed transport characteristics are replaced by a
new generation of modularised vehicles that can be configured
task-specifically. The experimental work is conducted within a well developed
strategic planning simulation environment which includes a scenario generation
engine for automatically sampling supply and re-supply missions and a
multi-objective meta-heuristic search algorithm (i.e. Evolutionary Algorithm)
for solving the particular scheduling and routing problems. The results
presented in this paper allow for a better understanding of how (and under what
conditions) a modularised vehicle fleet can provide advantages over the
currently implemented system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0598</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0598</id><created>2009-07-03</created><authors><author><keyname>Wesolkowski</keyname><forenames>Slawomir</forenames></author><author><keyname>Mazurek</keyname><forenames>Michael</forenames></author><author><keyname>Whitacre</keyname><forenames>James M.</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author><author><keyname>Abbass</keyname><forenames>Hussein</forenames></author></authors><title>Robustness and Adaptiveness Analysis of Future Fleets</title><categories>cs.NE cs.AI</categories><journal-ref>SimtecT 2009 conference, Adelaide, Australia</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Making decisions about the structure of a future military fleet is a
challenging task. Several issues need to be considered such as the existence of
multiple competing objectives and the complexity of the operating environment.
A particular challenge is posed by the various types of uncertainty that the
future might hold. It is uncertain what future events might be encountered; how
fleet design decisions will influence and shape the future; and how present and
future decision makers will act based on available information, their personal
biases regarding the importance of different objectives, and their economic
preferences. In order to assist strategic decision-making, an analysis of
future fleet options needs to account for conditions in which these different
classes of uncertainty are exposed. It is important to understand what
assumptions a particular fleet is robust to, what the fleet can readily adapt
to, and what conditions present clear risks to the fleet. We call this the
analysis of a fleet's strategic positioning. This paper introduces how
strategic positioning can be evaluated using computer simulations. Our main aim
is to introduce a framework for capturing information that can be useful to a
decision maker and for defining the concepts of robustness and adaptiveness in
the context of future fleet design. We demonstrate our conceptual framework
using simulation studies of an air transportation fleet. We capture uncertainty
by employing an explorative scenario-based approach. Each scenario represents a
sampling of different future conditions, different model assumptions, and
different economic preferences. Proposed changes to a fleet are then analysed
based on their influence on the fleet's robustness, adaptiveness, and risk to
different scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0611</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0611</id><created>2009-07-03</created><authors><author><keyname>Butdee</keyname><forenames>S.</forenames><affiliation>KMRC</affiliation></author><author><keyname>Noomtong</keyname><forenames>Chaiwat</forenames><affiliation>LGS</affiliation></author><author><keyname>Tichkiewitch</keyname><forenames>Serge</forenames><affiliation>LGS</affiliation></author></authors><title>A process planning system with feature based neural network search
  strategy for aluminum extrusion die manufacturing</title><categories>cs.NE</categories><proxy>ccsd hal-00400845</proxy><journal-ref>Asian International Journal of Science and Technology in
  Production and Manufacturing Engineering 2, 1 (2009) 137-157</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aluminum extrusion die manufacturing is a critical task for productive
improvement and increasing potential of competition in aluminum extrusion
industry. It causes to meet the efficiency not only consistent quality but also
time and production cost reduction. Die manufacturing consists first of die
design and process planning in order to make a die for extruding the customer's
requirement products. The efficiency of die design and process planning are
based on the knowledge and experience of die design and die manufacturer
experts. This knowledge has been formulated into a computer system called the
knowledge-based system. It can be reused to support a new die design and
process planning. Such knowledge can be extracted directly from die geometry
which is composed of die features. These features are stored in die feature
library to be prepared for producing a new die manufacturing. Die geometry is
defined according to the characteristics of the profile so we can reuse die
features from the previous similar profile design cases. This paper presents
the CaseXpert Process Planning System for die manufacturing based on feature
based neural network technique. Die manufacturing cases in the case library
would be retrieved with searching and learning method by neural network for
reusing or revising it to build a die design and process planning when a new
case is similar with the previous die manufacturing cases. The results of the
system are dies design and machining process. The system has been successfully
tested, it has been proved that the system can reduce planning time and respond
high consistent plans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0615</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0615</id><created>2009-07-03</created><authors><author><keyname>Charlier</keyname><forenames>Emilie</forenames></author><author><keyname>Karki</keyname><forenames>Tomi</forenames></author><author><keyname>Rigo</keyname><forenames>Michel</forenames></author></authors><title>Multidimensional Generalized Automatic Sequences and Shape-symmetric
  Morphic Words</title><categories>cs.FL cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An infinite word is S-automatic if, for all n&gt;=0, its (n + 1)st letter is the
output of a deterministic automaton fed with the representation of n in the
considered numeration system S. In this extended abstract, we consider an
analogous definition in a multidimensional setting and present the connection
to the shape-symmetric infinite words introduced by Arnaud Maes. More
precisely, for d&gt;=2, we state that a multidimensional infinite word x : N^d \to
\Sigma over a finite alphabet \Sigma is S-automatic for some abstract
numeration system S built on a regular language containing the empty word if
and only if x is the image by a coding of a shape-symmetric infinite word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0616</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0616</id><created>2009-07-03</created><updated>2009-08-03</updated><authors><author><keyname>Weis</keyname><forenames>Philipp</forenames></author><author><keyname>Immerman</keyname><forenames>Neil</forenames></author></authors><title>Structure Theorem and Strict Alternation Hierarchy for FO^2 on Words</title><categories>cs.LO cs.FL</categories><acm-class>F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (August 4,
  2009) lmcs:1159</journal-ref><doi>10.2168/LMCS-5(3:4)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that every first-order property on words is expressible
using at most three variables. The subclass of properties expressible with only
two variables is also quite interesting and well-studied. We prove precise
structure theorems that characterize the exact expressive power of first-order
logic with two variables on words. Our results apply to both the case with and
without a successor relation. For both languages, our structure theorems show
exactly what is expressible using a given quantifier depth, n, and using m
blocks of alternating quantifiers, for any m \leq n. Using these
characterizations, we prove, among other results, that there is a strict
hierarchy of alternating quantifiers for both languages. The question whether
there was such a hierarchy had been completely open. As another consequence of
our structural results, we show that satisfiability for first-order logic with
two variables without successor, which is NEXP-complete in general, becomes
NP-complete once we only consider alphabets of a bounded size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0620</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0620</id><created>2009-07-03</created><authors><author><keyname>Bell</keyname><forenames>J.</forenames></author><author><keyname>Charlier</keyname><forenames>E.</forenames></author><author><keyname>Fraenkel</keyname><forenames>A. S.</forenames></author><author><keyname>Rigo</keyname><forenames>M.</forenames></author></authors><title>A Decision Problem for Ultimately Periodic Sets in Non-standard
  Numeration Systems</title><categories>cs.FL cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a non-standard numeration system like the one built over the
Fibonacci sequence where nonnegative integers are represented by words over
$\{0,1\}$ without two consecutive 1. Given a set $X$ of integers such that the
language of their greedy representations in this system is accepted by a finite
automaton, we consider the problem of deciding whether or not $X$ is a finite
union of arithmetic progressions. We obtain a decision procedure for this
problem, under some hypothesis about the considered numeration system. In a
second part, we obtain an analogous decision result for a particular class of
abstract numeration systems built on an infinite regular language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0624</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0624</id><created>2009-07-03</created><authors><author><keyname>Rigo</keyname><forenames>M.</forenames></author><author><keyname>Waxweiler</keyname><forenames>L.</forenames></author></authors><title>A note on syndeticity, recognizable sets and Cobham's theorem</title><categories>cs.FL</categories><journal-ref>Bull. Eur. Assoc. Theor. Comput. Sci. EATCS 88 (2006), 169-173</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we give an alternative proof of the following result. Let p, q
&gt;= 2 be two multiplicatively independent integers. If an infinite set of
integers is both p- and q-recognizable, then it is syndetic. Notice that this
result is needed in the classical proof of the celebrated Cobham?s theorem.
Therefore the aim of this paper is to complete [13] and [1] to obtain an
accessible proof of Cobham?s theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0649</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0649</id><created>2009-07-03</created><updated>2010-07-08</updated><authors><author><keyname>Darties</keyname><forenames>Benoit</forenames><affiliation>LIG</affiliation></author><author><keyname>Theoleyre</keyname><forenames>Fabrice</forenames><affiliation>LIG</affiliation></author><author><keyname>Duda</keyname><forenames>Andrzej</forenames><affiliation>LIG</affiliation></author></authors><title>A Divide-and-Conquer Scheme for Assigning Roles in Multi-Channel
  Wireless Mesh Networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>IEEE Conference on Local Computer Networks (LCN), Zurich :
  Switzerland (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multi-channel MAC seems to be an interesting approach for improving network
throughput by multiplexing transmissions over orthogonal channels. In
particular, Molecular MAC has recently proposed to modify the standard IEEE
802.11 DCF access method to use dynamic channel switching for efficient packet
forwarding over multiple hops. However, this MAC layer requires role and
channel assignment to nodes: some of them use a static channel, while others
dynamically switch to neighbor channels on-demand. To assign roles and
channels, we extend the notion of the Weakly Connected Dominating Set, the
structure already used in clustering. More precisely, we adapt the WCDS
structure and introduce new constraints to define what we call a reversible
WCDS (r-WCDS), which is particularly suitable for wireless mesh networks
operating under Molecular MAC. We propose a divide-and-conquer scheme that
partitions the network into clusters with one leader per cluster solving a MILP
formulation to assign roles in its cluster. By appropriately defining the roles
at the border of clusters, we maintain global connectivity in the r-wcds.
Finally, our simulations show that the performance of the propose scheme is
close to a centralized algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0678</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0678</id><created>2009-07-03</created><authors><author><keyname>Shukla</keyname><forenames>Piyush Kumar</forenames></author><author><keyname>Silakari</keyname><forenames>Dr. S.</forenames></author><author><keyname>Bhadoria</keyname><forenames>Dr. Sarita Singh</forenames></author></authors><title>Design and Analysis of an Attack Resilient and Adaptive Medium access
  Control Protocol for Computer Networks</title><categories>cs.CR cs.NI</categories><comments>10 pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS May 2009 Issue, Vol. 1, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The challenge of designing an efficient Medium Access Control (MAC) protocol
and analyzing it has been an important research topic for over 30 years. This
paper focuses on the performance analysis (through simulation) and modification
of a well known MAC protocol CSMA/CD. The existing protocol does not consider
the wastage of bandwidth due to unutilized periods of the channel. By
considering this fact, performance of MAC protocol can be enhanced. The purpose
of this work is to modify the existing protocol by enabling it to adapt
according to state of the network. The modified protocol takes appropriate
action whenever unutilized periods detected. In this way, to increase the
effective bandwidth utilization and determine how it behaves under increasing
load, and varying packet sizes. It will also include effects of attacks i.e.
Denial of service attacks, Replay Attack, Continuous Channel Access or
Exhaustion attack, Flooding attack, Jamming (Radio interference) attack,
Selective forwarding attack which degrade performance of MAC protocol. In
Continuous Channel Access or Exhaustion attack, a malicious node disrupts the
MAC protocol, by continuously requesting or transmitting over the channel. This
eventually leads a starvation for other nodes in the network w.r.t channel
access. remedy may be the network ignores excessive requests without sending
expensive radio transmissions. This limit however cannot drop below the
expected maximum data rate the network has to support. This limit is usually
coded into the protocol during the design phase and requires additional logic
also. Repeated application of these exhaustion or collision based MAC layer
attacks can lead into unfairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0691</identifier>
 <datestamp>2009-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0691</id><created>2009-07-03</created><authors><author><keyname>Eschen</keyname><forenames>Elaine M.</forenames></author><author><keyname>Hoang</keyname><forenames>Chinh T.</forenames></author><author><keyname>Sritharan</keyname><forenames>R.</forenames></author><author><keyname>Stewart</keyname><forenames>Lorna</forenames></author></authors><title>On the complexity of deciding whether the distinguishing chromatic
  number of a graph is at most two</title><categories>cs.CC</categories><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an article [3] published recently in this journal, it was shown that when
k &gt;= 3, the problem of deciding whether the distinguishing chromatic number of
a graph is at most k is NP-hard. We consider the problem when k = 2. In regards
to the issue of solvability in polynomial time, we show that the problem is at
least as hard as graph automorphism but no harder than graph isomorphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0718</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0718</id><created>2009-07-03</created><updated>2010-01-15</updated><authors><author><keyname>Sorenson</keyname><forenames>Jonathan P.</forenames></author></authors><title>A Randomized Sublinear Time Parallel GCD Algorithm for the EREW PRAM</title><categories>cs.DS</categories><acm-class>F.2.1; I.1.2</acm-class><journal-ref>Information Processing Letters 110 (2010) 198-201</journal-ref><doi>10.1016/j.ipl.2009.12.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a randomized parallel algorithm that computes the greatest common
divisor of two integers of n bits in length with probability 1-o(1) that takes
O(n loglog n / log n) expected time using n^{6+\epsilon} processors on the EREW
PRAM parallel model of computation. We believe this to be the first randomized
sublinear time algorithm on the EREW PRAM for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0725</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0725</id><created>2009-07-03</created><authors><author><keyname>Basar</keyname><forenames>Ertugrul</forenames></author><author><keyname>Aygolu</keyname><forenames>Umit</forenames></author></authors><title>High-Rate Full-Diversity Space-Time Block Codes for Three and Four
  Transmit Antennas</title><categories>cs.IT math.IT</categories><comments>To appear in IET Communications, 21 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we deal with the design of high-rate, full-diversity, low
maximum likelihood (ML) decoding complexity space-time block codes (STBCs) with
code rates of 2 and 1.5 complex symbols per channel use for multiple-input
multiple output (MIMO) systems employing three and four transmit antennas. We
fill the empty slots of the existing STBCs from CIODs in their transmission
matrices by additional symbols and use the conditional ML decoding technique
which significantly reduces the ML decoding complexity of non-orthogonal STBCs
while ensuring full-diversity and high coding gain. First, two new schemes with
code rates of 2 and 1.5 are proposed for MIMO systems with four transmit
antennas. We show that our low-complexity rate-2 STBC outperforms the
corresponding best STBC recently proposed by Biglieri et al. for QPSK, due to
its superior coding gain while our rate-1.5 STBC outperforms the full-diversity
quasi-orthogonal STBC (QOSTBC). Then, two STBCs with code rates of 2 and 1.5
are proposed for three transmit antennas which are shown to outperform the
corresponding full-diversity QOSTBC for three transmit antennas. We prove by an
information-theoretic analysis that the capacities of new rate-2 STBCs for
three and four transmit antennas are much closer to the actual MIMO channel
capacity than the capacities of classical OSTBCs and CIODs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0726</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0726</id><created>2009-07-03</created><updated>2010-06-01</updated><authors><author><keyname>Friggstad</keyname><forenames>Zachary</forenames></author><author><keyname>Salavatipour</keyname><forenames>Mohammad R.</forenames></author><author><keyname>Svitkina</keyname><forenames>Zoya</forenames></author></authors><title>Asymmetric Traveling Salesman Path and Directed Latency Problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study integrality gaps and approximability of two closely related problems
on directed graphs. Given a set V of n nodes in an underlying asymmetric metric
and two specified nodes s and t, both problems ask to find an s-t path visiting
all other nodes. In the asymmetric traveling salesman path problem (ATSPP), the
objective is to minimize the total cost of this path. In the directed latency
problem, the objective is to minimize the sum of distances on this path from s
to each node. Both of these problems are NP-hard. The best known approximation
algorithms for ATSPP had ratio O(log n) until the very recent result that
improves it to O(log n/ log log n). However, only a bound of O(sqrt(n)) for the
integrality gap of its linear programming relaxation has been known. For
directed latency, the best previously known approximation algorithm has a
guarantee of O(n^(1/2+eps)), for any constant eps &gt; 0. We present a new
algorithm for the ATSPP problem that has an approximation ratio of O(log n),
but whose analysis also bounds the integrality gap of the standard LP
relaxation of ATSPP by the same factor. This solves an open problem posed by
Chekuri and Pal [2007]. We then pursue a deeper study of this linear program
and its variations, which leads to an algorithm for the k-person ATSPP (where k
s-t paths of minimum total length are sought) and an O(log n)-approximation for
the directed latency problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0741</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0741</id><created>2009-07-04</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Tight Bounds for Online Stable Sorting</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although many authors have considered how many ternary comparisons it takes
to sort a multiset $S$ of size $n$, the best known upper and lower bounds still
differ by a term linear in $n$. In this paper we restrict our attention to
online stable sorting and prove upper and lower bounds that are within (o (n))
not only of each other but also of the best known upper bound for offline
sorting. Specifically, we first prove that if the number of distinct elements
(\sigma = o (n / \log n)), then ((H + 1) n + o (n)) comparisons are sufficient,
where $H$ is the entropy of the distribution of the elements in $S$. We then
give a simple proof that ((H + 1) n - o (n)) comparisons are necessary in the
worst case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0746</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0746</id><created>2009-07-04</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Open Problems in Universal Induction &amp; Intelligence</title><categories>cs.AI cs.IT cs.LG math.IT</categories><comments>32 LaTeX pages</comments><journal-ref>Algorithms, 3:2 (2009) pages 879-906</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Specialized intelligent systems can be found everywhere: finger print,
handwriting, speech, and face recognition, spam filtering, chess and other game
programs, robots, et al. This decade the first presumably complete mathematical
theory of artificial intelligence based on universal
induction-prediction-decision-action has been proposed. This
information-theoretic approach solidifies the foundations of inductive
inference and artificial intelligence. Getting the foundations right usually
marks a significant progress and maturing of a field. The theory provides a
gold standard and guidance for researchers working on intelligent algorithms.
The roots of universal induction have been laid exactly half-a-century ago and
the roots of universal intelligence exactly one decade ago. So it is timely to
take stock of what has been achieved and what remains to be done. Since there
are already good recent surveys, I describe the state-of-the-art only in
passing and refer the reader to the literature. This article concentrates on
the open problems in universal induction and its extension to universal
intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0748</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0748</id><created>2009-07-04</created><updated>2009-09-14</updated><authors><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Zampieri</keyname><forenames>Sandro</forenames></author></authors><title>Gossip consensus algorithms via quantized communication</title><categories>math.OC cs.SY</categories><comments>Accepted for publication</comments><msc-class>93A14; 93D21; 60J10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the average consensus problem on a network of digital
links, and proposes a set of algorithms based on pairwise ''gossip''
communications and updates. We study the convergence properties of such
algorithms with the goal of answering two design questions, arising from the
literature: whether the agents should encode their communication by a
deterministic or a randomized quantizer, and whether they should use, and how,
exact information regarding their own states in the update.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0749</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0749</id><created>2009-07-04</created><authors><author><keyname>Ghica</keyname><forenames>Dan R.</forenames></author></authors><title>Function Interface Models for Hardware Compilation: Types, Signatures,
  Protocols</title><categories>cs.PL cs.AR</categories><comments>25 pages, 8 figures</comments><report-no>University of Birmingham Technical Report CSR-08-04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of synthesis of gate-level descriptions of digital circuits from
behavioural specifications written in higher-level programming languages
(hardware compilation) has been studied for a long time yet a definitive
solution has not been forthcoming. The argument of this essay is mainly
methodological, bringing a perspective that is informed by recent developments
in programming-language theory. We argue that one of the major obstacles in the
way of hardware compilation becoming a useful and mature technology is the lack
of a well defined function interface model, i.e. a canonical way in which
functions communicate with arguments. We discuss the consequences of this
problem and propose a solution based on new developments in programming
language theory. We conclude by presenting a prototype implementation and some
examples illustrating our principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0774</identifier>
 <datestamp>2014-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0774</id><created>2009-07-04</created><updated>2009-12-25</updated><authors><author><keyname>Ivanyos</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author></authors><title>Deterministic Polynomial Time Algorithms for Matrix Completion Problems</title><categories>cs.DS cs.CC</categories><comments>14 pages, preliminary</comments><journal-ref>LMS J. of Computation and Mathematics 17 (2014)</journal-ref><doi>10.1112/S1461157013000296</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new deterministic algorithms for several cases of the maximum rank
matrix completion problem (for short matrix completion), i.e. the problem of
assigning values to the variables in a given symbolic matrix as to maximize the
resulting matrix rank. Matrix completion belongs to the fundamental problems in
computational complexity with numerous important algorithmic applications,
among others, in computing dynamic transitive closures or multicast network
codings (Harvey et al SODA 2005, Harvey et al SODA 2006).
  We design efficient deterministic algorithms for common generalizations of
the results of Lovasz and Geelen on this problem by allowing linear functions
in the entries of the input matrix such that the submatrices corresponding to
each variable have rank one. We present also a deterministic polynomial time
algorithm for finding the minimal number of generators of a given module
structure given by matrices. We establish further several hardness results
related to matrix algebras and modules. As a result we connect the classical
problem of polynomial identity testing with checking surjectivity (or
injectivity) between two given modules. One of the elements of our algorithm is
a construction of a greedy algorithm for finding a maximum rank element in the
more general setting of the problem. The proof methods used in this paper could
be also of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0783</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0783</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Bayesian Multitask Learning with Latent Hierarchies</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We learn multiple hypotheses for related tasks under a latent hierarchical
relationship between tasks. We exploit the intuition that for domain
adaptation, we wish to share classifier structure, but for multitask learning,
we wish to share covariance structure. Our hierarchical model is seen to
subsume several previously proposed multitask learning models and performs well
on three distinct real-world data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0784</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0784</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Cross-Task Knowledge-Constrained Self Training</title><categories>cs.LG cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithmic framework for learning multiple related tasks. Our
framework exploits a form of prior knowledge that relates the output spaces of
these tasks. We present PAC learning results that analyze the conditions under
which such learning is possible. We present results on learning a shallow
parser and named-entity recognition system that exploits our framework, showing
consistent improvements over baseline methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0785</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0785</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Campbell</keyname><forenames>Lyle</forenames></author></authors><title>A Bayesian Model for Discovering Typological Implications</title><categories>cs.CL</categories><journal-ref>ACL 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A standard form of analysis for linguistic typology is the universal
implication. These implications state facts about the range of extant
languages, such as ``if objects come after verbs, then adjectives come after
nouns.'' Such implications are typically discovered by painstaking hand
analysis over a small sample of languages. We propose a computational model for
assisting at this process. Our model is able to discover both well-known
implications as well as some novel implications that deserve further study.
Moreover, through a careful application of hierarchical analysis, we are able
to cope with the well-known sampling problem: languages are not independent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0786</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0786</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Marcu</keyname><forenames>Daniel</forenames></author></authors><title>Search-based Structured Prediction</title><categories>cs.LG cs.CL</categories><journal-ref>Machine Learning Journal 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Searn, an algorithm for integrating search and learning to solve
complex structured prediction problems such as those that occur in natural
language, speech, computational biology, and vision. Searn is a meta-algorithm
that transforms these complex problems into simple classification problems to
which any binary classifier may be applied. Unlike current algorithms for
structured learning that require decomposition of both the loss function and
the feature functions over the predicted structure, Searn is able to learn
prediction functions for any loss function and any class of features. Moreover,
Searn comes with a strong, natural theoretical guarantee: good performance on
the derived classification problems implies good performance on the structured
prediction problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0792</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0792</id><created>2009-07-04</created><authors><author><keyname>Raynolds</keyname><forenames>James E.</forenames></author><author><keyname>Mullin</keyname><forenames>Lenore M.</forenames></author></authors><title>A generalized inner and outer product of arbitrary multi-dimensional
  arrays using A Mathematics of Arrays (MoA)</title><categories>cs.MS cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm has been devised to compute the inner and outer product between
two arbitrary multi-dimensional arrays A and B in a single piece of code. It
was derived using A Mathematics of Arrays (MoA) and the $\psi$-calculus.
Extensive tests of the new algorithm are presented for running in sequential as
well as OpenMP multiple processor modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0796</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0796</id><created>2009-07-04</created><authors><author><keyname>Mullin</keyname><forenames>Lenore M.</forenames></author><author><keyname>Raynolds</keyname><forenames>James E.</forenames></author></authors><title>Tensors and n-d Arrays:A Mathematics of Arrays (MoA), psi-Calculus and
  the Composition of Tensor and Array Operations</title><categories>cs.MS cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kronecker product is a key algorithm and is ubiquitous across the
physical, biological, and computation social sciences. Thus considerations of
optimal implementation are important. The need to have high performance and
computational reproducibility is paramount. Moreover, due to the need to
compose multiple Kronecker products, issues related to data structures, layout
and indexing algebra require a new look at an old problem. This paper discusses
the outer product/tensor product and a special case of the tensor product: the
Kronecker product, along with optimal implementation when composed, and mapped
to complex processor/memory hierarchies. We discuss how the use of ``A
Mathematics of Arrays&quot; (MoA), and the psi-Calculus, (a calculus of indexing
with shapes), provides optimal, verifiable, reproducible, scalable, and
portable implementations of both hardware and software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0804</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0804</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Marcu</keyname><forenames>Daniel</forenames></author></authors><title>Induction of Word and Phrase Alignments for Automatic Document
  Summarization</title><categories>cs.CL</categories><journal-ref>Computational Linguistics, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current research in automatic single document summarization is dominated by
two effective, yet naive approaches: summarization by sentence extraction, and
headline generation via bag-of-words models. While successful in some tasks,
neither of these models is able to adequately capture the large set of
linguistic devices utilized by humans when they produce summaries. One possible
explanation for the widespread use of these models is that good techniques have
been developed to extract appropriate training data for them from existing
document/abstract and document/headline corpora. We believe that future
progress in automatic summarization will be driven both by the development of
more sophisticated, linguistically informed models, as well as a more effective
leveraging of document/abstract corpora. In order to open the doors to
simultaneously achieving both of these goals, we have developed techniques for
automatically producing word-to-word and phrase-to-phrase alignments between
documents and their human-written abstracts. These alignments make explicit the
correspondences that exist in such document/abstract pairs, and create a
potentially rich data source from which complex summarization algorithms may
learn. This paper describes experiments we have carried out to analyze the
ability of humans to perform such alignments, and based on these analyses, we
describe experiments for creating them automatically. Our model for the
alignment task is based on an extension of the standard hidden Markov model,
and learns to create alignments in a completely unsupervised fashion. We
describe our model in detail and present experimental results that show that
our model is able to learn to reliably identify word- and phrase-level
alignments in a corpus of &lt;document,abstract&gt; pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0806</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0806</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Marcu</keyname><forenames>Daniel</forenames></author></authors><title>A Noisy-Channel Model for Document Compression</title><categories>cs.CL</categories><journal-ref>ACL 2002</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a document compression system that uses a hierarchical
noisy-channel model of text production. Our compression system first
automatically derives the syntactic structure of each sentence and the overall
discourse structure of the text given as input. The system then uses a
statistical hierarchical model of text production in order to drop
non-important syntactic and discourse constituents so as to generate coherent,
grammatical document compressions of arbitrary length. The system outperforms
both a baseline and a sentence-based compression system that operates by
simplifying sequentially all sentences in a text. Our results support the claim
that discourse knowledge plays an important role in document summarization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0807</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0807</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Marcu</keyname><forenames>Daniel</forenames></author></authors><title>A Large-Scale Exploration of Effective Global Features for a Joint
  Entity Detection and Tracking Model</title><categories>cs.CL</categories><journal-ref>HLT/EMNLP 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entity detection and tracking (EDT) is the task of identifying textual
mentions of real-world entities in documents, extending the named entity
detection and coreference resolution task by considering mentions other than
names (pronouns, definite descriptions, etc.). Like NE tagging and coreference
resolution, most solutions to the EDT task separate out the mention detection
aspect from the coreference aspect. By doing so, these solutions are limited to
using only local features for learning. In contrast, by modeling both aspects
of the EDT task simultaneously, we are able to learn using highly complex,
non-local features. We develop a new joint EDT model and explore the utility of
many features, demonstrating their effectiveness on this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0808</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0808</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Marcu</keyname><forenames>Daniel</forenames></author></authors><title>A Bayesian Model for Supervised Clustering with the Dirichlet Process
  Prior</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a Bayesian framework for tackling the supervised clustering
problem, the generic problem encountered in tasks such as reference matching,
coreference resolution, identity uncertainty and record linkage. Our clustering
model is based on the Dirichlet process prior, which enables us to define
distributions over the countably infinite sets that naturally arise in this
problem. We add supervision to our model by positing the existence of a set of
unobserved random variables (we call these &quot;reference types&quot;) that are generic
across all clusters. Inference in our framework, which requires integrating
over infinitely many parameters, is solved using Markov chain Monte Carlo
techniques. We present algorithms for both conjugate and non-conjugate priors.
We present a simple--but general--parameterization of our model based on a
Gaussian assumption. We evaluate this model on one artificial task and three
real-world tasks, comparing it against both unsupervised and state-of-the-art
supervised algorithms. Our results show that our model is able to outperform
other models across a variety of tasks and performance metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0809</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0809</id><created>2009-07-04</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Marcu</keyname><forenames>Daniel</forenames></author></authors><title>Learning as Search Optimization: Approximate Large Margin Methods for
  Structured Prediction</title><categories>cs.LG cs.CL</categories><journal-ref>ICML 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mappings to structured output spaces (strings, trees, partitions, etc.) are
typically learned using extensions of classification algorithms to simple
graphical structures (eg., linear chains) in which search and parameter
estimation can be performed exactly. Unfortunately, in many complex problems,
it is rare that exact search or parameter estimation is tractable. Instead of
learning exact models and searching via heuristic means, we embrace this
difficulty and treat the structured output problem in terms of approximate
search. We present a framework for learning as search optimization, and two
parameter updates with convergence theorems and bounds. Empirical evidence
shows that our integrated approach to learning and decoding can outperform
exact models at smaller computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0821</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0821</id><created>2009-07-04</created><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author></authors><title>Breaking a new substitution-diffusion based image cipher using chaotic
  standard and logistic maps</title><categories>cs.CR</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, an image encryption scheme based on chaotic standard and logistic
maps was proposed. This paper studies the security of the scheme and shows that
it can be broken with only one chosen-plaintext. Some other security defects of
the scheme are also reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0877</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0877</id><created>2009-07-05</created><updated>2010-02-08</updated><authors><author><keyname>Bloom</keyname><forenames>S. L.</forenames></author><author><keyname>Esik</keyname><forenames>Z.</forenames></author></authors><title>Algebraic Ordinals</title><categories>cs.FL cs.LO</categories><comments>30 pages</comments><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algebraic tree T is one determined by a finite system of fixed point
equations. The frontier \Fr(T) of an algebraic tree t is linearly ordered by
the lexicographic order \lex. When (\Fr(T),\lex) is well-ordered, its order
type is an \textbf{algebraic ordinal}. We prove that the algebraic ordinals are
exactly the ordinals less than $\omega^{\omega^\omega}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0884</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0884</id><created>2009-07-05</created><updated>2010-10-18</updated><authors><author><keyname>Ailon</keyname><forenames>Nir</forenames></author><author><keyname>Chazelle</keyname><forenames>Bernard</forenames></author><author><keyname>Clarkson</keyname><forenames>Kenneth L.</forenames></author><author><keyname>Liu</keyname><forenames>Ding</forenames></author><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>Self-Improving Algorithms</title><categories>cs.DS cs.CG</categories><comments>26 pages, 8 figures, preliminary versions appeared at SODA 2006 and
  SoCG 2008. Thorough revision to improve the presentation of the paper</comments><acm-class>F.2.2; D.1; F.1.1; I.2.6</acm-class><journal-ref>SIAM Journal on Computing (SICOMP), 40(2), 2011, pp. 350-375</journal-ref><doi>10.1137/090766437</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate ways in which an algorithm can improve its expected
performance by fine-tuning itself automatically with respect to an unknown
input distribution D. We assume here that D is of product type. More precisely,
suppose that we need to process a sequence I_1, I_2, ... of inputs I = (x_1,
x_2, ..., x_n) of some fixed length n, where each x_i is drawn independently
from some arbitrary, unknown distribution D_i. The goal is to design an
algorithm for these inputs so that eventually the expected running time will be
optimal for the input distribution D = D_1 * D_2 * ... * D_n.
  We give such self-improving algorithms for two problems: (i) sorting a
sequence of numbers and (ii) computing the Delaunay triangulation of a planar
point set. Both algorithms achieve optimal expected limiting complexity. The
algorithms begin with a training phase during which they collect information
about the input distribution, followed by a stationary regime in which the
algorithms settle to their optimized incarnations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0907</identifier>
 <datestamp>2009-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0907</id><created>2009-07-05</created><updated>2009-07-09</updated><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>Randomized Incremental Construction of Compressed Quadtrees</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple randomized incremental algorithm for building compressed
quadtrees. The resulting algorithm seems to be simpler than previously known
algorithms for this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0914</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0914</id><created>2009-07-06</created><updated>2009-12-05</updated><authors><author><keyname>Kabashima</keyname><forenames>Y.</forenames></author><author><keyname>Wadayama</keyname><forenames>T.</forenames></author><author><keyname>Tanaka</keyname><forenames>T.</forenames></author></authors><title>A typical reconstruction limit of compressed sensing based on Lp-norm
  minimization</title><categories>cs.IT cond-mat.dis-nn math.IT math.ST stat.TH</categories><comments>12 pages, 2 figures</comments><journal-ref>J. Stat. Mech. (2009) L09003 (12 pages)</journal-ref><doi>10.1088/1742-5468/2009/09/L09003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reconstructing an $N$-dimensional continuous
vector $\bx$ from $P$ constraints which are generated by its linear
transformation under the assumption that the number of non-zero elements of
$\bx$ is typically limited to $\rho N$ ($0\le \rho \le 1$). Problems of this
type can be solved by minimizing a cost function with respect to the $L_p$-norm
$||\bx||_p=\lim_{\epsilon \to +0}\sum_{i=1}^N |x_i|^{p+\epsilon}$, subject to
the constraints under an appropriate condition. For several $p$, we assess a
typical case limit $\alpha_c(\rho)$, which represents a critical relation
between $\alpha=P/N$ and $\rho$ for successfully reconstructing the original
vector by minimization for typical situations in the limit $N,P \to \infty$
with keeping $\alpha$ finite, utilizing the replica method. For $p=1$,
$\alpha_c(\rho)$ is considerably smaller than its worst case counterpart, which
has been rigorously derived by existing literature of information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0929</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0929</id><created>2009-07-06</created><authors><author><keyname>Letia</keyname><forenames>Mihai</forenames><affiliation>LIP</affiliation></author><author><keyname>Pregui&#xe7;a</keyname><forenames>Nuno</forenames><affiliation>CITI/Sep. Inform&#xe1;tica, FCT</affiliation></author><author><keyname>Shapiro</keyname><forenames>Marc</forenames><affiliation>LIP6, Inria Rocquencourt</affiliation></author></authors><title>CRDTs: Consistency without concurrency control</title><categories>cs.DC</categories><proxy>ccsd inria-00397981</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A CRDT is a data type whose operations commute when they are concurrent.
Replicas of a CRDT eventually converge without any complex concurrency control.
As an existence proof, we exhibit a non-trivial CRDT: a shared edit buffer
called Treedoc. We outline the design, implementation and performance of
Treedoc. We discuss how the CRDT concept can be generalised, and its
limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0931</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0931</id><created>2009-07-06</created><updated>2010-01-14</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Distributed Sensor Selection using a Truncated Newton Method</title><categories>cs.IT math.IT</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new distributed algorithm for computing a truncated Newton
method, where the main diagonal of the Hessian is computed using belief
propagation. As a case study for this approach, we examine the sensor selection
problem, a Boolean convex optimization problem. We form two distributed
algorithms. The first algorithm is a distributed version of the interior point
method by Joshi and Boyd, and the second algorithm is an order of magnitude
faster approximation. As an example application we discuss distributed anomaly
detection in networks. We demonstrate the applicability of our solution using
both synthetic data and real traffic logs collected from the Abilene Internet
backbone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0937</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0937</id><created>2009-07-06</created><authors><author><keyname>Creignou</keyname><forenames>Nadia</forenames></author><author><keyname>Daude</keyname><forenames>Herve</forenames></author><author><keyname>Egly</keyname><forenames>Uwe</forenames></author><author><keyname>Rossignol</keyname><forenames>Raphael</forenames></author></authors><title>The threshold for random (1,2)-QSAT</title><categories>cs.DM</categories><comments>20 pages. Preliminary, conference versions of this article appeared
  in SAT08 and SAT09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The QSAT problem is the quantified version of the SAT problem. We show the
existence of a threshold effect for the phase transition associated with the
satisfiability of random quantified extended 2-CNF formulas. We consider
boolean CNF formulas of the form $\forall X \exists Y \varphi(X,Y)$, where $X$
has $m$ variables, $Y$ has $n$ variables and each clause in $\varphi$ has one
literal from $X$ and two from $Y$. For such formulas, we show that the
threshold phenomenon is controlled by the ratio between the number of clauses
and the number $n$ of existential variables. Then we give the exact location of
the associated critical ratio $c^{*}$. Indeed, we prove that $c^{*}$ is a
decreasing function of $ \alpha$, where $\alpha$ is the limiting value of $m /
\log (n)$ when $n$ tends to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0939</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0939</id><created>2009-07-06</created><updated>2009-07-07</updated><authors><author><keyname>Petit</keyname><forenames>Thierry</forenames></author><author><keyname>Poder</keyname><forenames>Emmanuel</forenames></author></authors><title>The Soft Cumulative Constraint</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research report presents an extension of Cumulative of Choco constraint
solver, which is useful to encode over-constrained cumulative problems. This
new global constraint uses sweep and task interval violation-based algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0942</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0942</id><created>2009-07-06</created><authors><author><keyname>Emilie</keyname><forenames>Charlier</forenames></author><author><keyname>Marion</keyname><forenames>Le Gonidec</forenames></author><author><keyname>Michel</keyname><forenames>Rigo</forenames></author></authors><title>Representing Real Numbers in a Generalized Numeration Systems</title><categories>cs.FL</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to represent an interval of real numbers in an abstract
numeration system built on a language that is not necessarily regular. As an
application, we consider representations of real numbers using the Dyck
language. We also show that our framework can be applied to the rational base
numeration systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0944</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0944</id><created>2009-07-06</created><updated>2009-08-11</updated><authors><author><keyname>Wiaux</keyname><forenames>Y.</forenames></author><author><keyname>Puy</keyname><forenames>G.</forenames></author><author><keyname>Boursier</keyname><forenames>Y.</forenames></author><author><keyname>Vandergheynst</keyname><forenames>P.</forenames></author></authors><title>Spread spectrum for imaging techniques in radio interferometry</title><categories>astro-ph.IM cs.IT math.IT</categories><comments>10 pages, 3 figures. Version 2 matches version accepted for
  publication in MNRAS. Changes include minor clarifications</comments><journal-ref>Mon. Not. R. Astron. Soc. 400 (2009) 1029</journal-ref><doi>10.1111/j.1365-2966.2009.15519.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the probe of astrophysical signals through radio interferometers
with small field of view and baselines with non-negligible and constant
component in the pointing direction. In this context, the visibilities measured
essentially identify with a noisy and incomplete Fourier coverage of the
product of the planar signals with a linear chirp modulation. In light of the
recent theory of compressed sensing and in the perspective of defining the best
possible imaging techniques for sparse signals, we analyze the related spread
spectrum phenomenon and suggest its universality relative to the sparsity
dictionary. Our results rely both on theoretical considerations related to the
mutual coherence between the sparsity and sensing dictionaries, as well as on
numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.0971</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.0971</id><created>2009-07-06</created><updated>2009-07-13</updated><authors><author><keyname>Didier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Laigle-Chapuy</keyname><forenames>Yann</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Attacking the combination generator</title><categories>cs.CR</categories><proxy>ccsd hal-00401908</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present one of the most efficient attacks against the combination
generator. This attack is inherent to this system as its only assumption is
that the filtering function has a good autocorrelation. This is usually the
case if the system is designed to be resistant to other kinds of attacks. We
use only classical tools, namely vectorial correlation, weight 4 multiples and
Walsh transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1005</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1005</id><created>2009-07-06</created><authors><author><keyname>Cohen</keyname><forenames>Julien</forenames><affiliation>LINA</affiliation></author></authors><title>A class of structured P2P systems supporting browsing</title><categories>cs.IR cs.DC</categories><comments>14 pages</comments><proxy>ccsd hal-00402087</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Browsing is a way of finding documents in a large amount of data which is
complementary to querying and which is particularly suitable for multimedia
documents. Locating particular documents in a very large collection of
multimedia documents such as the ones available in peer to peer networks is a
difficult task. However, current peer to peer systems do not allow to do this
by browsing. In this report, we show how one can build a peer to peer system
supporting a kind of browsing. In our proposal, one must extend an existing
distributed hash table system with a few features : handling partial hash-keys
and providing appropriate routing mechanisms for these hash-keys. We give such
an algorithm for the particular case of the Tapestry distributed hash table.
This is a work in progress as no proper validation has been done yet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1012</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1012</id><created>2009-07-06</created><updated>2009-07-06</updated><authors><author><keyname>Pang</keyname><forenames>Chao-Yang</forenames></author><author><keyname>Hu</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Xia</forenames></author><author><keyname>Hu</keyname><forenames>Be-Qiong</forenames></author></authors><title>Apply Local Clustering Method to Improve the Running Speed of Ant Colony
  Optimization</title><categories>cs.NE cs.AI</categories><comments>21 pages, 5figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ant Colony Optimization (ACO) has time complexity O(t*m*N*N), and its typical
application is to solve Traveling Salesman Problem (TSP), where t, m, and N
denotes the iteration number, number of ants, number of cities respectively.
Cutting down running time is one of study focuses, and one way is to decrease
parameter t and N, especially N. For this focus, the following method is
presented in this paper. Firstly, design a novel clustering algorithm named
Special Local Clustering algorithm (SLC), then apply it to classify all cities
into compact classes, where compact class is the class that all cities in this
class cluster tightly in a small region. Secondly, let ACO act on every class
to get a local TSP route. Thirdly, all local TSP routes are jointed to form
solution. Fourthly, the inaccuracy of solution caused by clustering is
eliminated. Simulation shows that the presented method improves the running
speed of ACO by 200 factors at least. And this high speed is benefit from two
factors. One is that class has small size and parameter N is cut down. The
route length at every iteration step is convergent when ACO acts on compact
class. The other factor is that, using the convergence of route length as
termination criterion of ACO and parameter t is cut down.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1050</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1050</id><created>2009-07-06</created><updated>2009-09-23</updated><authors><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author><author><keyname>Markines</keyname><forenames>Benjamin</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>Diffusion of scientific credits and the ranking of scientists</title><categories>physics.soc-ph cs.DL physics.data-an</categories><comments>Revised version. 11 pages, 10 figures, 1 table. The portal to compute
  the rankings of scientists is at http://www.physauthorsrank.org</comments><journal-ref>Phys. Rev. E 80, 056103 (2009)</journal-ref><doi>10.1103/PhysRevE.80.056103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the abundance of digital data enabled the implementation of graph
based ranking algorithms that provide system level analysis for ranking
publications and authors. Here we take advantage of the entire Physical Review
publication archive (1893-2006) to construct authors' networks where weighted
edges, as measured from opportunely normalized citation counts, define a proxy
for the mechanism of scientific credit transfer. On this network we define a
ranking method based on a diffusion algorithm that mimics the spreading of
scientific credits on the network. We compare the results obtained with our
algorithm with those obtained by local measures such as the citation count and
provide a statistical analysis of the assignment of major career awards in the
area of Physics. A web site where the algorithm is made available to perform
customized rank analysis can be found at the address
http://www.physauthorsrank.org
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1054</identifier>
 <datestamp>2010-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1054</id><created>2009-07-06</created><updated>2010-05-13</updated><authors><author><keyname>Belkin</keyname><forenames>Mikhail</forenames></author><author><keyname>Sinha</keyname><forenames>Kaushik</forenames></author></authors><title>Learning Gaussian Mixtures with Arbitrary Separation</title><categories>cs.LG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a method for learning the parameters of a mixture of
$k$ identical spherical Gaussians in $n$-dimensional space with an arbitrarily
small separation between the components. Our algorithm is polynomial in all
parameters other than $k$. The algorithm is based on an appropriate grid search
over the space of parameters. The theoretical analysis of the algorithm hinges
on a reduction of the problem to 1 dimension and showing that two 1-dimensional
mixtures whose densities are close in the $L^2$ norm must have similar means
and mixing coefficients. To produce such a lower bound for the $L^2$ norm in
terms of the distances between the corresponding means, we analyze the behavior
of the Fourier transform of a mixture of Gaussians in 1 dimension around the
origin, which turns out to be closely related to the properties of the
Vandermonde matrix obtained from the component means. Analysis of this matrix
together with basic function approximation results allows us to provide a lower
bound for the norm of the mixture in the Fourier domain.
  In recent years much research has been aimed at understanding the
computational aspects of learning parameters of Gaussians mixture distributions
in high dimension. To the best of our knowledge all existing work on learning
parameters of Gaussian mixtures assumes minimum separation between components
of the mixture which is an increasing function of either the dimension of the
space $n$ or the number of components $k$. In our paper we prove the first
result showing that parameters of a $n$-dimensional Gaussian mixture model with
arbitrarily small component separation can be learned in time polynomial in
$n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1061</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1061</id><created>2009-07-06</created><updated>2013-12-10</updated><authors><author><keyname>Atia</keyname><forenames>George Kamal</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Boolean Compressed Sensing and Noisy Group Testing</title><categories>cs.IT math.IT</categories><comments>In this revision: reorganized the paper, added citations to related
  work, and fixed some bugs</comments><journal-ref>IEEE Trans.Inf.Theory 58 (2012) 1880-1901</journal-ref><doi>10.1109/TIT.2011.2178156</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental task of group testing is to recover a small distinguished
subset of items from a large population while efficiently reducing the total
number of tests (measurements). The key contribution of this paper is in
adopting a new information-theoretic perspective on group testing problems. We
formulate the group testing problem as a channel coding/decoding problem and
derive a single-letter characterization for the total number of tests used to
identify the defective set. Although the focus of this paper is primarily on
group testing, our main result is generally applicable to other compressive
sensing models.
  The single letter characterization is shown to be order-wise tight for many
interesting noisy group testing scenarios. Specifically, we consider an
additive Bernoulli($q$) noise model where we show that, for $N$ items and $K$
defectives, the number of tests $T$ is $O(\frac{K\log N}{1-q})$ for arbitrarily
small average error probability and $O(\frac{K^2\log N}{1-q})$ for a worst case
error criterion. We also consider dilution effects whereby a defective item in
a positive pool might get diluted with probability $u$ and potentially missed.
In this case, it is shown that $T$ is $O(\frac{K\log N}{(1-u)^2})$ and
$O(\frac{K^2\log N}{(1-u)^2})$ for the average and the worst case error
criteria, respectively. Furthermore, our bounds allow us to verify existing
known bounds for noiseless group testing including the deterministic noise-free
case and approximate reconstruction with bounded distortion. Our proof of
achievability is based on random coding and the analysis of a Maximum
Likelihood Detector, and our information theoretic lower bound is based on
Fano's inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1065</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1065</id><created>2009-07-06</created><authors><author><keyname>Narayanam</keyname><forenames>Ramasuri</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author></authors><title>Design of an Optimal Bayesian Incentive Compatible Broadcast Protocol
  for Ad hoc Networks with Rational Nodes</title><categories>cs.GT cs.AI cs.DC cs.NI</categories><comments>This version of the manuscript is published in IEEE Journal on
  Selected Areas in Communications (IEEE JSAC), VOL. 26, NO. 7, September 2008</comments><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nodes in an ad hoc wireless network incur certain costs for forwarding
packets since packet forwarding consumes the resources of the nodes. If the
nodes are rational, free packet forwarding by the nodes cannot be taken for
granted and incentive based protocols are required to stimulate cooperation
among the nodes. Existing incentive based approaches are based on the VCG
(Vickrey-Clarke-Groves) mechanism which leads to high levels of incentive
budgets and restricted applicability to only certain topologies of networks.
Moreover, the existing approaches have only focused on unicast and multicast.
Motivated by this, we propose an incentive based broadcast protocol that
satisfies Bayesian incentive compatibility and minimizes the incentive budgets
required by the individual nodes. The proposed protocol, which we call {\em
BIC-B} (Bayesian incentive compatible broadcast) protocol, also satisfies
budget balance. We also derive a necessary and sufficient condition for the
ex-post individual rationality of the BIC-B protocol. The {\em BIC-B} protocol
exhibits superior performance in comparison to a dominant strategy incentive
compatible broadcast protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1072</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1072</id><created>2009-07-06</created><updated>2011-07-20</updated><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Self-Assembling Systems are Distributed Systems</title><categories>cs.FL cs.DC cs.RO</categories><comments>Withdrawing because I would like to polish this before submitting it
  publicly again</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2004, Klavins et al. introduced the use of graph grammars to describe --
and to program -- systems of self-assembly. We show that these graph grammars
can be embedded in a graph rewriting characterization of distributed systems
that was proposed by Degano and Montanari over twenty years ago. We apply this
embedding to generalize Soloveichik and Winfree's local determinism criterion
(for achieving a unique terminal assembly), from assembly systems of 4-sided
tiles that embed in the plane, to arbitrary graph assembly systems. We present
a partial converse of the embedding result, by providing sufficient conditions
under which systems of distributed processors can be simulated by graph
assembly systems topologically, in the plane, and in 3-space. We conclude by
defining a new complexity measure: &quot;surface cost&quot; (essentially the convex hull
of the space inhabited by agents at the conclusion of a self-assembled
computation). We show that, for growth-bounded graphs, executing a subroutine
to find a Maximum Independent Set only increases the surface cost of a
self-assembling computation by a constant factor. We obtain this complexity
bound by using the simulation results to import the distributed computing
notions of &quot;local synchronizer&quot; and &quot;deterministic coin flipping&quot; into
self-assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1080</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1080</id><created>2009-07-06</created><authors><author><keyname>Gibson</keyname><forenames>Matt</forenames></author><author><keyname>Kanade</keyname><forenames>Gaurav</forenames></author><author><keyname>Krohn</keyname><forenames>Erik</forenames></author><author><keyname>Varadarajan</keyname><forenames>Kasturi</forenames></author></authors><title>Quasi-Polynomial Time Approximation Schemes for Target Tracking</title><categories>cs.CG</categories><comments>16 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of tracking $n$ targets in the plane using $2n$
cameras. We can use two cameras to estimate the location of a target. We are
then interested in forming $n$ camera pairs where each camera belongs to
exactly one pair, followed by forming a matching between the targets and camera
pairs so as to best estimate the locations of each of the targets. We consider
a special case of this problem where each of the cameras are placed along a
horizontal line $l$, and we consider two objective functions which have been
shown to give good estimates of the locations of the targets when the distances
between the targets and the cameras are sufficiently large. In the first
objective, the value of an assignment of a camera pair to a target is the
tracking angle formed by the assignment. Here, we are interested in maximizing
the sum of these tracking angles. A polynomial time 2-approximation is known
for this problem. We give a quasi-polynomial time algorithm that returns a
solution whose value is at least a $(1-\epsilon)$ factor of the value of an
optimal solution for any $\epsilon &gt; 0$. In the second objective, the cost of
an assignment of a camera pair to a target is the ratio of the vertical
distance between the target and $l$ to the horizontal distance between the
cameras in the camera pair. In this setting, we are interested in minimizing
the sum of these ratios. A polynomial time 2-approximation is known for this
problem. We give a quasi-polynomial time algorithm that returns a solution
whose value is at most a $(1+\epsilon)$ factor of the value of an optimal
solution for any $\epsilon &gt; 0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1099</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1099</id><created>2009-07-06</created><authors><author><keyname>Ravindran</keyname><forenames>Niranjay</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Multi-User Diversity vs. Accurate Channel State Information in MIMO
  Downlink Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications, July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multiple transmit antenna, single antenna per receiver downlink channel
with limited channel state feedback, we consider the following question: given
a constraint on the total system-wide feedback load, is it preferable to get
low-rate/coarse channel feedback from a large number of receivers or
high-rate/high-quality feedback from a smaller number of receivers? Acquiring
feedback from many receivers allows multi-user diversity to be exploited, while
high-rate feedback allows for very precise selection of beamforming directions.
We show that there is a strong preference for obtaining high-quality feedback,
and that obtaining near-perfect channel information from as many receivers as
possible provides a significantly larger sum rate than collecting a few
feedback bits from a large number of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1103</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1103</id><created>2009-07-06</created><authors><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author></authors><title>A Lower Bound for Succinct Rank Queries</title><categories>cs.DS cs.CC</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rank problem in succinct data structures asks to preprocess an array
A[1..n] of bits into a data structure using as close to n bits as possible, and
answer queries of the form rank(k) = Sum_{i=1}^k A[i]. The problem has been
intensely studied, and features as a subroutine in a majority of succinct data
structures.
  We show that in the cell probe model with w-bit cells, if rank takes t time,
the space of the data structure must be at least n + n/w^{O(t)} bits. This
redundancy/query trade-off is essentially optimal, matching our upper bound
from [FOCS'08].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1131</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1131</id><created>2009-07-06</created><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>Approximating Spanning Trees with Low Crossing Number</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a linear programming based algorithm for computing a spanning tree
$T$ of a set $P$ of $n$ points in $\Re^d$, such that its crossing number is
$O(\min(t \log n, n^{1-1/d}))$, where $t$ the minimum crossing number of any
spanning tree of $P$. This is the first guaranteed approximation algorithm for
this problem. We provide a similar approximation algorithm for the more general
settings of building a spanning tree for a set system with bounded \VC
dimension. Our approach is an alternative to the reweighting technique
previously used in computing such spanning trees.
  Our approach is an alternative to the reweighting technique previously used
in computing such spanning trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1201</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1201</id><created>2009-07-07</created><authors><author><keyname>Avni</keyname><forenames>Nir</forenames></author><author><keyname>Weiss</keyname><forenames>Benjamin</forenames></author></authors><title>Generating Product Systems</title><categories>math.DS cs.IT math.IT</categories><msc-class>28D20; 60G10; 37A35; 68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalizing Krieger's finite generation theorem, we give conditions for an
ergodic system to be generated by a pair of partitions, each required to be
measurable with respect to a given sub-algebra, and also required to have a
fixed size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1224</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1224</id><created>2009-07-07</created><updated>2009-10-14</updated><authors><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Guo</keyname><forenames>Qiang</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Effect of user tastes on personalized recommendation</title><categories>physics.data-an cs.IR physics.soc-ph</categories><comments>8 pages, 4 figures</comments><journal-ref>IJMPC 20(12) 2009 1925-1932</journal-ref><doi>10.1142/S0129183109014825</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, based on a weighted projection of the user-object bipartite
network, we study the effects of user tastes on the mass-diffusion-based
personalized recommendation algorithm, where a user's tastes or interests are
defined by the average degree of the objects he has collected. We argue that
the initial recommendation power located on the objects should be determined by
both of their degree and the users' tastes. By introducing a tunable parameter,
the user taste effects on the configuration of initial recommendation power
distribution are investigated. The numerical results indicate that the
presented algorithm could improve the accuracy, measured by the average ranking
score, more importantly, we find that when the data is sparse, the algorithm
should give more recommendation power to the objects whose degrees are close to
the users' tastes, while when the data becomes dense, it should assign more
power on the objects whose degrees are significantly different from user's
tastes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1227</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1227</id><created>2009-07-07</created><authors><author><keyname>Halevi</keyname><forenames>Tzipora</forenames></author><author><keyname>Saxena</keyname><forenames>Nitesh</forenames></author><author><keyname>Halevi</keyname><forenames>Shai</forenames></author></authors><title>Using HB Family of Protocols for Privacy-Preserving Authentication of
  RFID Tags in a Population</title><categories>cs.CR</categories><comments>15 pages, 1 figure, presented at RFIDSec 09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an HB-like protocol for privacy-preserving
authentication of RFID tags, whereby a tag can remain anonymous and untraceable
to an adversary during the authentication process. Previous proposals of such
protocols were based on PRF computations. Our protocol can instead be used on
low-cost tags that may be incapable of computing standard PRFs. Moreover, since
the underlying computations in HB protocols are very efficient, our protocol
also reduces reader load compared to PRF-based protocols.
  We suggest a tree-based approach that replaces the PRF-based authentication
from prior work with a procedure such as HB+ or HB#. We optimize the tree-
traversal stage through usage of a &quot;light version&quot; of the underlying protocol
and shared random challenges across all levels of the tree. This provides
significant reduction of the communication resources, resulting in a
privacy-preserving protocol almost as efficient as the underlying HB+ or HB#
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1228</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1228</id><created>2009-07-07</created><authors><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Xuan</keyname><forenames>Zhao-Guo</forenames></author><author><keyname>Che</keyname><forenames>Hong-An</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Degree correlation effect of bipartite network on personalized
  recommendation</title><categories>physics.data-an cs.IR physics.soc-ph</categories><comments>9 pages, 3 figures</comments><journal-ref>IJMPC 21(01) 2010 137-147</journal-ref><doi>10.1142/S0129183110014999</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, by introducing a new user similarity index base on the
diffusion process, we propose a modified collaborative filtering (MCF)
algorithm, which has remarkably higher accuracy than the standard collaborative
filtering. In the proposed algorithm, the degree correlation between users and
objects is taken into account and embedded into the similarity index by a
tunable parameter. The numerical simulation on a benchmark data set shows that
the algorithmic accuracy of the MCF, measured by the average ranking score, is
further improved by 18.19% in the optimal case. In addition, two significant
criteria of algorithmic performance, diversity and popularity, are also taken
into account. Numerical results show that the presented algorithm can provide
more diverse and less popular recommendations, for example, when the
recommendation list contains 10 objects, the diversity, measured by the hamming
distance, is improved by 21.90%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1238</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1238</id><created>2009-07-07</created><authors><author><keyname>Buferli</keyname><forenames>Matteo</forenames></author><author><keyname>Magnani</keyname><forenames>Matteo</forenames></author><author><keyname>Montesi</keyname><forenames>Danilo</forenames></author></authors><title>ChOrDa: a methodology for the modeling of business processes with BPMN</title><categories>cs.SE</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a modeling methodology for BPMN, the standard
notation for the representation of business processes. Our methodology
simplifies the development of collaborative BPMN diagrams, enabling the
automated creation of skeleton process diagrams representing complex
choreographies. To evaluate and tune the methodology, we have developed a tool
supporting it, that we apply to the modeling of an international patenting
process as a working example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1245</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1245</id><created>2009-07-07</created><authors><author><keyname>Kuhn</keyname><forenames>Tobias</forenames></author></authors><title>How Controlled English can Improve Semantic Wikis</title><categories>cs.HC cs.AI</categories><acm-class>H.5.2; I.2.4</acm-class><journal-ref>In Proceedings of the Fourth Semantic Wiki Workshop (SemWiki
  2009), co-located with 6th European Semantic Web Conference (ESWC 2009), CEUR
  Workshop Proceedings, Volume 464, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The motivation of semantic wikis is to make acquisition, maintenance, and
mining of formal knowledge simpler, faster, and more flexible. However, most
existing semantic wikis have a very technical interface and are restricted to a
relatively low level of expressivity. In this paper, we explain how AceWiki
uses controlled English - concretely Attempto Controlled English (ACE) - to
provide a natural and intuitive interface while supporting a high degree of
expressivity. We introduce recent improvements of the AceWiki system and user
studies that indicate that AceWiki is usable and useful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1251</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1251</id><created>2009-07-07</created><authors><author><keyname>Kuhn</keyname><forenames>Tobias</forenames></author></authors><title>How to Evaluate Controlled Natural Languages</title><categories>cs.HC</categories><acm-class>H.5.2; I.2.4</acm-class><journal-ref>In Pre-Proceedings of the Workshop on Controlled Natural Language
  (CNL 2009), CEUR Workshop Proceedings, Volume 448, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a general framework how controlled natural languages can
be evaluated and compared on the basis of user experiments. The subjects are
asked to classify given statements (in the language to be tested) as either
true or false with respect to a certain situation that is shown in a graphical
notation called &quot;ontographs&quot;. A first experiment has been conducted that
applies this framework to the language Attempto Controlled English (ACE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1255</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1255</id><created>2009-07-07</created><updated>2009-12-24</updated><authors><author><keyname>Perlaza</keyname><forenames>S. M.</forenames></author><author><keyname>Fawaz</keyname><forenames>N.</forenames></author><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author></authors><title>From Spectrum Pooling to Space Pooling: Opportunistic Interference
  Alignment in MIMO Cognitive Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. in Signal Processing. Revised on 23-11-09</comments><doi>10.1109/TSP.2010.2046084</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a non-cooperative interference alignment (IA) technique which
allows an opportunistic multiple input multiple output (MIMO) link (secondary)
to harmlessly coexist with another MIMO link (primary) in the same frequency
band. Assuming perfect channel knowledge at the primary receiver and
transmitter, capacity is achieved by transmiting along the spatial directions
(SD) associated with the singular values of its channel matrix using a
water-filling power allocation (PA) scheme. Often, power limitations lead the
primary transmitter to leave some of its SD unused. Here, it is shown that the
opportunistic link can transmit its own data if it is possible to align the
interference produced on the primary link with such unused SDs. We provide both
a processing scheme to perform IA and a PA scheme which maximizes the
transmission rate of the opportunistic link. The asymptotes of the achievable
transmission rates of the opportunistic link are obtained in the regime of
large numbers of antennas. Using this result, it is shown that depending on the
signal-to-noise ratio and the number of transmit and receive antennas of the
primary and opportunistic links, both systems can achieve transmission rates of
the same order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1256</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1256</id><created>2009-07-07</created><authors><author><keyname>Saxena</keyname><forenames>Nitesh</forenames></author><author><keyname>Voris</keyname><forenames>Jonathan</forenames></author></authors><title>We Can Remember It for You Wholesale: Implications of Data Remanence on
  the Use of RAM for True Random Number Generation on RFID Tags (RFIDSec 2009)</title><categories>cs.CR</categories><comments>Presented at the 5th Workshop on RFID Security held from June 30 -
  July 2 in Leuven, Belgium. Paper is 13 pages with 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random number generation is a fundamental security primitive for RFID
devices. However, even this relatively simple requirement is beyond the
capacity of today's average RFID tag. A recently proposed solution, Fingerprint
Extraction and Random Number Generation in SRAM (FERNS) [14, 15], involves the
use of onboard RAM as the source of &quot;true&quot; randomness. Unfortunately, practical
considerations prevent this approach from reaching its full potential. First,
this method must compete with other system functionalities for use of memory.
Thus, the amount of uninitialized RAM available for utilization as a randomness
generator may be severely restricted. Second, RAM is subject to data remanence;
there is a time period after losing power during which stored data remains
intact in memory. This means that after a portion of memory has been used for
entropy collection once it will require a relatively extended period of time
without power before it can be reused. In a usable RFID based security
application, which requires multiple or long random numbers, this may lead to
unacceptably high delays.
  In this paper, we show that data remanence negatively affects RAM based
random number generation. We demonstrate the practical considerations that must
be taken into account when using RAM as an entropy source. We also discuss the
implementation of a true random number generator on Intel's WISP RFID tag,
which is the first such implementation to the authors' best knowledge. By
relating this to the requirements of some popular RFID authentication
protocols, we assess the (im)practicality of utilizing memory based randomness
techniques on resource constrained devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1266</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1266</id><created>2009-07-07</created><authors><author><keyname>Jiang</keyname><forenames>Libin</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>Distributed Random Access Algorithm: Scheduling and Congesion Control</title><categories>cs.IT cs.NI math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides proofs of the rate stability, Harris recurrence, and
epsilon-optimality of CSMA algorithms where the backoff parameter of each node
is based on its backlog. These algorithms require only local information and
are easy to implement.
  The setup is a network of wireless nodes with a fixed conflict graph that
identifies pairs of nodes whose simultaneous transmissions conflict. The paper
studies two algorithms. The first algorithm schedules transmissions to keep up
with given arrival rates of packets. The second algorithm controls the arrivals
in addition to the scheduling and attempts to maximize the sum of the utilities
of the flows of packets at the different nodes. For the first algorithm, the
paper proves rate stability for strictly feasible arrival rates and also Harris
recurrence of the queues. For the second algorithm, the paper proves the
epsilon-optimality. Both algorithms operate with strictly local information in
the case of decreasing step sizes, and operate with the additional information
of the number of nodes in the network in the case of constant step size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1280</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1280</id><created>2009-07-07</created><authors><author><keyname>King</keyname><forenames>James</forenames></author><author><keyname>Krohn</keyname><forenames>Erik</forenames></author></authors><title>The Complexity of Guarding Terrains</title><categories>cs.CG</categories><comments>26 pages, 24 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set $G$ of points on a 1.5-dimensional terrain, also known as an
$x$-monotone polygonal chain, is said to guard the terrain if any point on the
terrain is 'seen' by a point in $G$. Two points on the terrain see each other
if and only if the line segment between them is never strictly below the
terrain. The minimum terrain guarding problem asks for a minimum guarding set
for the given input terrain. We prove that the decision version of this problem
is NP-hard. This solves a significant open problem and complements recent
positive approximability results for the optimization problem.
  Our proof uses a reduction from PLANAR 3-SAT. We build gadgets capable of
'mirroring' a consistent variable assignment back and forth across a main
valley. The structural simplicity of 1.5-dimensional terrains makes it
difficult to build general clause gadgets that do not destroy this assignment
when they are evaluated. However, we exploit the structure in instances of
PLANAR 3-SAT to find very specific operations involving only 'adjacent'
variables. For these restricted operations we can construct gadgets that allow
a full reduction to work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1295</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1295</id><created>2009-07-07</created><authors><author><keyname>Gupta</keyname><forenames>Ankur</forenames></author><author><keyname>Kispert</keyname><forenames>Anna</forenames></author><author><keyname>Sorenson</keyname><forenames>Jonathan P.</forenames></author></authors><title>Online Sorting via Searching and Selection</title><categories>cs.DS</categories><acm-class>F.2.2;E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a framework based on a simple data structure and
parameterized algorithms for the problems of finding items in an unsorted list
of linearly ordered items based on their rank (selection) or value (search). As
a side-effect of answering these online selection and search queries, we
progressively sort the list. Our algorithms are based on Hoare's Quickselect,
and are parameterized based on the pivot selection method.
  For example, if we choose the pivot as the last item in a subinterval, our
framework yields algorithms that will answer q&lt;=n unique selection and/or
search queries in a total of O(n log q) average time. After q=\Omega(n) queries
the list is sorted. Each repeated selection query takes constant time, and each
repeated search query takes O(log n) time. The two query types can be
interleaved freely. By plugging different pivot selection methods into our
framework, these results can, for example, become randomized expected time or
deterministic worst-case time. Our methods are easy to implement, and we show
they perform well in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1297</identifier>
 <datestamp>2014-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1297</id><created>2009-07-07</created><updated>2014-09-18</updated><authors><author><keyname>Bravyi</keyname><forenames>Sergey</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>Bounds on the quantum satisfiability threshold</title><categories>quant-ph cond-mat.stat-mech cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum k-SAT is the problem of deciding whether there is a n-qubit state
which is perpendicular to a set of vectors, each of which lies in the Hilbert
space of k qubits. Equivalently, the problem is to decide whether a particular
type of local Hamiltonian has a ground state with zero energy. We consider
random quantum k-SAT formulas with n variables and m = \alpha n clauses, and
ask at what value of \alpha these formulas cease to be satisfiable. We show
that the threshold for random quantum 3-SAT is at most 3.594. For comparison,
convincing arguments from statistical physics suggest that the classical 3-SAT
threshold is \alpha \approx 4.267. For larger k, we show that the quantum
threshold is a constant factor smaller than the classical one. Our bounds work
by determining the generic rank of the satisfying subspace for certain gadgets,
and then using the technique of differential equations to analyze various
algorithms that partition the hypergraph into a collection of these gadgets.
Our use of differential equation to establish upper bounds on a satisfiability
threshold appears to be novel, and our techniques may apply to various
classical problems as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1307</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1307</id><created>2009-07-07</created><authors><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author></authors><title>Reducing Tile Complexity for the Self-Assembly of Scaled Shapes Through
  Temperature Programming</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the self-assembly of scaled-up versions of arbitrary
finite shapes. We work in the multiple temperature model that was introduced by
Aggarwal, Cheng, Goldwasser, Kao, and Schweller (Complexities for Generalized
Models of Self-Assembly, SODA 2004). The multiple temperature model is a
natural generalization of Winfree's abstract tile assembly model, where the
temperature of a tile system is allowed to be shifted up and down as
self-assembly proceeds. We first exhibit two constant-size tile sets in which
scaled-up versions of arbitrary shapes self-assemble. Our first tile set has
the property that each scaled shape self-assembles via an asymptotically
&quot;Kolmogorov-optimum&quot; temperature sequence but the scaling factor grows with the
size of the shape being assembled. In contrast, our second tile set assembles
each scaled shape via a temperature sequence whose length is proportional to
the number of points in the shape but the scaling factor is a constant
independent of the shape being assembled. We then show that there is no
constant-size tile set that can uniquely assemble an arbitrary (non-scaled,
connected) shape in the multiple temperature model, i.e., the scaling is
necessary for self-assembly. This answers an open question of Kao and Schweller
(Reducing Tile Complexity for Self-Assembly Through Temperature Programming,
SODA 2006), who asked whether such a tile set existed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1334</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1334</id><created>2009-07-08</created><authors><author><keyname>Deng</keyname><forenames>Xiaotie</forenames></author><author><keyname>Qi</keyname><forenames>Qi</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author></authors><title>On the Complexity of Envy-Free Cake Cutting</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the envy-free cake-cutting problem for $d+1$ players with $d$ cuts,
for both the oracle function model and the polynomial time function model. For
the former, we derive a $\theta(({1\over\epsilon})^{d-1})$ time matching bound
for the query complexity of $d+1$ player cake cutting with Lipschitz utilities
for any $d&gt; 1$. When the utility functions are given by a polynomial time
algorithm, we prove the problem to be PPAD-complete.
  For measurable utility functions, we find a fully polynomial-time algorithm
for finding an approximate envy-free allocation of a cake among three people
using two cuts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1357</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1357</id><created>2009-07-08</created><authors><author><keyname>Couchot</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LIFC</affiliation></author><author><keyname>Giorgetti</keyname><forenames>Alain</forenames><affiliation>LIFC</affiliation></author><author><keyname>Stouls</keyname><forenames>Nicolas</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Graph Based Reduction of Program Verification Conditions</title><categories>cs.LO</categories><proxy>ccsd inria-00402204</proxy><journal-ref>Automated Formal Methods (AFM'09), colocated with CAV'09 (2009)
  40-47</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing the automaticity of proofs in deductive verification of C programs
is a challenging task. When applied to industrial C programs known heuristics
to generate simpler verification conditions are not efficient enough. This is
mainly due to their size and a high number of irrelevant hypotheses. This work
presents a strategy to reduce program verification conditions by selecting
their relevant hypotheses. The relevance of a hypothesis is determined by the
combination of a syntactic analysis and two graph traversals. The first graph
is labeled by constants and the second one by the predicates in the axioms. The
approach is applied on a benchmark arising in industrial program verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1369</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1369</id><created>2009-07-08</created><authors><author><keyname>Pal</keyname><forenames>Manjish</forenames></author></authors><title>Towards an $O(\sqrt[3]{\log n})$-Approximation Algorithm for {\sc
  Balanced Separator}</title><categories>cs.DS</categories><acm-class>F.2.2; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\sc $c$-Balanced Separator} problem is a graph-partitioning problem in
which given a graph $G$, one aims to find a cut of minimum size such that both
the sides of the cut have at least $cn$ vertices. In this paper, we present new
directions of progress in the {\sc $c$-Balanced Separator} problem. More
specifically, we propose a new family of mathematical programs, which depends
upon a parameter $\epsilon &gt; 0$, and extend the seminal work of
Arora-Rao-Vazirani ({\sf ARV}) \cite{ARV} to show that the polynomial time
solvability of the proposed family of programs implies an improvement in the
approximation factor to $O(\log^{{1/3} + \epsilon} n)$ from the best-known
factor of $O(\sqrt{\log n})$ due to {\sf ARV}. In fact, for $\epsilon = 1/3$,
the program we get is the SDP proposed by {\sf ARV}. For $\epsilon &lt; 1/3$, this
family of programs is not convex but one can transform them into so called
\emph{\textbf{concave programs}} in which one optimizes a concave function over
a convex feasible set. The properties of concave programs allows one to apply
techniques due to Hoffman \cite{H81} or Tuy \emph{et al} \cite{TTT85} to solve
such problems with arbitrary accuracy. But the problem of finding of a method
to solve these programs that converges in polynomial time still remains open.
Our result, although conditional, introduces a new family of programs which is
more powerful than semi-definite programming in the context of approximation
algorithms and hence it will of interest to investigate this family both in the
direction of designing efficient algorithms and proving hardness results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1375</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1375</id><created>2009-07-08</created><authors><author><keyname>Chevalier</keyname><forenames>C&#xe9;dric</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Pellegrini</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author></authors><title>PT-Scotch: A tool for efficient parallel graph ordering</title><categories>cs.DC</categories><proxy>ccsd hal-00402893</proxy><journal-ref>Parallel Computing 34, 6-8 (2008) 318-331</journal-ref><doi>10.1016/j.parco.2007.12.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parallel ordering of large graphs is a difficult problem, because on the
one hand minimum degree algorithms do not parallelize well, and on the other
hand the obtainment of high quality orderings with the nested dissection
algorithm requires efficient graph bipartitioning heuristics, the best
sequential implementations of which are also hard to parallelize. This paper
presents a set of algorithms, implemented in the PT-Scotch software package,
which allows one to order large graphs in parallel, yielding orderings the
quality of which is only slightly worse than the one of state-of-the-art
sequential algorithms. Our implementation uses the classical nested dissection
approach but relies on several novel features to solve the parallel graph
bipartitioning problem. Thanks to these improvements, PT-Scotch produces
consistently better orderings than ParMeTiS on large numbers of processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1413</identifier>
 <datestamp>2011-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1413</id><created>2009-07-09</created><updated>2011-06-21</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author></authors><title>Privacy constraints in regularized convex optimization</title><categories>cs.CR cs.DB cs.LG</categories><comments>This paper has been withdrawn by the authors due to some errors.
  Corrections have been included in arXiv:0912.0071v4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is withdrawn due to some errors, which are corrected in
arXiv:0912.0071v4 [cs.LG].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1432</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1432</id><created>2009-07-09</created><authors><author><keyname>Raja</keyname><forenames>Adnan</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Reciprocity in Linear Deterministic Networks under Linear Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear deterministic model has been used recently to get a first order
understanding of many wireless communication network problems. In many of these
cases, it has been pointed out that the capacity regions of the network and its
reciprocal (where the communication links are reversed and the roles of the
sources and the destinations are swapped) are the same. In this paper, we
consider a linear deterministic communication network with multiple unicast
information flows. For this model and under the restriction to the class of
linear coding, we show that the rate regions for a network and its reciprocal
are the same. This can be viewed as a generalization of the linear
reversibility of wireline networks, already known in the network coding
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1455</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1455</id><created>2009-07-09</created><authors><author><keyname>Costas</keyname><forenames>Rodrigo</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Thed N.</forenames></author><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author></authors><title>Is scientific literature subject to a sell-by-date? A general
  methodology to analyze the durability of scientific documents</title><categories>physics.soc-ph cs.DL physics.data-an</categories><comments>26 pages, 9 tables, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of the citation histories and ageing of documents are topics that
have been addressed from several perspectives, especially in the analysis of
documents with delayed recognition or sleeping beauties. However, there is no
general methodology that can be extensively applied for different time periods
and/or research fields. In this paper a new methodology for the general
analysis of the ageing and durability of scientific papers is presented. This
methodology classifies documents into three general types: Delayed documents,
which receive the main part of their citations later than normal documents;
Flash in the pans, which receive citations immediately after their publication
but they are not cited in the long term; and Normal documents, documents with a
typical distribution of citations over time. These three types of durability
have been analyzed considering the whole population of documents in the Web of
Science with at least 5 external citations (i.e. not considering
self-citations). Several patterns related to the three types of durability have
been found and the potential for further research of the developed methodology
is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1482</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1482</id><created>2009-07-09</created><authors><author><keyname>Pauly</keyname><forenames>Arno</forenames></author></authors><title>How discontinuous is Computing Nash Equilibria?</title><categories>cs.GT</categories><comments>to be presented at CCA 2009</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the degree of discontinuity of several solution concepts from
non-cooperative game theory. While the consideration of Nash equilibria forms
the core of our work, also pure and correlated equilibria are dealt with.
Formally, we restrict the treatment to two player games, but results and proofs
extend to the n-player case. As a side result, the degree of discontinuity of
solving systems of linear inequalities is settled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1523</identifier>
 <datestamp>2009-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1523</id><created>2009-07-09</created><updated>2009-09-23</updated><authors><author><keyname>Penna</keyname><forenames>Federico</forenames></author><author><keyname>Garello</keyname><forenames>Roberto</forenames></author></authors><title>Theoretical Performance Analysis of Eigenvalue-based Detection</title><categories>cs.IT math.IT</categories><comments>31 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a complete analytical framework based on Random
Matrix Theory for the performance evaluation of Eigenvalue-based Detection.
While, up to now, analysis was limited to false-alarm probability, we have
obtained an analytical expression also for the probability of missed detection,
by using the theory of spiked population models. A general scenario with
multiple signals present at the same time is considered. The theoretical
results of this paper allow to predict the error probabilities, and to set the
decision threshold accordingly, by means of a few mathematical formulae. In
this way the design of an eigenvalue-based detector is made conceptually
identical to that of a traditional energy detector. As additional results, the
paper discusses the conditions of signal identifiability for single and
multiple sources. All the analytical results are validated through numerical
simulations, covering also convergence, identifiabilty and non-Gaussian
practical modulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1540</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1540</id><created>2009-07-09</created><authors><author><keyname>Georgievska</keyname><forenames>Sonja</forenames></author><author><keyname>Andova</keyname><forenames>Suzana</forenames></author></authors><title>Testing Probabilistic Processes: Can Random Choices Be Unobservable?</title><categories>cs.LO</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central paradigm behind process semantics based on observability and
testing is that the exact moment of occurring of an internal nondeterministic
choice is unobservable. It is natural, therefore, for this property to hold
when the internal choice is quantified with probabilities. However, ever since
probabilities have been introduced in process semantics, it has been a
challenge to preserve the unobservability of the random choice, while not
violating the other laws of process theory and probability theory. This paper
addresses this problem. It proposes two semantics for processes where the
internal nondeterminism has been quantified with probabilities. The first one
is based on the notion of testing, i.e. interaction between the process and its
environment. The second one, the probabilistic ready trace semantics, is based
on the notion of observability. Both are shown to coincide. They are also
preserved under the standard operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1545</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1545</id><created>2009-07-09</created><authors><author><keyname>Oh</keyname><forenames>Se Baek</forenames></author><author><keyname>Barbastathis</keyname><forenames>George</forenames></author><author><keyname>Raskar</keyname><forenames>Ramesh</forenames></author></authors><title>Augmenting Light Field to model Wave Optics effects</title><categories>cs.CV</categories><comments>Covering some of the topics presented in CVPR 2009 short course on
  light field: Present and Future</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ray-based 4D light field representation cannot be directly used to
analyze diffractive or phase--sensitive optical elements. In this paper, we
exploit tools from wave optics and extend the light field representation via a
novel &quot;light field transform&quot;. We introduce a key modification to the
ray--based model to support the transform. We insert a &quot;virtual light source&quot;,
with potentially negative valued radiance for certain emitted rays. We create a
look-up table of light field transformers of canonical optical elements. The
two key conclusions are that (i) in free space, the 4D light field completely
represents wavefront propagation via rays with real (positive as well as
negative) valued radiance and (ii) at occluders, a light field composed of
light field transformers plus insertion of (ray--based) virtual light sources
represents resultant phase and amplitude of wavefronts. For free--space
propagation, we analyze different wavefronts and coherence possibilities. For
occluders, we show that the light field transform is simply based on a
convolution followed by a multiplication operation. This formulation brings
powerful concepts from wave optics to computer vision and graphics. We show
applications in cubic-phase plate imaging and holographic displays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1558</identifier>
 <datestamp>2010-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1558</id><created>2009-07-09</created><updated>2009-07-27</updated><authors><author><keyname>Montemurro</keyname><forenames>Marcelo A.</forenames></author><author><keyname>Zanette</keyname><forenames>Damian</forenames></author></authors><title>Towards the quantification of the semantic information encoded in
  written language</title><categories>physics.soc-ph cs.CL physics.data-an</categories><comments>19 pages, 4 figures</comments><journal-ref>Advances in Complex Systems, Volume 13, Issue 2 (2010), pp.
  135-153</journal-ref><doi>10.1142/S0219525910002530</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Written language is a complex communication signal capable of conveying
information encoded in the form of ordered sequences of words. Beyond the local
order ruled by grammar, semantic and thematic structures affect long-range
patterns in word usage. Here, we show that a direct application of information
theory quantifies the relationship between the statistical distribution of
words and the semantic content of the text. We show that there is a
characteristic scale, roughly around a few thousand words, which establishes
the typical size of the most informative segments in written language.
Moreover, we find that the words whose contributions to the overall information
is larger, are the ones more closely associated with the main subjects and
topics of the text. This scenario can be explained by a model of word usage
that assumes that words are distributed along the text in domains of a
characteristic size where their frequency is higher than elsewhere. Our
conclusions are based on the analysis of a large database of written language,
diverse in subjects and styles, and thus are likely to be applicable to general
language sequences encoding complex information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1579</identifier>
 <datestamp>2011-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1579</id><created>2009-07-09</created><authors><author><keyname>Biamonte</keyname><forenames>Jacob D.</forenames></author></authors><title>The Computational Power of Minkowski Spacetime</title><categories>quant-ph cs.CC gr-qc physics.class-ph</categories><comments>6 pages, LaTeX, feedback welcome</comments><journal-ref>J.Phys.Conf.Ser.229:012020,2010</journal-ref><doi>10.1088/1742-6596/229/1/012020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lorentzian length of a timelike curve connecting both endpoints of a
classical computation is a function of the path taken through Minkowski
spacetime. The associated runtime difference is due to time-dilation: the
phenomenon whereby an observer finds that another's physically identical ideal
clock has ticked at a different rate than their own clock. Using ideas
appearing in the framework of computational complexity theory, time-dilation is
quantified as an algorithmic resource by relating relativistic energy to an
$n$th order polynomial time reduction at the completion of an observer's
journey. These results enable a comparison between the optimal quadratic
\emph{Grover speedup} from quantum computing and an $n=2$ speedup using
classical computers and relativistic effects. The goal is not to propose a
practical model of computation, but to probe the ultimate limits physics places
on computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1586</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1586</id><created>2009-07-09</created><authors><author><keyname>South</keyname><forenames>David M.</forenames></author></authors><title>Data Preservation and Long Term Analysis in High Energy Physics</title><categories>hep-ex cs.DL physics.data-an</categories><comments>To appear in the proceedings of 44th Rencontres de Moriond on QCD and
  High Energy Interactions, La Thuile, Valle d'Aosta, Italy, 14-21 Mar 2009. 4
  pages, 2 figures + 1 photo, 1 style file</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High energy physics data is a long term investment and contains the potential
for physics results beyond the lifetime of a collaboration. Many existing
experiments are concluding their physics programs, and looking at ways to
preserve their data heritage. Preservation of high-energy physics data and data
analysis structures is a challenge, and past experience has shown it can be
difficult if adequate planning and resources are not provided. A study group
has been formed to provide guidelines for such data preservation efforts in the
future. Key areas to be investigated were identified at a workshop at DESY in
January 2009, to be followed by a workshop at SLAC in May 2009. More
information can be found at http://dphep.org
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1587</identifier>
 <datestamp>2009-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1587</id><created>2009-07-09</created><authors><author><keyname>Fischbacher</keyname><forenames>Thomas</forenames></author><author><keyname>Fangohr</keyname><forenames>Hans</forenames></author></authors><title>Continuum multi-physics modeling with scripting languages: the Nsim
  simulation compiler prototype for classical field theory</title><categories>physics.comp-ph cond-mat.mes-hall cs.DC</categories><comments>50 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that for a broad class of physical systems that can be
described using classical field theory, automated runtime translation of the
physical equations to parallelized finite-element numerical simulation code is
feasible. This allows the implementation of multiphysics extension modules to
popular scripting languages (such as Python) that handle the complete
specification of the physical system at script level. We discuss two example
applications that utilize this framework: the micromagnetic simulation package
&quot;Nmag&quot; as well as a short Python script to study morphogenesis in a
reaction-diffusion model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1597</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1597</id><created>2009-07-09</created><updated>2010-03-16</updated><authors><author><keyname>Marshall</keyname><forenames>James A. R.</forenames></author><author><keyname>Hinton</keyname><forenames>Thomas G.</forenames></author></authors><title>Beyond No Free Lunch: Realistic Algorithms for Arbitrary Problem Classes</title><categories>cs.IT cs.NE math.IT</categories><comments>(V3 fixed some other typos and improved some results)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how the necessary and sufficient conditions for the NFL to apply can
be reduced to the single requirement of the set of objective functions under
consideration being closed under permutation, and quantify the extent to which
a set of objectives not closed under permutation can give rise to a performance
difference between two algorithms. Then we provide a more refined definition of
performance under which we show that revisiting algorithms are always trumped
by enumerative ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1632</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1632</id><created>2009-07-09</created><authors><author><keyname>Ashish</keyname><forenames>Naveen</forenames></author><author><keyname>Mehrotra</keyname><forenames>Sharad</forenames></author><author><keyname>Pirzadeh</keyname><forenames>Pouria</forenames></author></authors><title>Incorporating Integrity Constraints in Uncertain Databases</title><categories>cs.DB cs.IR</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We develop an approach to incorporate additional knowledge, in the form of
general purpose integrity constraints (ICs), to reduce uncertainty in
probabilistic databases. While incorporating ICs improves data quality (and
hence quality of answers to a query), it significantly complicates query
processing. To overcome the additional complexity, we develop an approach to
map an uncertain relation U with ICs to another uncertain relation U', that
approximates the set of consistent worlds represented by U. Queries over U can
instead be evaluated over U' achieving higher quality (due to reduced
uncertainty in U') without additional complexity in query processing due to
ICs. We demonstrate the effectiveness and scalability of our approach to large
data-sets with complex constraints. We also present experimental results
demonstrating the utility of incorporating integrity constraints in uncertain
relations, in the context of an information extraction application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1678</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1678</id><created>2009-07-09</created><authors><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Lando</keyname><forenames>Yuval</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author></authors><title>Simple Random Walks on Radio Networks (Simple Random Walks on
  Hyper-Graphs)</title><categories>cs.NI cs.DM</categories><acm-class>C.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, protocols that are based on the properties of random walks
on graphs have found many applications in communication and information
networks, such as wireless networks, peer-to-peer networks and the Web. For
wireless networks (and other networks), graphs are actually not the correct
model of the communication; instead hyper-graphs better capture the
communication over a wireless shared channel. Motivated by this example, we
study in this paper random walks on hyper-graphs. First, we formalize the
random walk process on hyper-graphs and generalize key notions from random
walks on graphs. We then give the novel definition of radio cover time, namely,
the expected time of a random walk to be heard (as opposed to visit) by all
nodes. We then provide some basic bounds on the radio cover, in particular, we
show that while on graphs the radio cover time is O(mn), in hyper-graphs it is
O(mnr) where n, m and r are the number of nodes, the number of edges and the
rank of the hyper-graph, respectively. In addition, we define radio hitting
times and give a polynomial algorithm to compute them. We conclude the paper
with results on specific hyper-graphs that model wireless networks in one and
two dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1721</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1721</id><created>2009-07-10</created><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author><author><keyname>Venkatachalapathy</keyname><forenames>Rajesh</forenames></author></authors><title>Distributed Function Computation in Asymmetric Communication Scenarios</title><categories>cs.IT math.IT</categories><comments>10 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the distributed function computation problem in asymmetric
communication scenarios, where the sink computes some deterministic function of
the data split among N correlated informants. The distributed function
computation problem is addressed as a generalization of distributed source
coding (DSC) problem. We are mainly interested in minimizing the number of
informant bits required, in the worst-case, to allow the sink to exactly
compute the function. We provide a constructive solution for this in terms of
an interactive communication protocol and prove its optimality. The proposed
protocol also allows us to compute the worst-case achievable rate-region for
the computation of any function. We define two classes of functions: lossy and
lossless. We show that, in general, the lossy functions can be computed at the
sink with fewer number of informant bits than the DSC problem, while
computation of the lossless functions requires as many informant bits as the
DSC problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1722</identifier>
 <datestamp>2011-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1722</id><created>2009-07-10</created><updated>2011-08-31</updated><authors><author><keyname>Janicki</keyname><forenames>Ryszard</forenames></author><author><keyname>Le</keyname><forenames>Dai Tri Man</forenames></author></authors><title>Modelling Concurrency with Comtraces and Generalized Comtraces</title><categories>cs.LO cs.DC cs.FL</categories><comments>49 pages</comments><doi>10.1016/j.ic.2011.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comtraces (combined traces) are extensions of Mazurkiewicz traces that can
model the &quot;not later than&quot; relationship. In this paper, we first introduce the
novel notion of generalized comtraces, extensions of comtraces that can
additionally model the &quot;non-simultaneously&quot; relationship. Then we study some
basic algebraic properties and canonical reprentations of comtraces and
generalized comtraces. Finally we analyze the relationship between generalized
comtraces and generalized stratified order structures. The major technical
contribution of this paper is a proof showing that generalized comtraces can be
represented by generalized stratified order structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1723</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1723</id><created>2009-07-10</created><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author><author><keyname>Venkatachalapathy</keyname><forenames>Rajesh</forenames></author></authors><title>Worst-case Compressibility of Discrete and Finite Distributions</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the worst-case distributed source coding (DSC) problem of [1], the smaller
cardinality of the support-set describing the correlation in informant data,
may neither imply that fewer informant bits are required nor that fewer
informants need to be queried, to finish the data-gathering at the sink. It is
important to formally address these observations for two reasons: first, to
develop good worst-case information measures and second, to perform meaningful
worst-case information-theoretic analysis of various distributed data-gathering
problems. Towards this goal, we introduce the notions of bit-compressibility
and informant-compressibility of support-sets. We consider DSC and distributed
function computation problems and provide results on computing the bit- and
informant- compressibilities regions of the support-sets as a function of their
cardinality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1724</identifier>
 <datestamp>2012-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1724</id><created>2009-07-10</created><updated>2011-03-26</updated><authors><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>Inapproximability of the Tutte polynomial of a planar graph</title><categories>cs.CC math.CO</categories><comments>In this revision, significant changes have been made to the structure
  of the paper to clarify the presentation. Extra detail has been provided at
  certain points in the proofs, and on at least one occasion the exposition has
  been made more systematic. Some typos have been corrected. The results are
  unchanged. 28 pages and 5 figures</comments><journal-ref>Computational Complexity, 2012</journal-ref><doi>10.1007/s00037-012-0046-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Tutte polynomial of a graph G is a two-variable polynomial T(G;x,y) that
encodes many interesting properties of the graph. We study the complexity of
the following problem, for rationals x and y: given as input a planar graph G,
determine T(G;x,y). Vertigan completely mapped the complexity of exactly
computing the Tutte polynomial of a planar graph. He showed that the problem
can be solved in polynomial time if (x,y) is on the hyperbola H_q given by
(x-1)(y-1)=q for q=1 or q=2 or if (x,y) is one of the two special points
(x,y)=(-1,-1) or (x,y)=(1,1). Otherwise, the problem is #P-hard. In this paper,
we consider the problem of approximating T(G;x,y), in the usual sense of &quot;fully
polynomial randomised approximation scheme&quot; or FPRAS. Roughly speaking, an
FPRAS is required to produce, in polynomial time and with high probability, an
answer that has small relative error. Assuming that NP is different from RP, we
show that there is no FPRAS for the Tutte polynomial in a large portion of the
(x,y) plane. In particular, there is no FPRAS if x&gt;1, y&lt;-1 or if y&gt;1, x&lt;-1 or
if x&lt;0, y&lt;0 and q&gt;5. Also, there is no FPRAS if x&lt;1, y&lt;1 and q=3. For q&gt;5, our
result is intriguing because it shows that there is no FPRAS at
(x,y)=(1-q/(1+epsilon),-epsilon) for any positive epsilon but it leaves open
the limit point epsilon=0, which corresponds to approximately counting
q-colourings of a planar graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1728</identifier>
 <datestamp>2009-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1728</id><created>2009-07-10</created><updated>2009-08-14</updated><authors><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Role of Weak Ties in Link Prediction of Complex Networks</title><categories>cs.IR</categories><comments>4 pages, 1 figure and 2 tables. Accepted by CIKM workshop, see
  http://www.dcs.bbk.ac.uk/~dell/cnikm09/#programme</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plenty of algorithms for link prediction have been proposed and were applied
to various real networks. Among these works, the weights of links are rarely
taken into account. In this paper, we use local similarity indices to estimate
the likelihood of the existence of links in weighted networks, including Common
Neighbor, Adamic-Adar Index, Resource Allocation Index, and their weighted
versions. In both the unweighted and weighted cases, the resource allocation
index performs the best. To our surprise, the weighted indices perform worse,
which reminds us of the well-known Weak Tie Theory. Further extensive
experimental study shows that the weak ties play a significant role in the link
prediction problem, and to emphasize the contribution of weak ties can
remarkably enhance the predicting accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1737</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1737</id><created>2009-07-10</created><authors><author><keyname>Wang</keyname><forenames>Qing</forenames></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled Ben</forenames></author></authors><title>Throughput Improvement and Its Tradeoff with The Queuing Delay in the
  Diamond Relay Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diamond relay channel model, as a basic transmission model, has recently been
attracting considerable attention in wireless Ad Hoc networks. Node cooperation
and opportunistic scheduling scheme are two important techniques to improve the
performance in wireless scenarios. In the paper we consider such a problem how
to efficiently combine opportunistic scheduling and cooperative modes in the
Rayleigh fading scenarios. To do so, we first compare the throughput of SRP
(Spatial Reused Pattern) and AFP (Amplify Forwarding Pattern) in the
half-duplex case with the assumption that channel side information is known to
all and then come up with a new scheduling scheme. It will that that only
switching between SRP and AFP simply does little help to obtain an expected
improvement because SRP is always superior to AFP on average due to its
efficient spatial reuse. To improve the throughput further, we put forward a
new processing strategy in which buffers are employed at both relays in SRP
mode. By efficiently utilizing the links with relatively higher gains, the
throughput can be greatly improved at a cost of queuing delay. Furthermore, we
shall quantitatively evaluate the queuing delay and the tradeoff between the
throughput and the additional queuing delay. Finally, to realize our developed
strategy and make sure it always run at stable status, we present two criteria
and an algorithm on the selection and adjustment of the switching thresholds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1739</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1739</id><created>2009-07-10</created><authors><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Sun</keyname><forenames>Pei</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled Ben</forenames></author></authors><title>Efficient Signal-Time Coding Design and its Application in Wireless
  Gaussian Relay Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal-time coding, which combines the traditional encoding/modulation mode
in the signal domain with signal pulse phase modulation in the time domain, was
proposed to improve the information flow rate in relay networks. In this paper,
we mainly focus on the efficient signal-time coding design. We first derive an
explicit iterative algorithm to estimate the maximum number of available codes
given the code length of signal-time coding, and then present an iterative
construction method of codebooks. It is shown that compared with conventional
computer search, the proposed iterative construction method can reduce the
complexity greatly. Numerical results will also indicate that the new
constructed codebook is optimal in terms of coding rate. To minimize the buffer
size needed to store the codebook while keeping a relatively high efficiency,
we shall propose a combinatorial construction method. We will then consider
applications in wireless Gaussian relay networks. It will be shown that in the
three node network model, the mixed transmission by using two-hop and direct
transmissions is not always a good option.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1755</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1755</id><created>2009-07-10</created><authors><author><keyname>Faizullin</keyname><forenames>R. T.</forenames></author><author><keyname>Khnykin</keyname><forenames>I. G.</forenames></author><author><keyname>Dylkeyt</keyname><forenames>V. I.</forenames></author></authors><title>The SAT solving method as applied to cryptographic analysis of
  asymmetric ciphers</title><categories>cs.CR cs.DM</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The one of the most interesting problem of discrete mathematics is the SAT
(satisfiability) problem. Good way in SAT solver developing is to transform the
SAT problem to the problem of continuous search of global minimums of the
functional associated with the CNF. This article proves the special
construction of the functional and offers to solve the system of non-linear
algebraic equation that determines functional stationary points via modified
method of consecutive approximation. The article describes parallel versions of
the method. Also gives the schema of using the method to important problems of
cryptographic analysis of asymmetric ciphers, including determining concrete
bits of multipliers (in binary form) in large factorization problems and
concrete bits of exponent of discrete logarithm problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1779</identifier>
 <datestamp>2009-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1779</id><created>2009-07-10</created><updated>2009-10-25</updated><authors><author><keyname>Huang</keyname><forenames>Chien-Chung</forenames></author></authors><title>Classified Stable Matching</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the {\sc classified stable matching} problem, a problem
motivated by academic hiring. Suppose that a number of institutes are hiring
faculty members from a pool of applicants. Both institutes and applicants have
preferences over the other side. An institute classifies the applicants based
on their research areas (or any other criterion), and, for each class, it sets
a lower bound and an upper bound on the number of applicants it would hire in
that class. The objective is to find a stable matching from which no group of
participants has reason to deviate. Moreover, the matching should respect the
upper/lower bounds of the classes.
  In the first part of the paper, we study classified stable matching problems
whose classifications belong to a fixed set of ``order types.'' We show that if
the set consists entirely of downward forests, there is a polynomial-time
algorithm; otherwise, it is NP-complete to decide the existence of a stable
matching.
  In the second part, we investigate the problem using a polyhedral approach.
Suppose that all classifications are laminar families and there is no lower
bound. We propose a set of linear inequalities to describe stable matching
polytope and prove that it is integral. This integrality allows us to find
various optimal stable matchings using Ellipsoid algorithm. A further
ramification of our result is the description of the stable matching polytope
for the many-to-many (unclassified) stable matching problem. This answers an
open question posed by Sethuraman, Teo and Qian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1788</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1788</id><created>2009-07-10</created><authors><author><keyname>Soro</keyname><forenames>Alexandre</forenames></author><author><keyname>Lacan</keyname><forenames>Jerome</forenames></author></authors><title>FNT-based Reed-Solomon Erasure Codes</title><categories>cs.IT math.IT</categories><comments>submitted in CCNC'10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new construction of Maximum-Distance Separable (MDS)
Reed-Solomon erasure codes based on Fermat Number Transform (FNT). Thanks to
FNT, these codes support practical coding and decoding algorithms with
complexity O(n log n), where n is the number of symbols of a codeword. An
open-source implementation shows that the encoding speed can reach 150Mbps for
codes of length up to several 10,000s of symbols. These codes can be used as
the basic component of the Information Dispersal Algorithm (IDA) system used in
a several P2P systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1812</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1812</id><created>2009-07-10</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Fast search for Dirichlet process mixture models</title><categories>cs.LG</categories><journal-ref>AIStats 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dirichlet process (DP) mixture models provide a flexible Bayesian framework
for density estimation. Unfortunately, their flexibility comes at a cost:
inference in DP mixture models is computationally expensive, even when
conjugate distributions are used. In the common case when one seeks only a
maximum a posteriori assignment of data points to clusters, we show that search
algorithms provide a practical alternative to expensive MCMC and variational
techniques. When a true posterior sample is desired, the solution found by
search can serve as a good initializer for MCMC. Experimental results show that
using these techniques is it possible to apply DP mixture models to very large
data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1814</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1814</id><created>2009-07-10</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Bayesian Query-Focused Summarization</title><categories>cs.CL cs.IR cs.LG</categories><journal-ref>ACL 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present BayeSum (for ``Bayesian summarization''), a model for sentence
extraction in query-focused summarization. BayeSum leverages the common case in
which multiple documents are relevant to a single query. Using these documents
as reinforcement for query terms, BayeSum is not afflicted by the paucity of
information in short queries. We show that approximate inference in BayeSum is
possible on large data sets and results in a state-of-the-art summarization
system. Furthermore, we show how BayeSum can be understood as a justified query
expansion technique in the language modeling for IR framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1815</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1815</id><created>2009-07-10</created><authors><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Frustratingly Easy Domain Adaptation</title><categories>cs.LG cs.CL</categories><journal-ref>ACL 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an approach to domain adaptation that is appropriate exactly in
the case when one has enough ``target'' data to do slightly better than just
using only ``source'' data. Our approach is incredibly simple, easy to
implement as a preprocessing step (10 lines of Perl!) and outperforms
state-of-the-art approaches on a range of datasets. Moreover, it is trivially
extended to a multi-domain adaptation problem, where one has data from a
variety of different domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1817</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1817</id><created>2009-07-10</created><authors><author><keyname>Chen</keyname><forenames>Sheng-Gwo</forenames></author><author><keyname>Chi</keyname><forenames>Mei-Hsiu</forenames></author><author><keyname>Wu</keyname><forenames>Jyh-Yang</forenames></author></authors><title>A new intrinsic numerical method for PDE on surfaces</title><categories>cs.CG</categories><comments>14 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we shall introduce a simple, effective numerical method for
solving partial differential equations for scalar and vector-valued data
defined on surfaces. Even though we shall follow the traditional way to
approximate the regular surfaces under consideration by triangular meshes, the
key idea of our algorithm is to develop an intrinsic and unified way to compute
directly the partial derivatives of functions defined on triangular meshes. We
shall present examples in computer graphics and image processing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1839</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1839</id><created>2009-07-10</created><authors><author><keyname>Palmer</keyname><forenames>Michael E.</forenames></author><author><keyname>Miller</keyname><forenames>Daniel B.</forenames></author></authors><title>An Evolved Neural Controller for Bipdedal Walking with Dynamic Balance</title><categories>cs.NE cs.RO</categories><comments>6 pages, 7 figures. In Proceedings of the Genetic and Evolutionary
  Computation Conference (GECCO) 2009, Montreal</comments><acm-class>D.2.2; I.2.8</acm-class><journal-ref>Palmer, M.E. and Miller, D.B. An Evolved Neural Controller for
  Bipdedal Walking with Dynamic Balance. In Proceedings of the Genetic and
  Evolutionary Computation Conference (GECCO) 2009, Montreal, July 8-12, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We successfully evolved a neural network controller that produces dynamic
walking in a simulated bipedal robot with compliant actuators, a difficult
control problem. The evolutionary evaluation uses a detailed software
simulation of a physical robot. We describe: 1) a novel theoretical method to
encourage populations to evolve &quot;around&quot; local optima, which employs multiple
demes and fitness functions of progressively increasing difficulty, and 2) the
novel genetic representation of the neural controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1840</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1840</id><created>2009-07-10</created><authors><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author><author><keyname>Della Vedova</keyname><forenames>Gianluca</forenames></author><author><keyname>Dondi</keyname><forenames>Riccardo</forenames></author></authors><title>A PTAS for the Minimum Consensus Clustering Problem with a Fixed Number
  of Clusters</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Consensus Clustering problem has been introduced as an effective way to
analyze the results of different microarray experiments. The problem consists
of looking for a partition that best summarizes a set of input partitions (each
corresponding to a different microarray experiment) under a simple and
intuitive cost function. The problem admits polynomial time algorithms on two
input partitions, but is APX-hard on three input partitions. We investigate the
restriction of Consensus Clustering when the output partition is required to
contain at most k sets, giving a polynomial time approximation scheme (PTAS)
while proving the NP-hardness of this restriction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1888</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1888</id><created>2009-07-10</created><authors><author><keyname>Qaseem</keyname><forenames>Syed T.</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>Compressive Sensing for Feedback Reduction in MIMO Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications, April 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a generalized feedback model and compressive sensing based
opportunistic feedback schemes for feedback resource reduction in MIMO
Broadcast Channels under the assumption that both uplink and downlink channels
undergo block Rayleigh fading. Feedback resources are shared and are
opportunistically accessed by users who are strong, i.e. users whose channel
quality information is above a certain fixed threshold. Strong users send same
feedback information on all shared channels. They are identified by the base
station via compressive sensing. Both analog and digital feedbacks are
considered. The proposed analog &amp; digital opportunistic feedback schemes are
shown to achieve the same sum-rate throughput as that achieved by dedicated
feedback schemes, but with feedback channels growing only logarithmically with
number of users. Moreover, there is also a reduction in the feedback load. In
the analog feedback case, we show that the propose scheme reduces the feedback
noise which eventually results in better throughput, whereas in the digital
feedback case the proposed scheme in a noisy scenario achieves almost the
throughput obtained in a noiseless dedicated feedback scenario. We also show
that for a fixed given budget of feedback bits, there exist a trade-off between
the number of shared channels and thresholds accuracy of the feedback SINR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1916</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1916</id><created>2009-07-10</created><authors><author><keyname>Bournez</keyname><forenames>Olivier</forenames></author><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author></authors><title>Learning Equilibria in Games by Stochastic Distributed Algorithms</title><categories>cs.GT cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of fully stochastic and fully distributed algorithms,
that we prove to learn equilibria in games.
  Indeed, we consider a family of stochastic distributed dynamics that we prove
to converge weakly (in the sense of weak convergence for probabilistic
processes) towards their mean-field limit, i.e an ordinary differential
equation (ODE) in the general case. We focus then on a class of stochastic
dynamics where this ODE turns out to be related to multipopulation replicator
dynamics.
  Using facts known about convergence of this ODE, we discuss the convergence
of the initial stochastic dynamics: For general games, there might be
non-convergence, but when convergence of the ODE holds, considered stochastic
algorithms converge towards Nash equilibria. For games admitting Lyapunov
functions, that we call Lyapunov games, the stochastic dynamics converge. We
prove that any ordinal potential game, and hence any potential game is a
Lyapunov game, with a multiaffine Lyapunov function. For Lyapunov games with a
multiaffine Lyapunov function, we prove that this Lyapunov function is a
super-martingale over the stochastic dynamics. This leads a way to provide
bounds on their time of convergence by martingale arguments. This applies in
particular for many classes of games that have been considered in literature,
including several load balancing game scenarios and congestion games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1925</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1925</id><created>2009-07-10</created><authors><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author><author><keyname>Rosenblueth</keyname><forenames>David A.</forenames></author></authors><title>Modeling self-organizing traffic lights with elementary cellular
  automata</title><categories>nlin.CG cond-mat.stat-mech cs.AI nlin.AO</categories><comments>33 pages, 11 Figures, 3 Tables</comments><report-no>C3 Report No. 2009.06</report-no><journal-ref>Complex Systems: 19(4):305-322, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been several highway traffic models proposed based on cellular
automata. The simplest one is elementary cellular automaton rule 184. We extend
this model to city traffic with cellular automata coupled at intersections
using only rules 184, 252, and 136. The simplicity of the model offers a clear
understanding of the main properties of city traffic and its phase transitions.
  We use the proposed model to compare two methods for coordinating traffic
lights: a green-wave method that tries to optimize phases according to expected
flows and a self-organizing method that adapts to the current traffic
conditions. The self-organizing method delivers considerable improvements over
the green-wave method. For low densities, the self-organizing method promotes
the formation and coordination of platoons that flow freely in four directions,
i.e. with a maximum velocity and no stops. For medium densities, the method
allows a constant usage of the intersections, exploiting their maximum flux
capacity. For high densities, the method prevents gridlocks and promotes the
formation and coordination of &quot;free-spaces&quot; that flow in the opposite direction
of traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1948</identifier>
 <datestamp>2009-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1948</id><created>2009-07-13</created><updated>2009-12-18</updated><authors><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author><author><keyname>Fu</keyname><forenames>Hu</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author></authors><title>Amplified Hardness of Approximation for VCG-Based Mechanisms</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If a two-player social welfare maximization problem does not admit a PTAS, we
prove that any maximal-in-range truthful mechanism that runs in polynomial time
cannot achieve an approximation factor better than 1/2. Moreover, for the
k-player version of the same problem, the hardness of approximation improves to
1/k under the same two-player hardness assumption. (We note that 1/k is
achievable by a trivial deterministic maximal-in-range mechanism.) This
hardness result encompasses not only deterministic maximal-in-range mechanisms,
but also all universally-truthful randomized maximal in range algorithms, as
well as a class of strictly more powerful truthful-in-expectation randomized
mechanisms recently introduced by Dobzinski and Dughmi. Our result applies to
any class of valuation functions that satisfies some minimal closure
properties. These properties are satisfied by the valuation functions in all
well-studied APX-hard social welfare maximization problems, such as coverage,
submodular, and subadditive valuations.
  We also prove a stronger result for universally-truthful maximal-in-range
mechanisms. Namely, even for the class of budgeted additive valuations, which
admits an FPTAS, no such mechanism can achieve an approximation factor better
than 1/k in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1955</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1955</id><created>2009-07-11</created><authors><author><keyname>Clarke</keyname><forenames>Matthew C.</forenames></author></authors><title>On the Chances of Completing the Game of &quot;Perpetual Motion&quot;</title><categories>cs.GT</categories><comments>3 pages, 3 figures</comments><acm-class>I.6.8</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This brief paper describes the single-player card game called &quot;Perpetual
Motion&quot; and reports on a computational analysis of the game's outcome. The
analysis follows a Monte Carlo methodology based on a sample of 10,000 randomly
generated games. The key result is that 54.55% +/- 0.89% of games can be
completed (by a patient player!) but that the remaining 45.45% result in
non-terminating cycles. The lengths of these non-terminating cycles leave some
outstanding questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1956</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1956</id><created>2009-07-11</created><authors><author><keyname>Zhao</keyname><forenames>Lei</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author></authors><title>Zero-error feedback capacity via dynamic programming</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the zero-error capacity for finite state channels
with feedback when channel state information is known to both the transmitter
and the receiver. We prove that the zero-error capacity in this case can be
obtained through the solution of a dynamic programming problem. Each iteration
of the dynamic programming provides lower and upper bounds on the zero-error
capacity, and in the limit, the lower bound coincides with the zero-error
feedback capacity. Furthermore, a sufficient condition for solving the dynamic
programming problem is provided through a fixed-point equation. Analytical
solutions for several examples are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1975</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1975</id><created>2009-07-11</created><updated>2010-11-29</updated><authors><author><keyname>Fedorenko</keyname><forenames>Sergei V.</forenames></author></authors><title>On semifast Fourier transform algorithms</title><categories>cs.IT math.IT</categories><comments>8 pages. Proceedings of the XII international symposium on problems
  of redundancy in information and control systems at St.Petersburg, Russia,
  May 2009, pp.65-70</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the relations between well-known Fourier transform algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1978</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1978</id><created>2009-07-11</created><authors><author><keyname>Magnani</keyname><forenames>Matteo</forenames></author><author><keyname>Montesi</keyname><forenames>Danilo</forenames></author></authors><title>BPDMN: A Conservative Extension of BPMN with Enhanced Data
  Representation Capabilities</title><categories>cs.SE cs.DB</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of business processes involves the usage of modeling languages,
tools and methodologies. In this paper we highlight and address a relevant
limitation of the Business Process Modeling Notation (BPMN): its weak data
representation capabilities. In particular, we extend it with data-specific
constructs derived from existing data modeling notations and adapted to blend
gracefully into BPMN diagrams. The extension has been developed taking existing
modeling languages and requirement analyses into account: we characterize our
notation using the Workfl ow Data Patterns and provide mappings to the main
XML-based business process languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1990</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1990</id><created>2009-07-13</created><authors><author><keyname>Hassanzadeh</keyname><forenames>Oktie</forenames></author></authors><title>Automated Protein Structure Classification: A Survey</title><categories>cs.CE q-bio.BM</categories><comments>14 pages, Technical Report CSRG-589, University of Toronto</comments><report-no>CSRG-589</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification of proteins based on their structure provides a valuable
resource for studying protein structure, function and evolutionary
relationships. With the rapidly increasing number of known protein structures,
manual and semi-automatic classification is becoming ever more difficult and
prohibitively slow. Therefore, there is a growing need for automated, accurate
and efficient classification methods to generate classification databases or
increase the speed and accuracy of semi-automatic techniques. Recognizing this
need, several automated classification methods have been developed. In this
survey, we overview recent developments in this area. We classify different
methods based on their characteristics and compare their methodology, accuracy
and efficiency. We then present a few open problems and explain future
directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.1992</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.1992</id><created>2009-07-11</created><updated>2009-07-14</updated><authors><author><keyname>Quan</keyname><forenames>Zhi</forenames></author><author><keyname>Shellhammer</keyname><forenames>Stephen J.</forenames></author><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Spectrum sensing by cognitive radios at very low SNR</title><categories>cs.IT math.IT</categories><comments>IEEE Global Communications Conference 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is one of the enabling functionalities for cognitive radio
(CR) systems to operate in the spectrum white space. To protect the primary
incumbent users from interference, the CR is required to detect incumbent
signals at very low signal-to-noise ratio (SNR). In this paper, we present a
spectrum sensing technique based on correlating spectra for detection of
television (TV) broadcasting signals. The basic strategy is to correlate the
periodogram of the received signal with the a priori known spectral features of
the primary signal. We show that according to the Neyman-Pearson criterion,
this spectral correlation-based sensing technique is asymptotically optimal at
very low SNR and with a large sensing time. From the system design perspective,
we analyze the effect of the spectral features on the spectrum sensing
performance. Through the optimization analysis, we obtain useful insights on
how to choose effective spectral features to achieve reliable sensing.
Simulation results show that the proposed sensing technique can reliably detect
analog and digital TV signals at SNR as low as -20 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2019</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2019</id><created>2009-07-12</created><authors><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Foundations for a Developmental State: A case for technical education</title><categories>cs.CY</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the viability of making a country a developmental state.
In particular it studies the characteristics of a developmental state and how
they are linked to technology. It then identifies technical education, as a
vital force for the creation of a developmental state. In particular it
identifies analytical, numeracy, computational and communication skills as
vital forces for a society to create a developmental society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2039</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2039</id><created>2009-07-12</created><authors><author><keyname>Deharbe</keyname><forenames>David</forenames></author><author><keyname>Gomes</keyname><forenames>Bruno E. G.</forenames></author><author><keyname>Moreira</keyname><forenames>Anamaria M.</forenames></author></authors><title>Refining interfaces: the case of the B method</title><categories>cs.SE</categories><comments>18 pages, submitted to ICFEM 2009</comments><acm-class>D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-driven design of software for safety-critical applications often relies
on mathematically grounded techniques such as the B method. Such techniques
consist in the successive applications of refinements to derive a concrete
implementation from an abstract specification. Refinement theory defines
verification conditions to guarantee that such operations preserve the intended
behaviour of the abstract specifications. One of these conditions requires
however that concrete operations have exactly the same signatures as their
abstract counterpart, which is not always a practical requirement. This paper
shows how changes of signatures can be achieved while still staying within the
bounds of refinement theory. This makes it possible to take advantage of the
mathematical guarantees and tool support provided for the current
refinement-based techniques, such as the B method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2049</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2049</id><created>2009-07-12</created><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Procaccia</keyname><forenames>Ariel D.</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Strategyproof Approximation Mechanisms for Location on Networks</title><categories>cs.GT cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of locating a facility on a network, represented by a
graph. A set of strategic agents have different ideal locations for the
facility; the cost of an agent is the distance between its ideal location and
the facility. A mechanism maps the locations reported by the agents to the
location of the facility. Specifically, we are interested in social choice
mechanisms that do not utilize payments. We wish to design mechanisms that are
strategyproof, in the sense that agents can never benefit by lying, or, even
better, group strategyproof, in the sense that a coalition of agents cannot all
benefit by lying. At the same time, our mechanisms must provide a small
approximation ratio with respect to one of two optimization targets: the social
cost or the maximum cost.
  We give an almost complete characterization of the feasible truthful
approximation ratio under both target functions, deterministic and randomized
mechanisms, and with respect to different network topologies. Our main results
are: We show that a simple randomized mechanism is group strategyproof and
gives a (2-2/n)-approximation for the social cost, where n is the number of
agents, when the network is a circle (known as a ring in the case of computer
networks); we design a novel &quot;hybrid&quot; strategyproof randomized mechanism that
provides a tight approximation ratio of 3/2 for the maximum cost when the
network is a circle; and we show that no randomized SP mechanism can provide an
approximation ratio better than 2-o(1) to the maximum cost even when the
network is a tree, thereby matching a trivial upper bound of two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2050</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2050</id><created>2009-07-12</created><updated>2011-02-08</updated><authors><author><keyname>Je&#x17c;</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Randomised Buffer Management with Bounded Delay against Adaptive
  Adversary</title><categories>cs.DS</categories><comments>Obsolete; improved upon by arXiv:1102.1273 [cs.DS]. This comment is
  the only difference from previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new analysis of the RMix algorithm by Chin et al. for the Buffer
Management with Bounded Delay problem (or online scheduling of unit jobs to
maximise weighted throughput). Unlike the original proof of
e/(e-1)-competitiveness, the new one holds even in adaptive-online adversary
model. In fact, the proof works also for a slightly more general problem
studied by Bie{\'n}kowski et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2059</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2059</id><created>2009-07-12</created><updated>2009-11-02</updated><authors><author><keyname>Lebresne</keyname><forenames>Sylvain</forenames></author></authors><title>A Type System For Call-By-Name Exceptions</title><categories>cs.PL</categories><comments>25 pages</comments><acm-class>D.3.1; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 4 (November
  2, 2009) lmcs:817</journal-ref><doi>10.2168/LMCS-5(4:1)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension of System F with call-by-name exceptions. The type
system is enriched with two syntactic constructs: a union type for programs
whose execution may raise an exception at top level, and a corruption type for
programs that may raise an exception in any evaluation context (not necessarily
at top level). We present the syntax and reduction rules of the system, as well
as its typing and subtyping rules. We then study its properties, such as
confluence. Finally, we construct a realizability model using orthogonality
techniques, from which we deduce that well-typed programs are weakly
normalizing and that the ones who have the type of natural numbers really
compute a natural number, without raising exceptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2071</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2071</id><created>2009-07-13</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Dou&#xef;eb</keyname><forenames>Karim</forenames></author><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Howat</keyname><forenames>John</forenames></author></authors><title>Layered Working-Set Trees</title><categories>cs.DS</categories><comments>10 pages, 3 figures</comments><acm-class>E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The working-set bound [Sleator and Tarjan, J. ACM, 1985] roughly states that
searching for an element is fast if the element was accessed recently. Binary
search trees, such as splay trees, can achieve this property in the amortized
sense, while data structures that are not binary search trees are known to have
this property in the worst case. We close this gap and present a binary search
tree called a layered working-set tree that guarantees the working-set property
in the worst case. The unified bound [Badoiu et al., TCS, 2007] roughly states
that searching for an element is fast if it is near (in terms of rank distance)
to a recently accessed element. We show how layered working-set trees can be
used to achieve the unified bound to within a small additive term in the
amortized sense while maintaining in the worst case an access time that is both
logarithmic and within a small multiplicative factor of the working-set bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2072</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2072</id><created>2009-07-12</created><updated>2009-07-13</updated><authors><author><keyname>Cordeiro</keyname><forenames>Lucas</forenames></author><author><keyname>Fischer</keyname><forenames>Bernd</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author></authors><title>SMT-Based Bounded Model Checking for Embedded ANSI-C Software</title><categories>cs.SE</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Propositional bounded model checking has been applied successfully to verify
embedded software but is limited by the increasing propositional formula size
and the loss of structure during the translation. These limitations can be
reduced by encoding word-level information in theories richer than
propositional logic and using SMT solvers for the generated verification
conditions. Here, we investigate the application of different SMT solvers to
the verification of embedded software written in ANSI-C. We have extended the
encodings from previous SMT-based bounded model checkers to provide more
accurate support for finite variables, bit-vector operations, arrays,
structures, unions and pointers. We have integrated the CVC3, Boolector, and Z3
solvers with the CBMC front-end and evaluated them using both standard software
model checking benchmarks and typical embedded applications from
telecommunications, control systems and medical devices. The experiments show
that our approach can analyze larger problems and substantially reduce the
verification time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2075</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2075</id><created>2009-07-12</created><authors><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Bai</keyname><forenames>Li</forenames></author></authors><title>Multiresolution Elastic Medical Image Registration in Standard Intensity
  Scale</title><categories>cs.CV</categories><comments>IEEE Sibgrapi 2007 submission</comments><journal-ref>IEEE 20th Brazilian Symposium on Computer Graphics and Image
  Processing (SIBGRAPI-07), Belo Horizonte-Minas Gerais, Brasil, October 7-10,
  2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Medical image registration is a difficult problem. Not only a registration
algorithm needs to capture both large and small scale image deformations, it
also has to deal with global and local image intensity variations. In this
paper we describe a new multiresolution elastic image registration method that
challenges these difficulties in image registration. To capture large and small
scale image deformations, we use both global and local affine transformation
algorithms. To address global and local image intensity variations, we apply an
image intensity standardization algorithm to correct image intensity
variations. This transforms image intensities into a standard intensity scale,
which allows highly accurate registration of medical images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2076</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2076</id><created>2009-07-12</created><authors><author><keyname>Biscani</keyname><forenames>Francesco</forenames></author></authors><title>The Piranha algebraic manipulator</title><categories>cs.SC</categories><comments>24 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we present a specialised algebraic manipulation package devoted
to Celestial Mechanics. The system, called Piranha, is built on top of a
generic and extensible framework, which allows to treat efficiently and in a
unified way the algebraic structures most commonly encountered in Celestial
Mechanics (such as multivariate polynomials and Poisson series). In this
contribution we explain the architecture of the software, with special focus on
the implementation of series arithmetics, show its current capabilities, and
present benchmarks indicating that Piranha is competitive, performance-wise,
with other specialised manipulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2079</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2079</id><created>2009-07-12</created><authors><author><keyname>Lu</keyname><forenames>Zhaosong</forenames></author><author><keyname>Zhang</keyname><forenames>Yong</forenames></author></authors><title>An Augmented Lagrangian Approach for Sparse Principal Component Analysis</title><categories>math.OC cs.LG math.ST stat.AP stat.CO stat.ME stat.ML stat.TH</categories><comments>42 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principal component analysis (PCA) is a widely used technique for data
analysis and dimension reduction with numerous applications in science and
engineering. However, the standard PCA suffers from the fact that the principal
components (PCs) are usually linear combinations of all the original variables,
and it is thus often difficult to interpret the PCs. To alleviate this
drawback, various sparse PCA approaches were proposed in literature [15, 6, 17,
28, 8, 25, 18, 7, 16]. Despite success in achieving sparsity, some important
properties enjoyed by the standard PCA are lost in these methods such as
uncorrelation of PCs and orthogonality of loading vectors. Also, the total
explained variance that they attempt to maximize can be too optimistic. In this
paper we propose a new formulation for sparse PCA, aiming at finding sparse and
nearly uncorrelated PCs with orthogonal loading vectors while explaining as
much of the total variance as possible. We also develop a novel augmented
Lagrangian method for solving a class of nonsmooth constrained optimization
problems, which is well suited for our formulation of sparse PCA. We show that
it converges to a feasible point, and moreover under some regularity
assumptions, it converges to a stationary point. Additionally, we propose two
nonmonotone gradient methods for solving the augmented Lagrangian subproblems,
and establish their global and local convergence. Finally, we compare our
sparse PCA approach with several existing methods on synthetic, random, and
real data, respectively. The computational results demonstrate that the sparse
PCs produced by our approach substantially outperform those by other methods in
terms of total explained variance, correlation of PCs, and orthogonality of
loading vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2083</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2083</id><created>2009-07-12</created><authors><author><keyname>Zelinski</keyname><forenames>Adam C.</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author><author><keyname>Adalsteinsson</keyname><forenames>Elfar</forenames></author></authors><title>Simultaneously Sparse Solutions to Linear Inverse Problems with Multiple
  System Matrices and a Single Observation Vector</title><categories>cs.NA</categories><comments>36 pages; manuscript unchanged from July 21, 2008, except for updated
  references; content appears in September 2008 PhD thesis</comments><journal-ref>SIAM J. Scientific Computing, vol. 31, no. 5, pp. 4533-4579,
  January 2010</journal-ref><doi>10.1137/080730822</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A linear inverse problem is proposed that requires the determination of
multiple unknown signal vectors. Each unknown vector passes through a different
system matrix and the results are added to yield a single observation vector.
Given the matrices and lone observation, the objective is to find a
simultaneously sparse set of unknown vectors that solves the system. We will
refer to this as the multiple-system single-output (MSSO) simultaneous sparsity
problem. This manuscript contrasts the MSSO problem with other simultaneous
sparsity problems and conducts a thorough initial exploration of algorithms
with which to solve it. Seven algorithms are formulated that approximately
solve this NP-Hard problem. Three greedy techniques are developed (matching
pursuit, orthogonal matching pursuit, and least squares matching pursuit) along
with four methods based on a convex relaxation (iteratively reweighted least
squares, two forms of iterative shrinkage, and formulation as a second-order
cone program). The algorithms are evaluated across three experiments: the first
and second involve sparsity profile recovery in noiseless and noisy scenarios,
respectively, while the third deals with magnetic resonance imaging
radio-frequency excitation pulse design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2089</identifier>
 <datestamp>2011-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2089</id><created>2009-07-12</created><updated>2011-10-05</updated><authors><author><keyname>Arroyuelo</keyname><forenames>A.</forenames></author><author><keyname>Claude</keyname><forenames>F.</forenames></author><author><keyname>Maneth</keyname><forenames>S.</forenames></author><author><keyname>M&#xe4;kinen</keyname><forenames>V.</forenames></author><author><keyname>Navarro</keyname><forenames>G.</forenames></author><author><keyname>Nguyen</keyname><forenames>K.</forenames></author><author><keyname>Siren</keyname><forenames>J.</forenames></author><author><keyname>V&#xe4;lim&#xe4;ki</keyname><forenames>N.</forenames></author></authors><title>Fast In-Memory XPath Search over Compressed Text and Tree Indexes</title><categories>cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large fraction of an XML document typically consists of text data. The
XPath query language allows text search via the equal, contains, and
starts-with predicates. Such predicates can efficiently be implemented using a
compressed self-index of the document's text nodes. Most queries, however,
contain some parts of querying the text of the document, plus some parts of
querying the tree structure. It is therefore a challenge to choose an
appropriate evaluation order for a given query, which optimally leverages the
execution speeds of the text and tree indexes. Here the SXSI system is
introduced; it stores the tree structure of an XML document using a bit array
of opening and closing brackets, and stores the text nodes of the document
using a global compressed self-index. On top of these indexes sits an XPath
query engine that is based on tree automata. The engine uses fast counting
queries of the text index in order to dynamically determine whether to evaluate
top-down or bottom-up with respect to the tree structure. The resulting system
has several advantages over existing systems: (1) on pure tree queries (without
text search) such as the XPathMark queries, the SXSI system performs on par or
better than the fastest known systems MonetDB and Qizx, (2) on queries that use
text search, SXSI outperforms the existing systems by 1--3 orders of magnitude
(depending on the size of the result set), and (3) with respect to memory
consumption, SXSI outperforms all other systems for counting-only queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2090</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2090</id><created>2009-07-12</created><updated>2009-08-25</updated><authors><author><keyname>Rai</keyname><forenames>Brijesh Kumar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author><author><keyname>Shenvi</keyname><forenames>Sagar</forenames></author></authors><title>Some bounds on the capacity of communicating the sum of sources</title><categories>cs.IT math.IT</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider directed acyclic networks with multiple sources and multiple
terminals where each source generates one i.i.d. random process over an abelian
group and all the terminals want to recover the sum of these random processes.
The different source processes are assumed to be independent. The solvability
of such networks has been considered in some previous works. In this paper we
investigate on the capacity of such networks, referred as {\it sum-networks},
and present some bounds in terms of min-cut, and the numbers of sources and
terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2093</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2093</id><created>2009-07-13</created><authors><author><keyname>S.</keyname><forenames>Chandrashekhar Thejaswi P.</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author><author><keyname>Pun</keyname><forenames>Man-On</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Zheng</keyname><forenames>Dong</forenames></author></authors><title>Distributed Opportunistic Scheduling With Two-Level Probing</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed opportunistic scheduling (DOS) is studied for wireless ad-hoc
networks in which many links contend for the channel using random access before
data transmissions. Simply put, DOS involves a process of joint channel probing
and distributed scheduling for ad-hoc (peer-to-peer) communications. Since, in
practice, link conditions are estimated with noisy observations, the
transmission rate has to be backed off from the estimated rate to avoid
transmission outages. Then, a natural question to ask is whether it is
worthwhile for the link with successful contention to perform further channel
probing to mitigate estimation errors, at the cost of additional probing. Thus
motivated, this work investigates DOS with two-level channel probing by
optimizing the tradeoff between the throughput gain from more accurate rate
estimation and the resulting additional delay. Capitalizing on optimal stopping
theory with incomplete information, we show that the optimal scheduling policy
is threshold-based and is characterized by either one or two thresholds,
depending on network settings. Necessary and sufficient conditions for both
cases are rigorously established. In particular, our analysis reveals that
performing second-level channel probing is optimal when the first-level
estimated channel condition falls in between the two thresholds. Numerical
results are provided to illustrate the effectiveness of the proposed DOS with
two-level channel probing. We also extend our study to the case with limited
feedback, where the feedback from the receiver to its transmitter takes the
form of (0,1,e).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2121</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2121</id><created>2009-07-13</created><authors><author><keyname>Rodriguez</keyname><forenames>Sergio R.</forenames></author></authors><title>Topology Discovery Using Cisco Discovery Protocol</title><categories>cs.NI</categories><report-no>TR-200903-013</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of discovering network topology in
proprietary networks. Namely, we investigate topology discovery in Cisco-based
networks. Cisco devices run Cisco Discovery Protocol (CDP) which holds
information about these devices. We first compare properties of topologies that
can be obtained from networks deploying CDP versus Spanning Tree Protocol (STP)
and Management Information Base (MIB) Forwarding Database (FDB). Then we
describe a method of discovering topology of CDP-based networks. Our
experiments show that the physical topology of the network including links that
are in Forwarding Block state can be discovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2130</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2130</id><created>2009-07-13</created><authors><author><keyname>Reghizzi</keyname><forenames>Stefano Crespi</forenames></author><author><keyname>Mandrioli</keyname><forenames>Dino</forenames></author></authors><title>Algebraic properties of structured context-free languages: old
  approaches and novel developments</title><categories>cs.FL</categories><comments>Extended version of paper presented at WORDS2009, Salerno,Italy,
  September 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The historical research line on the algebraic properties of structured CF
languages initiated by McNaughton's Parenthesis Languages has recently
attracted much renewed interest with the Balanced Languages, the Visibly
Pushdown Automata languages (VPDA), the Synchronized Languages, and the
Height-deterministic ones. Such families preserve to a varying degree the basic
algebraic properties of Regular languages: boolean closure, closure under
reversal, under concatenation, and Kleene star. We prove that the VPDA family
is strictly contained within the Floyd Grammars (FG) family historically known
as operator precedence. Languages over the same precedence matrix are known to
be closed under boolean operations, and are recognized by a machine whose pop
or push operations on the stack are purely determined by terminal letters. We
characterize VPDA's as the subclass of FG having a peculiarly structured set of
precedence relations, and balanced grammars as a further restricted case. The
non-counting invariance property of FG has a direct implication for VPDA too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2139</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2139</id><created>2009-07-13</created><authors><author><keyname>Phan</keyname><forenames>Mai-Anh</forenames></author><author><keyname>Huschke</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>Adaptive Point-to-Multipoint Transmission for Multimedia Broadcast
  Multicast Services in LTE</title><categories>cs.NI cs.PF</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates point-to-multipoint (PTM) transmission supporting
adaptive modulation and coding (AMC) as well as retransmissions based on
incremental redundancy. In contrast to the classical PTM transmission which was
introduced by the Multimedia Broadcast Multicast Service (MBMS), the
adaptiveness requires user individual feedback channels that allow the
receivers to report their radio conditions and send positive or negative
acknowledgments (ACK/NACK) for a Layer 1 transport block to the eNodeB. In this
work, an adaptive PTM scheme based on feedback from multiple users is presented
and evaluated. Furthermore, a simple NACK-oriented feedback mechanism is
introduced to relieve the feedback channel that is used in the uplink. Finally,
the performance of different single-cell MBMS transmission modes is evaluated
by dynamic radio network simulations. It is shown that adaptive PTM
transmission outperforms the conventional MBMS configurations in terms of radio
resource consumption and user satisfaction rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2157</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2157</id><created>2009-07-13</created><authors><author><keyname>Crochemore</keyname><forenames>Maxime</forenames></author><author><keyname>Iliopoulos</keyname><forenames>Costas</forenames></author><author><keyname>Kubica</keyname><forenames>Marcin</forenames></author><author><keyname>Radoszewski</keyname><forenames>Jakub</forenames></author><author><keyname>Rytter</keyname><forenames>Wojciech</forenames></author><author><keyname>Walen</keyname><forenames>Tomasz</forenames></author></authors><title>On the maximal number of highly periodic runs in a string</title><categories>cs.DS cs.DM</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A run is a maximal occurrence of a repetition $v$ with a period $p$ such that
$2p \le |v|$. The maximal number of runs in a string of length $n$ was studied
by several authors and it is known to be between $0.944 n$ and $1.029 n$. We
investigate highly periodic runs, in which the shortest period $p$ satisfies
$3p \le |v|$. We show the upper bound $0.5n$ on the maximal number of such runs
in a string of length $n$ and construct a sequence of words for which we obtain
the lower bound $0.406 n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2165</identifier>
 <datestamp>2009-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2165</id><created>2009-07-13</created><updated>2009-10-29</updated><authors><author><keyname>Bessy</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Perez</keyname><forenames>Anthony</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>Kernels for Feedback Arc Set In Tournaments</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A tournament T=(V,A) is a directed graph in which there is exactly one arc
between every pair of distinct vertices. Given a digraph on n vertices and an
integer parameter k, the Feedback Arc Set problem asks whether the given
digraph has a set of k arcs whose removal results in an acyclic digraph. The
Feedback Arc Set problem restricted to tournaments is known as the k-Feedback
Arc Set in Tournaments (k-FAST) problem. In this paper we obtain a linear
vertex kernel for k-FAST. That is, we give a polynomial time algorithm which
given an input instance T to k-FAST obtains an equivalent instance T' on O(k)
vertices. In fact, given any fixed e&gt;0, the kernelized instance has at most
(2+e)k vertices. Our result improves the previous known bound of O(k^2) on the
kernel size for k-FAST. Our kernelization algorithm solves the problem on a
subclass of tournaments in polynomial time and uses a known polynomial time
approximation scheme for k-FAST.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2173</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2173</id><created>2009-07-13</created><updated>2011-06-05</updated><authors><author><keyname>Mazonka</keyname><forenames>Oleg</forenames></author></authors><title>Bit Copying - The Ultimate Computational Simplicity</title><categories>cs.PL</categories><journal-ref>Complex Systems Journal 2011, Vol 19, N3</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computational abstract machine based on two operations: referencing and bit
copying is presented. These operations are sufficient for carrying out any
computation. They can be used as the primitives for a Turing-complete
programming language. The interesting point is that the computation can be done
without logic operations such as AND or OR. The compiler and emulator of this
language with sample programs are available on the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2209</identifier>
 <datestamp>2009-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2209</id><created>2009-07-13</created><updated>2009-10-12</updated><authors><author><keyname>Krizhanovsky</keyname><forenames>A. A.</forenames></author><author><keyname>Lin</keyname><forenames>Feiyu</forenames></author></authors><title>Related terms search based on WordNet / Wiktionary and its application
  in Ontology Matching</title><categories>cs.IR</categories><comments>7 pages, 2 tables, 3 figures; In: RCDL 2009. September 17-21,
  Petrozavodsk, Russia. - pp. 363-369</comments><acm-class>I.7.2; I.7.3; I.7.5; H.3.1; H.3.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A set of ontology matching algorithms (for finding correspondences between
concepts) is based on a thesaurus that provides the source data for the
semantic distance calculations. In this wiki era, new resources may spring up
and improve this kind of semantic search. In the paper a solution of this task
based on Russian Wiktionary is compared to WordNet based algorithms. Metrics
are estimated using the test collection, containing 353 English word pairs with
a relatedness score assigned by human evaluators. The experiment shows that the
proposed method is capable in principle of calculating a semantic distance
between pair of words in any language presented in Russian Wiktionary. The
calculation of Wiktionary based metric had required the development of the
open-source Wiktionary parser software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2210</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2210</id><created>2009-07-13</created><authors><author><keyname>Parthasarathy</keyname><forenames>K. R.</forenames></author></authors><title>On the philosophy of Cram\'er-Rao-Bhattacharya Inequalities in Quantum
  Statistics</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><msc-class>81C20; 94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To any parametric family of states of a finite level quantum system we
associate a space of Fisher maps and introduce the natural notions of
Cram\'er-Rao-Bhattacharya tensor and Fisher information form. This leads us to
an abstract Cram\'er-Rao-Bhattacharya lower bound for the covariance matrix of
any finite number of unbiased estimators of parameteric functions. A number of
illustrative examples is included. Modulo technical assumptions of various
kinds our methods can be applied to infinite level quantum systems as well as
parametric families of classical probability distributions on Borel spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2222</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2222</id><created>2009-07-13</created><authors><author><keyname>Krishnaswamy</keyname><forenames>Dilip</forenames></author><author><keyname>Zhao</keyname><forenames>Shanyu</forenames></author></authors><title>Network-aware Adaptation with Real-Time Channel Statistics for Wireless
  LAN Multimedia Transmissions in the Digital Home</title><categories>cs.NI cs.LG</categories><comments>6 pages, 12 figures</comments><journal-ref>IEEE COMSWARE 2008, Jan 6-10 2008, Pages 714-719</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper suggests the use of intelligent network-aware processing agents in
wireless local area network drivers to generate metrics for bandwidth
estimation based on real-time channel statistics to enable wireless multimedia
application adaptation. Various configurations in the wireless digital home are
studied and the experimental results with performance variations are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2252</identifier>
 <datestamp>2009-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2252</id><created>2009-07-13</created><authors><author><keyname>Krishnaswamy</keyname><forenames>Dilip</forenames></author></authors><title>AWiMA: An architecture for Adhoc Wireless Mobile internet Access</title><categories>cs.NI</categories><comments>5 pages, 3 figures, submitted to IEEE Globecom 2008</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper suggests a system architecture for wireless widearea- networking
access using adhoc networking between a mobile Client node without direct
connectivity to a wirelesswide- area-network and a mobile Service Provider node
with connectivity to a wireless-wide-area-network. It provides a means for
securely providing such adhoc wireless networking services using a Server for
tunneling and routing, registration and authentication. The architecture also
provides support for handoff of a Client node from one Service Provider to
another with persistence of a tunnel between the Client and the Server enabling
a soft-handoff. Different wireless protocols may be used for adhoc networking,
with filtered interconnection of authenticated Clients implemented at a Service
Provider node. The architecture is applicable across different wide-areanetwork
protocols, and provides simultaneous support for multiple wide-area-network
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2268</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2268</id><created>2009-07-14</created><updated>2010-04-15</updated><authors><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L</forenames></author></authors><title>Evaluating Methods to Rediscover Missing Web Pages from the Web
  Infrastructure</title><categories>cs.IR cs.DL</categories><comments>10 pages, 11 figures, 5 tables, 40 references, accepted for
  publication at JCDL 2010 in Brisbane, Australia</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Missing web pages (pages that return the 404 &quot;Page Not Found&quot; error) are part
of the browsing experience. The manual use of search engines to rediscover
missing pages can be frustrating and unsuccessful. We compare four automated
methods for rediscovering web pages. We extract the page's title, generate the
page's lexical signature (LS), obtain the page's tags from the bookmarking
website delicious.com and generate a LS from the page's link neighborhood. We
use the output of all methods to query Internet search engines and analyze
their retrieval performance. Our results show that both LSs and titles perform
fairly well with over 60% URIs returned top ranked from Yahoo!. However, the
combination of methods improves the retrieval performance. Considering the
complexity of the LS generation, querying the title first and in case of
insufficient results querying the LSs second is the preferable setup. This
combination accounts for more than 75% top ranked URIs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2300</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2300</id><created>2009-07-14</created><updated>2010-10-01</updated><authors><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Dingkang</forenames></author></authors><title>An Efficient Algorithm for Factoring Polynomials over Algebraic
  Extension Field</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new efficient algorithm is proposed for factoring polynomials over an
algebraic extension field. The extension field is defined by a polynomial ring
modulo a maximal ideal. If the maximal ideal is given by its Groebner basis, no
extra Groebner basis computation is needed for factoring a polynomial over this
extension field. Nothing more than linear algebraic technique is used to get a
polynomial over the ground field by a generic linear map. Then this polynomial
is factorized over the ground field. From these factors, the factorization of
the polynomial over the extension field is obtained. The new algorithm has been
implemented and computer experiments indicate that the new algorithm is very
efficient, particularly in complicated examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2309</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2309</id><created>2009-07-14</created><updated>2010-02-02</updated><authors><author><keyname>Rost</keyname><forenames>Peter</forenames></author><author><keyname>Fettweis</keyname><forenames>Gerhard</forenames></author></authors><title>Protocols and Performance Limits for Half-Duplex Relay Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, protocols for the half-duplex relay channel are introduced and
performance limits are analyzed. Relay nodes underly an orthogonality
constraint, which prohibits simultaneous receiving and transmitting on the same
time-frequency resource. Based upon this practical consideration, different
protocols are discussed and evaluated using a Gaussian system model. For the
considered scenarios compress-and-forward based protocols dominate for a wide
range of parameters decode-and-forward protocols. In this paper, a protocol
with one compress-and-forward and one decode-and-forward based relay is
introduced. Just as the cut-set bound, which operates in a mode where relays
transmit alternately, both relays support each other. Furthermore, it is shown
that in practical systems a random channel access provides only marginal
performance gains if any.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2315</identifier>
 <datestamp>2009-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2315</id><created>2009-07-14</created><authors><author><keyname>Yupu</keyname><forenames>Hu</forenames></author><author><keyname>Fengrong</keyname><forenames>Zhang</forenames></author><author><keyname>Yiwei</keyname><forenames>Zhang</forenames></author></authors><title>Hard Fault Analysis of Trivium</title><categories>cs.CR cs.IT math.IT</categories><comments>10 pages</comments><acm-class>D.4.6; K.6.5</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Fault analysis is a powerful attack to stream ciphers. Up to now, the major
idea of fault analysis is to simplify the cipher system by injecting some soft
faults. We call it soft fault analysis. As a hardware-oriented stream cipher,
Trivium is weak under soft fault analysis.
  In this paper we consider another type of fault analysis of stream cipher,
which is to simplify the cipher system by injecting some hard faults. We call
it hard fault analysis. We present the following results about such attack to
Trivium. In Case 1 with the probability not smaller than 0.2396, the attacker
can obtain 69 bits of 80-bits-key. In Case 2 with the probability not smaller
than 0.2291, the attacker can obtain all of 80-bits-key. In Case 3 with the
probability not smaller than 0.2291, the attacker can partially solve the key.
In Case 4 with non-neglectable probability, the attacker can obtain a
simplified cipher, with smaller number of state bits and slower
non-linearization procedure. In Case 5 with non-neglectable probability, the
attacker can obtain another simplified cipher. Besides, these 5 cases can be
checked out by observing the key-stream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2324</identifier>
 <datestamp>2009-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2324</id><created>2009-07-14</created><authors><author><keyname>Bienvenu</keyname><forenames>Laurent</forenames></author><author><keyname>Hoelzl</keyname><forenames>Rupert</forenames></author><author><keyname>Kraling</keyname><forenames>Thorsten</forenames></author><author><keyname>Merkle</keyname><forenames>Wolfgang</forenames></author></authors><title>Separations of non-monotonic randomness notions</title><categories>cs.CC</categories><comments>A preliminary version of this paper was presented at the Sixth
  International Conference on Computability and Complexity in Analysis, August
  18-22, 2009, Ljubljana, Slovenia</comments><acm-class>F.1.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the theory of algorithmic randomness, several notions of random sequence
are defined via a game-theoretic approach, and the notions that received most
attention are perhaps Martin-Loef randomness and computable randomness. The
latter notion was introduced by Schnorr and is rather natural: an infinite
binary sequence is computably random if no total computable strategy succeeds
on it by betting on bits in order. However, computably random sequences can
have properties that one may consider to be incompatible with being random, in
particular, there are computably random sequences that are highly compressible.
The concept of Martin-Loef randomness is much better behaved in this and other
respects, on the other hand its definition in terms of martingales is
considerably less natural. Muchnik, elaborating on ideas of Kolmogorov and
Loveland, refined Schnorr's model by also allowing non-monotonic strategies,
i.e. strategies that do not bet on bits in order. The subsequent
``non-monotonic'' notion of randomness, now called Kolmogorov-Loveland
randomness, has been shown to be quite close to Martin-Loef randomness, but
whether these two classes coincide remains a fundamental open question. As
suggested by Miller and Nies, we study in this paper weak versions of
Kolmogorov-Loveland randomness, where the betting strategies are non-adaptive
(i.e., the positions of the bits to bet on should be decided before the game).
We obtain a full classification of the different notions we consider.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2376</identifier>
 <datestamp>2009-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2376</id><created>2009-07-14</created><authors><author><keyname>Peterson</keyname><forenames>Elisha</forenames></author></authors><title>Cooperation in Subset Team Games: Altruism and Selfishness</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends the theory of subset team games, a generalization of
cooperative game theory requiring a payoff function that is defined for all
subsets of players. This subset utility is used to define both altruistic and
selfish contributions of a player to the team. We investigate properties of
these games, and analyze the implications of altruism and selfishness for
general situations, for prisoner's dilemma, and for a specific game with a
Cobb-Douglas utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2391</identifier>
 <datestamp>2009-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2391</id><created>2009-07-14</created><authors><author><keyname>Coronel</keyname><forenames>Pedro</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Optimal Diversity-Multiplexing Tradeoff in Selective-Fading MIMO
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the optimal diversity-multiplexing (DM) tradeoff of coherent
time, frequency, and time-frequency selective-fading multiple-input
multiple-output (MIMO) channels and provide a code design criterion for DM
tradeoff optimality. Our results are based on the new concept of the &quot;Jensen
channel&quot; associated to a given selective-fading MIMO channel. While the
original problem seems analytically intractable due to the mutual information
between channel input and output being a sum of correlated random variables,
the Jensen channel is equivalent to the original channel in the sense of the DM
tradeoff and lends itself nicely to analytical treatment. We formulate a
systematic procedure for designing DM tradeoff optimal codes for general
selective-fading MIMO channels by demonstrating that the design problem can be
separated into two simpler and independent problems: the design of an inner
code, or precoder, adapted to the channel statistics (i.e., the selectivity
characteristics) and an outer code independent of the channel statistics. Our
results are supported by appealing geometric intuition, first pointed out for
the flat-fading case by Zheng and Tse, IEEE Trans. Inf. Theory, 2003.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2393</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2393</id><created>2009-07-14</created><updated>2010-09-24</updated><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Multiscale Network Reduction Methodologies: Bistochastic and Disparity
  Filtering of Human Migration Flows between 3,000+ U. S. Counties</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>35 pages, 12 figures, some rewriting. Dendrogram included as EPAPS
  file</comments><msc-class>91C20, 91D30, 05C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To control for multiscale effects in networks, one can transform the matrix
of (in general) weighted, directed internodal flows to bistochastic
(doubly-stochastic) form, using the iterative proportional fitting
(Sinkhorn-Knopp) procedure, which alternatively scales row and column sums to
all equal 1. The dominant entries in the bistochasticized table can then be
employed for network reduction, using strong component hierarchical clustering.
We illustrate various facets of this well-established, widely-applied two-stage
algorithm with the 3, 107 x 3, 107 (asymmetric) 1995-2000 intercounty migration
flow table for the United States. We compare the results obtained with ones
using the disparity filter, for &quot;extracting the &quot;multiscale backbone of complex
weighted networks&quot;, recently put forth by Serrano, Boguna and Vespignani (SBV)
(Proc. Natl. Acad. Sci. 106 [2009], 6483), upon which we have briefly commented
(Proc. Natl. Acad. Sci. 106 [2009], E66). The performance of the bistochastic
filter appears to be superior-at least in this specific case-in two respects:
(1) it requires far fewer links to complete a stongly-connected network
backbone; and (2) it &quot;belittles&quot; small flows and nodes less-a principal
desideratum of SBV-in the sense that the correlations of the nonzero raw flows
are considerably weaker with the corresponding bistochastized links than with
the significance levels yielded by the disparity filter. Additional comparative
studies--as called for by SBV-of these two filtering procedures, in particular
as regards their topological properties, should be of considerable interest.
Relatedly, in its many geographic applications, the two-stage procedure
has--with rare exceptions-clustered contiguous areas, often reconstructing
traditional regions (islands, for example), even though no contiguity
constraints, at all, are imposed beforehand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2412</identifier>
 <datestamp>2009-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2412</id><created>2009-07-14</created><authors><author><keyname>Hammerich</keyname><forenames>Edwin</forenames></author></authors><title>Design of Pulse Shapes and Digital Filters Based on Gaussian Functions</title><categories>cs.IT math.IT</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two new pulse shapes for communications are presented. The first pulse shape
is ISI-free and identical with the interpolating function (or ISI-free kernel)
of a reconstruction formula in shift-invariant spaces with Gaussian generator.
Several closed form representations in time and frequency domain are given
including one for an approximation that is particularly simple. The second
pulse shape is the root of the former and obtained by spectral factorization.
As a consequence, shifted versions of it form an orthonormal system in the
Hilbert space of finite-energy signals. The latter pulse shape is described as
the response of an infinite-order digital FIR filter on a Gaussian function as
input signal. Several equivalent versions of the digital filter including their
finite-order approximations are presented. All filters enjoy the property that
explicit formulas for their coefficients and poles are available. The filters
are fully parametrizable with respect to bandwidth and sampling rate of the
digital data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2423</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2423</id><created>2009-07-14</created><updated>2010-11-19</updated><authors><author><keyname>Carlsson</keyname><forenames>Gunnar</forenames></author><author><keyname>Singh</keyname><forenames>Gurjeet</forenames></author><author><keyname>Zomorodian</keyname><forenames>Afra</forenames></author></authors><title>Computing Multidimensional Persistence</title><categories>cs.CG cs.NA</categories><comments>This paper has been withdrawn by the authors. Journal of
  Computational Geometry, 1(1) 2010, pages 72-100.
  http://jocg.org/index.php/jocg/article/view/19</comments><acm-class>I.1.2; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of multidimensional persistence captures the topology of a
multifiltration -- a multiparameter family of increasing spaces.
Multifiltrations arise naturally in the topological analysis of scientific
data. In this paper, we give a polynomial time algorithm for computing
multidimensional persistence. We recast this computation as a problem within
computational algebraic geometry and utilize algorithms from this area to solve
it. While the resulting problem is Expspace-complete and the standard
algorithms take doubly-exponential time, we exploit the structure inherent
withing multifiltrations to yield practical algorithms. We implement all
algorithms in the paper and provide statistical experiments to demonstrate
their feasibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2435</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2435</id><created>2009-07-14</created><updated>2010-01-15</updated><authors><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Hartline</keyname><forenames>Jason</forenames></author><author><keyname>Malec</keyname><forenames>David</forenames></author><author><keyname>Sivan</keyname><forenames>Balasubramanian</forenames></author></authors><title>Sequential Posted Pricing and Multi-parameter Mechanism Design</title><categories>cs.GT</categories><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the classical mathematical economics problem of {\em Bayesian
optimal mechanism design} where a principal aims to optimize expected revenue
when allocating resources to self-interested agents with preferences drawn from
a known distribution. In single-parameter settings (i.e., where each agent's
preference is given by a single private value for being served and zero for not
being served) this problem is solved [Myerson '81]. Unfortunately, these single
parameter optimal mechanisms are impractical and rarely employed [Ausubel and
Milgrom '06], and furthermore the underlying economic theory fails to
generalize to the important, relevant, and unsolved multi-dimensional setting
(i.e., where each agent's preference is given by multiple values for each of
the multiple services available) [Manelli and Vincent '07]. In contrast to the
theory of optimal mechanisms we develop a theory of sequential posted price
mechanisms, where agents in sequence are offered take-it-or-leave-it prices.
These mechanisms are approximately optimal in single-dimensional settings, and
avoid many of the properties that make optimal mechanisms impractical.
Furthermore, these mechanisms generalize naturally to give the first known
approximations to the elusive optimal multi-dimensional mechanism design
problem. In particular, we solve multi-dimensional multi-unit auction problems
and generalizations to matroid feasibility constraints. The constant
approximations we obtain range from 1.5 to 8. For all but one case, our posted
price sequences can be computed in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2452</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2452</id><created>2009-07-14</created><authors><author><keyname>Takeuchi</keyname><forenames>Koichi</forenames><affiliation>NII</affiliation></author><author><keyname>Kageura</keyname><forenames>Kyo</forenames><affiliation>NII</affiliation></author><author><keyname>Koyama</keyname><forenames>Teruo</forenames><affiliation>NII</affiliation></author><author><keyname>Daille</keyname><forenames>B&#xe9;atrice</forenames><affiliation>LINA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Pattern Based Term Extraction Using ACABIT System</title><categories>cs.CL</categories><proxy>ccsd hal-00403925</proxy><journal-ref>IEIC Technical Report 103, 280 (2003) 31-36</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a pattern-based term extraction approach for
Japanese, applying ACABIT system originally developed for French. The proposed
approach evaluates termhood using morphological patterns of basic terms and
term variants. After extracting term candidates, ACABIT system filters out
non-terms from the candidates based on log-likelihood. This approach is
suitable for Japanese term extraction because most of Japanese terms are
compound nouns or simple phrasal patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2455</identifier>
 <datestamp>2011-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2455</id><created>2009-07-14</created><updated>2011-07-05</updated><authors><author><keyname>Shin</keyname><forenames>Won-Yong</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Lee</keyname><forenames>Yong H.</forenames></author></authors><title>Parallel Opportunistic Routing in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>18 pages, 7 figures, Under Review for Possible Publication in IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study benefits of opportunistic routing in a large wireless ad hoc network
by examining how the power, delay, and total throughput scale as the number of
source- destination pairs increases up to the operating maximum. Our
opportunistic routing is novel in a sense that it is massively parallel, i.e.,
it is performed by many nodes simultaneously to maximize the opportunistic gain
while controlling the inter-user interference. The scaling behavior of
conventional multi-hop transmission that does not employ opportunistic routing
is also examined for comparison. Our results indicate that our opportunistic
routing can exhibit a net improvement in overall power--delay trade-off over
the conventional routing by providing up to a logarithmic boost in the scaling
law. Such a gain is possible since the receivers can tolerate more interference
due to the increased received signal power provided by the multi-user diversity
gain, which means that having more simultaneous transmissions is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2465</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2465</id><created>2009-07-14</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>The Transactional Nature of Quantum Information</title><categories>quant-ph cs.IT math.IT</categories><comments>Presented at the 11th International Conference on Squeezed States and
  Uncertainty Relations and 4th Feynman Festival, Olomouc, Czech Republic, June
  22-26, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information, in its communications sense, is a transactional property. If the
received signals communicate choices made by the sender of the signals, then
information has been transmitter by the sender to the receiver. Given this
reality, the potential information in an unknown pure quantum state should be
non-zero. We examine transactional quantum information, which unlike von
Neumann entropy, depends on the mutuality of the relationship between the
sender and the receiver, associating information with an unknown pure state.
The information that can be obtained from a pure state in repeated experiments
is potentially infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2471</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2471</id><created>2009-07-14</created><authors><author><keyname>Hassanzadeh</keyname><forenames>Oktie</forenames></author></authors><title>Benchmarking Declarative Approximate Selection Predicates</title><categories>cs.DB cs.IR</categories><comments>75 pages, 7 figures, February 2007, Masters Thesis at University of
  Toronto</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Declarative data quality has been an active research topic. The fundamental
principle behind a declarative approach to data quality is the use of
declarative statements to realize data quality primitives on top of any
relational data source. A primary advantage of such an approach is the ease of
use and integration with existing applications. Several similarity predicates
have been proposed in the past for common quality primitives (approximate
selections, joins, etc.) and have been fully expressed using declarative SQL
statements. In this thesis, new similarity predicates are proposed along with
their declarative realization, based on notions of probabilistic information
retrieval. Then, full declarative specifications of previously proposed
similarity predicates in the literature are presented, grouped into classes
according to their primary characteristics. Finally, a thorough performance and
accuracy study comparing a large number of similarity predicates for data
cleaning operations is performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2479</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2479</id><created>2009-07-14</created><authors><author><keyname>Weidert</keyname><forenames>Craig</forenames></author></authors><title>Extremal problems in ordered graphs</title><categories>cs.DM</categories><comments>Thesis for Master Degree, Simon Fraser University</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis we consider ordered graphs (that is, graphs with a fixed
linear ordering on their vertices). We summarize and further investigations on
the number of edges an ordered graph may have while avoiding a fixed forbidden
ordered graph as a subgraph. In particular, we take a step toward confirming a
conjecture of Pach and Tardos regarding the number of edges allowed when the
forbidden pattern is a tree by establishing an upper bound for a particular
ordered graph for which existing techniques have failed. We also generalize a
theorem of Geneson by establishing an upper bound on the number of edges
allowed if the forbidden graphs fit a generalized notion of a matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2485</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2485</id><created>2009-07-15</created><updated>2009-10-12</updated><authors><author><keyname>Marinos</keyname><forenames>Alexandros</forenames></author><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author></authors><title>Community Cloud Computing</title><categories>cs.NI cs.DC cs.SE</categories><comments>11 Pages, 5 figures</comments><doi>10.1007/978-3-642-10665-1_43</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Computing is rising fast, with its data centres growing at an
unprecedented rate. However, this has come with concerns over privacy,
efficiency at the expense of resilience, and environmental sustainability,
because of the dependence on Cloud vendors such as Google, Amazon and
Microsoft. Our response is an alternative model for the Cloud
conceptualisation, providing a paradigm for Clouds in the community, utilising
networked personal computers for liberation from the centralised vendor model.
Community Cloud Computing (C3) offers an alternative architecture, created by
combing the Cloud with paradigms from Grid Computing, principles from Digital
Ecosystems, and sustainability from Green Computing, while remaining true to
the original vision of the Internet. It is more technically challenging than
Cloud Computing, having to deal with distributed computing issues, including
heterogeneous nodes, varying quality of service, and additional security
constraints. However, these are not insurmountable challenges, and with the
need to retain control over our digital lives and the potential environmental
consequences, it is a challenge we must pursue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2510</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2510</id><created>2009-07-15</created><updated>2011-02-24</updated><authors><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Capacity of a Class of Linear Binary Field Multi-source Relay Networks</title><categories>cs.IT math.IT</categories><comments>19 pages, 7 figures, submitted to IEEE trans. on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 59, no. 10, pp.
  6405-6420, Oct. 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Characterizing the capacity region of multi-source wireless relay networks is
one of the fundamental issues in network information theory. The problem is,
however, quite challenging due to inter-user interference when there exist
multiple source--destination (S--D) pairs in the network. By focusing on a
special class of networks, we show that the capacity can be found. Namely, we
study a layered linear binary field network with time-varying channels, which
is a simplified model reflecting broadcast, interference, and fading natures of
wireless communications. We observe that fading can play an important role in
mitigating inter-user interference effectively for both single-hop and
multi-hop networks. We propose new encoding and relaying schemes with
randomized channel pairing, which exploit such channel variations, and derive
their achievable rates. By comparing them with the cut-set upper bound, the
capacity region of single-hop networks and the sum capacity of multi-hop
networks can be characterized for some classes of channel distributions and
network topologies. For these classes, we show that the capacity region or sum
capacity can be interpreted as the max-flow min-cut theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2557</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2557</id><created>2009-07-15</created><updated>2009-11-14</updated><authors><author><keyname>Bl&#xfc;mlein</keyname><forenames>J.</forenames></author><author><keyname>Broadhurst</keyname><forenames>D. J.</forenames></author><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author></authors><title>The Multiple Zeta Value Data Mine</title><categories>math-ph cs.MS hep-ph hep-th math.AG math.MP math.NT</categories><report-no>DESY 09-003, SFB/CPP-09-65</report-no><journal-ref>Comput.Phys.Commun.181:582-625,2010</journal-ref><doi>10.1016/j.cpc.2009.11.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a data mine of proven results for multiple zeta values (MZVs) of
the form $\zeta(s_1,s_2,...,s_k)=\sum_{n_1&gt;n_2&gt;...&gt;n_k&gt;0}^\infty \{1/(n_1^{s_1}
&gt;... n_k^{s_k})\}$ with weight $w=\sum_{i=1}^k s_i$ and depth $k$ and for Euler
sums of the form $\sum_{n_1&gt;n_2&gt;...&gt;n_k&gt;0}^\infty t\{(\epsilon_1^{n_1}
&gt;...\epsilon_1 ^{n_k})/ (n_1^{s_1} ... n_k^{s_k}) \}$ with signs
$\epsilon_i=\pm1$. Notably, we achieve explicit proven reductions of all MZVs
with weights $w\le22$, and all Euler sums with weights $w\le12$, to bases whose
dimensions, bigraded by weight and depth, have sizes in precise agreement with
the Broadhurst--Kreimer and Broadhurst conjectures. Moreover, we lend further
support to these conjectures by studying even greater weights ($w\le30$), using
modular arithmetic. To obtain these results we derive a new type of relation
for Euler sums, the Generalized Doubling Relations. We elucidate the &quot;pushdown&quot;
mechanism, whereby the ornate enumeration of primitive MZVs, by weight and
depth, is reconciled with the far simpler enumeration of primitive Euler sums.
There is some evidence that this pushdown mechanism finds its origin in
doubling relations. We hope that our data mine, obtained by exploiting the
unique power of the computer algebra language {\sc form}, will enable the study
of many more such consequences of the double-shuffle algebra of MZVs, and their
Euler cousins, which are already the subject of keen interest, to practitioners
of quantum field theory, and to mathematicians alike.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2563</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2563</id><created>2009-07-15</created><authors><author><keyname>Jaho</keyname><forenames>Eva</forenames></author><author><keyname>Koukoutsidis</keyname><forenames>Ioannis</forenames></author><author><keyname>Tang</keyname><forenames>Siyu</forenames></author><author><keyname>Stavrakakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Van Mieghem</keyname><forenames>Piet</forenames></author></authors><title>Gossip-based Search in Multipeer Communication Networks</title><categories>cs.NI cs.PF</categories><comments>preprint (18 pages, 6 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a gossip-based algorithm for searching data objects in a multipeer
communication network. All of the nodes in the network are able to communicate
with each other. There exists an initiator node that starts a round of searches
by randomly querying one or more of its neighbors for a desired object. The
queried nodes can also be activated and look for the object. We examine several
behavioural patterns of nodes with respect to their willingness to cooperate in
the search. We derive mathematical models for the search process based on the
balls and bins model, as well as known approximations for the rumour-spreading
problem. All models are validated with simulations. We also evaluate the
performance of the algorithm and examine the impact of search parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2585</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2585</id><created>2009-07-15</created><authors><author><keyname>Gansner</keyname><forenames>Emden R.</forenames></author><author><keyname>Hu</keyname><forenames>Yifan</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author></authors><title>GMap: Drawing Graphs as Maps</title><categories>cs.CG</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information visualization is essential in making sense out of large data
sets. Often, high-dimensional data are visualized as a collection of points in
2-dimensional space through dimensionality reduction techniques. However, these
traditional methods often do not capture well the underlying structural
information, clustering, and neighborhoods. In this paper, we describe GMap: a
practical tool for visualizing relational data with geographic-like maps. We
illustrate the effectiveness of this approach with examples from several
domains All the maps referenced in this paper can be found in
http://www.research.att.com/~yifanhu/GMap
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2599</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2599</id><created>2009-07-15</created><authors><author><keyname>Ly</keyname><forenames>Hung D.</forenames></author><author><keyname>Liu</keyname><forenames>Tie</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author></authors><title>Multiple-Input Multiple-Output Gaussian Broadcast Channels with Common
  and Confidential Messages</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of the multiple-input multiple-output (MIMO)
Gaussian broadcast channel with two receivers (receivers 1 and 2) and two
messages: a common message intended for both receivers and a confidential
message intended only for receiver 1 but needing to be kept asymptotically
perfectly secure from receiver 2. A matrix characterization of the secrecy
capacity region is established via a channel enhancement argument. The enhanced
channel is constructed by first splitting receiver 1 into two virtual receivers
and then enhancing only the virtual receiver that decodes the confidential
message. The secrecy capacity region of the enhanced channel is characterized
using an extremal entropy inequality previously established for characterizing
the capacity region of a degraded compound MIMO Gaussian broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2601</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2601</id><created>2009-07-15</created><authors><author><keyname>Said</keyname><forenames>Salem</forenames></author><author><keyname>Lageman</keyname><forenames>Christian</forenames></author><author><keyname>Bihan</keyname><forenames>Nicolas Le</forenames></author><author><keyname>Manton</keyname><forenames>Jonathan H.</forenames></author></authors><title>Decompounding on compact Lie groups</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>26 pages, 3 figures, 25 references</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 56, Issue 6, pp.
  2766-2777, 2010</journal-ref><doi>10.1109/TIT.2010.2046216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noncommutative harmonic analysis is used to solve a nonparametric estimation
problem stated in terms of compound Poisson processes on compact Lie groups.
This problem of decompounding is a generalization of a similar classical
problem. The proposed solution is based on a char- acteristic function method.
The treated problem is important to recent models of the physical inverse
problem of multiple scattering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2621</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2621</id><created>2009-07-15</created><authors><author><keyname>Hrubes</keyname><forenames>Pavel</forenames></author><author><keyname>Yehudayoff</keyname><forenames>Amir</forenames></author></authors><title>Homogeneous formulas and symmetric polynomials</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the arithmetic formula complexity of the elementary symmetric
polynomials S(k,n). We show that every multilinear homogeneous formula
computing S(k,n) has size at least k^(Omega(log k))n, and that product-depth d
multilinear homogeneous formulas for S(k,n) have size at least
2^(Omega(k^{1/d}))n. Since S(n,2n) has a multilinear formula of size O(n^2), we
obtain a superpolynomial separation between multilinear and multilinear
homogeneous formulas. We also show that S(k,n) can be computed by homogeneous
formulas of size k^(O(log k))n, answering a question of Nisan and Wigderson.
Finally, we present a superpolynomial separation between monotone and
non-monotone formulas in the noncommutative setting, answering a question of
Nisan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2627</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2627</id><created>2009-07-15</created><authors><author><keyname>Bonsma</keyname><forenames>Paul</forenames></author><author><keyname>Breuer</keyname><forenames>Felix</forenames></author></authors><title>Finding Fullerene Patches in Polynomial Time</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following question, motivated by the enumeration of
fullerenes. A fullerene patch is a 2-connected plane graph G in which inner
faces have length 5 or 6, non-boundary vertices have degree 3, and boundary
vertices have degree 2 or 3. The degree sequence along the boundary is called
the boundary code of G. We show that the question whether a given sequence S is
a boundary code of some fullerene patch can be answered in polynomial time when
such patches have at most five 5-faces. We conjecture that our algorithm gives
the correct answer for any number of 5-faces, and sketch how to extend the
algorithm to the problem of counting the number of different patches with a
given boundary code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2639</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2639</id><created>2009-07-15</created><updated>2009-07-27</updated><authors><author><keyname>Pataki</keyname><forenames>Gabor</forenames></author><author><keyname>Tural</keyname><forenames>Mustafa</forenames></author></authors><title>Basis Reduction, and the Complexity of Branch-and-Bound</title><categories>math.OC cs.CC cs.DS math.CO</categories><comments>15 pages, 1 figure</comments><msc-class>9008, 52C07, 11H06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical branch-and-bound algorithm for the integer feasibility problem
has exponential worst case complexity.
  We prove that it is surprisingly efficient on reformulated problems, in which
the columns of the constraint matrix are short, and near orthogonal, i.e. a
reduced basis of the generated lattice; when the entries of A (the dense part
of the constraint matrix) are from {1, ..., M} for a large enough M,
branch-and-bound solves almost all reformulated instances at the rootnode. We
also prove an upper bound on the width of the reformulations along the last
unit vector.
  The analysis builds on the ideas of Furst and Kannan to bound the number of
integral matrices for which the shortest vectors of certain lattices are long,
and also uses a bound on the size of the branch-and-bound tree based on the
norms of the Gram-Schmidt vectors of the constraint matrix.
  We explore practical aspects of these results. First, we compute numerical
values of M which guarantee that 90, and 99 percent of the reformulated
problems solve at the root: these turn out to be surprisingly small when the
problem size is moderate. Second, we confirm with a computational study that
random integer programs become easier, as the coefficients grow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2640</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2640</id><created>2009-07-15</created><updated>2009-12-20</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Towards Hybrid Intensional Programming with JLucid, Objective Lucid, and
  General Imperative Compiler Framework in the GIPSY</title><categories>cs.PL cs.SE</categories><comments>222 pages, 82 figures, 2 tables, index, appendices; Master's thesis,
  October 2005. Also appears at http://clues.concordia.ca/record=b2222169~S0
  and at http://books.google.com/books?id=A2QvOzOxtC8C ; this revision fixes
  empty Nat42.tex example</comments><acm-class>D.3.3; D.3.2; D.3.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Pure Lucid programs are concurrent with very fine granularity. Sequential
Threads (STs) are functions introduced to enlarge the grain size; they are
passed from server to workers by Communication Procedures (CPs) in the General
Intensional Programming System (GIPSY). A JLucid program combines Java code for
the STs with Lucid code for parallel control. Thus first, in this thesis, we
describe the way in which the new JLucid compiler generates STs and CPs. JLucid
also introduces array support.
  Further exploration goes through the additional transformations that the
Lucid family of languages has undergone to enable the use of Java objects and
their members, in the Generic Intensional Programming Language (GIPL), and
Indexical Lucid: first, in the form of JLucid allowing the use of
pseudo-objects, and then through the specifically-designed the Objective Lucid
language. The syntax and semantic definitions of Objective Lucid and the
meaning of Java objects within an intensional program are provided with
discussions and examples.
  Finally, there are many useful scientific and utility routines written in
many imperative programming languages other than Java, for example in C, C++,
Fortran, Perl, etc. Therefore, it is wise to provide a framework to facilitate
inclusion of these languages into the GIPSY and their use by Lucid programs. A
General Imperative Compiler Framework and its concrete implementation is
proposed to address this issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2663</identifier>
 <datestamp>2011-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2663</id><created>2009-07-15</created><updated>2011-09-16</updated><authors><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author><author><keyname>Richerby</keyname><forenames>David</forenames></author></authors><title>The Complexity of Approximating Bounded-Degree Boolean \sharp CSP</title><categories>cs.CC cs.DM</categories><comments>22 pages. Full classification now applies to degree bounds of at
  least 6 (formerly at least 25) but no other significant changes from previous
  version (reduction in page count is just different typesetting)</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degree of a CSP instance is the maximum number of times that any variable
appears in the scopes of constraints. We consider the approximate counting
problem for Boolean CSP with bounded-degree instances, for constraint languages
containing the two unary constant relations {0} and {1}. When the maximum
allowed degree is large enough (at least 6) we obtain a complete classification
of the complexity of this problem. It is exactly solvable in polynomial-time if
every relation in the constraint language is affine. It is equivalent to the
problem of approximately counting independent sets in bipartite graphs if every
relation can be expressed as conjunctions of {0}, {1} and binary implication.
Otherwise, there is no FPRAS unless NP=RP. For lower degree bounds, additional
cases arise, where the complexity is related to the complexity of approximately
counting independent sets in hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2682</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2682</id><created>2009-07-15</created><authors><author><keyname>Kl&#xf8;ve</keyname><forenames>Torleiv</forenames></author><author><keyname>Lin</keyname><forenames>Te-Tsung</forenames></author><author><keyname>Tsai</keyname><forenames>Shi-Chun</forenames></author><author><keyname>Tzeng</keyname><forenames>Wen-Guey</forenames></author></authors><title>Permutation Arrays Under the Chebyshev Distance</title><categories>cs.IT math.IT</categories><comments>14 pages</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An (n,d) permutation array (PA) is a set of permutations of length n with the
property that the distance (under some metric) between any two permutations in
the array is at least d. They became popular recently for communication over
power lines. Motivated by an application to flash memories, in this paper the
metric used is the Chebyshev metric. A number of different constructions are
given as well as bounds on the size of such PA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2702</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2702</id><created>2009-07-15</created><updated>2010-11-06</updated><authors><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Interference Channels with Destination Cooperation</title><categories>cs.IT math.IT</categories><comments>revised based on reviewers' comments</comments><journal-ref>IEEE Trans. Inform. Theory 57 (2011) 187-209</journal-ref><doi>10.1109/TIT.2010.2090237</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is a fundamental feature of the wireless channel. To better
understand the role of cooperation in interference management, the two-user
Gaussian interference channel where the destination nodes can cooperate by
virtue of being able to both transmit and receive is studied. The sum-capacity
of this channel is characterized up to a constant number of bits. The coding
scheme employed builds up on the superposition scheme of Han and Kobayashi
(1981) for two-user interference channels without cooperation. New upperbounds
to the sum-capacity are also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2741</identifier>
 <datestamp>2009-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2741</id><created>2009-07-16</created><authors><author><keyname>Fung</keyname><forenames>Stanley P. Y.</forenames></author></authors><title>Bounded Delay Packet Scheduling in a Bounded Buffer</title><categories>cs.DS</categories><comments>5 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of buffer management in QoS-enabled network switches in
the bounded delay model where each packet is associated with a weight and a
deadline. We consider the more realistic situation where the network switch has
a finite buffer size. A 9.82-competitive algorithm is known for the case of
multiple buffers (Azar and Levy, SWAT'06). Recently, for the case of a single
buffer, a 3-competitive deterministic algorithm and a 2.618-competitive
randomized algorithm was known (Li, INFOCOM'09). In this paper we give a simple
deterministic 2-competitive algorithm for the case of a single buffer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2755</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2755</id><created>2009-07-16</created><updated>2010-11-23</updated><authors><author><keyname>Trahtman</keyname><forenames>A. N.</forenames></author><author><keyname>Bauer</keyname><forenames>T.</forenames></author><author><keyname>Cohen</keyname><forenames>N.</forenames></author></authors><title>The Visualization of the Road Coloring Algorithm in the package TESTAS</title><categories>cs.DM cs.FL</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A synchronizing word of a deterministic automaton is a word in the alphabet
of colors of its edges that maps the automaton to a single state. A coloring of
edges of a directed graph is synchronizing if the coloring turns the graph into
a deterministic finite automaton possessing a synchronizing word.
  The road coloring problem is the problem of synchronizing coloring of a
directed finite strongly connected graph with constant outdegree of all its
vertices if the greatest common divisor of the lengths of all its cycles is
one. A polynomial time algorithm of the road coloring has been based on recent
positive solution of this old famous problem.
  One can use our new visualization program for demonstration of the algorithm
as well as for visualization of the transition graph of any finite automaton.
The visual image presents some structure properties of the transition graph.
This help tool is linear in the size of the automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2759</identifier>
 <datestamp>2009-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2759</id><created>2009-07-16</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Bruckstein</keyname><forenames>Alfred</forenames></author></authors><title>On Cyclic and Nearly Cyclic Multiagent Interactions in the Plane</title><categories>cs.MA cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss certain types of cyclic and nearly cyclic interactions among N
&quot;point&quot;-agents in the plane, leading to formations of interesting limiting
geometric configurations. Cyclic pursuit and local averaging interactions have
been analyzed in the context of multi-agent gathering. In this paper, we
consider some nearly cyclic interactions that break symmetry leading to factor
circulants rather than circulant interaction matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2775</identifier>
 <datestamp>2009-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2775</id><created>2009-07-16</created><authors><author><keyname>Le</keyname><forenames>Dai Tri Man</forenames></author></authors><title>Modelling Concurrent Behaviors in the Process Specification Language</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a first-order ontology for generalized stratified
order structure. We then classify the models of the theory using
model-theoretic techniques. An ontology mapping from this ontology to the core
theory of Process Specification Language is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2850</identifier>
 <datestamp>2011-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2850</id><created>2009-07-16</created><updated>2011-01-07</updated><authors><author><keyname>Buergisser</keyname><forenames>Peter</forenames></author><author><keyname>Landsberg</keyname><forenames>J. M.</forenames></author><author><keyname>Manivel</keyname><forenames>Laurent</forenames></author><author><keyname>Weyman</keyname><forenames>Jerzy</forenames></author></authors><title>An overview of mathematical issues arising in the Geometric complexity
  theory approach to VP v.s. VNP</title><categories>cs.CC math.AG math.RT</categories><comments>29 pages, v2: role of symmetric Kronecker coefficients explained</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the geometry of orbit closures and the asymptotic behavior of
Kronecker coefficients in the context of the Geometric Complexity Theory
program to prove a variant of Valiant's algebraic analog of the P not equal to
NP conjecture. We also describe the precise separation of complexity classes
that their program proposes to demonstrate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2859</identifier>
 <datestamp>2009-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2859</id><created>2009-07-16</created><authors><author><keyname>Tu</keyname><forenames>Sheng-Yuan</forenames></author><author><keyname>Chen</keyname><forenames>Kwang-Cheng</forenames></author></authors><title>General Spectrum Sensing in Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>26 pages, 7 figures, 47 references, submitted to IEEE Trans. on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The successful operation of cognitive radio (CR) between CR transmitter and
CR receiver (CR link) relies on reliable spectrum sensing. To network CRs
requires spectrum sensing at CR transmitter and further information regarding
the spectrum availability at CR receiver. Redefining the spectrum sensing along
with statistical inference suitable for cognitive radio networks (CRN), we
mathematically derive conditions to allow CR transmitter forwarding packets to
CR receiver under guaranteed outage probability, and prove that the correlation
of localized spectrum availability between a cooperative node and CR receiver
determines effectiveness of the cooperative scheme. Applying our novel
mathematical model to potential hidden terminals in CRN, we illustrate that the
allowable transmission region of a CR, defined as neighborhood, is no longer
circular shape even in a pure path loss channel model. This results in
asymmetric CR links to make bidirectional links generally inappropriate in CRN,
though this challenge can be alleviated by cooperative sensing. Therefore,
spectrum sensing capability determines CRN topology. For multiple cooperative
nodes, to fully utilize spectrum availability, the selection methodology of
cooperative nodes is developed due to limited overhead of information exchange.
Defining reliability as information of spectrum availability at CR receiver
provided by a cooperative node and by applying neighborhood area, we can
compare sensing capability of cooperative nodes from both link and network
perspectives. In addition, due to lack of centralized coordination in dynamic
CRN, CRs can only acquire local and partial information within limited sensing
duration, robust spectrum sensing is therefore proposed. Limits of cooperative
schemes and their impacts on network operation are also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2868</identifier>
 <datestamp>2009-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2868</id><created>2009-07-16</created><authors><author><keyname>Bernecker</keyname><forenames>Thomas</forenames></author><author><keyname>Kriegel</keyname><forenames>Hans-Peter</forenames></author><author><keyname>Mamoulis</keyname><forenames>Nikos</forenames></author><author><keyname>Renz</keyname><forenames>Matthias</forenames></author><author><keyname>Zuefle</keyname><forenames>Andreas</forenames></author></authors><title>Scalable Probabilistic Similarity Ranking in Uncertain Databases
  (Technical Report)</title><categories>cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a scalable approach for probabilistic top-k similarity
ranking on uncertain vector data. Each uncertain object is represented by a set
of vector instances that are assumed to be mutually-exclusive. The objective is
to rank the uncertain data according to their distance to a reference object.
We propose a framework that incrementally computes for each object instance and
ranking position, the probability of the object falling at that ranking
position. The resulting rank probability distribution can serve as input for
several state-of-the-art probabilistic ranking models. Existing approaches
compute this probability distribution by applying a dynamic programming
approach of quadratic complexity. In this paper we theoretically as well as
experimentally show that our framework reduces this to a linear-time complexity
while having the same memory requirements, facilitated by incremental accessing
of the uncertain vector instances in increasing order of their distance to the
reference object. Furthermore, we show how the output of our method can be used
to apply probabilistic top-k ranking for the objects, according to different
state-of-the-art definitions. We conduct an experimental evaluation on
synthetic and real data, which demonstrates the efficiency of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2896</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2896</id><created>2009-07-16</created><updated>2010-01-06</updated><authors><author><keyname>Sta&#x144;czak</keyname><forenames>S&#x142;awomir</forenames></author><author><keyname>Kaliszan</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Bambos</keyname><forenames>Nicholas</forenames></author></authors><title>Decentralized Admission Control for Power-Controlled Wireless Links</title><categories>cs.IT math.IT</categories><comments>Section IV extended, Section V shortened; some corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of admission control/channel access in
power-controlled decentralized wireless networks, in which the
quality-of-service (QoS) is expressed in terms of the signal-to-interference
ratio (SIR). We analyze a previously proposed admission control algorithm,
which was designed to maintain the SIR of operational (active) links above some
given threshold at all times (protection of active links). This protection
property ensures that as new users attempt to join the network, the already
established links sustain their quality. The considered scheme may be thus
applicable in some cognitive radio networks, where the fundamental premise is
that secondary users may be granted channel access only if it does not cause
disturbance to primary users.
  The admission control algorithm was previously analyzed under the assumption
of affine interference functions. This paper extends all the previous results
to arbitrary standard interference functions, which capture many important
receiver designs, including optimal linear reception in the sense of maximizing
the SIR and the worst-case receiver design. Furthermore, we provide novel
conditions for protection of active users under the considered control scheme
when individual power constraints are imposed on each link. Finally, we
consider the possibility of a joint optimization of transmitters and receivers
in networks with linear transceivers, which includes linear beamforming in
multiple antenna systems. Transmitter optimization is performed alternately
with receiver optimization to generate non-decreasing sequences of SIRs.
Numerical evaluations show that additional transmitter side optimization has
potential for significant performance gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2914</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2914</id><created>2009-07-16</created><authors><author><keyname>Cyburt</keyname><forenames>Richard H.</forenames></author><author><keyname>Austin</keyname><forenames>Sam M.</forenames></author><author><keyname>Beers</keyname><forenames>Timothy C.</forenames></author><author><keyname>Estrade</keyname><forenames>Alfredo</forenames></author><author><keyname>Ferguson</keyname><forenames>Ryan M.</forenames></author><author><keyname>Sakharuk</keyname><forenames>A.</forenames></author><author><keyname>Smith</keyname><forenames>Karl</forenames></author><author><keyname>Warren</keyname><forenames>Scott</forenames></author></authors><title>Managing Information for Sparsely Distributed Articles and Readers: The
  Virtual Journals of the Joint Institute for Nuclear Astrophysics (JINA)</title><categories>astro-ph.IM astro-ph.GA astro-ph.SR cs.DL nucl-ex nucl-th</categories><comments>submitted, 9 pages, 5 figures, 1 table.
  http://groups.nscl.msu.edu/jina/journals</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research area of nuclear astrophysics is characterized by a need for
information published in tens of journals in several fields and an extremely
dilute distribution of researchers. For these reasons it is difficult for
researchers, especially students, to be adequately informed of the relevant
published research. For example, the commonly employed journal club is
inefficient for a group consisting of a professor and his two students. In an
attempt to address this problem, we have developed a virtual journal (VJ), a
process for collecting and distributing a weekly compendium of articles of
interest to researchers in nuclear astrophysics. Subscribers are notified of
each VJ issue using an email-list server or an RSS feed. The VJ data base is
searchable by topics assigned by the editors, or by keywords. There are two
related VJs: the Virtual Journal of Nuclear Astrophysics (JINA VJ), and the
SEGUE Virtual Journal (SEGUE VJ). The JINA VJ also serves as a source of new
experimental and theoretical information for the JINA REACLIB reaction rate
database. References to review articles and popular level articles provide an
introduction to the literature for students. The VJs and support information
are available at http://groups.nscl.msu.edu/jina/journals
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2929</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2929</id><created>2009-07-16</created><authors><author><keyname>Gobjuka</keyname><forenames>Hassan</forenames></author></authors><title>4G Wireless Networks: Opportunities and Challenges</title><categories>cs.NI</categories><report-no>VZ-TR-G1005309</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the major wireless service providers planning to start deployment of 4G
wireless networks by mid 2010, research and industry communities are racing
against time to find solutions for some of the prominent still open issues in
4G networks. The growing interest in 4G networks is driven by the set of new
services will be made available for the first time such as accessing the
Internet anytime from anywhere, global roaming, and wider support for
multimedia applications. In this paper describe some of the key opportunities
will be made available by 4G networks, present key challenges and point to some
proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2949</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2949</id><created>2009-07-16</created><updated>2009-07-28</updated><authors><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Olshevsky</keyname><forenames>Alex</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Distributed anonymous function computation in information fusion and
  multiagent systems</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model for deterministic distributed function computation by a
network of identical and anonymous nodes, with bounded computation and storage
capabilities that do not scale with the network size. Our goal is to
characterize the class of functions that can be computed within this model. In
our main result, we exhibit a class of non-computable functions, and prove that
every function outside this class can at least be approximated. The problem of
computing averages in a distributed manner plays a central role in our
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2951</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2951</id><created>2009-07-16</created><authors><author><keyname>Buragohain</keyname><forenames>Chiranjeeb</forenames></author><author><keyname>Foschini</keyname><forenames>Luca</forenames></author><author><keyname>Suri</keyname><forenames>Subhash</forenames></author></authors><title>Untangling the Braid: Finding Outliers in a Set of Streams</title><categories>cs.DB cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monitoring the performance of large shared computing systems such as the
cloud computing infrastructure raises many challenging algorithmic problems.
One common problem is to track users with the largest deviation from the norm
(outliers), for some measure of performance. Taking a stream-computing
perspective, we can think of each user's performance profile as a stream of
numbers (such as response times), and the aggregate performance profile of the
shared infrastructure as a &quot;braid&quot; of these intermixed streams. The monitoring
system's goal then is to untangle this braid sufficiently to track the top k
outliers. This paper investigates the space complexity of one-pass algorithms
for approximating outliers of this kind, proves lower bounds using multi-party
communication complexity, and proposes small-memory heuristic algorithms. On
one hand, stream outliers are easily tracked for simple measures, such as max
or min, but our theoretical results rule out even good approximations for most
of the natural measures such as average, median, or the quantiles. On the other
hand, we show through simulation that our proposed heuristics perform quite
well for a variety of synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2955</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2955</id><created>2009-07-16</created><authors><author><keyname>Herman</keyname><forenames>Matthew A.</forenames></author><author><keyname>Strohmer</keyname><forenames>Thomas</forenames></author></authors><title>General Deviants: An Analysis of Perturbations in Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>11 pages, 1 figure, preprint</comments><doi>10.1109/JSTSP.2009.2039170</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the Basis Pursuit recovery of signals with general perturbations.
Previous studies have only considered partially perturbed observations Ax + e.
Here, x is a signal which we wish to recover, A is a full-rank matrix with more
columns than rows, and e is simple additive noise. Our model also incorporates
perturbations E to the matrix A which result in multiplicative noise. This
completely perturbed framework extends the prior work of Candes, Romberg and
Tao on stable signal recovery from incomplete and inaccurate measurements. Our
results show that, under suitable conditions, the stability of the recovered
signal is limited by the noise level in the observation. Moreover, this
accuracy is within a constant multiple of the best-case reconstruction using
the technique of least squares. In the absence of additive noise numerical
simulations essentially confirm that this error is a linear function of the
relative perturbation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2974</identifier>
 <datestamp>2015-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2974</id><created>2009-07-16</created><updated>2015-12-28</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Rostami</keyname><forenames>Shahriar</forenames></author><author><keyname>Ali</keyname><forenames>Hammad</forenames></author><author><keyname>Chen</keyname><forenames>Min</forenames></author><author><keyname>Yan</keyname><forenames>Yuhong</forenames></author></authors><title>Service-Oriented Architectures and Web Services: Course Tutorial and Lab
  Notes</title><categories>cs.DC cs.SE</categories><comments>v19 (Winter 2015): 55 pages; TOC; index; course lab/tutorial notes
  (SOEN487); NOTE: a source of these notes is also maintained on SourceForge</comments><msc-class>68N15, 68U35</msc-class><acm-class>H.3.5; C.2.4; D.1.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This document presents a number of quick-step instructions to get started on
writing mini-service-oriented web services-based applications using OpenESB
2.31, Tomcat 6, GlassFish 2.x/3.0.1 with BPEL support, and Java 1.6+ primarily
in Scientific Linux 6.6 with user quota restrictions. While the tutorial notes
are oriented towards the students taking the SOEN487 on service-oriented
architectures (SOA) at Computer Science and Software Engineering (CSE)
Department, Faculty of Engineering and Computer Science (ENCS), other may find
some of it useful as well outside of CSE or Concordia. The notes are compiled
mostly based on the students' needs and feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2984</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2984</id><created>2009-07-17</created><updated>2011-06-09</updated><authors><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>Luo</keyname><forenames>Jie</forenames></author></authors><title>Fountain Communication using Concatenated Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends linear-complexity concatenated coding schemes to fountain
communication over the discrete-time memoryless channel. Achievable fountain
error exponents for one-level and multi-level concatenated fountain codes are
derived. It is also shown that concatenated coding schemes possess interesting
properties in several multi-user fountain communication scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2990</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2990</id><created>2009-07-17</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>The Single Machine Total Weighted Tardiness Problem - Is it (for
  Metaheuristics) a Solved Problem ?</title><categories>cs.AI</categories><journal-ref>Proceedings of the 8th Metaheuristics International Conference MIC
  2009, July 13-16, Hamburg, Germany, pp. 141.1-141.10</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents a study of rather simple local search heuristics for the
single machine total weighted tardiness problem (SMTWTP), namely hillclimbing
and Variable Neighborhood Search. In particular, we revisit these approaches
for the SMTWTP as there appears to be a lack of appropriate/challenging
benchmark instances in this case. The obtained results are impressive indeed.
Only few instances remain unsolved, and even those are approximated within 1%
of the optimal/best known solutions. Our experiments support the claim that
metaheuristics for the SMTWTP are very likely to lead to good results, and
that, before refining search strategies, more work must be done with regard to
the proposition of benchmark data. Some recommendations for the construction of
such data sets are derived from our investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.2993</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.2993</id><created>2009-07-17</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>Improvements for multi-objective flow shop scheduling by Pareto Iterated
  Local Search</title><categories>cs.AI</categories><journal-ref>Proceedings of the 8th Metaheuristics International Conference MIC
  2009, July 13-16, 2009, Hamburg, Germany, pp 195.1-195.10</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article describes the proposition and application of a local search
metaheuristic for multi-objective optimization problems. It is based on two
main principles of heuristic search, intensification through variable
neighborhoods, and diversification through perturbations and successive
iterations in favorable regions of the search space. The concept is
successfully tested on permutation flow shop scheduling problems under multiple
objectives and compared to other local search approaches. While the obtained
results are encouraging in terms of their quality, another positive attribute
of the approach is its simplicity as it does require the setting of only very
few parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3005</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3005</id><created>2009-07-17</created><authors><author><keyname>D'Alessandro</keyname><forenames>Flavio</forenames></author><author><keyname>Intrigila</keyname><forenames>Benedetto</forenames></author><author><keyname>Varricchio</keyname><forenames>Stefano</forenames></author></authors><title>On some counting problems for semi-linear sets</title><categories>cs.DM cs.FL</categories><comments>34 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $X$ be a subset of $\N^t$ or $\Z^t$. We can associate with $X$ a function
${\cal G}_X:\N^t\longrightarrow\N$ which returns, for every $(n_1, ..., n_t)\in
\N^t$, the number ${\cal G}_X(n_1, ..., n_t)$ of all vectors $x\in X$ such
that, for every $i=1,..., t, |x_{i}| \leq n_{i}$. This function is called the
{\em growth function} of $X$. The main result of this paper is that the growth
function of a semi-linear set of $\N^t$ or $\Z^t$ is a box spline. By using
this result and some theorems on semi-linear sets, we give a new proof of
combinatorial flavour of a well-known theorem by Dahmen and Micchelli on the
counting function of a system of Diophantine linear equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3016</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3016</id><created>2009-07-17</created><authors><author><keyname>Rafiey</keyname><forenames>Arash</forenames></author><author><keyname>Hell</keyname><forenames>Pavol</forenames></author></authors><title>Duality for Min-Max Orderings and Dichotomy for Min Cost Homomorphisms</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Min-Max orderings correspond to conservative lattice polymorphisms. Digraphs
with Min-Max orderings have polynomial time solvable minimum cost homomorphism
problems. They can also be viewed as digraph analogues of proper interval
graphs and bigraphs.
  We give a forbidden structure characterization of digraphs with a Min-Max
ordering which implies a polynomial time recognition algorithm. We also
similarly characterize digraphs with an extended Min-Max ordering, and we apply
this characterization to prove a conjectured form of dichotomy for minimum cost
homomorphism problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3019</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3019</id><created>2009-07-17</created><authors><author><keyname>Fisman</keyname><forenames>Dana</forenames></author><author><keyname>Kupferman</keyname><forenames>Orna</forenames></author><author><keyname>Lustig</keyname><forenames>Yoad</forenames></author></authors><title>Rational Synthesis</title><categories>cs.LO cs.GT</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthesis is the automated construction of a system from its specification.
The system has to satisfy its specification in all possible environments.
Modern systems often interact with other systems, or agents. Many times these
agents have objectives of their own, other than to fail the system. Thus, it
makes sense to model system environments not as hostile, but as composed of
rational agents; i.e., agents that act to achieve their own objectives. We
introduce the problem of synthesis in the context of rational agents (rational
synthesis, for short). The input consists of a temporal-logic formula
specifying the system and temporal-logic formulas specifying the objectives of
the agents. The output is an implementation T of the system and a profile of
strategies, suggesting a behavior for each of the agents. The output should
satisfy two conditions. First, the composition of T with the strategy profile
should satisfy the specification. Second, the strategy profile should be an
equilibria in the sense that, in view of their objectives, agents have no
incentive to deviate from the strategies assigned to them. We solve the
rational-synthesis problem for various definitions of equilibria studied in
game theory. We also consider the multi-valued case in which the objectives of
the system and the agents are still temporal logic formulas, but involve
payoffs from a finite lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3045</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3045</id><created>2009-07-17</created><authors><author><keyname>Lahmadi</keyname><forenames>Abdelkader</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Festor</keyname><forenames>Olivier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>SecSip: A Stateful Firewall for SIP-based Networks</title><categories>cs.CR cs.NI</categories><proxy>ccsd inria-00404853</proxy><journal-ref>11th IFIP/IEEE International Symposium on Integrated Network
  Management (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SIP-based networks are becoming the de-facto standard for voice, video and
instant messaging services. Being exposed to many threats while playing an
major role in the operation of essential services, the need for dedicated
security management approaches is rapidly increasing. In this paper we present
an original security management approach based on a specific vulnerability
aware SIP stateful firewall. Through known attack descriptions, we illustrate
the power of the configuration language of the firewall which uses the
capability to specify stateful objects that track data from multiple SIP
elements within their lifetime. We demonstrate through measurements on a real
implementation of the firewall its efficiency and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3047</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3047</id><created>2009-07-17</created><authors><author><keyname>Lahmadi</keyname><forenames>Abdelkader</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Andrey</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Festor</keyname><forenames>Olivier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Performance of Network and Service Monitoring Frameworks</title><categories>cs.PF</categories><proxy>ccsd inria-00404856</proxy><journal-ref>11th IFIP/IEEE International Symposium on Integrated Network
  Management (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficiency and the performance of anagement systems is becoming a hot
research topic within the networks and services management community. This
concern is due to the new challenges of large scale managed systems, where the
management plane is integrated within the functional plane and where management
activities have to carry accurate and up-to-date information. We defined a set
of primary and secondary metrics to measure the performance of a management
approach. Secondary metrics are derived from the primary ones and quantifies
mainly the efficiency, the scalability and the impact of management activities.
To validate our proposals, we have designed and developed a benchmarking
platform dedicated to the measurement of the performance of a JMX manager-agent
based management system. The second part of our work deals with the collection
of measurement data sets from our JMX benchmarking platform. We mainly studied
the effect of both load and the number of agents on the scalability, the impact
of management activities on the user perceived performance of a managed server
and the delays of JMX operations when carrying variables values. Our findings
show that most of these delays follow a Weibull statistical distribution. We
used this statistical model to study the behavior of a monitoring algorithm
proposed in the literature, under heavy tail delays distribution. In this case,
the view of the managed system on the manager side becomes noisy and out of
date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3068</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3068</id><created>2009-07-17</created><authors><author><keyname>Christodoulou</keyname><forenames>George</forenames></author><author><keyname>Kovacs</keyname><forenames>Annamaria</forenames></author></authors><title>A deterministic truthful PTAS for scheduling related machines</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheduling on related machines ($Q||C_{\max}$) is one of the most important
problems in the field of Algorithmic Mechanism Design. Each machine is
controlled by a selfish agent and her valuation can be expressed via a single
parameter, her {\em speed}. In contrast to other similar problems, Archer and
Tardos \cite{AT01} showed that an algorithm that minimizes the makespan can be
truthfully implemented, although in exponential time. On the other hand, if we
leave out the game-theoretic issues, the complexity of the problem has been
completely settled -- the problem is strongly NP-hard, while there exists a
PTAS \cite{HS88,ES04}.
  This problem is the most well studied in single-parameter algorithmic
mechanism design. It gives an excellent ground to explore the boundary between
truthfulness and efficient computation. Since the work of Archer and Tardos,
quite a lot of deterministic and randomized mechanisms have been suggested.
Recently, a breakthrough result \cite{DDDR08} showed that a randomized truthful
PTAS exists. On the other hand, for the deterministic case, the best known
approximation factor is 2.8 \cite{Kov05,Kov07}.
  It has been a major open question whether there exists a deterministic
truthful PTAS, or whether truthfulness has an essential, negative impact on the
computational complexity of the problem. In this paper we give a definitive
answer to this important question by providing a truthful {\em deterministic}
PTAS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3076</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3076</id><created>2009-07-17</created><authors><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author><author><keyname>Tazari</keyname><forenames>Siamak</forenames></author></authors><title>On Brambles, Grid-Like Minors, and Parameterized Intractability of
  Monadic Second-Order Logic</title><categories>cs.DM cs.DS cs.LO</categories><acm-class>G.2.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brambles were introduced as the dual notion to treewidth, one of the most
central concepts of the graph minor theory of Robertson and Seymour. Recently,
Grohe and Marx showed that there are graphs G, in which every bramble of order
larger than the square root of the treewidth is of exponential size in |G|. On
the positive side, they show the existence of polynomial-sized brambles of the
order of the square root of the treewidth, up to log factors. We provide the
first polynomial time algorithm to construct a bramble in general graphs and
achieve this bound, up to log-factors. We use this algorithm to construct
grid-like minors, a replacement structure for grid-minors recently introduced
by Reed and Wood, in polynomial time. Using the grid-like minors, we introduce
the notion of a perfect bramble and an algorithm to find one in polynomial
time. Perfect brambles are brambles with a particularly simple structure and
they also provide us with a subgraph that has bounded degree and still large
treewidth; we use them to obtain a meta-theorem on deciding certain
parameterized subgraph-closed problems on general graphs in time singly
exponential in the parameter.
  The second part of our work deals with providing a lower bound to Courcelle's
famous theorem, stating that every graph property that can be expressed by a
sentence in monadic second-order logic (MSO), can be decided by a linear time
algorithm on classes of graphs of bounded treewidth. Using our results from the
first part of our work we establish a strong lower bound for tractability of
MSO on classes of colored graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3085</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3085</id><created>2009-07-17</created><updated>2009-07-27</updated><authors><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author><author><keyname>Morzenti</keyname><forenames>Angelo</forenames></author><author><keyname>Pietro</keyname><forenames>Pierluigi San</forenames></author></authors><title>A Metric Encoding for Bounded Model Checking (extended version)</title><categories>cs.LO cs.SE</categories><doi>10.1007/978-3-642-05089-3_47</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bounded Model Checking both the system model and the checked property are
translated into a Boolean formula to be analyzed by a SAT-solver. We introduce
a new encoding technique which is particularly optimized for managing
quantitative future and past metric temporal operators, typically found in
properties of hard real time systems. The encoding is simple and intuitive in
principle, but it is made more complex by the presence, typical of the Bounded
Model Checking technique, of backward and forward loops used to represent an
ultimately periodic infinite domain by a finite structure. We report and
comment on the new encoding technique and on an extensive set of experiments
carried out to assess its feasibility and effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3095</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3095</id><created>2009-07-17</created><authors><author><keyname>Ahmat</keyname><forenames>Kamal</forenames></author></authors><title>Ethernet Topology Discovery: A Survey</title><categories>cs.NI</categories><report-no>TR-20091966</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ethernet networks have undergone impressive growth since the past few
decades. This growth can be appreciated in terms of the equipment, such as
switches and links, that have been added, as well as in the number of users
that it supports. In parallel to this expansion, over the past decade the
networking research community has shown a growing interest in discovering and
analyzing the Ethernet topology. Research in this area has concentrated on the
theoretical analysis of Ethernet topology as well as developing tools and
methods for mapping the network layout. These efforts have brought us to a
crucial juncture for Ethernet topology measurement infrastructures: while,
previously, these were both small (in terms of number of measurement points),
we are starting to see the deployment of large-scale distributed systems
composed of hundreds or thousands of monitors. As we look forward to this next
generation of systems, we take stock of what has been achieved so far. In this
survey, we discuss past and current mechanisms for discovering the Ethernet
topology from theoretical and practical prospective. In addition to discovery
techniques, we provide insights into some of the well known open issues related
to Ethernet topology discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3099</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3099</id><created>2009-07-17</created><authors><author><keyname>Ahmat</keyname><forenames>Kamal</forenames></author></authors><title>Graph Theory and Optimization Problems for Very Large Networks</title><categories>cs.NI cs.AI</categories><report-no>TR-20091970</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph theory provides a primary tool for analyzing and designing computer
communication networks. In the past few decades, Graph theory has been used to
study various types of networks, including the Internet, wide Area Networks,
Local Area Networks, and networking protocols such as border Gateway Protocol,
Open shortest Path Protocol, and Networking Networks. In this paper, we present
some key graph theory concepts used to represent different types of networks.
Then we describe how networks are modeled to investigate problems related to
network protocols. Finally, we present some of the tools used to generate graph
for representing practical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3117</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3117</id><created>2009-07-17</created><authors><author><keyname>Bournez</keyname><forenames>Olivier</forenames></author><author><keyname>Campagnolo</keyname><forenames>Manuel</forenames></author></authors><title>A Survey on Continuous Time Computations</title><categories>cs.CC</categories><journal-ref>New Computational Paradigms. Changing Conceptions of What is
  Computable. (Cooper, S.B. and L{\&quot;o}we, B. and Sorbi, A., Eds.). New York,
  Springer-Verlag, pages 383-423. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an overview of theories of continuous time computation. These
theories allow us to understand both the hardness of questions related to
continuous time dynamical systems and the computational power of continuous
time analog models. We survey the existing models, summarizing results, and
point to relevant references in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3118</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3118</id><created>2009-07-17</created><authors><author><keyname>Bournez</keyname><forenames>Olivier</forenames></author><author><keyname>Chassaing</keyname><forenames>Philippe</forenames></author><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author><author><keyname>Gerin</keyname><forenames>Lucas</forenames></author><author><keyname>Koegler</keyname><forenames>Xavier</forenames></author></authors><title>On the Convergence of Population Protocols When Population Goes to
  Infinity</title><categories>cs.DC</categories><comments>Submitted to Applied Mathematics and Computation. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Population protocols have been introduced as a model of sensor networks
consisting of very limited mobile agents with no control over their own
movement. A population protocol corresponds to a collection of anonymous
agents, modeled by finite automata, that interact with one another to carry out
computations, by updating their states, using some rules. Their computational
power has been investigated under several hypotheses but always when restricted
to finite size populations. In particular, predicates stably computable in the
original model have been characterized as those definable in Presburger
arithmetic. We study mathematically the convergence of population protocols
when the size of the population goes to infinity. We do so by giving general
results, that we illustrate through the example of a particular population
protocol for which we even obtain an asymptotic development. This example shows
in particular that these protocols seem to have a rather different
computational power when a huge population hypothesis is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3123</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3123</id><created>2009-07-17</created><authors><author><keyname>Beffara</keyname><forenames>Emmanuel</forenames></author><author><keyname>Bournez</keyname><forenames>Olivier</forenames></author><author><keyname>Kacem</keyname><forenames>Hassen</forenames></author><author><keyname>Kirchner</keyname><forenames>Claude</forenames></author></authors><title>Verification of Timed Automata Using Rewrite Rules and Strategies</title><categories>cs.LO</categories><comments>In the Proceedings BISFAI 2001, Seventh Biennial Bar-Ilan
  International Symposium on the Foundations of Artificial Intelligence.
  Ramat-Gan, 2001</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ELAN is a powerful language and environment for specifying and prototyping
deduction systems in a language based on rewrite rules controlled by
strategies. Timed automata is a class of continuous real-time models of
reactive systems for which efficient model-checking algorithms have been
devised. In this paper, we show that these algorithms can very easily be
prototyped in the ELAN system. This paper argues through this example that
rewriting based systems relying on rules and strategies are a good framework to
prototype, study and test rather efficiently symbolic model-checking
algorithms, i.e. algorithms which involve combination of graph exploration
rules, deduction rules, constraint solving techniques and decision procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3126</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3126</id><created>2009-07-17</created><authors><author><keyname>Bournez</keyname><forenames>Olivier</forenames></author><author><keyname>Chalopin</keyname><forenames>Jeremie</forenames></author><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author><author><keyname>Koegler</keyname><forenames>Xavier</forenames></author></authors><title>Population Protocols that Correspond to Symmetric Games</title><categories>cs.GT cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Population protocols have been introduced by Angluin et {al.} as a model of
networks consisting of very limited mobile agents that interact in pairs but
with no control over their own movement. A collection of anonymous agents,
modeled by finite automata, interact pairwise according to some rules that
update their states. The model has been considered as a computational model in
several papers. Input values are initially distributed among the agents, and
the agents must eventually converge to the the correct output. Predicates on
the initial configurations that can be computed by such protocols have been
characterized under various hypotheses. In an orthogonal way, several
distributed systems have been termed in literature as being realizations of
games in the sense of game theory. In this paper, we investigate under which
conditions population protocols, or more generally pairwise interaction rules,
can be considered as the result of a symmetric game. We prove that not all
rules can be considered as symmetric games.% We prove that some basic protocols
can be realized using symmetric games. As a side effect of our study, we also
prove that any population protocol can be simulated by a symmetric one (but not
necessarily a game).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3135</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3135</id><created>2009-07-17</created><updated>2010-09-07</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author></authors><title>Fast Searching in Packed Strings</title><categories>cs.DS</categories><comments>To appear in Journal of Discrete Algorithms. Special Issue on CPM
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given strings $P$ and $Q$ the (exact) string matching problem is to find all
positions of substrings in $Q$ matching $P$. The classical Knuth-Morris-Pratt
algorithm [SIAM J. Comput., 1977] solves the string matching problem in linear
time which is optimal if we can only read one character at the time. However,
most strings are stored in a computer in a packed representation with several
characters in a single word, giving us the opportunity to read multiple
characters simultaneously. In this paper we study the worst-case complexity of
string matching on strings given in packed representation. Let $m \leq n$ be
the lengths $P$ and $Q$, respectively, and let $\sigma$ denote the size of the
alphabet. On a standard unit-cost word-RAM with logarithmic word size we
present an algorithm using time $$ O\left(\frac{n}{\log_\sigma n} + m +
\occ\right). $$ Here $\occ$ is the number of occurrences of $P$ in $Q$. For $m
= o(n)$ this improves the $O(n)$ bound of the Knuth-Morris-Pratt algorithm.
Furthermore, if $m = O(n/\log_\sigma n)$ our algorithm is optimal since any
algorithm must spend at least $\Omega(\frac{(n+m)\log
  \sigma}{\log n} + \occ) = \Omega(\frac{n}{\log_\sigma n} + \occ)$ time to
read the input and report all occurrences. The result is obtained by a novel
automaton construction based on the Knuth-Morris-Pratt algorithm combined with
a new compact representation of subautomata allowing an optimal
tabulation-based simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3154</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3154</id><created>2009-07-17</created><authors><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>COMMENTARY ON: Citing and Reading Behavours in High-Energy Physics
  (arXiv:0906.5418)</title><categories>cs.DL</categories><comments>2 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Evidence confirming that OA increases impact will not be sufficient to induce
enough researchers to provide OA; only mandates from their institutions and
funders can ensure that. HEP researchers continue to submit their papers to
peer-reviewed journals, as they always did, depositing both their unrefereed
preprints and their refereed postprints. None of that has changed. In fields
like HEP and astrophysics, the journal affordability/accessibility problem is
not as great as in many other fields, where it the HEP Early Access impact
advantage translates into the OA impact advantage itself. Almost no one has
ever argued that Gold OA provides a greater OA advantage than Green OA. The OA
advantage is the OA advantage, whether Green or Gold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3177</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3177</id><created>2009-07-17</created><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Arroyo</keyname><forenames>David</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author></authors><title>Breaking a Chaotic Cryptographic Scheme Based on Composition Maps</title><categories>cs.CR</categories><comments>9 pages, 7 figures</comments><doi>10.1142/S0218127410027192</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a chaotic cryptographic scheme based on composition maps was
proposed. This paper studies the security of the scheme and reports the
following findings: 1) the scheme can be broken by a differential attack with
$6+\lceil\log_L(MN)\rceil$ chosen-plaintext, where $MN$ is the size of
plaintext and $L$ is the number of different elements in plain-text; 2) the
scheme is not sensitive to the changes of plaintext; 3) the two composition
maps do not work well as a secure and efficient random number source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3183</identifier>
 <datestamp>2011-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3183</id><created>2009-07-18</created><updated>2011-10-22</updated><authors><author><keyname>Borisov</keyname><forenames>Nedyalko</forenames></author><author><keyname>Babu</keyname><forenames>Shivnath</forenames></author><author><keyname>Uttamchandani</keyname><forenames>Sandeep</forenames></author><author><keyname>Routray</keyname><forenames>Ramani</forenames></author><author><keyname>Singh</keyname><forenames>Aameek</forenames></author></authors><title>Why Did My Query Slow Down?</title><categories>cs.DB</categories><comments>A conference version of this work was published as: Why Did My Query
  Slow Down, By Nedyalko Borisov, Sandeep Uttamchandani, Ramani Routray, and
  Aameek Singh, In the Proc. of the 4th Biennial Conference on Innovative Data
  Systems Research, Asilomar, CA, USA, Jan 4-7, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many enterprise environments have databases running on network-attached
server-storage infrastructure (referred to as Storage Area Networks or SANs).
Both the database and the SAN are complex systems that need their own separate
administrative teams. This paper puts forth the vision of an innovative
management framework to simplify administrative tasks that require an in-depth
understanding of both the database and the SAN. As a concrete instance, we
consider the task of diagnosing the slowdown in performance of a database query
that is executed multiple times (e.g., in a periodic report-generation
setting). This task is very challenging because the space of possible causes
includes problems specific to the database, problems specific to the SAN, and
problems that arise due to interactions between the two systems. In addition,
the monitoring data available from these systems can be noisy.
  We describe the design of DIADS which is an integrated diagnosis tool for
database and SAN administrators. DIADS generates and uses a powerful
abstraction called Annotated Plan Graphs (APGs) that ties together the
execution path of queries in the database and the SAN. Using an innovative
workflow that combines domain-specific knowledge with machine-learning
techniques, DIADS was applied successfully to diagnose query slowdowns caused
by complex combinations of events across a PostgreSQL database and a production
SAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3200</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3200</id><created>2009-07-18</created><authors><author><keyname>Yoon</keyname><forenames>Yourim</forenames></author><author><keyname>Kim</keyname><forenames>Yong-Hyuk</forenames></author><author><keyname>Moraglio</keyname><forenames>Alberto</forenames></author><author><keyname>Moon</keyname><forenames>Byung-Ro</forenames></author></authors><title>A Mathematical Unification of Geometric Crossovers Defined on Phenotype
  Space</title><categories>cs.NE cs.DM</categories><comments>20 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric crossover is a representation-independent definition of crossover
based on the distance of the search space interpreted as a metric space. It
generalizes the traditional crossover for binary strings and other important
recombination operators for the most frequently used representations. Using a
distance tailored to the problem at hand, the abstract definition of crossover
can be used to design new problem specific crossovers that embed problem
knowledge in the search. This paper is motivated by the fact that
genotype-phenotype mapping can be theoretically interpreted using the concept
of quotient space in mathematics. In this paper, we study a metric
transformation, the quotient metric space, that gives rise to the notion of
quotient geometric crossover. This turns out to be a very versatile notion. We
give many example applications of the quotient geometric crossover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3202</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3202</id><created>2009-07-18</created><authors><author><keyname>Yoon</keyname><forenames>Yourim</forenames></author><author><keyname>Kim</keyname><forenames>Yong-Hyuk</forenames></author><author><keyname>Moraglio</keyname><forenames>Alberto</forenames></author><author><keyname>Moon</keyname><forenames>Byung-Ro</forenames></author></authors><title>Mathematical Interpretation between Genotype and Phenotype Spaces and
  Induced Geometric Crossovers</title><categories>cs.NE cs.DM</categories><comments>21 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present that genotype-phenotype mapping can be
theoretically interpreted using the concept of quotient space in mathematics.
Quotient space can be considered as mathematically-defined phenotype space in
the evolutionary computation theory. The quotient geometric crossover has the
effect of reducing the search space actually searched by geometric crossover,
and it introduces problem knowledge in the search by using a distance better
tailored to the specific solution interpretation. Quotient geometric crossovers
are directly applied to the genotype space but they have the effect of the
crossovers performed on phenotype space. We give many example applications of
the quotient geometric crossover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3208</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3208</id><created>2009-07-20</created><updated>2012-03-03</updated><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>A Linear Vertex Kernel for Maximum Internal Spanning Tree</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a polynomial time algorithm that for any graph G and integer k &gt;=
0, either finds a spanning tree with at least k internal vertices, or outputs a
new graph G' on at most 3k vertices and an integer k' such that G has a
spanning tree with at least k internal vertices if and only if G' has a
spanning tree with at least k' internal vertices. In other words, we show that
the Maximum Internal Spanning Tree problem parameterized by the number of
internal vertices k, has a 3k-vertex kernel. Our result is based on an
innovative application of a classical min-max result about hypertrees in
hypergraphs which states that &quot;a hypergraph H contains a hypertree if and only
if H is partition connected.&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3209</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3209</id><created>2009-07-18</created><authors><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Bai</keyname><forenames>Li</forenames></author></authors><title>Registration of Standardized Histological Images in Feature Space</title><categories>cs.CV</categories><comments>SPIE Medical Imaging 2008 - submission</comments><acm-class>I.4.3; I.4.5; I.4</acm-class><journal-ref>SPIE Medical Imaging 2008: Image Processing. Edited by Reinhardt,
  Joseph M.; Pluim, Josien P. W. Proceedings of the SPIE, Volume 6914, pp.
  69142V-69142V-9 (2008)</journal-ref><doi>10.1117/12.770219</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose three novel and important methods for the
registration of histological images for 3D reconstruction. First, possible
intensity variations and nonstandardness in images are corrected by an
intensity standardization process which maps the image scale into a standard
scale where the similar intensities correspond to similar tissues meaning.
Second, 2D histological images are mapped into a feature space where continuous
variables are used as high confidence image features for accurate registration.
Third, we propose an automatic best reference slice selection algorithm that
improves reconstruction quality based on both image entropy and mean square
error of the registration process. We demonstrate that the choice of reference
slice has a significant impact on registration error, standardization, feature
space and entropy information. After 2D histological slices are registered
through an affine transformation with respect to an automatically chosen
reference, the 3D volume is reconstructed by co-registering 2D slices
elastically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3215</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3215</id><created>2009-07-18</created><authors><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Bai</keyname><forenames>Li</forenames></author></authors><title>Fully Automatic 3D Reconstruction of Histological Images</title><categories>cs.CV</categories><comments>IEEE ISBI-08 Submission</comments><acm-class>I.4.3; I.4.5; I.4</acm-class><journal-ref>5th IEEE International Symposium on Biomedical Imaging: From Nano
  to Macro ISBI-08, pp. 591-594. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a computational framework for 3D volume
reconstruction from 2D histological slices using registration algorithms in
feature space. To improve the quality of reconstructed 3D volume, first,
intensity variations in images are corrected by an intensity standardization
process which maps image intensity scale to a standard scale where similar
intensities correspond to similar tissues. Second, a subvolume approach is
proposed for 3D reconstruction by dividing standardized slices into groups.
Third, in order to improve the quality of the reconstruction process, an
automatic best reference slice selection algorithm is developed based on an
iterative assessment of image entropy and mean square error of the registration
process. Finally, we demonstrate that the choice of the reference slice has a
significant impact on registration quality and subsequent 3D reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3218</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3218</id><created>2009-07-18</created><authors><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Bai</keyname><forenames>Li</forenames></author></authors><title>Parallel AdaBoost Algorithm for Gabor Wavelet Selection in Face
  Recognition</title><categories>cs.CV</categories><comments>IEEE ICIP 2008 Submission</comments><acm-class>I.4; I.4.8; I.5.4; I.4.3</acm-class><journal-ref>IEEE International Conference on Image Processing (ICIP-08), San
  Diego, CA, U.S.A, 12-15 October, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of automatic Gabor wavelet selection for face
recognition is tackled by introducing an automatic algorithm based on Parallel
AdaBoosting method. Incorporating mutual information into the algorithm leads
to the selection procedure not only based on classification accuracy but also
on efficiency. Effective image features are selected by using properly chosen
Gabor wavelets optimised with Parallel AdaBoost method and mutual information
to get high recognition rates with low computational cost. Experiments are
conducted using the well-known FERET face database. In proposed framework,
memory and computation costs are reduced significantly and high classification
accuracy is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3220</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3220</id><created>2009-07-18</created><authors><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Erzin</keyname><forenames>Engin</forenames></author></authors><title>Inter Genre Similarity Modelling For Automatic Music Genre
  Classification</title><categories>cs.SD</categories><comments>Dafx 2006 submission</comments><acm-class>H.5.5; I.5</acm-class><journal-ref>9th International Conference on Digital Audio Effects (DAFx-06),
  Montreal, Canada, September 18-20, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music genre classification is an essential tool for music information
retrieval systems and it has been finding critical applications in various
media platforms. Two important problems of the automatic music genre
classification are feature extraction and classifier design. This paper
investigates inter-genre similarity modelling (IGS) to improve the performance
of automatic music genre classification. Inter-genre similarity information is
extracted over the mis-classified feature population. Once the inter-genre
similarity is modelled, elimination of the inter-genre similarity reduces the
inter-genre confusion and improves the identification rates. Inter-genre
similarity modelling is further improved with iterative IGS modelling(IIGS) and
score modelling for IGS elimination(SMIGS). Experimental results with promising
classification improvements are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3226</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3226</id><created>2009-07-18</created><updated>2010-04-13</updated><authors><author><keyname>Belkhir</keyname><forenames>Walid</forenames></author></authors><title>From Causal Semantics To Duration Timed Models</title><categories>cs.LO</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interleaving semantics is not compatible with both action refinement and
durational actions. Since many true concurrency semantics are congruent w.r.t.
action refinement, notably the causality and the maximality ones, this has
challenged us to study the dense time behavior - where the actions are of
arbitrary fixed duration - within the causality semantics of Da Costa.
  We extend the causal transition systems with the clocks and the timed
constraints, and thus we obtain an over class of timed automata where the
actions need not to be atomic. We define a real time extension of the formal
description technique CSP, called duration-CSP, by attributing the duration to
actions. We give the operational timed causal semantics of duration-CSP as well
as its denotational semantics over the class of timed causal transition
systems. Afterwards, we prove that the two semantics are equivalent. Finally we
extend the duration-CSP language with a refinement operator $\rho$ - that
allows to replace an action with a process - and prove that it preserves the
timed causal bisimulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3230</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3230</id><created>2009-07-20</created><authors><author><keyname>Pauly</keyname><forenames>Arno</forenames></author></authors><title>Infinite Oracle Queries in Type-2 Machines (Extended Abstract)</title><categories>cs.LO</categories><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define Oracle-Type-2-Machine capable of writing infinite oracle queries.
In contrast to finite oracle queries, this extends the realm of
oracle-computable functions into the discontinuous realm. Our definition is
conservative; access to a computable oracle does not increase the computational
power.
  Other models of real hypercomputation such as Ziegler's (finitely) revising
computation or Type-2-Nondeterminism are shown to be special cases of
Oracle-Type-2-Machines. Our approach offers an intuitive definition of the
weakest machine model capable to simulate both Type-2-Machines and BSS
machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3246</identifier>
 <datestamp>2009-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3246</id><created>2009-07-18</created><updated>2009-11-13</updated><authors><author><keyname>Gibbons</keyname><forenames>Alan</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author></authors><title>Wave propagation in filamental cellular automata</title><categories>cs.FL nlin.CG</categories><comments>To appear in the International Journal of Natural Computing Research.
  Changes to previous version: (1) Made title more specific, (2) added several
  explanatory figures, (3) improved background material, (4) several
  clarifications as requested by referees</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by questions in biology and distributed computing, we investigate
the behaviour of particular cellular automata, modelled as one-dimensional
arrays of identical finite automata. We investigate what sort of
self-stabilising cooperative behaviour these can induce in terms of waves of
cellular state changes along a filament of cells. We discover what the minimum
requirements are, in terms of numbers of states and the range of communication
between automata, to observe this for individual filaments. We also discover
that populations of growing filaments may have useful features that the
individual filament does not have, and we give the results of numerical
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3291</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3291</id><created>2009-07-19</created><authors><author><keyname>Hassani</keyname><forenames>S. Hamed</forenames></author><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>The Compound Capacity of Polar Codes</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the compound capacity of polar codes under successive
cancellation decoding for a collection of binary-input memoryless
output-symmetric channels. By deriving a sequence of upper and lower bounds, we
show that in general the compound capacity under successive decoding is
strictly smaller than the unrestricted compound capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3315</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3315</id><created>2009-07-19</created><authors><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Effective Personalized Recommendation in Collaborative Tagging Systems</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, collaborative tagging systems have attracted more and more
attention and have been widely applied in web systems. Tags provide highly
abstracted information about personal preferences and item content, and are
therefore potential to help in improving better personalized recommendations.
In this paper, we propose a tag-based recommendation algorithm considering the
personal vocabulary and evaluate it in a real-world dataset: Del.icio.us.
Experimental results demonstrate that the usage of tag information can
significantly improve the accuracy of personalized recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3330</identifier>
 <datestamp>2015-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3330</id><created>2009-07-19</created><updated>2015-02-17</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>Inconsistency Robustness in Foundations: Mathematics self proves its own
  Consistency and Other Matters</title><categories>cs.PL cs.DC</categories><comments>Notation was made consistent with other articles. arXiv admin note:
  substantial text overlap with arXiv:0812.4852</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inconsistency Robustness is performance of information systems with
pervasively inconsistent information. Inconsistency Robustness of the community
of professional mathematicians is their performance repeatedly repairing
contradictions over the centuries. In the Inconsistency Robustness paradigm,
deriving contradictions have been a progressive development and not &quot;game
stoppers.&quot; Contradictions can be helpful instead of being something to be
&quot;swept under the rug&quot; by denying their existence, which has been repeatedly
attempted by Establishment Philosophers (beginning with some Pythagoreans).
Such denial has delayed mathematical development. This article reports how
considerations of Inconsistency Robustness have recently influenced the
foundations of mathematics for Computer Science continuing a tradition
developing the sociological basis for foundations.
  The current common understanding is that G\&quot;odel proved &quot;Mathematics cannot
prove its own consistency, if it is consistent.&quot; However, the consistency of
mathematics is proved by a simple argument in this article. Consequently, the
current common understanding that G\&quot;odel proved &quot;Mathematics cannot prove its
own consistency, if it is consistent&quot; is inaccurate.
  Wittgenstein long ago showed that contradiction in mathematics results from
the kind of &quot;self-referential&quot; sentence that G\&quot;odel used in his argument that
mathematics cannot prove its own consistency. However, using a typed grammar
for mathematical sentences, it can be proved that the kind &quot;self-referential&quot;
sentence that G\&quot;odel used in his argument cannot be constructed because
required the fixed point that G\&quot;odel used to the construct the
&quot;self-referential&quot; sentence does not exist. In this way, consistency of
mathematics is preserved without giving up power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3340</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3340</id><created>2009-07-20</created><authors><author><keyname>Broughton</keyname><forenames>R.</forenames></author><author><keyname>Coope</keyname><forenames>I.</forenames></author><author><keyname>Renaud</keyname><forenames>P.</forenames></author><author><keyname>Tappenden</keyname><forenames>R.</forenames></author></authors><title>A Barzilai-Borwein $l_1$-Regularized Least Squares Algorithm for
  Compressed Sensing</title><categories>cs.NA cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Problems in signal processing and medical imaging often lead to calculating
sparse solutions to under-determined linear systems. Methodologies for solving
this problem are presented as background to the method used in this work where
the problem is reformulated as an unconstrained convex optimization problem.
The least squares approach is modified by an $l_1$-regularization term. A
sparse solution is sought using a Barzilai-Borwein type projection algorithm
with an adaptive step length. New insight into the choice of step length is
provided through a study of the special structure of the underlying problem.
Numerical experiments are conducted and results given, comparing this algorithm
with a number of other current algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3341</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3341</id><created>2009-07-20</created><authors><author><keyname>Khalil</keyname><forenames>Karim</forenames></author><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Opportunistic Secrecy with a Strict Delay Constraint</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the delay limited secrecy capacity of the flat fading channel
under two different assumptions on the available transmitter channel state
information (CSI). The first scenario assumes perfect prior knowledge of both
the main and eavesdropper channel gains. Here, upper and lower bounds on the
delay limited secrecy capacity are derived, and shown to be tight in the high
signal-to-noise ratio (SNR) regime. In the second scenario, only the main
channel CSI is assumed to be available at the transmitter where, remarkably, we
establish the achievability of a non-zero delay-limited secure rate, for a wide
class of channel distributions, with a high probability. In the two cases, our
achievability arguments are based on a novel two-stage key-sharing approach
that overcomes the secrecy outage phenomenon observed in earlier works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3342</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3342</id><created>2009-07-20</created><authors><author><keyname>Ouladsine</keyname><forenames>Mustapha</forenames><affiliation>LSIS</affiliation></author><author><keyname>Bloch</keyname><forenames>G&#xe9;rard</forenames><affiliation>CRAN</affiliation></author><author><keyname>Dovifaaz</keyname><forenames>Xavier</forenames><affiliation>CRAN</affiliation></author></authors><title>Neural Modeling and Control of Diesel Engine with Pollution Constraints</title><categories>cs.LG cs.NE</categories><comments>15 pages</comments><proxy>ccsd hal-00405175</proxy><journal-ref>Journal of Intelligent and Robotic Systems 41, 2-3 (2005) 157-171</journal-ref><doi>10.1007/s10846-005-3806-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes a neural approach for modelling and control of a
turbocharged Diesel engine. A neural model, whose structure is mainly based on
some physical equations describing the engine behaviour, is built for the
rotation speed and the exhaust gas opacity. The model is composed of three
interconnected neural submodels, each of them constituting a nonlinear
multi-input single-output error model. The structural identi?cation and the
parameter estimation from data gathered on a real engine are described. The
neural direct model is then used to determine a neural controller of the
engine, in a specialized training scheme minimising a multivariable criterion.
Simulations show the effect of the pollution constraint weighting on a
trajectory tracking of the engine speed. Neural networks, which are ?exible and
parsimonious nonlinear black-box models, with universal approximation
capabilities, can accurately describe or control complex nonlinear systems,
with little a priori theoretical knowledge. The presented work extends optimal
neuro-control to the multivariable case and shows the ?exibility of neural
optimisers. Considering the preliminary results, it appears that neural
networks can be used as embedded models for engine control, to satisfy the more
and more restricting pollutant emission legislation. Particularly, they are
able to model nonlinear dynamics and outperform during transients the control
schemes based on static mappings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3348</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3348</id><created>2009-07-20</created><authors><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author><author><keyname>Kholosha</keyname><forenames>Alexander</forenames></author></authors><title>New Binomial Bent Function over the Finite Fields of Odd Characteristic</title><categories>cs.DM cs.CR</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $p$-ary function $f(x)$ mapping $\mathrm{GF}(p^{4k})$ to $\mathrm{GF}(p)$
given by $f(x)={\rm Tr}_{4k}\big(x^{p^{3k}+p^{2k}-p^k+1}+x^2\big)$ is proven to
be a weakly regular bent function and the exact values of its Walsh transform
coefficients are found. The proof is based on a few new results in the area of
exponential sums and polynomials over finite fields that may also be
interesting as independent problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3387</identifier>
 <datestamp>2009-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3387</id><created>2009-07-20</created><updated>2009-08-02</updated><authors><author><keyname>Tamo</keyname><forenames>Itzhak</forenames></author><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>Correcting Limited-Magnitude Errors in the Rank-Modulation Scheme</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study error-correcting codes for permutations under the infinity norm,
motivated by a novel storage scheme for flash memories call rank modulation. In
this scheme, a set of $n$ flash cells are combined to create a single virtual
multi-level cell. Information is stored in the permutation induced by the cell
charge levels. Spike errors, which are characterized by a limited-magnitude
change in cell charge levels, correspond to a low-distance change under the
infinity norm.
  We define codes protecting against spike errors, called limited-magnitude
rank-modulation codes (LMRM codes), and present several constructions for these
codes, some resulting in optimal codes. These codes admit simple recursive, and
sometimes direct, encoding and decoding procedures.
  We also provide lower and upper bounds on the maximal size of LMRM codes both
in the general case, and in the case where the codes form a subgroup of the
symmetric group. In the asymptotic analysis, the codes we construct out-perform
the Gilbert-Varshamov-like bound estimate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3397</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3397</id><created>2009-07-20</created><updated>2009-10-02</updated><authors><author><keyname>Jitman</keyname><forenames>Somphong</forenames></author><author><keyname>Udomkavanich</keyname><forenames>Patanee</forenames></author></authors><title>The Gray Image of Codes over Finite Chain Rings</title><categories>math.RA cs.IT math.IT</categories><comments>Submit to Discrete Mathematics</comments><msc-class>94B15, 94B60, 94B99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The results of J. F. Qiann et al. [4] on $(1-\gamma)$-cyclic codes over
finite chain rings of nilpotency index 2 are extended to $(1-\gamma^e)$-cyclic
codes over finite chain rings of arbitrary nilpotency index $e+1$. The Gray map
is introduced for this type of rings. We prove that the Gray image of a linear
$(1 - \gamma^{e})$-cyclic code over a finite chain ring is a distance-invariant
quasi-cyclic code over its residue field. When the length of codes and the
characteristic of a ring are relatively prime, the Gray images of a linear
cyclic code and a linear $(1+\gamma^e)$-cyclic code are permutatively to
quasi-cyclic codes over its residue field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3402</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3402</id><created>2009-07-20</created><authors><author><keyname>Dell'Amico</keyname><forenames>Matteo</forenames></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames></author><author><keyname>Roudier</keyname><forenames>Yves</forenames></author></authors><title>Measuring Password Strength: An Empirical Analysis</title><categories>cs.CR</categories><comments>15 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an in-depth analysis on the strength of the almost 10,000
passwords from users of an instant messaging server in Italy. We estimate the
strength of those passwords, and compare the effectiveness of state-of-the-art
attack methods such as dictionaries and Markov chain-based techniques.
  We show that the strength of passwords chosen by users varies enormously, and
that the cost of attacks based on password strength grows very quickly when the
attacker wants to obtain a higher success percentage. In accordance with
existing studies we observe that, in the absence of measures for enforcing
password strength, weak passwords are common. On the other hand we discover
that there will always be a subset of users with extremely strong passwords
that are very unlikely to be broken.
  The results of our study will help in evaluating the security of
password-based authentication means, and they provide important insights for
inspiring new and better proactive password checkers and password recovery
tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3414</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3414</id><created>2009-07-20</created><authors><author><keyname>Jurdzi&#x144;ski</keyname><forenames>Marcin</forenames></author><author><keyname>Trivedi</keyname><forenames>Ashutosh</forenames></author></authors><title>Reachability-time games on timed automata</title><categories>cs.CC cs.DS cs.GT cs.LO</categories><journal-ref>M. Jurdzi\'nski and A. Trivedi, Reachability-Time Games on Timed
  Automata (Extended Abstract), In ICALP, Volume 4596 of LNCS, pages 838--849,
  Springer 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a reachability-time game, players Min and Max choose moves so that the
time to reach a final state in a timed automaton is minimised or maximised,
respectively. Asarin and Maler showed decidability of reachability-time games
on strongly non-Zeno timed automata using a value iteration algorithm. This
paper complements their work by providing a strategy improvement algorithm for
the problem. It also generalizes their decidability result because the proposed
strategy improvement algorithm solves reachability-time games on all timed
automata. The exact computational complexity of solving reachability-time games
is also established: the problem is EXPTIME-complete for timed automata with at
least two clocks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3445</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3445</id><created>2009-07-20</created><authors><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Investigating the Change of Web Pages' Titles Over Time</title><categories>cs.IR cs.DL</categories><comments>6 pages, 8 figures, 1 table, 1 appendix</comments><acm-class>H.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inaccessible web pages are part of the browsing experience. The content of
these pages however is often not completely lost but rather missing. Lexical
signatures (LS) generated from the web pages' textual content have been shown
to be suitable as search engine queries when trying to discover a (missing) web
page. Since LSs are expensive to generate, we investigate the potential of web
pages' titles as they are available at a lower cost. We present the results
from studying the change of titles over time. We take titles from copies
provided by the Internet Archive of randomly sampled web pages and show the
frequency of change as well as the degree of change in terms of the Levenshtein
score. We found very low frequencies of change and high Levenshtein scores
indicating that titles, on average, change little from their original, first
observed values (rooted comparison) and even less from the values of their
previous observation (sliding).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3456</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3456</id><created>2009-07-20</created><authors><author><keyname>Turner</keyname><forenames>Scott</forenames></author><author><keyname>Perez-Quinones</keyname><forenames>Manuel A.</forenames></author></authors><title>Exploring Peer Review in the Computer Science Classroom</title><categories>cs.CY</categories><comments>69 pages</comments><acm-class>K.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In computer science, students could benefit from more opportunities to learn
important, high-level concepts and to improve their learning skills. Peer
review is one method to encourage this by providing students with the
opportunity to evaluate other people's work and to receive feedback on their
own projects. This allows for rich learning experience but it is not
immediately obvious how to create a programming project review that will
improve the students' conceptual understanding, require higher level thinking,
and be engaging. The current literature does not typically address differences
between review implementations or provide reasons for design decisions. This
work explored how two different types of reviews affected the students'
learning of concepts, high-level thinking, and engagement. There were
indications that the type of review affected how well students addressed the
concept they were reviewing and the comments' length. This shows that the
review's type may affect student engagement and conceptual learning. There were
also differences in how they reviewed the concepts of Abstraction,
Decomposition, and Encapsulation, suggesting that the concepts are being
learned in different ways. Both of these results have an impact on the use of
peer review computer science but need further investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3493</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3493</id><created>2009-07-20</created><authors><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author><author><keyname>Sprintson</keyname><forenames>Alex</forenames></author></authors><title>Secure Network Coding for Wiretap Networks of Type II</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of securing a multicast network against a wiretapper
that can intercept the packets on a limited number of arbitrary network edges
of its choice. We assume that the network employs the network coding technique
to simultaneously deliver the packets available at the source to all the
receivers.
  We show that this problem can be looked at as a network generalization of the
wiretap channel of type II introduced in a seminal paper by Ozarow and Wyner.
In particular, we show that the transmitted information can be secured by using
the Ozarow-Wyner approach of coset coding at the source on top of the existing
network code. This way, we quickly and transparently recover some of the
results available in the literature on secure network coding for wiretap
networks. Moreover, we derive new bounds on the required alphabet size that are
independent of the network size and devise an algorithm for the construction of
secure network codes. We also look at the dual problem and analyze the amount
of information that can be gained by the wiretapper as a function of the number
of wiretapped edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3497</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3497</id><created>2009-07-20</created><authors><author><keyname>Bruce</keyname><forenames>Daniel</forenames></author><author><keyname>Hoang</keyname><forenames>Chinh T.</forenames></author><author><keyname>Sawada</keyname><forenames>Joe</forenames></author></authors><title>A certifying algorithm for 3-colorability of P5-free graphs</title><categories>cs.DM cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a certifying algorithm for the problem of deciding whether a P5-
free graph is 3-colorable by showing there are exactly six finite graphs that
are P5-free and not 3-colorable and minimal with respect to this property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3520</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3520</id><created>2009-07-20</created><authors><author><keyname>Djorgovski</keyname><forenames>S. G.</forenames></author><author><keyname>Hut</keyname><forenames>P.</forenames></author><author><keyname>McMillan</keyname><forenames>S.</forenames></author><author><keyname>Vesperini</keyname><forenames>E.</forenames></author><author><keyname>Knop</keyname><forenames>R.</forenames></author><author><keyname>Farr</keyname><forenames>W.</forenames></author><author><keyname>Graham</keyname><forenames>M. J.</forenames></author></authors><title>Exploring the Use of Virtual Worlds as a Scientific Research Platform:
  The Meta-Institute for Computational Astrophysics (MICA)</title><categories>astro-ph.IM cs.CY physics.ed-ph</categories><comments>15 pages, to appear in the refereed proceedings of &quot;Facets of Virtual
  Environments&quot; (FaVE 2009), eds. F. Lehmann-Grube, J. Sablating, et al., ICST
  Lecture Notes Ser., Berlin: Springer Verlag (2009); version with full
  resolution color figures is available at
  http://www.mica-vw.org/wiki/index.php/Publications</comments><doi>10.1007/978-3-642-11743-5_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the Meta-Institute for Computational Astrophysics (MICA), the
first professional scientific organization based exclusively in virtual worlds
(VWs). The goals of MICA are to explore the utility of the emerging VR and VWs
technologies for scientific and scholarly work in general, and to facilitate
and accelerate their adoption by the scientific research community. MICA itself
is an experiment in academic and scientific practices enabled by the immersive
VR technologies. We describe the current and planned activities and research
directions of MICA, and offer some thoughts as to what the future developments
in this arena may be.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3563</identifier>
 <datestamp>2009-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3563</id><created>2009-07-21</created><updated>2009-12-17</updated><authors><author><keyname>Byrka</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Karrenbauer</keyname><forenames>Andreas</forenames></author><author><keyname>Sanita</keyname><forenames>Laura</forenames></author></authors><title>The interval constrained 3-coloring problem</title><categories>cs.DM</categories><comments>minor revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we settle the open complexity status of interval constrained
coloring with a fixed number of colors. We prove that the problem is already
NP-complete if the number of different colors is 3. Previously, it has only
been known that it is NP-complete, if the number of colors is part of the input
and that the problem is solvable in polynomial time, if the number of colors is
at most 2. We also show that it is hard to satisfy almost all of the
constraints for a feasible instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3574</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3574</id><created>2009-07-21</created><authors><author><keyname>Donoho</keyname><forenames>David L.</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Message Passing Algorithms for Compressed Sensing</title><categories>cs.IT cond-mat.dis-nn math.IT stat.CO</categories><comments>6 pages paper + 9 pages supplementary information, 13 eps figure.
  Submitted to Proc. Natl. Acad. Sci. USA</comments><doi>10.1073/pnas.0909892106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing aims to undersample certain high-dimensional signals, yet
accurately reconstruct them by exploiting signal characteristics. Accurate
reconstruction is possible when the object to be recovered is sufficiently
sparse in a known basis. Currently, the best known sparsity-undersampling
tradeoff is achieved when reconstructing by convex optimization -- which is
expensive in important large-scale applications. Fast iterative thresholding
algorithms have been intensively studied as alternatives to convex optimization
for large-scale problems. Unfortunately known fast algorithms offer
substantially worse sparsity-undersampling tradeoffs than convex optimization.
  We introduce a simple costless modification to iterative thresholding making
the sparsity-undersampling tradeoff of the new algorithms equivalent to that of
the corresponding convex optimization procedures. The new
iterative-thresholding algorithms are inspired by belief propagation in
graphical models. Our empirical measurements of the sparsity-undersampling
tradeoff for the new algorithms agree with theoretical calculations. We show
that a state evolution formalism correctly derives the true
sparsity-undersampling tradeoff. There is a surprising agreement between
earlier calculations based on random convex polytopes and this new, apparently
very different theoretical formalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3576</identifier>
 <datestamp>2013-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3576</id><created>2009-07-21</created><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Pohl</keyname><forenames>Volker</forenames></author></authors><title>Recovering Signals from Lowpass Data</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. Signal Process. Jul. 2009</comments><journal-ref>IEEE Signal Process., vol. 58, no. 5, pp. 2636-2646 , May 2010</journal-ref><doi>10.1109/TSP.2010.2041278</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of recovering a signal from its low frequency components occurs
often in practical applications due to the lowpass behavior of many physical
systems. Here we study in detail conditions under which a signal can be
determined from its low-frequency content. We focus on signals in
shift-invariant spaces generated by multiple generators. For these signals, we
derive necessary conditions on the cutoff frequency of the lowpass filter as
well as necessary and sufficient conditions on the generators such that signal
recovery is possible. When the lowpass content is not sufficient to determine
the signal, we propose appropriate pre-processing that can improve the
reconstruction ability. In particular, we show that modulating the signal with
one or more mixing functions prior to lowpass filtering, can ensure the
recovery of the signal in many cases, and reduces the necessary bandwidth of
the filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3583</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3583</id><created>2009-07-21</created><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author><author><keyname>Lee</keyname><forenames>Dongman</forenames></author></authors><title>Web of Lossy Adapters for Interface Interoperability: An Algorithm and
  NP-completeness of Minimization</title><categories>cs.SE cs.DS</categories><comments>7 pages</comments><acm-class>D.2.12; F.2.2</acm-class><journal-ref>Proc. of ICSESS 2010</journal-ref><doi>10.1109/ICSESS.2010.5552291</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By using different interface adapters for different methods, it is possible
to construct a maximally covering web of interface adapters which incurs
minimum loss during interface adaptation. We introduce a polynomial-time
algorithm that can achieve this. However, we also show that minimizing the
number of adapters included in a maximally covering web of interface adapters
is an NP-complete problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3599</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3599</id><created>2009-07-21</created><authors><author><keyname>Monin</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>VERIMAG - Imag</affiliation></author><author><keyname>Ene</keyname><forenames>Cristian</forenames><affiliation>VERIMAG - Imag</affiliation></author><author><keyname>P&#xe9;rin</keyname><forenames>Micha&#xeb;l</forenames><affiliation>VERIMAG - Imag</affiliation></author></authors><title>Gentzen-Prawitz Natural Deduction as a Teaching Tool</title><categories>cs.LO</categories><proxy>ccsd hal-00405865</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a four-years experiment in teaching reasoning to undergraduate
students, ranging from weak to gifted, using Gentzen-Prawitz's style natural
deduction. We argue that this pedagogical approach is a good alternative to the
use of Boolean algebra for teaching reasoning, especially for computer
scientists and formal methods practionners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3604</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3604</id><created>2009-07-21</created><authors><author><keyname>Grundland</keyname><forenames>Mark</forenames></author><author><keyname>Patera</keyname><forenames>Jiri</forenames></author><author><keyname>Masakova</keyname><forenames>Zuzana</forenames></author><author><keyname>Dodgson</keyname><forenames>Neil A.</forenames></author></authors><title>Image Sampling with Quasicrystals</title><categories>cs.CV cs.GR</categories><comments>For a full resolution version of this paper, along with supplementary
  materials, please visit at
  http://www.Eyemaginary.com/Portfolio/Publications.html</comments><proxy>sigma</proxy><journal-ref>SIGMA 5 (2009), 075, 23 pages</journal-ref><doi>10.3842/SIGMA.2009.075</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We investigate the use of quasicrystals in image sampling. Quasicrystals
produce space-filling, non-periodic point sets that are uniformly discrete and
relatively dense, thereby ensuring the sample sites are evenly spread out
throughout the sampled image. Their self-similar structure can be attractive
for creating sampling patterns endowed with a decorative symmetry. We present a
brief general overview of the algebraic theory of cut-and-project quasicrystals
based on the geometry of the golden ratio. To assess the practical utility of
quasicrystal sampling, we evaluate the visual effects of a variety of
non-adaptive image sampling strategies on photorealistic image reconstruction
and non-photorealistic image rendering used in multiresolution image
representations. For computer visualization of point sets used in image
sampling, we introduce a mosaic rendering technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3616</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3616</id><created>2009-07-21</created><authors><author><keyname>Ramaiyan</keyname><forenames>Venkatesh</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author></authors><title>Optimal Routing and Power Control for a Single Cell, Dense, Ad Hoc
  Wireless Network</title><categories>cs.NI cs.IT math.IT</categories><comments>Technical report of WiOpt 2007 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dense, ad hoc wireless network, confined to a small region. The
wireless network is operated as a single cell, i.e., only one successful
transmission is supported at a time. Data packets are sent between
sourcedestination pairs by multihop relaying. We assume that nodes
self-organise into a multihop network such that all hops are of length d
meters, where d is a design parameter. There is a contention based multiaccess
scheme, and it is assumed that every node always has data to send, either
originated from it or a transit packet (saturation assumption). In this
scenario, we seek to maximize a measure of the transport capacity of the
network (measured in bit-meters per second) over power controls (in a fading
environment) and over the hop distance d, subject to an average power
constraint. We first argue that for a dense collection of nodes confined to a
small region, single cell operation is efficient for single user decoding
transceivers. Then, operating the dense ad hoc wireless network (described
above) as a single cell, we study the hop length and power control that
maximizes the transport capacity for a given network power constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3631</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3631</id><created>2009-07-21</created><authors><author><keyname>Andersen</keyname><forenames>Reid</forenames></author><author><keyname>Feige</keyname><forenames>Uriel</forenames></author></authors><title>Interchanging distance and capacity in probabilistic mappings</title><categories>cs.DS cs.DM</categories><comments>16 pages, no figures</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Harald Racke [STOC 2008] described a new method to obtain hierarchical
decompositions of networks in a way that minimizes the congestion. Racke's
approach is based on an equivalence that he discovered between minimizing
congestion and minimizing stretch (in a certain setting). Here we present
Racke's equivalence in an abstract setting that is more general than the one
described in Racke's work, and clarifies the power of Racke's result. In
addition, we present a related (but different) equivalence that was developed
by Yuval Emek [ESA 2009] and is only known to apply to planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3654</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3654</id><created>2009-07-21</created><authors><author><keyname>Gauthier</keyname><forenames>Jerome</forenames></author><author><keyname>Duval</keyname><forenames>Laurent</forenames></author><author><keyname>Pesquet</keyname><forenames>Jean-Christophe</forenames></author></authors><title>Optimization of Synthesis Oversampled Complex Filter Banks</title><categories>cs.IT math.IT math.OC</categories><journal-ref>IEEE Transactions on Signal Processing, October 2009, Volume 57,
  Issue 10, p. 3827-3843</journal-ref><doi>10.1109/TSP.2009.2023947</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important issue with oversampled FIR analysis filter banks (FBs) is to
determine inverse synthesis FBs, when they exist. Given any complex oversampled
FIR analysis FB, we first provide an algorithm to determine whether there
exists an inverse FIR synthesis system. We also provide a method to ensure the
Hermitian symmetry property on the synthesis side, which is serviceable to
processing real-valued signals. As an invertible analysis scheme corresponds to
a redundant decomposition, there is no unique inverse FB. Given a particular
solution, we parameterize the whole family of inverses through a null space
projection. The resulting reduced parameter set simplifies design procedures,
since the perfect reconstruction constrained optimization problem is recast as
an unconstrained optimization problem. The design of optimized synthesis FBs
based on time or frequency localization criteria is then investigated, using a
simple yet efficient gradient algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3666</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3666</id><created>2009-07-21</created><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Various thresholds for $\ell_1$-optimization in compressed sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, \cite{CRT,DonohoPol} theoretically analyzed the success of a
polynomial $\ell_1$-optimization algorithm in solving an under-determined
system of linear equations. In a large dimensional and statistical context
\cite{CRT,DonohoPol} proved that if the number of equations (measurements in
the compressed sensing terminology) in the system is proportional to the length
of the unknown vector then there is a sparsity (number of non-zero elements of
the unknown vector) also proportional to the length of the unknown vector such
that $\ell_1$-optimization succeeds in solving the system. In this paper, we
provide an alternative performance analysis of $\ell_1$-optimization and obtain
the proportionality constants that in certain cases match or improve on the
best currently known ones from \cite{DonohoPol,DT}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3679</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3679</id><created>2009-07-21</created><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author></authors><title>Block-length dependent thresholds in block-sparse compressed sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most basic problems in compressed sensing is solving an
under-determined system of linear equations. Although this problem seems rather
hard certain $\ell_1$-optimization algorithm appears to be very successful in
solving it. The recent work of \cite{CRT,DonohoPol} rigorously proved (in a
large dimensional and statistical context) that if the number of equations
(measurements in the compressed sensing terminology) in the system is
proportional to the length of the unknown vector then there is a sparsity
(number of non-zero elements of the unknown vector) also proportional to the
length of the unknown vector such that $\ell_1$-optimization algorithm succeeds
in solving the system. In more recent papers
\cite{StojnicICASSP09block,StojnicJSTSP09} we considered the setup of the
so-called \textbf{block}-sparse unknown vectors. In a large dimensional and
statistical context, we determined sharp lower bounds on the values of
allowable sparsity for any given number (proportional to the length of the
unknown vector) of equations such that an $\ell_2/\ell_1$-optimization
algorithm succeeds in solving the system. The results established in
\cite{StojnicICASSP09block,StojnicJSTSP09} assumed a fairly large block-length
of the block-sparse vectors. In this paper we consider the block-length to be a
parameter of the system. Consequently, we then establish sharp lower bounds on
the values of the allowable block-sparsity as functions of the block-length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3710</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3710</id><created>2009-07-21</created><authors><author><keyname>Sukhov</keyname><forenames>A. V.</forenames></author><author><keyname>Sultanov</keyname><forenames>T. G.</forenames></author><author><keyname>Strizhov</keyname><forenames>M. V.</forenames></author><author><keyname>Platonov</keyname><forenames>A. P.</forenames></author></authors><title>Throughput metrics and packet delay in TCP/IP networks</title><categories>cs.NI cs.PF</categories><comments>6 pages, 3 figures</comments><acm-class>C.2.3; C.4</acm-class><journal-ref>RIPE 59, Lissabon, 2009</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the paper the method for estimation of throughput metrics like available
bandwidth and end-t-end capacity is supposed. This method is based on
measurement of network delay $D_i$ for packets of different sizes $W_i$. The
simple expression for available bandwidth $B_{av} =(W_2-W_1)/(D_2-D_1)$ is
substantiated. The number of experiments on matching of the results received
new and traditional methods is spent. The received results testify to
possibility of application of new model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3754</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3754</id><created>2009-07-21</created><updated>2009-11-09</updated><authors><author><keyname>Hardt</keyname><forenames>Moritz</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author></authors><title>On the Geometry of Differential Privacy</title><categories>cs.CC cs.CR cs.DS</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the noise complexity of differentially private mechanisms in the
setting where the user asks $d$ linear queries $f\colon\Rn\to\Re$
non-adaptively. Here, the database is represented by a vector in $\Rn$ and
proximity between databases is measured in the $\ell_1$-metric.
  We show that the noise complexity is determined by two geometric parameters
associated with the set of queries.
  We use this connection to give tight upper and lower bounds on the noise
complexity for any $d \leq n$. We show that for $d$ random linear queries of
sensitivity~1, it is necessary and sufficient to add $\ell_2$-error
$\Theta(\min\{d\sqrt{d}/\epsilon,d\sqrt{\log (n/d)}/\epsilon\})$ to achieve
$\epsilon$-differential privacy. Assuming the truth of a deep conjecture from
convex geometry, known as the Hyperplane conjecture, we can extend our results
to arbitrary linear queries giving nearly matching upper and lower bounds.
  Our bound translates to error
$O(\min\{d/\epsilon,\sqrt{d\log(n/d)}/\epsilon\})$ per answer. The best
previous upper bound (Laplacian mechanism) gives a bound of
$O(\min\{d/\eps,\sqrt{n}/\epsilon\})$ per answer, while the best known lower
bound was $\Omega(\sqrt{d}/\epsilon)$. In contrast, our lower bound is strong
enough to separate the concept of differential privacy from the notion of
approximate differential privacy where an upper bound of $O(\sqrt{d}/\epsilon)$
can be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3777</identifier>
 <datestamp>2009-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3777</id><created>2009-07-22</created><authors><author><keyname>Jaffres-Runser</keyname><forenames>Katia</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes, EA 3720, WNET, CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames><affiliation>WNET</affiliation></author></authors><title>A multiobjective Tabu framework for the optimization and evaluation of
  wireless systems</title><categories>cs.NI</categories><proxy>ccsd inria-00406345</proxy><journal-ref>Local Search Techniques: Focus on Tabu Search I-Tech Education and
  Publishing (Ed.) (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter will focus on the multiobjective formulation of an optimization
problem and highlight the assets of a multiobjective Tabu implementation for
such problems. An illustration of a specific Multiobjective Tabu heuristic
(referred to as MO Tabu in the following) will be given for 2 particular
problems arising in wireless systems. The first problem addresses the planning
of access points for a WLAN network with some Quality of Service requirements
and the second one provides an evaluation mean to assess the performance
evaluation of a wireless sensor network. The chapter will begin with an
overview of multiobjective (MO) optimization featuring the definitions and
concepts of the domain (e.g. Dominance, Pareto front,...) and the main MO
search heuristics available so far. We will then emphasize on the definition of
a problem as a multiobjective optimization problem and illustrate it by the two
examples from the field of wireless networking. The next part will focus on MO
Tabu, a Tabu-inspired multiobjective heuristic and describe its assets compared
to other MO heuristics. The last part of the chapter will show the results
obtained with this MO Tabu strategy on the 2 wireless networks related
problems. Conclusion on the use of Tabu as a multiobjective heuristic will be
drawn based on the results presented so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3780</identifier>
 <datestamp>2009-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3780</id><created>2009-07-22</created><updated>2009-08-14</updated><authors><author><keyname>Arvind</keyname><forenames>V.</forenames></author><author><keyname>Joglekar</keyname><forenames>Pushkar S.</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>On Lower Bounds for Constant Width Arithmetic Circuits</title><categories>cs.CC</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The motivation for this paper is to study the complexity of constant-width
arithmetic circuits. Our main results are the following.
  1. For every k &gt; 1, we provide an explicit polynomial that can be computed by
a linear-sized monotone circuit of width 2k but has no subexponential-sized
monotone circuit of width k. It follows, from the definition of the polynomial,
that the constant-width and the constant-depth hierarchies of monotone
arithmetic circuits are infinite, both in the commutative and the
noncommutative settings.
  2. We prove hardness-randomness tradeoffs for identity testing constant-width
commutative circuits analogous to [KI03,DSY08].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3781</identifier>
 <datestamp>2009-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3781</id><created>2009-07-22</created><authors><author><keyname>L&#xe9;on</keyname><forenames>St&#xe9;phanie</forenames><affiliation>LIRMM</affiliation></author></authors><title>Un syst\`eme modulaire d'acquisition automatique de traductions \`a
  partir du Web</title><categories>cs.CL</categories><proxy>ccsd hal-00406358</proxy><journal-ref>TALN'09 (Traitement Automatique des Langues Naturelles), France
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method of automatic translation (French/English) of Complex
Lexical Units (CLU) for aiming at extracting a bilingual lexicon. Our modular
system is based on linguistic properties (compositionality, polysemy, etc.).
Different aspects of the multilingual Web are used to validate candidate
translations and collect new terms. We first build a French corpus of Web pages
to collect CLU. Three adapted processing stages are applied for each linguistic
property : compositional and non polysemous translations, compositional
polysemous translations and non compositional translations. Our evaluation on a
sample of CLU shows that our technique based on the Web can reach a very high
precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3793</identifier>
 <datestamp>2009-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3793</id><created>2009-07-22</created><authors><author><keyname>Khalil</keyname><forenames>Ayman</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author></authors><title>Cross-layer Resource Allocation Scheme for Multi-band High Rate UWB
  Systems</title><categories>cs.NI</categories><proxy>ccsd hal-00406378</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the use of a cross-layer allocation mechanism
for the high-rate ultra-wideband (UWB) systems. The aim of this paper is
twofold. First, through the cross-layer approach that provides a new service
differentiation approach to the fully distributed UWB systems, we support
traffic with quality of service (QoS) guarantee in a multi-user context.
Second, we exploit the effective SINR method that represents the
characteristics of multiple sub-carrier SINRs in the multi-band WiMedia
solution proposed for UWB systems, in order to provide the channel state
information needed for the multi-user sub-band allocation. This new approach
improves the system performance and optimizes the spectrum utilization with a
low cost data exchange between the different users while guaranteeing the
required QoS. In addition, this new approach solves the problem of the
cohabitation of more than three users in the same WiMedia channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3801</identifier>
 <datestamp>2013-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3801</id><created>2009-07-22</created><updated>2012-05-06</updated><authors><author><keyname>Sopena</keyname><forenames>Eric</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Wu</keyname><forenames>Jiaojiao</forenames><affiliation>LaBRI</affiliation></author></authors><title>The Incidence Chromatic Number of Toroidal Grids</title><categories>cs.DM</categories><comments>16 pages</comments><proxy>ccsd</proxy><journal-ref>Discussiones Mathematicae Graph Theory 33 (2013) 315-327</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An incidence in a graph $G$ is a pair $(v,e)$ with $v \in V(G)$ and $e \in
E(G)$, such that $v$ and $e$ are incident. Two incidences $(v,e)$ and $(w,f)$
are adjacent if $v=w$, or $e=f$, or the edge $vw$ equals $e$ or $f$. The
incidence chromatic number of $G$ is the smallest $k$ for which there exists a
mapping from the set of incidences of $G$ to a set of $k$ colors that assigns
distinct colors to adjacent incidences. In this paper, we prove that the
incidence chromatic number of the toroidal grid $T_{m,n}=C_m\Box C_n$ equals 5
when $m,n \equiv 0 \pmod 5$ and 6 otherwise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3804</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3804</id><created>2009-07-22</created><updated>2009-07-31</updated><authors><author><keyname>Stirling</keyname><forenames>Colin</forenames></author></authors><title>Decidability of higher-order matching</title><categories>cs.LO cs.GT</categories><comments>appears in LMCS (Logical Methods in Computer Science)</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (July 30,
  2009) lmcs:757</journal-ref><doi>10.2168/LMCS-5(3:2)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the higher-order matching problem is decidable using a
game-theoretic argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3819</identifier>
 <datestamp>2009-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3819</id><created>2009-07-22</created><authors><author><keyname>Guyet</keyname><forenames>Thomas</forenames><affiliation>Agrocampus Ouest, INRIA - IRISA</affiliation></author><author><keyname>Quiniou</keyname><forenames>Ren&#xe9;</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Wang</keyname><forenames>Wei</forenames><affiliation>NTNU</affiliation></author><author><keyname>Cordier</keyname><forenames>Marie-Odile</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Self-adaptive web intrusion detection system</title><categories>cs.NI cs.AI cs.MA</categories><proxy>ccsd inria-00406450</proxy><report-no>RR-6989</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of the web server contents and the emergence of new kinds of
intrusions make necessary the adaptation of the intrusion detection systems
(IDS). Nowadays, the adaptation of the IDS requires manual -- tedious and
unreactive -- actions from system administrators. In this paper, we present a
self-adaptive intrusion detection system which relies on a set of local
model-based diagnosers. The redundancy of diagnoses is exploited, online, by a
meta-diagnoser to check the consistency of computed partial diagnoses, and to
trigger the adaptation of defective diagnoser models (or signatures) in case of
inconsistency. This system is applied to the intrusion detection from a stream
of HTTP requests. Our results show that our system 1) detects intrusion
occurrences sensitively and precisely, 2) accurately self-adapts diagnoser
model, thus improving its detection accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3823</identifier>
 <datestamp>2015-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3823</id><created>2009-07-22</created><updated>2009-07-30</updated><authors><author><keyname>Chowdary</keyname><forenames>C Ravindranath</forenames></author><author><keyname>Kumar</keyname><forenames>P Sreenivasa</forenames></author></authors><title>USUM: Update Summary Generation System</title><categories>cs.IR</categories><journal-ref>Advances in Computational Linguistics, Research in Computing
  Science Vol. 41, 2009, pp. 229-240</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Huge amount of information is present in the World Wide Web and a large
amount is being added to it frequently. A query-specific summary of multiple
documents is very helpful to the user in this context. Currently, few systems
have been proposed for query-specific, extractive multi-document summarization.
If a summary is available for a set of documents on a given query and if a new
document is added to the corpus, generating an updated summary from the scratch
is time consuming and many a times it is not practical/possible. In this paper
we propose a solution to this problem. This is especially useful in a scenario
where the source documents are not accessible. We cleverly embed the sentences
of the current summary into the new document and then perform query-specific
summary generation on that document. Our experimental results show that the
performance of the proposed approach is good in terms of both quality and
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3826</identifier>
 <datestamp>2009-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3826</id><created>2009-07-22</created><authors><author><keyname>Namiki</keyname><forenames>Takao</forenames></author><author><keyname>Kuroda</keyname><forenames>Hiraku</forenames></author><author><keyname>Naruse</keyname><forenames>Shunsuke</forenames></author></authors><title>Experimental DML over digital repositories in Japan</title><categories>cs.DL</categories><journal-ref>Proceedings of Towards a Digital Mathematics Library 2009, Grand
  Bend, Ontario, Canada (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the authors show an overview of Virtual Digital Mathematics
Library in Japan (DML-JP), contents of which consist of metadata harvested from
institutional repositories in Japan and digital repositories in the world.
DML-JP is, in a sense, a subject specific repository which collaborate with
various digital repositories. Beyond portal website, DML-JP provides
subject-specific metadata through OAI-ORE. By the schema it is enabled that
digital repositories can load the rich metadata which were added by
mathematicians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3867</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3867</id><created>2009-07-22</created><updated>2009-07-23</updated><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Artificial Dendritic Cells: Multi-faceted Perspectives</title><categories>cs.AI cs.CR cs.MA</categories><comments>24 pages, 6 figures,</comments><journal-ref>Human-Centric Information Processing Through Granular Modelling,
  182, 375-395, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dendritic cells are the crime scene investigators of the human immune system.
Their function is to correlate potentially anomalous invading entities with
observed damage to the body. The detection of such invaders by dendritic cells
results in the activation of the adaptive immune system, eventually leading to
the removal of the invader from the host body. This mechanism has provided
inspiration for the development of a novel bio-inspired algorithm, the
Dendritic Cell Algorithm. This algorithm processes information at multiple
levels of resolution, resulting in the creation of information granules of
variable structure. In this chapter we examine the multi-faceted nature of
immunology and how research in this field has shaped the function of the
resulting Dendritic Cell Algorithm. A brief overview of the algorithm is given
in combination with the details of the processes used for its development. The
chapter is concluded with a discussion of the parallels between our
understanding of the human immune system and how such knowledge influences the
design of artificial immune systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3874</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3874</id><created>2009-07-22</created><updated>2011-02-01</updated><authors><author><keyname>Cuevas</keyname><forenames>Ruben</forenames></author><author><keyname>Laoutaris</keyname><forenames>Nikolaos</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoyuan</forenames></author><author><keyname>Siganos</keyname><forenames>Georgos</forenames></author><author><keyname>Rodriguez</keyname><forenames>Pablo</forenames></author></authors><title>Deep Diving into BitTorrent Locality</title><categories>cs.NI cs.CY</categories><comments>Please cite the conference version of this paper appearing in the
  Proceedings of IEEE INFOCOM'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A substantial amount of work has recently gone into localizing BitTorrent
traffic within an ISP in order to avoid excessive and often times unnecessary
transit costs. Several architectures and systems have been proposed and the
initial results from specific ISPs and a few torrents have been encouraging. In
this work we attempt to deepen and scale our understanding of locality and its
potential. Looking at specific ISPs, we consider tens of thousands of
concurrent torrents, and thus capture ISP-wide implications that cannot be
appreciated by looking at only a handful of torrents. Secondly, we go beyond
individual case studies and present results for the top 100 ISPs in terms of
number of users represented in our dataset of up to 40K torrents involving more
than 3.9M concurrent peers and more than 20M in the course of a day spread in
11K ASes. We develop scalable methodologies that permit us to process this huge
dataset and answer questions such as: &quot;\emph{what is the minimum and the
maximum transit traffic reduction across hundreds of ISPs?}&quot;, &quot;\emph{what are
the win-win boundaries for ISPs and their users?}&quot;, &quot;\emph{what is the maximum
amount of transit traffic that can be localized without requiring fine-grained
control of inter-AS overlay connections?}&quot;, &quot;\emph{what is the impact to
transit traffic from upgrades of residential broadband speeds?}&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3920</identifier>
 <datestamp>2011-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3920</id><created>2009-07-22</created><authors><author><keyname>Bravyi</keyname><forenames>Sergey</forenames></author><author><keyname>Harrow</keyname><forenames>Aram W.</forenames></author><author><keyname>Hassidim</keyname><forenames>Avinatan</forenames></author></authors><title>Quantum algorithms for testing properties of distributions</title><categories>quant-ph cs.CC</categories><comments>20 pages</comments><journal-ref>IEEE. Trans. Inf. Th., vol. 57, no. 6, pp. 3971--3981, June 2011</journal-ref><doi>10.1109/TIT.2011.2134250</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose one has access to oracles generating samples from two unknown
probability distributions P and Q on some N-element set. How many samples does
one need to test whether the two distributions are close or far from each other
in the L_1-norm ? This and related questions have been extensively studied
during the last years in the field of property testing. In the present paper we
study quantum algorithms for testing properties of distributions. It is shown
that the L_1-distance between P and Q can be estimated with a constant
precision using approximately N^{1/2} queries in the quantum settings, whereas
classical computers need \Omega(N) queries. We also describe quantum algorithms
for testing Uniformity and Orthogonality with query complexity O(N^{1/3}). The
classical query complexity of these problems is known to be \Omega(N^{1/2}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3942</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3942</id><created>2009-07-23</created><updated>2009-11-04</updated><authors><author><keyname>Owen</keyname><forenames>Megan</forenames></author><author><keyname>Provan</keyname><forenames>J. Scott</forenames></author></authors><title>A Fast Algorithm for Computing Geodesic Distances in Tree Space</title><categories>q-bio.PE cs.CG cs.DM math.MG</categories><comments>20 pages, 5 figures. Added new section on including common edges and
  leaf edge-lengths in the algorithm, clarified starting point for algorithm,
  added references, other minor improvements. To appear in IEEE/ACM
  Transactions on Computational Biology and Bioinformatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comparing and computing distances between phylogenetic trees are important
biological problems, especially for models where edge lengths play an important
role. The geodesic distance measure between two phylogenetic trees with edge
lengths is the length of the shortest path between them in the continuous tree
space introduced by Billera, Holmes, and Vogtmann. This tree space provides a
powerful tool for studying and comparing phylogenetic trees, both in exhibiting
a natural distance measure and in providing a Euclidean-like structure for
solving optimization problems on trees. An important open problem is to find a
polynomial time algorithm for finding geodesics in tree space. This paper gives
such an algorithm, which starts with a simple initial path and moves through a
series of successively shorter paths until the geodesic is attained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3965</identifier>
 <datestamp>2015-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3965</id><created>2009-07-22</created><updated>2015-12-04</updated><authors><author><keyname>Barbosa</keyname><forenames>Andr&#xe9; Luiz</forenames></author></authors><title>P != NP Proof</title><categories>cs.CC</categories><comments>25 pages and 3 new revolutionary ideas. Please: If possible, read the
  paper without preconceptions. Remember that, compared to proper Mathematics,
  immortality, fame, money and so on are vain things, silly concepts and
  bullshits that blow in the wind. The true happiness to an actual
  mathematician is to find the light into the darkest night! (By the way, see
  [25,26,27] for another amazing insights.)</comments><msc-class>Primary 68Q15, Secondary 68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates that P \not= NP. The way was to generalize the
traditional definitions of the classes P and NP, to construct an artificial
problem (a generalization to SAT: The XG-SAT, much more difficult than the
former) and then to demonstrate that it is in NP but not in P (where the
classes P and NP are generalized and called too simply P and NP in this paper,
and then it is explained why the traditional classes P and NP should be fixed
and replaced by these generalized ones into Theory of Computer Science). The
demonstration consists of: 1. Definition of Restricted Type X Program; 2.
Definition of the General Extended Problem of Satisfiability of a Boolean
Formula - XG-SAT; 3. Generalization to classes P and NP; 4. Demonstration that
the XG-SAT is in NP; 5. Demonstration that the XG-SAT is not in P; 6.
Demonstration that the Baker-Gill-Solovay Theorem does not refute the proof; 7.
Demonstration that the Razborov-Rudich Theorem does not refute the proof; 8.
Demonstration that the Aaronson-Wigderson Theorem does not refute the proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3970</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3970</id><created>2009-07-22</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Infinite Families of Recursive Formulas Generating Power Moments of
  Kloosterman Sums: Symplectic Case</title><categories>math.NT cs.IT math.IT</categories><comments>21 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct two infinite families of binary linear codes
associated with double cosets with respect to certain maximal parabolic
subgroup of the symplectic group Sp(2n,q) Here q is a power of two. Then we
obtain an infinite family of recursive formulas for the power moments of
Kloosterman sums and those of 2-dimensional Kloosterman sums in terms of the
frequencies of weights in the codes. This is done via Pless power moment
identity and by utilizing the explicit expressions of exponential sums over
those double cosets related to the evaluations of &quot;Gauss sums&quot; for the
symplectic groups Sp(2n,q).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3972</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3972</id><created>2009-07-22</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Infinite Families of Recursive Formulas Generating Power Moments of
  Kloosterman Sums: O\^{+}(2n, 2\^{r}) Case</title><categories>math.NT cs.IT math.IT</categories><comments>21pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct four infinite families of binary linear codes
associated with double cosets with respect to certain maximal parabolic
subgroup of the orthogonal group O^+(2n,2^r). Here q is a power of two. Then we
obtain two infinite families of recursive formulas for the power moments of
Kloosterman sums and those of 2-dimensional Kloosterman sums in terms of the
frequencies of weights in the codes. This is done via Pless power moment
identity and by utilizing the explicit expressions of exponential sums over
those double cosets related to the evaluations of &quot;Gauss sums&quot; for the
orthogonal groups O^+(2n,2^r).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3974</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3974</id><created>2009-07-22</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Simple Recursive Formulas Generating Power Moments of Kloosterman Sums</title><categories>math.NT cs.IT math.IT</categories><comments>8 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct four binary linear codes closely connected with
certain exponential sums over the finite field F_q and F_q-{0,1}. Here q is a
power of two. Then we obtain four recursive formulas for the power moments of
Kloosterman sums in terms of the frequencies of weights in the codes. This is
done via Pless power moment identity and by utilizing the explicit expressions
of the exponential sums obtained earlier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3977</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3977</id><created>2009-07-22</created><updated>2010-08-14</updated><authors><author><keyname>Liu</keyname><forenames>Shihuan</forenames></author><author><keyname>Ying</keyname><forenames>Lei</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Throughput-Optimal Opportunistic Scheduling in the Presence of
  Flow-Level Dynamics</title><categories>cs.NI</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multiuser scheduling in wireless networks with channel variations
and flow-level dynamics. Recently, it has been shown that the MaxWeight
algorithm, which is throughput-optimal in networks with a fixed number users,
fails to achieve the maximum throughput in the presence of flow-level dynamics.
In this paper, we propose a new algorithm, called workload-based scheduling
with learning, which is provably throughput-optimal, requires no prior
knowledge of channels and user demands, and performs significantly better than
previously suggested algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3983</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3983</id><created>2009-07-23</created><updated>2009-08-06</updated><authors><author><keyname>Wang</keyname><forenames>Wenguang</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Yu</keyname><forenames>Wenguang</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Li</keyname><forenames>Qun</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Wang</keyname><forenames>Weiping</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Liu</keyname><forenames>Xichun</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author></authors><title>Service-oriented high level architecture</title><categories>cs.SE</categories><comments>12 pages, 3 figures, 2 tables, Proceedings of 2008 European
  Simulation Interoperability Workshop, 08E-SIW-022</comments><report-no>08E-SIW-022</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-oriented High Level Architecture (SOHLA) refers to the high level
architecture (HLA) enabled by Service-Oriented Architecture (SOA) and Web
Services etc. techniques which supports distributed interoperating services.
The detailed comparisons between HLA and SOA are made to illustrate the
importance of their combination. Then several key enhancements and changes of
HLA Evolved Web Service API are introduced in comparison with native APIs, such
as Federation Development and Execution Process, communication mechanisms, data
encoding, session handling, testing environment and performance analysis. Some
approaches are summarized including Web-Enabling HLA at the communication
layer, HLA interface specification layer, federate interface layer and
application layer. Finally the problems of current research are discussed, and
the future directions are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.3986</identifier>
 <datestamp>2014-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.3986</id><created>2009-07-23</created><updated>2014-05-19</updated><authors><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Contextual Bandits with Similarity Information</title><categories>cs.DS cs.LG</categories><comments>This is the full version of a conference paper in COLT 2011, to
  appear in JMLR in 2014. A preliminary version of this manuscript (with all
  the results) has been posted to arXiv in February 2011. An earlier version on
  arXiv, which does not include the results in Section 6, dates back to July
  2009. The present revision addresses various presentation issues pointed out
  by journal referees</comments><acm-class>F.2.2; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multi-armed bandit (MAB) problem, an online algorithm makes a sequence
of choices. In each round it chooses from a time-invariant set of alternatives
and receives the payoff associated with this alternative. While the case of
small strategy sets is by now well-understood, a lot of recent work has focused
on MAB problems with exponentially or infinitely large strategy sets, where one
needs to assume extra structure in order to make the problem tractable. In
particular, recent literature considered information on similarity between
arms.
  We consider similarity information in the setting of &quot;contextual bandits&quot;, a
natural extension of the basic MAB problem where before each round an algorithm
is given the &quot;context&quot; -- a hint about the payoffs in this round. Contextual
bandits are directly motivated by placing advertisements on webpages, one of
the crucial problems in sponsored search. A particularly simple way to
represent similarity information in the contextual bandit setting is via a
&quot;similarity distance&quot; between the context-arm pairs which gives an upper bound
on the difference between the respective expected payoffs.
  Prior work on contextual bandits with similarity uses &quot;uniform&quot; partitions of
the similarity space, which is potentially wasteful. We design more efficient
algorithms that are based on adaptive partitions adjusted to &quot;popular&quot; context
and &quot;high-payoff&quot; arms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4006</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4006</id><created>2009-07-23</created><authors><author><keyname>Arvind</keyname><forenames>V.</forenames></author><author><keyname>Joglekar</keyname><forenames>Pushkar S.</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>Arithmetic Circuits and the Hadamard Product of Polynomials</title><categories>cs.CC</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the Hadamard product of matrices we define the Hadamard product
of multivariate polynomials and study its arithmetic circuit and branching
program complexity. We also give applications and connections to polynomial
identity testing. Our main results are the following. 1. We show that
noncommutative polynomial identity testing for algebraic branching programs
over rationals is complete for the logspace counting class $\ceql$, and over
fields of characteristic $p$ the problem is in $\ModpL/\Poly$. 2.We show an
exponential lower bound for expressing the Raz-Yehudayoff polynomial as the
Hadamard product of two monotone multilinear polynomials. In contrast the
Permanent can be expressed as the Hadamard product of two monotone multilinear
formulas of quadratic size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4031</identifier>
 <datestamp>2009-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4031</id><created>2009-07-23</created><authors><author><keyname>Mehanna</keyname><forenames>Omar</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>Cognitive MAC Protocols for General Primary Network Models</title><categories>cs.NI cs.IT math.IT</categories><comments>12 pages, 8 figures, submitted to IEEE Transactions on Mobile
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design of cognitive Medium Access Control (MAC) protocols
enabling a secondary (unlicensed) transmitter-receiver pair to communicate over
the idle periods of a set of primary (licensed) channels. More specifically, we
propose cognitive MAC protocols optimized for both slotted and un-slotted
primary networks. For the slotted structure, the objective is to maximize the
secondary throughput while maintaining synchronization between the secondary
pair and not causing interference to the primary network. Our investigations
differentiate between two sensing scenarios. In the first, the secondary
transmitter is capable of sensing all the primary channels, whereas it senses
only a subset of the primary channels in the second scenario. In both cases, we
propose blind MAC protocols that efficiently learn the statistics of the
primary traffic on-line and asymptotically achieve the throughput obtained when
prior knowledge of primary traffic statistics is available. For the un-slotted
structure, the objective is to maximize the secondary throughput while
satisfying an interference constraint on the primary network. Sensing-dependent
periods are optimized for each primary channel yielding a MAC protocol which
outperforms previously proposed techniques that rely on a single sensing period
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4036</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4036</id><created>2009-07-23</created><authors><author><keyname>Groen</keyname><forenames>D.</forenames></author><author><keyname>Harfst</keyname><forenames>S.</forenames></author><author><keyname>Zwart</keyname><forenames>S. Portegies</forenames></author></authors><title>The Living Application: a Self-Organising System for Complex Grid Tasks</title><categories>cs.DC astro-ph.GA cs.NI</categories><comments>26 pages, 3 figures, accepted by IJHPCA</comments><acm-class>C.2.4</acm-class><journal-ref>International Journal of High Performance Computing Applications
  May 2010 vol. 24 no. 2 185-193</journal-ref><doi>10.1177/1094342009347891</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the living application, a method to autonomously manage
applications on the grid. During its execution on the grid, the living
application makes choices on the resources to use in order to complete its
tasks. These choices can be based on the internal state, or on autonomously
acquired knowledge from external sensors. By giving limited user capabilities
to a living application, the living application is able to port itself from one
resource topology to another. The application performs these actions at
run-time without depending on users or external workflow tools. We demonstrate
this new concept in a special case of a living application: the living
simulation. Today, many simulations require a wide range of numerical solvers
and run most efficiently if specialized nodes are matched to the solvers. The
idea of the living simulation is that it decides itself which grid machines to
use based on the numerical solver currently in use. In this paper we apply the
living simulation to modelling the collision between two galaxies in a test
setup with two specialized computers. This simulation switces at run-time
between a GPU-enabled computer in the Netherlands and a GRAPE-enabled machine
that resides in the United States, using an oct-tree N-body code whenever it
runs in the Netherlands and a direct N-body solver in the United States.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4068</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4068</id><created>2009-07-23</created><updated>2010-03-09</updated><authors><author><keyname>Ahmed</keyname><forenames>Syed Ishtiaque</forenames></author><author><keyname>Hasan</keyname><forenames>Masud</forenames></author><author><keyname>Islam</keyname><forenames>Md. Ariful</forenames></author></authors><title>Cutting a Convex Polyhedron Out of a Sphere</title><categories>cs.CG cs.DM cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a convex polyhedron $P$ of $n$ vertices inside a sphere $Q$, we give an
$O(n^3)$-time algorithm that cuts $P$ out of $Q$ by using guillotine cuts and
has cutting cost $O((\log n)^2)$ times the optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4085</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4085</id><created>2009-07-23</created><authors><author><keyname>Saxena</keyname><forenames>Amitabh</forenames></author></authors><title>A Secure Wireless Routing Protocol Using Enhanced Chain Signatures</title><categories>cs.CR cs.NI</categories><comments>Extended version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a routing protocol for wireless networks. Wireless routing
protocols allow hosts within a network to have some knowledge of the topology
in order to know when to forward a packet (via broadcast) and when to drop it.
Since a routing protocol forms the backbone of a network, it is a lucrative
target for many attacks, all of which attempt to disrupt network traffic by
corrupting routing tables of neighboring routers using false updates. Secure
routing protocols designed for wired networks (such as S-BGP) are not scalable
in an ad-hoc wireless environment because of two main drawbacks: (1) the need
to maintain knowledge about all immediate neighbors (which requires a discovery
protocol), and (2) the need to transmit the same update several times, one for
each neighbor. Although information about neighbors is readily available in a
fairly static and wired network, such information is often not updated or
available in an ad-hoc wireless network with mobile devices. Our protocol is a
variant of S-BGP called SS-BGP and allows a single broadcast for routing
updates without having the need to be aware of every neighboring router. The
protocol is based on a novel authentication primitive called Enhanced Chain
Signatures (ECS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4100</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4100</id><created>2009-07-23</created><authors><author><keyname>Ammon</keyname><forenames>Kurt</forenames></author></authors><title>Beyond Turing Machines</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses &quot;computational&quot; systems capable of &quot;computing&quot; functions
not computable by predefined Turing machines if the systems are not isolated
from their environment. Roughly speaking, these systems can change their finite
descriptions by interacting with their environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4128</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4128</id><created>2009-07-23</created><authors><author><keyname>Truszczy&#x144;ski</keyname><forenames>Miroslaw</forenames></author><author><keyname>Woltran</keyname><forenames>Stefan</forenames></author></authors><title>Relativized hyperequivalence of logic programs for modular programming</title><categories>cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent framework of relativized hyperequivalence of programs offers a
unifying generalization of strong and uniform equivalence. It seems to be
especially well suited for applications in program optimization and modular
programming due to its flexibility that allows us to restrict, independently of
each other, the head and body alphabets in context programs. We study
relativized hyperequivalence for the three semantics of logic programs given by
stable, supported and supported minimal models. For each semantics, we identify
four types of contexts, depending on whether the head and body alphabets are
given directly or as the complement of a given set. Hyperequivalence relative
to contexts where the head and body alphabets are specified directly has been
studied before. In this paper, we establish the complexity of deciding
relativized hyperequivalence with respect to the three other types of context
programs.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4130</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4130</id><created>2009-07-23</created><authors><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Spending is not Easier than Trading: On the Computational Equivalence of
  Fisher and Arrow-Debreu Equilibria</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a common belief that computing a market equilibrium in Fisher's
spending model is easier than computing a market equilibrium in Arrow-Debreu's
exchange model. This belief is built on the fact that we have more algorithmic
success in Fisher equilibria than Arrow-Debreu equilibria. For example, a
Fisher equilibrium in a Leontief market can be found in polynomial time, while
it is PPAD-hard to compute an approximate Arrow-Debreu equilibrium in a
Leontief market.
  In this paper, we show that even when all the utilities are additively
separable, piecewise-linear, and concave functions, finding an approximate
equilibrium in Fisher's model is complete in PPAD. Our result solves a
long-term open question on the complexity of market equilibria. To the best of
our knowledge, this is the first PPAD-completeness result for Fisher's model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4166</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4166</id><created>2009-07-24</created><updated>2010-03-29</updated><authors><author><keyname>Bhattacharya</keyname><forenames>Sayan</forenames></author><author><keyname>Goel</keyname><forenames>Gagan</forenames></author><author><keyname>Gollapudi</keyname><forenames>Sreenivas</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author></authors><title>Budget Constrained Auctions with Heterogeneous Items</title><categories>cs.GT cs.DS</categories><comments>Final version accepted to STOC '10. Incorporates significant reviewer
  comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the first approximation algorithms for the problem
of designing revenue optimal Bayesian incentive compatible auctions when there
are multiple (heterogeneous) items and when bidders can have arbitrary demand
and budget constraints. Our mechanisms are surprisingly simple: We show that a
sequential all-pay mechanism is a 4 approximation to the revenue of the optimal
ex-interim truthful mechanism with discrete correlated type space for each
bidder. We also show that a sequential posted price mechanism is a O(1)
approximation to the revenue of the optimal ex-post truthful mechanism when the
type space of each bidder is a product distribution that satisfies the standard
hazard rate condition. We further show a logarithmic approximation when the
hazard rate condition is removed, and complete the picture by showing that
achieving a sub-logarithmic approximation, even for regular distributions and
one bidder, requires pricing bundles of items. Our results are based on
formulating novel LP relaxations for these problems, and developing generic
rounding schemes from first principles. We believe this approach will be useful
in other Bayesian mechanism design contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4169</identifier>
 <datestamp>2010-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4169</id><created>2009-07-23</created><updated>2010-01-10</updated><authors><author><keyname>Yodaiken</keyname><forenames>Victor</forenames></author></authors><title>Primitive Recursive Presentations of Automata and their Products</title><categories>cs.FL cs.LO</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods for specifying Moore type state machines (transducers) abstractly via
primitive recursive functions and for defining parallel composition via
simultaneous primitive recursion are discussed. The method is mostly of
interest as a concise and convenient way of working with the complex state
systems found in computer programming and engineering, but a short section
indicates connections to algebraic automata theory and the theorem of Krohn and
Rhodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4176</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4176</id><created>2009-07-23</created><authors><author><keyname>Kandregula</keyname><forenames>Renuka</forenames></author></authors><title>The Basic Discrete Hilbert Transform with an Information Hiding
  Application</title><categories>cs.CR</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents several experimental findings related to the basic
discrete Hilbert transform. The errors in the use of a finite set of the
transform values have been tabulated for the more commonly used functions. The
error can be quite small and, for example, it is of the order of 10^{-17} for
the chirp signal. The use of the discrete Hilbert transform in hiding
information is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4180</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4180</id><created>2009-07-24</created><authors><author><keyname>Kurlin</keyname><forenames>Vitaliy</forenames></author><author><keyname>Lisitsa</keyname><forenames>Alexei</forenames></author><author><keyname>Potapov</keyname><forenames>Igor</forenames></author><author><keyname>Saleh</keyname><forenames>Rafiq</forenames></author></authors><title>On Descriptional Complexity of the Planarity Problem for Gauss Words</title><categories>cs.FL cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the descriptional complexity of knot theoretic
problems and show upper bounds for planarity problem of signed and unsigned
knot diagrams represented by Gauss words. Since a topological equivalence of
knots can involve knot diagrams with arbitrarily many crossings then Gauss
words will be considered as strings over an infinite (unbounded) alphabet. For
establishing the upper bounds on recognition of knot properties, we study these
problems in a context of automata models over an infinite alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4230</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4230</id><created>2009-07-24</created><updated>2010-12-23</updated><authors><author><keyname>Bras-Amor&#xf3;s</keyname><forenames>Maria</forenames></author><author><keyname>Stokes</keyname><forenames>Klara</forenames></author></authors><title>The Semigroup of Combinatorial Configurations</title><categories>cs.DM</categories><comments>Title changed, article shortened</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A (v,b,r,k) combinatorial configuration is a (r,k)-biregular bipartite graph
with v vertices on the left and b vertices on the right and with no cycle of
length 4. Combinatorial configurations have become very important for some
cryptographic applications to sensor networks and to peer-to-peer communities.
Configurable tuples are those tuples (v,b,r,k) for which a (v,b,r,k)
combinatorial configuration exists. It is proved in this work that the set of
configurable tuples with fixed r and k has the structure of a numerical
semigroup. The numerical semigroup is completely described for r=2 and r=3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4251</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4251</id><created>2009-07-24</created><authors><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author><author><keyname>Dai</keyname><forenames>Lin</forenames></author></authors><title>Buffered Aloha with K-Exponential Backoff -- Part I: Stability and
  Throughput Analysis</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This two-part paper series studies the performance of buffered Aloha networks
with K-Exponential Backoff collision resolution algorithms. Part I focuses on
stability and throughput analysis and Part II presents the delay analysis.
  In Part I, the buffered Aloha network is modeled as a multi-queue
single-server system. We adopt a widely used approach in packet switching
systems to decompose the multi-queue system into independent first-in-first-out
(FIFO) queues, which are hinged together by the probability of success of
head-of-line (HOL) packets. A unified method is devised to tackle the stability
and throughput problems of K-Exponential Backoff with any cutoff phase K. We
demonstrate that a network with K-Exponential Backoff can be stabilized if the
retransmission factor q is properly selected. The stable region of q is
characterized and illustrated via examples of Geometric Retransmission (K=1)
and Exponential Backoff (K=infinity). With an increasing number of nodes n, we
show that the stable region of Geometric Retransmission rapidly shrinks, and
vanishes as n goes to infinity. In contrast, the stable region of Exponential
Backoff does not vary with the network population n, implying that a stable
throughput can be achieved in networks with Exponential Backoff even with an
infinite number of nodes. All the analytical results presented in this paper
series are verified by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4254</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4254</id><created>2009-07-24</created><authors><author><keyname>Dai</keyname><forenames>Lin</forenames></author><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author></authors><title>Buffered Aloha with K-Exponential Backoff -- Part II: Delay Analysis</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the delay analysis for buffered Aloha networks with
K-Exponential Backoff. Mean access delay and mean queueing delay are derived
and demonstrated via the examples of Geometric Retransmission (K=1) and
Exponential Backoff (K=infinity). The comparison shows that higher delay is
incurred with Geometric Retransmission when the aggregate input rate is small,
and the delay gap is enlarged as the number of nodes n increases. With a high
traffic input rate, however, the delay performance with Exponential Backoff
severely deteriorates. The mean queueing delay will be unbounded if the
aggregate input rate exceeds 0.3.
  We also extend the analysis to the contention-window-based backoff model
which is widely adopted in practical MAC protocols. It will be revealed that
both the retransmission-probability-based and the contention-window-based
models exhibit the same stable region and achieve similar queueing performance
in most cases, which justifies the intuition that was taken but remained
unverified in previous studies: the retransmission-probability-based backoff
model can serve as a good approximation of the contention-window-based one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4273</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4273</id><created>2009-07-24</created><authors><author><keyname>Gammel</keyname><forenames>Berndt M.</forenames></author><author><keyname>Mangard</keyname><forenames>Stefan</forenames></author></authors><title>On the Duality of Probing and Fault Attacks</title><categories>cs.CR</categories><journal-ref>Cryptology ePrint Archive, Report 2009/352</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we investigate the problem of simultaneous privacy and integrity
protection in cryptographic circuits. We consider a white-box scenario with a
powerful, yet limited attacker. A concise metric for the level of probing and
fault security is introduced, which is directly related to the capabilities of
a realistic attacker. In order to investigate the interrelation of probing and
fault security we introduce a common mathematical framework based on the
formalism of information and coding theory. The framework unifies the known
linear masking schemes. We proof a central theorem about the properties of
linear codes which leads to optimal secret sharing schemes. These schemes
provide the lower bound for the number of masks needed to counteract an
attacker with a given strength. The new formalism reveals an intriguing duality
principle between the problems of probing and fault security, and provides a
unified view on privacy and integrity protection using error detecting codes.
Finally, we introduce a new class of linear tamper-resistant codes. These are
eligible to preserve security against an attacker mounting simultaneous probing
and fault attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4283</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4283</id><created>2009-07-24</created><authors><author><keyname>Dawar</keyname><forenames>Anuj</forenames></author><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author></authors><title>Domination Problems in Nowhere-Dense Classes of Graphs</title><categories>cs.DS cs.DM</categories><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the parameterized complexity of generalisations and variations
of the dominating set problem on classes of graphs that are nowhere dense. In
particular, we show that the distance-d dominating-set problem, also known as
the (k,d)-centres problem, is fixed-parameter tractable on any class that is
nowhere dense and closed under induced subgraphs. This generalises known
results about the dominating set problem on H-minor free classes, classes with
locally excluded minors and classes of graphs of bounded expansion. A key
feature of our proof is that it is based simply on the fact that these graph
classes are uniformly quasi-wide, and does not rely on a structural
decomposition. Our result also establishes that the distance-d dominating-set
problem is FPT on classes of bounded expansion, answering a question of Ne{\v
s}et{\v{r}}il and Ossona de Mendez.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4296</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4296</id><created>2009-07-24</created><updated>2011-11-21</updated><authors><author><keyname>Caron</keyname><forenames>Pascal</forenames></author><author><keyname>Flouret</keyname><forenames>Marianne</forenames></author></authors><title>Algorithms for Glushkov K-graphs</title><categories>cs.FL</categories><comments>31 pages, 20 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automata arising from the well known conversion of regular expression to
non deterministic automata have rather particular transition graphs. We refer
to them as the Glushkov graphs, to honour his nice expression-to-automaton
algorithmic short cut (On a synthesis algorithm for abstract automata, Ukr.
Matem. Zhurnal, 12(2):147-156, 1960, In Russian). The Glushkov graphs have been
characterized (P. Caron and D. Ziadi, Characterization of Glushkov automata.
Theoret. Comput. Sci., 233(1-2):75-90, 2000) in terms of simple graph
theoretical properties and certain reduction rules. We show how to carry, under
certain restrictions, this characterization over to the weighted Glushkov
graphs. With the weights in a semiring K, they are defined as the transition
Glushkov K-graphs of the Weighted Finite Automata (WFA) obtained by the
generalized Glushkov construction (P. Caron and M. Flouret, Glushkov
construction for series: the non commutative case, Internat. J. Comput. Math.,
80(4):457-472, 2003) from the K-expressions. It works provided that the
semiring K is factorial and the K-expressions are in the so called star normal
form (SNF) of Bruggeman-Klein (Regular expressions into finite automata,
Theoret. Comput. Sci., 120(2):197-213, 1993) The restriction to the factorial
semiring ensures to obtain algorithms. The restriction to the SNF would not be
necessary if every K-expressions were equivalent to some with the same litteral
length, as it is the case for the boolean semiring B but remains an open
question for a general K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4311</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4311</id><created>2009-07-24</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Kleiman</keyname><forenames>Elena</forenames></author><author><keyname>Mestre</keyname><forenames>Julian</forenames></author></authors><title>Parametric packing of selfish items and the subset sum algorithm</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subset sum algorithm is a natural heuristic for the classical Bin Packing
problem: In each iteration, the algorithm finds among the unpacked items, a
maximum size set of items that fits into a new bin. More than 35 years after
its first mention in the literature, establishing the worst-case performance of
this heuristic remains, surprisingly, an open problem.
  Due to their simplicity and intuitive appeal, greedy algorithms are the
heuristics of choice of many practitioners. Therefore, better understanding
simple greedy heuristics is, in general, an interesting topic in its own right.
Very recently, Epstein and Kleiman (Proc. ESA 2008) provided another incentive
to study the subset sum algorithm by showing that the Strong Price of Anarchy
of the game theoretic version of the bin-packing problem is precisely the
approximation ratio of this heuristic.
  In this paper we establish the exact approximation ratio of the subset sum
algorithm, thus settling a long standing open problem. We generalize this
result to the parametric variant of the bin packing problem where item sizes
lie on the interval (0,\alpha] for some \alpha \leq 1, yielding tight bounds
for the Strong Price of Anarchy for all \alpha \leq 1. Finally, we study the
pure Price of Anarchy of the parametric Bin Packing game for which we show
nearly tight upper and lower bounds for all \alpha \leq 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4316</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4316</id><created>2009-07-24</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>de Boer</keyname><forenames>Frank S.</forenames></author><author><keyname>Olderog</keyname><forenames>Ernst-R&#xfc;diger</forenames></author></authors><title>Modular Verification of Recursive Programs</title><categories>cs.LO cs.PL</categories><comments>21 pages. appeared in: Languages: From Formal to Natural, Essays
  Dedicated to Nissim Francez on the Occasion of His 65th Birthday. Lecture
  Notes in Computer Science 5533 Springer 2009</comments><acm-class>F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We argue that verification of recursive programs by means of the assertional
method of C.A.R. Hoare can be conceptually simplified using a modular
reasoning. In this approach some properties of the program are established
first and subsequently used to establish other program properties. We
illustrate this approach by providing a modular correctness proof of the
Quicksort program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4354</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4354</id><created>2009-07-24</created><authors><author><keyname>Eads</keyname><forenames>Damian</forenames><affiliation>University of California Santa Cruz</affiliation></author><author><keyname>Rosten</keyname><forenames>Edward</forenames><affiliation>University of Cambridge</affiliation></author><author><keyname>Helmbold</keyname><forenames>David</forenames><affiliation>University of California Santa Cruz</affiliation></author></authors><title>Learning Object Location Predictors with Boosting and Grammar-Guided
  Feature Extraction</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present BEAMER: a new spatially exploitative approach to learning object
detectors which shows excellent results when applied to the task of detecting
objects in greyscale aerial imagery in the presence of ambiguous and noisy
data. There are four main contributions used to produce these results. First,
we introduce a grammar-guided feature extraction system, enabling the
exploration of a richer feature space while constraining the features to a
useful subset. This is specified with a rule-based generative grammar crafted
by a human expert. Second, we learn a classifier on this data using a newly
proposed variant of AdaBoost which takes into account the spatially correlated
nature of the data. Third, we perform another round of training to optimize the
method of converting the pixel classifications generated by boosting into a
high quality set of (x, y) locations. Lastly, we carefully define three common
problems in object detection and define two evaluation criteria that are
tightly matched to these problems. Major strengths of this approach are: (1) a
way of randomly searching a broad feature space, (2) its performance when
evaluated on well-matched evaluation criteria, and (3) its use of the location
prediction domain to learn object detectors as well as to generate detections
that perform well on several tasks: object counting, tracking, and target
detection. We demonstrate the efficacy of BEAMER with a comprehensive
experimental evaluation on a challenging data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4356</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4356</id><created>2009-07-24</created><authors><author><keyname>Azar</keyname><forenames>Yossi</forenames></author><author><keyname>Birnbaum</keyname><forenames>Benjamin</forenames></author><author><keyname>Celis</keyname><forenames>L. Elisa</forenames></author><author><keyname>Devanur</keyname><forenames>Nikhil R.</forenames></author><author><keyname>Peres</keyname><forenames>Yuval</forenames></author></authors><title>Convergence of Local Dynamics to Balanced Outcomes in Exchange Networks</title><categories>cs.GT cs.DS</categories><comments>Full version of FOCS 2009 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bargaining games on exchange networks have been studied by both economists
and sociologists. A Balanced Outcome for such a game is an equilibrium concept
that combines notions of stability and fairness. In a recent paper, Kleinberg
and Tardos introduced balanced outcomes to the computer science community and
provided a polynomial-time algorithm to compute the set of such outcomes. Their
work left open a pertinent question: are there natural, local dynamics that
converge quickly to a balanced outcome? In this paper, we provide a partial
answer to this question by showing that simple edge-balancing dynamics converge
to a balanced outcome whenever one exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4364</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4364</id><created>2009-07-24</created><updated>2009-07-25</updated><authors><author><keyname>Song</keyname><forenames>Miao</forenames></author></authors><title>Dynamic Deformation of Uniform Elastic Two-Layer Objects</title><categories>cs.GR</categories><comments>96 pages, 46 pages; master's thesis; August 2007; also available at
  http://clues.concordia.ca/record=b2343207~S0</comments><acm-class>I.3.7; I.3.5; I.3.6</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This thesis presents a two-layer uniform facet elastic object for real-time
simulation based on physics modeling method. It describes the elastic object
procedural modeling algorithm with particle system from the simplest
one-dimensional object, to more complex two-dimensional and three-dimensional
objects.
  The double-layered elastic object consists of inner and outer elastic mass
spring surfaces and compressible internal pressure. The density of the inner
layer can be set different from the density of the outer layer; the motion of
the inner layer can be opposite to the motion of the outer layer. These special
features, which cannot be achieved by a single layered object, result in
improved imitation of a soft body, such as tissue's liquidity non-uniform
deformation. The construction of the double-layered elastic object is closer to
the real tissue's physical structure.
  The inertial behavior of the elastic object is well illustrated in
environments with gravity and collisions with walls, ceiling, and floor. The
collision detection is defined by elastic collision penalty method and the
motion of the object is guided by the Ordinary Differential Equation
computation.
  Users can interact with the modeled objects, deform them, and observe the
response to their action in real time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4385</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4385</id><created>2009-07-24</created><authors><author><keyname>Bachrach</keyname><forenames>Yoram</forenames></author><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Meir</keyname><forenames>Reshef</forenames></author><author><keyname>Pasechnik</keyname><forenames>Dmitrii</forenames></author><author><keyname>Zuckerman</keyname><forenames>Michael</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author><author><keyname>Rosenschein</keyname><forenames>Jeffrey S.</forenames></author></authors><title>The Cost of Stability in Coalitional Games</title><categories>cs.GT cs.AI cs.CC</categories><comments>20 pages; will be presented at SAGT'09</comments><acm-class>F.2.2; G.1.6; I.2.8</acm-class><journal-ref>Proceedings of SAGT 2009, LNCS, 5814, 122-134</journal-ref><doi>10.1007/978-3-642-04645-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key question in cooperative game theory is that of coalitional stability,
usually captured by the notion of the \emph{core}--the set of outcomes such
that no subgroup of players has an incentive to deviate. However, some
coalitional games have empty cores, and any outcome in such a game is unstable.
  In this paper, we investigate the possibility of stabilizing a coalitional
game by using external payments. We consider a scenario where an external
party, which is interested in having the players work together, offers a
supplemental payment to the grand coalition (or, more generally, a particular
coalition structure). This payment is conditional on players not deviating from
their coalition(s). The sum of this payment plus the actual gains of the
coalition(s) may then be divided among the agents so as to promote stability.
We define the \emph{cost of stability (CoS)} as the minimal external payment
that stabilizes the game.
  We provide general bounds on the cost of stability in several classes of
games, and explore its algorithmic properties. To develop a better intuition
for the concepts we introduce, we provide a detailed algorithmic study of the
cost of stability in weighted voting games, a simple but expressive class of
games which can model decision-making in political bodies, and cooperation in
multiagent settings. Finally, we extend our model and results to games with
coalition structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4426</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4426</id><created>2009-07-25</created><authors><author><keyname>Frenz</keyname><forenames>Christopher M.</forenames></author><author><keyname>Peters</keyname><forenames>Steve</forenames></author><author><keyname>Julien</keyname><forenames>Wilson</forenames></author></authors><title>Evolution of Digital Logic Functionality via a Genetic Algorithm</title><categories>cs.NE</categories><comments>Frenz, C.M., Peters, S., Julien, W. (2009) Evolution of Digital Logic
  Functionality via a Genetic Algorithm, Proceedings of the 2009 International
  Conference on Genetic and Evolutionary Methods (GEM 2009), 99-101</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital logic forms the functional basics of most modern electronic equipment
and as such the creation of novel digital logic circuits is an active area of
computer engineering research. This study demonstrates that genetic algorithms
can be used to evolve functionally useful sets of logic gate interconnections
to create useful digital logic circuits. The efficacy of this approach is
illustrated via the evolution of AND, OR, XOR, NOR, and XNOR functionality from
sets of NAND gates, thereby illustrating that evolutionary methods have the
potential be applied to the design of digital electronics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4447</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4447</id><created>2009-07-25</created><authors><author><keyname>Levesque</keyname><forenames>Martin</forenames></author><author><keyname>Elbiaze</keyname><forenames>Halima</forenames></author></authors><title>Graphical Probabilistic Routing Model for OBS Networks with Realistic
  Traffic Scenario</title><categories>cs.NI cs.AI</categories><comments>6 pages</comments><journal-ref>IEEE Globecom 2009, Hawaii, United States, November 30 - December
  4, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Burst contention is a well-known challenging problem in Optical Burst
Switching (OBS) networks. Contention resolution approaches are always reactive
and attempt to minimize the BLR based on local information available at the
core node. On the other hand, a proactive approach that avoids burst losses
before they occur is desirable. To reduce the probability of burst contention,
a more robust routing algorithm than the shortest path is needed. This paper
proposes a new routing mechanism for JET-based OBS networks, called Graphical
Probabilistic Routing Model (GPRM) that selects less utilized links, on a
hop-by-hop basis by using a bayesian network. We assume no wavelength
conversion and no buffering to be available at the core nodes of the OBS
network. We simulate the proposed approach under dynamic load to demonstrate
that it reduces the Burst Loss Ratio (BLR) compared to static approaches by
using Network Simulator 2 (ns-2) on NSFnet network topology and with realistic
traffic matrix. Simulation results clearly show that the proposed approach
outperforms static approaches in terms of BLR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4468</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4468</id><created>2009-07-26</created><authors><author><keyname>Sukhov</keyname><forenames>A. M.</forenames></author><author><keyname>Kuznetsova</keyname><forenames>N.</forenames></author></authors><title>What type of distribution for packet delay in a global network should be
  used in the control theory?</title><categories>cs.NI</categories><comments>5 pages, 2 figures</comments><acm-class>I.2.8; C.2.5</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper correspondence between experimental data for packet delay and
two theoretical types of distribution is investigated. Calculations have shown
that the exponential distribution describes the data on network delay better,
than truncated normal distribution. Precision experimental data to within
microseconds are gathered by means of the RIPE Test Box. In addition to exact
measurements the data gathered by means of the utility {\em ping} has been
parsed that has not changed the main result. As a result, the equation for an
exponential distribution, in the best way describing process of packet delay in
a TCP/IP based network is written. The search algorithm for key parameters as
for normal, and an exponential distribution is resulted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4471</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4471</id><created>2009-07-26</created><updated>2009-09-17</updated><authors><author><keyname>Zivic</keyname><forenames>Natasa</forenames></author></authors><title>Strategies and performances of Soft Input Decryption</title><categories>cs.IT cs.CR math.IT</categories><comments>International Journal of Computer science and Information security,
  12 pages, IJCSIS Volume 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes performance aspects of Soft Input Decryption and L
values. Soft Input Decryption is a novel method which uses L values (soft
output) of a SISO channel decoder for the correction of input of Soft Input
Decryption (SID blocks) which have been modified during the transmission over a
noisy channel. The method is based on the combination of cryptography and
channel coding improving characteristics of both of them. The algorithm,
strategies and scenarios of Soft Input Decryption are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4477</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4477</id><created>2009-07-26</created><updated>2009-09-11</updated><authors><author><keyname>Tzevelekos</keyname><forenames>Nikos</forenames></author></authors><title>Full abstraction for nominal general references</title><categories>cs.PL cs.LO</categories><acm-class>D.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (September
  11, 2009) lmcs:918</journal-ref><doi>10.2168/LMCS-5(3:8)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game semantics has been used with considerable success in formulating fully
abstract semantics for languages with higher-order procedures and a wide range
of computational effects. Recently, nominal games have been proposed for
modelling functional languages with names. These are ordinary, stateful games
cast in the theory of nominal sets developed by Pitts and Gabbay. Here we take
nominal games one step further, by developing a fully abstract semantics for a
language with nominal general references.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4488</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4488</id><created>2009-07-26</created><updated>2009-08-28</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Lampis</keyname><forenames>Michael</forenames></author><author><keyname>Mitsou</keyname><forenames>Valia</forenames></author></authors><title>Vertex Cover Problem Parameterized Above and Below Tight Bounds</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the well-known Vertex Cover problem parameterized above and below
tight bounds. We show that two of the parameterizations (both were suggested by
Mahajan, Raman and Sikdar, J. Computer and System Sciences, 75(2):137--153,
2009) are fixed-parameter tractable and two other parameterizations are
W[1]-hard (one of them is, in fact, W[2]-hard).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4509</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4509</id><created>2009-07-26</created><authors><author><keyname>de Paiva</keyname><forenames>Gilberto</forenames></author></authors><title>Pattern Recognition Theory of Mind</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I propose that pattern recognition, memorization and processing are key
concepts that can be a principle set for the theoretical modeling of the mind
function. Most of the questions about the mind functioning can be answered by a
descriptive modeling and definitions from these principles. An understandable
consciousness definition can be drawn based on the assumption that a pattern
recognition system can recognize its own patterns of activity. The principles,
descriptive modeling and definitions can be a basis for theoretical and applied
research on cognitive sciences, particularly at artificial intelligence
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4521</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4521</id><created>2009-07-27</created><authors><author><keyname>Gutman</keyname><forenames>Igor</forenames></author><author><keyname>Ezri</keyname><forenames>Doron</forenames></author><author><keyname>Wulich</keyname><forenames>Dov</forenames></author></authors><title>Grassmannian Beamforming for MIMO-OFDM Systems with Frequency and
  Spatially Correlated Channels Using Huffman Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple input multiple output (MIMO) precoding is an efficient scheme that
may significantly enhance the communication link. However, this enhancement
comes with a cost. Many precoding schemes require channel knowledge at the
transmitter that is obtained through feedback from the receiver. Focusing on
the natural common fusion of orthogonal frequency division multiplexing (OFDM)
and MIMO, we exploit the channel correlation in the frequency and spatial
domain to reduce the required feedback rate in a frequency division duplex
(FDD) system. The proposed feedback method is based on Huffman coding and is
employed here for the single stream case. The method leads to a significant
reduction in the required feedback rate, without any loss in performance. The
proposed method may be extended to the multi-stream case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4531</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4531</id><created>2009-07-27</created><authors><author><keyname>Luo</keyname><forenames>Zhaohua</forenames></author></authors><title>Clone Theory and Algebraic Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of a clone is central to many branches of mathematics, such as
universal algebra, algebraic logic, and lambda calculus. Abstractly a clone is
a category with two objects such that one is a countably infinite power of the
other. Left and right algebras over a clone are covariant and contravariant
functors from the category to that of sets respectively. In this paper we show
that first-order logic can be studied effectively using the notions of right
and left algebras over a clone. It is easy to translate the classical treatment
of logic into our setting and prove all the fundamental theorems of first-order
theory algebraically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4547</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4547</id><created>2009-07-27</created><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author></authors><title>Quotient Complexity of Regular Languages</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 17-28</journal-ref><doi>10.4204/EPTCS.3.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past research on the state complexity of operations on regular languages
is examined, and a new approach based on an old method (derivatives of regular
expressions) is presented. Since state complexity is a property of a language,
it is appropriate to define it in formal-language terms as the number of
distinct quotients of the language, and to call it &quot;quotient complexity&quot;. The
problem of finding the quotient complexity of a language f(K,L) is considered,
where K and L are regular languages and f is a regular operation, for example,
union or concatenation. Since quotients can be represented by derivatives, one
can find a formula for the typical quotient of f(K,L) in terms of the quotients
of K and L. To obtain an upper bound on the number of quotients of f(K,L) all
one has to do is count how many such quotients are possible, and this makes
automaton constructions unnecessary. The advantages of this point of view are
illustrated by many examples. Moreover, new general observations are presented
to help in the estimation of the upper bounds on quotient complexity of regular
operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4554</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4554</id><created>2009-07-27</created><authors><author><keyname>Jack</keyname><forenames>John</forenames><affiliation>Louisiana Tech University</affiliation></author><author><keyname>Paun</keyname><forenames>Andrei</forenames><affiliation>Louisiana Tech University, INCDSB, UPM</affiliation></author></authors><title>The Nondeterministic Waiting Time Algorithm: A Review</title><categories>cs.FL cs.OH</categories><journal-ref>EPTCS 3, 2009, pp. 29-46</journal-ref><doi>10.4204/EPTCS.3.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present briefly the Nondeterministic Waiting Time algorithm. Our technique
for the simulation of biochemical reaction networks has the ability to mimic
the Gillespie Algorithm for some networks and solutions to ordinary
differential equations for other networks, depending on the rules of the
system, the kinetic rates and numbers of molecules. We provide a full
description of the algorithm as well as specifics on its implementation. Some
results for two well-known models are reported. We have used the algorithm to
explore Fas-mediated apoptosis models in cancerous and HIV-1 infected T cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4561</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4561</id><created>2009-07-27</created><authors><author><keyname>Sure</keyname><forenames>York</forenames></author></authors><title>Fact Sheet on Semantic Web</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The report gives an overview about activities on the topic Semantic Web. It
has been released as technical report for the project &quot;KTweb -- Connecting
Knowledge Technologies Communities&quot; in 2003.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4573</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4573</id><created>2009-07-27</created><updated>2011-08-22</updated><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>Solving MAX-r-SAT Above a Tight Lower Bound</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an exact algorithm that decides, for every fixed $r \geq 2$ in
time $O(m) + 2^{O(k^2)}$ whether a given multiset of $m$ clauses of size $r$
admits a truth assignment that satisfies at least $((2^r-1)m+k)/2^r$ clauses.
Thus \textsc{Max-$r$-Sat} is fixed-parameter tractable when parameterized by
the number of satisfied clauses above the tight lower bound $(1-2^{-r})m$. This
solves an open problem of Mahajan et al. (J. Comput. System Sci., 75, 2009).
  Our algorithm is based on a polynomial-time data reduction procedure that
reduces a problem instance to an equivalent algebraically represented problem
with $O(k^2)$ variables. This is done by representing the instance as an
appropriate polynomial, and by applying a probabilistic argument combined with
some simple tools from Harmonic analysis to show that if the polynomial cannot
be reduced to one of size $O(k^2)$, then there is a truth assignment satisfying
the required number of clauses.
  We introduce a new notion of bikernelization from a parameterized problem to
another one and apply it to prove that the above-mentioned parameterized
\textsc{Max-$r$-Sat} admits a polynomial-size kernel.
  Combining another probabilistic argument with tools from graph matching
theory and signed graphs, we show that if an instance of \textsc{Max-2-Sat}
with $m$ clauses has at least $3k$ variables after application of certain
polynomial time reduction rules to it, then there is a truth assignment that
satisfies at least $(3m+k)/4$ clauses.
  We also outline how the fixed-parameter tractability and polynomial-size
kernel results on \textsc{Max-$r$-Sat} can be extended to more general families
of Boolean Constraint Satisfaction Problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4576</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4576</id><created>2009-07-27</created><authors><author><keyname>Pribavkina</keyname><forenames>E. V.</forenames></author></authors><title>Slowly synchronizing automata with zero and incomplete sets</title><categories>cs.FL</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using combinatorial properties of incomplete sets in a free monoid we
construct a series of n-state deterministic automata with zero whose shortest
synchronizing word has length n^2/4+n/2-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4583</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4583</id><created>2009-07-27</created><authors><author><keyname>Durand</keyname><forenames>Fabien</forenames><affiliation>LAMFA</affiliation></author><author><keyname>Rigo</keyname><forenames>Michel</forenames></author></authors><title>Syndeticity and independent substitutions</title><categories>math.CO cs.DM</categories><proxy>ccsd hal-00407667</proxy><msc-class>11B85, 68R15, 68Q45</msc-class><journal-ref>Advances in Applied Mathematics, 42 (2009) 1-22</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We associate in a canonical way a substitution to any abstract numeration
system built on a regular language. In relationship with the growth order of
the letters, we define the notion of two independent substitutions. Our main
result is the following. If a sequence $x$ is generated by two independent
substitutions, at least one being of exponential growth, then the factors of
$x$ appearing infinitely often in $x$ appear with bounded gaps. As an
application, we derive an analogue of Cobham's theorem for two independent
substitutions (or abstract numeration systems) one with polynomial growth, the
other being exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4622</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4622</id><created>2009-07-25</created><authors><author><keyname>Vecchiola</keyname><forenames>Christian</forenames></author><author><keyname>Chu</keyname><forenames>Xingchen</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Aneka: A Software Platform for .NET-based Cloud Computing</title><categories>cs.DC cs.CE cs.NI cs.OS cs.PL cs.SE</categories><comments>30 pages, 10 figures</comments><report-no>GRIDS-TR-2009-4, Grid Computing and Distributed Systems Laboratory,
  The University of Melbourne, Australia, May 25, 2009</report-no><acm-class>C.1.4; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aneka is a platform for deploying Clouds developing applications on top of
it. It provides a runtime environment and a set of APIs that allow developers
to build .NET applications that leverage their computation on either public or
private clouds. One of the key features of Aneka is the ability of supporting
multiple programming models that are ways of expressing the execution logic of
applications by using specific abstractions. This is accomplished by creating a
customizable and extensible service oriented runtime environment represented by
a collection of software containers connected together. By leveraging on these
architecture advanced services including resource reservation, persistence,
storage management, security, and performance monitoring have been implemented.
On top of this infrastructure different programming models can be plugged to
provide support for different scenarios as demonstrated by the engineering,
life science, and industry applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4640</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4640</id><created>2009-07-27</created><authors><author><keyname>Nakata</keyname><forenames>Keiko</forenames></author><author><keyname>Hasegawa</keyname><forenames>Masahito</forenames></author></authors><title>Small-step and big-step semantics for call-by-need</title><categories>cs.PL</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present natural semantics for acyclic as well as cyclic call-by-need
lambda calculi, which are proved equivalent to the reduction semantics given by
Ariola and Felleisen. The natural semantics are big-step and use global heaps,
where evaluation is suspended and memorized. The reduction semantics are
small-step and evaluation is suspended and memorized locally in let-bindings.
Thus two styles of formalization describe the call-by-need strategy from
different angles.
  The natural semantics for the acyclic calculus is revised from the previous
presentation by Maraist et al. and its adequacy is ascribed to its
correspondence with the reduction semantics, which has been proved equivalent
to call-by-name by Ariola and Felleisen. The natural semantics for the cyclic
calculus is inspired by that of Launchbury and Sestoft and we state its
adequacy using a denotational semantics in the style of Launchbury; adequacy of
the reduction semantics for the cyclic calculus is in turn ascribed to its
correspondence with the natural semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4653</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4653</id><created>2009-07-27</created><authors><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Distributed MIMO radar using compressive sampling</title><categories>cs.IT math.IT</categories><journal-ref>Proc. 42th Asilomar Conf.Signals, Syst. Comput, pp. 203 - 207,
  Nov. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed MIMO radar is considered, in which the transmit and receive
antennas belong to nodes of a small scale wireless network. The transmit
waveforms could be uncorrelated, or correlated in order to achieve a desirable
beampattern. The concept of compressive sampling is employed at the receive
nodes in order to perform direction of arrival (DOA) estimation. According to
the theory of compressive sampling, a signal that is sparse in some domain can
be recovered based on far fewer samples than required by the Nyquist sampling
theorem. The DOAs of targets form a sparse vector in the angle space, and
therefore, compressive sampling can be applied for DOA estimation. The proposed
approach achieves the superior resolution of MIMO radar with far fewer samples
than other approaches. This is particularly useful in a distributed scenario,
in which the results at each receive node need to be transmitted to a fusion
center.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4667</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4667</id><created>2009-07-27</created><authors><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>Further applications of a power series method for pattern avoidance</title><categories>math.CO cs.FL</categories><comments>7 pages</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In combinatorics on words, a word w over an alphabet Sigma is said to avoid a
pattern p over an alphabet Delta if there is no factor x of w and no
non-erasing morphism h from Delta^* to Sigma^* such that h(p) = x. Bell and Goh
have recently applied an algebraic technique due to Golod to show that for a
certain wide class of patterns p there are exponentially many words of length n
over a 4-letter alphabet that avoid p. We consider some further consequences of
their work. In particular, we show that any pattern with k variables of length
at least 4^k is avoidable on the binary alphabet. This improves an earlier
bound due to Cassaigne and Roth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4697</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4697</id><created>2009-07-27</created><updated>2013-09-25</updated><authors><author><keyname>Saoudi</keyname><forenames>Samir</forenames></author><author><keyname>Ait-Idir</keyname><forenames>Tarik</forenames></author><author><keyname>Mochida</keyname><forenames>Yukou</forenames></author></authors><title>Unsupervised and Non Parametric Iterative Soft Bit Error Rate Estimation
  for Any Communications System</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author because it was not
  accepted as it is for publication in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of unsupervised soft bit error rate (BER)
estimation for any communications system, where no prior knowledge either about
transmitted information bits, or the transceiver scheme is available. We show
that the problem of BER estimation is equivalent to estimating the conditional
probability density functions (pdf)s of soft channel/receiver outputs. Assuming
that the receiver has no analytical model of soft observations, we propose a
non parametric Kernel-based pdf estimation technique, and show that the
resulting BER estimator is asymptotically unbiased and point-wise consistent.
We then introduce an iterative Stochastic Expectation Maximization (EM)
algorithm for the estimation of both a priori and a posteriori probabilities of
transmitted information bits, and the classification of soft observations
according to transmitted bit values. These inputs serve in the iterative
Kernel-based estimation procedure of conditional pdfs. We analyze the
performance of the proposed unsupervised and non parametric BER estimator in
the framework of a multiuser code division multiple access (CDMA) system with
single user detection, and show that attractive performance are achieved
compared with conventional Monte Carlo (MC)-aided techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4705</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4705</id><created>2009-07-27</created><authors><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Compressive Sensing for MIMO Radar</title><categories>cs.IT math.IT</categories><journal-ref>Proc. IEEE International Conf. Acoust.Speech Signal Process, pp.
  3017 - 3020, Apr. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input multiple-output (MIMO) radar systems have been shown to
achieve superior resolution as compared to traditional radar systems with the
same number of transmit and receive antennas. This paper considers a
distributed MIMO radar scenario, in which each transmit element is a node in a
wireless network, and investigates the use of compressive sampling for
direction-of-arrival (DOA) estimation. According to the theory of compressive
sampling, a signal that is sparse in some domain can be recovered based on far
fewer samples than required by the Nyquist sampling theorem. The DOA of targets
form a sparse vector in the angle space, and therefore, compressive sampling
can be applied for DOA estimation. The proposed approach achieves the superior
resolution of MIMO radar with far fewer samples than other approaches. This is
particularly useful in a distributed scenario, in which the results at each
receive node need to be transmitted to a fusion center for further processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4740</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4740</id><created>2009-07-27</created><authors><author><keyname>Haque</keyname><forenames>Asif-ul</forenames></author><author><keyname>Ginsparg</keyname><forenames>Paul</forenames></author></authors><title>Positional Effects on Citation and Readership in arXiv</title><categories>cs.DL astro-ph.IM hep-ph hep-th physics.soc-ph</categories><comments>28 pages, to appear in JASIST</comments><journal-ref>JASIST 60, 2203-2218 (Nov 2009)</journal-ref><doi>10.1002/asi.21166</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  arXiv.org mediates contact with the literature for entire scholarly
communities, both through provision of archival access and through daily email
and web announcements of new materials, potentially many screenlengths long. We
confirm and extend a surprising correlation between article position in these
initial announcements, ordered by submission time, and later citation impact,
due primarily to intentional &quot;self-promotion&quot; on the part of authors. A pure
&quot;visibility&quot; effect was also present: the subset of articles accidentally in
early positions fared measurably better in the long-term citation record than
those lower down. Astrophysics articles announced in position 1, for example,
overall received a median number of citations 83\% higher, while those there
accidentally had a 44\% visibility boost. For two large subcommunities of
theoretical high energy physics, hep-th and hep-ph articles announced in
position 1 had median numbers of citations 50\% and 100\% larger than for
positions 5--15, and the subsets there accidentally had visibility boosts of
38\% and 71\%.
  We also consider the positional effects on early readership. The median
numbers of early full text downloads for astro-ph, hep-th, and hep-ph articles
announced in position 1 were 82\%, 61\%, and 58\% higher than for lower
positions, respectively, and those there accidentally had medians
visibility-boosted by 53\%, 44\%, and 46\%. Finally, we correlate a variety of
readership features with long-term citations, using machine learning methods,
thereby extending previous results on the predictive power of early readership
in a broader context. We conclude with some observations on impact metrics and
dangers of recommender mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4743</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4743</id><created>2009-07-27</created><authors><author><keyname>Kumar</keyname><forenames>Arun</forenames></author><author><keyname>Saxena</keyname><forenames>Nitesh</forenames></author><author><keyname>Uzun</keyname><forenames>Ersin</forenames></author></authors><title>Alice Meets Bob: A Comparative Usability Study of Wireless Device
  Pairing Methods for a &quot;Two-User&quot; Setting</title><categories>cs.CR cs.HC</categories><comments>16 pages manuscript. Keywords: Wireless Security, Device
  Authentication, Pairing, Usability</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When users want to establish wireless communication between/among their
devices, the channel has to be bootstrapped first. To prevent any malicious
control of or eavesdropping over the communication, the channel is desired to
be authenticated and confidential. The process of setting up a secure
communication channel between two previously unassociated devices is referred
to as &quot;Secure Device Pairing&quot;. When there is no prior security context, e.g.,
shared secrets, common key servers or public key certificates, device pairing
requires user involvement into the process. The idea usually involves
leveraging an auxiliary human-perceptible channel to authenticate the data
exchanged over the insecure wireless channel.
  We observe that the focus of prior research has mostly been limited to
pairing scenarios where a single user controls both the devices. In this paper,
we consider more general and emerging &quot;two-user&quot; scenarios, where two different
users establish pairing between their respective devices. Although a number of
pairing methods exists in the literature, only a handful of those are
applicable to the two-user setting. We present the first study to identify the
methods practical for two-user pairing scenarios, and comparatively evaluate
the usability of these methods. Our results identify methods best-suited for
users, in terms of efficiency, error-tolerance and of course, usability. Our
work sheds light on the applicability and usability of pairing methods for
emerging two-user scenarios, a topic largely ignored so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4760</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4760</id><created>2009-07-27</created><authors><author><keyname>Baier</keyname><forenames>Christel</forenames><affiliation>Technische Universit&#xe4;t Dresden</affiliation></author><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames><affiliation>INRIA Rennes</affiliation></author><author><keyname>Gr&#xf6;&#xdf;er</keyname><forenames>Marcus</forenames><affiliation>Technische Universit&#xe4;t Dresden</affiliation></author></authors><title>Probabilistic Automata over Infinite Words: Expressiveness, Efficiency,
  and Decidability</title><categories>cs.FL</categories><acm-class>F.4.3</acm-class><journal-ref>EPTCS 3, 2009, pp. 3-16</journal-ref><doi>10.4204/EPTCS.3.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic omega-automata are variants of nondeterministic automata for
infinite words where all choices are resolved by probabilistic distributions.
Acceptance of an infinite input word can be defined in different ways: by
requiring that (i) the probability for the accepting runs is positive (probable
semantics), or (ii) almost all runs are accepting (almost-sure semantics), or
(iii) the probability measure of the accepting runs is greater than a certain
threshold (threshold semantics). The underlying notion of an accepting run can
be defined as for standard omega-automata by means of a Buechi condition or
other acceptance conditions, e.g., Rabin or Streett conditions. In this paper,
we put the main focus on the probable semantics and provide a summary of the
fundamental properties of probabilistic omega-automata concerning
expressiveness, efficiency, and decision problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4764</identifier>
 <datestamp>2011-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4764</id><created>2009-07-27</created><updated>2011-07-07</updated><authors><author><keyname>Shokrieh</keyname><forenames>Farbod</forenames></author></authors><title>The monodromy pairing and discrete logarithm on the Jacobian of finite
  graphs</title><categories>math.CO cs.CR math.AG</categories><msc-class>05C50, 14H40, 11Y99</msc-class><journal-ref>J. Math. Cryptol. 4 (2010), 43--56</journal-ref><doi>10.1515/JMC.2010.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every graph has a canonical finite abelian group attached to it. This group
has appeared in the literature under a variety of names including the sandpile
group, critical group, Jacobian group, and Picard group. The construction of
this group closely mirrors the construction of the Jacobian variety of an
algebraic curve. Motivated by this analogy, it was recently suggested by Norman
Biggs that the critical group of a finite graph is a good candidate for doing
discrete logarithm based cryptography. In this paper, we study a bilinear
pairing on this group and show how to compute it. Then we use this pairing to
find the discrete logarithm efficiently, thus showing that the associated
cryptographic schemes are not secure. Our approach resembles the MOV attack on
elliptic curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4775</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4775</id><created>2009-07-27</created><updated>2011-06-29</updated><authors><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Grochow</keyname><forenames>Joshua A.</forenames></author></authors><title>Complexity Classes of Equivalence Problems Revisited</title><categories>cs.CC</categories><comments>21 pages</comments><acm-class>F.1.3; F.1.2; F.1.m</acm-class><journal-ref>Information and Computation 209(4):748-763, April 2011</journal-ref><doi>10.1016/j.ic.2011.01.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To determine if two lists of numbers are the same set, we sort both lists and
see if we get the same result. The sorted list is a canonical form for the
equivalence relation of set equality. Other canonical forms arise in graph
isomorphism algorithms, and the equality of permutation groups given by
generators. To determine if two graphs are cospectral (have the same
eigenvalues), however, we compute their characteristic polynomials and see if
they are the same; the characteristic polynomial is a complete invariant for
the equivalence relation of cospectrality. This is weaker than a canonical
form, and it is not known whether a polynomial-time canonical form for
cospectrality exists. Note that it is a priori possible for an equivalence
relation to be decidable in polynomial time without either a complete invariant
or canonical form.
  Blass and Gurevich (SIAM J. Comput., 1984) ask whether these conditions on
equivalence relations -- having an FP canonical form, having an FP complete
invariant, and simply being in P -- are in fact different. They showed that
this question requires non-relativizing techniques to resolve. Here we extend
their results, and give new connections to probabilistic and quantum
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4803</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4803</id><created>2009-07-27</created><updated>2010-10-05</updated><authors><author><keyname>Allahverdyan</keyname><forenames>Armen E.</forenames></author><author><keyname>Steeg</keyname><forenames>Greg Ver</forenames></author><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author></authors><title>Community Detection with and without Prior Information</title><categories>physics.soc-ph cond-mat.stat-mech cs.CY physics.data-an q-bio.QM</categories><comments>6 pages, 2 figures</comments><journal-ref>Europhysics Letters 90, p.18002, 2010</journal-ref><doi>10.1209/0295-5075/90/18002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of graph partitioning, or clustering, in sparse networks
with prior information about the clusters. Specifically, we assume that for a
fraction $\rho$ of the nodes their true cluster assignments are known in
advance. This can be understood as a semi--supervised version of clustering, in
contrast to unsupervised clustering where the only available information is the
graph structure. In the unsupervised case, it is known that there is a
threshold of the inter--cluster connectivity beyond which clusters cannot be
detected. Here we study the impact of the prior information on the detection
threshold, and show that even minute [but generic] values of $\rho&gt;0$ shift the
threshold downwards to its lowest possible value. For weighted graphs we show
that a small semi--supervising can be used for a non-trivial definition of
communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4810</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4810</id><created>2009-07-27</created><authors><author><keyname>Grossman</keyname><forenames>Robert</forenames></author><author><keyname>Gu</keyname><forenames>Yunhong</forenames></author><author><keyname>Sabala</keyname><forenames>Michal</forenames></author><author><keyname>Bennet</keyname><forenames>Collin</forenames></author><author><keyname>Seidman</keyname><forenames>Jonathan</forenames></author><author><keyname>Mambratti</keyname><forenames>Joe</forenames></author></authors><title>The Open Cloud Testbed: A Wide Area Testbed for Cloud Computing
  Utilizing High Performance Network Services</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a number of cloud platforms and services have been developed for
data intensive computing, including Hadoop, Sector, CloudStore (formerly KFS),
HBase, and Thrift. In order to benchmark the performance of these systems, to
investigate their interoperability, and to experiment with new services based
on flexible compute node and network provisioning capabilities, we have
designed and implemented a large scale testbed called the Open Cloud Testbed
(OCT). Currently the OCT has 120 nodes in four data centers: Baltimore, Chicago
(two locations), and San Diego. In contrast to other cloud testbeds, which are
in small geographic areas and which are based on commodity Internet services,
the OCT is a wide area testbed and the four data centers are connected with a
high performance 10Gb/s network, based on a foundation of dedicated lightpaths.
This testbed can address the requirements of extremely large data streams that
challenge other types of distributed infrastructure. We have also developed
several utilities to support the development of cloud computing systems and
services, including novel node and network provisioning services, a monitoring
system, and a RPC system. In this paper, we describe the OCT architecture and
monitoring system. We also describe some benchmarks that we developed and some
interoperability studies we performed using these benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4815</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4815</id><created>2009-07-27</created><authors><author><keyname>Narayanan</keyname><forenames>Amit</forenames></author></authors><title>A Survey on BGP Issues and Solutions</title><categories>cs.NI</categories><report-no>Rep0352009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BGP is the de facto protocol used for inter-autonomous system routing in the
Internet. Generally speaking, BGP has been proven to be secure, efficient,
scalable, and robust. However, with the rapid evolving of the Internet in the
past few decades, there are increasing concerns about BGS's ability to meet the
needs of the Internet routing. There are two major limitations of BGP which are
its failure to address several key security issues, and some operational
related problems. The design and ubiquity of BGP have complicated past efforts
at securing inter-domain routing. This paper surveys the past work related to
BGP security and operational issues. We explore the limitations and advantages
of proposed solutions in these two limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4852</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4852</id><created>2009-07-28</created><authors><author><keyname>Kafri</keyname><forenames>Oded</forenames></author></authors><title>The Distributions in Nature and Entropy Principle</title><categories>cs.DM physics.data-an</categories><comments>19 pages 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The derivation of the maximum entropy distribution of particles in boxes
yields two kinds of distributions: a &quot;bell-like&quot; distribution and a long-tail
distribution. The first one is obtained when the ratio between particles and
boxes is low, and the second one - when the ratio is high. The obtained long
tail distribution yields correctly the empirical Zipf law, Pareto's 20:80 rule
and Benford's law. Therefore, it is concluded that the long tail and the
&quot;bell-like&quot; distributions are outcomes of the tendency of statistical systems
to maximize entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4870</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4870</id><created>2009-07-28</created><updated>2009-12-21</updated><authors><author><keyname>Naveen</keyname><forenames>K. P.</forenames></author><author><keyname>Kumar</keyname><forenames>A.</forenames></author></authors><title>Tunable locally-optimal geographical forwarding in wireless sensor
  networks with sleep-wake cycling nodes</title><categories>cs.NI</categories><comments>13 Pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless sensor network whose main function is to detect
certain infrequent alarm events, and to forward alarm packets to a base
station, using geographical forwarding. The nodes know their locations, and
they sleep-wake cycle, waking up periodically but not synchronously. In this
situation, when a node has a packet to forward to the sink, there is a
trade-off between how long this node waits for a suitable neighbor to wake up
and the progress the packet makes towards the sink once it is forwarded to this
neighbr. Hence, in choosing a relay node, we consider the problem of minimizing
average delay subject to a constraint on the average progress. By constraint
relaxation, involving a Lagrange multiplier, we formulate this next hop relay
selection problem as a Markov decision process (MDP). The exact optimal
solution (BF (Best Forward)) can be found, but is computationally intensive.
Next, we consider a mathematically simplified model for which the optimal
policy (SF (Simplified Forward)) turns out to be a simple one-step-look-ahead
rule. Simulations show that SF is very close in performance to BF, even for
reasonably small node density. We then study the end-to-end performance of SF
in comparison with two extremal policies: Max Forward (MF), which makes the
maximum possible progress per hop and thus reduces network energy consumption,
and First Forward (FF), which forwards the packet to the first node to wake up,
and thus tends to make end-to-end forwarding delays small. We find that, with
appropriate choice of one hop average progress constraint, SF can be tuned to
provide a favorable trade-off between end-to-end packet delay and the number of
hops in the forwarding path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4876</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4876</id><created>2009-07-28</created><authors><author><keyname>Pathan</keyname><forenames>Mukaddim</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Architecture and Performance Models for QoS-Driven Effective Peering of
  Content Delivery Networks</title><categories>cs.DC cs.NI</categories><comments>31 pages, 19 figures</comments><acm-class>C.2.4</acm-class><journal-ref>Multiagent and Grid Systems, Volume 5, Number 2, Pages: 165-195,
  ISSN: 1574-1702, IOS Press, Amsterdam, The Netherlands, July 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proprietary nature of existing Content Delivery Networks (CDNs) means
they are closed and do not naturally cooperate. A CDN is expected to provide
high performance Internet content delivery through global coverage, which might
be an obstacle for new CDN providers, as well as affecting commercial viability
of existing ones. Finding ways for distinct CDNs to coordinate and cooperate
with other CDNs is necessary to achieve better overall service, as perceived by
end-users, at lower cost. In this paper, we present an architecture to support
peering arrangements between CDNs, based on a Virtual Organization (VO) model.
Our approach promotes peering among providers, while upholding user perceived
performance. This is achieved through proper policy management of negotiated
Service Level Agreements (SLAs) between peers. We also present a Quality of
Service (QoS)-driven performance modeling approach for peering CDNs in order to
predict the user perceived performance. We show that peering between CDNs
upholds user perceived performance by satisfying the target QoS. The
methodology presented in this paper provides CDNs a way to dynamically
distribute user requests to other peers according to different
request-redirection policies. The model-based approach helps an overloaded CDN
to return to a normal state by offloading excess requests to the peers. It also
assists in making concrete QoS guarantee for a CDN provider. Our approach
endeavors to achieve scalability and resource sharing among CDNs through
effective peering in a user transparent manner, thus evolving past the current
landscape where non-cooperative and distinct CDNs exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4877</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4877</id><created>2009-07-28</created><authors><author><keyname>Xiao</keyname><forenames>Liang</forenames></author><author><keyname>Greenstein</keyname><forenames>Larry</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan</forenames></author><author><keyname>Trappe</keyname><forenames>Wade</forenames></author></authors><title>Fingerprints in the Ether: Using the Physical Layer for Wireless
  Authentication</title><categories>cs.CR</categories><comments>5 pages, 10 figures, ICC</comments><journal-ref>ICC, pp. 4646-4651, Glasgow, Scotland, Jun. 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The wireless medium contains domain-specific information that can be used to
complement and enhance traditional security mechanisms. In this paper we
propose ways to exploit the fact that, in a typically rich scattering
environment, the radio channel response decorrelates quite rapidly in space.
Specifically, we describe a physical-layer algorithm that combines channel
probing (M complex frequency response samples over a bandwidth W) with
hypothesis testing to determine whether current and prior communication
attempts are made by the same user (same channel response). In this way,
legitimate users can be reliably authenticated and false users can be reliably
detected. To evaluate the feasibility of our algorithm, we simulate spatially
variable channel responses in real environments using the WiSE ray-tracing
tool; and we analyze the ability of a receiver to discriminate between
transmitters (users) based on their channel frequency responses in a given
office environment. For several rooms in the extremities of the building we
considered, we have confirmed the efficacy of our approach under static channel
conditions. For example, measuring five frequency response samples over a
bandwidth of 100 MHz and using a transmit power of 100 mW, valid users can be
verified with 99% confidence while rejecting false users with greater than 95%
confidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4878</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4878</id><created>2009-07-28</created><authors><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Calheiros</keyname><forenames>Rodrigo N.</forenames></author></authors><title>Modeling and Simulation of Scalable Cloud Computing Environments and the
  CloudSim Toolkit: Challenges and Opportunities</title><categories>cs.DC cs.NI</categories><comments>11 pages, 11 figures</comments><acm-class>C.2.4</acm-class><journal-ref>Proceedings of the 7th High Performance Computing and Simulation
  (HPCS 2009) Conference, Leipzig, Germany, June 21 - 24, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing aims to power the next generation data centers and enables
application service providers to lease data center capabilities for deploying
applications depending on user QoS (Quality of Service) requirements. Cloud
applications have different composition, configuration, and deployment
requirements. Quantifying the performance of resource allocation policies and
application scheduling algorithms at finer details in Cloud computing
environments for different application and service models under varying load,
energy performance (power consumption, heat dissipation), and system size is a
challenging problem to tackle. To simplify this process, in this paper we
propose CloudSim: an extensible simulation toolkit that enables modelling and
simulation of Cloud computing environments. The CloudSim toolkit supports
modelling and creation of one or more virtual machines (VMs) on a simulated
node of a Data Center, jobs, and their mapping to suitable VMs. It also allows
simulation of multiple Data Centers to enable a study on federation and
associated policies for migration of VMs for reliability and automatic scaling
of applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4881</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4881</id><created>2009-07-28</created><authors><author><keyname>M</keyname><forenames>Vipin</forenames></author><author><keyname>R</keyname><forenames>Mohamed Imran K</forenames></author></authors><title>Approximate mechanism for measuring stability of Internet link in
  aggregated Internet pipe</title><categories>cs.NI cs.PF</categories><comments>8 pages, 5 figures</comments><acm-class>C.2.1; C.2.3; C.2.6</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this article we propose a method for measuring internet connection
stability which is fast and has negligible overhead for the process of its
complexity. This method finds a relative value for representing the stability
of internet connections and can also be extended for aggregated internet
connections. The method is documented with help of a real time implementation
and results are shared. This proposed measurement scheme uses HTTP GET method
for each connections. The normalized responses to identified sites like
gateways of ISPs, google.com etc are used for calculating current link
stability. The novelty of the approach is that historic values are used to
calculate overall link stability. In this discussion, we also document a method
to use the calculated values as a dynamic threshold metric. This is used in
routing decisions and for load-balancing each of the connections in an
aggregated bandwidth pipe. This scheme is a very popular practice in aggregated
internet connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4885</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4885</id><created>2009-07-28</created><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Fossorier</keyname><forenames>Marc P. C.</forenames></author></authors><title>Growth Rate of the Weight Distribution of Doubly-Generalized LDPC Codes:
  General Case and Efficient Evaluation</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure. Proc. IEEE Globecom 2009, Hawaii, USA, November 30
  - December 4, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growth rate of the weight distribution of irregular doubly-generalized
LDPC (D-GLDPC) codes is developed and in the process, a new efficient numerical
technique for its evaluation is presented. The solution involves simultaneous
solution of a 4 x 4 system of polynomial equations. This represents the first
efficient numerical technique for exact evaluation of the growth rate, even for
LDPC codes. The technique is applied to two example D-GLDPC code ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4908</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4908</id><created>2009-07-28</created><authors><author><keyname>Xiao</keyname><forenames>Liang</forenames></author><author><keyname>Greenstein</keyname><forenames>Larry</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan</forenames></author><author><keyname>Trappe</keyname><forenames>Wade</forenames></author></authors><title>MIMO-Assisted Channel-Based Authentication in Wireless Networks</title><categories>cs.CR</categories><comments>5 pages, 6 figures, CISS</comments><journal-ref>Proc. Conference on Information Sciences and Systems (CISS), pp.
  642-646, Princeton, NJ, Mar. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input multiple-output (MIMO) techniques allow for multiplexing
and/or diversity gain, and will be widely deployed in future wireless systems.
In this paper, we propose a MIMO-assisted channel-based authentication scheme,
exploiting current channel estimation mechanisms in MIMO systems to detect
spoofing attacks with very low overhead. In this scheme, the use of multiple
antennas provides extra dimensions of channel estimation data, and thus leads
to a &quot;security gain&quot; over single-input single-output (SISO) systems. We
investigate the security gain of MIMO systems in several system configurations
via simulations for a specific real indoor environment using ray-tracing
software. We also discuss the effect of increasing the number of transmit and
receive antennas on the security gain and contrast that to the
diversity/multiplexing gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4919</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4919</id><created>2009-07-28</created><authors><author><keyname>Xiao</keyname><forenames>Liang</forenames></author><author><keyname>Greenstein</keyname><forenames>Larry</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan</forenames></author><author><keyname>Trappe</keyname><forenames>Wade</forenames></author></authors><title>Using the Physical Layer for Wireless Authentication in Time-Variant
  Channels</title><categories>cs.CR</categories><comments>10 pages, 6 figures</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 7, pp.
  2571-2579, Jul. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The wireless medium contains domain-specific information that can be used to
complement and enhance traditional security mechanisms. In this paper we
propose ways to exploit the spatial variability of the radio channel response
in a rich scattering environment, as is typical of indoor environments.
Specifically, we describe a physical-layer authentication algorithm that
utilizes channel probing and hypothesis testing to determine whether current
and prior communication attempts are made by the same transmit terminal. In
this way, legitimate users can be reliably authenticated and false users can be
reliably detected. We analyze the ability of a receiver to discriminate between
transmitters (users) according to their channel frequency responses. This work
is based on a generalized channel response with both spatial and temporal
variability, and considers correlations among the time, frequency and spatial
domains. Simulation results, using the ray-tracing tool WiSE to generate the
time-averaged response, verify the efficacy of the approach under realistic
channel conditions, as well as its capability to work under unknown channel
variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4957</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4957</id><created>2009-07-28</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>Iterative pushdown automata and hyperbolic contour words</title><categories>cs.CG cs.FL</categories><comments>15 pages, 6 figures</comments><acm-class>F.2.2; F.4.1; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give an application of iterated pushdown automata to
contour words of balls and two other domains in infinitely many tilings of the
hyperbolic plane. We also give a similar application for the tiling {5,3,4} of
the hyperbolic 3D space and for the tiling {5,3,3,4} of the hyperbolic 4D space
as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4960</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4960</id><created>2009-07-28</created><authors><author><keyname>Annamalai</keyname><forenames>Muthiah</forenames></author></authors><title>Ezhil: A Tamil Programming Language</title><categories>cs.PL cs.CL</categories><comments>6 pages, Tamil UTF-8 characters</comments><acm-class>D.3.0</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Ezhil is a Tamil language based interpreted procedural programming language.
Tamil keywords and grammar are chosen to make the native Tamil speaker write
programs in the Ezhil system. Ezhil allows easy representation of computer
program closer to the Tamil language logical constructs equivalent to the
conditional, branch and loop statements in modern English based programming
languages. Ezhil is a compact programming language aimed towards Tamil speaking
novice computer users. Grammar for Ezhil and a few example programs are
reported here, from the initial proof-of-concept implementation using the
Python programming language1. To the best of our knowledge, Ezhil language is
the first freely available Tamil programming language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4984</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4984</id><created>2009-07-28</created><authors><author><keyname>Jemaa</keyname><forenames>Yousra Ben</forenames></author><author><keyname>Khanfir</keyname><forenames>Sana</forenames></author></authors><title>Automatic local Gabor Features extraction for face recognition</title><categories>cs.CV</categories><comments>7 pages, International Journal of Computer Science and Information
  Security, IJCSIS, Impact Factor 0.423</comments><journal-ref>IJCSIS July 2009, Volume 3, ISSN 1947 5500</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper a biometric system of face detection and recognition
in color images. The face detection technique is based on skin color
information and fuzzy classification. A new algorithm is proposed in order to
detect automatically face features (eyes, mouth and nose) and extract their
correspondent geometrical points. These fiducial points are described by sets
of wavelet components which are used for recognition. To achieve the face
recognition, we use neural networks and we study its performances for different
inputs. We compare the two types of features used for recognition: geometric
distances and Gabor coefficients which can be used either independently or
jointly. This comparison shows that Gabor coefficients are more powerful than
geometric distances. We show with experimental results how the importance
recognition ratio makes our system an effective tool for automatic face
detection and recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4994</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4994</id><created>2009-07-28</created><authors><author><keyname>Pateriya</keyname><forenames>R. K.</forenames></author><author><keyname>Rana</keyname><forenames>J. L.</forenames></author><author><keyname>Shrivastava</keyname><forenames>S. C.</forenames></author><author><keyname>Patel</keyname><forenames>Jaideep</forenames></author></authors><title>A Proposed Algorithm to improve security &amp; Efficiency of SSL-TLS servers
  using Batch RSA decryption</title><categories>cs.CR</categories><comments>5 pages, International Journal of Computer Science and Information
  Security, IJCSIS, Impact Factor 0.423</comments><journal-ref>IJCSIS July 2009, Volume 3, ISSN 1947 5500</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, Internet becomes the essential part of our lives. Over 90 percent of
the ecommerce is developed on the Internet. A security algorithm became very
necessary for producer client transactions assurance and the financial
applications safety. The rsa algorithm applicability derives from algorithm
properties like confidentiality, safe authentication, data safety and integrity
on the internet. Thus, this kind of networks can have a more easy utilization
by practical accessing from short, medium, even long distance and from
different public places. Rsa encryption in the client side is relatively cheap,
whereas, the corresponding decryption in the server side is expensive because
its private exponent is much larger. Thus ssl tls servers become swamped to
perform public key decryption operations when the simultaneous requests
increase quickly .The batch rsa method is useful for such highly loaded web
server .In our proposed algorithm by reducing the response time and clients
tolerable waiting time an improvement in performance of ssl tls servers can be
done. The proposed algorithm should provide the reasonable response time and
optimizes server performance significantly. At Encryption side, to withstand
many attacks like brute force attack, subtle attack etc. we also adapted a
parameter generation method, which sieve all the parameters strictly, and
filter out every insecure parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.4996</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.4996</id><created>2009-07-28</created><authors><author><keyname>Dong</keyname><forenames>Lun</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Cooperative Jamming for Wireless Physical Layer Security</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures, in Proceedings of IEEE Workshop on Statistical
  Signal Processing (SSP 2009), Cardiff, Wales, UK, Aug. - Sept. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative jamming is an approach that has been recently proposed for
improving physical layer based security for wireless networks in the presence
of an eavesdropper. While the source transmits its message to its destination,
a relay node transmits a jamming signal to create interference at the
eavesdropper. In this paper, a scenario in which the relay is equipped with
multiple antennas is considered. A novel system design is proposed for
determining the antenna weights and transmit power of source and relay, so that
the system secrecy rate is maximized subject to a total transmit power
constraint, or, the transmit power is minimized subject to a secrecy rate
constraint. Since the optimal solutions to these problems are difficult to
obtain, suboptimal closed-form solutions are proposed that introduce an
additional constraint, i.e., the complete nulling of jamming signal at the
destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5016</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5016</id><created>2009-07-28</created><updated>2009-07-29</updated><authors><author><keyname>Gonchigdanzan</keyname><forenames>Hurlee</forenames></author></authors><title>How much does a Hamiltonian cycle weigh?</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate how much Hamiltonian cycles weigh in K_4 and K_5
compare to the total weight of the graph and establish precise estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5024</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5024</id><created>2009-07-28</created><updated>2010-10-14</updated><authors><author><keyname>Kazakopoulos</keyname><forenames>P.</forenames></author><author><keyname>Mertikopoulos</keyname><forenames>P.</forenames></author><author><keyname>Moustakas</keyname><forenames>A. L.</forenames></author><author><keyname>Caire</keyname><forenames>G.</forenames></author></authors><title>Living at the Edge: A Large Deviations Approach to the Outage MIMO
  Capacity</title><categories>cs.IT cond-mat.stat-mech math.IT stat.AP</categories><comments>Accepted for publication, IEEE Transactions on Information Theory
  (2010). Part of this work appears in the Proc. IEEE Information Theory
  Workshop, June 2009, Volos, Greece</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no 4, p. 1984,
  April 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a large deviations approach we calculate the probability distribution
of the mutual information of MIMO channels in the limit of large antenna
numbers. In contrast to previous methods that only focused at the distribution
close to its mean (thus obtaining an asymptotically Gaussian distribution), we
calculate the full distribution, including its tails which strongly deviate
from the Gaussian behavior near the mean. The resulting distribution
interpolates seamlessly between the Gaussian approximation for rates $R$ close
to the ergodic value of the mutual information and the approach of Zheng and
Tse for large signal to noise ratios $\rho$. This calculation provides us with
a tool to obtain outage probabilities analytically at any point in the $(R,
\rho, N)$ parameter space, as long as the number of antennas $N$ is not too
small. In addition, this method also yields the probability distribution of
eigenvalues constrained in the subspace where the mutual information per
antenna is fixed to $R$ for a given $\rho$. Quite remarkably, this eigenvalue
density is of the form of the Marcenko-Pastur distribution with square-root
singularities, and it depends on the values of $R$ and $\rho$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5030</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5030</id><created>2009-07-29</created><updated>2009-09-18</updated><authors><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author><author><keyname>Kern</keyname><forenames>Doris</forenames></author></authors><title>Existence of new inequalities for representable polymatroids</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An Ingletonian polymatroid satisfies, in addition to the polymatroid axioms,
the inequalities of Ingleton (Combin. Math. Appln., 1971). These inequalities
are required for a polymatroid to be representable. It is has been an open
question as to whether these inequalities are also sufficient. Representable
polymatroids are of interest in their own right. They also have a strong
connection to network coding. In particular, the problem of finding the linear
network coding capacity region is equivalent to the characterization of all
representable, entropic polymatroids. In this paper, we describe a new approach
to adhere two polymatroids together to produce a new polymatroid. Using this
approach, we can construct a polymatroid that is not inside the minimal closed
and convex cone containing all representable polymatroids. This polymatroid is
proved to satisfy not only the Ingleton inequalities, but also the recently
reported inequalities of Dougherty, Freiling and Zeger. A direct consequence is
that these inequalities are not sufficient to characterize representable
polymatroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5032</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5032</id><created>2009-07-28</created><authors><author><keyname>Haim</keyname><forenames>Shai</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Restart Strategy Selection using Machine Learning Techniques</title><categories>cs.AI</categories><comments>14 pages, 4 figures</comments><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restart strategies are an important factor in the performance of
conflict-driven Davis Putnam style SAT solvers. Selecting a good restart
strategy for a problem instance can enhance the performance of a solver.
Inspired by recent success applying machine learning techniques to predict the
runtime of SAT solvers, we present a method which uses machine learning to
boost solver performance through a smart selection of the restart strategy.
Based on easy to compute features, we train both a satisfiability classifier
and runtime models. We use these models to choose between restart strategies.
We present experimental results comparing this technique with the most commonly
used restart strategies. Our results demonstrate that machine learning is
effective in improving solver performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5033</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5033</id><created>2009-07-28</created><authors><author><keyname>Haim</keyname><forenames>Shai</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Online Search Cost Estimation for SAT Solvers</title><categories>cs.AI</categories><comments>8 pages, 9 figures</comments><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two different methods for estimating the cost of solving SAT
problems. The methods focus on the online behaviour of the backtracking solver,
as well as the structure of the problem. Modern SAT solvers present several
challenges to estimate search cost including coping with nonchronological
backtracking, learning and restarts. Our first method adapt an existing
algorithm for estimating the size of a search tree to deal with these
challenges. We then suggest a second method that uses a linear model trained on
data gathered online at the start of search. We compare the effectiveness of
these two methods using random and structured problems. We also demonstrate
that predictions made in early restarts can be used to improve later
predictions. We conclude by showing that the cost of solving a set of problems
can be reduced by selecting a solver from a portfolio based on such cost
estimations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5038</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5038</id><created>2009-07-28</created><authors><author><keyname>Li</keyname><forenames>Yi</forenames></author></authors><title>An Explicit Construction of Gauss-Jordan Elimination Matrix</title><categories>cs.SC cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A constructive approach to get the reduced row echelon form of a given matrix
$A$ is presented. It has been shown that after the $k$th step of the
Gauss-Jordan procedure, each entry $a^k_{ij}(i&lt;&gt;j; j &gt; k)$ in the new matrix
$A^k$ can always be expressed as a ratio of two determinants whose entries are
from the original matrix $A$. The new method also gives a more general
generalization of Cramer's rule than existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5043</identifier>
 <datestamp>2009-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5043</id><created>2009-07-29</created><authors><author><keyname>Jiang</keyname><forenames>Zhi-Qiang</forenames><affiliation>ECUST</affiliation></author><author><keyname>Zhou</keyname><forenames>Wei-Xing</forenames><affiliation>ECUST</affiliation></author><author><keyname>Tan</keyname><forenames>Qun-Zhao</forenames><affiliation>SNDA</affiliation></author></authors><title>Online-offline activities and game-playing behaviors of avatars in a
  massive multiplayer online role-playing game</title><categories>physics.pop-ph cs.MA physics.soc-ph</categories><comments>6 EPL pages including 10 eps figures</comments><journal-ref>EPL 88, 48007 (2009)</journal-ref><doi>10.1209/0295-5075/88/48007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiplayer online role-playing games (MMORPGs) are very popular in
China, which provides a potential platform for scientific research. We study
the online-offline activities of avatars in an MMORPG to understand their
game-playing behavior. The statistical analysis unveils that the active avatars
can be classified into three types. The avatars of the first type are owned by
game cheaters who go online and offline in preset time intervals with the
online duration distributions dominated by pulses. The second type of avatars
is characterized by a Weibull distribution in the online durations, which is
confirmed by statistical tests. The distributions of online durations of the
remaining individual avatars differ from the above two types and cannot be
described by a simple form. These findings have potential applications in the
game industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5055</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5055</id><created>2009-07-29</created><authors><author><keyname>Belli</keyname><forenames>Fevzi</forenames></author><author><keyname>Beyazit</keyname><forenames>Mutlu</forenames></author></authors><title>Mutation of Directed Graphs -- Corresponding Regular Expressions and
  Complexity of Their Generation</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 69-77</journal-ref><doi>10.4204/EPTCS.3.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directed graphs (DG), interpreted as state transition diagrams, are
traditionally used to represent finite-state automata (FSA). In the context of
formal languages, both FSA and regular expressions (RE) are equivalent in that
they accept and generate, respectively, type-3 (regular) languages. Based on
our previous work, this paper analyzes effects of graph manipulations on
corresponding RE. In this present, starting stage we assume that the DG under
consideration contains no cycles. Graph manipulation is performed by deleting
or inserting of nodes or arcs. Combined and/or multiple application of these
basic operators enable a great variety of transformations of DG (and
corresponding RE) that can be seen as mutants of the original DG (and
corresponding RE). DG are popular for modeling complex systems; however they
easily become intractable if the system under consideration is complex and/or
large. In such situations, we propose to switch to corresponding RE in order to
benefit from their compact format for modeling and algebraic operations for
analysis. The results of the study are of great potential interest to mutation
testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5058</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5058</id><created>2009-07-29</created><authors><author><keyname>Almeida</keyname><forenames>Marco</forenames><affiliation>LIACC-U.Porto</affiliation></author><author><keyname>Moreira</keyname><forenames>Nelma</forenames><affiliation>LIACC-U.Porto</affiliation></author><author><keyname>Reis</keyname><forenames>Rog&#xe9;rio</forenames><affiliation>LIACC-U.Porto</affiliation></author></authors><title>Testing the Equivalence of Regular Languages</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 47-57</journal-ref><doi>10.4204/EPTCS.3.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimal deterministic finite automaton is generally used to determine
regular languages equality. Antimirov and Mosses proposed a rewrite system for
deciding regular expressions equivalence of which Almeida et al. presented an
improved variant. Hopcroft and Karp proposed an almost linear algorithm for
testing the equivalence of two deterministic finite automata that avoids
minimisation. In this paper we improve the best-case running time, present an
extension of this algorithm to non-deterministic finite automata, and establish
a relationship between this algorithm and the one proposed in Almeida et al. We
also present some experimental comparative results. All these algorithms are
closely related with the recent coalgebraic approach to automata proposed by
Rutten.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5063</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5063</id><created>2009-07-29</created><authors><author><keyname>Gruber</keyname><forenames>Hermann</forenames></author><author><keyname>Holzer</keyname><forenames>Markus</forenames></author><author><keyname>Kutrib</keyname><forenames>Martin</forenames></author></authors><title>On Measuring Non-Recursive Trade-Offs</title><categories>cs.FL cs.IT math.IT</categories><journal-ref>EPTCS 3, 2009, pp. 141-150</journal-ref><doi>10.4204/EPTCS.3.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the phenomenon of non-recursive trade-offs between
descriptional systems in an abstract fashion. We aim at categorizing
non-recursive trade-offs by bounds on their growth rate, and show how to deduce
such bounds in general. We also identify criteria which, in the spirit of
abstract language theory, allow us to deduce non-recursive tradeoffs from
effective closure properties of language families on the one hand, and
differences in the decidability status of basic decision problems on the other.
We develop a qualitative classification of non-recursive trade-offs in order to
obtain a better understanding of this very fundamental behaviour of
descriptional systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5072</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5072</id><created>2009-07-29</created><authors><author><keyname>Jir&#xe1;skov&#xe1;</keyname><forenames>Galina</forenames><affiliation>Slovak Academy of Sciences</affiliation></author><author><keyname>Okhotin</keyname><forenames>Alexander</forenames><affiliation>University of Turku</affiliation></author></authors><title>Nondeterministic State Complexity of Positional Addition</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 151-161</journal-ref><doi>10.4204/EPTCS.3.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider nondeterministic finite automata recognizing base-k positional
notation of numbers. Assume that numbers are read starting from their least
significant digits. It is proved that if two sets of numbers S and T are
represented by nondeterministic automata of m and n states, respectively, then
their sum {s+t | s in S, t in T} is represented by a nondeterministic automaton
with 2mn+2m+2n+1 states. Moreover, this number of states is necessary in the
worst case for all k&gt;=9.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5074</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5074</id><created>2009-07-29</created><authors><author><keyname>Bersani</keyname><forenames>Marcello M.</forenames></author><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author><author><keyname>Rossi</keyname><forenames>Matteo</forenames></author></authors><title>Integrated Modeling and Verification of Real-Time Systems through
  Multiple Paradigms</title><categories>cs.LO</categories><comments>27 pages</comments><journal-ref>Proceedings of the 7th IEEE International Conference on Software
  Engineering and Formal Methods (SEFM'09). Pgg. 13--22, IEEE Computer Society
  Press, November 2009</journal-ref><doi>10.1109/SEFM.2009.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex systems typically have many different parts and facets, with
different characteristics. In a multi-paradigm approach to modeling, formalisms
with different natures are used in combination to describe complementary parts
and aspects of the system. This can have a beneficial impact on the modeling
activity, as different paradigms an be better suited to describe different
aspects of the system. While each paradigm provides a different view on the
many facets of the system, it is of paramount importance that a coherent
comprehensive model emerges from the combination of the various partial
descriptions. In this paper we present a technique to model different aspects
of the same system with different formalisms, while keeping the various models
tightly integrated with one another. In addition, our approach leverages the
flexibility provided by a bounded satisfiability checker to encode the
verification problem of the integrated model in the propositional
satisfiability (SAT) problem; this allows users to carry out formal
verification activities both on the whole model and on parts thereof. The
effectiveness of the approach is illustrated through the example of a
monitoring system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5083</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5083</id><created>2009-07-29</created><authors><author><keyname>Balan</keyname><forenames>M. Sakthi</forenames><affiliation>Infosys</affiliation></author></authors><title>Serializing the Parallelism in Parallel Communicating Pushdown Automata
  Systems</title><categories>cs.FL cs.CL cs.DC</categories><journal-ref>EPTCS 3, 2009, pp. 59-68</journal-ref><doi>10.4204/EPTCS.3.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider parallel communicating pushdown automata systems (PCPA) and
define a property called known communication for it. We use this property to
prove that the power of a variant of PCPA, called returning centralized
parallel communicating pushdown automata (RCPCPA), is equivalent to that of
multi-head pushdown automata. The above result presents a new sub-class of
returning parallel communicating pushdown automata systems (RPCPA) called
simple-RPCPA and we show that it can be written as a finite intersection of
multi-head pushdown automata systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5096</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5096</id><created>2009-07-29</created><authors><author><keyname>Richard</keyname><forenames>Adrien</forenames></author></authors><title>Negative circuits and sustained oscillations in asynchronous automata
  networks</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The biologist Ren\'e Thomas conjectured, twenty years ago, that the presence
of a negative feedback circuit in the interaction graph of a dynamical system
is a necessary condition for this system to produce sustained oscillations. In
this paper, we state and prove this conjecture for asynchronous automata
networks, a class of discrete dynamical systems extensively used to model the
behaviors of gene networks. As a corollary, we obtain the following fixed point
theorem: given a product $X$ of $n$ finite intervals of integers, and a map $F$
from $X$ to itself, if the interaction graph associated with $F$ has no
negative circuit, then $F$ has at least one fixed point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5111</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5111</id><created>2009-07-29</created><authors><author><keyname>Biegler</keyname><forenames>Franziska</forenames></author><author><keyname>Daley</keyname><forenames>Mark</forenames></author><author><keyname>McQuillan</keyname><forenames>Ian</forenames></author></authors><title>On the Shuffle Automaton Size for Words</title><categories>cs.FL cs.DM</categories><journal-ref>EPTCS 3, 2009, pp. 79-89</journal-ref><doi>10.4204/EPTCS.3.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the state size of DFAs accepting the shuffle of two words. We
provide words u and v, such that the minimal DFA for u shuffled with v requires
an exponential number of states. We also show some conditions for the words u
and v which ensure a quadratic upper bound on the state size of u shuffled with
v. Moreover, switching only two letters within one of u or v is enough to
trigger the change from quadratic to exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5119</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5119</id><created>2009-07-29</created><authors><author><keyname>Csuhaj-Varj&#xfa;</keyname><forenames>Erzs&#xe9;bet</forenames></author><author><keyname>Vaszil</keyname><forenames>Gy&#xf6;rgy</forenames></author></authors><title>On the Size Complexity of Non-Returning Context-Free PC Grammar Systems</title><categories>cs.FL cs.DC cs.MA</categories><journal-ref>EPTCS 3, 2009, pp. 91-100</journal-ref><doi>10.4204/EPTCS.3.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improving the previously known best bound, we show that any recursively
enumerable language can be generated with a non-returning parallel
communicating (PC) grammar system having six context-free components. We also
present a non-returning universal PC grammar system generating unary languages,
that is, a system where not only the number of components, but also the number
of productions and the number of nonterminals are limited by certain constants,
and these size parameters do not depend on the generated language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5120</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5120</id><created>2009-07-29</created><authors><author><keyname>Freund</keyname><forenames>Rudolf</forenames></author><author><keyname>Klein</keyname><forenames>Andreas</forenames></author><author><keyname>Kutrib</keyname><forenames>Martin</forenames></author></authors><title>On the Number of Membranes in Unary P Systems</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 101-109</journal-ref><doi>10.4204/EPTCS.3.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider P systems with a linear membrane structure working on objects
over a unary alphabet using sets of rules resembling homomorphisms. Such a
restricted variant of P systems allows for a unique minimal representation of
the generated unary language and in that way for an effective solution of the
equivalence problem. Moreover, we examine the descriptional complexity of unary
P systems with respect to the number of membranes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5121</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5121</id><created>2009-07-29</created><authors><author><keyname>Frisco</keyname><forenames>Pierluigi</forenames><affiliation>Heriot-Watt University</affiliation></author><author><keyname>Ibarra</keyname><forenames>Oscar H.</forenames><affiliation>University of California</affiliation></author></authors><title>On Languages Accepted by P/T Systems Composed of joins</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 111-120</journal-ref><doi>10.4204/EPTCS.3.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, some studies linked the computational power of abstract computing
systems based on multiset rewriting to models of Petri nets and the computation
power of these nets to their topology. In turn, the computational power of
these abstract computing devices can be understood by just looking at their
topology, that is, information flow.
  Here we continue this line of research introducing J languages and proving
that they can be accepted by place/transition systems whose underlying net is
composed only of joins. Moreover, we investigate how J languages relate to
other families of formal languages. In particular, we show that every J
language can be accepted by a log n space-bounded non-deterministic Turing
machine with a one-way read-only input. We also show that every J language has
a semilinear Parikh map and that J languages and context-free languages (CFLs)
are incomparable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5124</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5124</id><created>2009-07-29</created><authors><author><keyname>Gao</keyname><forenames>Yuan</forenames></author><author><keyname>Yu</keyname><forenames>Sheng</forenames></author></authors><title>State Complexity Approximation</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 121-130</journal-ref><doi>10.4204/EPTCS.3.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the new concept of state complexity
approximation, which is a further development of state complexity estimation.
We show that this new concept is useful in both of the following two cases: the
exact state complexities are not known and the state complexities have been
obtained but are in incomprehensible form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5125</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5125</id><created>2009-07-29</created><authors><author><keyname>Jacquemard</keyname><forenames>Florent</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Rusinowitch</keyname><forenames>Michael</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author></authors><title>Rewrite based Verification of XML Updates</title><categories>cs.LO</categories><proxy>ccsd inria-00408162</proxy><report-no>RR-7007</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider problems of access control for update of XML documents. In the
context of XML programming, types can be viewed as hedge automata, and static
type checking amounts to verify that a program always converts valid source
documents into also valid output documents. Given a set of update operations we
are particularly interested by checking safety properties such as preservation
of document types along any sequence of updates. We are also interested by the
related policy consistency problem, that is detecting whether a sequence of
authorized operations can simulate a forbidden one. We reduce these questions
to type checking problems, solved by computing variants of hedge automata
characterizing the set of ancestors and descendants of the initial document
type for the closure of parameterized rewrite rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5126</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5126</id><created>2009-07-29</created><updated>2009-08-05</updated><authors><author><keyname>Panaretos</keyname><forenames>John</forenames></author><author><keyname>Malesios</keyname><forenames>Chrisovaladis</forenames></author></authors><title>A population-modulated bibliometric measure with an application in the
  field of statistics</title><categories>stat.AP cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use confirmatory factor analysis to derive a unifying measure of
comparison of scientists based on bibliometric measurements, by utilizing the
h-index, some similar h-type indices as well as other common measures of
scientific performance. We use a real data example from nine well-known
departments of statistics to demonstrate our approach and argue that our
combined measure results in a better overall evaluation of a researchers'
scientific work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5127</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5127</id><created>2009-07-29</created><authors><author><keyname>Geffert</keyname><forenames>Viliam</forenames></author><author><keyname>I&#x161;to&#x148;ov&#xe1;</keyname><forenames>Lubom&#xed;ra</forenames></author></authors><title>Translation from Classical Two-Way Automata to Pebble Two-Way Automata</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 131-140</journal-ref><doi>10.4204/EPTCS.3.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the relation between the standard two-way automata and more powerful
devices, namely, two-way finite automata with an additional &quot;pebble&quot; movable
along the input tape. Similarly as in the case of the classical two-way
machines, it is not known whether there exists a polynomial trade-off, in the
number of states, between the nondeterministic and deterministic pebble two-way
automata. However, we show that these two machine models are not independent:
if there exists a polynomial trade-off for the classical two-way automata, then
there must also exist a polynomial trade-off for the pebble two-way automata.
Thus, we have an upward collapse (or a downward separation) from the classical
two-way automata to more powerful pebble automata, still staying within the
class of regular languages. The same upward collapse holds for complementation
of nondeterministic two-way machines.
  These results are obtained by showing that each pebble machine can be, by
using suitable inputs, simulated by a classical two-way automaton with a linear
number of states (and vice versa), despite the existing exponential blow-up
between the classical and pebble two-way machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5128</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5128</id><created>2009-07-29</created><authors><author><keyname>Kutrib</keyname><forenames>Martin</forenames></author><author><keyname>Malcher</keyname><forenames>Andreas</forenames></author></authors><title>Bounded Languages Meet Cellular Automata with Sparse Communication</title><categories>cs.FL cs.DC</categories><journal-ref>EPTCS 3, 2009, pp. 163-172</journal-ref><doi>10.4204/EPTCS.3.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular automata are one-dimensional arrays of interconnected interacting
finite automata. We investigate one of the weakest classes, the real-time
one-way cellular automata, and impose an additional restriction on their
inter-cell communication by bounding the number of allowed uses of the links
between cells. Moreover, we consider the devices as acceptors for bounded
languages in order to explore the borderline at which non-trivial decidability
problems of cellular automata classes become decidable. It is shown that even
devices with drastically reduced communication, that is, each two neighboring
cells may communicate only constantly often, accept bounded languages that are
not semilinear. If the number of communications is at least logarithmic in the
length of the input, several problems are undecidable. The same result is
obtained for classes where the total number of communications during a
computation is linearly bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5130</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5130</id><created>2009-07-29</created><authors><author><keyname>Loos</keyname><forenames>Remco</forenames></author><author><keyname>Manea</keyname><forenames>Florin</forenames></author><author><keyname>Mitrana</keyname><forenames>Victor</forenames></author></authors><title>Small Universal Accepting Networks of Evolutionary Processors with
  Filtered Connections</title><categories>cs.FL cs.CC</categories><journal-ref>EPTCS 3, 2009, pp. 173-182</journal-ref><doi>10.4204/EPTCS.3.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present some results regarding the size complexity of
Accepting Networks of Evolutionary Processors with Filtered Connections
(ANEPFCs). We show that there are universal ANEPFCs of size 10, by devising a
method for simulating 2-Tag Systems. This result significantly improves the
known upper bound for the size of universal ANEPFCs which is 18.
  We also propose a new, computationally and descriptionally efficient
simulation of nondeterministic Turing machines by ANEPFCs. More precisely, we
describe (informally, due to space limitations) how ANEPFCs with 16 nodes can
simulate in O(f(n)) time any nondeterministic Turing machine of time complexity
f(n). Thus the known upper bound for the number of nodes in a network
simulating an arbitrary Turing machine is decreased from 26 to 16.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5132</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5132</id><created>2009-07-29</created><authors><author><keyname>Masopust</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Meduna</keyname><forenames>Alexander</forenames></author></authors><title>Descriptional Complexity of Three-Nonterminal Scattered Context
  Grammars: An Improvement</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 183-192</journal-ref><doi>10.4204/EPTCS.3.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that every recursively enumerable language can be
generated by a scattered context grammar with no more than three nonterminals.
However, in that construction, the maximal number of nonterminals
simultaneously rewritten during a derivation step depends on many factors, such
as the cardinality of the alphabet of the generated language and the structure
of the generated language itself. This paper improves the result by showing
that the maximal number of nonterminals simultaneously rewritten during any
derivation step can be limited by a small constant regardless of other factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5136</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5136</id><created>2009-07-29</created><authors><author><keyname>Stiebe</keyname><forenames>Ralf</forenames></author><author><keyname>Turaev</keyname><forenames>Sherzod</forenames></author></authors><title>Capacity Bounded Grammars and Petri Nets</title><categories>cs.FL</categories><journal-ref>EPTCS 3, 2009, pp. 193-203</journal-ref><doi>10.4204/EPTCS.3.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A capacity bounded grammar is a grammar whose derivations are restricted by
assigning a bound to the number of every nonterminal symbol in the sentential
forms. In the paper the generative power and closure properties of capacity
bounded grammars and their Petri net controlled counterparts are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5138</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5138</id><created>2009-07-29</created><updated>2010-10-29</updated><authors><author><keyname>Kloeckner</keyname><forenames>Benoit</forenames><affiliation>IF</affiliation></author></authors><title>Cutwidth and degeneracy of graphs</title><categories>math.CO cs.DM</categories><comments>v2: slightly shortened, some typos corrected.</comments><proxy>ccsd</proxy><report-no>IF_PREPUB</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an inequality involving the degeneracy, the cutwidth and the
sparsity of graphs. It implies a quadratic lower bound on the cutwidth in terms
of the degeneracy for all graphs and an improvement of it for clique-free
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5141</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5141</id><created>2009-07-29</created><authors><author><keyname>Zheng</keyname><forenames>Haipeng</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Cooperative Training for Attribute-Distributed Data: Trade-off Between
  Data Transmission and Performance</title><categories>cs.DC cs.MA</categories><journal-ref>Proceedings of IEEE Fusion 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a modeling framework for distributed regression with
agents/experts observing attribute-distributed data (heterogeneous data). Under
this model, a new algorithm, the iterative covariance optimization algorithm
(ICOA), is designed to reshape the covariance matrix of the training residuals
of individual agents so that the linear combination of the individual
estimators minimizes the ensemble training error. Moreover, a scheme (Minimax
Protection) is designed to provide a trade-off between the number of data
instances transmitted among the agents and the performance of the ensemble
estimator without undermining the convergence of the algorithm. This scheme
also provides an upper bound (with high probability) on the test error of the
ensemble estimator. The efficacy of ICOA combined with Minimax Protection and
the comparison between the upper bound and actual performance are both
demonstrated by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5155</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5155</id><created>2009-07-29</created><updated>2012-01-02</updated><authors><author><keyname>Hsiao</keyname><forenames>C. A.</forenames></author></authors><title>On Classification from Outlier View</title><categories>cs.AI</categories><comments>Conclusion renewed; IAENG International Journal of Computer Science,
  Volume 37, Issue 4, Nov, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification is the basis of cognition. Unlike other solutions, this study
approaches it from the view of outliers. We present an expanding algorithm to
detect outliers in univariate datasets, together with the underlying
foundation. The expanding algorithm runs in a holistic way, making it a rather
robust solution. Synthetic and real data experiments show its power.
Furthermore, an application for multi-class problems leads to the introduction
of the oscillator algorithm. The corresponding result implies the potential
wide use of the expanding algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5162</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5162</id><created>2009-07-29</created><authors><author><keyname>Tafliovich</keyname><forenames>Anya</forenames></author><author><keyname>Hehner</keyname><forenames>Eric C. R.</forenames></author></authors><title>Programming with Quantum Communication</title><categories>cs.PL cs.LO quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work develops a formal framework for specifying, implementing, and
analysing quantum communication protocols. We provide tools for developing
simple proofs and analysing programs which involve communication, both via
quantum channels and exhibiting the LOCC (local operations, classical
communication) paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5165</identifier>
 <datestamp>2011-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5165</id><created>2009-07-29</created><authors><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Aldridge</keyname><forenames>Matthew</forenames></author><author><keyname>Piechocki</keyname><forenames>Robert</forenames></author></authors><title>Interference alignment-based sum capacity bounds for random dense
  Gaussian interference networks</title><categories>cs.IT math.IT</categories><comments>23 pages</comments><journal-ref>IEEE Transactions on Information Theory, 57:1, 282-290, 2011</journal-ref><doi>10.1109/TIT.2010.2090242</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dense $K$ user Gaussian interference network formed by paired
transmitters and receivers placed independently at random in a fixed spatial
region. Under natural conditions on the node position distributions and signal
attenuation, we prove convergence in probability of the average per-user
capacity $\csum/K$ to $\half \ep \log(1 + 2 \SNR)$. The achievability result
follows directly from results based on an interference alignment scheme
presented in recent work of Nazer et al. Our main contribution comes through an
upper bound, motivated by ideas of `bottleneck capacity' developed in recent
work of Jafar. By controlling the physical location of transmitter--receiver
pairs, we can match a large proportion of these pairs to form so-called
$\epsilon$-bottleneck links, with consequent control of the sum capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5168</identifier>
 <datestamp>2009-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5168</id><created>2009-07-29</created><authors><author><keyname>Zheng</keyname><forenames>Haipeng</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Collaborative Training in Sensor Networks: A graphical model approach</title><categories>cs.DC cs.MA</categories><journal-ref>Proceedings of IEEE International Workshop on Machine Learning for
  Signal Processing, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical models have been widely applied in solving distributed inference
problems in sensor networks. In this paper, the problem of coordinating a
network of sensors to train a unique ensemble estimator under communication
constraints is discussed. The information structure of graphical models with
specific potential functions is employed, and this thus converts the
collaborative training task into a problem of local training plus global
inference. Two important classes of algorithms of graphical model inference,
message-passing algorithm and sampling algorithm, are employed to tackle
low-dimensional, parametrized and high-dimensional, non-parametrized problems
respectively. The efficacy of this approach is demonstrated by concrete
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5219</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5219</id><created>2009-07-30</created><updated>2009-08-24</updated><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author></authors><title>A Note on the Power of Truthful Approximation Mechanisms</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the power of polynomial-time truthful mechanisms comparing to
polynomial time (non-truthful) algorithms. We show that there is a setting in
which deterministic polynomial-time truthful mechanisms cannot guarantee a
bounded approximation ratio, but a non-truthful FPTAS exists. We also show that
in the same setting there is a universally truthful mechanism that provides an
approximation ratio of 2. This shows that the cost of truthfulness is
unbounded. The proofs are almost standard in the field and follow from known
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5226</identifier>
 <datestamp>2009-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5226</id><created>2009-07-29</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Recursive Random Number Generator Using Prime Reciprocals</title><categories>cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recursive random number generator using prime reciprocals is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5233</identifier>
 <datestamp>2009-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5233</id><created>2009-07-29</created><authors><author><keyname>McPherson</keyname><forenames>Sean</forenames></author><author><keyname>Ortega</keyname><forenames>Antonio</forenames></author></authors><title>Analysis of Internet Measurement Systems for Optimized Anomaly Detection
  System Design</title><categories>cs.NI</categories><comments>18 Pages, 10 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although there exist very accurate hardware systems for measuring traffic on
the internet, their widespread use for analysis tasks is limited by their high
cost. On the other hand, less expensive, software-based systems exist that are
widely available and can be used to perform a number of simple analysis tasks.
The caveat with using such software systems is that application of standard
analysis methods cannot proceed blindly because inherent distortions exist in
the measurements obtained from software systems. The goal of this paper is to
analyze common Internet measurement systems to discover the effect of these
distortions on common analysis tasks. Then by selecting one specific task,
periodic signal detection, a more in-depth analysis is conducted which derives
a signal representation to capture the salient features of the measurement and
develops a periodic detection mechanism designed for the measurement system
which outperforms an existing detection method not optimized for the
measurement system. Finally, through experiments the importance of
understanding the relationship between the input traffic, measurement system
configuration and detection method performance is emphasized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5234</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5234</id><created>2009-07-29</created><updated>2010-04-08</updated><authors><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Rajagopal</keyname><forenames>K. R.</forenames></author></authors><title>A numerical study of fluids with pressure dependent viscosity flowing
  through a rigid porous medium</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider modifications to Darcy's equation wherein the drag
coefficient is a function of pressure, which is a realistic model for
technological applications like enhanced oil recovery and geological carbon
sequestration. We first outline the approximations behind Darcy's equation and
the modifications that we propose to Darcy's equation, and derive the governing
equations through a systematic approach using mixture theory. We then propose a
stabilized mixed finite element formulation for the modified Darcy's equation.
To solve the resulting nonlinear equations we present a solution procedure
based on the consistent Newton-Raphson method. We solve representative test
problems to illustrate the performance of the proposed stabilized formulation.
One of the objectives of this paper is also to show that the dependence of
viscosity on the pressure can have a significant effect both on the qualitative
and quantitative nature of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5257</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5257</id><created>2009-07-30</created><authors><author><keyname>Dassow</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Pighizzini</keyname><forenames>Giovanni</forenames></author><author><keyname>Truthe</keyname><forenames>Bianca</forenames></author></authors><title>Proceedings Eleventh International Workshop on Descriptional Complexity
  of Formal Systems</title><categories>cs.FL cs.CC</categories><journal-ref>EPTCS 3, 2009</journal-ref><doi>10.4204/EPTCS.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 11th workshop, Descriptional Complexity of Formal Systems 2009, is taking
place in Magdeburg, Germany, on July 6-9, 2009. It is jointly organized by the
IFIP Working Group 1.2 on Descriptional Complexity and by the Faculty of
Computer Science at the Otto von Guericke University Magdeburg. This volume
contains the papers of the invited lectures and the accepted contributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5269</identifier>
 <datestamp>2009-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5269</id><created>2009-07-30</created><authors><author><keyname>Geisberger</keyname><forenames>Robert</forenames></author><author><keyname>Luxen</keyname><forenames>Dennis</forenames></author><author><keyname>Neubauer</keyname><forenames>Sabine</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author><author><keyname>Volker</keyname><forenames>Lars</forenames></author></authors><title>Fast Detour Computation for Ride Sharing</title><categories>cs.DS</categories><comments>5 pages, 2 figure environment, 4 includegraphics</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Todays ride sharing services still mimic a better billboard. They list the
offers and allow to search for the source and target city, sometimes enriched
with radial search. So finding a connection between big cities is quite easy.
These places are on a list of designated origin and distination points. But
when you want to go from a small town to another small town, even when they are
next to a freeway, you run into problems. You can't find offers that would or
could pass by the town easily with little or no detour. We solve this
interesting problem by presenting a fast algorithm that computes the offers
with the smallest detours w.r.t. a request. Our experiments show that the
problem is efficiently solvable in times suitable for a web service
implementation. For realistic database size we achieve lookup times of about
5ms and a matching rate of 90% instead of just 70% for the simple matching
algorithms used today.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5287</identifier>
 <datestamp>2009-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5287</id><created>2009-07-30</created><authors><author><keyname>Borges</keyname><forenames>J.</forenames></author><author><keyname>Fernandez-Cordoba</keyname><forenames>C.</forenames></author><author><keyname>Rifa</keyname><forenames>J.</forenames></author></authors><title>Propelinear structure of Z_{2k}-linear codes</title><categories>cs.IT math.IT</categories><journal-ref>Electronic Notes in Discrete Mathematics, Volume 10, November
  2001, Pages 100-102</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let C be an additive subgroup of $\Z_{2k}^n$ for any $k\geq 1$. We define a
Gray map $\Phi:\Z_{2k}^n \longrightarrow \Z_2^{kn}$ such that $\Phi(\codi)$ is
a binary propelinear code and, hence, a Hamming-compatible group code.
Moreover, $\Phi$ is the unique Gray map such that $\Phi(C)$ is
Hamming-compatible group code. Using this Gray map we discuss about the
nonexistence of 1-perfect binary mixed group code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5290</identifier>
 <datestamp>2012-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5290</id><created>2009-07-30</created><updated>2012-03-22</updated><authors><author><keyname>Shkotin</keyname><forenames>Alex</forenames></author></authors><title>Program structure</title><categories>cs.PL</categories><comments>22 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A program is usually represented as a word chain. It is exactly a word chain
that appears as the lexical analyzer output and is parsed. The work shows that
a program can be syntactically represented as an oriented word tree, that is a
syntactic program tree, program words being located both in tree nodes and on
tree arrows. The basic property of a tree is that arrows starting from each
node are marked by different words (including an empty word). Semantics can
then be directly specified on such tree using either requirements or additional
links, and adding instructions to some tree nodes enables program execution
specification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5321</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5321</id><created>2009-07-30</created><updated>2009-08-04</updated><authors><author><keyname>Sakai</keyname><forenames>Tomoya</forenames></author></authors><title>Multiple pattern classification by sparse subspace decomposition</title><categories>cs.CV</categories><comments>8 pages, 3 figures, 2nd IEEE International Workshop on Subspace
  Methods, Workshop Proceedings of ICCV 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A robust classification method is developed on the basis of sparse subspace
decomposition. This method tries to decompose a mixture of subspaces of
unlabeled data (queries) into class subspaces as few as possible. Each query is
classified into the class whose subspace significantly contributes to the
decomposed subspace. Multiple queries from different classes can be
simultaneously classified into their respective classes. A practical greedy
algorithm of the sparse subspace decomposition is designed for the
classification. The present method achieves high recognition rate and robust
performance exploiting joint sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5372</identifier>
 <datestamp>2009-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5372</id><created>2009-07-30</created><authors><author><keyname>Frederickson</keyname><forenames>Greg N.</forenames></author><author><keyname>Wittman</keyname><forenames>Barry</forenames></author></authors><title>Speedup in the Traveling Repairman Problem with Unit Time Windows</title><categories>cs.DS</categories><comments>16 pages, 3 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The input to the unrooted traveling repairman problem is an undirected metric
graph and a subset of nodes, each of which has a time window of unit length.
Given that a repairman can start at any location, the goal is to plan a route
that visits as many nodes as possible during their respective time windows. A
polynomial-time bicriteria approximation algorithm is presented for this
problem, gaining an increased fraction of repairman visits for increased
speedup of repairman motion. For speedup $s$, we find a $6\gamma/(s +
1)$-approximation for $s$ in the range $1 \leq s \leq 2$ and a
$4\gamma/s$-approximation for $s$ in the range $2 \leq s \leq 4$, where $\gamma
= 1$ on tree-shaped networks and $\gamma = 2 + \epsilon$ on general metric
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5388</identifier>
 <datestamp>2009-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5388</id><created>2009-07-30</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Providing Secrecy With Structured Codes: Tools and Applications to
  Two-User Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>50 pages. Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent results have shown that structured codes can be used to construct good
channel codes, source codes and physical layer network codes for Gaussian
channels. For Gaussian channels with secrecy constraints, however, efforts to
date rely on random codes. In this work, we advocate that structured codes are
useful for providing secrecy, and show how to compute the secrecy rate when
structured codes are used. In particular, we solve the problem of bounding
equivocation rates with one important class of structured codes, i.e., nested
lattice codes. Having established this result, we next demonstrate the use of
structured codes for secrecy in two-user Gaussian channels. In particular, with
structured codes, we prove that a positive secure degree of freedom is
achievable for a large class of fully connected Gaussian channels as long as
the channel is not degraded. By way of this, for these channels, we establish
that structured codes outperform Gaussian random codes at high SNR. This class
of channels include the two-user multiple access wiretap channel, the two-user
interference channel with confidential messages and the two-user interference
wiretap channel. A notable consequence of this result is that, unlike the case
with Gaussian random codes, using structured codes for both transmission and
cooperative jamming, it is possible to achieve an arbitrary large secrecy rate
given enough power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5397</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5397</id><created>2009-07-30</created><updated>2010-12-19</updated><authors><author><keyname>Vats</keyname><forenames>Divyanshu</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Telescoping Recursive Representations and Estimation of Gauss-Markov
  Random Fields</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>To appear in the Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 3, pp
  1645-1663, March 2011</journal-ref><doi>10.1109/TIT.2011.2104612</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present \emph{telescoping} recursive representations for both continuous
and discrete indexed noncausal Gauss-Markov random fields. Our recursions start
at the boundary (a hypersurface in $\R^d$, $d \ge 1$) and telescope inwards.
For example, for images, the telescoping representation reduce recursions from
$d = 2$ to $d = 1$, i.e., to recursions on a single dimension. Under
appropriate conditions, the recursions for the random field are linear
stochastic differential/difference equations driven by white noise, for which
we derive recursive estimation algorithms, that extend standard algorithms,
like the Kalman-Bucy filter and the Rauch-Tung-Striebel smoother, to noncausal
Markov random fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5402</identifier>
 <datestamp>2009-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5402</id><created>2009-07-30</created><updated>2009-12-12</updated><authors><author><keyname>Jaramillo</keyname><forenames>Juan Jose</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Optimal Scheduling for Fair Resource Allocation in Ad Hoc Networks with
  Elastic and Inelastic Traffic</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of congestion control and scheduling in ad hoc
wireless networks that have to support a mixture of best-effort and real-time
traffic. Optimization and stochastic network theory have been successful in
designing architectures for fair resource allocation to meet long-term
throughput demands. However, to the best of our knowledge, strict packet delay
deadlines were not considered in this framework previously. In this paper, we
propose a model for incorporating the quality of service (QoS) requirements of
packets with deadlines in the optimization framework. The solution to the
problem results in a joint congestion control and scheduling algorithm which
fairly allocates resources to meet the fairness objectives of both elastic and
inelastic flows, and per-packet delay requirements of inelastic flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5427</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5427</id><created>2009-07-30</created><updated>2013-06-22</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>Betweenness Parameterized Above Tight Lower Bound</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study ordinal embedding relaxations in the realm of parameterized
complexity. We prove the existence of a quadratic kernel for the {\sc
Betweenness} problem parameterized above its tight lower bound, which is stated
as follows. For a set $V$ of variables and set $\mathcal C$ of constraints
&quot;$v_i$ \mbox{is between} $v_j$ \mbox{and} $v_k$&quot;, decide whether there is a
bijection from $V$ to the set $\{1,\ldots,|V|\}$ satisfying at least $|\mathcal
C|/3 + \kappa$ of the constraints in $\mathcal C$. Our result solves an open
problem attributed to Benny Chor in Niedermeier's monograph &quot;Invitation to
Fixed-Parameter Algorithms.&quot; The betweenness problem is of interest in
molecular biology. An approach developed in this paper can be used to determine
parameterized complexity of a number of other optimization problems on
permutations parameterized above or below tight bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5429</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5429</id><created>2009-07-30</created><authors><author><keyname>Sohail</keyname><forenames>Muhammad</forenames></author><author><keyname>Khan</keyname><forenames>Abdur Rashid</forenames></author></authors><title>Knowledge Elecitation for Factors Affecting Taskforce Productivity using
  a Questionnaire</title><categories>cs.CY cs.GL</categories><comments>7 pages, International Journal of Computer Science and Information
  Security, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, July 2009, Volume 3. No.1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the process of Knowledge Elicitation through a
structured questionnaire technique. This is an effort to depict a problem
domain as Investigation of factors affecting taskforce productivity. The
problem has to be solved using the expert system technology. This problem is
the very first step how to acquire knowledge from the domain experts. Knowledge
Elicitation is one of the difficult tasks in knowledge base formation which is
a key component of expert system. The questionnaire was distributed among 105
different domain experts of Public and Private Organizations (i.e. Education
Institutions, Industries and Research etc) in Pakistan. A total 61 responses
from these experts were received. All the experts were well qualified, highly
experienced and has been remained the members for selection committees a number
of times for different posts. Facts acquired were analyzed from which knowledge
was extracted and elicited. A standard shape was given to the questionnaire for
further research as a knowledge learning tool. This tool may be used as a
standard document for selection and promotion of employees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5430</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5430</id><created>2009-07-30</created><updated>2009-08-07</updated><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>De Pellegrini</keyname><forenames>Francesco</forenames></author><author><keyname>Sassatelli</keyname><forenames>Lucile</forenames></author></authors><title>Dynamic control of Coding in Delay Tolerant Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delay tolerant Networks (DTNs) leverage the mobility of relay nodes to
compensate for lack of permanent connectivity and thus enable communication
between nodes that are out of range of each other. To decrease message delivery
delay, the information to be transmitted is replicated in the network. We study
replication mechanisms that include Reed-Solomon type codes as well as network
coding in order to improve the probability of successful delivery within a
given time limit. We propose an analytical approach that allows us to compute
the probability of successful delivery. We study the effect of coding on the
performance of the network while optimizing parameters that govern routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5433</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5433</id><created>2009-07-30</created><authors><author><keyname>Jain</keyname><forenames>Ratnesh Kumar</forenames></author><author><keyname>Kasana</keyname><forenames>Dr. R. S.</forenames></author><author><keyname>Jain</keyname><forenames>Dr. Suresh</forenames></author></authors><title>Efficient Web Log Mining using Doubly Linked Tree</title><categories>cs.IR cs.IT math.IT</categories><comments>5 pages, International Journal of Computer Science and Information
  Security, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, July 2009, Volume 3. No.1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  World Wide Web is a huge data repository and is growing with the explosive
rate of about 1 million pages a day. As the information available on World Wide
Web is growing the usage of the web sites is also growing. Web log records each
access of the web page and number of entries in the web logs is increasing
rapidly. These web logs, when mined properly can provide useful information for
decision-making. The designer of the web site, analyst and management
executives are interested in extracting this hidden information from web logs
for decision making. Web access pattern, which is the frequently used sequence
of accesses, is one of the important information that can be mined from the web
logs. This information can be used to gather business intelligence to improve
sales and advertisement, personalization for a user, to analyze system
performance and to improve the web site organization. There exist many
techniques to mine access patterns from the web logs. This paper describes the
powerful algorithm that mines the web logs efficiently. Proposed algorithm
firstly converts the web access data available in a special doubly linked tree.
Each access is called an event. This tree keeps the critical mining related
information in very compressed form based on the frequent event count. Proposed
recursive algorithm uses this tree to efficiently find all access patterns that
satisfy user specified criteria. To prove that our algorithm is efficient from
the other GSP (Generalized Sequential Pattern) algorithms we have done
experimental studies on sample data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5438</identifier>
 <datestamp>2009-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5438</id><created>2009-07-30</created><updated>2009-08-29</updated><authors><author><keyname>Agrawal</keyname><forenames>Pranav</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>Key Distribution Scheme without Deployment Knowledge</title><categories>cs.CR</categories><comments>8 pages, 5 figures, Accepted in ICUMT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many basic key distribution schemes specifically tuned to wireless sensor
networks have been proposed in the literature. Recently, several researchers
have proposed schemes in which they have used group-based deployment models and
assumed predeployment knowledge of the expected locations of nodes. They have
shown that these schemes achieve better performance than the basic schemes, in
terms of connectivity, resilience against node capture and storage
requirements. But in many situations expected locations of nodes are not
available. In this paper we propose a solution which uses the basic scheme, but
does not use group-based deployment model and predeployment knowledge of the
locations of nodes, and yet performs better than schemes which make the
aforementioned assumptions.
  In our scheme, groups are formed after deployment of sensor nodes, on the
basis of their physical locations, and the nodes sample keys from disjoint key
pools. Compromise of a node affects secure links with other nodes that are part
of its group only. Because of this reason, our scheme performs better than the
basic schemes and the schemes using predeployment knowledge, in terms of
connectivity, storage requirement, and security. Moreover, the post-deployment
key generation process completes sooner than in schemes like LEAP+.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5441</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5441</id><created>2009-07-30</created><authors><author><keyname>Narasimhan</keyname><forenames>B.</forenames></author><author><keyname>baboo</keyname><forenames>S. Santhosh</forenames></author></authors><title>A Hop-by-Hop Congestion-Aware Routing Protocol for Heterogeneous Mobile
  Ad-hoc Networks</title><categories>cs.NI</categories><comments>7 pages, International Journal of Computer Science and Information
  Security, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, July 2009, Volume 3. No.1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Heterogeneous mobile ad hoc networks (MANETs) congestion occurs with
limited resources. Due to the shared wireless channel and dynamic topology,
packet transmissions suffer from interference and fading. In heterogeneous ad
hoc networks, throughput via a given route is depending on the minimum data
rate of all its links. In a route of links with various data rates, if a high
data rate node forwards more traffic to a low data rate node, there is a chance
of congestion, which leads to long queuing delays in such routes. Since hop
count is used as a routing metric in traditional routing, it do not adapt well
to mobile nodes. A congestion-aware routing metric for MANETs should
incorporate transmission capability, reliability, and congestion around a link.
In this paper, we propose to develop a hop-by-hop congestion aware routing
protocol which employs a combined weight value as a routing metric, based on
the data rate, queuing delay, link quality and MAC overhead. Among the
discovered routes, the route with minimum cost index is selected, which is
based on the node weight of all the in-network nodes. Simulation results prove
that our proposed routing protocol attains high throughput and packet delivery
ratio, by reducing the packet drop and delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5442</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5442</id><created>2009-07-30</created><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Deshpande</keyname><forenames>Amol</forenames></author><author><keyname>Khuller</keyname><forenames>Samir</forenames></author></authors><title>On Computing Compression Trees for Data Collection in Sensor Networks</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of efficiently gathering correlated data from a wired
or a wireless sensor network, with the aim of designing algorithms with
provable optimality guarantees, and understanding how close we can get to the
known theoretical lower bounds. Our proposed approach is based on finding an
optimal or a near-optimal {\em compression tree} for a given sensor network: a
compression tree is a directed tree over the sensor network nodes such that the
value of a node is compressed using the value of its parent. We consider this
problem under different communication models, including the {\em broadcast
communication} model that enables many new opportunities for energy-efficient
data collection. We draw connections between the data collection problem and a
previously studied graph concept, called {\em weakly connected dominating
sets}, and we use this to develop novel approximation algorithms for the
problem. We present comparative results on several synthetic and real-world
datasets showing that our algorithms construct near-optimal compression trees
that yield a significant reduction in the data collection cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5443</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5443</id><created>2009-07-30</created><authors><author><keyname>Guruprasad</keyname><forenames>H S</forenames></author><author><keyname>Maheshappa</keyname><forenames>H D</forenames></author></authors><title>Dynamic Bandwidth Management in Distributed VoD based on the User Class
  Using Agents</title><categories>cs.NI cs.PF</categories><comments>7 pages, International Journal of Computer Science and Information
  Security, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, July 2009, Volume 3. No.1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a dynamic bandwidth management algorithm in which more
bandwidth is allocated for higher class users and also higher priority is given
to the videos with higher popularity within a class using agent technology. The
popularity and weight profile of the videos which is used for efficiently
allocating bandwidth is periodically updated by a mobile agent. The proposed
approach allocates more bandwidth for higher class users and gives higher
priority for higher weight videos [popular videos] so that they can be served
with high QoS, reduces the load on the central multimedia server and maximizes
the channel utilization between the neighboring proxy servers and the central
multimedia server and lower video rejection ratio. The simulation results prove
the reduction of load on central multimedia server by load sharing among the
neighboring proxy servers, maximum bandwidth utilization, and more bandwidth
allocation for higher class users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5469</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5469</id><created>2009-07-31</created><authors><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author></authors><title>Feasibility/Desirability Games for Normal Form Games, Choice Models and
  Evolutionary Games</title><categories>cs.GT</categories><comments>17 pages</comments><proxy>ccsd ensl-00408519</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An abstraction of normal form games is proposed, called
Feasibility/Desirability Games (or FD Games in short). FD Games can be seen
from three points of view: as a new presentation of games in which Nash
equilibria can be found, as choice models in microeconomics or as a model of
evolution in games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5474</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5474</id><created>2009-07-31</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Wortman</keyname><forenames>Kevin A.</forenames></author></authors><title>Optimal Angular Resolution for Face-Symmetric Drawings</title><categories>cs.DS</categories><comments>10 pages, 6 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a graph that may be drawn in the plane in such a way that all
internal faces are centrally symmetric convex polygons. We show how to find a
drawing of this type that maximizes the angular resolution of the drawing, the
minimum angle between any two incident edges, in polynomial time, by reducing
the problem to one of finding parametric shortest paths in an auxiliary graph.
The running time is at most O(t^3), where t is a parameter of the input graph
that is at most O(n) but is more typically proportional to n^.5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5477</identifier>
 <datestamp>2015-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5477</id><created>2009-07-31</created><updated>2015-05-14</updated><authors><author><keyname>Gottlieb</keyname><forenames>Lee-Ad</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author></authors><title>A Nonlinear Approach to Dimension Reduction</title><categories>cs.CG cs.DS math.FA math.MG</categories><doi>10.1007/s00454-015-9707-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $l_2$ flattening lemma of Johnson and Lindenstrauss [JL84] is a powerful
tool for dimension reduction. It has been conjectured that the target dimension
bounds can be refined and bounded in terms of the intrinsic dimensionality of
the data set (for example, the doubling dimension). One such problem was
proposed by Lang and Plaut [LP01] (see also
[GKL03,MatousekProblems07,ABN08,CGT10]), and is still open. We prove another
result in this line of work:
  The snowflake metric $d^{1/2}$ of a doubling set $S \subset l_2$ embeds with
constant distortion into $l_2^D$, for dimension $D$ that depends solely on the
doubling constant of the metric. In fact, the distortion can be made
arbitrarily close to 1, and the target dimension is polylogarithmic in the
doubling constant. Our techniques are robust and extend to the more difficult
spaces $l_1$ and $l_\infty$, although the dimension bounds here are
quantitatively inferior than those for $l_2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5481</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5481</id><created>2009-07-31</created><authors><author><keyname>Gao</keyname><forenames>Yong</forenames></author></authors><title>Treewidth of Erd\&quot;{o}s-R\'{e}nyi Random Graphs, Random Intersection
  Graphs, and Scale-Free Random Graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the treewidth of an Erd\&quot;{o}s-R\'{e}nyi random graph $\rg{n,
m}$ is, with high probability, greater than $\beta n$ for some constant $\beta
&gt; 0$ if the edge/vertex ratio $\frac{m}{n}$ is greater than 1.073. Our lower
bound $\frac{m}{n} &gt; 1.073$ improves the only previously-known lower bound. We
also study the treewidth of random graphs under two other random models for
large-scale complex networks. In particular, our result on the treewidth of
\rigs strengths a previous observation on the average-case behavior of the
\textit{gate matrix layout} problem. For scale-free random graphs based on the
Barab\'{a}si-Albert preferential-attachment model, our result shows that if
more than 12 vertices are attached to a new vertex, then the treewidth of the
obtained network is linear in the size of the network with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5488</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5488</id><created>2009-07-31</created><updated>2010-02-23</updated><authors><author><keyname>Sassatelli</keyname><forenames>Lucile</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Network Coding for Delay Tolerant Networks with Byzantine Adversaries</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article has been withdrawn by the authors
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5489</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5489</id><created>2009-07-31</created><updated>2009-08-15</updated><authors><author><keyname>Zhou</keyname><forenames>Shan</forenames></author><author><keyname>Ying</keyname><forenames>Lei</forenames></author></authors><title>On Delay Constrained Multicast Capacity of Large-Scale Mobile Ad-Hoc
  Networks</title><categories>cs.NI</categories><comments>12 pages,8 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the delay constrained multicast capacity of large scale
mobile ad hoc networks (MANETs). We consider a MANET consists of $n_s$
multicast sessions. Each multicast session has one source and $p$ destinations.
The wireless mobiles move according to a two-dimensional i.i.d. mobility model.
Each source sends identical information to the $p$ destinations in its
multicast session, and the information is required to be delivered to all the
$p$ destinations within $D$ time-slots. Given the delay constraint $D,$ we
first prove that the capacity per multicast session is $O(\min\{1, (\log
p)(\log (n_sp)) \sqrt{\frac{D}{n_s}}\}).$ Given non-negative functions $f(n)$
and $g(n)$: $f(n)=O(g(n))$ means there exist positive constants $c$ and $m$
such that $f(n) \leq cg(n)$ for all $ n\geq m;$ $f(n)=\Omega(g(n))$ means there
exist positive constants $c$ and $m$ such that $f(n)\geq cg(n)$ for all $n\geq
m;$ $f(n)=\Theta(g(n))$ means that both $f(n)=\Omega(g(n))$ and $f(n)=O(g(n))$
hold; $f(n)=o(g(n))$ means that $\lim_{n\to \infty} f(n)/g(n)=0;$ and
$f(n)=\omega(g(n))$ means that $\lim_{n\to \infty} g(n)/f(n)=0.$ We then
propose a joint coding/scheduling algorithm achieving a throughput of
$\Theta(\min\{1,\sqrt{\frac{D}{n_s}}\}).$ Our simulations show that the joint
coding/scheduling algorithm achieves a throughput of the same order
($\Theta(\min\{1, \sqrt{\frac{D}{n_s}}\})$) under random walk model and random
waypoint model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5500</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5500</id><created>2009-07-31</created><authors><author><keyname>Liang</keyname><forenames>Nanying</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Bougrain</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Decoding Finger Flexion using amplitude modulation from band-specific
  ECoG</title><categories>cs.HC</categories><proxy>ccsd inria-00408595</proxy><journal-ref>European Symposium on Artificial Neural Networks (ESANN) (2009)
  467-472</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EEG-BCIs have been well studied in the past decades and implemented into
several famous applications, like P300 speller and wheelchair controller.
However, these interfaces are indirect due to low spatial resolution of EEG.
Recently, direct ECoG-BCIs attract intensive attention because ECoG provides a
higher spatial resolution and signal quality. This makes possible localization
of the source of neural signals with respect to certain brain functions. In
this article, we present a realization of ECoG-BCIs for finger flexion
prediction provided by BCI competition IV. Methods for finger flexion
prediction including feature extraction and selection are provided in this
article. Results show that the predicted finger movement is highly correlated
with the true movement when we use band-specific amplitude modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5527</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5527</id><created>2009-07-31</created><updated>2009-12-30</updated><authors><author><keyname>Moser</keyname><forenames>Georg</forenames></author></authors><title>Proof Theory at Work: Complexity Analysis of Term Rewrite Systems</title><categories>cs.LO cs.CC cs.SC cs.SE</categories><comments>Cumulative Habilitation Thesis, submitted to the University of
  Innsbruck</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis is concerned with investigations into the &quot;complexity of term
rewriting systems&quot;. Moreover the majority of the presented work deals with the
&quot;automation&quot; of such a complexity analysis. The aim of this introduction is to
present the main ideas in an easily accessible fashion to make the result
presented accessible to the general public. Necessarily some technical points
are stated in an over-simplified way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5538</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5538</id><created>2009-07-31</created><authors><author><keyname>Carraro</keyname><forenames>Francesco</forenames></author><author><keyname>Fonte</keyname><forenames>Sergio</forenames></author><author><keyname>Turrini</keyname><forenames>Diego</forenames></author><author><keyname>De Sanctis</keyname><forenames>Maria Cristina</forenames></author><author><keyname>Giacomini</keyname><forenames>Livia</forenames></author></authors><title>A preliminary XML-based search system for planetary data</title><categories>cs.IR astro-ph.EP cs.DB physics.geo-ph</categories><comments>10 pages, 5 figures, submitted to Computers and Geosciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planetary sciences can benefit from several different sources of information,
i.e. ground-based or near Earth-based observations, space missions and
laboratory experiments. The data collected from these sources, however, are
spread over a number of smaller, separate communities and stored through
different facilities: this makes it difficult to integrate them. The IDIS
initiative, born in the context of the Europlanet project, performed a pilot
study of the viability and the issues to be overcome in order to create an
integrated search system for planetary data. As part of the results of such
pilot study, the IDIS Small Bodies and Dust node developed a search system
based on a preliminary XML data model. Here we introduce the goals of the IDIS
initiative and describe the structure and the working of this search system.
The source code of the search system is released under GPL license to allow
people interested in participating to the IDIS initiative both as developers
and as data providers to familiarise with the search environment and to allow
the creation of volunteer nodes to be integrated into the existing network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5575</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5575</id><created>2009-07-31</created><updated>2009-12-08</updated><authors><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author></authors><title>A hitting set construction, with application to arithmetic circuit lower
  bounds</title><categories>cs.CC</categories><comments>14 pages</comments><proxy>ccsd ensl-00408713</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A polynomial identity testing algorithm must determine whether a given input
polynomial is identically equal to 0. We give a deterministic black-box
identity testing algorithm for univariate polynomials of the form $\sum_{j=0}^t
c_j X^{\alpha_j} (a + b X)^{\beta_j}$. From our algorithm we derive an
exponential lower bound for representations of polynomials such as
$\prod_{i=1}^{2^n} (X^i-1)$ under this form. It has been conjectured that these
polynomials are hard to compute by general arithmetic circuits. Our result
shows that the &quot;hardness from derandomization&quot; approach to lower bounds is
feasible for a restricted class of arithmetic circuits. The proof is based on
techniques from algebraic number theory, and more precisely on properties of
the height function of algebraic numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0907.5598</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0907.5598</id><created>2009-07-31</created><updated>2009-12-02</updated><authors><author><keyname>de Blanc</keyname><forenames>Peter</forenames></author></authors><title>Convergence of Expected Utility for Universal AI</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a sequence of repeated interactions between an agent and an
environment. Uncertainty about the environment is captured by a probability
distribution over a space of hypotheses, which includes all computable
functions. Given a utility function, we can evaluate the expected utility of
any computational policy for interaction with the environment. After making
some plausible assumptions (and maybe one not-so-plausible assumption), we show
that if the utility function is unbounded, then the expected utility of any
policy is undefined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0014</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0014</id><created>2009-07-31</created><authors><author><keyname>Latif</keyname><forenames>Mohamed Abdel</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>Keys through ARQ</title><categories>cs.IT cs.CR math.IT</categories><comments>21 Files 11 Figures Submitted to the IEEE Transactions on Information
  Theory on July 31st, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a novel framework for sharing secret keys using the
well-known Automatic Repeat reQuest (ARQ) protocol. The proposed key sharing
protocol does not assume any prior knowledge about the channel state
information (CSI), but, harnesses the available opportunistic secrecy gains
using only the one bit feedback, in the form of ACK/NACK. The distribution of
key bits among multiple ARQ epochs, in our approach, allows for mitigating the
secrecy outage phenomenon observed in earlier works. We characterize the
information theoretic limits of the proposed scheme, under different
assumptions on the channel spatial and temporal correlation function, and
develop low complexity explicit implementations. Our analysis reveals a novel
role of &quot;dumb antennas&quot; in overcoming the negative impact of spatial
correlation, between the legitimate and eavesdropper channels, on the
achievable secrecy rates. We further develop an adaptive rate allocation policy
which achieves higher secrecy rates by exploiting the channel temporal
correlation. Finally, our theoretical claims are validated by numerical results
that establish the achievability of non-zero secrecy rates even when the
eavesdropper channel is less noisy, on the average, than the legitimate
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0043</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0043</id><created>2009-08-01</created><authors><author><keyname>V.</keyname><forenames>Ashwinkumar B.</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author></authors><title>Randomized Online Algorithms for the Buyback Problem</title><categories>cs.GT</categories><journal-ref>WINE 2009, LNCS 5929, pp. 529-536, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the matroid buyback problem, an algorithm observes a sequence of bids and
must decide whether to accept each bid at the moment it arrives, subject to a
matroid constraint on the set of accepted bids. Decisions to reject bids are
irrevocable, whereas decisions to accept bids may be canceled at a cost which
is a fixed fraction of the bid value. We present a new randomized algorithm for
this problem, and we prove matching upper and lower bounds to establish that
the competitive ratio of this algorithm, against an oblivious adversary, is the
best possible. We also observe that when the adversary is adaptive, no
randomized algorithm can improve the competitive ratio of the optimal
deterministic algorithm. Thus, our work completely resolves the question of
what competitive ratios can be achieved by randomized algorithms for the
matroid buyback problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0045</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0045</id><created>2009-08-01</created><authors><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author></authors><title>On Random Construction of a Bipolar Sensing Matrix with Compact
  Representation</title><categories>cs.IT math.IT</categories><comments>6 pages, to be presented at 2009 IEEE Information Theory Workshop,
  Taormina</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A random construction of bipolar sensing matrices based on binary linear
codes is introduced and its RIP (Restricted Isometry Property) is analyzed
based on an argument on the ensemble average of the weight distribution of
binary linear codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0050</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0050</id><created>2009-08-01</created><updated>2010-02-11</updated><authors><author><keyname>Mairal</keyname><forenames>Julien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Ponce</keyname><forenames>Jean</forenames><affiliation>INRIA Rocquencourt, LIENS</affiliation></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Online Learning for Matrix Factorization and Sparse Coding</title><categories>stat.ML cs.LG math.OC</categories><comments>revised version</comments><proxy>ccsd inria-00408716</proxy><journal-ref>Journal of Machine Learning Research 11 (2010) 19--60</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse coding--that is, modelling data vectors as sparse linear combinations
of basis elements--is widely used in machine learning, neuroscience, signal
processing, and statistics. This paper focuses on the large-scale matrix
factorization problem that consists of learning the basis set, adapting it to
specific data. Variations of this problem include dictionary learning in signal
processing, non-negative matrix factorization and sparse principal component
analysis. In this paper, we propose to address these tasks with a new online
optimization algorithm, based on stochastic approximations, which scales up
gracefully to large datasets with millions of training samples, and extends
naturally to various matrix factorization formulations, making it suitable for
a wide range of learning problems. A proof of convergence is presented, along
with experiments with natural images and genomic data demonstrating that it
leads to state-of-the-art performance in terms of speed and optimization for
both small and large datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0051</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0051</id><created>2009-08-01</created><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>High-Rate, Distributed Training-Embedded Complex Orthogonal Designs for
  Relay Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Space-Time Block Codes (DSTBCs) from Complex Orthogonal Designs
(CODs) (both square and non-square CODs other than the Alamouti design) are
known to lose their single-symbol ML decodable (SSD) property when used in
two-hop wireless relay networks using amplify and forward protocol. For such a
network, in this paper, a new class of high rate, training-embedded (TE) SSD
DSTBCs are constructed from TE-CODs. The proposed codes include the training
symbols in the structure of the code which is shown to be the key point to
obtain high rate as well as the SSD property. TE-CODs are shown to offer
full-diversity for arbitrary complex constellations. Non-square TE-CODs are
shown to provide higher rates (in symbols per channel use) compared to the
known SSD DSTBCs for relay networks with number of relays less than $10.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0060</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0060</id><created>2009-08-01</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Algorithmic Decision Optimization Techniques for Multiple Types of
  Agents with Contrasting Interests</title><categories>cs.GT cs.DS</categories><acm-class>I.2.1; I.2.8; G.2.2</acm-class><journal-ref>Metalurgia International, vol. 14, special issue no. 11, pp.
  162-170, 2009. (ISSN: 1582-2214)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I present several algorithmic techniques for improving the
decision process of multiple types of agents behaving in environments where
their interests are in conflict. The interactions between the agents are
modelled by using several types of two-player games, where the agents have
identical roles and compete for the same resources, or where they have
different roles, like in query-response games. The described situations have
applications in modelling behavior in many types of environments, like
distributed systems, learning environments, resource negotiation environments,
and many others. The mentioned models are applicable in a wide range of
domains, like computer science or the industrial (e.g. metallurgical), economic
or financial sector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0076</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0076</id><created>2009-08-01</created><authors><author><keyname>Pamila</keyname><forenames>J. C. Miraclin Joyce</forenames></author><author><keyname>Thanushkodi</keyname><forenames>K.</forenames></author></authors><title>Log Management support for recovery in mobile computing Environment</title><categories>cs.NI</categories><comments>6 Pages, International Journal of Computer Science and Information
  Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapid and innovative improvement in wireless communication technologies has
led to an increase in the demand for mobile internet transactions. However,
internet access from mobile devices is very expensive due to limited bandwidth
available on wireless links and high mobility rate of mobile hosts. When a user
executes a transaction with a web portal from a mobile device, the
disconnection necessitates failure of the transaction or redoing all the steps
after reconnection, to get back into consistent application state. Thus
considering challenges in wireless mobile networks, a new log management scheme
is proposed for recovery of mobile transactions.
  In this proposed approach, the model parameters that affect application state
recovery are analyzed. The proposed scheme is compared with the existing Lazy
and Pessimistic scheme and a trade off analysis between the cost invested to
manage log and the return of investment in terms of improved failure
recoverability is made. From the analysis, the best checkpoint interval period
that yields the best return of investment is identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0078</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0078</id><created>2009-08-01</created><updated>2010-01-19</updated><authors><author><keyname>Das</keyname><forenames>Abhik</forenames></author><author><keyname>Agarwal</keyname><forenames>Shweta</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On Algebraic Traceback in Dynamic Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the concept of incremental traceback for determining
changes in the trace of a network as it evolves with time. A distributed
algorithm, based on the methodology of algebraic traceback developed by Dean et
al, is proposed which can completely determine a path of d nodes/routers using
O(d) marked packets, and subsequently determine the changes in its topology
using O(log d) marked packets with high probability. The algorithm is
established to be order-wise optimal i.e., no other distributed algorithm can
determine changes in the path topology using lesser order of bits (i.e., marked
packets). The algorithm is shown to have a computational complexity of O(d log
d), which is significantly less than that of any existing non-incremental
algorithm of algebraic traceback. Extensions of this algorithm to settings with
node identity spoofing and network coding are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0080</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0080</id><created>2009-08-01</created><authors><author><keyname>Paul</keyname><forenames>Manas</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Tanmay</forenames></author><author><keyname>Pal</keyname><forenames>Suvajit</forenames></author><author><keyname>Saha</keyname><forenames>Ranit</forenames></author></authors><title>A Novel Generic Session Based Bit Level Encryption Technique to Enhance
  Information Security</title><categories>cs.CR</categories><comments>7 Pages, International Journal of Computer Science and Information
  Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  - In this paper a session based symmetric key encryption system has been
proposed and is termed as Permutated Cipher Technique (PCT). This technique is
more fast, suitable and secure for larger files. In this technique the input
file is broken down into blocks of various sizes (of 2 power n order) and
encrypted by shifting the position of each bit by a certain value for a certain
number of times. A key is generated randomly wherein the length of each block
is determined. Each block length generates a unique value of number of bits to
be skipped. This value determines the new position of the bits within the block
that are to be shifted. After the shifting and inverting each block is XORed
with SHA 512 digest of the key. The resultant blocks from the cipher text. The
key is generated according to the binary value of the input file size.
Decryption is done following the same process as the technique is symmetric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0089</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0089</id><created>2009-08-01</created><authors><author><keyname>Ghaffari</keyname><forenames>H. O.</forenames></author><author><keyname>Ejtemaei</keyname><forenames>M.</forenames></author><author><keyname>Irannajad</keyname><forenames>M.</forenames></author></authors><title>Knowledge Discovery of Hydrocyclone s Circuit Based on SONFIS and SORST</title><categories>cs.AI</categories><comments>Proceedings of the 11th International Mineral Processing Symposium
  21-23 October 2008, Belek-Antalya, Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study describes application of some approximate reasoning methods to
analysis of hydrocyclone performance. In this manner, using a combining of Self
Organizing Map (SOM), Neuro-Fuzzy Inference System (NFIS)-SONFIS- and Rough Set
Theory (RST)-SORST-crisp and fuzzy granules are obtained. Balancing of crisp
granules and non-crisp granules can be implemented in close-open iteration.
Using different criteria and based on granulation level balance point
(interval) or a pseudo-balance point is estimated. Validation of the proposed
methods, on the data set of the hydrocyclone is rendered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0099</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0099</id><created>2009-08-01</created><authors><author><keyname>Ayofe</keyname><forenames>Azeez Nureni</forenames></author><author><keyname>Oluwaseyifunmitan</keyname><forenames>Osunade</forenames></author></authors><title>Approach To Solving Cybercrime And Cybersecurity</title><categories>cs.CY cs.CR</categories><comments>11 Pages, International Journal of Computer Science and Information
  Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3, No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cybercrime is becoming ever more serious. Findings from 2002 Computer Crime
and Security Survey show an upward trend that demonstrates a need for a timely
review of existing approaches to fighting this new phenomenon in the
information age. In this paper, we provide an overview of Cybercrime and
present an international perspective on fighting Cybercrime.
  This work seeks to define the concept of cyber-crime, identify reasons for
cyber-crime, how it can be eradicated, look at those involved and the reasons
for their involvement, we would look at how best to detect a criminal mail and
in conclusion, proffer recommendations that would help in checking the
increasing rate of cyber-crimes and criminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0100</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0100</id><created>2009-08-01</created><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Alford</keyname><forenames>Mark</forenames></author></authors><title>A Class of DSm Conditional Rules</title><categories>cs.AI</categories><comments>9 pages. SUbmitted to COGIS 2009 International Conference in PAris</comments><acm-class>I.2.3</acm-class><journal-ref>Proceedings of COGIS 2009 International Conference, Paris, France,
  16-18 November 2009. Also, presented at this conference</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce two new DSm fusion conditioning rules with
example, and as a generalization of them a class of DSm fusion conditioning
rules, and then extend them to a class of DSm conditioning rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0122</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0122</id><created>2009-08-02</created><authors><author><keyname>Sharma</keyname><forenames>Kalpana</forenames></author><author><keyname>Ghose</keyname><forenames>M. K.</forenames></author><author><keyname>Kuldeep</keyname></author></authors><title>Complete Security Framework for Wireless Sensor Networks</title><categories>cs.CR</categories><comments>7 pages, International Journal of Computer Science and Information
  Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3 No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security concern for a Sensor Networks and level of security desired may
differ according to application specific needs where the sensor networks are
deployed. Till now, most of the security solutions proposed for sensor networks
are layer wise i.e a particular solution is applicable to single layer itself.
So, to integrate them all is a new research challenge. In this paper we took up
the challenge and have proposed an integrated comprehensive security framework
that will provide security services for all services of sensor network. We have
added one extra component i.e. Intelligent Security Agent (ISA) to assess level
of security and cross layer interactions. This framework has many components
like Intrusion Detection System, Trust Framework, Key Management scheme and
Link layer communication protocol. We have also tested it on three different
application scenarios in Castalia and Omnet++ simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0124</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0124</id><created>2009-08-02</created><authors><author><keyname>Elalfi</keyname><forenames>Atta E. E.</forenames></author><author><keyname>ElAlami</keyname><forenames>M. E.</forenames></author></authors><title>Intelligent Advisory System for Supporting University Managers in Law</title><categories>cs.CY</categories><comments>6 pages, International Journal of Computer Science and Information
  Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3 No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rights and duties of both staff members and students are regulated by a
large and different numbers of legal regulations and rules. This large number
of rules and regulations makes the decision-making process time consuming and
error boring. Smart advisory systems could provide rapid and accurate advices
to managers and give the arguments for these advices. This paper presents an
intelligent advisory system in law to assist the legal educational processes in
universities and institutes. The aims of the system are: to provide smart legal
advisors in the universities and institutes, to integrate rules and regulations
of universities and institutes in the e-government, to ease the burden on the
legal advisor and the provision of consulting services to users, to achieve
accurate and timely presentation of the legal opinion to a given problem and to
assure flexibility for accepting changes in the rules and legal regulations.
The system is based on experienced jurists and the rules and regulations of the
law organizing Saudi Arabia universities and institutes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0126</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0126</id><created>2009-08-02</created><authors><author><keyname>de Aguiar</keyname><forenames>Alexei Barbosa</forenames></author><author><keyname>Neto</keyname><forenames>Alvaro de M. S.</forenames></author><author><keyname>Pinheiro</keyname><forenames>Placido Rogerio</forenames></author><author><keyname>Coelho</keyname><forenames>Andre L. V.</forenames></author></authors><title>Applicability of a Novel Integer Programming Model for Wireless Sensor
  Networks</title><categories>cs.NI cs.PF</categories><comments>7 pages, International Journal of Computer Science and Information
  Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3 No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an applicability analysis over a novel integer
programming model devoted to optimize power consumption efficiency in
heterogeneous wireless sensor networks. This model is based upon a schedule of
sensor allocation plans in multiple time intervals subject to coverage and
connectivity constraints. By turning off a specific set of redundant sensors in
each time interval, it is possible to reduce the total energy consumption in
the network and, at the same time, avoid partitioning the whole network by
losing some strategic sensors too prematurely. Since the network is
heterogeneous, sensors can sense different phenomena from different demand
points, with different sample rates. As the problem instances grows the time
spent to the execution turns impracticable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0160</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0160</id><created>2009-08-02</created><authors><author><keyname>Daliot</keyname><forenames>Ariel</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Self-stabilizing Byzantine Agreement</title><categories>cs.DC</categories><comments>A revision of PODC06 submission that includes full proofs and
  corrections of mistakes</comments><acm-class>C.1.4; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Byzantine agreement algorithms typically assume implicit initial state
consistency and synchronization among the correct nodes and then operate in
coordinated rounds of information exchange to reach agreement based on the
input values. The implicit initial assumptions enable correct nodes to infer
about the progression of the algorithm at other nodes from their local state.
This paper considers a more severe fault model than permanent Byzantine
failures, one in which the system can in addition be subject to severe
transient failures that can temporarily throw the system out of its assumption
boundaries. When the system eventually returns to behave according to the
presumed assumptions it may be in an arbitrary state in which any
synchronization among the nodes might be lost, and each node may be at an
arbitrary state. We present a self-stabilizing Byzantine agreement algorithm
that reaches agreement among the correct nodes in an optimal ration of faulty
to correct, by using only the assumption of eventually bounded message
transmission delay. In the process of solving the problem, two additional
important and challenging building blocks were developed: a unique
self-stabilizing protocol for assigning consistent relative times to protocol
initialization and a Reliable Broadcast primitive that progresses at the speed
of actual message delivery time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0163</identifier>
 <datestamp>2009-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0163</id><created>2009-08-02</created><updated>2009-08-15</updated><authors><author><keyname>Xie</keyname><forenames>Liang-Liang</forenames></author></authors><title>An Improvement of Cover/El Gamal's Compress-and-Forward Relay Scheme</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The compress-and-forward relay scheme developed by (Cover and El Gamal, 1979)
is improved with a modification on the decoding process. The improvement
follows as a result of realizing that it is not necessary for the destination
to decode the compressed observation of the relay; and even if the compressed
observation is to be decoded, it can be more easily done by joint decoding with
the original message, rather than in a successive way. An extension to multiple
relays is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0175</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0175</id><created>2009-08-02</created><authors><author><keyname>Stewart</keyname><forenames>Alex A.</forenames></author><author><keyname>Antoszkiewicz</keyname><forenames>Marta F.</forenames></author></authors><title>BGP Route Analysis and Management Systems</title><categories>cs.NI cs.IT math.IT</categories><comments>IEEE Proceedings of 5th International Conference on Information
  Technology</comments><report-no>ITNG'08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Border Gateway Protocol (BGP) is an important component in today's IP
network infrastructure. As the main routing protocol of the Internet, clear
understanding of its dynamics is crucial for configuring, diagnosing and
debugging Internet routing problems. Despite the increase in the services that
BGP provide such as MPLS VPNs, there is no much progress achieved in automating
the BGP management tasks. In this paper we discuss some of the problems
encountered by network engineers when managing BGP networks. We also describe
some of the open source tools and methods that attempt to resolve these issues.
Then we present some of the features that, if implemented, will ease BGP
management related tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0191</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0191</id><created>2009-08-03</created><authors><author><keyname>WANG</keyname><forenames>Wenguang</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>TOLK</keyname><forenames>Andreas</forenames><affiliation>Engineering Management &amp; Systems Engineering, Old Dominion University, Norfolk, VA, United States</affiliation></author><author><keyname>WANG</keyname><forenames>Weiping</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author></authors><title>The Levels of Conceptual Interoperability Model: Applying Systems
  Engineering Principles to M&amp;S</title><categories>cs.SE</categories><comments>9 pages, 2 figures, 4 tables, Proceedings of Spring Simulation
  Multiconference (SpringSim'09). San Diego, CA, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the use of the Levels of Conceptual Interoperability
Model (LCIM) as a framework for conceptual modeling and its descriptive and
prescriptive uses. LCIM is applied to show its potential and shortcomings in
the current simulation interoperability approaches, in particular the High
Level Architecture (HLA) and Base Object Models (BOM). It emphasizes the need
to apply rigorous engineering methods and principles and replace ad-hoc
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0216</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0216</id><created>2009-08-03</created><authors><author><keyname>Naji</keyname><forenames>A. W.</forenames></author><author><keyname>Hameed</keyname><forenames>Shihab A.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author><author><keyname>Al-Khateeb</keyname><forenames>Wajdi F.</forenames></author><author><keyname>Khalifa</keyname><forenames>Othman O.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author><author><keyname>Gunawan</keyname><forenames>Teddy S.</forenames></author></authors><title>Novel Framework for Hidden Data in the Image Page within Executable File
  Using Computation between Advanced Encryption Standard and Distortion
  Techniques</title><categories>cs.CR</categories><comments>6 Pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3, No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hurried development of multimedia and internet allows for wide
distribution of digital media data. It becomes much easier to edit, modify and
duplicate digital information. In additional, digital document is also easy to
copy and distribute, therefore it may face many threats. It became necessary to
find an appropriate protection due to the significance, accuracy and
sensitivity of the information. Furthermore, there is no formal method to be
followed to discover a hidden data. In this paper, a new information hiding
framework is presented.The proposed framework aim is implementation of
framework computation between advance encryption standard (AES) and distortion
technique (DT) which embeds information in image page within executable file
(EXE file) to find a secure solution to cover file without change the size of
cover file. The framework includes two main functions; first is the hiding of
the information in the image page of EXE file, through the execution of four
process (specify the cover file, specify the information file, encryption of
the information, and hiding the information) and the second function is the
extraction of the hiding information through three process (specify the stego
file, extract the information, and decryption of the information).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0221</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0221</id><created>2009-08-03</created><authors><author><keyname>Kale</keyname><forenames>Shilpa</forenames></author><author><keyname>Shriramwar</keyname><forenames>S. S.</forenames></author></authors><title>FPGA-based Controller for a Mobile Robot</title><categories>cs.RO cs.AR</categories><comments>5 Pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3, No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With application in the robotics and automation, more and more it becomes
necessary the development of applications based on methodologies that
facilitate future modifications, updates and enhancements in the original
projected system. This project presents a conception of mobile robots using
rapid prototyping, distributing the several control actions in growing levels
of complexity and computing proposal oriented to embed systems implementation.
This kind of controller can be tested on different platform representing the
mobile robots using reprogrammable logic components (FPGA). This mobile robot
will detect obstacle and also be able to control the speed. Different modules
will be Actuators, Sensors, wireless transmission. All this modules will be
interfaced using FPGA controller. I would like to construct a mechanically
simple robot model, which can measure the distance from obstacle with the aid
of sensor and accordingly should able to control the speed of motor. I would
like to construct a mechanically simple robot model, which can measure the
distance from obstacle with the aid of sensor and accordingly should able to
control the speed of motor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0222</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0222</id><created>2009-08-03</created><authors><author><keyname>Anita</keyname><forenames>E. A. Mary</forenames></author><author><keyname>Vasudevan</keyname><forenames>V.</forenames></author></authors><title>Performance Evaluation of Mesh based Multicast Reactive Routing Protocol
  under Black Hole Attack</title><categories>cs.CR cs.PF</categories><comments>6 Pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3, No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile ad-hoc network is an autonomous system of mobile nodes connected by
wireless links in which nodes cooperate by forwarding packets for each other
thereby enabling communication beyond direct wireless transmission range. The
wireless and dynamic nature of ad-hoc networks makes them vulnerable to attacks
especially in routing protocols. Providing security in mobile ad-hoc networks
has been a major issue over the recent years. One of the prominent mesh base
reactive multicast routing protocols used in ad-hoc networks is On Demand
Multicast Routing protocol (ODMRP). The security of ODMRP is compromised by a
primary routing attack called black hole attack. In this attack a malicious
node advertises itself as having the shortest path to the node whose packets it
wants to intercept. This paper discusses the impact of black hole attack on
ODMRP under various scenarios. The performance is evaluated using metrics such
as packet delivery ratio and end to end delay for various numbers of senders
and receivers via simulation. Simulations are carried out using network
simulator ns-2. The results enable us to propose solutions to counter the
effect of black hole attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0239</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0239</id><created>2009-08-03</created><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author></authors><title>On Bijective Variants of the Burrows-Wheeler Transform</title><categories>cs.DS</categories><comments>15 pages, presented at the Prague Stringology Conference 2009 (PSC
  2009)</comments><acm-class>E.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sort transform (ST) is a modification of the Burrows-Wheeler transform
(BWT). Both transformations map an arbitrary word of length n to a pair
consisting of a word of length n and an index between 1 and n. The BWT sorts
all rotation conjugates of the input word, whereas the ST of order k only uses
the first k letters for sorting all such conjugates. If two conjugates start
with the same prefix of length k, then the indices of the rotations are used
for tie-breaking. Both transforms output the sequence of the last letters of
the sorted list and the index of the input within the sorted list. In this
paper, we discuss a bijective variant of the BWT (due to Scott), proving its
correctness and relations to other results due to Gessel and Reutenauer (1993)
and Crochemore, Desarmenien, and Perrin (2005). Further, we present a novel
bijective variant of the ST.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0302</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0302</id><created>2009-08-03</created><authors><author><keyname>Sasoglu</keyname><forenames>Eren</forenames></author><author><keyname>Telatar</keyname><forenames>Emre</forenames></author><author><keyname>Arikan</keyname><forenames>Erdal</forenames></author></authors><title>Polarization for arbitrary discrete memoryless channels</title><categories>cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel polarization, originally proposed for binary-input channels, is
generalized to arbitrary discrete memoryless channels. Specifically, it is
shown that when the input alphabet size is a prime number, a similar
construction to that for the binary case leads to polarization. This method can
be extended to channels of composite input alphabet sizes by decomposing such
channels into a set of channels with prime input alphabet sizes. It is also
shown that all discrete memoryless channels can be polarized by randomized
constructions. The introduction of randomness does not change the order of
complexity of polar code construction, encoding, and decoding. A previous
result on the error probability behavior of polar codes is also extended to the
case of arbitrary discrete memoryless channels. The generalization of
polarization to channels with arbitrary finite input alphabet sizes leads to
polar-coding methods for approaching the true (as opposed to symmetric) channel
capacity of arbitrary channels with discrete or continuous input alphabets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0319</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0319</id><created>2009-08-03</created><authors><author><keyname>Filippi</keyname><forenames>Sarah</forenames><affiliation>LTCI</affiliation></author><author><keyname>Capp&#xe9;</keyname><forenames>Olivier</forenames><affiliation>LTCI</affiliation></author><author><keyname>Garivier</keyname><forenames>Aur&#xe9;lien</forenames><affiliation>LTCI</affiliation></author></authors><title>Regret Bounds for Opportunistic Channel Access</title><categories>stat.ML cs.AI cs.LG cs.NI</categories><proxy>ccsd hal-00408867</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of opportunistic channel access in a primary system
composed of independent Gilbert-Elliot channels where the secondary (or
opportunistic) user does not dispose of a priori information regarding the
statistical characteristics of the system. It is shown that this problem may be
cast into the framework of model-based learning in a specific class of
Partially Observed Markov Decision Processes (POMDPs) for which we introduce an
algorithm aimed at striking an optimal tradeoff between the exploration (or
estimation) and exploitation requirements. We provide finite horizon regret
bounds for this algorithm as well as a numerical evaluation of its performance
in the single channel model as well as in the case of stochastically identical
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0320</identifier>
 <datestamp>2014-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0320</id><created>2009-08-03</created><authors><author><keyname>Adimurthi</keyname><forenames>Adimurthi</forenames><affiliation>INRIA Rocquencourt, INRIA Rocquencourt</affiliation></author><author><keyname>Gowda</keyname><forenames>G. D. Veerappa</forenames><affiliation>INRIA Rocquencourt, INRIA Rocquencourt</affiliation></author><author><keyname>Jaffr&#xe9;</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>INRIA Rocquencourt, INRIA Rocquencourt</affiliation></author></authors><title>Applications of the DFLU flux to systems of conservation laws</title><categories>cs.NA math.AP math.NA</categories><proxy>ccsd inria-00408869</proxy><report-no>RR-7009</report-no><journal-ref>Journal of Computational and Applied Mathematics 247 (2013)
  102-103</journal-ref><doi>10.1016/j.cam.2012.12.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The DFLU numerical flux was introduced in order to solve hyperbolic scalar
conservation laws with a flux function discontinuous in space. We show how this
flux can be used to solve systems of conservation laws. The obtained numerical
flux is very close to a Godunov flux. As an example we consider a system
modeling polymer flooding in oil reservoir engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0350</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0350</id><created>2009-08-03</created><authors><author><keyname>Barman</keyname><forenames>Siddharth</forenames></author><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author></authors><title>Region growing for multi-route cuts</title><categories>cs.DS</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a number of multi-route cut problems: given a graph G=(V,E) and
connectivity thresholds k_(u,v) on pairs of nodes, the goal is to find a
minimum cost set of edges or vertices the removal of which reduces the
connectivity between every pair (u,v) to strictly below its given threshold.
These problems arise in the context of reliability in communication networks;
They are natural generalizations of traditional minimum cut problems where the
thresholds are either 1 (we want to completely separate the pair) or infinity
(we don't care about the connectivity for the pair). We provide the first
non-trivial approximations to a number of variants of the problem including for
both node-disjoint and edge-disjoint connectivity thresholds. A main
contribution of our work is an extension of the region growing technique for
approximating minimum multicuts to the multi-route setting. When the
connectivity thresholds are either 2 or infinity (the &quot;2-route cut&quot; case), we
obtain polylogarithmic approximations while satisfying the thresholds exactly.
For arbitrary connectivity thresholds this approach leads to bicriteria
approximations where we approximately satisfy the thresholds and approximately
minimize the cost. We present a number of different algorithms achieving
different cost-connectivity tradeoffs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0358</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0358</id><created>2009-08-03</created><authors><author><keyname>Weng</keyname><forenames>Yang</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>Outage analysis of Block-Fading Gaussian Interference Channels</title><categories>cs.IT math.IT</categories><comments>39 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the asymptotic behavior of two-source block-fading
single-antenna Gaussian interference channels in the high-SNR regime by means
of the diversity-multiplexing tradeoff. We consider a general setting where the
users and the average channel gains are not restricted to be symmetric. Our
results are not just extensions of previous results for symmetric networks, as
our setting covers scenarios that are not possible under the symmetric
assumption, such as the case of &quot;mixed&quot; interference, i.e., when difference
sources have different distances from their intended receivers. We derive upper
and lower bounds on the diversity. We show that for a fairly large set of
channel parameters the two bounds coincides.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0362</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0362</id><created>2009-08-03</created><authors><author><keyname>Hou</keyname><forenames>I-Hong</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Utility Maximization for Delay Constrained QoS in Wireless</title><categories>cs.NI</categories><comments>submitted to INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of utility maximization for clients with delay
based QoS requirements in wireless networks. We adopt a model used in a
previous work that characterizes the QoS requirements of clients by their delay
constraints, channel reliabilities, and delivery ratio requirements. In this
work, we assume that the utility of a client is a function of the delivery
ratio it obtains. We treat the delivery ratio for a client as a tunable
parameter by the access point (AP), instead of a given value as in the previous
work. We then study how the AP should assign delivery ratios to clients so that
the total utility of all clients is maximized.
  We apply the techniques introduced in two previous papers to decompose the
utility maximization problem into two simpler problems, a CLIENT problem and an
ACCESS-POINT problem. We show that this decomposition actually describes a
bidding game, where clients bid for the service time from the AP. We prove that
although all clients behave selfishly in this game, the resulting equilibrium
point of the game maximizes the total utility. In addition, we also establish
an efficient scheduling policy for the AP to reach the optimal point of the
ACCESS-POINT problem. We prove that the policy not only approaches the optimal
point but also achieves some forms of fairness among clients. Finally,
simulation results show that our proposed policy does achieve higher utility
than all other compared policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0373</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0373</id><created>2009-08-03</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>A Reflection on the Structure and Process of the Web of Data</title><categories>cs.AI cs.DL cs.GL</categories><report-no>LA-UR-09-03724</report-no><acm-class>E.1; C.2.4</acm-class><journal-ref>Bulletin of the American Society for Information Science and
  Technology, American Society for Information Science and Technology, volume
  35, number 6, ISSN: 1550-8366, LA-UR-09-03724, pages 38-43, September 2009</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The Web community has introduced a set of standards and technologies for
representing, querying, and manipulating a globally distributed data structure
known as the Web of Data. The proponents of the Web of Data envision much of
the world's data being interrelated and openly accessible to the general
public. This vision is analogous in many ways to the Web of Documents of common
knowledge, but instead of making documents and media openly accessible, the
focus is on making data openly accessible. In providing data for public use,
there has been a stimulated interest in a movement dubbed Open Data. Open Data
is analogous in many ways to the Open Source movement. However, instead of
focusing on software, Open Data is focused on the legal and licensing issues
around publicly exposed data. Together, various technological and legal tools
are laying the groundwork for the future of global-scale data management on the
Web. As of today, in its early form, the Web of Data hosts a variety of data
sets that include encyclopedic facts, drug and protein data, metadata on music,
books and scholarly articles, social network representations, geospatial
information, and many other types of information. The size and diversity of the
Web of Data is a demonstration of the flexibility of the underlying standards
and the overall feasibility of the project as a whole. The purpose of this
article is to provide a review of the technological underpinnings of the Web of
Data as well as some of the hurdles that need to be overcome if the Web of Data
is to emerge as the defacto medium for data representation, distribution, and
ultimately, processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0375</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0375</id><created>2009-08-03</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Karthekeyan</forenames></author><author><keyname>Goyal</keyname><forenames>Navin</forenames></author><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author></authors><title>Deterministic Algorithms for the Lovasz Local Lemma</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lovasz Local Lemma (LLL) is a powerful result in probability theory that
states that the probability that none of a set of bad events happens is nonzero
if the probability of each event is small compared to the number of events that
depend on it. It is often used in combination with the probabilistic method for
non-constructive existence proofs. A prominent application is to k-CNF
formulas, where LLL implies that, if every clause in the formula shares
variables with at most d &lt;= 2^k/e other clauses then such a formula has a
satisfying assignment. Recently, a randomized algorithm to efficiently
construct a satisfying assignment was given by Moser. Subsequently Moser and
Tardos gave a randomized algorithm to construct the structures guaranteed by
the LLL in a very general algorithmic framework. We address the main problem
left open by Moser and Tardos of derandomizing these algorithms efficiently.
Specifically, for a k-CNF formula with m clauses and d &lt;= 2^{k/(1+\eps)}/e for
some \eps\in (0,1), we give an algorithm that finds a satisfying assignment in
time \tilde{O}(m^{2(1+1/\eps)}). This improves upon the deterministic
algorithms of Moser and of Moser-Tardos with running time m^{\Omega(k^2)} which
is superpolynomial for k=\omega(1) and upon other previous algorithms which
work only for d\leq 2^{k/16}/e. Our algorithm works efficiently for a general
version of LLL under the algorithmic framework of Moser and Tardos, and is also
parallelizable, i.e., has polylogarithmic running time using polynomially many
processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0390</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0390</id><created>2009-08-04</created><authors><author><keyname>Bouzid</keyname><forenames>Zohir</forenames><affiliation>LIP6</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Byzantine Convergence in Robots Networks: The Price of Asynchrony</title><categories>cs.DC cs.RO</categories><proxy>ccsd inria-00408881</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the convergence problem in fully asynchronous, uni-dimensional robot
networks that are prone to Byzantine (i.e. malicious) failures. In these
settings, oblivious anonymous robots with arbitrary initial positions are
required to eventually converge to an a apriori unknown position despite a
subset of them exhibiting Byzantine behavior. Our contribution is twofold. We
propose a deterministic algorithm that solves the problem in the most generic
settings: fully asynchronous robots that operate in the non-atomic CORDA model.
Our algorithm provides convergence in 5f+1-sized networks where f is the upper
bound on the number of Byzantine robots. Additionally, we prove that 5f+1 is a
lower bound whenever robot scheduling is fully asynchronous. This constrasts
with previous results in partially synchronous robots networks, where 3f+1
robots are necessary and sufficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0398</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0398</id><created>2009-08-04</created><authors><author><keyname>Anceaume</keyname><forenames>Emmanuelle</forenames><affiliation>INRIA - Irisa</affiliation></author><author><keyname>Ludinard</keyname><forenames>R.</forenames><affiliation>INRIA - Irisa</affiliation></author><author><keyname>Sericola</keyname><forenames>B.</forenames><affiliation>INRIA - Irisa</affiliation></author><author><keyname>Tronel</keyname><forenames>F.</forenames></author><author><keyname>Brasiliero</keyname><forenames>F.</forenames></author></authors><title>Analytical Study of Adversarial Strategies in Cluster-based Overlays</title><categories>cs.GT</categories><proxy>ccsd hal-00408871</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheideler has shown that peer-to-peer overlays networks can only survive
Byzantine attacks if malicious nodes are not able to predict what is going to
be the topology of the network for a given sequence of join and leave
operations. In this paper we investigate adversarial strategies by following
specific games. Our analysis demonstrates first that an adversary can very
quickly subvert DHT-based overlays by simply never triggering leave operations.
We then show that when all nodes (honest and malicious ones) are imposed on a
limited lifetime, the system eventually reaches a stationary regime where the
ratio of polluted clusters is bounded, independently from the initial amount of
corruption in the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0411</identifier>
 <datestamp>2009-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0411</id><created>2009-08-04</created><updated>2009-12-15</updated><authors><author><keyname>Mayer</keyname><forenames>Gerhard</forenames></author></authors><title>Data management in systems biology I - Overview and bibliography</title><categories>cs.DB cs.DS q-bio.OT</categories><comments>20 pages</comments><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large systems biology projects can encompass several workgroups often located
in different countries. An overview about existing data standards in systems
biology and the management, storage, exchange and integration of the generated
data in large distributed research projects is given, the pros and cons of the
different approaches are illustrated from a practical point of view, the
existing software - open source as well as commercial - and the relevant
literature is extensively overview, so that the reader should be enabled to
decide which data management approach is the best suited for his special needs.
An emphasis is laid on the use of workflow systems and of TAB-based formats.
The data in this format can be viewed and edited easily using spreadsheet
programs which are familiar to the working experimental biologists. The use of
workflows for the standardized access to data in either own or publicly
available databanks and the standardization of operation procedures is
presented. The use of ontologies and semantic web technologies for data
management will be discussed in a further paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0464</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0464</id><created>2009-08-04</created><updated>2011-10-07</updated><authors><author><keyname>Staworko</keyname><forenames>Slawomir</forenames></author><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author><author><keyname>Marcinkowski</keyname><forenames>Jerzy</forenames></author></authors><title>Prioritized Repairing and Consistent Query Answering in Relational
  Databases</title><categories>cs.DB</categories><comments>Accepted to the special SUM'08 issue of AMAI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A consistent query answer in an inconsistent database is an answer obtained
in every (minimal) repair. The repairs are obtained by resolving all conflicts
in all possible ways. Often, however, the user is able to provide a preference
on how conflicts should be resolved. We investigate here the framework of
preferred consistent query answers, in which user preferences are used to
narrow down the set of repairs to a set of preferred repairs. We axiomatize
desirable properties of preferred repairs. We present three different families
of preferred repairs and study their mutual relationships. Finally, we
investigate the complexity of preferred repairing and computing preferred
consistent query answers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0482</identifier>
 <datestamp>2014-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0482</id><created>2009-08-04</created><updated>2014-08-25</updated><authors><author><keyname>Su</keyname><forenames>Shenghui</forenames></author><author><keyname>Lu</keyname><forenames>Shuwang</forenames></author></authors><title>REESSE1+ . Reward . Proof by Experiment . A New Approach to Proof of P
  != NP</title><categories>cs.CR</categories><comments>5 pages</comments><acm-class>F.1.3; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The authors discuss what is provable security in cryptography. Think that
provable security is asymptotic, relative, and dynamic, and only a supplement
to but not a replacement of exact security analysis. Because the conjecture P
!= NP has not been proven yet, and it is possible in terms of the two
incompleteness theorems of Kurt Godel that there is some cryptosystem of which
the security cannot or only ideally be proven in the random oracle model, the
security of a cryptosystem is between provability and unprovability, and any
academic conclusion must be checked and verified with practices or experiments
as much as possible. Extra, a new approach to proof of P != NP is pointed out.
Lastly, a reward is offered for the subexponential time solutions to the three
REESSE1+ problems: MPP, ASPP, and TLP with n &gt;= 80 and lg M &gt;= 80, which may be
regarded as a type of security proof by experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0488</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0488</id><created>2009-08-04</created><updated>2010-07-23</updated><authors><author><keyname>Mor</keyname><forenames>Ares Rib&#xf3;</forenames></author><author><keyname>Rote</keyname><forenames>G&#xfc;nter</forenames></author><author><keyname>Schulz</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Small grid embeddings of 3-polytopes</title><categories>cs.CG</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an algorithm that embeds a given 3-connected planar graph as a
convex 3-polytope with integer coordinates. The size of the coordinates is
bounded by $O(2^{7.55n})=O(188^{n})$. If the graph contains a triangle we can
bound the integer coordinates by $O(2^{4.82n})$. If the graph contains a
quadrilateral we can bound the integer coordinates by $O(2^{5.46n})$. The
crucial part of the algorithm is to find a convex plane embedding whose edges
can be weighted such that the sum of the weighted edges, seen as vectors,
cancel at every point. It is well known that this can be guaranteed for the
interior vertices by applying a technique of Tutte. We show how to extend
Tutte's ideas to construct a plane embedding where the weighted vector sums
cancel also on the vertices of the boundary face.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0494</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0494</id><created>2009-08-04</created><authors><author><keyname>Fraguas</keyname><forenames>Francisco L&#xf3;pez</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Merz</keyname><forenames>Stephan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Hortal&#xe1;</keyname><forenames>Juan Rodr&#xed;guez</forenames></author></authors><title>A Formalization of the Semantics of Functional-Logic Programming in
  Isabelle</title><categories>cs.LO</categories><proxy>ccsd inria-00408964</proxy><journal-ref>22nd International Conference Theorem Proving for Higher-Order
  Logics (TPHOLs 2009): emerging trends session (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern functional-logic programming languages like Toy or Curry feature
non-strict non-deterministic functions that behave under call-time choice
semantics. A standard formulation for this semantics is the CRWL logic, that
specifies a proof calculus for computing the set of possible results for each
expression. In this paper we present a formalization of that calculus in the
Isabelle/HOL proof assistant. We have proved some basic properties of CRWL:
closedness under c-substitutions, polarity and compositionality. We also
discuss some insights that have been gained, such as the fact that left
linearity of program rules is not needed for any of these results to hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0497</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0497</id><created>2009-08-04</created><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Lucani</keyname><forenames>Daniel</forenames></author><author><keyname>Shi</keyname><forenames>Xiaomeng</forenames></author><author><keyname>Zhao</keyname><forenames>Fang</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Network Coding for Multi-Resolution Multicast</title><categories>cs.NI cs.IT math.IT</categories><comments>9 pages, 16 figures, submitted to IEEE INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-resolution codes enable multicast at different rates to different
receivers, a setup that is often desirable for graphics or video streaming. We
propose a simple, distributed, two-stage message passing algorithm to generate
network codes for single-source multicast of multi-resolution codes. The goal
of this &quot;pushback algorithm&quot; is to maximize the total rate achieved by all
receivers, while guaranteeing decodability of the base layer at each receiver.
By conducting pushback and code generation stages, this algorithm takes
advantage of inter-layer as well as intra-layer coding. Numerical simulations
show that in terms of total rate achieved, the pushback algorithm outperforms
routing and intra-layer coding schemes, even with codeword sizes as small as 10
bits. In addition, the performance gap widens as the number of receivers and
the number of nodes in the network increases. We also observe that naiive
inter-layer coding schemes may perform worse than intra-layer schemes under
certain network conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0512</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0512</id><created>2009-08-04</created><updated>2014-10-27</updated><authors><author><keyname>Kuperberg</keyname><forenames>Greg</forenames><affiliation>UC Davis</affiliation></author></authors><title>How hard is it to approximate the Jones polynomial?</title><categories>quant-ph cs.CC math.QA</categories><comments>19 pages. Don't miss this major revision! Includes more complete
  explanations of all results, and refinements of both Aaronson's theorem and
  the Solovay-Kitaev theorem. To appear in ToC</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Freedman, Kitaev, and Wang [arXiv:quant-ph/0001071], and later Aharonov,
Jones, and Landau [arXiv:quant-ph/0511096], established a quantum algorithm to
&quot;additively&quot; approximate the Jones polynomial V(L,t) at any principal root of
unity t. The strength of this additive approximation depends exponentially on
the bridge number of the link presentation. Freedman, Larsen, and Wang
[arXiv:math/0103200] established that the approximation is universal for
quantum computation at a non-lattice, principal root of unity; and Aharonov and
Arad [arXiv:quant-ph/0605181] established a uniform version of this result.
  In this article, we show that any value-dependent approximation of the Jones
polynomial at these non-lattice roots of unity is #P-hard. If given the power
to decide whether |V(L,t)| &gt; a or |V(L,t)| &lt; b for fixed constants a &gt; b &gt; 0,
there is a polynomial-time algorithm to exactly count the solutions to
arbitrary combinatorial equations. In our argument, the result follows fairly
directly from the universality result and Aaronson's theorem that PostBQP = PP
[arXiv:quant-ph/0412187].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0515</identifier>
 <datestamp>2009-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0515</id><created>2009-08-04</created><authors><author><keyname>Chen</keyname><forenames>Hongyang</forenames></author><author><keyname>Shi</keyname><forenames>Qingjiang</forenames></author><author><keyname>Huang</keyname><forenames>Pei</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Sezaki</keyname><forenames>Kaoru</forenames></author></authors><title>Mobile Anchor Assisted Node Localization for Wireless Sensor Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, IEEE PIMRC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a cooperative localization algorithm is proposed that
considers the existence of obstacles in mobilityassisted wireless sensor
networks (WSNs). In this scheme, a mobile anchor (MA) node cooperates with
static sensor nodes and moves actively to refine location performance. The
localization accuracy of the proposed algorithm can be improved further by
changing the transmission range of mobile anchor node. The algorithm takes
advantage of cooperation betweenMAs and static sensors while, at the same time,
taking into account the relay node availability to make the best use of beacon
signals. For achieving high localization accuracy and coverage, a novel convex
position estimation algorithm is proposed, which can effectively solve the
localization problem when infeasible points occur because of the effects of
radio irregularity and obstacles. This method is the only range-free based
convex method to solve the localization problem when the feasible set of
localization inequalities is empty. Simulation results demonstrate the
effectiveness of this algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0516</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0516</id><created>2009-08-04</created><authors><author><keyname>Guervos</keyname><forenames>Juan J. Merelo</forenames></author></authors><title>Still doing evolutionary algorithms with Perl</title><categories>cs.NE</categories><comments>Corrected version of the paper published in YAPC::EU::2009, Corporate
  Perl, pp 83-97</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Algorithm::Evolutionary (A::E from now on) was introduced in 2002, after a
talk in YAPC::EU in Munich. 7 years later, A::E is in its 0.67 version (past
its &quot;number of the beast&quot; 0.666), and has been used extensively, to the point
of being the foundation of much of the (computer) science being done by our
research group (and, admittedly, not many others). All is not done, however;
now A::E is being integrated with POE so that evolutionary algorithms (EAs) can
be combined with all kinds of servers and used in client, servers, and anything
in between. In this companion to the talk I will explain what evolutionary
algorithms are, what they are being used for, how to do them with Perl (using
these or other fine modules found in CPAN) and what evolutionary algorithms can
do for Perl at large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0548</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0548</id><created>2009-08-04</created><authors><author><keyname>J.</keyname><forenames>Hanumanthappa</forenames></author><author><keyname>H</keyname><forenames>Manjaiah D.</forenames></author></authors><title>IPv6 and IPv4 Threat reviews with Automatic Tunneling and Configuration
  Tunneling Considerations Transitional Model:A Case Study for University of
  Mysore Network</title><categories>cs.NI cs.CR</categories><comments>12 Pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3, No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The actual transition from IPv4 to IPv6 requires network administrators to
become aware of the next generation protocol and the associated risk
problems.Due to the scale and complexity of current internet architecture how
to protect from the existing investment and reduce the negative influence to
users and service providers during the transition from IPv4 to IPv6 is a very
important future topic for the advanced version of an internet
architecture.This paper summarizes and compares the IPv6 transition mechanism
methods like Dual Stack,Tunneling issues like IPv6 Automatic tunneling and
manually configured tunneling considerations, the IPv6 transition
scenarios,IPv6 transition security problems,highlights IPv6 and IPv4 threat
review with automatic tunneling and configuration tunneling considerations.In
this paper we have proposed a transitional threat model for automatic tunneling
and a configuration tunneling that could be followed by the University of
Mysore(UoM),to estimate automatic tunneling and a manually configured tunneling
threat review issues.Furthermore,there are different tunneling mechanisms such
as IPv6 over IPv4 GRE Tunnel,Tunnel broker,Automatic IPv4 Compatible Tunnel and
Automatic 6 to 4 Tunnel and also outlines many of the common known threats
against IPv6 and then it compares and contrast how these threats are similar
ones,might affect an IPv6 network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0551</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0551</id><created>2009-08-04</created><authors><author><keyname>Kumar</keyname><forenames>Dr. Shishir</forenames></author><author><keyname>Rawat</keyname><forenames>U. S.</forenames></author><author><keyname>Jasra</keyname><forenames>Sameer Kumar</forenames></author><author><keyname>Jain</keyname><forenames>Akshay Kumar</forenames></author></authors><title>Efficient methodology for implementation of Encrypted File System in
  User Space</title><categories>cs.CR</categories><comments>8 Pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS July 2009, Vol. 3, No. 1, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Encrypted File System (EFS) pushes encryption services into the file
system itself. EFS supports secure storage at the system level through a
standard UNIX file system interface to encrypted files. User can associate a
cryptographic key with the directories they wish to protect. Files in these
directories (as well as their pathname components) are transparently encrypted
and decrypted with the specified key without further user intervention; clear
text is never stored on a disk or sent to a remote file server. EFS can use any
available file system for its underlying storage without modifications,
including remote file servers such as NFS. System management functions, such as
file backup, work in a normal manner and without knowledge of the key.
Performance is an important factor to users since encryption can be time
consuming. This paper describes the design and implementation of EFS in user
space using faster cryptographic algorithms on UNIX Operating system.
Implementing EFS in user space makes it portable and flexible; Kernel size will
also not increase resulting in more reliable &amp; efficient Operating System.
Encryption techniques for file system level encryption are described, and
general issues of cryptographic system interfaces to support routine secure
computing are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0554</identifier>
 <datestamp>2011-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0554</id><created>2009-08-05</created><updated>2011-06-13</updated><authors><author><keyname>Nayebi</keyname><forenames>Aran</forenames></author></authors><title>On integers as the sum of a prime and a $k$-th power</title><categories>math.NT cs.DS</categories><comments>This paper has been withdrawn by the author due to several errors in
  the manuscript, a prominent problem being that it has been known at least
  since Tarski that in real numbers there exists a deterministic Turing machine
  which determines if a variety is empty or nonempty</comments><msc-class>11P32, 11P55, 11D85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{R}_k(n)$ be the number of representations of an integer $n$ as
the sum of a prime and a $k$-th power. Define E_k(X) := |\{n \le X, n \in I_k,
n\text{not a sum of a prime and a $k$-th power}\}|.
  Hardy and Littlewood conjectured that for $k = 2$ and $k=3$, E_k(X) \ll_{k}
1. In this note we present an alternative approach grounded in the theory of
Diophantine equations towards a proof of the conjecture for all $k \ge 2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0567</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0567</id><created>2009-08-04</created><authors><author><keyname>Hassanzadeh</keyname><forenames>Oktie</forenames></author><author><keyname>Kementsietsidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Lim</keyname><forenames>Lipyeow</forenames></author><author><keyname>Miller</keyname><forenames>Renee J.</forenames></author><author><keyname>Wang</keyname><forenames>Min</forenames></author></authors><title>LinkedCT: A Linked Data Space for Clinical Trials</title><categories>cs.DB cs.CE cs.IR</categories><comments>5 pages, 1 figure, 4 tables</comments><acm-class>H.2.8; H.3.5; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Linked Clinical Trials (LinkedCT) project aims at publishing the first
open semantic web data source for clinical trials data. The database exposed by
LinkedCT is generated by (1) transforming existing data sources of clinical
trials into RDF, and (2) discovering semantic links between the records in the
trials data and several other data sources. In this paper, we discuss several
challenges involved in these two steps and present the methodology used in
LinkedCT to overcome these challenges. Our approach for semantic link discovery
involves using state-of-the-art approximate string matching techniques combined
with ontology-based semantic matching of the records, all performed in a
declarative and easy-to-use framework. We present an evaluation of the
performance of our proposed techniques in several link discovery scenarios in
LinkedCT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0570</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0570</id><created>2009-08-04</created><authors><author><keyname>Rai</keyname><forenames>Piyush</forenames></author><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>The Infinite Hierarchical Factor Regression Model</title><categories>cs.LG stat.ML</categories><journal-ref>NIPS 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a nonparametric Bayesian factor regression model that accounts for
uncertainty in the number of factors, and the relationship between factors. To
accomplish this, we propose a sparse variant of the Indian Buffet Process and
couple this with a hierarchical model over factors, based on Kingman's
coalescent. We apply this model to two problems (factor analysis and factor
regression) in gene-expression data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0572</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0572</id><created>2009-08-04</created><authors><author><keyname>Rai</keyname><forenames>Piyush</forenames></author><author><keyname>Daum&#xe9;</keyname><forenames>Hal</forenames><suffix>III</suffix></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Streamed Learning: One-Pass SVMs</title><categories>cs.LG stat.ML</categories><journal-ref>IJCAI 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a streaming model for large-scale classification (in the context
of $\ell_2$-SVM) by leveraging connections between learning and computational
geometry. The streaming model imposes the constraint that only a single pass
over the data is allowed. The $\ell_2$-SVM is known to have an equivalent
formulation in terms of the minimum enclosing ball (MEB) problem, and an
efficient algorithm based on the idea of \emph{core sets} exists (Core Vector
Machine, CVM). CVM learns a $(1+\varepsilon)$-approximate MEB for a set of
points and yields an approximate solution to corresponding SVM instance.
However CVM works in batch mode requiring multiple passes over the data. This
paper presents a single-pass SVM which is based on the minimum enclosing ball
of streaming data. We show that the MEB updates for the streaming case can be
easily adapted to learn the SVM weight vector in a way similar to using online
stochastic gradient updates. Our algorithm performs polylogarithmic computation
at each example, and requires very small and constant storage. Experimental
results show that, even in such restrictive settings, we can learn efficiently
in just one pass and get accuracies comparable to other state-of-the-art SVM
solvers (batch and online). We also give an analysis of the algorithm, and
discuss some open issues and possible extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0583</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0583</id><created>2009-08-05</created><updated>2009-08-07</updated><authors><author><keyname>Pickens</keyname><forenames>Jeremy</forenames></author><author><keyname>Golovchinsky</keyname><forenames>Gene</forenames></author><author><keyname>Morris</keyname><forenames>Meredith Ringel</forenames></author></authors><title>Proceedings of 1st International Workshop on Collaborative Information
  Seeking</title><categories>cs.IR cs.HC</categories><comments>Fixed some typos</comments><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of the workshop is to bring together researchers interested in
various aspects of small-team collaborative search to share ideas, to stimulate
research in the area, and to increase the visibility of this emerging area. We
expect to identify promising directions for further exploration and to
establish collaborative links among research groups. The workshop took place on
June 20, 2008 in Pittsburgh, Pennsylvania, USA, in conjunction with the JCDL
2008 conference.
  The workshop was organized around three themes: practices, models, and
evaluation. We started with a discussion (still ongoing) about terminology,
about how to situate our work in the existing research space. We also wanted to
motivate our modeling and design discussions with real-world examples of
collaboration. We discussed examples from the healthcare domain, students,
faculty members, the military, and businesses such as pharmaceutical companies
that conduct research.
  We discussed several models of collaborative information seeking, including
sense-making, communication, and information seeking theory based on Marcia
Bates' Berrypicking theory.
  Finally, presenters described several systems that implement various aspects
of collaboration, including using search paths, simulations of user behavior to
model system performance, and characterizing properties of groups that lead to
more effective collaboration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0586</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0586</id><created>2009-08-05</created><authors><author><keyname>Morris</keyname><forenames>Meredith Ringel</forenames></author><author><keyname>Teevan</keyname><forenames>Jaime</forenames></author></authors><title>Understanding Groups' Properties as a Means of Improving Collaborative
  Search Systems</title><categories>cs.IR cs.HC</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/mortee</report-no><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the similar properties of people involved in group search
sessions has the potential to significantly improve collaborative search
systems; such systems could be enhanced by information retrieval algorithms and
user interface modifications that take advantage of important properties, for
example by re-ordering search results using information from group members'
combined user profiles. Understanding what makes group members similar can also
assist with the identification of groups, which can be valuable for connecting
users with others with whom they might undertake a collaborative search. In
this workshop paper, we describe our current research efforts towards studying
the properties of a variety of group types. We discuss properties of groups
that may be relevant to designers of collaborative search systems, and propose
ways in which understanding such properties could influence the design of
interfaces and algorithms for collaborative Web search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0587</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0587</id><created>2009-08-05</created><authors><author><keyname>Hou</keyname><forenames>I-Hong</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Scheduling Heterogeneous Real-Time Traffic over Fading Wireless Channels</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a general approach for designing scheduling policies for real-time
traffic over wireless channels. We extend prior work, which characterizes a
real-time flow by its traffic pattern, delay bound, timely-throughput
requirement, and channel reliability, to allow time-varying channels, allow
clients to have different deadlines, and allow for the optional employment of
rate adaptation. Thus, our model allow the treatment of more realistic fading
channels as well as scenarios with mobile nodes, and the usage of more general
transmission strategies.
  We derive a sufficient condition for a scheduling policy to be feasibility
optimal, and thereby establish a class of feasibility optimal policies. We
demonstrate the utility of the identified class by deriving a feasibility
optimal policy for the scenario with rate adaptation, time-varying channels,
and heterogeneous delay bounds. When rate adaptation is not available, we also
derive a feasibility optimal policy for time-varying channels. For the scenario
where rate adaptation is not available but clients have different delay bounds,
we describe a heuristic. Simulation results are also presented which indicate
the usefulness of the scheduling policies for more realistic and complex
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0588</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0588</id><created>2009-08-05</created><updated>2009-09-01</updated><authors><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Liu</keyname><forenames>Liandong</forenames></author><author><keyname>Liang</keyname><forenames>Xiao</forenames></author></authors><title>Complex networks: A mixture of power-law and Weibull distributions</title><categories>cs.NI cond-mat.stat-mech physics.soc-ph</categories><comments>5 pages, 3 figures. Added a new finding about the degree distribution</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks have recently aroused a lot of interest. However, network
edges are considered to be the same in almost all these studies. In this paper,
we present a simple classification method, which divides the edges of
undirected, unweighted networks into two types: p2c and p2p. The p2c edge
represents a hierarchical relationship between two nodes, while the p2p edge
represents an equal relationship between two nodes. It is surprising and
unexpected that for many real-world networks from a wide variety of domains
(including computer science, transportation, biology, engineering and social
science etc), the p2c degree distribution follows a power law more strictly
than the total degree distribution, while the p2p degree distribution follows
the Weibull distribution very well. Thus, the total degree distribution can be
seen as a mixture of power-law and Weibull distributions. More surprisingly, it
is found that in many cases, the total degree distribution can be better
described by the Weibull distribution, rather than a power law as previously
suggested. By comparing two topology models, we think that the origin of the
Weibull distribution in complex networks might be a mixture of both
preferential and random attachments when networks evolve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0595</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0595</id><created>2009-08-05</created><authors><author><keyname>Evans</keyname><forenames>Brynn M.</forenames></author><author><keyname>Chi</keyname><forenames>Ed H.</forenames></author></authors><title>Towards a Model of Understanding Social Search</title><categories>cs.IR cs.HC</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/evachi</report-no><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search engine researchers typically depict search as the solitary activity of
an individual searcher. In contrast, results from our critical-incident survey
of 150 users on Amazon's Mechanical Turk service suggest that social
interactions play an important role throughout the search process. Our main
contribution is that we have integrated models from previous work in
sensemaking and information seeking behavior to present a canonical social
model of user activities before, during, and after search, suggesting where in
the search process even implicitly shared information may be valuable to
individual searchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0619</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0619</id><created>2009-08-05</created><updated>2009-08-07</updated><authors><author><keyname>Amini</keyname><forenames>Arash</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Deterministic Construction of Compressed Sensing Matrices using BCH
  Codes</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce deterministic $m\times n$ RIP fulfilling $\pm 1$
matrices of order $k$ such that $\frac{\log m}{\log k}\approx \frac{\log(\log_2
n)}{\log(\log_2 k)}$. The columns of these matrices are binary BCH code vectors
that their zeros are replaced with -1 (excluding the normalization factor). The
samples obtained by these matrices can be easily converted to the original
sparse signal; more precisely, for the noiseless samples, the simple Matching
Pursuit technique, even with less than the common computational complexity,
exactly reconstructs the sparse signal. In addition, using Devore's binary
matrices, we expand the binary scheme to matrices with $\{0,1,-1\}$ elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0660</identifier>
 <datestamp>2010-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0660</id><created>2009-08-05</created><updated>2010-02-21</updated><authors><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author></authors><title>A Short Note on Compressed Sensing with Partially Known Signal Support</title><categories>cs.IT math.IT</categories><report-no>TR-LJ-2009.02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note studies a variation of the Compressed Sensing paradigm
introduced recently by Vaswani et al., i.e. the recovery of sparse signals from
a certain number of linear measurements when the signal support is partially
known. The reconstruction method is based on a convex minimization program
coined &quot;innovative Basis Pursuit DeNoise&quot; (or iBPDN). Under the common
$\ell_2$-fidelity constraint made on the available measurements, this
optimization promotes the ($\ell_1$) sparsity of the candidate signal over the
complement of this known part. In particular, this paper extends the results of
Vaswani et al. to the cases of compressible signals and noisy measurements. Our
proof relies on a small adaption of the results of Candes in 2008 for
characterizing the stability of the Basis Pursuit DeNoise (BPDN) program. We
emphasize also an interesting link between our method and the recent work of
Davenport et al. on the $\delta$-stable embeddings and the
&quot;cancel-then-recover&quot; strategy applied to our problem. For both approaches,
reconstructions are indeed stabilized when the sensing matrix respects the
Restricted Isometry Property for the same sparsity order. We conclude by
sketching an easy numerical method relying on monotone operator splitting and
proximal methods that iteratively solves iBPDN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0667</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0667</id><created>2009-08-05</created><authors><author><keyname>Dini</keyname><forenames>Paolo</forenames></author><author><keyname>Nin-Guerrero</keyname><forenames>Jaume</forenames></author><author><keyname>Mangues-Bafalluy</keyname><forenames>Josep</forenames></author><author><keyname>Dai</keyname><forenames>Lillian</forenames></author><author><keyname>Addepalli</keyname><forenames>Sateesh</forenames></author></authors><title>Interworking Scheme Using Optimized SIP Mobility for MultiHomed Mobile
  Nodes in Wireless Heterogeneous Networks</title><categories>cs.NI cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, mobile users wish to use their multi-interface mobile devices to
access the Internet through network points of attachment (PoA) based on
heterogeneous wireless technologies. They also wish to seamlessly change the
PoAs during their ongoing sessions to improve service quality and/or reduce
monetary cost. If appropriately handled, multihomed mobile nodes offer a
potential solution to this issue. In this sense, the management of multihomed
mobile nodes in heterogeneous environment is a key research topic. In this
paper, we present an improvement of SIP mobility (pre-call plus mid-call
mobility) to support seamless mobility of multihomed mobile nodes in
heterogeneous wireless networks. Pre-call mobility is extended to associate
user identifier (i.e. SIP URI) and interface identifiers (i.e. IP addresses).
The multiple addresses of a mobile device are weighted by the user to create a
priority list in the SIP server so as to guarantee resilient reachability of
mobile nodes and to avoid unnecessary signaling through wireless links, thus
saving radio resources. Then, three variations of mid-call mobility, called
hard, hybrid and soft procedures, are also proposed. Their main aim is to
minimize, or even avoid, packet losses during interface switching at the mobile
node. The proposed solutions have been implemented in a wireless heterogeneous
testbed composed of 802.11 WLAN plus 3.5 cellular network, which are fully
controlled and configurable. The testbed has been used to study the performance
and the robustness of the three proposed mid-call mobility procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0697</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0697</id><created>2009-08-05</created><authors><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Girth of a Planar Digraph with Real Edge Weights in O(n(log n)^3) Time</title><categories>cs.DM</categories><comments>8 pages, no figures, zip file containing tex and pdf file</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The girth of a graph is the length of its shortest cycle. We give an
algorithm that computes in O(n(log n)^3) time and O(n) space the (weighted)
girth of an n-vertex planar digraph with arbitrary real edge weights. This is
an improvement of a previous time bound of O(n^(3/2)), a bound which was only
valid for non-negative edge-weights. Our algorithm can be modified to output a
shortest cycle within the same time and space bounds if such a cycle exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0703</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0703</id><created>2009-08-05</created><authors><author><keyname>Wilson</keyname><forenames>Max L.</forenames></author><author><keyname>schraefel</keyname><forenames>m. c.</forenames></author></authors><title>Evaluating Collaborative Search Interfaces with Information Seeking
  Theory</title><categories>cs.IR cs.HC</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/wilsch</report-no><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the many implicit references to the social aspects of search within
Information Seeking and Retrieval research, there has been relatively little
work that has specifically investigated the additional requirements for
collaborative search software. In this paper we re-assess a recent evaluation
framework, designed for individual information seeking experiences, to see a)
how it could still be applied to collaborative search software; b) how it could
produce additional requirements for collaborative search; and c) how it could
be extended in future work to be even more appropriate for collaborative search
evaluation. The position held after the assessment is that it can be used to
evaluate collaborative search software, while providing new insights into their
requirements. Finally, future work will validate the frameworks applicability
to collaborative search and investigate roles within collaborative groups as a
means to extend the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0704</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0704</id><created>2009-08-05</created><authors><author><keyname>Golovchinsky</keyname><forenames>Gene</forenames></author><author><keyname>Pickens</keyname><forenames>Jeremy</forenames></author><author><keyname>Back</keyname><forenames>Maribeth</forenames></author></authors><title>A Taxonomy of Collaboration in Online Information Seeking</title><categories>cs.IR cs.HC</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/golpicbac</report-no><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People can help other people find information in networked information
seeking environments. Recently, many such systems and algorithms have
proliferated in industry and in academia. Unfortunately, it is difficult to
compare the systems in meaningful ways because they often define collaboration
in different ways. In this paper, we propose a model of possible kinds of
collaboration, and illustrate it with examples from literature. The model
contains four dimensions: intent, depth, concurrency and location. This model
can be used to classify existing systems and to suggest possible opportunities
for design in this space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0709</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0709</id><created>2009-08-05</created><authors><author><keyname>Shah</keyname><forenames>Chirag</forenames></author></authors><title>Toward Collaborative Information Seeking (CIS)</title><categories>cs.IR cs.HC</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/sha</report-no><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is natural for humans to collaborate while dealing with complex problems.
In this article I consider this process of collaboration in the context of
information seeking. The study and discussion presented here are driven by two
dissatisfactions: (1) the majority of IR systems today do not facilitate
collaboration directly, and (2) the concept of collaboration itself is not
well-understood. I begin by probing the notion of collaboration and propose a
model that helps us understand the requirements for a successful collaboration.
A model of a Collaborative Information Seeking (CIS) environment is then
rendered based on an extended model of information seeking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0711</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0711</id><created>2009-08-05</created><updated>2010-04-15</updated><authors><author><keyname>Yao</keyname><forenames>Hongyi</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author></authors><title>Passive network tomography for erroneous networks: A network coding
  approach</title><categories>cs.NI</categories><comments>40 pages, under submission for IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passive network tomography uses end-to-end observations of network
communication to characterize the network, for instance to estimate the network
topology and to localize random or adversarial glitches. Under the setting of
linear network coding this work provides a comprehensive study of passive
network tomography in the presence of network (random or adversarial) glitches.
To be concrete, this work is developed along two directions: 1. Tomographic
upper and lower bounds (i.e., the most adverse conditions in each problem
setting under which network tomography is possible, and corresponding schemes
(computationally efficient, if possible) that achieve this performance) are
presented for random linear network coding (RLNC). We consider RLNC designed
with common randomness, i.e., the receiver knows the random code-books all
nodes. (To justify this, we show an upper bound for the problem of topology
estimation in networks using RLNC without common randomness.) In this setting
we present the first set of algorithms that characterize the network topology
exactly. Our algorithm for topology estimation with random network errors has
time complexity that is polynomial in network parameters. For the problem of
network error localization given the topology information, we present the first
computationally tractable algorithm to localize random errors, and prove it is
computationally intractable to localize adversarial errors. 2. New network
coding schemes are designed that improve the tomographic performance of RLNC
while maintaining the desirable low-complexity, throughput-optimal, distributed
linear network coding properties of RLNC. In particular, we design network
codes based on Reed-Solomon codes so that a maximal number of adversarial
errors can be localized in a computationally efficient manner even without the
information of network topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0722</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0722</id><created>2009-08-05</created><authors><author><keyname>Al-Kofahi</keyname><forenames>Osameh M.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Max-Flow Protection using Network Coding</title><categories>cs.NI</categories><comments>9 pages, submitted to INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In any communication network, the maximum number of link-disjoint paths
between any pair of communicating nodes, S and T, is limited by the S-T minimum
link-cut. Multipath routing protocols have been proposed in the literature to
make use of these S-T paths in enhancing the survivability of the S-T
information flow. This is usually accomplished by using a subset of these paths
to forward redundant data units or combinations (if network coding is allowed)
from S to T. Therefore, this enhancement in survivability reduces the useful
S-T information rate. In this paper we present a new way to enhance the
survivability of the S-T information flow without compromising the maximum
achievable S-T information rate. To do this, bottleneck links (in the min-cut)
should only forward useful information, and not redundant data units. We
introduce the idea of extra source or destination connectivity with respect to
a certain S-T max-flow, and then we study two problems: namely, pre-cut
protection and post-cut protection. Although our objective in both problems is
the same, where we aim to maximize the number of protected paths, our analysis
shows that the nature of these two problems are very different, and that the
pre-cut protection problem is much harder. Specifically, we prove the hardness
of the pre-cut protection problem, formulate it as an integer linear program,
and propose a heuristic approach to solve it. Simulations show that the
performance of the heuristic is acceptable even on relatively large networks.
In the post-cut problem we show that all the data units, forwarded by the
min-cut edges not incident to T, can be post-cut-protected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0744</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0744</id><created>2009-08-05</created><updated>2009-11-05</updated><authors><author><keyname>Tang</keyname><forenames>Gongguo</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author></authors><title>Performance analysis for sparse support recovery</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of estimating the common support for jointly sparse signals
based on their projections onto lower-dimensional space is analyzed. Support
recovery is formulated as a multiple-hypothesis testing problem. Both upper and
lower bounds on the probability of error are derived for general measurement
matrices, by using the Chernoff bound and Fano's inequality, respectively. The
upper bound shows that the performance is determined by a quantity measuring
the measurement matrix incoherence, while the lower bound reveals the
importance of the total measurement gain. The lower bound is applied to derive
the minimal number of samples needed for accurate direction-of-arrival (DOA)
estimation for a sparse representation based algorithm. When applied to
Gaussian measurement ensembles, these bounds give necessary and sufficient
conditions for a vanishing probability of error for majority realizations of
the measurement matrix. Our results offer surprising insights into sparse
signal recovery. For example, as far as support recovery is concerned, the
well-known bound in Compressive Sensing with the Gaussian measurement matrix is
generally not sufficient unless the noise level is low. Our study provides an
alternative performance measure, one that is natural and important in practice,
for signal recovery in Compressive Sensing and other application areas
exploiting signal sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0753</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0753</id><created>2009-08-05</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>H.</forenames></author><author><keyname>Helmke</keyname><forenames>U.</forenames></author><author><keyname>Curto</keyname><forenames>J. I. Iglesias</forenames></author></authors><title>Algebraic Decoding for Doubly Cyclic Convolutional Codes</title><categories>cs.IT math.IT math.OC</categories><comments>16 pages</comments><msc-class>94B10 (primary), 94B35, 93B15, 93B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An iterative decoding algorithm for convolutional codes is presented. It
successively processes $N$ consecutive blocks of the received word in order to
decode the first block. A bound is presented showing which error configurations
can be corrected. The algorithm can be efficiently used on a particular class
of convolutional codes, known as doubly cyclic convolutional codes. Due to
their highly algebraic structure those codes are well suited for the algorithm
and the main step of the procedure can be carried out using Reed-Solomon
decoding. Examples illustrate the decoding and a comparison with existing
algorithms is being made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0764</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0764</id><created>2009-08-05</created><authors><author><keyname>Reddy</keyname><forenames>Madhu</forenames></author><author><keyname>Jansen</keyname><forenames>Bernard J.</forenames></author></authors><title>Learning about Potential Users of Collaborative Information Retrieval
  Systems</title><categories>cs.IR cs.HC</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/redjan</report-no><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key components of designing usable and useful collaborative
information retrieval systems is to understand the needs of the users of these
systems. Our research team has been exploring collaborative information
behavior in a variety of organizational settings. Our research goals have been
two-fold: First, to develop a conceptual understanding of collaborative
information behavior and second, gather requirements for the design of
collaborative information retrieval systems. In this paper, we present a brief
overview of our fieldwork in a three different organizational settings, discuss
our methodology for collecting data on collaborative information behavior, and
highlight some lessons that we are learning about potential users of
collaborative information retrieval systems in these domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0772</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0772</id><created>2009-08-05</created><authors><author><keyname>Golovin</keyname><forenames>Daniel</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author><author><keyname>Streeter</keyname><forenames>Matthew</forenames></author></authors><title>Online Learning of Assignments that Maximize Submodular Functions</title><categories>cs.LG cs.DS</categories><comments>12 pages</comments><report-no>0908.0772</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Which ads should we display in sponsored search in order to maximize our
revenue? How should we dynamically rank information sources to maximize value
of information? These applications exhibit strong diminishing returns:
Selection of redundant ads and information sources decreases their marginal
utility. We show that these and other problems can be formalized as repeatedly
selecting an assignment of items to positions to maximize a sequence of
monotone submodular functions that arrive one by one. We present an efficient
algorithm for this general problem and analyze it in the no-regret model. Our
algorithm possesses strong theoretical guarantees, such as a performance ratio
that converges to the optimal constant of 1-1/e. We empirically evaluate our
algorithm on two real-world online optimization problems on the web: ad
allocation with submodular utilities, and dynamically ranking blogs to detect
information cascades.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0775</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0775</id><created>2009-08-06</created><updated>2010-07-08</updated><authors><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author><author><keyname>Gong</keyname><forenames>Tao</forenames></author><author><keyname>Puglisi</keyname><forenames>Andrea</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author></authors><title>Modeling the emergence of universality in color naming patterns</title><categories>physics.soc-ph cond-mat.stat-mech cs.GT cs.MA q-bio.PE</categories><comments>Supplementery Information available here
  http://www.pnas.org/content/107/6/2403/suppl/DCSupplemental</comments><journal-ref>Proc. Natl. Acad. Sci. USA 107, 2403 (2010)</journal-ref><doi>10.1073/pnas.0908533107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The empirical evidence that human color categorization exhibits some
universal patterns beyond superficial discrepancies across different cultures
is a major breakthrough in cognitive science. As observed in the World Color
Survey (WCS), indeed, any two groups of individuals develop quite different
categorization patterns, but some universal properties can be identified by a
statistical analysis over a large number of populations. Here, we reproduce the
WCS in a numerical model in which different populations develop independently
their own categorization systems by playing elementary language games. We find
that a simple perceptual constraint shared by all humans, namely the human Just
Noticeable Difference (JND), is sufficient to trigger the emergence of
universal patterns that unconstrained cultural interaction fails to produce. We
test the results of our experiment against real data by performing the same
statistical analysis proposed to quantify the universal tendencies shown in the
WCS [Kay P and Regier T. (2003) Proc. Natl. Acad. Sci. USA 100: 9085-9089], and
obtain an excellent quantitative agreement. This work confirms that synthetic
modeling has nowadays reached the maturity to contribute significantly to the
ongoing debate in cognitive science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0794</identifier>
 <datestamp>2014-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0794</id><created>2009-08-06</created><updated>2014-06-07</updated><authors><author><keyname>Li</keyname><forenames>Li</forenames></author><author><keyname>Chen</keyname><forenames>Yudong</forenames></author></authors><title>Quantization Errors of Modulo Sigma-Delta Modulated ARMA Processes</title><categories>cs.IT cs.NI math.IT</categories><comments>An abbreviated version of this paper had been published as Li Li,
  Yudong Chen, &quot;Quantization errors of modulo sigma-delta modulated ARMA
  processes,&quot; Proceedings of IEEE China Summit &amp; International Conference on
  Signal and Information Processing, pp. 86-90, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the quantization errors of modulo sigma-delta
modulated finite, asymptotically-infinite, infinite causal stable ARMA
processes. We prove that the normalized quantization error can be taken as a
uniformly distributed white noise for all the cases. Moreover, we find that
this nice property is guaranteed by two different mechanisms: the high-enough
quantization resolution \cite{Bennett1948}-\cite{WidrowKollar2008} and the
asymptotic convergence of quantization errors for some quasi-stationary
processes \cite{ChouGray1991}-\cite{LiChenLiZhang2009}, for different cases.
But the assumption of the smooth density of the sampled random processes is
needed in all the cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0812</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0812</id><created>2009-08-06</created><authors><author><keyname>Rossi</keyname><forenames>Dario</forenames></author><author><keyname>Testa</keyname><forenames>Claudio</forenames></author><author><keyname>Valenti</keyname><forenames>Silvio</forenames></author><author><keyname>Veglia</keyname><forenames>Paolo</forenames></author><author><keyname>Muscariello</keyname><forenames>Luca</forenames></author></authors><title>News from the Internet congestion control world</title><categories>cs.NI</categories><comments>9 pages, 4 figures, submitted to IEEE INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A few months ago, the BitTorrent developers announced that the transfer of
torrent data in the official client was about to switch to uTP, an
application-layer congestion-control protocol using UDP at the transport-layer.
This announcement immediately raised an unmotivated buzz about a new, imminent
congestion collapse of the whole Internet. Though this reaction was not built
on solid technical foundation, nevertheless a legitimate question remains:
i.e., whether this novel algorithm is a necessary building block for future
Internet applications, or whether it may result in an umpteenth addition to the
already well populated world of Internet congestion control algorithms.
  In this paper, we tackle precisely this issue. The novel protocol is now
under discussion at the IETF LEDBAT working group, and has been defined in a
draft document in March 2009, whose adoption decision will be taken at the
beginning of August 2009. Adhering to the IETF draft definition, we implement
the LEDBAT congestion control algorithm and investigate its performance by
means of packet-level simulations. Considering a simple bottleneck scenario
where LEDBAT competes against either TCP or other LEDBAT flows, we evaluate the
fairness of the resource share as well as its efficiency. Our preliminary
results show that indeed, there is an undoubted appeal behind the novel
application-layer congestion-control protocol. Yet, care must be taken in order
to ensure that some important points, such as intra-protocol fairness, are
fully clarified in the draft specification -- which we hope that this work can
contribute to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0828</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0828</id><created>2009-08-06</created><authors><author><keyname>Martinez</keyname><forenames>Genaro J.</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>McIntosh</keyname><forenames>Harold V.</forenames></author></authors><title>Localization dynamics in a binary two-dimensional cellular automaton:
  the Diffusion Rule</title><categories>cs.FL</categories><comments>Accepted to Journal of Cellular Automata</comments><doi>10.1007/978-1-84996-217-9_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a two-dimensional cellular automaton (CA), called Diffusion Rule
(DR), which exhibits diffusion-like dynamics of propagating patterns. In
computational experiments we discover a wide range of mobile and stationary
localizations (gliders, oscillators, glider guns, puffer trains, etc), analyze
spatio-temporal dynamics of collisions between localizations, and discuss
possible applications in unconventional computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0833</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0833</id><created>2009-08-06</created><authors><author><keyname>Ivankov</keyname><forenames>Petr R.</forenames></author></authors><title>Top-down Paradigm in Engineering Software Integration</title><categories>cs.CE cs.SE</categories><comments>29 pages, 44 figures, 5 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The top-down approach of engineering software integration is considered in
this parer. A set of advantages of this approach are presented, by examples.
All examples are supplied by open source code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0850</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0850</id><created>2009-08-06</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Steering plasmodium with light: Dynamical programming of Physarum
  machine</title><categories>nlin.PS cs.ET nlin.AO q-bio.QM</categories><comments>Accepted for publication in New Mathematics and Natural Computation
  Journal (April, 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A plasmodium of Physarum polycephalum is a very large cell visible by unaided
eye. The plasmodium is capable for distributed sensing, parallel information
processing, and decentralized optimization. It is an ideal substrate for future
and emerging bio-computing devices. We study space-time dynamics of plasmodium
reactiom to localised illumination, and provide analogies between propagating
plasmodium and travelling wave-fragments in excitable media. We show how
plasmodium-based computing devices can be precisely controlled and shaped by
planar domains of illumination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0853</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0853</id><created>2009-08-06</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Martinez</keyname><forenames>Genaro</forenames></author><author><keyname>Zhang</keyname><forenames>Liang</forenames></author><author><keyname>Wuensche</keyname><forenames>Andrew</forenames></author></authors><title>Operating binary strings using gliders and eaters in reaction-diffusion
  cellular automaton</title><categories>cs.FL</categories><journal-ref>Mathematical and Computer Modelling, Volume 52, Issues 1-2, July
  2010, Pages 177-190</journal-ref><doi>10.1016/j.mcm.2010.02.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study transformations of 2-, 4- and 6-bit numbers in interactions between
traveling and stationary localizations in the Spiral Rule reaction-diffusion
cellular automaton. The Spiral Rule automaton is a hexagonal ternary-state
two-dimensional cellular automaton -- a finite-state machine imitation of an
activator-inhibitor reaction-diffusion system. The activator is self-inhibited
in certain concentrations. The inhibitor dissociates in the absence of the
activator. The Spiral Rule cellular automaton has rich spatio-temporal dynamics
of traveling (glider) and stationary (eater) patterns. When a glider brushes an
eater the eater may slightly change its configuration, which is updated once
more every next hit. We encode binary strings in the states of eaters and
sequences of gliders. We study what types of binary compositions of binary
strings are implementable by sequences of gliders brushing an eater. The models
developed will be used in future laboratory designs of reaction-diffusion
chemical computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0856</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0856</id><created>2009-08-06</created><authors><author><keyname>Renk</keyname><forenames>Tobias</forenames></author><author><keyname>Jaekel</keyname><forenames>Holger</forenames></author><author><keyname>Jondral</keyname><forenames>Friedrich K.</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Outage Capacity of Incremental Relaying at Low Signal-to-Noise Ratios</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, to be presented at VTC Fall 2009 in Anchorage,
  Alaska</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the \epsilon-outage capacity of incremental relaying at low
signal-to-noise ratios (SNR) in a wireless cooperative network with slow
Rayleigh fading channels. The relay performs decode-and-forward and repetition
coding is employed in the network, which is optimal in the low SNR regime. We
derive an expression on the optimal relay location that maximizes the
\epsilon-outage capacity. It is shown that this location is independent of the
outage probability and SNR but only depends on the channel conditions
represented by a path-loss factor. We compare our results to the
\epsilon-outage capacity of the cut-set bound and demonstrate that the ratio
between the \epsilon-outage capacity of incremental relaying and the cut-set
bound lies within 1/\sqrt{2} and 1. Furthermore, we derive lower bounds on the
\epsilon-outage capacity for the case of K relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0893</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0893</id><created>2009-08-06</created><authors><author><keyname>Seifeldin</keyname><forenames>Moustafa</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Nuzzer: A Large-Scale Device-Free Passive Localization System for
  Wireless Environments</title><categories>cs.NI cs.PF</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread usage of wireless local area networks and mobile devices has
fostered the interest in localization systems for wireless environments. The
majority of research in the context of wireless-based localization systems has
focused on device-based active localization, in which a device is attached to
tracked entities. Recently, device-free passive localization (DfP) has been
proposed where the tracked entity is neither required to carry devices nor
participate actively in the localization process. DfP systems are based on the
fact that RF signals are affected by the presence of people and objects in the
environment. The DfP concept enables a wide range of applications including
intrusion detection and tracking, border protection, and smart buildings
automation. Previous studies have focused on small areas with direct line of
sight and/or controlled environments. In this paper, we present the design,
implementation and analysis of Nuzzer, a large-scale device-free passive
localization system for real environments.
  Without any additional hardware, it makes use of the already installed
wireless data networks to monitor and process changes in the received signal
strength (RSS) transmitted from access points at one or more monitoring points.
We present probabilistic techniques for DfP localization and evaluate their
performance in a typical office building, rich in multipath, with an area of
1500 square meters. Our results show that the Nuzzer system gives device-free
location estimates with less than 2 meters median distance error using only two
monitoring laptops and three access points. This indicates the suitability of
Nuzzer to a large number of application domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0898</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0898</id><created>2009-08-06</created><updated>2010-04-09</updated><authors><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On Secrecy Capacity Scaling in Wireless Networks</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the achievable secure rate per source-destination pair in
wireless networks. First, a path loss model is considered, where the legitimate
and eavesdropper nodes are assumed to be placed according to Poisson point
processes with intensities $\lambda$ and $\lambda_e$, respectively. It is shown
that, as long as $\lambda_e/\lambda=o((\log n)^{-2})$, almost all of the nodes
achieve a perfectly secure rate of $\Omega(\frac{1}{\sqrt{n}})$ for the
extended and dense network models. Therefore, under these assumptions, securing
the network does not entail a loss in the per-node throughput. The
achievability argument is based on a novel multi-hop forwarding scheme where
randomization is added in every hop to ensure maximal ambiguity at the
eavesdropper(s). Secondly, an ergodic fading model with $n$ source-destination
pairs and $n_e$ eavesdroppers is considered. Employing the ergodic interference
alignment scheme with an appropriate secrecy pre-coding, each user is shown to
achieve a constant positive secret rate for sufficiently large $n$. Remarkably,
the scheme does not require eavesdropper CSI (only the statistical knowledge is
assumed) and the secure throughput per node increases as we add more legitimate
users to the network in this setting. Finally, the effect of eavesdropper
collusion on the performance of the proposed schemes is characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0912</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0912</id><created>2009-08-06</created><authors><author><keyname>Foley</keyname><forenames>Colum</forenames></author><author><keyname>Smeaton</keyname><forenames>Alan F.</forenames></author></authors><title>Evaluation of Coordination Techniques in Synchronous Collaborative
  Information Retrieval</title><categories>cs.IR</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/folsme</report-no><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional Information Retrieval (IR) research has focussed on a single user
interaction modality, where a user searches to satisfy an information need.
Recent advances in web technologies and computer hardware have enabled multiple
users to collaborate on many computer-supported tasks, therefore there is an
increasing opportunity to support two or more users searching together at the
same time in order to satisfy a shared information need, which we refer to as
Synchronous Collaborative Information Retrieval (SCIR). SCIR systems represent
a significant paradigmatic shift from traditional IR systems. In order to
support effective SCIR, new techniques are required to coordinate users'
activities. In addition, the novel domain of SCIR presents challenges for
effective evaluations of these systems. In this paper we will propose an
effective and re-usable evaluation methodology based on simulating users
searching together. We will outline how we have used this evaluation in
empirical studies of the effects of different division of labour and sharing of
knowledge techniques for SCIR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0919</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0919</id><created>2009-08-06</created><authors><author><keyname>Hopfgartner</keyname><forenames>Frank</forenames></author><author><keyname>Vallet</keyname><forenames>David</forenames></author><author><keyname>Halvey</keyname><forenames>Martin</forenames></author><author><keyname>Jose</keyname><forenames>Joemon</forenames></author></authors><title>Collaborative Search Trails for Video Search</title><categories>cs.IR</categories><comments>Presented at 1st Intl Workshop on Collaborative Information Seeking,
  2008 (arXiv:0908.0583)</comments><report-no>JCDL2008CIRWS/2008/hopvalhaljos</report-no><acm-class>H.3.3; H.5.2; H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an approach for supporting users in the difficult
task of searching for video. We use collaborative feedback mined from the
interactions of earlier users of a video search system to help users in their
current search tasks. Our objective is to improve the quality of the results
that users find, and in doing so also assist users to explore a large and
complex information space. It is hoped that this will lead to them considering
search options that they may not have considered otherwise. We performed a user
centred evaluation. The results of our evaluation indicate that we achieved our
goals, the performance of the users in finding relevant video clips was
enhanced with our system; users were able to explore the collection of video
clips more and users demonstrated a preference for our system that provided
recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0928</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0928</id><created>2009-08-06</created><authors><author><keyname>Dunn</keyname><forenames>Angus</forenames></author></authors><title>Automated Spreadsheet Development</title><categories>cs.HC cs.SE</categories><comments>8 Pages, 3 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 39-46
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Few major commercial or economic decisions are made today which are not
underpinned by analysis using spreadsheets. It is virtually impossible to avoid
making mistakes during their drafting and some of these errors remain, unseen
and uncorrected, until something turns the spotlight on them. By then it may be
too late. The challenge is to find a way of creating spreadsheets which will
preserve the benefit of their power and flexibility while making their creation
more transparent and safer. Full documentation and documented version and
quality control, section by section, of the eventual spreadsheet would be a
bonus. And if the whole process could be made quicker, too, that would be a
further bonus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0930</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0930</id><created>2009-08-06</created><authors><author><keyname>Bekenn</keyname><forenames>Bill</forenames></author><author><keyname>Hooper</keyname><forenames>Ray</forenames></author></authors><title>Some Spreadsheet Poka-Yoke</title><categories>cs.HC cs.SE</categories><comments>12 Pages, 8 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 83-94
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whilst not all spreadsheet defects are structural in nature, poor layout
choices can compromise spreadsheet quality. These defects may be avoided at the
development stage by some simple mistake prevention and detection devices.
Poka-Yoke (Japanese for Mistake Proofing), which owes its genesis to the Toyota
Production System (the standard for manufacturing excellence throughout the
world) offers some principles that may be applied to reducing spreadsheet
defects. In this paper we examine spreadsheet structure and how it can lead to
defects and illustrate some basic spreadsheet Poka-Yokes to reduce them. These
include guidelines on how to arrange areas of cells so that whole rows and
columns can be inserted anywhere without causing errors, and rules for when to
use relative and absolute references with respect to what type of area is being
referred to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0932</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0932</id><created>2009-08-06</created><authors><author><keyname>Iyengar</keyname><forenames>M. Sriram</forenames></author><author><keyname>Svirbely</keyname><forenames>John R.</forenames></author></authors><title>The Medical Algorithms Project</title><categories>cs.HC cs.IR</categories><comments>6 Pages, 2 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 113-118
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Medical Algorithms Project, a web-based resource located at
www.medal.org, is the world's largest collection of medical-related
spreadsheets, consisting of over 13,500 Excel spreadsheets each encoding a
medical algorithm from 45 different areas of medical practice. This free
resource is in use worldwide with over 106,000 registered users as of March 1,
2009.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0935</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0935</id><created>2009-08-06</created><authors><author><keyname>McKeever</keyname><forenames>Ruth</forenames></author><author><keyname>McDaid</keyname><forenames>Kevin</forenames></author><author><keyname>Bishop</keyname><forenames>Brian</forenames></author></authors><title>An Exploratory Analysis of the Impact of Named Ranges on the Debugging
  Performance of Novice Users</title><categories>cs.HC cs.SE</categories><comments>13 Pages, 4 Figures. Winner of the 2009 David Chadwick Prize for Best
  Student Paper</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 69-81
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an exploratory empirical study of the effect of named
ranges on spreadsheet debugging performance. Named ranges are advocated in both
academia and industry, yet no experimental evidence has been cited to back up
these recommendations. This paper describes an exploratory experiment involving
21 participants that assesses the performance of novices debugging a
spreadsheet containing named ranges. The results are compared with the
performance of a different set of novices debugging the same spreadsheet
without named ranges. The findings suggest that novice users debug on average
significantly fewer errors if the spreadsheet contains named ranges. The
purpose of the investigative study is to derive a detailed and coherent set of
research questions regarding the impact of range names on the debugging
performance and behaviour of spreadsheet users. These will be answered through
future controlled experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0939</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0939</id><created>2009-08-06</created><authors><author><keyname>White</keyname><forenames>Eddie</forenames></author></authors><title>Clustering for Improved Learning in Maze Traversal Problem</title><categories>cs.LG</categories><comments>29 pages, 15 figures, Undergraduate Honors Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maze traversal problem (finding the shortest distance to the goal from
any position in a maze) has been an interesting challenge in computational
intelligence. Recent work has shown that the cellular simultaneous recurrent
neural network (CSRN) can solve this problem for simple mazes. This thesis
focuses on exploiting relevant information about the maze to improve learning
and decrease the training time for the CSRN to solve mazes. Appropriate
variables are identified to create useful clusters using relevant information.
The CSRN was next modified to allow for an additional external input. With this
additional input, several methods were tested and results show that clustering
the mazes improves the overall learning of the traversal problem for the CSRN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0968</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0968</id><created>2009-08-07</created><updated>2010-03-28</updated><authors><author><keyname>Emek</keyname><forenames>Yuval</forenames></author><author><keyname>Korman</keyname><forenames>Amos</forenames></author><author><keyname>Shavitt</keyname><forenames>Yuval</forenames></author></authors><title>Approximating the Statistics of various Properties in Randomly Weighted
  Graphs</title><categories>cs.DS cs.DM</categories><comments>22 pages (excluding the title page)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the setting of \emph{randomly weighted graphs}, namely, graphs whose
edge weights are chosen independently according to probability distributions
with finite support over the non-negative reals. Under this setting, properties
of weighted graphs typically become random variables and we are interested in
computing their statistical features. Unfortunately, this turns out to be
computationally hard for some properties albeit the problem of computing them
in the traditional setting of algorithmic graph theory is tractable. For
example, there are well known efficient algorithms that compute the
\emph{diameter} of a given weighted graph, yet, computing the \emph{expected}
diameter of a given randomly weighted graph is \SharpP{}-hard even if the edge
weights are identically distributed. In this paper, we define a family of
properties of weighted graphs and show that for each property in this family,
the problem of computing the \emph{$k^{\text{th}}$ moment} (and in particular,
the expected value) of the corresponding random variable in a given randomly
weighted graph $G$ admits a \emph{fully polynomial time randomized
approximation scheme (FPRAS)} for every fixed $k$. This family includes
fundamental properties of weighted graphs such as the diameter of $G$, the
\emph{radius} of $G$ (with respect to any designated vertex) and the weight of
a \emph{minimum spanning tree} of $G$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0979</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0979</id><created>2009-08-07</created><authors><author><keyname>Damodaram</keyname><forenames>A.</forenames></author><author><keyname>Jayasri</keyname><forenames>H.</forenames></author></authors><title>Authentication Without Identification using Anonymous Credential System</title><categories>cs.CR</categories><comments>4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy and security are often intertwined. For example, identity theft is
rampant because we have become accustomed to authentication by identification.
To obtain some service, we provide enough information about our identity for an
unscrupulous person to steal it (for example, we give our credit card number to
Amazon.com). One of the consequences is that many people avoid e-commerce
entirely due to privacy and security concerns. The solution is to perform
authentication without identification. In fact, all on-line actions should be
as anonymous as possible, for this is the only way to guarantee security for
the overall system. A credential system is a system in which users can obtain
credentials from organizations and demonstrate possession of these credentials.
Such a system is anonymous when transactions carried out by the same user
cannot be linked. An anonymous credential system is of significant practical
relevance because it is the best means of providing privacy for users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0980</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0980</id><created>2009-08-09</created><authors><author><keyname>Rizvi</keyname><forenames>Syed S.</forenames></author><author><keyname>Elleithy</keyname><forenames>Khaled M.</forenames></author><author><keyname>Riasat</keyname><forenames>Aasia</forenames></author></authors><title>Deterministic Formulization of SNR for Wireless Multiuser DS-CDMA
  Networks</title><categories>cs.NI</categories><comments>9 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Multiuser receivers suffer from their relatively higher
computational complexity that prevents widespread use of this technique. In
addition, one of the main characteristics of multi-channel communications that
can severely degrade the performance is the inconsistent and low values of SNR
that result in high BER and poor channel capacity. It has been shown that the
computational complexity of a multiuser receiver can be reduced by using the
transformation matrix (TM) algorithm [4]. In this paper, we provide
quantification of SNR based on the computational complexity of TM algorithm. We
show that the reduction of complexity results high and consistent values of SNR
that can consequently be used to achieve a desirable BER performance. In
addition, our simulation results suggest that the high and consistent values of
SNR can be achieved for a desirable BER performance. The performance measure
adopted in this paper is the consistent values of SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0981</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0981</id><created>2009-08-07</created><updated>2009-08-09</updated><authors><author><keyname>Rizvi</keyname><forenames>Syed S.</forenames></author><author><keyname>Elleithy</keyname><forenames>Khaled M.</forenames></author></authors><title>A New Scheme for Minimizing Malicious Behavior of Mobile Nodes in Mobile
  Ad Hoc Networks</title><categories>cs.CR cs.NI</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of Mobile Ad hoc networks (MANET) depends on the cooperation
of all active nodes. However, supporting a MANET is a cost-intensive activity
for a mobile node. From a single mobile node perspective, the detection of
routes as well as forwarding packets consume local CPU time, memory,
network-bandwidth, and last but not least energy. We believe that this is one
of the main factors that strongly motivate a mobile node to deny packet
forwarding for others, while at the same time use their services to deliver its
own data. This behavior of an independent mobile node is commonly known as
misbehaving or selfishness. A vast amount of research has already been done for
minimizing malicious behavior of mobile nodes. However, most of them focused on
the methods/techniques/algorithms to remove such nodes from the MANET. We
believe that the frequent elimination of such miss-behaving nodes never allowed
a free and faster growth of MANET. This paper provides a critical analysis of
the recent research wok and its impact on the overall performance of a MANET.
In this paper, we clarify some of the misconceptions in the understating of
selfishness and miss-behavior of nodes. Moreover, we propose a mathematical
model that based on the time division technique to minimize the malicious
behavior of mobile nodes by avoiding unnecessary elimination of bad nodes. Our
proposed approach not only improves the resource sharing but also creates a
consistent trust and cooperation (CTC) environment among the mobile nodes. The
simulation results demonstrate the success of the proposed approach that
significantly minimizes the malicious nodes and consequently maximizes the
overall throughput of MANET than other well known schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0982</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0982</id><created>2009-08-07</created><authors><author><keyname>Hosseini-Pozveh</keyname><forenames>Maryam</forenames></author><author><keyname>Nematbakhsh</keyname><forenames>Mohamadali</forenames></author><author><keyname>Movahhedinia</keyname><forenames>Naser</forenames></author></authors><title>A multidimensional approach for context-aware recommendation in mobile
  commerce</title><categories>cs.CY cs.MA</categories><comments>6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context as the dynamic information describing the situation of items and
users and affecting the users decision process is essential to be used by
recommender systems in mobile commerce to guarantee the quality of
recommendation. This paper proposes a novel multidimensional approach for
context aware recommendation in mobile commerce. The approach represents users,
items, context information and the relationship between them in a
multidimensional space. It then determines the usage patterns of each user
under different contextual situations and creates a new 2 dimensional
recommendation space and does the final recommendation in that space. This
paper also represents an evaluation process by implementing the proposed
approach in a restaurant food recommendation system considering day, time,
weather and companion as the contextual information and comparing the approach
with the traditional 2 dimensional one. The results of comparison illustrates
that the multidimensional approach increases the recommendation quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0984</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0984</id><created>2009-08-07</created><authors><author><keyname>Balasubramanian</keyname><forenames>C.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>An Application of Bayesian classification to Interval Encoded Temporal
  mining with prioritized items</title><categories>cs.DB cs.LG</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In real life, media information has time attributes either implicitly or
explicitly known as temporal data. This paper investigates the usefulness of
applying Bayesian classification to an interval encoded temporal database with
prioritized items. The proposed method performs temporal mining by encoding the
database with weighted items which prioritizes the items according to their
importance from the user perspective. Naive Bayesian classification helps in
making the resulting temporal rules more effective. The proposed priority based
temporal mining (PBTM) method added with classification aids in solving
problems in a well informed and systematic manner. The experimental results are
obtained from the complaints database of the telecommunications system, which
shows the feasibility of this method of classification based temporal mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0986</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0986</id><created>2009-08-07</created><authors><author><keyname>El-Sayed</keyname><forenames>Abdulqader M.</forenames></author></authors><title>Ethernet Networks: Current Trends and Tools</title><categories>cs.NI</categories><comments>Proceedings of IEEE International Conference on Advanced Information
  Networking and Applications, 8 pages</comments><report-no>TR-G14-2009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ethernet topology discovery has gained increasing interest in the recent
years. This trend is motivated mostly by increasing number of carrier Ethernet
networks as well as the size of these networks, and consequently the increasing
sales of these networks. To manage these networks efficiently, detailed and
accurate knowledge of their topology is needed. Knowledge of a network's
entities and the physical connections between them can be useful in various
prospective. Administrators can use topology information for network planning
and fault detecting. Topology information can also be used during protocol and
routing algorithm development, for performance prediction and as a basis for
accurate network simulations. From a network security perspective, threat
detection, network monitoring, network access control and forensic
investigations can benefit from accurate network topology information. In this
paper, we analyze market trends and investigate current tools available for
both research and commercial purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0993</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0993</id><created>2009-08-07</created><authors><author><keyname>Renk</keyname><forenames>Tobias</forenames></author><author><keyname>Jaekel</keyname><forenames>Holger</forenames></author><author><keyname>Jondral</keyname><forenames>Friedrich K.</forenames></author></authors><title>Outage Regions and Optimal Power Allocation for Wireless Relay Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, 1 table, accepted for ITW 2009, Taormina, Sicily</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study outage regions for energy-constrained multi-hop and adaptive
multi-route networks with an arbitrary number of relay nodes. Optimal power
allocation strategies in the sense that outage probability is minimized are
derived depending on the distances between the transmit nodes. We further
investigate the rate gain of adaptive multi-route and multi-hop over direct
transmission. It is shown that a combined strategy of direct transmission and
adaptive multi-route outperforms multi-hop for all values of rate R. It can be
stated that cooperation strategies are beneficial for low-rate systems where
the main goal is a very low outage probability of the network. As the rate is
increased, direct transmission becomes more and more attractive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.0994</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.0994</id><created>2009-08-07</created><authors><author><keyname>Mishra</keyname><forenames>Dr. Durgesh Kumar</forenames></author><author><keyname>Koria</keyname><forenames>Neha</forenames></author><author><keyname>Kapoor</keyname><forenames>Nikhil</forenames></author><author><keyname>Bahety</keyname><forenames>Ravish</forenames></author></authors><title>A Secure Multi-Party Computation Protocol for Malicious Computation
  Prevention for preserving privacy during Data Mining</title><categories>cs.CR cs.DB</categories><comments>6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Volume 3, Number 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure Multi-Party Computation (SMC) allows parties with similar background
to compute results upon their private data, minimizing the threat of
disclosure. The exponential increase in sensitive data that needs to be passed
upon networked computers and the stupendous growth of internet has precipitated
vast opportunities for cooperative computation, where parties come together to
facilitate computations and draw out conclusions that are mutually beneficial;
at the same time aspiring to keep their private data secure. These computations
are generally required to be done between competitors, who are obviously weary
of each-others intentions. SMC caters not only to the needs of such parties but
also provides plausible solutions to individual organizations for problems like
privacy-preserving database query, privacy-preserving scientific computations,
privacy-preserving intrusion detection and privacy-preserving data mining. This
paper is an extension to a previously proposed protocol Encrytpo_Random, which
presented a plain sailing yet effective approach to SMC and also put forward an
aptly crafted architecture, whereby such an efficient protocol, involving the
parties that have come forward for joint-computations and the third party who
undertakes such computations, can be developed. Through this extended work an
attempt has been made to further strengthen the existing protocol thus paving
the way for a more secure multi-party computational process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1004</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1004</id><created>2009-08-07</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author></authors><title>A New Scaling Law on Throughput and Delay Performance of Wireless Mobile
  Relay Networks over Parallel Fading Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, utilizing the relay buffers, we propose an opportunistic
decode-wait-and-forward relay scheme for a point-to-point communication system
with a half-duplexing relay network to better exploit the time diversity and
relay mobility. For instance, we analyze the asymptotic throughput-delay
tradeoffs in a dense relay network for two scenarios: (1) fixed relays with
\textit{microscopic fading} channels (multipath channels), and (2) mobile
relays with \textit{macroscopic fading} channels (path loss). In the first
scenario, the proposed scheme can better exploit the \textit{multi-relay
diversity} in the sense that with $K$ fixed relays and a cost of
$\mathcal{O}(K)$ average end-to-end packet delay, it could achieve the same
optimal asymptotic average throughput as the existing designs (such as regular
decode-and-forward relay schemes) with $K^2$ fixed relays. In the second
scenario, the proposed scheme achieves the maximum throughput of $\Theta(\log
K)$ at a cost of $\mathcal{O}(K/q)$ average end-to-end packet delay, where
$0&lt;q\leq {1/2}$ measures the speed of relays' mobility. This system throughput
is unattainable for the existing designs with low relay mobility, the proposed
relay scheme can exploit the relays' mobility more efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1027</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1027</id><created>2009-08-07</created><authors><author><keyname>Ohno</keyname><forenames>Yasuo</forenames></author><author><keyname>Sasaki</keyname><forenames>Yoshitaka</forenames></author><author><keyname>Yamazaki</keyname><forenames>Chika</forenames></author></authors><title>On exponential polynomials and quantum computing</title><categories>quant-ph cs.CC</categories><comments>7pages, LaTeX</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We calculate the zeros of an exponential polynomial of three variables by a
classical algorithm and quantum algorithms which are based on the method of van
Dam and Shparlinski, they treated the case of two variables, and compare with
the time complexity of those cases. Further we compare the case of van Dam and
Shparlinski with our case by considering the ratio (classical/quantum) of the
time complexity. Then we can observe the ratio decreases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1033</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1033</id><created>2009-08-07</created><authors><author><keyname>N</keyname><forenames>Kamalesh V.</forenames></author><author><keyname>Srivatsa</keyname><forenames>S. K.</forenames></author></authors><title>Topological design of minimum cost survivable computer communication
  networks, Bipartite Graph Method</title><categories>cs.NI</categories><comments>5 Pages, International Journal of Computer Science and Information
  Security, IJCSIS July 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A good computer network is hard to disrupt. It is desired that the computer
communication network remains connected even when some of the links or nodes
fail. Since the communication links are expensive, one wants to achieve these
goals with fewer links. The computer communication network is fault tolerant if
it has alternative paths between vertices, the more disjoint paths, the better
is the survivability. This paper presents a method for generating k-connected
computer communication network with optimal number of links using bipartite
graph concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1056</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1056</id><created>2009-08-07</created><authors><author><keyname>Mohamed</keyname><forenames>Abd El Naser A.</forenames></author><author><keyname>El-Halawany</keyname><forenames>Mohamed M. E.</forenames></author><author><keyname>Rashed</keyname><forenames>Ahmed Nabih Zaki</forenames></author><author><keyname>Eid</keyname><forenames>Mahmoud M. A.</forenames></author></authors><title>Recent Applications of Optical Parametric Amplifiers in Hybrid WDM TDM
  Local Area Optical Networks</title><categories>cs.NI</categories><comments>10 pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Internation Journal of Computer Science and Information Security,
  IJCSIS, Vol. 3, No.1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, the recent applications of optical parametric
amplifiers (OPAs) in hybrid wavelength division multiplexing (WDM)/time
division multiplexing (TDM) local area passive optical networks have been
modeled and parametrically investigated over wide range of the affecting
parameters. Moreover, we have analyzed the ability of the hybrid WDM/TDM
Passive optical networks to handle a triple play solution, offering voice,
video, and data services to the multiple users. Finally, we have investigated
the maximum time division multiplexing (MTDM) bit rates for optical network
units (ONUs) for maximum number of supported users with optical parametric
amplifier technique across the single mode fiber (SMF) or highly nonlinear
fiber (HNLF) cables to achieve both maximum network reach and quality of
service (QOS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1057</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1057</id><created>2009-08-07</created><authors><author><keyname>Mohamed</keyname><forenames>Abd El Naser A.</forenames></author><author><keyname>Halawany</keyname><forenames>Mohamed M. E. El</forenames></author><author><keyname>Rashed</keyname><forenames>Ahmed Nabih Zaki</forenames></author><author><keyname>Nabawy</keyname><forenames>Amina E. M. El</forenames></author></authors><title>Transmission Performance Analysis of Digital Wire and Wireless Optical
  Links in Local and Wide Areas Optical Networks</title><categories>cs.PF</categories><comments>10 pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>Internation Journal of Computer Science and Information Security,
  IJCSIS, Vol. 3, No.1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, the transmission performance analysis of digital wire
and wireless optical links in local and wide areas optical networks have been
modeled and parametrically investigated over wide range of the affecting
parameters. Moreover, we have analyzed the basic equations of the comparative
study of the performance of digital fiber optic links with wire and wireless
optical links. The development of optical wireless communication systems is
accelerating as a high cost effective to wire fiber optic links. The optical
wireless technology is used mostly in wide bandwidth data transmission
applications. Finally, we have investigated the maximum transmission distance
and data transmission bit rates that can be achieved within digital wire and
wireless optical links for local and wide areas optical network applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1059</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1059</id><created>2009-08-07</created><authors><author><keyname>Enguehard</keyname><forenames>Chantal</forenames><affiliation>LINA</affiliation></author><author><keyname>Lehn</keyname><forenames>R&#xe9;mi</forenames><affiliation>LINA</affiliation></author></authors><title>Vulnerability analysis of three remote voting methods</title><categories>cs.CY</categories><comments>15 pages</comments><proxy>ccsd hal-00409410</proxy><journal-ref>XXI IPSA World Congress of Political Science, RC10 Electronic
  Democracy - Dilemmas of Change?, Santiago : Chile (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article analyses three methods of remote voting in an uncontrolled
environment: postal voting, internet voting and hybrid voting. It breaks down
the voting process into different stages and compares their vulnerabilities
considering criteria that must be respected in any democratic vote:
confidentiality, anonymity, transparency, vote unicity and authenticity.
Whether for safety or reliability, each vulnerability is quantified by three
parameters: size, visibility and difficulty to achieve. The study concludes
that the automatisation of treatments combined with the dematerialisation of
the objects used during an election tends to substitute visible vulnerabilities
of a lesser magnitude by invisible and widespread vulnerabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1071</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1071</id><created>2009-08-07</created><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Jajamovich</keyname><forenames>Guido H.</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author><author><keyname>Moustakides</keyname><forenames>George V.</forenames></author></authors><title>Optimal Joint Target Detection and Parameter Estimation By MIMO Radar</title><categories>cs.IT math.IT</categories><comments>37 pages, 8 figures</comments><doi>10.1109/JSTSP.2010.2040104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multiple-input multiple-output (MIMO) radar systems with
widely-spaced antennas. Such antenna configuration facilitates capturing the
inherent diversity gain due to independent signal dispersion by the target
scatterers. We consider a new MIMO radar framework for detecting a target that
lies in an unknown location. This is in contrast with conventional MIMO radars
which break the space into small cells and aim at detecting the presence of a
target in a specified cell. We treat this problem through offering a novel
composite hypothesis testing framework for target detection when (i) one or
more parameters of the target are unknown and we are interested in estimating
them, and (ii) only a finite number of observations are available. The test
offered optimizes a metric which accounts for both detection and estimation
accuracies. In this paper as the parameter of interest we focus on the vector
of time-delays that the waveforms undergo from being emitted by the transmit
antennas until being observed by the receive antennas. The analytical and
empirical results establish that for the proposed joint target detection and
time-delay estimation framework, MIMO radars exhibit significant gains over
phased-array radars for extended targets which consist of multiple independent
scatterers. For point targets modeled as single scatterers, however, the
detection/estimation accuracies of MIMO and phased-array radars for this
specific setup (joint target detection and time-delay estimation) are
comparable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1076</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1076</id><created>2009-08-07</created><authors><author><keyname>Negenborn</keyname><forenames>R. R.</forenames></author><author><keyname>De Schutter</keyname><forenames>B.</forenames></author><author><keyname>Hellendoorn</keyname><forenames>J.</forenames></author></authors><title>Multi-Agent Model Predictive Control: A Survey</title><categories>cs.MA</categories><report-no>04-010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we define characteristic control design elements and show how
conventional single-agent MPC implements these. We survey recent literature on
multi-agent MPC and discuss how this literature deals with decomposition,
problem assignment, and cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1077</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1077</id><created>2009-08-07</created><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Prasad</keyname><forenames>Narayan</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Beamforming and Rate Allocation in MISO Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>32 pages, 6 figures</comments><doi>10.1109/TSP.2009.2031280</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider decentralized multi-antenna cognitive radio networks where
secondary (cognitive) users are granted simultaneous spectrum access along with
license-holding (primary) users. We treat the problem of distributed
beamforming and rate allocation for the secondary users such that the minimum
weighted secondary rate is maximized. Such an optimization is subject to (1) a
limited weighted sum-power budget for the secondary users and (2) guaranteed
protection for the primary users in the sense that the interference level
imposed on each primary receiver does not exceed a specified level. Based on
the decoding method deployed by the secondary receivers, we consider three
scenarios for solving this problem. In the first scenario each secondary
receiver decodes only its designated transmitter while suppressing the rest as
Gaussian interferers (single-user decoding). In the second case each secondary
receiver employs the maximum likelihood decoder (MLD) to jointly decode all
secondary transmissions, and in the third one each secondary receiver uses the
unconstrained group decoder (UGD). By deploying the UGD, each secondary user is
allowed to decode any arbitrary subset of users (which contains its designated
user) after suppressing or canceling the remaining users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1090</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1090</id><created>2009-08-07</created><authors><author><keyname>Sinha</keyname><forenames>Anshuman</forenames></author></authors><title>Study of Proposed Methods for Improving TCP Performance Over Wireless
  Links</title><categories>cs.NI</categories><comments>7 pages, 4 figures, 3 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  TCP is designed for networks with assumption that major losses occur only due
to congestion of network traffic. On a wireless network TCP misinterprets the
transmission losses due to bit errors and handoffs as losses caused by
congestion, and triggers congestion control mechanisms. Because of its end to
end delivery model, congestion handling and avoidance mechanisms, TCP has been
widely accepted as Transport layer protocol for internetworks. Extension of
Internetworks over wireless links is inevitable with the spread of ubiquitous
computing and mobile communications. This paper presents study of different
mechanisms proposed to extend Transport Control Protocol and other alternate
solutions to enhance end to end performance over lossy wireless links. The
paper studies details of different design choices proposed and their technical
advantages and disadvantages. Finally, an analysis and proposal for best choice
of proposed schemes are made for wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1116</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1116</id><created>2009-08-07</created><authors><author><keyname>Mumtaz</keyname><forenames>Shahid</forenames></author><author><keyname>Gamerio</keyname><forenames>Alitio</forenames></author><author><keyname>Sadeghi</keyname><forenames>Rasool</forenames></author></authors><title>Enhanced Algorithm for Link to System level Interface Mapping</title><categories>cs.IT cs.PF math.IT</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current SINR mechanism does not provide the base station (BS) with any
knowledge on the frequency selectivity of channel from mobile service
station(MSS). This knowledge is important since, contrary to the AWGN channel,
in a frequency selective channel there is no longer a 1 to 1 relation between
amount of increase in power and amount of improvement in effective SINR 1.
Furthermore, the relation is dependent on MCS level. This lack of knowledge in
the BS side results in larger fade margins, which translates directly to
reduction in capacity. In this paper we propose a enhanced algorithm on the
EESM model with weighted beta (\beta) that provides the BS with sufficient
knowledge on the channel-dependent relationship between power increase, MCS
change and improvement in effective SINR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1143</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1143</id><created>2009-08-07</created><updated>2015-03-01</updated><authors><author><keyname>Jamakovic</keyname><forenames>Almerima</forenames></author><author><keyname>Mahadevan</keyname><forenames>Priya</forenames></author><author><keyname>Vahdat</keyname><forenames>Amin</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author></authors><title>How small are building blocks of complex networks</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network motifs are small building blocks of complex networks. Statistically
significant motifs often perform network-specific functions. However, the
precise nature of the connection between motifs and the global structure and
function of networks remains elusive. Here we show that the global structure of
some real networks is statistically determined by the probability of
connections within motifs of size at most 3, once this probability accounts for
node degrees. The connectivity profiles of node triples in these networks
capture all their local and global properties. This finding impacts methods
relying on motif statistical significance, and enriches our understanding of
the elementary forces that shape the structure of complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1159</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1159</id><created>2009-08-10</created><updated>2009-09-07</updated><authors><author><keyname>B&#xe1;tfai</keyname><forenames>Norbert</forenames></author></authors><title>On the Running Time of the Shortest Programs</title><categories>cs.CC</categories><comments>24 pages, 15 figures; added new values to the table &quot;The increasing
  of running time of the shortest programs&quot;</comments><acm-class>D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kolmogorov complexity of the word w is equal to the length of the
shortest concatenation of program Z and its input x with which the word w is
computed by the universal turing machine U. The question introduced in this
paper is the following: How long do the shortest programs run for?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1162</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1162</id><created>2009-08-08</created><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>STBCs with Reduced Sphere Decoding Complexity for Two-User MIMO-MAC</title><categories>cs.IT math.IT</categories><comments>6 pages, to appear in the proceedings of IEEE GLOBECOM 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Space-Time Block Codes (STBCs) with reduced Sphere Decoding
Complexity (SDC) are constructed for two-user Multiple-Input Multiple-Output
(MIMO) fading multiple access channels. In this set-up, both the users employ
identical STBCs and the destination performs sphere decoding for the symbols of
the two users. First, we identify the positions of the zeros in the
$\textbf{R}$ matrix arising out of the Q-R decomposition of the lattice
generator such that (i) the worst case SDC (WSDC) and (ii) the average SDC
(ASDC) are reduced. Then, a set of necessary and sufficient conditions on the
lattice generator is provided such that the $\textbf{R}$ matrix has zeros at
the identified positions. Subsequently, explicit constructions of STBCs which
results in the reduced ASDC are presented. The rate (in complex symbols per
channel use) of the proposed designs is at most $2/N_{t}$ where $N_{t}$ denotes
the number of transmit antennas for each user. We also show that the class of
STBCs from complex orthogonal designs (other than the Alamouti design) reduce
the WSDC but not the ASDC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1163</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1163</id><created>2009-08-08</created><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Trellis Coded Modulation for Two-User Unequal-Rate Gaussian MAC</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, code pairs based on trellis coded modulation are proposed over
PSK signal sets for a two-user Gaussian multiple access channel. In order to
provide unique decodability property to the receiver and to maximally enlarge
the constellation constrained (CC) capacity region, a relative angle of
rotation is introduced between the signal sets. Subsequently, the structure of
the \textit{sum alphabet} of two PSK signal sets is exploited to prove that
Ungerboeck labelling on the trellis of each user maximizes the guaranteed
minimum squared Euclidean distance, $d^{2}_{g, min}$ in the \textit{sum
trellis}. Hence, such a labelling scheme can be used systematically to
construct trellis code pairs for a two-user GMAC to approach \emph{any rate
pair} within the capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1181</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1181</id><created>2009-08-08</created><updated>2009-09-24</updated><authors><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author></authors><title>2-Player Nash and Nonsymmetric Bargaining Games: Algorithms and
  Structural Properties</title><categories>cs.GT cs.DS</categories><doi>10.1007/978-3-642-16170-4_28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The solution to a Nash or a nonsymmetric bargaining game is obtained by
maximizing a concave function over a convex set, i.e., it is the solution to a
convex program. We show that each 2-player game whose convex program has linear
constraints, admits a rational solution and such a solution can be found in
polynomial time using only an LP solver. If in addition, the game is succinct,
i.e., the coefficients in its convex program are ``small'', then its solution
can be found in strongly polynomial time. We also give a non-succinct linear
game whose solution can be found in strongly polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1185</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1185</id><created>2009-08-08</created><authors><author><keyname>Hernandez-Castro</keyname><forenames>Carlos Javier</forenames></author><author><keyname>Ribagorda</keyname><forenames>Arturo</forenames></author><author><keyname>Saez</keyname><forenames>Yago</forenames></author></authors><title>Side-channel attack on labeling CAPTCHAs</title><categories>cs.CR cs.CV cs.CY cs.HC</categories><acm-class>C.2.0; D.4.6; K.4.4; K.6.5; H.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new scheme of attack on the Microsoft's ASIRRA CAPTCHA which
represents a significant shortcut to the intended attacking path, as it is not
based in any advance in the state of the art on the field of image recognition.
After studying the ASIRRA Public Corpus, we conclude that the security margin
as stated by their authors seems to be quite optimistic. Then, we analyze which
of the studied parameters for the image files seems to disclose the most
valuable information for helping in correct classification, arriving at a
surprising discovery. This represents a completely new approach to breaking
CAPTCHAs that can be applied to many of the currently proposed image-labeling
algorithms, and to prove this point we show how to use the very same approach
against the HumanAuth CAPTCHA. Lastly, we investigate some measures that could
be used to secure the ASIRRA and HumanAuth schemes, but conclude no easy
solutions are at hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1186</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1186</id><created>2009-08-08</created><authors><author><keyname>O'Beirne</keyname><forenames>Patrick</forenames></author></authors><title>Checks and Controls in Spreadsheets</title><categories>cs.HC cs.SE</categories><comments>7 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 1-7 ISBN
  978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets that are informally created are harder to test than they should
be. Simple cross-foot checks or being easily readable are modest but attainable
goals for every spreadsheet developer. This paper lists some tips on building
self-checking into a spreadsheet in order to provide more confidence to the
reader that a spreadsheet is robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1187</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1187</id><created>2009-08-08</created><authors><author><keyname>Paine</keyname><forenames>Jocelyn</forenames></author></authors><title>Documenting Spreadsheets with Pseudo-Code: an Exercise with Cash-Flow
  and Loans</title><categories>cs.SE cs.HC</categories><comments>12 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 173-183
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Look before you leap&quot;; &quot;a stitch in time saves nine&quot;; &quot;more haste, less
speed&quot;. Many proverbs declare the wisdom of planning before doing. We suggest
how to apply this to Excel, by explaining and specifying spreadsheets before
coding them, so there will always be documentation for auditors and maintenance
programmers. The specification method uses &quot;pseudo-code&quot;: code that, for
precision and conciseness, resembles a programming language, but is not
executable. It is, however, based on the notation used by our Excelsior
spreadsheet generator, which is executable. This paper is structured as a
tutorial, in which we develop a simple cash-flow and loans spreadsheet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1188</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1188</id><created>2009-08-08</created><authors><author><keyname>Grossman</keyname><forenames>Thomas A.</forenames></author><author><keyname>Ozluk</keyname><forenames>Ozgur</forenames></author><author><keyname>Gustavson</keyname><forenames>Jan</forenames></author></authors><title>The Lookup Technique to Replace Nested-IF Formulas in Spreadsheet
  Programming</title><categories>cs.SE cs.HC</categories><comments>10 Pages, 5 Figures; ISBN 978-1-905617-89-0</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 17-26</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheet programmers often implement contingent logic using a nested-IF
formula even though this technique is difficult to test and audit and is
believed to be risky. We interpret the programming of contingent logic in
spreadsheets in the context of traditional computer programming. We investigate
the &quot;lookup technique&quot; as an alternative to nested-IF formulas, describe its
benefits for testing and auditing, and define its limitations. The lookup
technique employs four distinct principles: 1) make logical tests visible; 2)
make outcomes visible; 3) make logical structure visible; and 4) replace a
multi-function nested-IF formula with a single-function lookup formula. It can
be used only for certain simple contingent logic. We describe how the
principles can be applied in more complex situations, and suggest avenues for
further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1189</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1189</id><created>2009-08-08</created><authors><author><keyname>Vandeput</keyname><forenames>Etienne</forenames></author></authors><title>Milestones for Teaching the Spreadsheet Program</title><categories>cs.HC cs.LO</categories><comments>11 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 133-143
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are different manners of teaching a spreadsheet program. In any case,
it is intended that the teacher settles the objectives of the course and adapts
them to the particular audience he/she has to deal with. This paper aims at
providing any teacher whatever his/her specific objectives and his/her audience
with elements to help him/her building a course. It focuses mainly on two
important issues: 1 - select in all that may be said about such complex tools,
what is prior to know and to teach, i.e. what leads to autonomy in using but
also to autonomy in learning (because everything cannot be taught) and 2 - show
how concepts are closely related to good formatting considerations. A method
based on the &quot;invariants of information processing&quot; is outlined, partially
illustrated and an implementation is described throughout a course designed for
students preparing a master in Education Sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1190</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1190</id><created>2009-08-08</created><authors><author><keyname>Bradley</keyname><forenames>Leslie</forenames></author><author><keyname>McDaid</keyname><forenames>Kevin</forenames></author></authors><title>Error Estimation in Large Spreadsheets using Bayesian Statistics</title><categories>cs.SE cs.HC</categories><comments>12 Pages, 5 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 27-38
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets are ubiquitous in business with the financial sector
particularly heavily reliant on the technology. It is known that the level of
spreadsheet error can be high and that it is often necessary to review
spreadsheets based on a structured methodology which includes a cell by cell
examination of the spreadsheet. This paper outlines the early research that has
been carried out into the use of Bayesian Statistical methods to estimate the
level of error in large spreadsheets during cell be cell examination based on
expert knowledge and partial spreadsheet test data. The estimate can aid in the
decision as to the quality of the spreadsheet and the necessity to conduct
further testing or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1191</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1191</id><created>2009-08-08</created><authors><author><keyname>Collins</keyname><forenames>Angela</forenames></author></authors><title>Embedded Spreadsheet Modelling</title><categories>cs.HC</categories><comments>5 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 95-99
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In larger accounting firms, specialist modellers typically sit in separate
teams. This paper will look at the advantages of embedding a specialist
modeller within a Corporate Finance Team.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1192</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1192</id><created>2009-08-08</created><authors><author><keyname>Dinmore</keyname><forenames>Matthew</forenames></author></authors><title>Documenting Problem-Solving Knowledge: Proposed Annotation Design
  Guidelines and their Application to Spreadsheet Tools</title><categories>cs.SE cs.HC</categories><comments>12 Pages, 4 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 57-68
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-user programmers create software to solve problems, yet the
problem-solving knowledge generated in the process often remains tacit within
the software artifact. One approach to exposing this knowledge is to enable the
end-user to annotate the artifact as they create and use it. A 3-level model of
annotation is presented and guidelines are proposed for the design of end-user
programming environments supporting the explicit and literate annotation
levels. These guidelines are then applied to the spreadsheet end-user
programming paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1193</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1193</id><created>2009-08-08</created><authors><author><keyname>Flood</keyname><forenames>Derek</forenames></author><author><keyname>Daid</keyname><forenames>Kevin Mc</forenames></author><author><keyname>Caffery</keyname><forenames>Fergal Mc</forenames></author></authors><title>NLP-SIR: A Natural Language Approach for Spreadsheet Information
  Retrieval</title><categories>cs.SE cs.HC cs.IR</categories><comments>12 Pages, 2 Colour Figures, 3 Tables</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 101-112
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets are a ubiquitous software tool, used for a wide variety of tasks
such as financial modelling, statistical analysis and inventory management.
Extracting meaningful information from such data can be a difficult task,
especially for novice users unfamiliar with the advanced data processing
features of many spreadsheet applications. We believe that through the use of
Natural Language Processing (NLP) techniques this task can be made considerably
easier. This paper introduces NLP-SIR, a Natural language interface for
spreadsheet information retrieval. The results of a recent evaluation which
compared NLP-SIR with existing Information retrieval tools are also outlined.
This evaluation has shown that NLP-SIR is a more effective method of
spreadsheet information retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1208</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1208</id><created>2009-08-09</created><updated>2009-08-12</updated><authors><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Gharan</keyname><forenames>Shahab Oveis</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Real Interference Alignment with Real Numbers</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel coding scheme applicable in networks with single antenna nodes is
proposed. This scheme converts a single antenna system to an equivalent
Multiple Input Multiple Output (MIMO) system with fractional dimensions.
Interference can be aligned along these dimensions and higher Multiplexing
gains can be achieved. Tools from the field of Diophantine approximation in
number theory are used to show that the proposed coding scheme in fact mimics
the traditional schemes used in MIMO systems where each data stream is sent
along a direction and alignment happens when several streams arrive at the same
direction. Two types of constellation are proposed for the encoding part,
namely the single layer constellation and the multi-layer constellation.
  Using the single layer constellation, the coding scheme is applied to the
two-user $X$ channel and the three-user Gaussian Interference Channel (GIC). In
case of the two-user $X$ channel, it is proved that the total
Degrees-of-Freedom (DOF), i.e. 4/3, of the channel is achievable almost surely.
This is the first example in which it is shown that a time invariant single
antenna system does not fall short of achieving its total DOF.
  Using the multi-layer constellation, the coding scheme is applied to the
symmetric three-user GIC. Achievable DOFs are derived for all channel gains. As
a function of the channel gain, it is observed that the DOF is everywhere
discontinuous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1220</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1220</id><created>2009-08-09</created><authors><author><keyname>Jemaa</keyname><forenames>Maher Ben</forenames></author><author><keyname>Zouari</keyname><forenames>Maryam Kallel</forenames></author><author><keyname>Zouari</keyname><forenames>Bachar</forenames></author></authors><title>A new approach to services differentiation between mobile terminals of a
  wireless LAN</title><categories>cs.NI</categories><comments>8 Pages, IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study aims to identify the advantages and disadvantages of several
mechanisms for service differentiation in mobile terminals of a wireless LAN to
establish a more better and more optimal. At the end of the analysis of
available approaches for the quality of service of the IEEE 802.11 standard,
the objective of this paper is to suggest a new method named DF-DCF
Differentiated Frame DCF. The performance of the suggested method in a Network
Simulator (NS) environment allowed its validation through a set of testing and
simulation scenarios. Simulation results have shown that the DF-DCF method is
better suited for mobile nodes in a wireless communication network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1222</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1222</id><created>2009-08-09</created><authors><author><keyname>Rajesh</keyname><forenames>R</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author></authors><title>Distributed Joint Source-Channel Coding for Functions over a Multiple
  Access Channel</title><categories>cs.IT math.IT</categories><comments>7 Pages, 2 Figures. To Appear in IEEE GLOBECOM, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide sufficient conditions for lossy transmission of
functions of correlated data over a multiple access channel (MAC). The
conditions obtained can be shown as generalized version of Yamamoto's result.
We also obtain efficient joint source-channel coding schemes for transmission
of discrete and continuous alphabet sources to recover the function values.
  Keywords: Joint source-channel coding, Graph coloring, Lipschitz functions,
Correlated sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1223</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1223</id><created>2009-08-09</created><authors><author><keyname>Rajesh</keyname><forenames>R</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author></authors><title>Joint Source-Channel Coding over a Fading Multiple Access Channel with
  Partial Channel State Information</title><categories>cs.IT math.IT</categories><comments>7 Pages, 3 figures. To Appear in IEEE GLOBECOM, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of transmission of correlated sources
over a fast fading multiple access channel (MAC) with partial channel state
information available at both the encoders and the decoder. We provide
sufficient conditions for transmission with given distortions. Next these
conditions are specialized to a Gaussian MAC (GMAC). We provide the optimal
power allocation strategy and compare the strategy with various levels of
channel state information.
  Keywords: Fading MAC, Power allocation, Partial channel state information,
Correlated sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1264</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1264</id><created>2009-08-09</created><authors><author><keyname>Agarwal</keyname><forenames>Manish</forenames></author><author><keyname>Honig</keyname><forenames>Michael</forenames></author><author><keyname>Ata</keyname><forenames>Baris</forenames></author></authors><title>Adaptive Training for Correlated Fading Channels with Feedback</title><categories>cs.IT math.IT</categories><comments>39 pages. Submitted to IEEE Transactions on Information Theory (Aug
  2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider data transmission through a time-selective, correlated
(first-order Markov) Rayleigh fading channel subject to an average power
constraint. The channel is estimated at the receiver with a pilot signal, and
the estimate is fed back to the transmitter. The estimate is used for coherent
demodulation, and to adapt the data and pilot powers. We explicitly determine
the optimal pilot and data power control policies in a continuous-time limit
where the channel state evolves as an Ornstein-Uhlenbeck diffusion process, and
is estimated by a Kalman filter at the receiver. The optimal pilot policy
switches between zero and the maximum (peak-constrained) value (``bang-bang''
control), and approximates the optimal discrete-time policy at low
Signal-to-Noise Ratios (equivalently, large bandwidths). The switching boundary
is defined in terms of the system state (estimated channel mean and associated
error variance), and can be explicitly computed. Under the optimal policy, the
transmitter conserves power by decreasing the training power when the channel
is faded, thereby increasing the data rate. Numerical results show a
significant increase in achievable rate due to the adaptive training scheme
with feedback, relative to constant (non-adaptive) training, which does not
require feedback. The gain is more pronounced at relatively low SNRs and with
fast fading. Results are further verified through Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1273</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1273</id><created>2009-08-10</created><updated>2011-03-10</updated><authors><author><keyname>Naghshvar</keyname><forenames>Mohammad</forenames></author><author><keyname>Zhuang</keyname><forenames>Hairuo</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author></authors><title>A General Class of Throughput Optimal Routing Policies in Multi-hop
  Wireless Networks</title><categories>math.OC cs.NI cs.SY</categories><comments>31 pages (one column), 8 figures, (revision submitted to IEEE
  Transactions on Information Theory)</comments><msc-class>34D20</msc-class><doi>10.1109/TIT.2011.2178152</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of throughput optimal routing/scheduling in
a multi-hop constrained queueing network with random connectivity whose special
case includes opportunistic multi-hop wireless networks and input-queued switch
fabrics. The main challenge in the design of throughput optimal routing
policies is closely related to identifying appropriate and universal Lyapunov
functions with negative expected drift. The few well-known throughput optimal
policies in the literature are constructed using simple quadratic or
exponential Lyapunov functions of the queue backlogs and as such they seek to
balance the queue backlogs across network independent of the topology. By
considering a class of continuous, differentiable, and piece-wise quadratic
Lyapunov functions, this paper provides a large class of throughput optimal
routing policies. The proposed class of Lyapunov functions allow for the
routing policy to control the traffic along short paths for a large portion of
state-space while ensuring a negative expected drift. This structure enables
the design of a large class of routing policies. In particular, and in addition
to recovering the throughput optimality of the well known backpressure routing
policy, an opportunistic routing policy with congestion diversity is proved to
be throughput optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1298</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1298</id><created>2009-08-10</created><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>Exposing Pseudoweight Layers in Regular LDPC Code Ensembles</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures. In Proc. Information Theory Workshop 2009
  (Taormina, Sicily)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A solution is presented for the asymptotic growth rate of the
AWGN-pseudoweight distribution of regular low-density parity-check (LDPC) code
ensembles for a selected graph cover degree M &gt;= 1. The evaluation of the
growth rate requires solution of a system of 2M+1 nonlinear equations in 2M+1
unknowns. Simulation results for the pseudoweight distribution of two regular
LDPC code ensembles are presented for graph covers of low degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1313</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1313</id><created>2009-08-10</created><updated>2009-08-25</updated><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On Konig-Egervary Square-Stable Graphs</title><categories>math.CO cs.DM</categories><comments>12 pages, 9 figures</comments><msc-class>05C69 (Primary), 05C76 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stability number of a graph G, denoted by alpha(G), is the cardinality of
a maximum stable set, and mu(G) is the cardinality of a maximum matching in G.
If alpha(G)+mu(G) equals its order, then G is a Konig-Egervary graph.
  In this paper we deal with square-stable graphs, i.e., the graphs G enjoying
the equality alpha(G)=alpha(G^{2}), where G^{2} denotes the second power of G.
In particular, we show that a Konig-Egervary graph is square-stable if and only
if it has a perfect matching consisting of pendant edges, and in consequence,
we deduce that well-covered trees are exactly the square-stable trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1348</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1348</id><created>2009-08-10</created><authors><author><keyname>Bierbrauer</keyname><forenames>J.</forenames></author><author><keyname>Marcugini</keyname><forenames>S.</forenames></author><author><keyname>Pambianco</keyname><forenames>F.</forenames></author></authors><title>The non-existence of a [[13,5,4]] quantum stabilizer code</title><categories>cs.IT math.IT quant-ph</categories><msc-class>51E22; 94B27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve one of the oldest problems in the theory of quantum stabilizer codes
by proving the non-existence of quantum [[13,5,4]]-codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1369</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1369</id><created>2009-08-10</created><authors><author><keyname>Zhu</keyname><forenames>Meijun</forenames></author><author><keyname>Zhang</keyname><forenames>Pengfei</forenames></author></authors><title>Segmentation for radar images based on active contour</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exam various geometric active contour methods for radar image
segmentation. Due to special properties of radar images, we propose our new
model based on modified Chan-Vese functional. Our method is efficient in
separating non-meteorological noises from meteorological images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1379</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1379</id><created>2009-08-10</created><authors><author><keyname>Sherman</keyname><forenames>Jonah</forenames></author></authors><title>Breaking the Multicommodity Flow Barrier for sqrt(log(n))-Approximations
  to Sparsest Cut</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper ties the line of work on algorithms that find an
O(sqrt(log(n)))-approximation to the sparsest cut together with the line of
work on algorithms that run in sub-quadratic time by using only
single-commodity flows. We present an algorithm that simultaneously achieves
both goals, finding an O(sqrt(log(n)/eps))-approximation using O(n^eps log^O(1)
n) max-flows. The core of the algorithm is a stronger, algorithmic version of
Arora et al.'s structure theorem, where we show that matching-chaining argument
at the heart of their proof can be viewed as an algorithm that finds good
augmenting paths in certain geometric multicommodity flow networks. By using
that specialized algorithm in place of a black-box solver, we are able to solve
those instances much more efficiently. We also show the cut-matching game
framework can not achieve an approximation any better than Omega(log(n)/log
log(n)) without re-routing flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1390</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1390</id><created>2009-08-10</created><updated>2010-09-23</updated><authors><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author><author><keyname>Miller</keyname><forenames>Dale</forenames></author><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author></authors><title>Nominal Abstraction</title><categories>cs.LO</categories><comments>To appear in the Journal of Information and Computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recursive relational specifications are commonly used to describe the
computational structure of formal systems. Recent research in proof theory has
identified two features that facilitate direct, logic-based reasoning about
such descriptions: the interpretation of atomic judgments through recursive
definitions and an encoding of binding constructs via generic judgments.
However, logics encompassing these two features do not currently allow for the
definition of relations that embody dynamic aspects related to binding, a
capability needed in many reasoning tasks. We propose a new relation between
terms called nominal abstraction as a means for overcoming this deficiency. We
incorporate nominal abstraction into a rich logic also including definitions,
generic quantification, induction, and co-induction that we then prove to be
consistent. We present examples to show that this logic can provide elegant
treatments of binding contexts that appear in many proofs, such as those
establishing properties of typing calculi and of arbitrarily cascading
substitutions that play a role in reducibility arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1397</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1397</id><created>2009-08-10</created><updated>2010-04-23</updated><authors><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Olshevsky</keyname><forenames>Alex</forenames></author></authors><title>Matrix P-norms are NP-hard to approximate if p \neq 1,2,\infty</title><categories>cs.CC</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for any rational p \in [1,\infty) except p = 1, 2, unless P =
NP, there is no polynomial-time algorithm for approximating the matrix p-norm
to arbitrary relative precision. We also show that for any rational p\in
[1,\infty) including p = 1, 2, unless P = NP, there is no polynomial-time
algorithm approximates the \infty, p mixed norm to some fixed relative
precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1407</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1407</id><created>2009-08-10</created><authors><author><keyname>Banerjee</keyname><forenames>Taposh</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author></authors><title>Generalized Analysis of a Distributed Energy Efficient Algorithm for
  Change Detection</title><categories>cs.IT cs.PF math.IT stat.AP</categories><comments>Accepted as a short paper in Proc. of the 12th ACM International
  Symposium on Modeling, Analysis and Simulation of Wireless and Mobile Systems
  (MSWiM), Tenerife, Canary Islands, Spain, Oct 26-30, 2009. Please contact
  vinod@ece.iisc.ernet.in or banerje5@illinois.edu for any clarifications. Also
  visit: http://www.ece.iisc.ernet.in/~vinod/</comments><acm-class>G.3; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An energy efficient distributed Change Detection scheme based on Page's CUSUM
algorithm was presented in \cite{icassp}. In this paper we consider a
nonparametric version of this algorithm. In the algorithm in \cite{icassp},
each sensor runs CUSUM and transmits only when the CUSUM is above some
threshold. The transmissions from the sensors are fused at the physical layer.
The channel is modeled as a Multiple Access Channel (MAC) corrupted with noise.
The fusion center performs another CUSUM to detect the change. In this paper,
we generalize the algorithm to also include nonparametric CUSUM and provide a
unified analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1448</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1448</id><created>2009-08-11</created><authors><author><keyname>Kelner</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Madry</keyname><forenames>Aleksander</forenames></author></authors><title>Faster generation of random spanning trees</title><categories>cs.DS cs.DM</categories><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we set forth a new algorithm for generating approximately
uniformly random spanning trees in undirected graphs. We show how to sample
from a distribution that is within a multiplicative $(1+\delta)$ of uniform in
expected time $\TO(m\sqrt{n}\log 1/\delta)$. This improves the sparse graph
case of the best previously known worst-case bound of $O(\min \{mn,
n^{2.376}\})$, which has stood for twenty years.
  To achieve this goal, we exploit the connection between random walks on
graphs and electrical networks, and we use this to introduce a new approach to
the problem that integrates discrete random walk-based techniques with
continuous linear algebraic methods. We believe that our use of electrical
networks and sparse linear system solvers in conjunction with random walks and
combinatorial partitioning techniques is a useful paradigm that will find
further applications in algorithmic graph theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1453</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1453</id><created>2009-08-11</created><authors><author><keyname>Asadi</keyname><forenames>Roya</forenames></author><author><keyname>Mustapha</keyname><forenames>Norwati</forenames></author><author><keyname>Sulaiman</keyname><forenames>Nasir</forenames></author></authors><title>Training Process Reduction Based On Potential Weights Linear Analysis To
  Accelarate Back Propagation Network</title><categories>cs.NE</categories><comments>11 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning is the important property of Back Propagation Network (BPN) and
finding the suitable weights and thresholds during training in order to improve
training time as well as achieve high accuracy. Currently, data pre-processing
such as dimension reduction input values and pre-training are the contributing
factors in developing efficient techniques for reducing training time with high
accuracy and initialization of the weights is the important issue which is
random and creates paradox, and leads to low accuracy with high training time.
One good data preprocessing technique for accelerating BPN classification is
dimension reduction technique but it has problem of missing data. In this
paper, we study current pre-training techniques and new preprocessing technique
called Potential Weight Linear Analysis (PWLA) which combines normalization,
dimension reduction input values and pre-training. In PWLA, the first data
preprocessing is performed for generating normalized input values and then
applying them by pre-training technique in order to obtain the potential
weights. After these phases, dimension of input values matrix will be reduced
by using real potential weights. For experiment results XOR problem and three
datasets, which are SPECT Heart, SPECTF Heart and Liver disorders (BUPA) will
be evaluated. Our results, however, will show that the new technique of PWLA
will change BPN to new Supervised Multi Layer Feed Forward Neural Network
(SMFFNN) model with high accuracy in one epoch without training cycle. Also
PWLA will be able to have power of non linear supervised and unsupervised
dimension reduction property for applying by other supervised multi layer feed
forward neural network model in future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1457</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1457</id><created>2009-08-11</created><authors><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Gall</keyname><forenames>Fran&#xe7;ois Le</forenames></author><author><keyname>Nishimura</keyname><forenames>Harumichi</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>General Scheme for Perfect Quantum Network Coding with Free Classical
  Communication</title><categories>quant-ph cs.IT math.IT</categories><comments>12 pages, 2 figures, generalizes some of the results in
  arXiv:0902.1299 to the k-pair problem and codes over rings. Appeared in the
  Proceedings of the 36th International Colloquium on Automata, Languages and
  Programming (ICALP'09), LNCS 5555, pp. 622-633, 2009</comments><journal-ref>Proceedings of the 36th International Colloquium on Automata,
  Languages and Programming (ICALP'09), LNCS 5555, pp. 622-633, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of efficiently transmitting quantum states
through a network. It has been known for some time that without additional
assumptions it is impossible to achieve this task perfectly in general --
indeed, it is impossible even for the simple butterfly network. As additional
resource we allow free classical communication between any pair of network
nodes. It is shown that perfect quantum network coding is achievable in this
model whenever classical network coding is possible over the same network when
replacing all quantum capacities by classical capacities. More precisely, it is
proved that perfect quantum network coding using free classical communication
is possible over a network with $k$ source-target pairs if there exists a
classical linear (or even vector linear) coding scheme over a finite ring. Our
proof is constructive in that we give explicit quantum coding operations for
each network node. This paper also gives an upper bound on the number of
classical communication required in terms of $k$, the maximal fan-in of any
network node, and the size of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1471</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1471</id><created>2009-08-11</created><authors><author><keyname>Zhou</keyname><forenames>Fen</forenames><affiliation>IRISA / INSA Rennes</affiliation></author><author><keyname>Molnar</keyname><forenames>Miklos</forenames><affiliation>IRISA / INSA Rennes</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA / University of Rennes I</affiliation></author></authors><title>Distance priority based multicast routing in WDM networks considering
  sparse light splitting</title><categories>cs.NI</categories><comments>11th IEEE International Conference on Communication Systems,
  Guangzhou. China, 19-21 Nov. 2008. (ICCS 2008)</comments><acm-class>C.2.2; C.2.5</acm-class><journal-ref>IEEE International Conference on Communication Systems. (2008)
  709-714</journal-ref><doi>10.1109/ICCS.2008.4737278</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we know, the member-only algorithm in provides the best links stress and
wavelength usage for the construction of multicast light-trees in WDM networks
with sparse splitting. However, the diameter of tree is too big and the average
delay is also too large, which are intolerant for QoS required multimedia
applications. In this paper, a distance priority based algorithm is proposed to
build light-trees for multicast routing, where the Candidate Destinations and
the Candidate Connectors are introduced. Simulations show the proposed
algorithm is able to greatly reduce the diameter and average delay of the
multicast tree (up to 51% and 50% respectively), while keep the same or get a
slightly better link stress as well as the wavelength usage than the famous
Member-Only algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1490</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1490</id><created>2009-08-11</created><updated>2011-02-21</updated><authors><author><keyname>Nagananda</keyname><forenames>K. G.</forenames></author><author><keyname>Murthy</keyname><forenames>Chandra R.</forenames></author></authors><title>Asymmetric Transmitter Cooperation in Multiuser Wireless Networks:
  Achievable Rate Regions</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due another related
  publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we derive achievable rate regions for the three-user
interference channels with asymmetric transmitter cooperation and various
decoding capabilities at the receivers. The three-user channel facilitates
different ways of message sharing between the transmitters. We introduce two
natural ways of extending the concept of unidirectional message sharing from
two users to three users - (i) cumulative message sharing and (ii) primary-only
message sharing. In addition, we define several cognitive interference channels
based on the decoding capability of the receivers. We employ a coding
technique, which is a combination of superposition and Gel'fand-Pinsker coding
techniques, to derive an achievable rate region for each of the cognitive
interference channels. Simulation results, by considering the Gaussian channel
case, enables a visual comparison of the two message-sharing schemes considered
in this paper. It also provides useful insights into the effect of
message-splitting at the transmitters and the decoding capability of the
receivers on the achievable rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1510</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1510</id><created>2009-08-11</created><authors><author><keyname>Reani</keyname><forenames>Avraham</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Efficient On-line Schemes for Encoding Individual Sequences with Side
  Information at the Decoder</title><categories>cs.IT math.IT</categories><comments>33 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present adaptive on-line schemes for lossy encoding of individual
sequences under the conditions of the Wyner-Ziv (WZ) problem. In the first part
of this article, a set of fixed-rate scalar source codes with zero delay is
presented. We propose a randomized on-line coding scheme, which achieves
asymptotically (and with high probability), the performance of the best source
code in the set, uniformly over all source sequences. The scheme uses the same
rate and has zero delay. We then present an efficient algorithm for
implementing our on-line coding scheme in the case of a relatively small set of
encoders. We also present an efficient algorithm for the case of a larger set
of encoders with a structure, using the method of the weighted graph and the
Weight Pushing Algorithm (WPA). In the second part of this article, we extend
our results to the case of variable-rate coding. A set of variable-rate scalar
source codes is presented. We generalize the randomized on-line coding scheme,
to our case. This time, the performance is measured by the Lagrangian Cost
(LC), which is defined as a weighted sum of the distortion and the length of
the encoded sequence. We present an efficient algorithm for implementing our
on-line variable-rate coding scheme in the case of a relatively small set of
encoders. We then consider the special case of lossless variable-rate coding.
An on-line scheme which use Huffman codes is presented. We show that this
scheme can be implemented efficiently using the same graphic methods from the
first part. Combining the results from former sections, we build a generalized
efficient algorithm for structured set of variable-rate encoders. The
complexity of all the algorithms is no more than linear in the sequence length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1528</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1528</id><created>2009-08-11</created><updated>2009-08-12</updated><authors><author><keyname>Geisberger</keyname><forenames>Robert</forenames></author></authors><title>Contraction of Timetable Networks with Realistic Transfers</title><categories>cs.DS</categories><comments>15 pages, technical report</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We successfully contract timetable networks with realistic transfer times.
Contraction gradually removes nodes from the graph and adds shortcuts to
preserve shortest paths. This reduces query times to 1 ms with preprocessing
times around 6 minutes on all tested instances. We achieve this by an improved
contraction algorithm and by using a station graph model. Every node in our
graph has a one-to-one correspondence to a station and every edge has an
assigned collection of connections. Our graph model does not need parallel
edges. The query algorithm does not compute a single earliest arrival time at a
station but a set of arriving connections that allow best transfer
opportunities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1564</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1564</id><created>2009-08-11</created><authors><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Jakubczak</keyname><forenames>Szymon</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Interfacing network coding with TCP: an implementation</title><categories>cs.NI cs.IT math.IT</categories><comments>9 pages; Submitted to INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work (`Network coding meets TCP') we proposed a new protocol that
interfaces network coding with TCP by means of a coding layer between TCP and
IP. Unlike the usual batch-based coding schemes, the protocol uses a
TCP-compatible sliding window code in combination with new rules for
acknowledging bytes to TCP that take into account the network coding operations
in the lower layer. The protocol was presented in a theoretical framework and
considered only in conjunction with TCP Vegas. In this paper we present a
real-world implementation of this protocol that addresses several important
practical aspects of incorporating network coding and decoding with TCP's
window management mechanism. Further, we work with the more widespread and
practical TCP Reno. Our implementation significantly advances the goal of
designing a deployable, general, TCP-compatible protocol that provides the
benefits of network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1580</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1580</id><created>2009-08-11</created><authors><author><keyname>Tort</keyname><forenames>Francoise</forenames></author><author><keyname>Blondel</keyname><forenames>Francois-Marie</forenames></author><author><keyname>Bruillard</keyname><forenames>Eric</forenames></author></authors><title>From error detection to behaviour observation: first results from screen
  capture analysis</title><categories>cs.HC cs.SE</categories><comments>13 Pages; 4 Figures, 6 Tables; ISBN 978-1-905617-89-0</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 119-132</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with errors in using spreadsheets and analysis of automatic
recording of user interaction with spreadsheets. After a review of literature
devoted to spreadsheet errors, we advocate the importance of going from error
detection to interaction behaviour analysis. We explain how we analyze screen
captures and give the main results we have obtained using this specific
methodology with secondary school students (N=24). Transcription provides
general characteristics: time, sequence of performed tasks, unsuccessful
attempts and user preferences. Analysis reveals preferred modes of actions
(toolbar buttons or menu commands), ways of writing formulas, and typical
approaches in searching for solutions. Time, rhythm and density appear to be
promising indicators. We think such an approach (to analyze screen captures)
could be used with more advanced spreadsheet users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1584</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1584</id><created>2009-08-11</created><authors><author><keyname>Glass</keyname><forenames>Mel</forenames></author><author><keyname>Ford</keyname><forenames>David</forenames></author><author><keyname>Dewhurst</keyname><forenames>Sebastian</forenames></author></authors><title>Reducing the Risk of Spreadsheet Usage - a Case Study</title><categories>cs.HC cs.SE</categories><comments>10 Pages, 7 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 163-172
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The frequency with which spreadsheets are used and the associated risk is
well known. Many tools and techniques have been developed which help reduce
risks associate with creating and maintaining spreadsheet. However, little
consideration has been given to reducing the risks of routine usage by the
&quot;consumers&quot; - for example when entering and editing data. EASA's solution,
available commercially, ensures that any routine process involving spreadsheets
can be executed rapidly and without errors by the end-users, often with a
significant reduction in manual effort. Specifically, the technology enables
the rapid creation and deployment of web-based applications, connected to one
or more centralized spreadsheets; this ensures version control, easy and error
free usage, and security of intellectual property contained in spreadsheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1597</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1597</id><created>2009-08-11</created><authors><author><keyname>Kesidis</keyname><forenames>George</forenames></author></authors><title>A quantum diffusion network</title><categories>cs.NE</categories><report-no>Technical Report Number CSE 09-012</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wong's diffusion network is a stochastic, zero-input Hopfield network with a
Gibbs stationary distribution over a bounded, connected continuum. Previously,
logarithmic thermal annealing was demonstrated for the diffusion network and
digital versions of it were studied and applied to imaging. Recently, &quot;quantum&quot;
annealed Markov chains have garnered significant attention because of their
improved performance over &quot;pure&quot; thermal annealing. In this note, a joint
quantum and thermal version of Wong's diffusion network is described and its
convergence properties are studied. Different choices for &quot;auxiliary&quot; functions
are discussed, including those of the kinetic type previously associated with
quantum annealing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1599</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1599</id><created>2009-08-11</created><authors><author><keyname>Higuchi</keyname><forenames>Saburo</forenames></author><author><keyname>M&#xe9;zard</keyname><forenames>Marc</forenames></author></authors><title>Decimation flows in constraint satisfaction problems</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC</categories><comments>14 pages, 2 figures</comments><journal-ref>J. Stat. Mech. (2009) P12009</journal-ref><doi>10.1088/1742-5468/2009/12/P12009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study hard constraint satisfaction problems with a decimation approach
based on message passing algorithms. Decimation induces a renormalization flow
in the space of problems, and we exploit the fact that this flow transforms
some of the constraints into linear constraints over GF(2). In particular, when
the flow hits the subspace of linear problems, one can stop decimation and use
Gaussian elimination. We introduce a new decimation algorithm which uses this
linear structure and shows a strongly improved performance with respect to the
usual decimation methods on some of the hardest locked occupation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1608</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1608</id><created>2009-08-11</created><authors><author><keyname>Duncan</keyname><forenames>Christian A.</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author></authors><title>Planar Drawings of Higher-Genus Graphs</title><categories>cs.CG cs.DM</categories><comments>A condensed version of this paper is to appear in Graph Drawing 2009.
  This is just a first draft. A final draft will appear in the near future</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give polynomial-time algorithms that can take a graph G
with a given combinatorial embedding on an orientable surface S of genus g and
produce a planar drawing of G in R^2, with a bounding face defined by a
polygonal schema P for S. Our drawings are planar, but they allow for multiple
copies of vertices and edges on P's boundary, which is a common way of
visualizing higher-genus graphs in the plane. Our drawings can be defined with
respect to either a canonical polygonal schema or a polygonal cutset schema,
which provides an interesting tradeoff, since canonical schemas have fewer
sides, and have a nice topological structure, but they can have many more
repeated vertices and edges than general polygonal cutsets. As a side note, we
show that it is NP-complete to determine whether a given graph embedded in a
genus-g surface has a set of 2g fundamental cycles with vertex-disjoint
interiors, which would be desirable from a graph-drawing perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1613</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1613</id><created>2009-08-12</created><authors><author><keyname>Su</keyname><forenames>Yi</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Linearly Coupled Communication Games</title><categories>cs.GT</categories><comments>20 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses a special type of multi-user communication scenario, in
which users' utilities are linearly impacted by their competitors' actions.
First, we explicitly characterize the Nash equilibrium and Pareto boundary of
the achievable utility region. Second, the price of anarchy incurred by the
non-collaborative Nash strategy is quantified. Third, to improve the
performance in the non-cooperative scenarios, we investigate the properties of
an alternative solution concept named conjectural equilibrium, in which
individual users compensate for their lack of information by forming internal
beliefs about their competitors. The global convergence of the best response
and Jacobi update dynamics that achieve various conjectural equilibria are
analyzed. It is shown that the Pareto boundaries of the investigated linearly
coupled games can be sustained as stable conjectural equilibria if the belief
functions are properly initialized. The investigated models apply to a variety
of realistic applications encountered in the multiple access design, including
wireless random access and flow control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1667</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1667</id><created>2009-08-12</created><authors><author><keyname>Perlaza</keyname><forenames>S. M.</forenames></author><author><keyname>Belmega</keyname><forenames>E. V.</forenames></author><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author></authors><title>On the Base Station Selection and Base Station Sharing in
  Self-Configuring Networks</title><categories>cs.GT</categories><comments>3rd ICST/ACM International Workshop on Game Theory in Communication
  Networks. October 23th 2009. Pisa, Italy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model the interaction of several radio devices aiming to obtain wireless
connectivity by using a set of base stations (BS) as a non-cooperative game.
Each radio device aims to maximize its own spectral efficiency (SE) in two
different scenarios: First, we let each player to use a unique BS (BS
selection) and second, we let them to simultaneously use several BSs (BS
Sharing). In both cases, we show that the resulting game is an exact potential
game. We found that the BS selection game posses multiple Nash equilibria (NE)
while the BS sharing game posses a unique one. We provide fully decentralized
algorithms which always converge to a NE in both games. We analyze the price of
anarchy and the price of stability for the case of BS selection. Finally, we
observed that depending on the number of transmitters, the BS selection
technique might provide a better global performance (network spectral
efficiency) than BS sharing, which suggests the existence of a Braess type
paradox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1669</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1669</id><created>2009-08-12</created><updated>2010-07-30</updated><authors><author><keyname>Ezerman</keyname><forenames>Martianus Frederic</forenames></author><author><keyname>Grassl</keyname><forenames>Markus</forenames></author><author><keyname>Sole</keyname><forenames>Patrick</forenames></author></authors><title>The Weights in MDS Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE Trans. IT. This version 2 is the revised
  version after the refereeing process. Accepted for publication</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 1, January
  2011, pp. 392-396</journal-ref><doi>10.1109/TIT.2010.2090246</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The weights in MDS codes of length n and dimension k over the finite field
GF(q) are studied. Up to some explicit exceptional cases, the MDS codes with
parameters given by the MDS conjecture are shown to contain all k weights in
the range n-k+1 to n. The proof uses the covering radius of the dual code
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1676</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1676</id><created>2009-08-12</created><authors><author><keyname>Kuppinger</keyname><forenames>Patrick</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Improved Sparsity Thresholds Through Dictionary Splitting</title><categories>cs.IT math.IT</categories><comments>IEEE Information Theory Workshop (ITW), Taormina, Italy, Oct. 2009,
  to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Known sparsity thresholds for basis pursuit to deliver the maximally sparse
solution of the compressed sensing recovery problem typically depend on the
dictionary's coherence. While the coherence is easy to compute, it can lead to
rather pessimistic thresholds as it captures only limited information about the
dictionary. In this paper, we show that viewing the dictionary as the
concatenation of two general sub-dictionaries leads to provably better sparsity
thresholds--that are explicit in the coherence parameters of the dictionary and
of the individual sub-dictionaries. Equivalently, our results can be
interpreted as sparsity thresholds for dictionaries that are unions of two
general (i.e., not necessarily orthonormal) sub-dictionaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1769</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1769</id><created>2009-08-12</created><authors><author><keyname>Huang</keyname><forenames>Bert</forenames></author><author><keyname>Jebara</keyname><forenames>Tony</forenames></author></authors><title>Approximating the Permanent with Belief Propagation</title><categories>cs.LG cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This work describes a method of approximating matrix permanents efficiently
using belief propagation. We formulate a probability distribution whose
partition function is exactly the permanent, then use Bethe free energy to
approximate this partition function. After deriving some speedups to standard
belief propagation, the resulting algorithm requires $(n^2)$ time per
iteration. Finally, we demonstrate the advantages of using this approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1774</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1774</id><created>2009-08-12</created><updated>2010-02-15</updated><authors><author><keyname>Shuman</keyname><forenames>David I</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author><author><keyname>Wu</keyname><forenames>Owen Q.</forenames></author></authors><title>Energy-Efficient Transmission Scheduling with Strict Underflow
  Constraints</title><categories>math.OC cs.IT math.IT</categories><comments>109 pages, 11 pdf figures, template.tex is main file. We have
  significantly revised the paper from version 1. Additions include the case of
  a single receiver with piecewise-linear convex power-rate curves, the case of
  two receivers, and the infinite horizon average expected cost problem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a single source transmitting data to one or more receivers/users
over a shared wireless channel. Due to random fading, the wireless channel
conditions vary with time and from user to user. Each user has a buffer to
store received packets before they are drained. At each time step, the source
determines how much power to use for transmission to each user. The source's
objective is to allocate power in a manner that minimizes an expected cost
measure, while satisfying strict buffer underflow constraints and a total power
constraint in each slot. The expected cost measure is composed of costs
associated with power consumption from transmission and packet holding costs.
The primary application motivating this problem is wireless media streaming.
For this application, the buffer underflow constraints prevent the user buffers
from emptying, so as to maintain playout quality. In the case of a single user
with linear power-rate curves, we show that a modified base-stock policy is
optimal under the finite horizon, infinite horizon discounted, and infinite
horizon average expected cost criteria. For a single user with piecewise-linear
convex power-rate curves, we show that a finite generalized base-stock policy
is optimal under all three expected cost criteria. We also present the
sequences of critical numbers that complete the characterization of the optimal
control laws in each of these cases when some additional technical conditions
are satisfied. We then analyze the structure of the optimal policy for the case
of two users. We conclude with a discussion of methods to identify
implementable near-optimal policies for the most general case of M users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1776</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1776</id><created>2009-08-12</created><authors><author><keyname>Lariviere</keyname><forenames>Vincent</forenames></author><author><keyname>Gingras</keyname><forenames>Yves</forenames></author></authors><title>On the relationship between interdisciplinarity and scientific impact</title><categories>physics.soc-ph cs.DL</categories><comments>10 pages, 3 figures, 1 table. Forthcoming in JASIST</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the effect of interdisciplinarity on the scientific
impact of individual papers. Using all the papers published in Web of Science
in 2000, we define the degree of interdisciplinarity of a given paper as the
percentage of its cited references made to journals of other disciplines. We
show that, although for all disciplines combined there is no clear correlation
between the level of interdisciplinarity of papers and their citation rates,
there are nonetheless some disciplines in which a higher level of
interdisciplinarity is related to a higher citation rates. For other
disciplines, citations decline as interdisciplinarity grows. One characteristic
is visible in all disciplines: highly disciplinary and highly interdisciplinary
papers have a low scientific impact. This suggests that there might be an
optimum of interdisciplinarity beyond which the research is too dispersed to
find its niche and under which it is too mainstream to have high impact.
Finally, the relationship between interdisciplinarity and scientific impact is
highly determined by the citation characteristics of the disciplines involved:
papers citing citation intensive disciplines are more likely to be cited by
those disciplines and, hence, obtain higher citation scores than papers citing
non citation intensive disciplines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1789</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1789</id><created>2009-08-12</created><updated>2010-06-25</updated><authors><author><keyname>Kumar</keyname><forenames>Naveen</forenames></author><author><keyname>Agarwal</keyname><forenames>Pranav</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author><author><keyname>Salapaka</keyname><forenames>Murti</forenames></author></authors><title>Maximum-Likelihood Sequence Detector for Dynamic Mode High Density Probe
  Storage</title><categories>cs.IT math.IT</categories><comments>This paper is published in IEEE Trans. on communication</comments><journal-ref>IEEE Trans. on Communications vol. 58(6), pp. 1686-1694, Jun. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an increasing need for high density data storage devices driven by
the increased demand of consumer electronics. In this work, we consider a data
storage system that operates by encoding information as topographic profiles on
a polymer medium. A cantilever probe with a sharp tip (few nm radius) is used
to create and sense the presence of topographic profiles, resulting in a
density of few Tb per in.2. The prevalent mode of using the cantilever probe is
the static mode that is harsh on the probe and the media. In this article, the
high quality factor dynamic mode operation, that is less harsh on the media and
the probe, is analyzed. The read operation is modeled as a communication
channel which incorporates system memory due to inter-symbol interference and
the cantilever state. We demonstrate an appropriate level of abstraction of
this complex nanoscale system that obviates the need for an involved physical
model. Next, a solution to the maximum likelihood sequence detection problem
based on the Viterbi algorithm is devised. Experimental and simulation results
demonstrate that the performance of this detector is several orders of
magnitude better than the performance of other existing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1797</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1797</id><created>2009-08-12</created><updated>2009-10-10</updated><authors><author><keyname>Dastidar</keyname><forenames>Kajari Ghosh</forenames></author><author><keyname>Herman</keyname><forenames>Ted</forenames></author></authors><title>Separation of Circulating Tokens</title><categories>cs.DC</categories><comments>22 pages, 7 figures, epsf and pstricks in LaTeX</comments><report-no>TR09-02</report-no><acm-class>C.2.4; D.1.3; D.2.2; C.3</acm-class><doi>10.1007/978-3-642-05118-0_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-stabilizing distributed control is often modeled by token abstractions.
A system with a single token may implement mutual exclusion; a system with
multiple tokens may ensure that immediate neighbors do not simultaneously enjoy
a privilege. For a cyber-physical system, tokens may represent physical objects
whose movement is controlled. The problem studied in this paper is to ensure
that a synchronous system with m circulating tokens has at least d distance
between tokens. This problem is first considered in a ring where d is given
whilst m and the ring size n are unknown. The protocol solving this problem can
be uniform, with all processes running the same program, or it can be
non-uniform, with some processes acting only as token relays. The protocol for
this first problem is simple, and can be expressed with Petri net formalism. A
second problem is to maximize d when m is given, and n is unknown. For the
second problem, the paper presents a non-uniform protocol with a single
corrective process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1805</identifier>
 <datestamp>2012-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1805</id><created>2009-08-12</created><updated>2012-11-12</updated><authors><author><keyname>Ghaderi</keyname><forenames>J.</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Towards a Theory of Anonymous Networking</title><categories>cs.NI cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of anonymous networking when an eavesdropper observes packet
timings in a communication network is considered. The goal is to hide the
identities of source-destination nodes, and paths of information flow in the
network. One way to achieve such an anonymity is to use mixers. Mixers are
nodes that receive packets from multiple sources and change the timing of
packets, by mixing packets at the output links, to prevent the eavesdropper
from finding sources of outgoing packets. In this paper, we consider two simple
but fundamental scenarios: double input-single output mixer and double
input-double output mixer. For the first case, we use the information-theoretic
definition of the anonymity, based on average entropy per packet, and find an
optimal mixing strategy under a strict latency constraint. For the second case,
perfect anonymity is considered, and maximal throughput strategies with perfect
anonymity are found under a strict latency constraint and an average queue
length constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1826</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1826</id><created>2009-08-12</created><updated>2009-08-18</updated><authors><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author></authors><title>An Efficient Greedy Algorithm for Sparse Recovery in Noisy Environment</title><categories>cs.IT math.IT</categories><comments>12 pages, 20 figures, submitted to IEEE Trans on Signal Processing.
  Revised version, 2 figures are replaced</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Greedy algorithm are in widespread use for sparse recovery because of its
efficiency. But some evident flaws exists in most popular greedy algorithms,
such as CoSaMP, which includes unreasonable demands on prior knowledge of
target signal and excessive sensitivity to random noise. A new greedy algorithm
called AMOP is proposed in this paper to overcome these obstacles. Unlike
CoSaMP, AMOP can extract necessary information of target signal from sample
data adaptively and operate normally with little prior knowledge. The recovery
error of AMOP is well controlled when random noise is presented and fades away
along with increase of SNR. Moreover, AMOP has good robustness on detailed
setting of target signal and less dependence on structure of measurement
matrix. The validity of AMOP is verified by theoretical derivation. Extensive
simulation experiment is performed to illustrate the advantages of AMOP over
CoSaMP in many respects. AMOP is a good candidate of practical greedy algorithm
in various applications of Compressed Sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1916</identifier>
 <datestamp>2012-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1916</id><created>2009-08-13</created><updated>2011-12-29</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Caching in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>28 pages, to appear in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 58, pp. 6524 - 6540,
  October 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of delivering content cached in a wireless network of
n nodes randomly located on a square of area n. The network performance is
described by the n2^n-dimensional caching capacity region of the wireless
network. We provide an inner bound on this caching capacity region, and, in the
high path-loss regime, a matching (in the scaling sense) outer bound. For large
path-loss exponent, this provides an information-theoretic scaling
characterization of the entire caching capacity region. The proposed
communication scheme achieving the inner bound shows that the problems of cache
selection and channel coding can be solved separately without loss of
order-optimality. On the other hand, our results show that the common
architecture of nearest-neighbor cache selection can be arbitrarily bad,
implying that cache selection and load balancing need to be performed jointly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1919</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1919</id><created>2009-08-13</created><updated>2009-10-01</updated><authors><author><keyname>Bradley</keyname><forenames>Patrick Erik</forenames></author></authors><title>A dyadic solution of relative pose problems</title><categories>cs.CV</categories><comments>7 pages; references added; typos and Thm 2 corrected (not affecting
  the other results)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hierarchical interval subdivision is shown to lead to a $p$-adic encoding
of image data. This allows in the case of the relative pose problem in computer
vision and photogrammetry to derive equations having 2-adic numbers as
coefficients, and to use Hensel's lifting method to their solution. This method
is applied to the linear and non-linear equations coming from eight, seven or
five point correspondences. An inherent property of the method is its
robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1932</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1932</id><created>2009-08-13</created><updated>2009-08-18</updated><authors><author><keyname>Mulmuley</keyname><forenames>Ketan D.</forenames></author></authors><title>On P vs. NP, Geometric Complexity Theory, Explicit Proofs and the
  Complexity Barrier</title><categories>cs.CC</categories><comments>65 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric complexity theory (GCT) is an approach to the P vs. NP and related
problems. This article gives its complexity theoretic overview without assuming
any background in algebraic geometry or representation theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1936</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1936</id><created>2009-08-13</created><updated>2009-08-18</updated><authors><author><keyname>Mulmuley</keyname><forenames>Ketan D.</forenames></author></authors><title>On P vs. NP, Geometric Complexity Theory, and the Riemann Hypothesis</title><categories>cs.CC</categories><comments>71 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric complexity theory (GCT) is an approach to the $P$ vs. $NP$ and
related problems. A high level overview of this research plan and the results
obtained so far was presented in a series of three lectures in the Institute of
Advanced study, Princeton, Feb 9-11, 2009. This article contains the material
covered in those lectures after some revision, and gives a mathematical
overview of GCT. No background in algebraic geometry, representation theory or
quantum groups is assumed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1948</identifier>
 <datestamp>2009-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1948</id><created>2009-08-13</created><updated>2009-08-20</updated><authors><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Interference Mitigation Through Limited Receiver Cooperation: Symmetric
  Case</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Information Theory Workshop, Taormina, October
  2009. Final version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is a major issue that limits the performance in wireless
networks, and cooperation among receivers can help mitigate interference by
forming distributed MIMO systems. The rate at which receivers cooperate,
however, is limited in most scenarios. How much interference can one bit of
receiver cooperation mitigate? In this paper, we study the two-user Gaussian
interference channel with conferencing decoders to answer this question in a
simple setting. We characterize the fundamental gain from cooperation: at high
SNR, when INR is below 50% of SNR in dB scale, one-bit cooperation per
direction buys roughly one-bit gain per user until full receiver cooperation
performance is reached, while when INR is between 67% and 200% of SNR in dB
scale, one-bit cooperation per direction buys roughly half-bit gain per user.
The conclusion is drawn based on the approximate characterization of the
symmetric capacity in the symmetric set-up. We propose strategies achieving the
symmetric capacity universally to within 3 bits. The strategy consists of two
parts: (1) the transmission scheme, where superposition encoding with a simple
power split is employed, and (2) the cooperative protocol, where
quantize-binning is used for relaying.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.1966</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.1966</id><created>2009-08-14</created><updated>2009-08-16</updated><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>Spectral Graph Analysis of Quasi-Cyclic Codes</title><categories>cs.IT math.IT</categories><comments>5 pages. Proc. IEEE Globecom 2009, Hawaii, USA, November 30 -
  December 4, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze the bound on the additive white Gaussian noise
channel (AWGNC) pseudo-weight of a (c,d)-regular linear block code based on the
two largest eigenvalues of H^T H. In particular, we analyze (c,d)-regular
quasi-cyclic (QC) codes of length rL described by J x L block parity-check
matrices with circulant block entries of size r x r. We proceed by showing how
the problem of computing the eigenvalues of the rL x rL matrix H^T H can be
reduced to the problem of computing eigenvalues for r matrices of size L x L.
We also give a necessary condition for the bound to be attained for a circulant
matrix H and show a few classes of cyclic codes satisfying this criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2005</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2005</id><created>2009-08-13</created><updated>2011-02-01</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Baron</keyname><forenames>Dror</forenames></author><author><keyname>Ihler</keyname><forenames>Alex T.</forenames></author><author><keyname>Avissar</keyname><forenames>Harel</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Fault Identification via Non-parametric Belief Propagation</title><categories>cs.IT math.IT</categories><comments>In IEEE Tran. On Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of identifying a pattern of faults from a set of
noisy linear measurements. Unfortunately, maximum a posteriori probability
estimation of the fault pattern is computationally intractable. To solve the
fault identification problem, we propose a non-parametric belief propagation
approach. We show empirically that our belief propagation solver is more
accurate than recent state-of-the-art algorithms including interior point
methods and semidefinite programming. Our superior performance is explained by
the fact that we take into account both the binary nature of the individual
faults and the sparsity of the fault pattern arising from their rarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2007</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2007</id><created>2009-08-13</created><authors><author><keyname>Soldo</keyname><forenames>Fabio</forenames></author><author><keyname>Le</keyname><forenames>Anh</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>Predictive Blacklisting as an Implicit Recommendation System</title><categories>cs.NI</categories><comments>Comments: 11 pages; Submitted to INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A widely used defense practice against malicious traffic on the Internet is
through blacklists: lists of prolific attack sources are compiled and shared.
The goal of blacklists is to predict and block future attack sources. Existing
blacklisting techniques have focused on the most prolific attack sources and,
more recently, on collaborative blacklisting. In this paper, we formulate the
problem of forecasting attack sources (also referred to as predictive
blacklisting) based on shared attack logs as an implicit recommendation system.
We compare the performance of existing approaches against the upper bound for
prediction, and we demonstrate that there is much room for improvement.
Inspired by the recent Netflix competition, we propose a multi-level prediction
model that is adjusted and tuned specifically for the attack forecasting
problem. Our model captures and combines various factors, namely:
attacker-victim history (using time-series) and attackers and/or victims
interactions (using neighborhood models). We evaluate our combined method on
one month of logs from Dshield.org and demonstrate that it improves
significantly the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2024</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2024</id><created>2009-08-14</created><authors><author><keyname>Ndifon</keyname><forenames>Wilfred</forenames></author><author><keyname>Plotkin</keyname><forenames>Joshua B.</forenames></author><author><keyname>Dushoff</keyname><forenames>Jonathan</forenames></author></authors><title>On the accessibility of adaptive phenotypes of a bacterial metabolic
  network</title><categories>q-bio.PE cs.IT math.IT q-bio.MN q-bio.QM</categories><comments>48 pages, 9 figures, 1 table. Accepted in PLoS Computational Biology
  (July '09)</comments><doi>10.1371/journal.pcbi.1000472</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mechanisms by which adaptive phenotypes spread within an evolving
population after their emergence are understood fairly well. Much less is known
about the factors that influence the evolutionary accessibility of such
phenotypes, a pre-requisite for their emergence in a population. Here, we
investigate the influence of environmental quality on the accessibility of
adaptive phenotypes of Escherichia coli's central metabolic network. We used an
established flux-balance model of metabolism as the basis for a
genotype-phenotype map (GPM). We quantified the effects of seven qualitatively
different environments (corresponding to both carbohydrate and gluconeogenic
metabolic substrates) on the structure of this GPM. We found that the GPM has a
more rugged structure in qualitatively poorer environments, suggesting that
adaptive phenotypes could be intrinsically less accessible in such
environments. Nevertheless, on average ~74% of the genotype can be altered by
neutral drift, in the environment where the GPM is most rugged; this could
allow evolving populations to circumvent such ruggedness. Furthermore, we found
that the normalized mutual information (NMI) of genotype differences relative
to phenotype differences, which measures the GPM's capacity to transmit
information about phenotype differences, is positively correlated with
(simulation-based) estimates of the accessibility of adaptive phenotypes in
different environments. These results are consistent with the predictions of a
simple analytic theory and they suggest an intuitive information-theoretic
principle for evolutionary adaptation; adaptation could be faster in
environments where the GPM has a greater capacity to transmit information about
phenotype differences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2032</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2032</id><created>2009-08-14</created><authors><author><keyname>Meyer</keyname><forenames>Eric T.</forenames></author><author><keyname>Schroeder</keyname><forenames>Ralph</forenames></author></authors><title>Untangling the Web of E-Research: Towards a Sociology of Online
  Knowledge</title><categories>cs.CY</categories><journal-ref>Journal of Informetrics (2009) 3(3):246-260</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  e-Research is a rapidly growing research area, both in terms of publications
and in terms of funding. In this article we argue that it is necessary to
reconceptualize the ways in which we seek to measure and understand e-Research
by developing a sociology of knowledge based on our understanding of how
science has been transformed historically and shifted into online forms. Next,
we report data which allows the examination of e-Research through a variety of
traces in order to begin to understand how the knowledge in the realm of
e-Research has been and is being constructed. These data indicate that
e-Research has had a variable impact in different fields of research. We argue
that only an overall account of the scale and scope of e-Research within and
between different fields makes it possible to identify the organizational
coherence and diffuseness of e-Research in terms of its socio-technical
networks, and thus to identify the contributions of e-Research to various
research fronts in the online production of knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2042</identifier>
 <datestamp>2009-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2042</id><created>2009-08-14</created><updated>2009-09-13</updated><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author></authors><title>Problems in application of LDPC codes to information reconciliation in
  quantum key distribution protocols</title><categories>cs.IT cs.CR math.IT quant-ph</categories><comments>10 pages, 1 figure. short survey article</comments><report-no>IT2009-41</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The information reconciliation in a quantum key distribution protocol can be
studied separately from other steps in the protocol. The problem of information
reconciliation can be reduced to that of distributed source coding. Its
solution by LDPC codes is reviewed. We list some obstacles preventing the
LDPC-based distributed source coding from becoming a more favorable alternative
to the Cascade protocol for information reconciliation in quantum key
distribution protocols. This exposition does not require knowledge of the
quantum theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2050</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2050</id><created>2009-08-14</created><authors><author><keyname>Schulte</keyname><forenames>Christian</forenames></author><author><keyname>Tack</keyname><forenames>Guido</forenames></author></authors><title>View-based Propagator Derivation</title><categories>cs.AI</categories><comments>28 pages, 7 tables, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When implementing a propagator for a constraint, one must decide about
variants: When implementing min, should one also implement max? Should one
implement linear constraints both with unit and non-unit coefficients?
Constraint variants are ubiquitous: implementing them requires considerable (if
not prohibitive) effort and decreases maintainability, but will deliver better
performance than resorting to constraint decomposition.
  This paper shows how to use views to derive perfect propagator variants. A
model for views and derived propagators is introduced. Derived propagators are
proved to be indeed perfect in that they inherit essential properties such as
correctness and domain and bounds consistency. Techniques for systematically
deriving propagators such as transformation, generalization, specialization,
and type conversion are developed. The paper introduces an implementation
architecture for views that is independent of the underlying constraint
programming system. A detailed evaluation of views implemented in Gecode shows
that derived propagators are efficient and that views often incur no overhead.
Without views, Gecode would either require 180 000 rather than 40 000 lines of
propagator code, or would lack many efficient propagator variants. Compared to
8 000 lines of code for views, the reduction in code for propagators yields a
1750% return on investment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2056</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2056</id><created>2009-08-14</created><authors><author><keyname>Peres</keyname><forenames>Yuval</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Reconstruction on Trees: Exponential Moment Bounds for Linear Estimators</title><categories>math.PR cs.DS math.ST q-bio.PE stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a Markov chain $(\xi_v)_{v \in V} \in [k]^V$ on the infinite $b$-ary
tree $T = (V,E)$ with irreducible edge transition matrix $M$, where $b \geq 2$,
$k \geq 2$ and $[k] = \{1,...,k\}$. We denote by $L_n$ the level-$n$ vertices
of $T$. Assume $M$ has a real second-largest (in absolute value) eigenvalue
$\lambda$ with corresponding real eigenvector $\nu \neq 0$. Letting $\sigma_v =
\nu_{\xi_v}$, we consider the following root-state estimator, which was
introduced by Mossel and Peres (2003) in the context of the &quot;recontruction
problem&quot; on trees: \begin{equation*} S_n = (b\lambda)^{-n} \sum_{x\in L_n}
\sigma_x. \end{equation*} As noted by Mossel and Peres, when $b\lambda^2 &gt; 1$
(the so-called Kesten-Stigum reconstruction phase) the quantity $S_n$ has
uniformly bounded variance. Here, we give bounds on the moment-generating
functions of $S_n$ and $S_n^2$ when $b\lambda^2 &gt; 1$. Our results have
implications for the inference of evolutionary trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2061</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2061</id><created>2009-08-14</created><authors><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Sequence-Length Requirement of Distance-Based Phylogeny Reconstruction:
  Breaking the Polynomial Barrier</title><categories>math.PR cs.CE cs.DS math.ST q-bio.PE q-bio.QM stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new distance-based phylogeny reconstruction technique which
provably achieves, at sufficiently short branch lengths, a polylogarithmic
sequence-length requirement -- improving significantly over previous polynomial
bounds for distance-based methods. The technique is based on an averaging
procedure that implicitly reconstructs ancestral sequences.
  In the same token, we extend previous results on phase transitions in
phylogeny reconstruction to general time-reversible models. More precisely, we
show that in the so-called Kesten-Stigum zone (roughly, a region of the
parameter space where ancestral sequences are well approximated by ``linear
combinations'' of the observed sequences) sequences of length $\poly(\log n)$
suffice for reconstruction when branch lengths are discretized. Here $n$ is the
number of extant species.
  Our results challenge, to some extent, the conventional wisdom that estimates
of evolutionary distances alone carry significantly less information about
phylogenies than full sequence datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2083</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2083</id><created>2009-08-14</created><authors><author><keyname>Brzozowski</keyname><forenames>J.</forenames></author><author><keyname>Jir&#xe1;skov&#xe1;</keyname><forenames>G.</forenames></author><author><keyname>Li</keyname><forenames>B.</forenames></author></authors><title>Quotient complexity of ideal languages</title><categories>cs.FL</categories><comments>24 pages, 9 .eepic figures, 2 tables, use llncs.cls</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the state complexity of regular operations in the class of ideal
languages. A language L over an alphabet Sigma is a right (left) ideal if it
satisfies L = L Sigma* (L = Sigma* L). It is a two-sided ideal if L = Sigma* L
Sigma *, and an all-sided ideal if it is the shuffle of Sigma* with L. We
prefer the term &quot;quotient complexity&quot; instead of &quot;state complexity&quot;, and we use
derivatives to calculate upper bounds on quotient complexity, whenever it is
convenient. We find tight upper bounds on the quotient complexity of each type
of ideal language in terms of the complexity of an arbitrary generator and of
its minimal generator, the complexity of the minimal generator, and also on the
operations union, intersection, set difference, symmetric difference,
concatenation, star and reversal of ideal languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2117</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2117</id><created>2009-08-14</created><authors><author><keyname>Zaerin</keyname><forenames>Masoud</forenames></author><author><keyname>Seyfe</keyname><forenames>Babak</forenames></author><author><keyname>Nikoofar</keyname><forenames>Hamid R.</forenames></author></authors><title>Multiuser Modulation Classification Based on Cumulants in AWGN Channel</title><categories>cs.IT math.IT</categories><comments>25 Pages, 7 Figures, 1 Table, Submitted to IEEE Transaction on
  Communications. Submitted to IEEE Transaction on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the negative impacts of interference transmitters on automatic
modulation classification (AMC) have been discussed. We proposed two approaches
for AMC in the presence of interference: single user modulation classification
(SUMC) and multiuser modulation classification (MUMC). When the received power
of one transmitter is larger than the other transmitters, SUMC approach
recognizes the modulation type of that transmitter and other transmitters are
treated as interferences. Alternatively when the received powers of all
transmitters are close to each other we propose MUMC method to recognize the
modulation type of all of the transmitted signals. The features being used to
recognize the modulation types of transmitters for both approaches, SUMC and
MUMC are higher order cumulants. The super-position property of cumulants for
independent random variables is utilized for SUMC and MUMC. We investigated the
robustness of our classifier with respect to different powers of the received
signals via analytical and simulation results and we have shown the analytical
results will be confirmed by simulations. Also we studied the effect of signal
synchroni-zation error via simulation results in the both condition for MUMC
and SUMC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2119</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2119</id><created>2009-08-14</created><updated>2011-06-12</updated><authors><author><keyname>Nazer</keyname><forenames>Bobak</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>Compute-and-Forward: Harnessing Interference through Structured Codes</title><categories>cs.IT math.IT</categories><comments>IEEE Trans. Info Theory, to appear. 23 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is usually viewed as an obstacle to communication in wireless
networks. This paper proposes a new strategy, compute-and-forward, that
exploits interference to obtain significantly higher rates between users in a
network. The key idea is that relays should decode linear functions of
transmitted messages according to their observed channel coefficients rather
than ignoring the interference as noise. After decoding these linear equations,
the relays simply send them towards the destinations, which given enough
equations, can recover their desired messages. The underlying codes are based
on nested lattices whose algebraic structure ensures that integer combinations
of codewords can be decoded reliably. Encoders map messages from a finite field
to a lattice and decoders recover equations of lattice points which are then
mapped back to equations over the finite field. This scheme is applicable even
if the transmitters lack channel state information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2122</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2122</id><created>2009-08-14</created><authors><author><keyname>Bordewich</keyname><forenames>M.</forenames></author><author><keyname>Freedman</keyname><forenames>M.</forenames></author><author><keyname>Lov&#xe1;sz</keyname><forenames>L.</forenames></author><author><keyname>Welsh</keyname><forenames>D.</forenames></author></authors><title>Approximate Counting and Quantum Computation</title><categories>cs.CC</categories><journal-ref>Combinatorics, Probability and Computing (2005) 14,737-754</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the result that an `approximate' evaluation of the Jones
polynomial of a braid at a $5^{th}$ root of unity can be used to simulate the
quantum part of any algorithm in the quantum complexity class BQP, and results
relating BQP to the counting class GapP, we introduce a form of additive
approximation which can be used to simulate a function in BQP. We show that all
functions in the classes #P and GapP have such an approximation scheme under
certain natural normalisations. However we are unable to determine whether the
particular functions we are motivated by, such as the above evaluation of the
Jones polynomial, can be approximated in this way. We close with some open
problems motivated by this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2128</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2128</id><created>2009-08-17</created><updated>2011-09-12</updated><authors><author><keyname>Cubitt</keyname><forenames>Toby S.</forenames></author><author><keyname>Eisert</keyname><forenames>Jens</forenames></author><author><keyname>Wolf</keyname><forenames>Michael M.</forenames></author></authors><title>The Complexity of Relating Quantum Channels to Master Equations</title><categories>math-ph cs.CC math.MP quant-ph</categories><comments>V1: 43 pages, single column, 8 figures. V2: titled changed; added
  proof-overview and accompanying figure; 50 pages, single column, 9 figures</comments><journal-ref>Commun. Math. Phys. 310, 383 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Completely positive, trace preserving (CPT) maps and Lindblad master
equations are both widely used to describe the dynamics of open quantum
systems. The connection between these two descriptions is a classic topic in
mathematical physics. One direction was solved by the now famous result due to
Lindblad, Kossakowski Gorini and Sudarshan, who gave a complete
characterisation of the master equations that generate completely positive
semi-groups. However, the other direction has remained open: given a CPT map,
is there a Lindblad master equation that generates it (and if so, can we find
it's form)? This is sometimes known as the Markovianity problem. Physically, it
is asking how one can deduce underlying physical processes from experimental
observations.
  We give a complexity theoretic answer to this problem: it is NP-hard. We also
give an explicit algorithm that reduces the problem to integer semi-definite
programming, a well-known NP problem. Together, these results imply that
resolving the question of which CPT maps can be generated by master equations
is tantamount to solving P=NP: any efficiently computable criterion for
Markovianity would imply P=NP; whereas a proof that P=NP would imply that our
algorithm already gives an efficiently computable criterion. Thus, unless P
does equal NP, there cannot exist any simple criterion for determining when a
CPT map has a master equation description.
  However, we also show that if the system dimension is fixed (relevant for
current quantum process tomography experiments), then our algorithm scales
efficiently in the required precision, allowing an underlying Lindblad master
equation to be determined efficiently from even a single snapshot in this case.
  Our work also leads to similar complexity-theoretic answers to a related
long-standing open problem in probability theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2141</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2141</id><created>2009-08-14</created><authors><author><keyname>Altug</keyname><forenames>Yucel</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>Source and Channel Simulation Using Arbitrary Randomness</title><categories>cs.IT math.IT</categories><comments>26 pages, 2 figures, submitted to IEEE Trans. on Information Theory.
  A shorter version will be presented at 2009 Allerton Conference on
  Communication, Control, and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Necessary and sufficient conditions for approximation of a general channel by
a general source are proved. For the special case in which the channel input is
deterministic, which corresponds to source simulation, we prove a stronger
necessary condition. As the approximation criteria, vanishing variational
distance between the original and the approximated quantity is used for both of
the problems. Both necessary and sufficient conditions for the two problems are
based on some individual properties of the sources and the channel and are
relatively easy to evaluate. In particular, unlike prior results for this
problem, our results do not require solving an optimization problem to test
simulatability. The results are illustrated with several non-ergodic examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2153</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2153</id><created>2009-08-14</created><authors><author><keyname>Hassanien</keyname><forenames>Aboulnasr</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>Phased-MIMO Radar: A Tradeoff Between Phased-Array and MIMO Radars</title><categories>cs.IT math.IT</categories><comments>33 pages, 14 figures, Submitted to the IEEE Transactions on Signal
  Processing in July 2009</comments><journal-ref>A. Hassanien and S.A. Vorobyov, &quot;Phased-MIMO radar: A tradeoff
  between phased-array and MIMO radars,&quot; IEEE Trans. Signal Processing, vol.
  58, no. 6, pp. 3137-3151, June 2010</journal-ref><doi>10.1109/TSP.2010.2043976</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new technique for multiple-input multiple-output (MIMO) radar
with colocated antennas which we call phased-MIMO radar. The new technique
enjoys the advantages of MIMO radar without sacrificing the main advantage of
phased-array radar which is the coherent processing gain at the transmitting
side. The essence of the proposed technique is to partition the transmitting
array into a number of subarrays that are allowed to overlap. Then, each
subarray is used to coherently transmit a waveform which is orthogonal to the
waveforms transmitted by other subarrays. Coherent processing gain can be
achieved by designing a weight vector for each subarray to form a beam towards
a certain direction in space. Moreover, the subarrays are combined jointly to
form a MIMO radar resulting in higher resolution capabilities. The substantial
improvements offered by the proposed phased-MIMO radar technique as compared to
previous techniques are demonstrated analytically and by simulations through
analysis of the corresponding beampatterns and achievable output
signal-to-noise-plus-interference ratios. Both analytical and simulation
results validate the effectiveness of the proposed phased-MIMO radar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2174</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2174</id><created>2009-08-15</created><authors><author><keyname>Choi</keyname><forenames>Suhan</forenames></author></authors><title>Distributed Source Coding with One Distortion Criterion and Correlated
  Messages</title><categories>cs.IT math.IT</categories><comments>20 pages, 7 figures, submitted to IEEE Trans. on Info. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, distributed (or multiterminal) source coding with one
distortion criterion and correlated messages is considered. This problem can be
also called ``Berger-Yeung problem with correlated messages''. It corresponds
to the source coding part of the graph-based framework for transmission of a
pair of correlated sources over the multiple-access channel (MAC) where one is
lossless and the other is lossy. As a result, the achievable rate-distortion
region for this problem is provided. It is an information-theoretic
characterization of the rate of exponential growth (as a function of the number
of source samples) of the size of the bipartite graphs which can represent a
pair of correlated sources with satisfying one distortion criterion. A rigorous
proof of the achievability and the converse part is given. It is also shown
that there exists functional duality between Berger-Yeung problem with
correlated messages and semi-deterministic broadcast channel with correlated
messages. This means that the optimal encoder-decoder mappings for one problem
become the optimal decoder-encoder mappings for the dual problem. In the
duality setup, the correlation structure of the messages in the two dual
problems, source distortion measure and channel cost measure are also
specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2198</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2198</id><created>2009-08-15</created><authors><author><keyname>Bras-Amor&#xf3;s</keyname><forenames>Maria</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael E.</forenames></author></authors><title>The Berlekamp-Massey Algorithm and the Euclidean Algorithm: a Closer
  Link</title><categories>cs.IT cs.DM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two primary decoding algorithms for Reed-Solomon codes are the
Berlekamp-Massey algorithm and the Sugiyama et al. adaptation of the Euclidean
algorithm, both designed to solve a key equation. In this article an
alternative version of the key equation and a new way to use the Euclidean
algorithm to solve it are presented, which yield the Berlekamp-Massey
algorithm. This results in a new, simpler, and compacter presentation of the
Berlekamp-Massey algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2203</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2203</id><created>2009-08-15</created><authors><author><keyname>Wilson</keyname><forenames>Makesh Pravin</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna</forenames></author></authors><title>Transmitting an analog Gaussian source over a Gaussian wiretap channel
  under SNR mismatch</title><categories>cs.IT math.IT</categories><comments>6 pages and 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study encoding/decoding schemes for the transmission of a
discrete time analog Gaussian source over a Gaussian wiretap channel. The
intended receiver is assumed to have a certain minimum signal to noise ratio
(SNR) and the eavesdropper is assumed to have a strictly lower SNR compared to
the intended receiver. For a fixed information leakage to the eavesdropper, we
are interested in minimizing the distortion in source reconstruction at the
intended receiver, and we propose joint source channel coding (JSCC) schemes
for this setup. For a fixed information leakage to the eavesdropper, we also
show that the schemes considered give a graceful degradation of distortion with
SNR under SNR mismatch, i.e., when the actual channel SNR is observed to be
different from the design SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2222</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2222</id><created>2009-08-16</created><authors><author><keyname>Krafft</keyname><forenames>Gerald</forenames></author><author><keyname>Getov</keyname><forenames>Vladimir</forenames></author></authors><title>Transaction-Oriented Simulation In Ad Hoc Grids: Design and Experience</title><categories>cs.DC</categories><comments>7 pages, 6 figures, 1 tables, Proceedings of the 2008 High
  Performance Computing and Simulation Conference (HPCS 2008), 3 - 6 June 2008,
  Nicosia, Cyprus. pp. 38-44; http://westminsterresearch.wmin.ac.uk/5341/</comments><acm-class>I.6.3; I.6.1; I.6.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyse the requirements of performing parallel
transaction-oriented simulations within loosely coupled systems like ad hoc
grids. We focus especially on the space-parallel approach to parallel
simulation and on discrete event synchronisation algorithms that are suitable
for transaction-oriented simulation and the target environment of ad hoc grids.
To demonstrate our findings, a Java-based parallel simulator for the
transaction-oriented language GPSS/H is implemented on the basis of the most
promising shock-resistant Time Warp (SRTW) synchronisation algorithm and using
the grid framework ProActive. The analysis of our parallel simulator, based on
experiments using the Grid5000 platform, shows that the SRTW algorithm can
successfully reduce the number of rolled back transaction moves but it also
reveals circumstances in which the SRTW algorithm can be outperformed by the
normal Time Warp algorithm. Finally, possible improvements to the SRTW
algorithm are proposed in order to avoid such problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2231</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2231</id><created>2009-08-16</created><updated>2009-10-20</updated><authors><author><keyname>Ali</keyname><forenames>Redouane</forenames></author><author><keyname>Lor</keyname><forenames>Suksant Sae</forenames></author><author><keyname>Rio</keyname><forenames>Miguel</forenames></author></authors><title>Two Algorithms for Network Size Estimation for Master/Slave Ad Hoc
  Networks</title><categories>cs.NI</categories><comments>3 pages, 2 figures, submitted to ANTS'09 - Corrected typos and
  definitions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an adaptation of two network size estimation methods:
random tour and gossip-based aggregation to suit master/slave mobile ad hoc
networks. We show that it is feasible to accurately estimate the size of ad hoc
networks when topology changes due to mobility using both methods. The
algorithms were modified to account for the specific constraints of
master/slave ad hoc networks and the results show that the proposed
modifications perform better on these networks than the original protocols.
Each of the two algorithms presents strengths and weaknesses and these are
outlined in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2237</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2237</id><created>2009-08-16</created><authors><author><keyname>Basavaraju</keyname><forenames>Manu</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author></authors><title>Acyclic Edge coloring of Planar Graphs</title><categories>cs.DM</categories><comments>10 pages. 0 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $acyclic$ edge coloring of a graph is a proper edge coloring such that
there are no bichromatic cycles. The \emph{acyclic chromatic index} of a graph
is the minimum number k such that there is an acyclic edge coloring using k
colors and is denoted by $a'(G)$. It was conjectured by Alon, Sudakov and Zaks
(and much earlier by Fiamcik) that $a'(G)\le \Delta+2$, where $\Delta
=\Delta(G)$ denotes the maximum degree of the graph. We prove that if $G$ is a
planar graph with maximum degree $\Delta$, then $a'(G)\le \Delta + 12$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2256</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2256</id><created>2009-08-16</created><updated>2010-03-14</updated><authors><author><keyname>Bansal</keyname><forenames>Nikhil</forenames></author><author><keyname>Korula</keyname><forenames>Nitish</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Srinivasan</keyname><forenames>Aravind</forenames></author></authors><title>On k-Column Sparse Packing Programs</title><categories>cs.DS</categories><comments>19 pages, v3: additional details</comments><acm-class>F.2.2</acm-class><doi>10.1007/978-3-642-13036-6_28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class of packing integer programs (PIPs) that are column
sparse, i.e. there is a specified upper bound k on the number of constraints
that each variable appears in. We give an (ek+o(k))-approximation algorithm for
k-column sparse PIPs, improving on recent results of $k^2\cdot 2^k$ and
$O(k^2)$. We also show that the integrality gap of our linear programming
relaxation is at least 2k-1; it is known that k-column sparse PIPs are
$\Omega(k/ \log k)$-hard to approximate. We also extend our result (at the loss
of a small constant factor) to the more general case of maximizing a submodular
objective over k-column sparse packing constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2277</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2277</id><created>2009-08-16</created><updated>2010-08-26</updated><authors><author><keyname>Santipach</keyname><forenames>Wiroonsak</forenames></author><author><keyname>Honig</keyname><forenames>Michael L.</forenames></author></authors><title>Optimization of Training and Feedback Overhead for Beamforming over
  Block Fading Channels</title><categories>cs.IT math.IT</categories><comments>accepted for IEEE Trans. Info. Theory, 2010</comments><journal-ref>IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 56, NO. 12, DECEMBER
  2010</journal-ref><doi>10.1109/TIT.2010.2081150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the capacity of beamforming over a single-user, multi-antenna link
taking into account the overhead due to channel estimation and limited feedback
of channel state information. Multi-input single-output (MISO) and multi-input
multi-output (MIMO) channels are considered subject to block Rayleigh fading.
Each coherence block contains $L$ symbols, and is spanned by $T$ training
symbols, $B$ feedback bits, and the data symbols. The training symbols are used
to obtain a Minimum Mean Squared Error estimate of the channel matrix. Given
this estimate, the receiver selects a transmit beamforming vector from a
codebook containing $2^B$ {\em i.i.d.} random vectors, and sends the
corresponding $B$ bits back to the transmitter. We derive bounds on the
beamforming capacity for MISO and MIMO channels and characterize the optimal
(rate-maximizing) training and feedback overhead ($T$ and $B$) as $L$ and the
number of transmit antennas $N_t$ both become large. The optimal $N_t$ is
limited by the coherence time, and increases as $L/\log L$. For the MISO
channel the optimal $T/L$ and $B/L$ (fractional overhead due to training and
feedback) are asymptotically the same, and tend to zero at the rate $1/\log
N_t$. For the MIMO channel the optimal feedback overhead $B/L$ tends to zero
faster (as $1/\log^2 N_t$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2282</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2282</id><created>2009-08-17</created><updated>2009-11-23</updated><authors><author><keyname>Motahari</keyname><forenames>Abolfazl Seyed</forenames></author><author><keyname>Gharan</keyname><forenames>Shahab Oveis</forenames></author><author><keyname>Maddah-Ali</keyname><forenames>Mohammad-Ali</forenames></author><author><keyname>Khandani</keyname><forenames>Amir Keyvan</forenames></author></authors><title>Real Interference Alignment: Exploiting the Potential of Single Antenna
  Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transaction on Information Theory. The first
  version was uploaded on arxiv on 17 Aug 2009 with the following title:
  Forming Pseudo-MIMO by Embedding Infinite Rational Dimensions Along a Single
  Real Line: Removing Barriers in Achieving the DOFs of Single Antenna Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the available spatial Degrees-Of-Freedoms (DOF) in single
antenna systems is exploited. A new coding scheme is proposed in which several
data streams having fractional multiplexing gains are sent by transmitters and
interfering streams are aligned at receivers. Viewed as a field over rational
numbers, a received signal has infinite fractional DOFs, allowing simultaneous
interference alignment of any finite number of signals at any finite number of
receivers. The coding scheme is backed up by a recent result in the field of
Diophantine approximation, which states that the convergence part of the
Khintchine-Groshev theorem holds for points on non-degenerate manifolds. The
proposed coding scheme is proved to be optimal for three communication
channels, namely the Gaussian Interference Channel (GIC), the uplink channel in
cellular systems, and the $X$ channel. It is proved that the total DOF of the
$K$-user GIC is $\frac{K}{2}$ almost surely, i.e. each user enjoys half of its
maximum DOF. Having $K$ cells and $M$ users within each cell in a cellular
system, the total DOF of the uplink channel is proved to be $\frac{KM}{M+1}$.
Finally, the total DOF of the $X$ channel with $K$ transmitters and $M$
receivers is shown to be $\frac{KM}{K+M-1}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2295</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2295</id><created>2009-08-17</created><authors><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author><author><keyname>Moses</keyname><forenames>Yoram</forenames></author></authors><title>An Optimal Self-Stabilizing Firing Squad</title><categories>cs.DC</categories><comments>Shorter version to appear in SSS09</comments><doi>10.1007/978-3-642-05118-0_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a fully connected network where up to $t$ processes may crash, and
all processes start in an arbitrary memory state. The self-stabilizing firing
squad problem consists of eventually guaranteeing simultaneous response to an
external input. This is modeled by requiring that the non-crashed processes
&quot;fire&quot; simultaneously if some correct process received an external &quot;GO&quot; input,
and that they only fire as a response to some process receiving such an input.
This paper presents FireAlg, the first self-stabilizing firing squad algorithm.
  The FireAlg algorithm is optimal in two respects: (a) Once the algorithm is
in a safe state, it fires in response to a GO input as fast as any other
algorithm does, and (b) Starting from an arbitrary state, it converges to a
safe state as fast as any other algorithm does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2328</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2328</id><created>2009-08-17</created><authors><author><keyname>Omar</keyname><forenames>Yara</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>ARQ Secrecy: From Theory to Practice</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, invited to ITW'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by our earlier work on Automatic Repeat reQuest (ARQ) secrecy, we
propose a simple, yet efficient, security overlay protocol to existing 802.11
networks. Our work targets networks secured by the Wired Equivalent Privacy
(WEP) protocol because of its widespread use and vulnerability to a multitude
of security threats. By exploiting the existing ARQ protocol in the 802.11
standard, our proposed opportunistic secrecy scheme is shown to defend against
all known passive WEP attacks. Moreover, our implementation on the madwifi-ng
driver is used to establish the achievability of a vanishing secrecy outage
probability in several realistic scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2332</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2332</id><created>2009-08-17</created><updated>2009-12-30</updated><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author><author><keyname>Solomon</keyname><forenames>Allan I.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Penson</keyname><forenames>Karol A.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Blasiak</keyname><forenames>Pawel</forenames><affiliation>IFJ-PAN - Polish Academy of Sciences</affiliation></author><author><keyname>Horzela</keyname><forenames>Andrzej</forenames><affiliation>IFJ-PAN - Polish Academy of Sciences</affiliation></author></authors><title>Ladder Operators and Endomorphisms in Combinatorial Physics</title><categories>math.CO cs.SC quant-ph</categories><proxy>ccsd hal-00410094</proxy><msc-class>05E99, 03.65.Fd</msc-class><journal-ref>DMTCS 12, 2 (2010) 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting with the Heisenberg-Weyl algebra, fundamental to quantum physics, we
first show how the ordering of the non-commuting operators intrinsic to that
algebra gives rise to generalizations of the classical Stirling Numbers of
Combinatorics. These may be expressed in terms of infinite, but {\em
row-finite}, matrices, which may also be considered as endomorphisms of
$\C[[x]]$. This leads us to consider endomorphisms in more general spaces, and
these in turn may be expressed in terms of generalizations of the
ladder-operators familiar in physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2363</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2363</id><created>2009-08-17</created><updated>2009-10-20</updated><authors><author><keyname>Ito</keyname><forenames>Tsuyoshi</forenames></author></authors><title>Polynomial-Space Approximation of No-Signaling Provers</title><categories>cs.CC quant-ph</categories><comments>13 pages. v2: Introduction expanded, references added, some open
  problems stated, and typos corrected</comments><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two-prover one-round interactive proof systems, no-signaling provers are
those who are allowed to use arbitrary strategies, not limited to local
operations, as long as their strategies cannot be used for communication
between them. Study of multi-prover interactive proof systems with no-signaling
provers is motivated by study of those with provers sharing quantum states. The
relation between them is that no-signaling strategies include all the
strategies realizable by provers sharing arbitrary entangled quantum states,
and more.
  This paper shows that two-prover one-round interactive proof systems with
no-signaling provers only accept languages in PSPACE. Combined with the
protocol for PSPACE by Ito, Kobayashi and Matsumoto (CCC 2009), this implies
MIPns(2,1)=PSPACE, where MIPns(2,1) is the class of languages having a
two-prover one-round interactive proof system with no-signaling provers. This
is proved by constructing a fast parallel algorithm which approximates within
an additive error the maximum value of a two-player one-round game achievable
by cooperative no-signaling players. The algorithm uses the fast parallel
algorithm for the mixed packing and covering problem by Young (FOCS 2001).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2369</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2369</id><created>2009-08-17</created><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>Being Fat and Friendly is Not Enough</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there is no $(1+\eps)$-approximation algorithm for the problem
of covering points in the plane by minimum number of fat triangles of similar
size (with the minimum angle of the triangles being close to 45 degrees). Here,
the available triangles are prespecified in advance. Since a constant factor
approximation algorithm is known for this problem \cite{cv-iaags-07}, this
settles the approximability of this problem.
  We also investigate some related problems, including cover by friendly fat
shapes, and independent set of triangles in three dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2397</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2397</id><created>2009-08-17</created><authors><author><keyname>Tang</keyname><forenames>Xiaojun</forenames></author><author><keyname>Liu</keyname><forenames>Ruoheng</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Interference Assisted Secret Communication</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><report-no>WINLAB-09-0817</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless communication is susceptible to eavesdropping attacks because of its
broadcast nature. This paper illustrates how interference can be used to
counter eavesdropping and assist secrecy. In particular, a wire-tap channel
with a helping interferer (WT-HI) is considered. Here, a transmitter sends a
confidential message to its intended receiver in the presence of a passive
eavesdropper and with the help of an independent interferer. The interferer,
which does not know the confidential message, helps in ensuring the secrecy of
the message by sending an independent signal. An achievable secrecy rate and
several computable outer bounds on the secrecy capacity of the WT-HI are given
for both discrete memoryless and Gaussian channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2399</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2399</id><created>2009-08-17</created><updated>2011-08-17</updated><authors><author><keyname>Witzel</keyname><forenames>Andreas</forenames></author><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Zvesper</keyname><forenames>Jonathan A.</forenames></author></authors><title>Distributed iterated elimination of strictly dominated strategies</title><categories>cs.GT cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize epistemic consequences of truthful communication among
rational agents in a game-theoretic setting. To this end we introduce
normal-form games equipped with an interaction structure, which specifies which
groups of players can communicate their preferences with each other. We then
focus on a specific form of interaction, namely a distributed form of iterated
elimination of strictly dominated strategies (IESDS), driven by communication
among the agents. We study the outcome of IESDS after some (possibly all)
messages about players' preferences have been sent. The main result of the
paper provides an epistemic justification of this form of IESDS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2402</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2402</id><created>2009-08-17</created><authors><author><keyname>Sedighizad</keyname><forenames>Mahboobeh</forenames></author><author><keyname>Seyfe</keyname><forenames>Babak</forenames></author><author><keyname>Navaie</keyname><forenames>Keivan</forenames></author></authors><title>MR-BART: Multi-Rate Available Bandwidth Estimation in Real-Time</title><categories>cs.NI</categories><comments>12 Pages (Two columns), 14 Figures, 4 Tables,</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose Multi-Rate Bandwidth Available in Real Time
(MR-BART) to estimate the end-to-end Available Bandwidth (AB) of a network
path. The proposed scheme is an extension of the Bandwidth Available in Real
Time (BART) which employs multi-rate (MR) probe packet sequences with Kalman
filtering. Comparing to BART, we show that the proposed method is more robust
and converges faster than that of BART and achieves a more AB accurate
estimation. Furthermore, we analyze the estimation error in MR-BART and obtain
analytical formula and empirical expression for the AB estimation error based
on the system parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2408</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2408</id><created>2009-08-17</created><authors><author><keyname>Wilson</keyname><forenames>Makesh Pravin</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna</forenames></author></authors><title>Power Allocation Strategies and Lattice Based Coding schemes for
  Bi-directional relaying</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures and was presented at the International Symposium
  on Information Theory - ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a communication system where two transmitters wish to exchange
information through a half-duplex relay in the middle. The channels between the
transmitters and the relay have asymmetric channel gains. More specifically,
the channels are assumed to be synchronized with complex inputs and complex
fading coefficients with an average power constraint on the inputs to the
channels. The noise at the receivers have the same power spectral density and
are assumed to be white and Gaussian. We restrict our attention to transmission
schemes where information from the two nodes are simultaneously sent to the
relay during a medium access phase followed by a broadcast phase where the
relay broadcasts information to both the nodes. An upper bound on the capacity
for the two phase protocol under a sum power constraint on the transmit power
from all the nodes is obtained as a solution to a convex optimization problem.
We show that a scheme using channel inversion with lattice decoding can obtain
a rate a small constant 0.09 bits from the upper bound at high signal-to-noise
ratios. Numerical results show that the proposed scheme can perform very close
to the upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2440</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2440</id><created>2009-08-17</created><authors><author><keyname>Aloupis</keyname><forenames>Greg</forenames></author><author><keyname>Collette</keyname><forenames>Sebastien</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Sacristan</keyname><forenames>Vera</forenames></author><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author></authors><title>Reconfiguration of 3D Crystalline Robots Using O(log n) Parallel Moves</title><categories>cs.CG cs.RO</categories><comments>21 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the theoretical model of Crystalline robots, which have been
introduced and prototyped by the robotics community. These robots consist of
independently manipulable unit-square atoms that can extend/contract arms on
each side and attach/detach from neighbors. These operations suffice to
reconfigure between any two given (connected) shapes. The worst-case number of
sequential moves required to transform one connected configuration to another
is known to be Theta(n). However, in principle, atoms can all move
simultaneously. We develop a parallel algorithm for reconfiguration that runs
in only O(log n) parallel steps, although the total number of operations
increases slightly to Theta(nlogn). The result is the first (theoretically)
almost-instantaneous universally reconfigurable robot built from simple units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2442</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2442</id><created>2009-08-17</created><authors><author><keyname>Aloupis</keyname><forenames>Greg</forenames></author><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Collette</keyname><forenames>Sebastien</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author></authors><title>Detecting all regular polygons in a point set</title><categories>cs.CG</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the time complexity of finding regular polygons in
a set of n points. We combine two different approaches to find regular
polygons, depending on their number of edges. Our result depends on the
parameter alpha, which has been used to bound the maximum number of isosceles
triangles that can be formed by n points. This bound has been expressed as
O(n^{2+2alpha+epsilon}), and the current best value for alpha is ~0.068.
  Our algorithm finds polygons with O(n^alpha) edges by sweeping a line through
the set of points, while larger polygons are found by random sampling. We can
find all regular polygons with high probability in O(n^{2+alpha+epsilon})
expected time for every positive epsilon. This compares well to the
O(n^{2+2alpha+epsilon}) deterministic algorithm of Brass.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2462</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2462</id><created>2009-08-17</created><authors><author><keyname>Yoon</keyname><forenames>Ji Won</forenames></author><author><keyname>Kim</keyname><forenames>Hyoungshick</forenames></author><author><keyname>Huh</keyname><forenames>Jun Ho</forenames></author></authors><title>Hybrid Spam Filtering for Mobile Communication</title><categories>cs.CR cs.NI</categories><comments>6 pages, 5 figures, 1 table</comments><acm-class>H.4; D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam messages are an increasing threat to mobile communication. Several
mitigation techniques have been proposed, including white and black listing,
challenge-response and content-based filtering. However, none are perfect and
it makes sense to use a combination rather than just one. We propose an
anti-spam framework based on the hybrid of content-based filtering and
challenge-response. There is the trade-offs between accuracy of anti-spam
classifiers and the communication overhead. Experimental results show how,
depending on the proportion of spam messages, different filtering %%@
parameters should be set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2467</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2467</id><created>2009-08-17</created><updated>2009-09-30</updated><authors><author><keyname>Koo</keyname><forenames>Joseph C.</forenames></author><author><keyname>Gill</keyname><forenames>John</forenames></author></authors><title>Low-complexity non-uniform demand multicast network coding problems</title><categories>cs.IT math.IT</categories><comments>8 pages, 3 figures, presented at 47th Allerton Conference on
  Communication Control and Computing, 2009. Includes more complete proof of
  Theorem 3</comments><doi>10.1109/ALLERTON.2009.5394805</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The non-uniform demand network coding problem is posed as a single-source and
multiple-sink network transmission problem where the sinks may have
heterogeneous demands. In contrast with multicast problems, non-uniform demand
problems are concerned with the amounts of data received by each sink, rather
than the specifics of the received data. In this work, we enumerate non-uniform
network demand scenarios under which network coding solutions can be found in
polynomial time. This is accomplished by relating the demand problem with the
graph coloring problem, and then applying results from the strong perfect graph
theorem to identify coloring problems which can be solved in polynomial time.
This characterization of efficiently-solvable non-uniform demand problems is an
important step in understanding such problems, as it allows us to better
understand situations under which the NP-complete problem might be tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2468</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2468</id><created>2009-08-17</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Iwama</keyname><forenames>Kazuo</forenames></author><author><keyname>Nakanishi</keyname><forenames>Masaki</forenames></author><author><keyname>Nishimura</keyname><forenames>Harumichi</forenames></author><author><keyname>Raymond</keyname><forenames>Rudy</forenames></author><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author><author><keyname>Yamashita</keyname><forenames>Shigeru</forenames></author></authors><title>Average/Worst-Case Gap of Quantum Query Complexities by On-Set Size</title><categories>quant-ph cs.CC</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the query complexity of the functions in the family
F_{N,M} of N-variable Boolean functions with onset size M, i.e., the number of
inputs for which the function value is 1, where 1&lt;= M &lt;= 2^{N}/2 is assumed
without loss of generality because of the symmetry of function values, 0 and 1.
Our main results are as follows: (1) There is a super-linear gap between the
average-case and worst-case quantum query complexities over F_{N,M} for a
certain range of M. (2) There is no super-linear gap between the average-case
and worst-case randomized query complexities over F_{N,M} for every M. (3) For
every M bounded by a polynomial in N, any function in F_{N,M} has quantum query
complexity Theta (sqrt{N}). (4) For every M=O(2^{cN}) with an arbitrary large
constant c&lt;1, any function in F_{N,M} has randomized query complexity Omega
(N).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2476</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2476</id><created>2009-08-17</created><authors><author><keyname>Yao</keyname><forenames>Andrew C.</forenames></author><author><keyname>Yung</keyname><forenames>Moti</forenames></author><author><keyname>Zhao</keyname><forenames>Yunlei</forenames></author></authors><title>Concurrent Knowledge-Extraction in the Public-Key Model</title><categories>cs.CC</categories><comments>38 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge extraction is a fundamental notion, modelling machine possession of
values (witnesses) in a computational complexity sense. The notion provides an
essential tool for cryptographic protocol design and analysis, enabling one to
argue about the internal state of protocol players without ever looking at this
supposedly secret state. However, when transactions are concurrent (e.g., over
the Internet) with players possessing public-keys (as is common in
cryptography), assuring that entities ``know'' what they claim to know, where
adversaries may be well coordinated across different transactions, turns out to
be much more subtle and in need of re-examination. Here, we investigate how to
formally treat knowledge possession by parties (with registered public-keys)
interacting over the Internet. Stated more technically, we look into the
relative power of the notion of ``concurrent knowledge-extraction'' (CKE) in
the concurrent zero-knowledge (CZK) bare public-key (BPK) model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2493</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2493</id><created>2009-08-18</created><authors><author><keyname>Aloupis</keyname><forenames>Greg</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author></authors><title>Minimum feature size preserving decompositions</title><categories>cs.CG</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum feature size of a crossing-free straight line drawing is the
minimum distance between a vertex and a non-incident edge. This quantity
measures the resolution needed to display a figure or the tool size needed to
mill the figure. The spread is the ratio of the diameter to the minimum feature
size. While many algorithms (particularly in meshing) depend on the spread of
the input, none explicitly consider finding a mesh whose spread is similar to
the input. When a polygon is partitioned into smaller regions, such as
triangles or quadrangles, the degradation is the ratio of original to final
spread (the final spread is always greater).
  Here we present an algorithm to quadrangulate a simple n-gon, while achieving
constant degradation. Note that although all faces have a quadrangular shape,
the number of edges bounding each face may be larger. This method uses Theta(n)
Steiner points and produces Theta(n) quadrangles. In fact to obtain constant
degradation, Omega(n) Steiner points are required by any algorithm.
  We also show that, for some polygons, a constant factor cannot be achieved by
any triangulation, even with an unbounded number of Steiner points. The
specific lower bounds depend on whether Steiner vertices are used or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2494</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2494</id><created>2009-08-18</created><authors><author><keyname>Aditya</keyname><forenames>S. T.</forenames></author><author><keyname>Dabeer</keyname><forenames>Onkar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author></authors><title>A Channel Coding Perspective of Collaborative Filtering</title><categories>cs.IT math.IT</categories><comments>32 pages, 1 figure, Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of collaborative filtering from a channel coding
perspective. We model the underlying rating matrix as a finite alphabet matrix
with block constant structure. The observations are obtained from this
underlying matrix through a discrete memoryless channel with a noisy part
representing noisy user behavior and an erasure part representing missing data.
Moreover, the clusters over which the underlying matrix is constant are {\it
unknown}. We establish a sharp threshold result for this model: if the largest
cluster size is smaller than $C_1 \log(mn)$ (where the rating matrix is of size
$m \times n$), then the underlying matrix cannot be recovered with any
estimator, but if the smallest cluster size is larger than $C_2 \log(mn)$, then
we show a polynomial time estimator with diminishing probability of error. In
the case of uniform cluster size, not only the order of the threshold, but also
the constant is identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2496</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2496</id><created>2009-08-18</created><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Lo</keyname><forenames>Kowk-Tung</forenames></author><author><keyname>Kyamakya</keyname><forenames>Kyandoghere</forenames></author></authors><title>A Differential Cryptanalysis of Yen-Chen-Wu Multimedia Cryptography
  System (MCS)</title><categories>cs.CR</categories><comments>22 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At ISCAS'2005, Yen et al. presented a new chaos-based cryptosystem for
multimedia transmission named &quot;Multimedia Cryptography System&quot; (MCS). No
cryptanalytic results have been reported so far. This paper presents a
differential attack to break MCS, which requires only seven chosen plaintexts.
The complexity of the attack is O(N), where $N$ is the size of plaintext.
Experimental results are also given to show the real performance of the
proposed attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2505</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2505</id><created>2009-08-18</created><authors><author><keyname>Lahtonen</keyname><forenames>Jyrki</forenames></author><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author><author><keyname>Lu</keyname><forenames>Hsiao-feng</forenames></author><author><keyname>Hollanti</keyname><forenames>Camilla</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author></authors><title>On the Decay of the Determinants of Multiuser MIMO Lattice Codes</title><categories>cs.IT cs.DM math.IT math.RA</categories><comments>5 pages, submitted to ITW 2010, Cairo, Egypt</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent work, Coronel et al. initiated the study of the relation between
the diversity-multiplexing tradeoff (DMT) performance of a multiuser
multiple-input multiple-output (MU-MIMO) lattice code and the rate of the decay
of the determinants of the code matrix as a function of the size of the signal
constellation. In this note, we state a simple general upper bound on the decay
function and study the promising code proposed by Badr and Belfiore in close
detail. We derive a lower bound to its decay function based on a classical
theorem due to Liouville. The resulting bound is applicable also to other codes
with constructions based on algebraic number theory. Further, we study an
example sequence of small determinants within the Badr-Belfiore code and derive
a tighter upper bound to its decay function. The upper bound has certain
conjectural asymptotic uncertainties, whence we also list the exact bound for
several finite data rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2506</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2506</id><created>2009-08-18</created><authors><author><keyname>Diertens</keyname><forenames>B.</forenames></author></authors><title>Software Engineering with Process Algebra: Modelling Client / Server
  Architectures</title><categories>cs.SE</categories><report-no>PRG0908</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work we described how the process algebra based language PSF can
be used in software engineering, using the ToolBus, a coordination architecture
also based on process algebra, as implementation model. We also described this
software development process more formally by presenting the tools we use in
this process in a CASE setting, leading to the PSF-ToolBus software engineering
environment. In this article we summarize that work and describe a similar
software development process for implementation of software systems using a
client / server model and present this in a CASE setting as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2509</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2509</id><created>2009-08-18</created><authors><author><keyname>Saha</keyname><forenames>Mounita</forenames></author><author><keyname>Chowdhury</keyname><forenames>Dipanwita Roy</forenames></author></authors><title>A Secure and Efficient Protocol for Group Key agreement in Heterogeneous
  Environment</title><categories>cs.CR</categories><comments>9 pages, 3 figures, Conference paper in Secrypt 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure group communication in heterogeneous environment is gaining popularity
due to the advent of wireless and ubiquitous computing. Although a number of
protocols for group key agreement have been proposed, most of them are not
applicable in heterogeneous environment where a number of computationally
limited nodes coexist with one or more computationally efficient nodes. Among
the few existing protocols, where some fail to satisfy the key agreement
properties, some are unable to handle the agreement for dynamic group. In this
work, we propose a constant round group key agreement protocol for
heterogeneous environment using polynomial interpolation. The protocol ensures
both communication and computation efficiency by shifting the major computation
load on powerful users, achieves true contributory key agreement property and
dynamic handling of user join and leave. The security of the protocol has been
analyzed under formal model. The comparison result shows considerable
improvement in protocol efficiency compared to the existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2529</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2529</id><created>2009-08-18</created><authors><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Wu</keyname><forenames>Tianyu</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>A Low-Overhead Energy Detection Based Cooperative Sensing Protocol for
  Cognitive Radio Systems</title><categories>cs.IT math.IT</categories><comments>11 pages, 8 figures, journal. To appear in IEEE Transactions on
  Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio and dynamic spectrum access represent a new paradigm shift in
more effective use of limited radio spectrum. One core component behind dynamic
spectrum access is the sensing of primary user activity in the shared spectrum.
Conventional distributed sensing and centralized decision framework involving
multiple sensor nodes is proposed to enhance the sensing performance. However,
it is difficult to apply the conventional schemes in reality since the overhead
in sensing measurement and sensing reporting as well as in sensing report
combining limit the number of sensor nodes that can participate in distributive
sensing. In this paper, we shall propose a novel, low overhead and low
complexity energy detection based cooperative sensing framework for the
cognitive radio systems which addresses the above two issues. The energy
detection based cooperative sensing scheme greatly reduces the quiet period
overhead (for sensing measurement) as well as sensing reporting overhead of the
secondary systems and the power scheduling algorithm dynamically allocate the
transmission power of the cooperative sensor nodes based on the channel
statistics of the links to the BS as well as the quality of the sensing
measurement. In order to obtain design insights, we also derive the asymptotic
sensing performance of the proposed cooperative sensing framework based on the
mobility model. We show that the false alarm and mis-detection performance of
the proposed cooperative sensing framework improve as we increase the number of
cooperative sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2542</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2542</id><created>2009-08-18</created><authors><author><keyname>Giovanidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Stanczak</keyname><forenames>Slawomir</forenames></author></authors><title>Stability and Distributed Power Control in MANETs with Outages and
  Retransmissions</title><categories>cs.NI cs.GT</categories><comments>25 pages, 6 figures, 1 table, submitted to the IEEE Trans. on
  Communications</comments><journal-ref>IEEE Transactions on Communications (Volume:59 , Issue: 6 ), pp.
  1632 - 1643, June 2011</journal-ref><doi>10.1109/TCOMM.2011.042111.090486</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current work the effects of hop-by-hop packet loss and retransmissions
via ARQ protocols are investigated within a Mobile Ad-hoc NET-work (MANET).
Errors occur due to outages and a success probability function is related to
each link, which can be controlled by power and rate allocation. We first
derive the expression for the network's capacity region, where the success
function plays a critical role. Properties of the latter as well as the related
maximum goodput function are presented and proved. A Network Utility
Maximization problem (NUM) with stability constraints is further formulated
which decomposes into (a) the input rate control problem and (b) the scheduling
problem. Under certain assumptions problem (b) is relaxed to a weighted sum
maximization problem with number of summants equal to the number of nodes. This
further allows the formulation of a non-cooperative game where each node
decides independently over its transmitting power through a chosen link. Use of
supermodular game theory suggests a price based algorithm that converges to a
power allocation satisfying the necessary optimality conditions of (b).
Implementation issues are considered so that minimum information exchange
between interfering nodes is required. Simulations illustrate that the
suggested algorithm brings near optimal results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2578</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2578</id><created>2009-08-18</created><authors><author><keyname>Bisu</keyname><forenames>Claudiu-Florinel</forenames><affiliation>MPS</affiliation></author><author><keyname>K'Nevez</keyname><forenames>Jean-Yves</forenames><affiliation>LMP</affiliation></author><author><keyname>Darnis</keyname><forenames>Philippe</forenames><affiliation>LGM2B</affiliation></author><author><keyname>Laheurte</keyname><forenames>Raynald</forenames><affiliation>LMP</affiliation></author><author><keyname>G&#xe9;rard</keyname><forenames>Alain</forenames><affiliation>LMP</affiliation></author></authors><title>New method to characterize a machining system: application in turning</title><categories>cs.CE</categories><proxy>ccsd hal-00408731</proxy><journal-ref>Int. J. of Mat. Form. 2, 2 (2009) 93-105</journal-ref><doi>10.1007/s12289-009-0395-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many studies simulates the machining process by using a single degree of
freedom spring-mass sytem to model the tool stiffness, or the workpiece
stiffness, or the unit tool-workpiece stiffness in modelings 2D. Others impose
the tool action, or use more or less complex modelings of the efforts applied
by the tool taking account the tool geometry. Thus, all these models remain
two-dimensional or sometimes partially three-dimensional. This paper aims at
developing an experimental method allowing to determine accurately the real
three-dimensional behaviour of a machining system (machine tool, cutting tool,
tool-holder and associated system of force metrology six-component
dynamometer). In the work-space model of machining, a new experimental
procedure is implemented to determine the machining system elastic behaviour.
An experimental study of machining system is presented. We propose a machining
system static characterization. A decomposition in two distinct blocks of the
system &quot;Workpiece-Tool-Machine&quot; is realized. The block Tool and the block
Workpiece are studied and characterized separately by matrix stiffness and
displacement (three translations and three rotations). The Castigliano's theory
allows us to calculate the total stiffness matrix and the total displacement
matrix. A stiffness center point and a plan of tool tip static displacement are
presented in agreement with the turning machining dynamic model and especially
during the self induced vibration. These results are necessary to have a good
three-dimensional machining system dynamic characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2588</identifier>
 <datestamp>2009-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2588</id><created>2009-08-18</created><authors><author><keyname>Rafiei</keyname><forenames>Davood</forenames></author><author><keyname>Li</keyname><forenames>Haobin</forenames></author></authors><title>Wild Card Queries for Searching Resources on the Web</title><categories>cs.DB cs.IR</categories><comments>11 pages</comments><acm-class>H.3.3; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a domain-independent framework for searching and retrieving facts
and relationships within natural language text sources. In this framework, an
extraction task over a text collection is expressed as a query that combines
text fragments with wild cards, and the query result is a set of facts in the
form of unary, binary and general $n$-ary tuples. A significance of our
querying mechanism is that, despite being both simple and declarative, it can
be applied to a wide range of extraction tasks. A problem in querying natural
language text though is that a user-specified query may not retrieve enough
exact matches. Unlike term queries which can be relaxed by removing some of the
terms (as is done in search engines), removing terms from a wild card query
without ruining its meaning is more challenging. Also, any query expansion has
the potential to introduce false positives. In this paper, we address the
problem of query expansion, and also analyze a few ranking alternatives to
score the results and to remove false positives. We conduct experiments and
report an evaluation of the effectiveness of our querying and scoring
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2615</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2615</id><created>2009-08-18</created><authors><author><keyname>Wu</keyname><forenames>Zhi-Xi</forenames></author><author><keyname>Holme</keyname><forenames>Petter</forenames></author></authors><title>Modeling scientific-citation patterns and other triangle-rich acyclic
  networks</title><categories>physics.soc-ph cs.DL</categories><comments>4 pages, 4 figures</comments><journal-ref>Phys.Rev.E 80, 037101 (2009).</journal-ref><doi>10.1103/PhysRevE.80.037101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model of the evolution of the networks of scientific citations.
The model takes an out-degree distribution (distribution of number of
citations) and two parameters as input. The parameters capture the two main
ingredients of the model, the aging of the relevance of papers and the
formation of triangles when new papers cite old. We compare our model with
three network structural quantities of an empirical citation network. We find
that an unique point in parameter space optimizing the match between the real
and model data for all quantities. The optimal parameter values suggest that
the impact of scientific papers, at least in the empirical data set we model is
proportional to the inverse of the number of papers since they were published.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2644</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2644</id><created>2009-08-18</created><authors><author><keyname>Weinstein</keyname><forenames>Marvin</forenames></author><author><keyname>Horn</keyname><forenames>David</forenames></author></authors><title>Dynamic quantum clustering: a method for visual exploration of
  structures in data</title><categories>physics.data-an cs.DS hep-ex physics.comp-ph stat.ML</categories><comments>15 pages, 9 figures</comments><report-no>SLAC-PUB-13759</report-no><journal-ref>Phys.Rev.E80:066117,2009</journal-ref><doi>10.1103/PhysRevE.80.066117</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A given set of data-points in some feature space may be associated with a
Schrodinger equation whose potential is determined by the data. This is known
to lead to good clustering solutions. Here we extend this approach into a
full-fledged dynamical scheme using a time-dependent Schrodinger equation.
Moreover, we approximate this Hamiltonian formalism by a truncated calculation
within a set of Gaussian wave functions (coherent states) centered around the
original points. This allows for analytic evaluation of the time evolution of
all such states, opening up the possibility of exploration of relationships
among data-points through observation of varying dynamical-distances among
points and convergence of points into clusters. This formalism may be further
supplemented by preprocessing, such as dimensional reduction through singular
value decomposition or feature filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2656</identifier>
 <datestamp>2009-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2656</id><created>2009-08-18</created><authors><author><keyname>Helmer</keyname><forenames>Scott</forenames></author><author><keyname>Meger</keyname><forenames>David</forenames></author><author><keyname>Viswanathan</keyname><forenames>Pooja</forenames></author><author><keyname>McCann</keyname><forenames>Sancho</forenames></author><author><keyname>Dockrey</keyname><forenames>Matthew</forenames></author><author><keyname>Fazli</keyname><forenames>Pooyan</forenames></author><author><keyname>Southey</keyname><forenames>Tristram</forenames></author><author><keyname>Muja</keyname><forenames>Marius</forenames></author><author><keyname>Joya</keyname><forenames>Michael</forenames></author><author><keyname>Little</keyname><forenames>Jim</forenames></author><author><keyname>Lowe</keyname><forenames>David</forenames></author><author><keyname>Mackworth</keyname><forenames>Alan</forenames></author></authors><title>Semantic Robot Vision Challenge: Current State and Future Directions</title><categories>cs.CV cs.RO</categories><comments>The IJCAI-09 Workshop on Competitions in Artificial Intelligence and
  Robotics, Pasadena, California, USA, July 11-17, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Semantic Robot Vision Competition provided an excellent opportunity for
our research lab to integrate our many ideas under one umbrella, inspiring both
collaboration and new research. The task, visual search for an unknown object,
is relevant to both the vision and robotics communities. Moreover, since the
interplay of robotics and vision is sometimes ignored, the competition provides
a venue to integrate two communities. In this paper, we outline a number of
modifications to the competition to both improve the state-of-the-art and
increase participation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2661</identifier>
 <datestamp>2009-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2661</id><created>2009-08-18</created><authors><author><keyname>Fazli</keyname><forenames>Pooyan</forenames></author><author><keyname>Mackworth</keyname><forenames>Alan K.</forenames></author></authors><title>Human-Robot Teams in Entertainment and Other Everyday Scenarios</title><categories>cs.MA cs.CY cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new and relatively unexplored research direction in robotics systems is the
coordination of humans and robots working as a team. In this paper, we focus
upon problem domains and tasks in which multiple robots, humans and other
agents are cooperating through coordination to satisfy a set of goals or to
maximize utility. We are primarily interested in applications of human robot
coordination in entertainment and other activities of daily life. We discuss
the teamwork problem and propose an architecture to address this.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2676</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2676</id><created>2009-08-19</created><updated>2010-10-02</updated><authors><author><keyname>Amini</keyname><forenames>Arash</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Deterministic Construction of Binary, Bipolar and Ternary Compressed
  Sensing Matrices</title><categories>cs.IT math.IT</categories><comments>The paper is accepted for publication in IEEE Transaction on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we establish the connection between the Orthogonal Optical
Codes (OOC) and binary compressed sensing matrices. We also introduce
deterministic bipolar $m\times n$ RIP fulfilling $\pm 1$ matrices of order $k$
such that $m\leq\mathcal{O}\big(k (\log_2 n)^{\frac{\log_2 k}{\ln \log_2
k}}\big)$. The columns of these matrices are binary BCH code vectors where the
zeros are replaced by -1. Since the RIP is established by means of coherence,
the simple greedy algorithms such as Matching Pursuit are able to recover the
sparse solution from the noiseless samples. Due to the cyclic property of the
BCH codes, we show that the FFT algorithm can be employed in the reconstruction
methods to considerably reduce the computational complexity. In addition, we
combine the binary and bipolar matrices to form ternary sensing matrices
($\{0,1,-1\}$ elements) that satisfy the RIP condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2681</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2681</id><created>2009-08-19</created><authors><author><keyname>Saichev</keyname><forenames>A.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Effects of Diversity and Procrastination in Priority Queuing Theory: the
  Different Power Law Regimes</title><categories>physics.soc-ph cs.PF physics.data-an</categories><comments>32 pages, 10 figures</comments><journal-ref>Physical Review E 81, 016108 (2009)</journal-ref><doi>10.1103/PhysRevE.81.016108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical analysis show that, after the update of a browser, the publication
of the vulnerability of a software, or the discovery of a cyber worm, the
fraction of computers still using the older version, or being not yet patched,
or exhibiting worm activity decays as power laws $\sim 1/t^{\alpha}$ with $0 &lt;
\alpha \leq 1$ over time scales of years. We present a simple model for this
persistence phenomenon framed within the standard priority queuing theory, of a
target task which has the lowest priority compared with all other tasks that
flow on the computer of an individual. We identify a &quot;time deficit&quot; control
parameter $\beta$ and a bifurcation to a regime where there is a non-zero
probability for the target task to never be completed. The distribution of
waiting time ${\cal T}$ till the completion of the target task has the power
law tail $\sim 1/t^{1/2}$, resulting from a first-passage solution of an
equivalent Wiener process. Taking into account a diversity of time deficit
parameters in a population of individuals, the power law tail is changed into
$1/t^\alpha$ with $\alpha\in(0.5,\infty)$, including the well-known case $1/t$.
We also study the effect of &quot;procrastination&quot;, defined as the situation in
which the target task may be postponed or delayed even after the individual has
solved all other pending tasks. This new regime provides an explanation for
even slower apparent decay and longer persistence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2707</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2707</id><created>2009-08-19</created><updated>2010-02-03</updated><authors><author><keyname>Hirsch</keyname><forenames>Edward A.</forenames></author><author><keyname>Itsykson</keyname><forenames>Dmitry</forenames></author></authors><title>On optimal heuristic randomized semidecision procedures, with
  application to proof complexity</title><categories>cs.CC cs.LO</categories><comments>11 pages, accepted to STACS 2010</comments><acm-class>F.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The existence of a (p-)optimal propositional proof system is a major open
question in (proof) complexity; many people conjecture that such systems do not
exist. Krajicek and Pudlak (1989) show that this question is equivalent to the
existence of an algorithm that is optimal on all propositional tautologies.
Monroe (2009) recently gave a conjecture implying that such algorithm does not
exist.
  We show that in the presence of errors such optimal algorithms do exist. The
concept is motivated by the notion of heuristic algorithms. Namely, we allow
the algorithm to claim a small number of false &quot;theorems&quot; (according to any
samplable distribution on non-tautologies) and err with bounded probability on
other inputs.
  Our result can also be viewed as the existence of an optimal proof system in
a class of proof systems obtained by generalizing automatizable proof systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2721</identifier>
 <datestamp>2009-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2721</id><created>2009-08-19</created><updated>2009-10-23</updated><authors><author><keyname>Carofiglio</keyname><forenames>Giovanna</forenames></author><author><keyname>Muscariello</keyname><forenames>Luca</forenames></author></authors><title>On the impact of TCP and per-flow scheduling on Internet performance
  (extended version)</title><categories>cs.NI</categories><comments>26 pages, 5 figures, shorter version submitted to INFOCOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet performance is tightly related to the properties of TCP and UDP
protocols, jointly responsible for the delivery of the great majority of
Internet traffic. It is well understood how these protocols behave under FIFO
queuing and what the network congestion effects. However, no comprehensive
analysis is available when flow-aware mechanisms such as per-flow scheduling
and dropping policies are deployed. Previous simulation and experimental
results leave a number of unanswered questions. In the paper, we tackle this
issue by modeling via a set of fluid non-linear ODEs the instantaneous
throughput and the buffer occupancy of N long-lived TCP sources under three
per-flow scheduling disciplines (Fair Queuing, Longest Queue First, Shortest
Queue First) and with longest queue drop buffer management. We study the system
evolution and analytically characterize the stationary regime: closed-form
expressions are derived for the stationary throughput/sending rate and buffer
occupancy which give thorough understanding of short/long-term fairness for TCP
traffic. Similarly, we provide the characterization of the loss rate
experienced by UDP flows in presence of TCP traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2741</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2741</id><created>2009-08-19</created><updated>2012-04-30</updated><authors><author><keyname>Blattner</keyname><forenames>Marcel</forenames></author></authors><title>B-Rank: A top N Recommendation Algorithm</title><categories>physics.data-an cs.IR</categories><comments>6 pages, 1 figure</comments><msc-class>68U35</msc-class><acm-class>H.4.2</acm-class><journal-ref>Proceedings of International Multi-Conference on Complexity,
  Informatics and Cybernetics, 2010, Volume 1, pp. 336-341</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper B-Rank, an efficient ranking algorithm for recommender systems,
is proposed. B-Rank is based on a random walk model on hypergraphs. Depending
on the setup, B-Rank outperforms other state of the art algorithms in terms of
precision, recall (19% - 50%), and inter list diversity (20% - 60%). B-Rank
captures well the difference between popular and niche objects. The proposed
algorithm produces very promising results for sparse and dense voting matrices.
Furthermore, a recommendation list update algorithm is introduced,to cope with
new votes. This technique significantly reduces computational complexity. The
implementation of the algorithm is simple, since B-Rank needs no parameter
tuning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2744</identifier>
 <datestamp>2009-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2744</id><created>2009-08-19</created><authors><author><keyname>Chaurasia</keyname><forenames>Anshul</forenames></author><author><keyname>Dwivedi</keyname><forenames>Sudhanshu</forenames></author><author><keyname>Jain</keyname><forenames>Prateek</forenames></author><author><keyname>Gupta</keyname><forenames>Manish K.</forenames></author></authors><title>XTile: An Error-Correction Package for DNA Self-Assembly</title><categories>cs.IT math.IT</categories><comments>5 pages, FNANO 2009 conference paper, The tool XTile is available for
  download and use at http://www.guptalab.org/xtile</comments><journal-ref>Proceedings of 6th Annual Conference on Foundations of Nanoscience
  (FNANO 09): Self-Assembled Architectures and Devices, Salt Lake City, Utah,
  U.S.A., 20th-24th April 2009, pp. 225 - 229</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self assembly is a process by which supramolecular species form spontaneously
from their components. This process is ubiquitous throughout the life chemistry
and is central to biological information processing. It has been predicted that
in future self assembly will become an important engineering discipline by
combining the fields of bio molecular computation, nano technology and
medicine. However error control is a key challenge in realizing the potential
of self assembly. Recently many authors have proposed several combinatorial
error correction schemes to control errors which have a close analogy with the
coding theory such as Winfree s proofreading scheme and its generalizations by
Chen and Goel and compact scheme of Reif, Sahu and Yin. In this work, we
present an error correction computational tool XTile that can be used to create
input files to the Xgrow simulator of Winfree by providing the design logic of
the tiles and it also allows the user to apply proofreading, snake and compact
error correction schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2782</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2782</id><created>2009-08-19</created><updated>2009-12-01</updated><authors><author><keyname>Altshuler</keyname><forenames>Boris</forenames></author><author><keyname>Krovi</keyname><forenames>Hari</forenames></author><author><keyname>Roland</keyname><forenames>Jeremie</forenames></author></authors><title>Adiabatic quantum optimization fails for random instances of NP-complete
  problems</title><categories>quant-ph cs.CC</categories><comments>34 pages, 5 color figures. Significant changes compared to v1,
  including a new section about Anderson Localization</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adiabatic quantum optimization has attracted a lot of attention because small
scale simulations gave hope that it would allow to solve NP-complete problems
efficiently. Later, negative results proved the existence of specifically
designed hard instances where adiabatic optimization requires exponential time.
In spite of this, there was still hope that this would not happen for random
instances of NP-complete problems. This is an important issue since random
instances are a good model for hard instances that can not be solved by current
classical solvers, for which an efficient quantum algorithm would therefore be
desirable. Here, we will show that because of a phenomenon similar to Anderson
localization, an exponentially small eigenvalue gap appears in the spectrum of
the adiabatic Hamiltonian for large random instances, very close to the end of
the algorithm. This implies that unfortunately, adiabatic quantum optimization
also fails for these instances by getting stuck in a local minimum, unless the
computation is exponentially long.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2793</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2793</id><created>2009-08-19</created><updated>2009-09-16</updated><authors><author><keyname>Kozen</keyname><forenames>Dexter</forenames></author><author><keyname>Ruozzi</keyname><forenames>Nicholas</forenames></author></authors><title>Applications of Metric Coinduction</title><categories>cs.LO</categories><acm-class>F.4.1; F.3.1; I.1.3; I.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (September
  16, 2009) lmcs:1168</journal-ref><doi>10.2168/LMCS-5(3:10)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metric coinduction is a form of coinduction that can be used to establish
properties of objects constructed as a limit of finite approximations. One can
prove a coinduction step showing that some property is preserved by one step of
the approximation process, then automatically infer by the coinduction
principle that the property holds of the limit object. This can often be used
to avoid complicated analytic arguments involving limits and convergence,
replacing them with simpler algebraic arguments. This paper examines the
application of this principle in a variety of areas, including infinite
streams, Markov chains, Markov decision processes, and non-well-founded sets.
These results point to the usefulness of coinduction as a general proof
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2828</identifier>
 <datestamp>2009-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2828</id><created>2009-08-19</created><authors><author><keyname>Nguyen</keyname><forenames>Phong S.</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>A Rate-Distortion Perspective on Multiple Decoding Attempts for
  Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><comments>10 pages, 3 figures, accepted to Allerton Conference on Communication
  Control and Computing, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a number of authors have proposed decoding schemes for Reed-Solomon
(RS) codes based on multiple trials of a simple RS decoding algorithm. In this
paper, we present a rate-distortion (R-D) approach to analyze these
multiple-decoding algorithms for RS codes. This approach is first used to
understand the asymptotic performance-versus-complexity trade-off of multiple
error-and-erasure decoding of RS codes. By defining an appropriate distortion
measure between an error pattern and an erasure pattern, the condition for a
single error-and-erasure decoding to succeed reduces to a form where the
distortion is compared to a fixed threshold. Finding the best set of erasure
patterns for multiple decoding trials then turns out to be a covering problem
which can be solved asymptotically by rate-distortion theory. Next, this
approach is extended to analyze multiple algebraic soft-decision (ASD) decoding
of RS codes. Both analytical and numerical computations of the R-D functions
for the corresponding distortion measures are discussed. Simulation results
show that proposed algorithms using this approach perform better than other
algorithms with the same complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2834</identifier>
 <datestamp>2009-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2834</id><created>2009-08-19</created><authors><author><keyname>Azar</keyname><forenames>Yossi</forenames></author><author><keyname>Birnbaum</keyname><forenames>Benjamin</forenames></author><author><keyname>Karlin</keyname><forenames>Anna R.</forenames></author><author><keyname>Nguyen</keyname><forenames>C. Thach</forenames></author></authors><title>On Revenue Maximization in Second-Price Ad Auctions</title><categories>cs.DS</categories><comments>Full version of ESA 2009 paper, 23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most recent papers addressing the algorithmic problem of allocating
advertisement space for keywords in sponsored search auctions assume that
pricing is done via a first-price auction, which does not realistically model
the Generalized Second Price (GSP) auction used in practice. Towards the goal
of more realistically modeling these auctions, we introduce the Second-Price Ad
Auctions problem, in which bidders' payments are determined by the GSP
mechanism. We show that the complexity of the Second-Price Ad Auctions problem
is quite different than that of the more studied First-Price Ad Auctions
problem. First, unlike the first-price variant, for which small constant-factor
approximations are known, it is NP-hard to approximate the Second-Price Ad
Auctions problem to any non-trivial factor. Second, this discrepancy extends
even to the 0-1 special case that we call the Second-Price Matching problem
(2PM). In particular, offline 2PM is APX-hard, and for online 2PM there is no
deterministic algorithm achieving a non-trivial competitive ratio and no
randomized algorithm achieving a competitive ratio better than 2. This stands
in contrast to the results for the analogous special case in the first-price
model, the standard bipartite matching problem, which is solvable in polynomial
time and which has deterministic and randomized online algorithms achieving
better competitive ratios. On the positive side, we provide a 2-approximation
for offline 2PM and a 5.083-competitive randomized algorithm for online 2PM.
The latter result makes use of a new generalization of a classic result on the
performance of the &quot;Ranking&quot; algorithm for online bipartite matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2847</identifier>
 <datestamp>2009-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2847</id><created>2009-08-19</created><authors><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>The Single Source Two Terminal Network with Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>4 pages, appeared at the Canadian Workshop on Information Theory
  (CWIT), 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a communication network with a single source that has a set of
messages and two terminals where each terminal is interested in an arbitrary
subset of messages at the source. A tight capacity region for this problem is
demonstrated. We show by a simple graph-theoretic procedure that any such
problem can be solved by performing network coding on the subset of messages
that are requested by both the terminals and that routing is sufficient for
transferring the remaining messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2871</identifier>
 <datestamp>2009-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2871</id><created>2009-08-20</created><authors><author><keyname>Genge</keyname><forenames>Bela</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author><author><keyname>Ignat</keyname><forenames>Iosif</forenames></author><author><keyname>Ratoi</keyname><forenames>Ovidiu</forenames></author></authors><title>Informal specification-based performance evaluation of security
  protocols</title><categories>cs.CR cs.NI</categories><comments>4th IEEE International Conference on Intelligent Computer
  Communication and Processing, Cluj-Napoca, Romania, pp. 193-200, Aug. 2008,
  ISBN 978-1-4244-2673-7</comments><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a performance evaluation method for security protocols. Based on
the informal specification, we construct a canonical model which includes,
alongside protocol messages, cryptographic operations performed by participants
in the process of message construction. Each cryptographic operation is
assigned a cost modeled as a function of the size of processed message
components. We model not only the size of regular message components but also
the size of ciphertext produced by various cryptographic operations. We
illustrate the applicability of our method by comparatively analyzing the
performance of the original CCITT X.509 protocol and a slightly modified
version of the same protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2905</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2905</id><created>2009-08-20</created><updated>2010-01-17</updated><authors><author><keyname>Catrina</keyname><forenames>Octavian</forenames></author><author><keyname>Saxena</keyname><forenames>Amitabh</forenames></author><author><keyname>Hoogh</keyname><forenames>Sebastiaan J</forenames></author></authors><title>Secure Linear Programming Using Privacy-Preserving Simplex</title><categories>cs.CR</categories><comments>The current version is withdrawn due to a error. An older version of
  the paper is available on this archive. Please contact the author(s) for an
  updated copy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This version of the paper has been withdrawn due to an error. Please contact
one of the authors for an updated copy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2940</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2940</id><created>2009-08-20</created><updated>2010-04-09</updated><authors><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author></authors><title>A Strong Direct Product Theorem for Disjointness</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A strong direct product theorem states that if we want to compute $k$
independent instances of a function, using less than $k$ times the resources
needed for one instance, then the overall success probability will be
exponentially small in $k$. We establish such a theorem for the randomized
communication complexity of the Disjointness problem, i.e., with communication
$const\cdot kn$ the success probability of solving $k$ instances of size $n$
can only be exponentially small in $k$. We show that this bound even holds for
$AM$ communication protocols with limited ambiguity. This also implies a new
lower bound for Disjointness in a restricted 3-player NOF protocol, and optimal
communication-space tradeoffs for Boolean matrix product. Our main result
follows from a solution to the dual of a linear programming problem, whose
feasibility comes from a so-called Intersection Sampling Lemma that generalizes
a result by Razborov.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2941</identifier>
 <datestamp>2009-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2941</id><created>2009-08-20</created><authors><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Delay-Sensitive Distributed Power and Transmission Threshold Control for
  S-ALOHA Network with Finite State Markov Fading Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the delay-sensitive power and transmission
threshold control design in S-ALOHA network with FSMC fading channels. The
random access system consists of an access point with K competing users, each
has access to the local channel state information (CSI) and queue state
information (QSI) as well as the common feedback (ACK/NAK/Collision) from the
access point. We seek to derive the delay-optimal control policy (composed of
threshold and power control). The optimization problem belongs to the
memoryless policy K-agent infinite horizon decentralized Markov decision
process (DEC-MDP), and finding the optimal policy is shown to be
computationally intractable. To obtain a feasible and low complexity solution,
we recast the optimization problem into two subproblems, namely the power
control and the threshold control problem. For a given threshold control
policy, the power control problem is decomposed into a reduced state MDP for
single user so that the overall complexity is O(NJ), where N and J are the
buffer size and the cardinality of the CSI states. For the threshold control
problem, we exploit some special structure of the collision channel and common
feedback information to derive a low complexity solution. The delay performance
of the proposed design is shown to have substantial gain relative to
conventional throughput optimal approaches for S-ALOHA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2958</identifier>
 <datestamp>2009-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2958</id><created>2009-08-20</created><authors><author><keyname>Nguyen</keyname><forenames>Que Thu Dung</forenames></author></authors><title>Design and Implementation of a Distributed Middleware for Parallel
  Execution of Legacy Enterprise Applications</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A typical enterprise uses a local area network of computers to perform its
business. During the off-working hours, the computational capacities of these
networked computers are underused or unused. In order to utilize this
computational capacity an application has to be recoded to exploit concurrency
inherent in a computation which is clearly not possible for legacy applications
without any source code. This thesis presents the design an implementation of a
distributed middleware which can automatically execute a legacy application on
multiple networked computers by parallelizing it. This middleware runs multiple
copies of the binary executable code in parallel on different hosts in the
network. It wraps up the binary executable code of the legacy application in
order to capture the kernel level data access system calls and perform them
distributively over multiple computers in a safe and conflict free manner. The
middleware also incorporates a dynamic scheduling technique to execute the
target application in minimum time by scavenging the available CPU cycles of
the hosts in the network. This dynamic scheduling also supports the CPU
availability of the hosts to change over time and properly reschedule the
replicas performing the computation to minimize the execution time. A prototype
implementation of this middleware has been developed as a proof of concept of
the design. This implementation has been evaluated with a few typical case
studies and the test results confirm that the middleware works as expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.2984</identifier>
 <datestamp>2009-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.2984</id><created>2009-08-20</created><updated>2009-09-05</updated><authors><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Explicit Codes Minimizing Repair Bandwidth for Distributed Storage</title><categories>cs.IT math.IT</categories><comments>11 pages, 4 figures v2: corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the setting of data storage across n nodes in a distributed
manner. A data collector (DC) should be able to reconstruct the entire data by
connecting to any k out of the n nodes and downloading all the data stored in
them. When a node fails, it has to be regenerated back using the existing
nodes. In a recent paper, Wu et al. have obtained an information theoretic
lower bound for the repair bandwidth. Also, there has been additional interest
in storing data in systematic form as no post processing is required when DC
connects to k systematic nodes. Because of their preferred status there is a
need to regenerate back any systematic node quickly and exactly. Replacement of
a failed node by an exact replica is termed Exact Regeneration.In this paper,
we consider the problem of minimizing the repair bandwidth for exact
regeneration of the systematic nodes. The file to be stored is of size B and
each node can store alpha = B/k units of data. A failed systematic node is
regenerated by downloading beta units of data each from d existing nodes. We
give a lower bound for the repair bandwidth for exact regeneration of the
systematic nodes which matches with the bound given by Wu et al. For d &gt;= 2k-1
we give an explicit code construction which minimizes the repair bandwidth when
the existing k-1 systematic nodes participate in the regeneration. We show the
existence and construction of codes that achieve the bound for d &gt;= 2k-3. Here
we also establish the necessity of interference alignment. We prove that the
bound is not achievable for d &lt;= 2k-4 when beta=1. We also give a coding scheme
which can be used for any d and k, which is optimal for d &gt;= 2k-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3022</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3022</id><created>2009-08-20</created><authors><author><keyname>Hunt</keyname><forenames>John</forenames></author></authors><title>An approach for the automated risk assessment of structural differences
  between spreadsheets (DiffXL)</title><categories>cs.HC cs.SE</categories><comments>10 Pages, Numerous Colour Diagrams &amp; Screenshots</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 ISBN
  978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper outlines an approach to manage and quantify the risks associated
with changes made to spreadsheets. The methodology focuses on structural
differences between spreadsheets and suggests a technique by which a risk
analysis can be achieved in an automated environment. The paper offers an
example that demonstrates how contiguous ranges of data can be mapped into a
generic list of formulae, data and metadata. The example then shows that
comparison of these generic lists can establish the structural differences
between spreadsheets and quantify the level of risk that each change has
introduced. Lastly the benefits, drawbacks and limitations of the technique are
discussed in a commercial context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3025</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3025</id><created>2009-08-20</created><authors><author><keyname>Corne</keyname><forenames>David</forenames></author><author><keyname>Knowles</keyname><forenames>Joshua</forenames></author></authors><title>Techniques for Highly Multiobjective Optimisation: Some Nondominated
  Points are Better than Others</title><categories>cs.NE</categories><comments>8 pages, 2 tables</comments><journal-ref>in Hod Lipson (Ed.): Genetic and Evolutionary Computation
  Conference, GECCO 2007, Proceedings, London, England, UK, July 7-11, 2007.
  ACM 2007, pp. 773--780, ISBN 978-1-59593-697-4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research area of evolutionary multiobjective optimization (EMO) is
reaching better understandings of the properties and capabilities of EMO
algorithms, and accumulating much evidence of their worth in practical
scenarios. An urgent emerging issue is that the favoured EMO algorithms scale
poorly when problems have many (e.g. five or more) objectives. One of the chief
reasons for this is believed to be that, in many-objective EMO search,
populations are likely to be largely composed of nondominated solutions. In
turn, this means that the commonly-used algorithms cannot distinguish between
these for selective purposes. However, there are methods that can be used
validly to rank points in a nondominated set, and may therefore usefully
underpin selection in EMO search. Here we discuss and compare several such
methods. Our main finding is that simple variants of the often-overlooked
Average Ranking strategy usually outperform other methods tested, covering
problems with 5-20 objectives and differing amounts of inter-objective
correlation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3082</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3082</id><created>2009-08-21</created><authors><author><keyname>Ratoi</keyname><forenames>Ovidiu</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author><author><keyname>Salomie</keyname><forenames>Ioan</forenames></author><author><keyname>Genge</keyname><forenames>Bela</forenames></author></authors><title>Component based platform for multimedia applications</title><categories>cs.MM cs.NI</categories><comments>7th IEEE RoEduNet International Conference, Cluj-Napoca, Romania,
  Aug. 2008, pp. 40-43, ISBN 978-973-662-393-6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a platform for distributed multimedia applications which
simplifies the development process and at the same time ensures application
portability, flexibility and performance. The platform is implemented using the
Netscape Portable Runtime (NSPR) and the Cross-Platform Component Object Model
(XPCOM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3083</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3083</id><created>2009-08-21</created><authors><author><keyname>Genge</keyname><forenames>Bela</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author><author><keyname>Ratoi</keyname><forenames>Ovidiu</forenames></author><author><keyname>Ignat</keyname><forenames>Iosif</forenames></author></authors><title>Term-based composition of security protocols</title><categories>cs.CR cs.NI</categories><comments>2008 IEEE International Conference on Automation, Quality and
  Testing, Robotics, Cluj-Napoca, Romania, May 2008, pp. 233-238, ISBN
  978-1-4244-2576-1</comments><acm-class>D.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of security protocol parallel composition, where messages
belonging to different protocols can intersect each other, we introduce a new
paradigm: term-based composition (i.e. the composition of message components
also known as terms). First, we create a protocol specification model by
extending the original strand spaces. Then, we provide a term composition
algorithm based on which new terms can be constructed. To ensure that security
properties are maintained, we introduce the concept of term connections to
express the existing connections between terms and encryption contexts. We
illustrate the proposed composition process by using two existing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3089</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3089</id><created>2009-08-21</created><authors><author><keyname>Kolosovskiy</keyname><forenames>Maxim A.</forenames><affiliation>Altai State Technical University, Russia</affiliation></author></authors><title>Data structure for representing a graph: combination of linked list and
  hash table</title><categories>cs.DS</categories><comments>7 pages</comments><acm-class>E.1.2; E.2.2; E.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we discuss a data structure, which combines advantages of two
different ways for representing graphs: adjacency matrix and collection of
adjacency lists. This data structure can fast add and search edges (advantages
of adjacency matrix), use linear amount of memory, let to obtain adjacency list
for certain vertex (advantages of collection of adjacency lists). Basic
knowledge of linked lists and hash tables is required to understand this
article. The article contains examples of implementation on Java.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3090</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3090</id><created>2009-08-21</created><authors><author><keyname>Genge</keyname><forenames>Bela</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author></authors><title>A Modeling Framework for Generating Security Protocol Specifications</title><categories>cs.CR cs.NI</categories><comments>10th International Symposium on Symbolic and Numeric Algorithms for
  Scientific Computing (SYNASC'08), Workshop on Global Computing Models and
  Technologies, Timisoara, Romania, Sept. 2008, pp. 362-365, ISBN
  978-0-7695-3523-4</comments><acm-class>D.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a modeling framework for generating security protocol
specifications. The generated protocol specifications rely on the use of a
sequential and a semantical component. The first component defines protocol
properties such as preconditions, effects, message sequences and it is
developed as a WSDL-S specification. The second component defines the semantic
aspects corresponding to the messages included in the first component by the
use of ontological constructions and it is developed as an OWL-based
specification. Our approach was validated on 13 protocols from which we
mention: the ISO9798 protocol, the CCITTX.509 data transfer protocol and the
Kerberos symmetric key protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3091</identifier>
 <datestamp>2014-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3091</id><created>2009-08-21</created><updated>2014-10-14</updated><authors><author><keyname>Egri-Nagy</keyname><forenames>Attila</forenames></author><author><keyname>Nehaniv</keyname><forenames>Chrystopher L.</forenames></author></authors><title>Computational Understanding and Manipulation of Symmetries</title><categories>cs.AI cs.MS</categories><comments>14 pages, 5 figures, v2 major revision of computational examples</comments><msc-class>20B40</msc-class><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For natural and artificial systems with some symmetry structure,
computational understanding and manipulation can be achieved without learning
by exploiting the algebraic structure. Here we describe this algebraic
coordinatization method and apply it to permutation puzzles. Coordinatization
yields a structural understanding, not just solutions for the puzzles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3098</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3098</id><created>2009-08-21</created><authors><author><keyname>Somekh</keyname><forenames>Oren</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Throughput of Cellular Uplink with Dynamic User Activity and Cooperative
  Base-Stations</title><categories>cs.IT math.IT</categories><comments>To be presented at the IEEE Information Theory Workshop, Taormina,
  Sicily, Italy, October 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The throughput of a linear cellular uplink with a random number of users,
different power control schemes, and cooperative base stations is considered in
the large system limit where the number of cells is large for non fading
Gaussian channels. The analysis is facilitated by establishing an analogy
between the cellular channel per-cell throughput with joint multi-cell
processing (MCP), and the rate of a deterministic inter-symbol interference
(ISI) channel with flat fading. It is shown that, under certain conditions, the
dynamics of cellular systems (i.e., a random number of users coupled with a
given power control scheme) can be interpreted, as far as the uplink throughput
is concerned, as the flat fading process of the equivalent ISI channel. The
results are used to demonstrate the benefits of MCP over the conventional
single cell processing approach as a function of various system parameters in
the presence of random user activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3148</identifier>
 <datestamp>2013-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3148</id><created>2009-08-21</created><updated>2013-03-14</updated><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Another Look at Quantum Neural Computing</title><categories>cs.NE cs.AI</categories><comments>10 pages, 4 figures; Based on lecture given at Czech Technical
  University, Prague on June 25, 2009. This revision adds clarifying remarks
  and corrects typographical errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The term quantum neural computing indicates a unity in the functioning of the
brain. It assumes that the neural structures perform classical processing and
that the virtual particles associated with the dynamical states of the
structures define the underlying quantum state. We revisit the concept and also
summarize new arguments related to the learning modes of the brain in response
to sensory input that may be aggregated in three types: associative,
reorganizational, and quantum. The associative and reorganizational types are
quite apparent based on experimental findings; it is much harder to establish
that the brain as an entity exhibits quantum properties. We argue that the
reorganizational behavior of the brain may be viewed as inner adjustment
corresponding to its quantum behavior at the system level. Not only neural
structures but their higher abstractions also may be seen as whole entities. We
consider the dualities associated with the behavior of the brain and how these
dualities are bridged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3162</identifier>
 <datestamp>2014-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3162</id><created>2009-08-21</created><updated>2010-01-17</updated><authors><author><keyname>Pershin</keyname><forenames>Yuriy V.</forenames></author><author><keyname>Di Ventra</keyname><forenames>Massimiliano</forenames></author></authors><title>Practical approach to programmable analog circuits with memristors</title><categories>physics.ins-det cond-mat.mes-hall cs.AI</categories><journal-ref>IEEE Trans.Circuits Theor.57:1857-1964,2010</journal-ref><doi>10.1109/TCSI.2009.2038539</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest an approach to use memristors (resistors with memory) in
programmable analog circuits. Our idea consists in a circuit design in which
low voltages are applied to memristors during their operation as analog circuit
elements and high voltages are used to program the memristor's states. This
way, as it was demonstrated in recent experiments, the state of memristors does
not essentially change during analog mode operation. As an example of our
approach, we have built several programmable analog circuits demonstrating
memristor-based programming of threshold, gain and frequency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3166</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3166</id><created>2009-08-21</created><authors><author><keyname>Hsiao-feng</keyname><affiliation>Francis</affiliation></author><author><keyname>Lu</keyname></author><author><keyname>Lahtonen</keyname><forenames>Jyrki</forenames></author><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author><author><keyname>Hollanti</keyname><forenames>Camilla</forenames></author></authors><title>Remarks on the Criteria of Constructing MIMO-MAC DMT Optimal Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the criteria proposed by Coronel et al. for
constructing MIMO MAC-DMT optimal codes over several classes of fading
channels. We first give a counterexample showing their DMT result is not
correct when the channel is frequency-selective. For the case of symmetric
MIMO-MAC flat fading channels, their DMT result reduces to exactly the same as
that derived by Tse et al., and we therefore focus on their criteria for
constructing MAC-DMT optimal codes, especially when the number of receive
antennas is sufficiently large. In such case, we show their criterion is
equivalent to requiring the codes of any subset of users to satisfy a joint
non-vanishing determinant criterion when the system operates in the antenna
pooling regime. Finally an upper bound on the product of minimum eigenvalues of
the difference matrices is provided, and is used to show any MIMO-MAC codes
satisfying their criterion can possibly exist only when the target multiplexing
gain is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3170</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3170</id><created>2009-08-21</created><authors><author><keyname>Mart&#xed;n</keyname><forenames>Ferm&#xed;n Moscoso del Prado</forenames></author></authors><title>The thermodynamics of human reaction times</title><categories>q-bio.NC cond-mat.dis-nn cond-mat.stat-mech cs.HC</categories><comments>Submitted manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I present a new approach for the interpretation of reaction time (RT) data
from behavioral experiments. From a physical perspective, the entropy of the RT
distribution provides a model-free estimate of the amount of processing
performed by the cognitive system. In this way, the focus is shifted from the
conventional interpretation of individual RTs being either long or short, into
their distribution being more or less complex in terms of entropy. The new
approach enables the estimation of the cognitive processing load without
reference to the informational content of the stimuli themselves, thus
providing a more appropriate estimate of the cognitive impact of different
sources of information that are carried by experimental stimuli or tasks. The
paper introduces the formulation of the theory, followed by an empirical
validation using a database of human RTs in lexical tasks (visual lexical
decision and word naming). The results show that this new interpretation of RTs
is more powerful than the traditional one. The method provides theoretical
estimates of the processing loads elicited by individual stimuli. These loads
sharply distinguish the responses from different tasks. In addition, it
provides upper-bound estimates for the speed at which the system processes
information. Finally, I argue that the theoretical proposal, and the associated
empirical evidence, provide strong arguments for an adaptive system that
systematically adjusts its operational processing speed to the particular
demands of each stimulus. This finding is in contradiction with Hick's law,
which posits a relatively constant processing speed within an experimental
context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3171</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3171</id><created>2009-08-21</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On the Optimality of Beamforming for Multi-User MISO Interference
  Channels with Single-User Detection</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, to appear at Globecom 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a multi-user interference channel with multi-antenna transmitters and
single-antenna receivers, by restricting each receiver to a single-user
detector, computing the largest achievable rate region amounts to solving a
family of non-convex optimization problems. Recognizing the intrinsic
connection between the signal power at the intended receiver and the
interference power at the unintended receiver, the original family of
non-convex optimization problems is converted into a new family of convex
optimization problems. It is shown that, for such interference channels with
each receiver implementing single-user detection, transmitter beamforming can
achieve all boundary points of the achievable rate region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3177</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3177</id><created>2009-08-21</created><authors><author><keyname>Lariviere</keyname><forenames>Vincent</forenames></author><author><keyname>Gingras</keyname><forenames>Yves</forenames></author></authors><title>The impact factor's Matthew effect: a natural experiment in
  bibliometrics</title><categories>physics.soc-ph cs.DL</categories><comments>7 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the publication of Robert K. Merton's theory of cumulative advantage in
science (Matthew Effect), several empirical studies have tried to measure its
presence at the level of papers, individual researchers, institutions or
countries. However, these studies seldom control for the intrinsic &quot;quality&quot; of
papers or of researchers--&quot;better&quot; (however defined) papers or researchers
could receive higher citation rates because they are indeed of better quality.
Using an original method for controlling the intrinsic value of
papers--identical duplicate papers published in different journals with
different impact factors--this paper shows that the journal in which papers are
published have a strong influence on their citation rates, as duplicate papers
published in high impact journals obtain, on average, twice as much citations
as their identical counterparts published in journals with lower impact
factors. The intrinsic value of a paper is thus not the only reason a given
paper gets cited or not; there is a specific Matthew effect attached to
journals and this gives to paper published there an added value over and above
their intrinsic quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3184</identifier>
 <datestamp>2009-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3184</id><created>2009-08-21</created><updated>2009-11-19</updated><authors><author><keyname>Lingashetty</keyname><forenames>Krishna Chaithanya</forenames></author></authors><title>Location of Single Neuron Memories in a Hebbian Network</title><categories>cs.NE</categories><comments>7 pages, 11 figures, Presented at the Conference on Theoretical and
  Applied Computer Science 2009(TACS'09), Stillwater, Oklahoma. Corrected
  results and formatting changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports the results of an experiment on the use of Kak's B-Matrix
approach to spreading activity in a Hebbian neural network. Specifically, it
concentrates on the memory retrieval from single neurons and compares the
performance of the B-Matrix approach to that of the traditional approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3212</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3212</id><created>2009-08-21</created><updated>2009-11-13</updated><authors><author><keyname>Caticha</keyname><forenames>Ariel</forenames></author></authors><title>Quantifying Rational Belief</title><categories>physics.data-an cs.AI</categories><comments>Presented at MaxEnt 2009, the 29th International Workshop on Bayesian
  Inference and Maximum Entropy Methods in Science and Engineering (July 5-10,
  2009, Oxford, Mississippi, USA.) In version 2 one mistake and a few typos
  have been corrected</comments><doi>10.1063/1.3275647</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some criticisms that have been raised against the Cox approach to probability
theory are addressed. Should we use a single real number to measure a degree of
rational belief? Can beliefs be compared? Are the Cox axioms obvious? Are there
counterexamples to Cox? Rather than justifying Cox's choice of axioms we follow
a different path and derive the sum and product rules of probability theory as
the unique (up to regraduations) consistent representations of the Boolean AND
and OR operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3222</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3222</id><created>2009-08-21</created><authors><author><keyname>Hattori</keyname><forenames>Kumiko</forenames></author><author><keyname>Hattori</keyname><forenames>Tetsuya</forenames></author></authors><title>Hydrodynamic limit of move-to-front rules and search cost probabilities</title><categories>math.PR cs.DS</categories><msc-class>68P10; 35C05;82C22;60K35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a hydrodynamic limit approach to move-to-front rules, namely, a
scaling limit as the number of items tends to infinity, of the joint
distribution of jump rate and position of items. As an application of the limit
formula, we present asymptotic formulas on search cost probability
distributions, applicable for general jump rate distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3231</identifier>
 <datestamp>2010-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3231</id><created>2009-08-22</created><updated>2010-05-19</updated><authors><author><keyname>Korsnes</keyname><forenames>Reinert</forenames></author></authors><title>Rapid self-organised initiation of ad hoc sensor networks close above
  the percolation threshold</title><categories>cs.NI cond-mat.dis-nn cond-mat.stat-mech</categories><comments>13 pages, 7 figures, research paper</comments><journal-ref>Physica A: Statistical Mechanics and its Applications, Volume 389,
  Issue 14, 15 July 2010, Pages 2841-2848</journal-ref><doi>10.1016/j.physa.2010.03.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work shows potentials for rapid self-organisation of sensor networks
where nodes collaborate to relay messages to a common data collecting unit
(sink node). The study problem is, in the sense of graph theory, to find a
shortest path tree spanning a weighted graph. This is a well-studied problem
where for example Dijkstra's algorithm provides a solution for non-negative
edge weights. The present contribution shows by simulation examples that simple
modifications of known distributed approaches here can provide significant
improvements in performance. Phase transition phenomena, which are known to
take place in networks close to percolation thresholds, may explain these
observations. An initial method, which here serves as reference, assumes the
sink node starts organisation of the network (tree) by transmitting a control
message advertising its availability for its neighbours. These neighbours then
advertise their current cost estimate for routing a message to the sink. A node
which in this way receives a message implying an improved route to the sink,
advertises its new finding and remembers which neighbouring node the message
came from. This activity proceeds until there are no more improvements to
advertise to neighbours. The result is a tree network for cost effective
transmission of messages to the sink (root). This distributed approach has
potential for simple improvements which are of interest when minimisation of
storage and communication of network information are a concern. Fast
organisation of the network takes place when the number $k$ of connections for
each node ({\em degree}) is close above its critical value for global network
percolation and at the same time there is a threshold for the nodes to decide
to advertise network route updates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3233</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3233</id><created>2009-08-22</created><authors><author><keyname>Oruc</keyname><forenames>A. Yavuz</forenames></author><author><keyname>Atmaca</keyname><forenames>Abdullah</forenames></author></authors><title>Asymptotically Optimal Assignments In Ordinal Evaluations of Proposals</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In ordinal evaluations of proposals in peer review systems, a set of
proposals is assigned to a fixed set of referees so as to maximize the number
of pairwise comparisons of proposals under certain referee capacity and
proposal subject constraints. In this paper, the following two related problems
are considered: (1) Assuming that each referee has a capacity to review k out
of n proposals, 2 &lt; k &lt; n, determine the minimum number of referees needed to
ensure that each pair of proposals is reviewed by at least one referee, (2)
Find an assignment that meets the lower bound determined in (1). It is easy to
see that one referee is both necessary and sufficient when k = n, and n(n-1)/2
referees are both necessary and sufficient when k = 2. We show that 6 referees
are both necessary and sufficient when k = n/2. We further show that 11
referees are necessary and 12 are sufficient when k = n/3, and 18 referees are
necessary and 20 referees are sufficient when k = n/4. A more general lower
bound of n(n-1)/k(k-1) referees is also given for any k, 2 &lt; k &lt; n, and an
assignment asymptotically matching this lower bound within a factor of 2 is
presented. These results are not only theoretically interesting but they also
provide practical methods for efficient assignments of proposals to referees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3234</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3234</id><created>2009-08-22</created><authors><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Overlapped Chunked Network Coding</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ITW 2010, Cairo</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding is known to improve the throughput and the resilience to
losses in most network scenarios. In a practical network scenario, however, the
accurate modeling of the traffic is often too complex and/or infeasible. The
goal is thus to design codes that perform close to the capacity of any network
(with arbitrary traffic) efficiently. In this context, random linear network
codes are known to be capacity-achieving while requiring a decoding complexity
quadratic in the message length. Chunked Codes (CC) were proposed by Maymounkov
et al. to improve the computational efficiency of random codes by partitioning
the message into a number of non-overlapping chunks. CC can also be
capacity-achieving but have a lower encoding/decoding complexity at the expense
of slower convergence to the capacity. In this paper, we propose and analyze a
generalized version of CC called Overlapped Chunked Codes (OCC) in which chunks
are allowed to overlap. Our theoretical analysis and simulation results show
that compared to CC, OCC can achieve the capacity with a faster speed while
maintaining almost the same advantage in computational efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3252</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3252</id><created>2009-08-22</created><authors><author><keyname>Boubertakh</keyname><forenames>R.</forenames></author><author><keyname>Giovannelli</keyname><forenames>J. -F.</forenames></author><author><keyname>Herment</keyname><forenames>A.</forenames></author><author><keyname>De Cesare</keyname><forenames>A.</forenames></author></authors><title>Non-quadratic convex regularized reconstruction of MR images from spiral
  acquisitions</title><categories>cs.CV cs.CE</categories><journal-ref>Signal Processing, vol. 86, pp. 2479-2494, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining fast MR acquisition sequences and high resolution imaging is a
major issue in dynamic imaging. Reducing the acquisition time can be achieved
by using non-Cartesian and sparse acquisitions. The reconstruction of MR images
from these measurements is generally carried out using gridding that
interpolates the missing data to obtain a dense Cartesian k-space filling. The
MR image is then reconstructed using a conventional Fast Fourier Transform. The
estimation of the missing data unavoidably introduces artifacts in the image
that remain difficult to quantify.
  A general reconstruction method is proposed to take into account these
limitations. It can be applied to any sampling trajectory in k-space, Cartesian
or not, and specifically takes into account the exact location of the measured
data, without making any interpolation of the missing data in k-space.
Information about the expected characteristics of the imaged object is
introduced to preserve the spatial resolution and improve the signal to noise
ratio in a regularization framework. The reconstructed image is obtained by
minimizing a non-quadratic convex objective function. An original rewriting of
this criterion is shown to strongly improve the reconstruction efficiency.
Results on simulated data and on a real spiral acquisition are presented and
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3265</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3265</id><created>2009-08-22</created><authors><author><keyname>Salodkar</keyname><forenames>Nitin</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>Rate Constrained Random Access over a Fading Channel</title><categories>cs.GT cs.LG cs.NI</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we consider uplink transmissions involving multiple users
communicating with a base station over a fading channel. We assume that the
base station does not coordinate the transmissions of the users and hence the
users employ random access communication. The situation is modeled as a
non-cooperative repeated game with incomplete information. Each user attempts
to minimize its long term power consumption subject to a minimum rate
requirement. We propose a two timescale stochastic gradient algorithm (TTSGA)
for tuning the users' transmission probabilities. The algorithm includes a
'waterfilling threshold update mechanism' that ensures that the rate
constraints are satisfied. We prove that under the algorithm, the users'
transmission probabilities converge to a Nash equilibrium. Moreover, we also
prove that the rate constraints are satisfied; this is also demonstrated using
simulation studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3269</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3269</id><created>2009-08-22</created><authors><author><keyname>Salodkar</keyname><forenames>Nitin</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author><author><keyname>Borkar</keyname><forenames>V. S.</forenames></author></authors><title>A Stable On-line Algorithm for Energy Efficient Multi-user Scheduling</title><categories>cs.NI cs.GT</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we consider the problem of energy efficient uplink scheduling
with delay constraint for a multi-user wireless system. We address this problem
within the framework of constrained Markov decision processes (CMDPs) wherein
one seeks to minimize one cost (average power) subject to a hard constraint on
another (average delay). We do not assume the arrival and channel statistics to
be known. To handle state space explosion and informational constraints, we
split the problem into individual CMDPs for the users, coupled through their
Lagrange multipliers; and a user selection problem at the base station. To
address the issue of unknown channel and arrival statistics, we propose a
reinforcement learning algorithm. The users use this learning algorithm to
determine the rate at which they wish to transmit in a slot and communicate
this to the base station. The base station then schedules the user with the
highest rate in a slot. We analyze convergence, stability and optimality
properties of the algorithm. We also demonstrate the efficacy of the algorithm
through simulations within IEEE 802.16 system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3271</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3271</id><created>2009-08-22</created><authors><author><keyname>Gorneff</keyname><forenames>Serge</forenames></author></authors><title>Mathematical Modeling of Aerodynamic Space -to - Surface Flight with
  Trajectory for Avoid Intercepting Process for Safety and Security Issues</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research project has been made for mathematical modeling of aerospace
system Space-to-Surface for avoid intercepting process by flight objects
Surface-to-Air. The research has been completed and created mathematical models
which used for research and statistical analysis. In mathematical modeling has
been including a few models: Model of atmosphere, Model of speed of sound,
Model of flight head in space, Model of flight in atmosphere, Models of
navigation and guidance, Model and statistical analysis of approximation of
aerodynamic characteristics. Modeling has been created for a Space-to-Surface
system defined for an optimal trajectory in terminal phase. The modeling
includes models for simulation atmosphere, aerodynamic flight and navigation by
an infrared system. The modeling simulation includes statistical analysis of
the modeling results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3280</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3280</id><created>2009-08-22</created><updated>2009-09-29</updated><authors><author><keyname>Mirzal</keyname><forenames>Andri</forenames></author></authors><title>On the Relationship between Trading Network and WWW Network: A
  Preferential Attachment Perspective</title><categories>cs.IR cs.CE</categories><comments>21 pages, 6 figures, submitted to International Journal of Business
  Intelligence and Data Mining</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper describes the relationship between trading network and WWW network
from preferential attachment mechanism perspective. This mechanism is known to
be the underlying principle in the network evolution and has been incorporated
to formulate two famous web pages ranking algorithms, PageRank and HITS. We
point out the differences between trading network and WWW network in this
mechanism, derive the formulation of HITS-based ranking algorithm for trading
network as a direct consequence of the differences, and apply the same
framework when deriving the formulation back to the HITS formulation that turns
to become a technique to accelerate its convergences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3315</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3315</id><created>2009-08-23</created><authors><author><keyname>Almeida</keyname><forenames>Marco</forenames></author><author><keyname>Moreira</keyname><forenames>Nelma</forenames></author><author><keyname>Reis</keyname><forenames>Rog&#xe9;rio</forenames></author></authors><title>Exact generation of acyclic deterministic finite automata</title><categories>cs.FL</categories><comments>DCFS'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a canonical representation for trim acyclic deterministic finite
automata (Adfa) with n states over an alphabet of k symbols. Using this normal
form, we present a backtracking algorithm for the exact generation of Adfas.
This algorithm is a non trivial adaptation of the algorithm for the exact
generation of minimal acyclic deterministic finite automata, presented by
Almeida et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3317</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3317</id><created>2009-08-23</created><authors><author><keyname>Reddy</keyname><forenames>Vinith</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author><author><keyname>Sprintson</keyname><forenames>Alex</forenames></author><author><keyname>Gautam</keyname><forenames>Natarajan</forenames></author></authors><title>Multipath Wireless Network Coding: A Population Game Perspective</title><categories>cs.GT cs.NI</categories><comments>9 pages and 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider wireless networks in which multiple paths are available between
each source and destination. We allow each source to split traffic among all of
its available paths, and ask the question: how do we attain the lowest possible
number of transmissions to support a given traffic matrix? Traffic bound in
opposite directions over two wireless hops can utilize the ``reverse
carpooling'' advantage of network coding in order to decrease the number of
transmissions used. We call such coded hops as ``hyper-links''. With the
reverse carpooling technique longer paths might be cheaper than shorter ones.
However, there is a prisoners dilemma type situation among sources -- the
network coding advantage is realized only if there is traffic in both
directions of a shared path. We develop a two-level distributed control scheme
that decouples user choices from each other by declaring a hyper-link capacity,
allowing sources to split their traffic selfishly in a distributed fashion, and
then changing the hyper-link capacity based on user actions. We show that such
a controller is stable, and verify our analytical insights by simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3359</identifier>
 <datestamp>2009-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3359</id><created>2009-08-24</created><updated>2009-08-29</updated><authors><author><keyname>Turski</keyname><forenames>Jacek</forenames></author></authors><title>Geometric Analysis of the Conformal Camera for Intermediate-Level Vision
  and Perisaccadic Perception</title><categories>cs.CV cs.RO</categories><comments>Ver2 with figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binocular system developed by the author in terms of projective Fourier
transform (PFT) of the conformal camera, which numerically integrates the head,
eyes, and visual cortex, is used to process visual information during saccadic
eye movements. Although we make three saccades per second at the eyeball's
maximum speed of 700 deg/sec, our visual system accounts for these incisive eye
movements to produce a stable percept of the world. This visual constancy is
maintained by neuronal receptive field shifts in various retinotopically
organized cortical areas prior to saccade onset, giving the brain access to
visual information from the saccade's target before the eyes' arrival. It
integrates visual information acquisition across saccades. Our modeling
utilizes basic properties of PFT. First, PFT is computable by FFT in complex
logarithmic coordinates that approximate the retinotopy. Second, a translation
in retinotopic (logarithmic) coordinates, modeled by the shift property of the
Fourier transform, remaps the presaccadic scene into a postsaccadic reference
frame. It also accounts for the perisaccadic mislocalization observed by human
subjects in laboratory experiments. Because our modeling involves
cross-disciplinary areas of conformal geometry, abstract and computational
harmonic analysis, computational vision, and visual neuroscience, we include
the corresponding background material and elucidate how these different areas
interwove in our modeling of primate perception. In particular, we present the
physiological and behavioral facts underlying the neural processes related to
our modeling. We also emphasize the conformal camera's geometry and discuss how
it is uniquely useful in the intermediate-level vision computational aspects of
natural scene understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3361</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3361</id><created>2009-08-24</created><authors><author><keyname>Denoue</keyname><forenames>Laurent</forenames></author><author><keyname>Carter</keyname><forenames>Scott</forenames></author><author><keyname>Adcock</keyname><forenames>John</forenames></author><author><keyname>Golovchinsky</keyname><forenames>Gene</forenames></author><author><keyname>Girgensohn</keyname><forenames>Andreas</forenames></author></authors><title>WebNC: efficient sharing of web applications</title><categories>cs.HC</categories><comments>Presented at WWW 2009, Madrid, Spain</comments><acm-class>H.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WebNC is a system for efficiently sharing, retrieving and viewing web
applications. Unlike existing screencasting and screensharing tools, WebNC is
optimized to work with web pages where a lot of scrolling happens. WebNC uses a
tile-based encoding to capture, transmit and deliver web applications, and
relies only on dynamic HTML and JavaScript. The resulting webcasts require very
little bandwidth and are viewable on any modern web browser including Firefox
and Internet Explorer as well as browsers on the iPhone and Android platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3362</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3362</id><created>2009-08-24</created><authors><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>LTCI</affiliation></author></authors><title>The Function of Gesture in an Architectural Design Meeting</title><categories>cs.HC</categories><proxy>ccsd inria-00410315</proxy><journal-ref>About: Designing. Analysing design meetings, Janet McDonnell and
  Peter Lloyd (Ed.) (2009) 269-284</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This text presents a cognitive-psychology analysis of spontaneous, co-speech
gestures in a face-to-face architectural design meeting (A1 in DTRS7). The
long-term objective is to formulate specifications for remote
collaborative-design systems, especially for supporting the use of different
semiotic modalities (multi-modal interaction). According to their function for
design, interaction, and collaboration, we distinguish different gesture
families: representational (entity designating or specifying), organisational
(management of discourse, interaction, or functional design actions),
focalising, discourse and interaction modulating, and disambiguating gestures.
Discussion and conclusion concern the following points. It is impossible to
attribute fixed functions to particular gesture forms. &quot;Designating&quot; gestures
may also have a design function. The gestures identified in A1 possess a
certain generic character. The gestures identified are neither systematically
irreplaceable, nor optional accessories to speech or drawing. We discuss the
possibilities for gesture in computer-supported collaborative software systems.
The paper closes on our contribution to gesture studies and cognitive design
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3380</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3380</id><created>2009-08-24</created><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Construction of Hilbert Transform Pairs of Wavelet Bases and Gabor-like
  Transforms</title><categories>cs.IT cs.CV math.IT</categories><comments>36 pages, 8 figures</comments><journal-ref>IEEE Transactions on Signal Processing, vol 7, no. 9, pp.
  3411-3425, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel method for constructing Hilbert transform (HT) pairs of
wavelet bases based on a fundamental approximation-theoretic characterization
of scaling functions--the B-spline factorization theorem. In particular,
starting from well-localized scaling functions, we construct HT pairs of
biorthogonal wavelet bases of L^2(R) by relating the corresponding wavelet
filters via a discrete form of the continuous HT filter. As a concrete
application of this methodology, we identify HT pairs of spline wavelets of a
specific flavor, which are then combined to realize a family of complex
wavelets that resemble the optimally-localized Gabor function for sufficiently
large orders.
  Analytic wavelets, derived from the complexification of HT wavelet pairs,
exhibit a one-sided spectrum. Based on the tensor-product of such analytic
wavelets, and, in effect, by appropriately combining four separable
biorthogonal wavelet bases of L^2(R^2), we then discuss a methodology for
constructing 2D directional-selective complex wavelets. In particular,
analogous to the HT correspondence between the components of the 1D
counterpart, we relate the real and imaginary components of these complex
wavelets using a multi-dimensional extension of the HT--the directional HT.
Next, we construct a family of complex spline wavelets that resemble the
directional Gabor functions proposed by Daugman. Finally, we present an
efficient FFT-based filterbank algorithm for implementing the associated
complex wavelet transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3383</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3383</id><created>2009-08-24</created><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>On the Shiftability of Dual-Tree Complex Wavelet Transforms</title><categories>cs.IT cs.CV math.IT</categories><comments>to appear in IEEE Transactions on Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 58(1), pp. 221 - 232,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dual-tree complex wavelet transform (DT-CWT) is known to exhibit better
shift-invariance than the conventional discrete wavelet transform. We propose
an amplitude-phase representation of the DT-CWT which, among other things,
offers a direct explanation for the improvement in the shift-invariance. The
representation is based on the shifting action of the group of fractional
Hilbert transform (fHT) operators, which extends the notion of arbitrary
phase-shifts from sinusoids to finite-energy signals (wavelets in particular).
In particular, we characterize the shiftability of the DT-CWT in terms of the
shifting property of the fHTs. At the heart of the representation are certain
fundamental invariances of the fHT group, namely that of translation, dilation,
and norm, which play a decisive role in establishing the key properties of the
transform. It turns out that these fundamental invariances are exclusive to
this group.
  Next, by introducing a generalization of the Bedrosian theorem for the fHT
operator, we derive an explicitly understanding of the shifting action of the
fHT for the particular family of wavelets obtained through the modulation of
lowpass functions (e.g., the Shannon and Gabor wavelet). This, in effect, links
the corresponding dual-tree transform with the framework of windowed-Fourier
analysis. Finally, we extend these ideas to the multi-dimensional setting by
introducing a directional extension of the fHT, the fractional directional
Hilbert transform. In particular, we derive a signal representation involving
the superposition of direction-selective wavelets with appropriate
phase-shifts, which helps explain the improved shift-invariance of the
transform along certain preferential directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3394</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3394</id><created>2009-08-24</created><updated>2009-08-24</updated><authors><author><keyname>Poray</keyname><forenames>Jayanta</forenames></author><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author></authors><title>A Cognitive Mind-map Framework to Foster Trust</title><categories>cs.AI</categories><comments>5 pages, 4 Figures, Extended Version, presented at the 5th
  International Conference on Natural Computation, 2009</comments><acm-class>I.2.0; I.2.6; H.2.8</acm-class><doi>10.1109/ICNC.2009.614</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The explorative mind-map is a dynamic framework, that emerges automatically
from the input, it gets. It is unlike a verificative modeling system where
existing (human) thoughts are placed and connected together. In this regard,
explorative mind-maps change their size continuously, being adaptive with
connectionist cells inside; mind-maps process data input incrementally and
offer lots of possibilities to interact with the user through an appropriate
communication interface. With respect to a cognitive motivated situation like a
conversation between partners, mind-maps become interesting as they are able to
process stimulating signals whenever they occur. If these signals are close to
an own understanding of the world, then the conversational partner becomes
automatically more trustful than if the signals do not or less match the own
knowledge scheme. In this (position) paper, we therefore motivate explorative
mind-maps as a cognitive engine and propose these as a decision support engine
to foster trust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3430</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3430</id><created>2009-08-24</created><authors><author><keyname>Manin</keyname><forenames>Yuri I.</forenames></author></authors><title>Renormalization and Computation II: Time Cut-off and the Halting Problem</title><categories>math.QA cs.CC cs.LO math.LO</categories><comments>28 pages</comments><msc-class>81T15; 68Q10; 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the second installment to the project initiated in [Ma3]. In the
first Part, I argued that both philosophy and technique of the perturbative
renormalization in quantum field theory could be meaningfully transplanted to
the theory of computation, and sketched several contexts supporting this view.
  In this second part, I address some of the issues raised in [Ma3] and provide
their development in three contexts: a categorification of the algorithmic
computations; time cut--off and Anytime Algorithms; and finally, a Hopf algebra
renormalization of the Halting Problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3455</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3455</id><created>2009-08-24</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Pargaru</keyname><forenames>Ion</forenames></author><author><keyname>Ionescu</keyname><forenames>Florin</forenames></author><author><keyname>Andreica</keyname><forenames>Cristina Teodora</forenames></author></authors><title>Algorithmic Aspects of Several Data Transfer Service Optimization
  Problems</title><categories>cs.DS cs.DC</categories><comments>Proceedings of the International Symposium on Sustainable Development
  in Conditions of Economic Instability, Satu Mare, 26-27 June, 2009</comments><acm-class>F.2.2; G.2.2; I.2.8</acm-class><journal-ref>&quot;Quality - Access to Success&quot; Journal, vol. 10, special issue no.
  101, pp. 30-32, 2009. (ISSN: 1582-2559)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimized data transfer services are highly demanded nowadays, due to the
large amounts of data which are frequently being produced and accessed. In this
paper we consider several data transfer service optimization problems (optimal
server location in path networks, optimal packet sequencing and minimum
makespan packet scheduling), for which we provide novel algorithmic solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3459</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3459</id><created>2009-08-24</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Ungureanu</keyname><forenames>Mihai Aristotel</forenames></author><author><keyname>Andreica</keyname><forenames>Romulus</forenames></author><author><keyname>Andreica</keyname><forenames>Angela</forenames></author></authors><title>An Algorithmic Perspective on Some Network Design, Construction and
  Analysis Problems</title><categories>cs.DS cs.DM</categories><comments>Proceedings of the International Symposium on Sustainable Development
  in Conditions of Economic Instability, Satu Mare, 26-27 June, 2009</comments><acm-class>F.2.2; G.2.2; I.2.8</acm-class><journal-ref>&quot;Quality - Access to Success&quot; Journal, vol. 10, special issue no.
  101, pp. 20-22, 2009. (ISSN: 1582-2559)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient network design, construction and analysis are important topics,
considering the highly dynamic environment in which data communication occurs
nowadays. In this paper we address several problems concerning these topics
from an algorithmic point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3463</identifier>
 <datestamp>2009-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3463</id><created>2009-08-24</created><updated>2009-10-30</updated><authors><author><keyname>Cescato</keyname><forenames>Davide</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Interpolation-Based QR Decomposition in MIMO-OFDM Systems</title><categories>cs.IT math.IT</categories><comments>The original submission to Appl. Comput. Harmon. Anal. in Aug. 2009
  was withdrawn. The paper was split in two parts, which were submitted in Oct.
  2009 to IEEE Trans. Inf. Theory and to IEEE Trans. Signal Proc., respectively</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection algorithms for multiple-input multiple-output (MIMO) wireless
systems based on orthogonal frequency-division multiplexing (OFDM) typically
require the computation of a QR decomposition for each of the data-carrying
OFDM tones. The resulting computational complexity will, in general, be
significant, as the number of data-carrying tones ranges from 48 (as in the
IEEE 802.11a/g standards) to 1728 (as in the IEEE 802.16e standard). Motivated
by the fact that the channel matrices arising in MIMO-OFDM systems are highly
oversampled polynomial matrices, we formulate interpolation-based QR
decomposition algorithms. An in-depth complexity analysis, based on a metric
relevant for very large scale integration (VLSI) implementations, shows that
the proposed algorithms, for sufficiently high number of data-carrying tones
and sufficiently small channel order, provably exhibit significantly smaller
complexity than brute-force per-tone QR decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3491</identifier>
 <datestamp>2009-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3491</id><created>2009-08-24</created><updated>2009-09-02</updated><authors><author><keyname>Gutoski</keyname><forenames>Gus</forenames></author></authors><title>Entangled games do not require much entanglement (withdrawn)</title><categories>quant-ph cs.CC</categories><comments>Withdrawn. I found a mistake in my proof. This one-page replacement
  note explains the problem in more detail. Sorry, everyone</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an explicit upper bound on the amount of entanglement required by
any strategy in a two-player cooperative game with classical questions and
quantum answers. Specifically, we show that every strategy for a game with
n-bit questions and n-qubit answers can be implemented exactly by players who
share an entangled state of no more than 5n qubits--a bound which is optimal to
within a factor of 5/2. Previously, no upper bound at all was known on the
amount of entanglement required even to approximate such a strategy. It follows
that the problem of computing the value of these games is in NP, whereas
previously this problem was not known to be computable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3497</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3497</id><created>2009-08-24</created><updated>2009-12-14</updated><authors><author><keyname>Fowler</keyname><forenames>James H.</forenames></author><author><keyname>Christakis</keyname><forenames>Nicholas A.</forenames></author></authors><title>Cooperative Behavior Cascades in Human Social Networks</title><categories>physics.soc-ph cs.HC</categories><doi>10.1073/pnas.0913149107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theoretical models suggest that social networks influence the evolution of
cooperation, but to date there have been few experimental studies.
Observational data suggest that a wide variety of behaviors may spread in human
social networks, but subjects in such studies can choose to befriend people
with similar behaviors, posing difficulty for causal inference. Here, we
exploit a seminal set of laboratory experiments that originally showed that
voluntary costly punishment can help sustain cooperation. In these experiments,
subjects were randomly assigned to a sequence of different groups in order to
play a series of single-shot public goods games with strangers; this feature
allowed us to draw networks of interactions to explore how cooperative and
uncooperative behavior spreads from person to person to person. We show that,
in both an ordinary public goods game and in a public goods game with
punishment, focal individuals are influenced by fellow group members'
contribution behavior in future interactions with other individuals who were
not a party to the initial interaction. Furthermore, this influence persists
for multiple periods and spreads up to three degrees of separation (from person
to person to person to person). The results suggest that each additional
contribution a subject makes to the public good in the first period is tripled
over the course of the experiment by other subjects who are directly or
indirectly influenced to contribute more as a consequence. These are the first
results to show experimentally that cooperative behavior cascades in human
social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3505</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3505</id><created>2009-08-24</created><updated>2010-09-03</updated><authors><author><keyname>Baptiste</keyname><forenames>Philippe</forenames></author><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author><author><keyname>Durr</keyname><forenames>Christoph</forenames></author></authors><title>Polynomial Time Algorithms for Minimum Energy Scheduling</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of power management policies is to reduce the amount of energy
consumed by computer systems while maintaining satisfactory level of
performance. One common method for saving energy is to simply suspend the
system during the idle times. No energy is consumed in the suspend mode.
However, the process of waking up the system itself requires a certain fixed
amount of energy, and thus suspending the system is beneficial only if the idle
time is long enough to compensate for this additional energy expenditure. In
the specific problem studied in the paper, we have a set of jobs with release
times and deadlines that need to be executed on a single processor. Preemptions
are allowed. The processor requires energy L to be woken up and, when it is on,
it uses one unit of energy per one unit of time. It has been an open problem
whether a schedule minimizing the overall energy consumption can be computed in
polynomial time. We solve this problem in positive, by providing an O(n^5)-time
algorithm. In addition we provide an O(n^4)-time algorithm for computing the
minimum energy schedule when all jobs have unit length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3512</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3512</id><created>2009-08-24</created><updated>2012-08-02</updated><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>The Infinite-message Limit of Two-terminal Interactive Source Coding</title><categories>cs.IT math.IT</categories><comments>40 pages, 5 figures. Submitted to IEEE Transactions on Information
  Theory in Sep 2010 and revised in Mar 2012. This version (version 3) is the
  latest revised version. Version 1 was published in Allerton Conference 2009.
  Version 2 contains extensions to the rate-distortion theory and an achievable
  proof of the sum-rate R* in the second example</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-terminal interactive function computation problem with alternating
messages is studied within the framework of distributed block source coding
theory. For any finite number of messages, a single-letter characterization of
the sum-rate-distortion function was established in previous works using
standard information-theoretic techniques. This, however, does not provide a
satisfactory characterization of the infinite-message limit, which is a new,
unexplored dimension for asymptotic-analysis in distributed block source coding
involving potentially an infinite number of infinitesimal-rate messages. In
this paper, the infinite-message sum-rate-distortion function, viewed as a
functional of the joint source pmf and the distortion levels, is characterized
as the least element of a partially ordered family of functionals having
certain convex-geometric properties. The new characterization does not involve
evaluating the infinite-message limit of a finite-message sum-rate-distortion
expression. This characterization leads to a family of lower bounds for the
infinite-message sum-rate-distortion expression and a simple criterion to test
the optimality of any achievable infinite-message sum-rate-distortion
expression. For computing the amplewise Boolean AND function, the
infinite-message minimum sum-rates are characterized in closed analytic form.
These sum-rates are shown to be achievable using infinitely many
infinitesimal-rate messages. The new convex-geometric characterization is used
to develop an iterative algorithm for evaluating any finite-message
sumrate-distortion function. It is also used to construct the first examples
which demonstrate that for lossy source reproduction, two messages can strictly
improve the one-message Wyner-Ziv rate-distortion function settling an
unresolved question from a 1985 paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3519</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3519</id><created>2009-08-25</created><authors><author><keyname>Cucu-Grosjean</keyname><forenames>Liliana</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author></authors><title>Predictability of Fixed-Job Priority Schedulers on Heterogeneous
  Multiprocessor Real-Time Systems</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiprocessor Fixed-Job Priority (FJP) scheduling of real-time systems
is studied. An important property for the schedulability analysis, the
predictability (regardless to the execution times), is studied for
heterogeneous multiprocessor platforms. Our main contribution is to show that
any FJP schedulers are predictable on unrelated platforms. A convenient
consequence is the fact that any FJP schedulers are predictable on uniform
multiprocessors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3523</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3523</id><created>2009-08-24</created><authors><author><keyname>Golovchinsky</keyname><forenames>Gene</forenames></author></authors><title>Cognitive Dimensions Analysis of Interfaces for Information Seeking</title><categories>cs.HC cs.IR</categories><comments>Submitted to HCIR'09 http://cuaslis.org/hcir2009/</comments><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive Dimensions is a framework for analyzing human-computer interaction.
It is used for meta-analysis, that is, for talking about characteristics of
systems without getting bogged down in details of a particular implementation.
In this paper, I discuss some of the dimensions of this theory and how they can
be applied to analyze information seeking interfaces. The goal of this analysis
is to introduce a useful vocabulary that practitioners and researchers can use
to describe systems, and to guide interface design toward more usable and
useful systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3539</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3539</id><created>2009-08-25</created><authors><author><keyname>Hadzi-Velkov</keyname><forenames>Zoran</forenames></author><author><keyname>Zlatanov</keyname><forenames>Nikola</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>An Accurate Approximation to the Distribution of the Sum of Equally
  Correlated Nakagami-m Envelopes and its Application in Equal Gain Diversity
  Receivers</title><categories>cs.IT math.IT</categories><journal-ref>2009. ICC '09. IEEE International Conference on Communications,
  14-18 June 2009 Page(s):1 - 5</journal-ref><doi>10.1109/ICC.2009.5198714</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel and accurate approximation for the distribution of the sum
of equally correlated Nakagami-m variates. Ascertaining on this result we study
the performance of Equal Gain Combining (EGC) receivers, operating over equally
correlating fading channels. Numerical results and simulations show the
accuracy of the proposed approximation and the validity of the mathematical
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3541</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3541</id><created>2009-08-25</created><authors><author><keyname>Zlatanov</keyname><forenames>Nikola</forenames></author><author><keyname>Hadzi-Velkov</keyname><forenames>Zoran</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>Level Crossing Rate and Average Fade Duration of the Double Nakagami-m
  Random Process and Application in MIMO Keyhole Fading Channels</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Communications Letters, Volume 12, Issue 11, November 2008
  Page(s):822 - 824</journal-ref><doi>10.1109/LCOMM.2008.081058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present novel exact expressions and accurate closed-form approximations
for the level crossing rate (LCR) and the average fade duration (AFD) of the
double Nakagami-m random process. These results are then used to study the
second order statistics of multiple input multiple output (MIMO) keyhole fading
channels with space-time block coding. Numerical and computer simulation
examples validate the accuracy of the presented mathematical analysis and show
the tightness of the proposed approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3544</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3544</id><created>2009-08-25</created><authors><author><keyname>Hadzi-Velkov</keyname><forenames>Zoran</forenames></author><author><keyname>Zlatanov</keyname><forenames>Nikola</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>On the Second Order Statistics of the Multihop Rayleigh Fading Channel</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Communications, Volume 57, Issue 6, June 2009
  Page(s):1815 - 1823</journal-ref><doi>10.1109/TCOMM.2009.06.070460</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Second order statistics provides a dynamic representation of a fading channel
and plays an important role in the evaluation and design of the wireless
communication systems. In this paper, we present a novel analytical framework
for the evaluation of important second order statistical parameters, as the
level crossing rate (LCR) and the average fade duration (AFD) of the
amplify-and-forward multihop Rayleigh fading channel. More specifically,
motivated by the fact that this channel is a cascaded one and can be modeled as
the product of N fading amplitudes, we derive novel analytical expressions for
the average LCR and the AFD of the product of N Rayleigh fading envelopes (or
of the recently so-called N*Rayleigh channel). Furthermore, we derive simple
and efficient closed-form approximations to the aforementioned parameters,
using the multivariate Laplace approximation theorem. It is shown that our
general results reduce to the corresponding ones of the specific dual-hop case,
previously published. Numerical and computer simulation examples verify the
accuracy of the presented mathematical analysis and show the tightness of the
proposed approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3545</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3545</id><created>2009-08-25</created><updated>2010-11-29</updated><authors><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Wolle</keyname><forenames>Thomas</forenames></author></authors><title>Notes on large angle crossing graphs</title><categories>cs.DS cs.CG</categories><acm-class>F.2.2</acm-class><journal-ref>Chicago Journal of Theoretical Computer Science, Article 2011-4</journal-ref><doi>10.4086/cjtcs.2011.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph G is an a-angle crossing (aAC) graph if every pair of crossing edges
in G intersect at an angle of at least a. The concept of right angle crossing
(RAC) graphs (a=Pi/2) was recently introduced by Didimo et. al. It was shown
that any RAC graph with n vertices has at most 4n-10 edges and that there are
infinitely many values of n for which there exists a RAC graph with n vertices
and 4n-10 edges. In this paper, we give upper and lower bounds for the number
of edges in aAC graphs for all 0 &lt; a &lt; Pi/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3549</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3549</id><created>2009-08-25</created><authors><author><keyname>Hadzi-Velkov</keyname><forenames>Zoran</forenames></author><author><keyname>Zlatanov</keyname><forenames>Nikola</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>Level Crossing Rate and Average Fade Duration of the Multihop Rayleigh
  Fading Channel</title><categories>cs.IT math.IT</categories><journal-ref>2008. ICC '08. IEEE International Conference on Communications,
  19-23 May 2008 Page(s):4451 - 4455</journal-ref><doi>10.1109/ICC.2008.835</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel analytical framework for the evaluation of important
second order statistical parameters, as the level crossing rate (LCR) and the
average fade duration (AFD) of the amplify-and-forward multihop Rayleigh fading
channel. More specifically, motivated by the fact that this channel is a
cascaded one, which can be modelled as the product of N fading amplitudes, we
derive novel analytical expressions for the average LCR and AFD of the product
of N Rayleigh fading envelopes, or of the recently so-called N*Rayleigh
channel. Furthermore, we derive simple and efficient closed-form approximations
to the aforementioned parameters, using the multivariate Laplace approximation
theorem. It is shown that our general results reduce to the specific dual-hop
case, previously published. Numerical and computer simulation examples verify
the accuracy of the presented mathematical analysis and show the tightness of
the proposed approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3551</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3551</id><created>2009-08-25</created><authors><author><keyname>Hadzi-Velkov</keyname><forenames>Zoran</forenames></author></authors><title>Level Crossing Rate and Average Fade Duration of EGC Systems with
  Cochannel Interference in Rayleigh Fading</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Communications, Volume 55, Issue 11, Nov.
  2007 Page(s):2104 - 2113</journal-ref><doi>10.1109/TCOMM.2007.908519</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both the first-order signal statistics (e.g. the outage probability) and the
second-order signal statistics (e.g. the average level crossing rate, LCR, and
the average fade duration, AFD) are important design criteria and performance
measures for the wireless communication systems, including the equal gain
combining (EGC) systems in presence of the cochannel interference (CCI).
Although the analytical expressions for the outage probability of the coherent
EGC systems exposed to CCI and various fading channels are already known, the
respective ones for the average LCR and the AFD are not available in the
literature. This paper presents such analytical expressions for the Rayleigh
fading channel, which are obtained by utilizing a novel analytical approach
that does not require the explicit expression for the joint PDF of the
instantaneous output signal-to-interference ratio (SIR) and its time
derivative. Applying the characteristic function method and the Beaulieu
series, we determined the average LCR and the AFD at the output of an
interference-limited EGC system with an arbitrary diversity order and an
arbitrary number of cochannel interferers in forms of an infinite integral and
an infinite series. For the dual diversity case, the respective expressions are
derived in closed forms in terms of the gamma and the beta functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3552</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3552</id><created>2009-08-25</created><authors><author><keyname>Hadzi-Velkov</keyname><forenames>Zoran</forenames></author></authors><title>Level Crossing Rate and Average Fade Duration of Dual Selection
  Combining with Cochannel Interference and Nakagami Fading</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Wireless Communications, Volume 6, Issue 11,
  November 2007 Page(s):3870 - 3876</journal-ref><doi>10.1109/TWC.2007.060206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter provides closed-form expressions for the outage probability, the
average level crossing rate (LCR) and the average fade duration (AFD) of a dual
diversity selection combining (SC) system exposed to the combined influence of
the cochannel interference (CCI) and the thermal noise (AWGN) in Nakagami
fading channel. The branch selection is based on the desired signal power SC
algorithm with all input signals assumed to be independent, while the powers of
the desired signals in all diversity branches are mutually equal but distinct
from the power of the interference signals. The analytical results reduce to
known solutions in the cases of an interference-limited system in Rayleigh
fading and an AWGN-limited system in Nakagami fading. The average LCR is
determined by an original approach that does not require explicit knowledge of
the joint PDF of the envelope and its time derivative, which also paves the way
for similar analysis of other diversity systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3562</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3562</id><created>2009-08-25</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Another Look at the Physics of Large Deviations With Application to
  Rate-Distortion Theory</title><categories>cs.IT math.IT</categories><comments>10 pages, 2 figures, submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit and extend the physical interpretation recently given to a certain
identity between large--deviations rate--functions (as well as applications of
this identity to Information Theory), as an instance of thermal equilibrium
between several physical systems that are brought into contact. Our new
interpretation, of mechanical equilibrium between these systems, is shown to
have several advantages relative to that of thermal equilibrium. This physical
point of view also provides a trigger to the development of certain alternative
representations of the rate--distortion function and channel capacity, which
are new to the best knowledge of the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3565</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3565</id><created>2009-08-25</created><updated>2011-10-12</updated><authors><author><keyname>Guruprasad</keyname><forenames>K. R.</forenames></author><author><keyname>Ghose</keyname><forenames>Debasish</forenames></author></authors><title>Coverage Optimization using Generalized Voronoi Partition</title><categories>math.OC cs.SY math.DS</categories><comments>16 pages</comments><msc-class>37N35, 68W15, 93D20, 49J52</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a generalization of the Voronoi partition is used for optimal
deployment of autonomous agents carrying sensors with heterogeneous
capabilities, to maximize the sensor coverage. The generalized centroidal
Voronoi configuration, in which the agents are located at the centroids of the
corresponding generalized Voronoi cells, is shown to be a local optimal
configuration. Simulation results are presented to illustrate the presented
deployment strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3574</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3574</id><created>2009-08-25</created><updated>2010-01-19</updated><authors><author><keyname>Rothenberg</keyname><forenames>Christian Esteve</forenames></author><author><keyname>Macapuna</keyname><forenames>Carlos A.</forenames></author><author><keyname>Verdi</keyname><forenames>Fabio L.</forenames></author><author><keyname>Magalhaes</keyname><forenames>Mauricio F.</forenames></author><author><keyname>Wiesmaier</keyname><forenames>Alexander</forenames></author></authors><title>In-packet Bloom filters: Design and networking applications</title><categories>cs.DS cs.IT cs.NI cs.PF math.IT</categories><comments>15 pages, 11 figures, preprint submitted to Elsevier COMNET Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Bloom filter (BF) is a well-known space-efficient data structure that
answers set membership queries with some probability of false positives. In an
attempt to solve many of the limitations of current inter-networking
architectures, some recent proposals rely on including small BFs in packet
headers for routing, security, accountability or other purposes that move
application states into the packets themselves. In this paper, we consider the
design of such in-packet Bloom filters (iBF). Our main contributions are
exploring the design space and the evaluation of a series of extensions (1) to
increase the practicality and performance of iBFs, (2) to enable
false-negative-free element deletion, and (3) to provide security enhancements.
In addition to the theoretical estimates, extensive simulations of the multiple
design parameters and implementation alternatives validate the usefulness of
the extensions, providing for enhanced and novel iBF networking applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3587</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3587</id><created>2009-08-25</created><authors><author><keyname>S.</keyname><forenames>Siti Rahayu</forenames></author><author><keyname>Y.</keyname><forenames>Robiah</forenames></author><author><keyname>S.</keyname><forenames>Shahrin</forenames></author><author><keyname>A.</keyname><forenames>Faizal M.</forenames></author><author><keyname>M</keyname><forenames>Mohd Zaki</forenames></author><author><keyname>R</keyname><forenames>Irda</forenames></author></authors><title>Tracing Technique for Blaster Attack</title><categories>cs.CR</categories><comments>8 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Volume 4, No. 1, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blaster worm of 2003 is still persistent, the infection appears to have
successfully transitioned to new hosts as the original systems are cleaned or
shut off, suggesting that the Blaster worm, and other similar worms, will
remain significant Internet threats for many years after their initial release.
This paper is to propose technique on tracing the Blaster attack from various
logs in different OSI layers based on fingerprint of Blaster attack on victim
logs, attacker logs and IDS alert log. The researchers intended to do a
preliminary investigation upon this particular attack so that it can be used
for further research in alert correlation and computer forensic investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3610</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3610</id><created>2009-08-25</created><authors><author><keyname>Rohlf</keyname><forenames>Thimo</forenames></author><author><keyname>Winkler</keyname><forenames>Christopher R.</forenames></author></authors><title>Emergent Network Structure, evolvable Robustness and non-linear Effects
  of Point Mutations in an Artificial Genome Model</title><categories>q-bio.MN cond-mat.dis-nn cs.NE q-bio.GN q-bio.SC</categories><journal-ref>Advances in Complex Systems, Vol. 12, pp. 293 - 310 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genetic regulation is a key component in development, but a clear
understanding of the structure and dynamics of genetic networks is not yet at
hand. In this paper we investigate these properties within an artificial genome
model originally introduced by Reil (1999). We analyze statistical properties
of randomly generated genomes both on the sequence- and network level, and show
that this model correctly predicts the frequency of genes in genomes as found
in experimental data. Using an evolutionary algorithm based on stabilizing
selection for a phenotype, we show that dynamical robustness against single
base mutations, as well as against random changes in initial states of
regulatory dynamics that mimic stochastic fluctuations in environmental
conditions, can emerge in parallel. Point mutations at the sequence level have
strongly non-linear effects on network wiring, including as well structurally
neutral mutations and simultaneous rewiring of multiple connections, which
occasionally lead to strong reorganization of the attractor landscape and
metastability of evolutionary dynamics. Evolved genomes exhibit characteristic
patterns on both sequence and network level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3633</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3633</id><created>2009-08-25</created><authors><author><keyname>Das</keyname><forenames>Aparna</forenames></author><author><keyname>Mathieu</keyname><forenames>Claire</forenames></author><author><keyname>Ricketts</keyname><forenames>Daniel</forenames></author></authors><title>Maximizing profit using recommender systems</title><categories>cs.CY cs.AI cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional recommendation systems make recommendations based solely on the
customer's past purchases, product ratings and demographic data without
considering the profitability the items being recommended. In this work we
study the question of how a vendor can directly incorporate the profitability
of items into its recommender so as to maximize its expected profit while still
providing accurate recommendations. Our approach uses the output of any
traditional recommender system and adjust them according to item
profitabilities. Our approach is parameterized so the vendor can control how
much the recommendation incorporating profits can deviate from the traditional
recommendation. We study our approach under two settings and show that it
achieves approximately 22% more profit than traditional recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3634</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3634</id><created>2009-08-25</created><authors><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author><author><keyname>Dominguez</keyname><forenames>C&#xe9;sar</forenames></author></authors><title>A parameterization process as a categorical construction</title><categories>cs.LO math.CT</categories><proxy>ccsd hal-00411061</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parameterization process used in the symbolic computation systems Kenzo
and EAT is studied here as a general construction in a categorical framework.
This parameterization process starts from a given specification and builds a
parameterized specification by transforming some operations into parameterized
operations, which depend on one additional variable called the parameter. Given
a model of the parameterized specification, each interpretation of the
parameter, called an argument, provides a model of the given specification.
Moreover, under some relevant terminality assumption, this correspondence
between the arguments and the models of the given specification is a bijection.
It is proved in this paper that the parameterization process is provided by a
free functor and the subsequent parameter passing process by a natural
transformation. Various categorical notions are used, mainly adjoint functors,
pushouts and lax colimits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3650</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3650</id><created>2009-08-25</created><authors><author><keyname>Nakata</keyname><forenames>Keiko</forenames></author></authors><title>Lazy mixin modules and disciplined effects</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Programming languages are expected to support programmer's effort to
structure program code. The ML module system, object systems and mixins are
good examples of language constructs promoting modular programming. Among the
three, mixins can be thought of as a generalization of the two others in the
sense that mixins can incorporate features of ML modules and objects with a set
of primitive operators with clean semantics. Much work has been devoted to
build mixin-based module systems for practical programming languages. In
respect of the operational semantics, previous work notably investigated mixin
calculi in call-by-name and call-by-value evaluation settings. In this paper we
examine a mixin calculus in a call-by-need, or lazy, evaluation setting. We
demonstrate how lazy mixins can be interesting in practice with a series of
examples, and formalize the operational semantics by adapting Ancona and
Zucca's concise formalization of call-by-name mixins. We then extend the
semantics with constraints to control the evaluation order of components of
mixins in several ways. The main motivation for considering the constraints is
to produce side effects in a more explicit order than in a purely lazy,
demand-driven setting. We explore the design space of possibly interesting
constraints and consider two examples in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3652</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3652</id><created>2009-08-25</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tirsa</keyname><forenames>Eliana-Dina</forenames></author><author><keyname>Andreica</keyname><forenames>Cristina Teodora</forenames></author><author><keyname>Andreica</keyname><forenames>Romulus</forenames></author><author><keyname>Ungureanu</keyname><forenames>Mihai Aristotel</forenames></author></authors><title>Optimal Geometric Partitions, Covers and K-Centers</title><categories>cs.DS cs.CG</categories><comments>Extended version of the conference paper</comments><acm-class>F.2.2; I.3.5</acm-class><journal-ref>Proc. of the 9th WSEAS Intl. Conf. on Mathematics and Computers in
  Business and Economics (MCBE), pp. 173-178, Bucharest, Romania, 24-26 June,
  2008. (ISBN: 978-960-6766-76-3 / ISSN: 1790-5109)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present some new, practical, geometric optimization
techniques for computing polygon partitions, 1D and 2D point, interval, square
and rectangle covers, as well as 1D and 2D interval and rectangle K-centers.
All the techniques we present have immediate applications to several cost
optimization and facility location problems which are quite common in practice.
The main technique employed is dynamic programming, but we also make use of
efficient data structures and fast greedy algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3653</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3653</id><created>2009-08-25</created><authors><author><keyname>Bullen</keyname><forenames>Harry W.</forenames><suffix>IV</suffix></author><author><keyname>Ranjan</keyname><forenames>Priya</forenames></author></authors><title>Chaotic Transitions in Wall Following Robots</title><categories>nlin.CD cs.RO nlin.AO</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we examine how simple agents similar to Braitenberg vehicles
can exhibit chaotic movement patterns. The agents are wall following robots as
described by Steve Mesburger and Alfred Hubler in their paper &quot;Chaos in Wall
Following Robots&quot;. These agents uses a simple forward facing distance sensor,
with a limited field of view &quot;phi&quot; for navigation. An agent drives forward at a
constant velocity and uses the sensor to turn right when it is too close to an
object and left when it is too far away.
  For a flat wall the agent stays a fixed distance from the wall and travels
along it, regardless of the sensor's capabilities. But, if the wall represents
a periodic function, the agent drives on a periodic path when the sensor has a
narrow field of view. The agent's trajectory transitions to chaos when the
sensor's field of view is increased. Numerical experiments were performed with
square, triangle, and sawtooth waves for the wall, to find this pattern. The
bifurcations of the agents were analyzed, finding both border collision and
period doubling bifurcations. Detailed experimental results will be reported
separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3666</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3666</id><created>2009-08-25</created><authors><author><keyname>van Handel</keyname><forenames>Ramon</forenames></author></authors><title>On the minimal penalty for Markov order estimation</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>29 pages</comments><msc-class>62M05, 60E15, 60F15, 60G42, 60J10</msc-class><journal-ref>Probab. Th. Rel. Fields 150 (2011), pp. 709-738</journal-ref><doi>10.1007/s00440-010-0290-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that large-scale typicality of Markov sample paths implies that the
likelihood ratio statistic satisfies a law of iterated logarithm uniformly to
the same scale. As a consequence, the penalized likelihood Markov order
estimator is strongly consistent for penalties growing as slowly as log log n
when an upper bound is imposed on the order which may grow as rapidly as log n.
Our method of proof, using techniques from empirical process theory, does not
rely on the explicit expression for the maximum likelihood estimator in the
Markov case and could therefore be applicable in other settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3670</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3670</id><created>2009-08-25</created><updated>2010-04-04</updated><authors><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author></authors><title>Randomized Scheduling Algorithm for Queueing Networks</title><categories>cs.IT cs.NI math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has recently been considerable interest in design of low-complexity,
myopic, distributed and stable scheduling policies for constrained queueing
network models that arise in the context of emerging communication networks.
Here, we consider two representative models. One, a model for the collection of
wireless nodes communicating through a shared medium, that represents randomly
varying number of packets in the queues at the nodes of networks. Two, a
buffered circuit switched network model for an optical core of future Internet,
to capture the randomness in calls or flows present in the network. The maximum
weight scheduling policy proposed by Tassiulas and Ephremide in 1992 leads to a
myopic and stable policy for the packet-level wireless network model. But
computationally it is very expensive (NP-hard) and centralized. It is not
applicable to the buffered circuit switched network due to the requirement of
non-premption of the calls in the service. As the main contribution of this
paper, we present a stable scheduling algorithm for both of these models. The
algorithm is myopic, distributed and performs few logical operations at each
node per unit time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3689</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3689</id><created>2009-08-25</created><authors><author><keyname>Kandregula</keyname><forenames>Renuka</forenames></author></authors><title>A DHT Based Measure of Randomness</title><categories>cs.CR</categories><comments>15 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new discrete Hilbert transform (DHT) based measure of
randomness for discrete sequences. The measure has been used to test three
different classes of sequences with satisfactory results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3702</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3702</id><created>2009-08-25</created><authors><author><keyname>Park</keyname><forenames>Hong Ju</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Bit-Interleaved Coded Multiple Beamforming with Constellation Precoding</title><categories>cs.IT math.IT</categories><comments>submitted to conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the diversity order analysis of bit-interleaved
coded multiple beamforming (BICMB) combined with the constellation precoding
scheme. Multiple beamforming is realized by singular value decomposition of the
channel matrix which is assumed to be perfectly known to the transmitter as
well as the receiver. Previously, BICMB is known to have a diversity order
bound related with the product of the code rate and the number of parallel
subchannels, losing the full diversity order in some cases. In this paper, we
show that BICMB combined with the constellation precoder and maximum likelihood
detection achieves the full diversity order. We also provide simulation results
that match the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3706</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3706</id><created>2009-08-25</created><authors><author><keyname>Cuevas-Tello</keyname><forenames>Juan C.</forenames></author><author><keyname>Tino</keyname><forenames>Peter</forenames></author><author><keyname>Raychaudhury</keyname><forenames>Somak</forenames></author><author><keyname>Yao</keyname><forenames>Xin</forenames></author><author><keyname>Harva</keyname><forenames>Markus</forenames></author></authors><title>Uncovering delayed patterns in noisy and irregularly sampled time
  series: an astronomy application</title><categories>astro-ph.CO astro-ph.IM cs.LG cs.NE</categories><comments>36 pages, 10 figures, 16 tables, accepted for publication in Pattern
  Recognition. This is a shortened version of the article: interested readers
  are urged to refer to the published version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of estimating the time delay between two signals
representing delayed, irregularly sampled and noisy versions of the same
underlying pattern. We propose and demonstrate an evolutionary algorithm for
the (hyper)parameter estimation of a kernel-based technique in the context of
an astronomical problem, namely estimating the time delay between two
gravitationally lensed signals from a distant quasar. Mixed types (integer and
real) are used to represent variables within the evolutionary algorithm. We
test the algorithm on several artificial data sets, and also on real
astronomical observations of quasar Q0957+561. By carrying out a statistical
analysis of the results we present a detailed comparison of our method with the
most popular methods for time delay estimation in astrophysics. Our method
yields more accurate and more stable time delay estimates: for Q0957+561, we
obtain 419.6 days for the time delay between images A and B. Our methodology
can be readily applied to current state-of-the-art optical monitoring data in
astronomy, but can also be applied in other disciplines involving similar time
series data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3710</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3710</id><created>2009-08-25</created><authors><author><keyname>Gamal</keyname><forenames>Aly El</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>Randomization for Security in Half-Duplex Two-Way Gaussian Channels</title><categories>cs.IT cs.CR math.IT</categories><journal-ref>Globecom 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a new physical layer framework for secure two-way
wireless communication in the presence of a passive eavesdropper, i.e., Eve.
Our approach achieves perfect information theoretic secrecy via a novel
randomized scheduling and power allocation scheme. The key idea is to allow
Alice and Bob to send symbols at random time instants. While Alice will be able
to determine the symbols transmitted by Bob, Eve will suffer from ambiguity
regarding the source of any particular symbol. This desirable ambiguity is
enhanced, in our approach, by randomizing the transmit power level. Our
theoretical analysis, in a 2-D geometry, reveals the ability of the proposed
approach to achieve relatively high secure data rates under mild conditions on
the spatial location of Eve. These theoretical claims are then validated by
experimental results using IEEE 802.15.4-enabled sensor boards in different
configurations, motivated by the spatial characteristics of Wireless Body Area
Networks (WBAN).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3715</identifier>
 <datestamp>2013-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3715</id><created>2009-08-25</created><authors><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Youssef</keyname><forenames>Adel</forenames></author><author><keyname>Younis</keyname><forenames>Mohamed</forenames></author></authors><title>Overlapping Multi-hop Clustering for Wireless Sensor Networks</title><categories>cs.NI</categories><report-no>WINC-TR-1001</report-no><journal-ref>IEEE TPDS 2009</journal-ref><doi>10.1109/TPDS.2009.32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering is a standard approach for achieving efficient and scalable
performance in wireless sensor networks. Traditionally, clustering algorithms
aim at generating a number of disjoint clusters that satisfy some criteria. In
this paper, we formulate a novel clustering problem that aims at generating
overlapping multi-hop clusters. Overlapping clusters are useful in many sensor
network applications, including inter-cluster routing, node localization, and
time synchronization protocols. We also propose a randomized, distributed
multi-hop clustering algorithm (KOCA) for solving the overlapping clustering
problem. KOCA aims at generating connected overlapping clusters that cover the
entire sensor network with a specific average overlapping degree. Through
analysis and simulation experiments we show how to select the different values
of the parameters to achieve the clustering process objectives. Moreover, the
results show that KOCA produces approximately equal-sized clusters, which
allows distributing the load evenly over different clusters. In addition, KOCA
is scalable; the clustering formation terminates in a constant time regardless
of the network size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3716</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3716</id><created>2009-08-25</created><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>Carnival of Samplings: Nets, Approximations, Relative and Sensitive</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey several results known on sampling in computational geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3731</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3731</id><created>2009-08-26</created><updated>2009-09-23</updated><authors><author><keyname>Balakrishnan</keyname><forenames>Jennifer</forenames></author><author><keyname>Belding</keyname><forenames>Juliana</forenames></author><author><keyname>Chisholm</keyname><forenames>Sarah</forenames></author><author><keyname>Eisentraeger</keyname><forenames>Kirsten</forenames></author><author><keyname>Stange</keyname><forenames>Katherine</forenames></author><author><keyname>Teske</keyname><forenames>Edlyn</forenames></author></authors><title>Pairings on hyperelliptic curves</title><categories>math.NT cs.CR math.AG</categories><comments>v2: with corrections and improvements in sections 4 and 5</comments><msc-class>14G50, 94A60</msc-class><journal-ref>Fields Institute Communications 60 (2011) 87-120</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We assemble and reorganize the recent work in the area of hyperelliptic
pairings: We survey the research on constructing hyperelliptic curves suitable
for pairing-based cryptography. We also showcase the hyperelliptic pairings
proposed to date, and develop a unifying framework. We discuss the techniques
used to optimize the pairing computation on hyperelliptic curves, and present
many directions for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3737</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3737</id><created>2009-08-26</created><authors><author><keyname>Dominguez</keyname><forenames>Cesar</forenames><affiliation>LJK</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author></authors><title>Diagrammatic logic applied to a parameterization process</title><categories>cs.LO math.CT</categories><proxy>ccsd hal-00411069</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an abstract definition of some kinds of logics, called
diagrammatic logics, together with a definition of morphisms and of 2-morphisms
between diagrammatic logics. The definition of the 2-category of diagrammatic
logics rely on category theory, mainly on adjunction, categories of fractions
and limit sketches. This framework is applied to the formalization of a
parameterization process. This process, which consists in adding a formal
parameter to some operations in a given specification, is presented as a
morphism of logics. Then the parameter passing process, for recovering a model
of the given specification from a model of the parameterized specification and
an actual parameter, is seen as a 2-morphism of logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3740</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3740</id><created>2009-08-26</created><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Post</keyname><forenames>Ian</forenames></author></authors><title>An Oblivious O(1)-Approximation for Single Source Buy-at-Bulk</title><categories>cs.DS cs.DM</categories><comments>22 pages, 1 figure To appear in the proceedings of the 50th annual
  IEEE Symposium on Foundations of Computer Science (FOCS 2009)</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the single-source (or single-sink) buy-at-bulk problem with an
unknown concave cost function. We want to route a set of demands along a graph
to or from a designated root node, and the cost of routing x units of flow
along an edge is proportional to some concave, non-decreasing function f such
that f(0) = 0. We present a polynomial time algorithm that finds a distribution
over trees such that the expected cost of a tree for any f is within an
O(1)-factor of the optimum cost for that f. The previous best simultaneous
approximation for this problem, even ignoring computation time, was O(log |D|),
where D is the multi-set of demand nodes.
  We design a simple algorithmic framework using the ellipsoid method that
finds an O(1)-approximation if one exists, and then construct a separation
oracle using a novel adaptation of the Guha, Meyerson, and Munagala algorithm
for the single-sink buy-at-bulk problem that proves an O(1) approximation is
possible for all f. The number of trees in the support of the distribution
constructed by our algorithm is at most 1+log |D|.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3784</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3784</id><created>2009-08-26</created><authors><author><keyname>Kari</keyname><forenames>Jarkko</forenames></author><author><keyname>Kazda</keyname><forenames>Alexandr</forenames></author><author><keyname>Steinby</keyname><forenames>Paula</forenames></author></authors><title>On Continuous Weighted Finite Automata</title><categories>cs.FL</categories><comments>41 pages, 9 figures</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the continuity of the \omega-functions and real functions
defined by weighted finite automata (WFA). We concentrate on the case of
average preserving WFA. We show that every continuous \omega-function definable
by some WFA can be defined by an average preserving WFA and then characterize
minimal average preserving WFA whose \omega-function or \omega-function and
real function are continuous.
  We obtain several algorithmic reductions for WFA-related decision problems.
In particular, we show that deciding whether the \omega-function and real
function of an average preserving WFA are both continuous is computationally
equivalent to deciding stability of a set of matrices.
  We also present a method for constructing WFA that compute continuous real
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3850</identifier>
 <datestamp>2010-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3850</id><created>2009-08-26</created><updated>2010-06-03</updated><authors><author><keyname>Watanabe</keyname><forenames>Yusuke</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author></authors><title>New graph polynomials from the Bethe approximation of the Ising
  partition function</title><categories>math.CO cs.DM</categories><comments>To appear in Combinatorics, Probability &amp; Computing. Revised from the
  first version, 28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce two graph polynomials and discuss their properties. One is a
polynomial of two variables whose investigation is motivated by the performance
analysis of the Bethe approximation of the Ising partition function. The other
is a polynomial of one variable that is obtained by the specialization of the
first one. It is shown that these polynomials satisfy deletion-contraction
relations and are new examples of the V-function, which was introduced by Tutte
(1947, Proc. Cambridge Philos. Soc. 43, 26-40). For these polynomials, we
discuss the interpretations of special values and then obtain the bound on the
number of sub-coregraphs, i.e., spanning subgraphs with no vertices of degree
one. It is proved that the polynomial of one variable is equal to the
monomer-dimer partition function with weights parameterized by that variable.
The properties of the coefficients and the possible region of zeros are also
discussed for this polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3855</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3855</id><created>2009-08-26</created><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Gabor wavelet analysis and the fractional Hilbert transform</title><categories>cs.IT cs.CV math.IT</categories><comments>7 pages, 1 figure</comments><journal-ref>SPIE Proceedings: Wavelets XIII 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an amplitude-phase representation of the dual-tree complex wavelet
transform (DT-CWT) which provides an intuitive interpretation of the associated
complex wavelet coefficients. The representation, in particular, is based on
the shifting action of the group of fractional Hilbert transforms (fHT) which
allow us to extend the notion of arbitrary phase-shifts beyond pure sinusoids.
We explicitly characterize this shifting action for a particular family of
Gabor-like wavelets which, in effect, links the corresponding dual-tree
transform with the framework of windowed-Fourier analysis.
  We then extend these ideas to the bivariate DT-CWT based on certain
directional extensions of the fHT. In particular, we derive a signal
representation involving the superposition of direction-selective wavelets
affected with appropriate phase-shifts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3861</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3861</id><created>2009-08-26</created><updated>2009-08-27</updated><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author><author><keyname>Barrutia</keyname><forenames>Arrate Munoz</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Fast adaptive elliptical filtering using box splines</title><categories>cs.IT cs.CV math.IT</categories><comments>9 pages, 1 figure</comments><journal-ref>Proceedings IEEE International Conference on Image Processing,
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that it is possible to filter an image with an elliptic window
of varying size, elongation and orientation with a fixed computational cost per
pixel. Our method involves the application of a suitable global pre-integrator
followed by a pointwise-adaptive localization mesh. We present the basic theory
for the 1D case using a B-spline formalism and then appropriately extend it to
2D using radially-uniform box splines. The size and ellipticity of these
radially-uniform box splines is adaptively controlled. Moreover, they converge
to Gaussians as the order increases. Finally, we present a fast and practical
directional filtering algorithm that has the capability of adapting to the
local image features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3886</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3886</id><created>2009-08-26</created><authors><author><keyname>Draper</keyname><forenames>Stark C.</forenames></author><author><keyname>Liu</keyname><forenames>Lingjia</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author><author><keyname>Yedidia</keyname><forenames>Jonathan S.</forenames></author></authors><title>Cooperative Routing for Wireless Networks using Mutual-Information
  Accumulation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperation between the nodes of wireless multihop networks can increase
communication reliability, reduce energy consumption, and decrease latency. The
possible improvements are even greater when nodes perform mutual information
accumulation using rateless codes. In this paper, we investigate routing
problems in such networks. Given a network, a source, and a destination, our
objective is to minimize end-to-end transmission delay under energy and
bandwidth constraints. We provide an algorithm that determines which nodes
should participate in forwarding the message and what resources (time, energy,
bandwidth) should be allocated to each.
  Our approach factors into two sub-problems, each of which can be solved
efficiently. For any transmission order we show that solving for the optimum
resource allocation can be formulated as a linear programming problem. We then
show that the transmission order can be improved systematically by swapping
nodes based on the solution of the linear program. Solving a sequence of linear
programs leads to a locally optimal solution in a very efficient manner. In
comparison to the proposed cooperative routing solution, it is observed that
conventional shortest path multihop routing typically incurs additional delays
and energy expenditures on the order of 70%.
  Our first algorithm is centralized, assuming that routing computations can be
done at a central processor with full access to channel state information for
the entire system. We also design two distributed routing algorithms that
require only local channel state information. We provide simulations showing
that for the same networks the distributed algorithms find routes that are only
about two to five percent less efficient than the centralized algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3889</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3889</id><created>2009-08-26</created><updated>2009-08-27</updated><authors><author><keyname>Herrmann</keyname><forenames>Frank</forenames></author><author><keyname>Silberholz</keyname><forenames>John</forenames></author><author><keyname>Bellone</keyname><forenames>Matias</forenames></author><author><keyname>Guerberoff</keyname><forenames>Gustavo</forenames></author><author><keyname>Tiglio</keyname><forenames>Manuel</forenames></author></authors><title>Integrating Post-Newtonian Equations on Graphics Processing Units</title><categories>gr-qc astro-ph.CO astro-ph.EP astro-ph.GA astro-ph.HE astro-ph.IM astro-ph.SR cs.DC cs.GR cs.PF</categories><comments>Added one reference</comments><journal-ref>Class.Quant.Grav.27:032001,2010</journal-ref><doi>10.1088/0264-9381/27/3/032001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on early results of a numerical and statistical study of binary
black hole inspirals. The two black holes are evolved using post-Newtonian
approximations starting with initially randomly distributed spin vectors. We
characterize certain aspects of the distribution shortly before merger. In
particular we note the uniform distribution of black hole spin vector dot
products shortly before merger and a high correlation between the initial and
final black hole spin vector dot products in the equal-mass, maximally spinning
case. These simulations were performed on Graphics Processing Units, and we
demonstrate a speed-up of a factor 50 over a more conventional CPU
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3902</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3902</id><created>2009-08-26</created><authors><author><keyname>Hollestelle</keyname><forenames>Harm</forenames></author></authors><title>On the Expressiveness of Line Drawings</title><categories>cs.OH cs.NE</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can expressiveness of a drawing be traced with a computer? In this study a
neural network (perceptron) and a support vector machine are used to classify
line drawings. To do this the line drawings are attributed values according to
a kinematic model and a diffusion model for the lines they consist of. The
values for both models are related to looking times. Extreme values according
to these models, that is both extremely short and extremely long looking times,
are interpreted as indicating expressiveness. The results strongly indicate
that expressiveness in this sense can be detected, at least with a neural
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3911</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3911</id><created>2009-08-27</created><authors><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author><author><keyname>Tejada</keyname><forenames>Pedro J.</forenames></author></authors><title>Spreading grid cells</title><categories>cs.CG cs.DM</categories><journal-ref>Minghui Jiang, Vincent Pilaud, and Pedro J. Tejada. On a
  dispersion problem in grid labeling. In Proceedings of the 22nd Canadian
  Conference on Computational Geometry (CCCG 2010), pages 75-78</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $S$ be a set of $n^2$ symbols. Let $A$ be an $n\times n$ square grid with
each cell labeled by a distinct symbol in $S$. Let $B$ be another $n\times n$
square grid, also with each cell labeled by a distinct symbol in $S$. Then each
symbol in $S$ labels two cells, one in $A$ and one in $B$. Define the
\emph{combined distance} between two symbols in $S$ as the distance between the
two cells in $A$ plus the distance between the two cells in $B$ that are
labeled by the two symbols. Bel\'en Palop asked the following question at the
open problems session of CCCG 2009: How to arrange the symbols in the two grids
such that the minimum combined distance between any two symbols is maximized?
In this paper, we give a partial answer to Bel\'en Palop's question.
  Define $c_p(n) = \max_{A,B}\min_{s,t \in S} \{\dist_p(A,s,t) + \dist_p(B,s,t)
\}$, where $A$ and $B$ range over all pairs of $n\times n$ square grids labeled
by the same set $S$ of $n^2$ distinct symbols, and where $\dist_p(A,s,t)$ and
$\dist_p(B,s,t)$ are the $L_p$ distances between the cells in $A$ and in $B$,
respectively, that are labeled by the two symbols $s$ and $t$. We present
asymptotically optimal bounds $c_p(n) = \Theta(\sqrt{n})$ for all
$p=1,2,...,\infty$. The bounds also hold for generalizations to $d$-dimensional
grids for any constant $d \ge 2$. Our proof yields a simple linear-time
constant-factor approximation algorithm for maximizing the minimum combined
distance between any two symbols in two grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3916</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3916</id><created>2009-08-26</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Graph-Theoretic Solutions to Computational Geometry Problems</title><categories>cs.CG</categories><comments>16 pages, 7 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems in computational geometry are not stated in graph-theoretic
terms, but can be solved efficiently by constructing an auxiliary graph and
performing a graph-theoretic algorithm on it. Often, the efficiency of the
algorithm depends on the special properties of the graph constructed in this
way. We survey the art gallery problem, partition into rectangles,
minimum-diameter clustering, rectilinear cartogram construction, mesh
stripification, angle optimization in tilings, and metric embedding from this
perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3929</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3929</id><created>2009-08-26</created><authors><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Bopardikar</keyname><forenames>Shaunak D.</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>A Dynamic Boundary Guarding Problem with Translating Targets</title><categories>cs.RO</categories><comments>Extended version of paper for the joint 48th IEEE Conference on
  Decision and Control and 28th Chinese Control Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a problem in which a service vehicle seeks to guard a deadline
(boundary) from dynamically arriving mobile targets. The environment is a
rectangle and the deadline is one of its edges. Targets arrive continuously
over time on the edge opposite the deadline, and move towards the deadline at a
fixed speed. The goal for the vehicle is to maximize the fraction of targets
that are captured before reaching the deadline. We consider two cases; when the
service vehicle is faster than the targets, and; when the service vehicle is
slower than the targets. In the first case we develop a novel vehicle policy
based on computing longest paths in a directed acyclic graph. We give a lower
bound on the capture fraction of the policy and show that the policy is optimal
when the distance between the target arrival edge and deadline becomes very
large. We present numerical results which suggest near optimal performance away
from this limiting regime. In the second case, when the targets are slower than
the vehicle, we propose a policy based on servicing fractions of the
translational minimum Hamiltonian path. In the limit of low target speed and
high arrival rate, the capture fraction of this policy is within a small
constant factor of the optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3930</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3930</id><created>2009-08-26</created><authors><author><keyname>Sirivianos</keyname><forenames>Michael</forenames></author><author><keyname>Yang</keyname><forenames>Xiaowei</forenames></author><author><keyname>Kim</keyname><forenames>Kyungbaek</forenames></author></authors><title>SocialFilter: Collaborative Spam Mitigation using Social Networks</title><categories>cs.CR cs.DC</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam mitigation can be broadly classified into two main approaches: a)
centralized security infrastructures that rely on a limited number of trusted
monitors to detect and report malicious traffic; and b) highly distributed
systems that leverage the experiences of multiple nodes within distinct trust
domains. The first approach offers limited threat coverage and slow response
times, and it is often proprietary. The second approach is not widely adopted,
partly due to the lack of guarantees regarding the trustworthiness of nodes
that comprise the system.
  Our proposal, SocialFilter, aims to achieve the trustworthiness of
centralized security services and the wide coverage, responsiveness and
inexpensiveness of large-scale collaborative spam mitigation. We propose a
large-scale distributed system that enables clients with no email
classification functionality to query the network on the behavior of a host. A
SocialFilter node builds trust for its peers by auditing their behavioral
reports and by leveraging the social network of SocialFilter administrators.
The node combines the confidence its peers have in their own reports and the
trust it places on its peers to derive the likelihood that a host is spamming.
  The simulation-based evaluation of our approach indicates its potential under
a real-world deployment: during a simulated spam campaign, SocialFilternodes
characterized 92% of spam bot connections with confidence greater than 50%,
while yielding no false positives
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3954</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3954</id><created>2009-08-27</created><authors><author><keyname>Goldsztejn</keyname><forenames>Alexandre</forenames><affiliation>LINA</affiliation></author></authors><title>On the Exponentiation of Interval Matrices</title><categories>cs.NA cs.CC math.NA</categories><proxy>ccsd hal-00411330</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The numerical computation of the exponentiation of a real matrix has been
intensively studied. The main objective of a good numerical method is to deal
with round-off errors and computational cost. The situation is more complicated
when dealing with interval matrices exponentiation: Indeed, the main problem
will now be the dependency loss of the different occurrences of the variables
due to interval evaluation, which may lead to so wide enclosures that they are
useless. In this paper, the problem of computing a sharp enclosure of the
interval matrix exponential is proved to be NP-hard. Then the scaling and
squaring method is adapted to interval matrices and shown to drastically reduce
the dependency loss w.r.t. the interval evaluation of the Taylor series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3957</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3957</id><created>2009-08-27</created><authors><author><keyname>Mahboubi</keyname><forenames>Hadj</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Enhancing XML Data Warehouse Query Performance by Fragmentation</title><categories>cs.DB</categories><proxy>ccsd hal-00411232</proxy><journal-ref>24th Annual ACM Symposium on Applied Computing (SAC 09), Hawaii :
  United States (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML data warehouses form an interesting basis for decision-support
applications that exploit heterogeneous data from multiple sources. However,
XML-native database systems currently suffer from limited performances in terms
of manageable data volume and response time for complex analytical queries.
Fragmenting and distributing XML data warehouses (e.g., on data grids) allow to
address both these issues. In this paper, we work on XML warehouse
fragmentation. In relational data warehouses, several studies recommend the use
of derived horizontal fragmentation. Hence, we propose to adapt it to the XML
context. We particularly focus on the initial horizontal fragmentation of
dimensions' XML documents and exploit two alternative algorithms. We
experimentally validate our proposal and compare these alternatives with
respect to a unified XML warehouse model we advocate for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3981</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3981</id><created>2009-08-27</created><authors><author><keyname>Mozeika</keyname><forenames>Alexander</forenames></author><author><keyname>Saad</keyname><forenames>David</forenames></author><author><keyname>Raymond</keyname><forenames>Jack</forenames></author></authors><title>Computing with Noise - Phase Transitions in Boolean Formulas</title><categories>cond-mat.dis-nn cs.CC</categories><comments>10 pages, 2 figures</comments><doi>10.1103/PhysRevLett.103.248701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing circuits composed of noisy logical gates and their ability to
represent arbitrary Boolean functions with a given level of error are
investigated within a statistical mechanics setting. Bounds on their
performance, derived in the information theory literature for specific gates,
are straightforwardly retrieved, generalized and identified as the
corresponding typical-case phase transitions. This framework paves the way for
obtaining new results on error-rates, function-depth and sensitivity, and their
dependence on the gate-type and noise model used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3982</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3982</id><created>2009-08-27</created><updated>2010-01-13</updated><authors><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Distributed Source Coding for Correlated Memoryless Gaussian Sources</title><categories>cs.IT math.IT</categories><comments>23 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a distributed source coding problem of $L$ correlated Gaussian
observations $Y_i, i=1,2,...,L$. We assume that the random vector
$Y^{L}={}^{\rm t} (Y_1,Y_2,$ $...,Y_L)$ is an observation of the Gaussian
random vector $X^K={}^{\rm t}(X_1,X_2,...,X_K)$, having the form $Y^L=AX^K+N^L
,$ where $A$ is a $L\times K$ matrix and $N^L={}^{\rm t}(N_1,N_2,...,N_L)$ is a
vector of $L$ independent Gaussian random variables also independent of $X^K$.
The estimation error on $X^K$ is measured by the distortion covariance matrix.
The rate distortion region is defined by a set of all rate vectors for which
the estimation error is upper bounded by an arbitrary prescribed covariance
matrix in the meaning of positive semi definite. In this paper we derive
explicit outer and inner bounds of the rate distortion region. This result
provides a useful tool to study the direct and indirect source coding problems
on this Gaussian distributed source coding system, which remain open in
general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3994</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3994</id><created>2009-08-27</created><authors><author><keyname>Mimram</keyname><forenames>Samuel</forenames><affiliation>PPS</affiliation></author></authors><title>The Structure of First-Order Causality</title><categories>cs.LO math.CT math.LO</categories><proxy>ccsd inria-00411399</proxy><journal-ref>Logic in Computer Science, Los Angeles : United States (2009)</journal-ref><doi>10.1109/LICS.2009.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game semantics describe the interactive behavior of proofs by interpreting
formulas as games on which proofs induce strategies. Such a semantics is
introduced here for capturing dependencies induced by quantifications in
first-order propositional logic. One of the main difficulties that has to be
faced during the elaboration of this kind of semantics is to characterize
definable strategies, that is strategies which actually behave like a proof.
This is usually done by restricting the model to strategies satisfying subtle
combinatorial conditions, whose preservation under composition is often
difficult to show. Here, we present an original methodology to achieve this
task, which requires to combine advanced tools from game semantics, rewriting
theory and categorical algebra. We introduce a diagrammatic presentation of the
monoidal category of definable strategies of our model, by the means of
generators and relations: those strategies can be generated from a finite set
of atomic strategies and the equality between strategies admits a finite
axiomatization, this equational structure corresponding to a polarized
variation of the notion of bialgebra. This work thus bridges algebra and
denotational semantics in order to reveal the structure of dependencies induced
by first-order quantifiers, and lays the foundations for a mechanized analysis
of causality in programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.3999</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.3999</id><created>2009-08-27</created><authors><author><keyname>Zhu</keyname><forenames>Ping</forenames></author></authors><title>An improved axiomatic definition of information granulation</title><categories>cs.AI</categories><comments>10 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  To capture the uncertainty of information or knowledge in information
systems, various information granulations, also known as knowledge
granulations, have been proposed. Recently, several axiomatic definitions of
information granulation have been introduced. In this paper, we try to improve
these axiomatic definitions and give a universal construction of information
granulation by relating information granulations with a class of functions of
multiple variables. We show that the improved axiomatic definition has some
concrete information granulations in the literature as instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4005</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4005</id><created>2009-08-27</created><authors><author><keyname>Nataf</keyname><forenames>Emmanuel</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Festor</keyname><forenames>Olivier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>jYang : A YANG parser in java</title><categories>cs.PL cs.NI</categories><proxy>ccsd inria-00411261</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The NETCONF con?guration protocol of the IETF Network Work- ing Group
provides mechanisms to manipulate the con?guration of network devices. YANG is
the language currently under consideration within the IETF to specify the data
models to be used in NETCONF . This report describes the design and development
of a syntax and semantics parser for YANG in java.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4013</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4013</id><created>2009-08-27</created><updated>2009-09-07</updated><authors><author><keyname>B&#xe1;tfai</keyname><forenames>Norbert</forenames></author></authors><title>Recombinations of Busy Beaver Machines</title><categories>cs.CC</categories><comments>15 pages, 11 figures; added new recombinated M_PP(4097) machines</comments><acm-class>D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many programmers belive that Turing-based machines cannot think. We also
believe in this, however it is interesting to note that the most sophisticated
machines are not programmed by human beings. We have only discovered them. In
this paper, using well-known Busy Beaver and Placid Platypus machines, we
generate further very similar, but not exactly the same machines. We have found
a recombinated BB_5 machine which can make 70.740.809 steps before halting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4016</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4016</id><created>2009-08-27</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Tankus</keyname><forenames>David</forenames></author></authors><title>On Relating Edges in Graphs without Cycles of Length 4</title><categories>cs.DM cs.CC</categories><comments>6 pages, 1 figure</comments><acm-class>G.2.2; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An edge xy is relating in the graph G if there is an independent set S,
containing neither x nor y, such that S_{x} and S_{y} are both maximal
independent sets in G. It is an NP-complete problem to decide whether an edge
is relating (Brown, Nowakowski, Zverovich, 2007). We show that the problem
remains NP-complete even for graphs without cycles of length 4 and 5. On the
other hand, for graphs without cycles of length 4 and 6, the problem can be
solved in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4041</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4041</id><created>2009-08-27</created><authors><author><keyname>Bagheri</keyname><forenames>Alireza</forenames></author><author><keyname>Razzazi</keyname><forenames>Mohammadreza</forenames></author></authors><title>Complexity of Planar Embeddability of Trees inside Simple Polygons</title><categories>cs.CG cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric embedding of graphs in a point set in the plane is a well known
problem. In this paper, the complexity of a variant of this problem, where the
point set is bounded by a simple polygon, is considered. Given a point set in
the plane bounded by a simple polygon and a free tree, we show that deciding
whether there is a planar straight-line embedding of the tree on the point set
inside the simple polygon is NP-complete. This implies that the straight-line
constrained point-set embedding of trees is also NP-complete, which was posed
as an open problem in [8].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4051</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4051</id><created>2009-08-27</created><authors><author><keyname>Chandar</keyname><forenames>Venkat</forenames></author><author><keyname>Tchamkerten</keyname><forenames>Aslan</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory W.</forenames></author></authors><title>Training-Based Schemes are Suboptimal for High Rate Asynchronous
  Communication</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2009 IEEE Information Theory
  Workshop (Taormina)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider asynchronous point-to-point communication. Building on a recently
developed model, we show that training based schemes, i.e., communication
strategies that separate synchronization from information transmission, perform
suboptimally at high rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4061</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4061</id><created>2009-08-27</created><updated>2009-08-31</updated><authors><author><keyname>Sharir</keyname><forenames>Micha</forenames></author><author><keyname>Shaul</keyname><forenames>Hayim</forenames></author></authors><title>Semi-algebraic Range Reporting and Emptiness Searching with Applications</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a typical range emptiness searching (resp., reporting) problem, we are
given a set $P$ of $n$ points in $\reals^d$, and wish to preprocess it into a
data structure that supports efficient range emptiness (resp., reporting)
queries, in which we specify a range $\sigma$, which, in general, is a
semi-algebraic set in $\reals^d$ of constant description complexity, and wish
to determine whether $P\cap\sigma=\emptyset$, or to report all the points in
$P\cap\sigma$. Range emptiness searching and reporting arise in many
applications, and have been treated by Matou\v{s}ek \cite{Ma:rph} in the
special case where the ranges are halfspaces bounded by hyperplanes. As shown
in \cite{Ma:rph}, the two problems are closely related, and have solutions (for
the case of halfspaces) with similar performance bounds. In this paper we
extend the analysis to general semi-algebraic ranges, and show how to adapt
Matou\v{s}ek's technique, without the need to {\em linearize} the ranges into a
higher-dimensional space. This yields more efficient solutions to several
useful problems, and we demonstrate the new technique in four applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4062</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4062</id><created>2009-08-27</created><authors><author><keyname>Kejgir</keyname><forenames>Sushma</forenames></author><author><keyname>Kokare</keyname><forenames>Manesh</forenames></author></authors><title>Optimization of Bit Plane Combination for Efficient Digital Image
  Watermarking</title><categories>cs.CR cs.MM</categories><comments>10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; No. 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In view of the frequent multimedia data transfer authentication and
protection of images has gained importance in todays world. In this paper we
propose a new watermarking technique, based on bit plane, which enhances
robustness and capacity of the watermark, as well as maintains transparency of
the watermark and fidelity of the image. In the proposed technique, higher
strength bit plane of digital signature watermark is embedded in to a
significant bit plane of the original image. The combination of bit planes
(image and watermark) selection is an important issue. Therefore, a mechanism
is developed for appropriate bit plane selection. Ten different attacks are
selected to test different alternatives. These attacks are given different
weightings as appropriate to user requirement. A weighted correlation
coefficient for retrieved watermark is estimated for each of the alternatives.
Based on these estimated values optimal bit plane combination is identified for
a given user requirement. The proposed method is found to be useful for
authentication and to prove legal ownership. We observed better results by our
proposed method in comparison with the previously reported work on pseudorandom
watermark embedded in least significant bit (LSB) plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4073</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4073</id><created>2009-08-27</created><authors><author><keyname>Jung</keyname><forenames>Kyomin</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author></authors><title>Distributed Averaging via Lifted Markov Chains</title><categories>cs.IT cs.DC math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications of distributed linear estimation, distributed
control and distributed optimization, we consider the question of designing
linear iterative algorithms for computing the average of numbers in a network.
Specifically, our interest is in designing such an algorithm with the fastest
rate of convergence given the topological constraints of the network. As the
main result of this paper, we design an algorithm with the fastest possible
rate of convergence using a non-reversible Markov chain on the given network
graph. We construct such a Markov chain by transforming the standard Markov
chain, which is obtained using the Metropolis-Hastings method. We call this
novel transformation pseudo-lifting. We apply our method to graphs with
geometry, or graphs with doubling dimension. Specifically, the convergence time
of our algorithm (equivalently, the mixing time of our Markov chain) is
proportional to the diameter of the network graph and hence optimal. As a
byproduct, our result provides the fastest mixing Markov chain given the
network topological constraints, and should naturally find their applications
in the context of distributed optimization, estimation and control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4074</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4074</id><created>2009-08-27</created><authors><author><keyname>Maheswary</keyname><forenames>Priti</forenames></author><author><keyname>Srivastava</keyname><forenames>Namita</forenames></author></authors><title>Retrieval of Remote Sensing Images Using Colour and Texture Attribute</title><categories>cs.IR cs.MM</categories><comments>5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; No. 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grouping images into semantically meaningful categories using low-level
visual feature is a challenging and important problem in content-based image
retrieval. The groupings can be used to build effective indices for an image
database. Digital image analysis techniques are being used widely in remote
sensing assuming that each terrain surface category is characterized with
spectral signature observed by remote sensors. Even with the remote sensing
images of IRS data, integration of spatial information is expected to assist
and to improve the image analysis of remote sensing data. In this paper we
present a satellite image retrieval based on a mixture of old fashioned ideas
and state of the art learning tools. We have developed a methodology to
classify remote sensing images using HSV color features and Haar wavelet
texture features and then grouping them on the basis of particular threshold
value. The experimental results indicate that the use of color and texture
feature extraction is very useful for image retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4094</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4094</id><created>2009-08-27</created><updated>2010-10-22</updated><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author></authors><title>Codes in Permutations and Error Correction for Rank Modulation</title><categories>cs.IT math.IT</categories><comments>Some typos corrected from the published journal version</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 56, Issue 7, July
  2010, pp. 3158 - 3165</journal-ref><doi>10.1109/TIT.2010.2048455</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes for rank modulation have been recently proposed as a means of
protecting flash memory devices from errors. We study basic coding theoretic
problems for such codes, representing them as subsets of the set of
permutations of $n$ elements equipped with the Kendall tau distance. We derive
several lower and upper bounds on the size of codes. These bounds enable us to
establish the exact scaling of the size of optimal codes for large values of
$n$. We also show the existence of codes whose size is within a constant factor
of the sphere packing bound for any fixed number of errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4116</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4116</id><created>2009-08-27</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Tamassia</keyname><forenames>Roberto</forenames></author><author><keyname>Triandopoulos</keyname><forenames>Nikos</forenames></author></authors><title>Efficient Authenticated Data Structures for Graph Connectivity and
  Geometric Search Problems</title><categories>cs.CR cs.DS</categories><comments>Full version of related paper appearing in CT-RSA 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Authenticated data structures provide cryptographic proofs that their answers
are as accurate as the author intended, even if the data structure is being
controlled by a remote untrusted host. We present efficient techniques for
authenticating data structures that represent graphs and collections of
geometric objects. We introduce the path hash accumulator, a new primitive
based on cryptographic hashing for efficiently authenticating various
properties of structured data represented as paths, including any decomposable
query over sequences of elements. We show how to employ our primitive to
authenticate queries about properties of paths in graphs and search queries on
multi-catalogs. This allows the design of new, efficient authenticated data
structures for fundamental problems on networks, such as path and connectivity
queries over graphs, and complex queries on two-dimensional geometric objects,
such as intersection and containment queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4144</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4144</id><created>2009-08-28</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>ABC-LogitBoost for Multi-class Classification</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop abc-logitboost, based on the prior work on abc-boost and robust
logitboost. Our extensive experiments on a variety of datasets demonstrate the
considerable improvement of abc-logitboost over logitboost and abc-mart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4188</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4188</id><created>2009-08-28</created><authors><author><keyname>Saha</keyname><forenames>Suman</forenames></author></authors><title>Consideration Points Detecting Cross-Site Scripting</title><categories>cs.CR cs.PL</categories><comments>8 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web application (WA) expands its usages to provide more and more services and
it has become one of the most essential communication channels between service
providers and the users. To augment the users experience many web applications
are using client side scripting languages such as JavaScript but this growing
of JavaScript is increasing serious security vulnerabilities in web application
too, such as cross site scripting (XSS). In this paper, I survey all the
techniques those have been used to detect XSS and arrange a number of analyses
to evaluate performances of those methodologies. This paper points major
difficulties to detect XSS. I do not implement any solution of this
vulnerability problem because my focus is for reviewing this issue. But, I
believe that this assessment will be cooperative for further research on this
concern as this treatise figure out everything on this transcendent security
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4208</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4208</id><created>2009-08-28</created><authors><author><keyname>Ksairi</keyname><forenames>Nassar</forenames></author><author><keyname>Ciblat</keyname><forenames>Philippe</forenames></author><author><keyname>Bianchi</keyname><forenames>Pascal</forenames></author><author><keyname>Hachem</keyname><forenames>Walid</forenames></author></authors><title>Performance Analysis over Slow Fading Channels of a Half-Duplex
  Single-Relay Protocol: Decode or Quantize and Forward</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new static relaying protocol is introduced for half duplex
single-relay networks, and its performance is studied in the context of
communications over slow fading wireless channels. The proposed protocol is
based on a Decode or Quantize and Forward (DoQF) approach. In slow fading
scenarios, two performance metrics are relevant and complementary, namely the
outage probability gain and the Diversity-Multiplexing Tradeoff (DMT).
  First, we analyze the behavior of the outage probability P_o associated with
the proposed protocol as the SNR tends to infinity. In this case, we prove that
SNR^2 P_o converges to a constant. We refer to this constant as the outage gain
and we derive its closed-form expression for a general class of wireless
channels that includes the Rayleigh and the Rice channels as particular cases.
We furthermore prove that the DoQF protocol has the best achievable outage gain
in the wide class of half-duplex static relaying protocols. A method for
minimizing the outage gain with respect to the power distribution between the
source and the relay, and with respect to the durations of the slots is also
provided.
  Next, we focus on Rayleigh distributed fading channels to derive the DMT
associated with the proposed DoQF protocol. Our results show that the DMT of
DoQF achieves the 2 by 1 MISO upper-bound for multiplexing gains r &lt; 0.25.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4211</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4211</id><created>2009-08-28</created><authors><author><keyname>Kong</keyname><forenames>Zhenning</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Coding Improves the Throughput-Delay Trade-off in Mobile Wireless
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the throughput-delay performance tradeoff in large-scale wireless ad
hoc networks. It has been shown that the per source-destination pair throughput
can be improved from Theta(1/sqrt(n log n)) to Theta(1) if nodes are allowed to
move and a 2-hop relay scheme is employed. The price paid for such an
improvement on throughput is large delay. Indeed, the delay scaling of the
2-hop relay scheme is Theta(n log n) under the random walk mobility model. In
this paper, we employ coding techniques to improve the throughput-delay
trade-off for mobile wireless networks. For the random walk mobility model, we
improve the delay from Theta(n log n) to Theta(n) by employing Reed-Solomon
codes. Our approach maintains the diversity gained by mobility while decreasing
the delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4256</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4256</id><created>2009-08-28</created><authors><author><keyname>Salah</keyname><forenames>Hamdi</forenames></author><author><keyname>Adel</keyname><forenames>Soudani</forenames></author><author><keyname>Rached</keyname><forenames>Tourki</forenames></author></authors><title>Experimental Performances Analysis of Load Balancing Algorithms in IEEE
  802.11</title><categories>cs.PF</categories><comments>6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor
  0.423,http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2., August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In IEEE 802.11, load balancing algorithms (LBA) consider only the associated
stations to balance the load of the available access points (APs). However,
although the APs are balanced, it causes a bad situation if the AP has a lower
signal length (SNR) less than the neighbor APs. So, balance the load and
associate one mobile station to an access point without care about the signal
to noise ratio (SNR) of the AP cause possibly an unforeseen QoS, such as the
bit rate, the end to end delay, the packet loss. In this way, we study an
improvement load balancing algorithm with SNR integration at the selection
policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4265</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4265</id><created>2009-08-28</created><updated>2009-08-28</updated><authors><author><keyname>Asif</keyname><forenames>M. Salman</forenames></author><author><keyname>Mantzel</keyname><forenames>William</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author></authors><title>Channel Protection: Random Coding Meets Sparse Channels</title><categories>cs.IT math.IT math.OC</categories><comments>To appear in the proceedings of the 2009 IEEE Information Theory
  Workshop (Taormina)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multipath interference is an ubiquitous phenomenon in modern communication
systems. The conventional way to compensate for this effect is to equalize the
channel by estimating its impulse response by transmitting a set of training
symbols. The primary drawback to this type of approach is that it can be
unreliable if the channel is changing rapidly. In this paper, we show that
randomly encoding the signal can protect it against channel uncertainty when
the channel is sparse. Before transmission, the signal is mapped into a
slightly longer codeword using a random matrix. From the received signal, we
are able to simultaneously estimate the channel and recover the transmitted
signal. We discuss two schemes for the recovery. Both of them exploit the
sparsity of the underlying channel. We show that if the channel impulse
response is sufficiently sparse, the transmitted signal can be recovered
reliably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4288</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4288</id><created>2009-08-28</created><updated>2010-11-07</updated><authors><author><keyname>Foster</keyname><forenames>Jacob G.</forenames></author><author><keyname>Foster</keyname><forenames>David V.</forenames></author><author><keyname>Grassberger</keyname><forenames>Peter</forenames></author><author><keyname>Paczuski</keyname><forenames>Maya</forenames></author></authors><title>Edge direction and the structure of networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.NI</categories><comments>13 pages, 6 figures, 3 tables</comments><journal-ref>Proceedings of the National Academy of Sciences of the United
  States of America 2010, Vol. 107, No. 24</journal-ref><doi>10.1073/pnas.0912671107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directed networks are ubiquitous and are necessary to represent complex
systems with asymmetric interactions---from food webs to the World Wide Web.
Despite the importance of edge direction for detecting local and community
structure, it has been disregarded in studying a basic type of global diversity
in networks: the tendency of nodes with similar numbers of edges to connect.
This tendency, called assortativity, affects crucial structural and dynamic
properties of real-world networks, such as error tolerance or epidemic
spreading. Here we demonstrate that edge direction has profound effects on
assortativity. We define a set of four directed assortativity measures and
assign statistical significance by comparison to randomized networks. We apply
these measures to three network classes---online/social networks, food webs,
and word-adjacency networks. Our measures (i) reveal patterns common to each
class, (ii) separate networks that have been previously classified together,
and (iii) expose limitations of several existing theoretical models. We reject
the standard classification of directed networks as purely assortative or
disassortative. Many display a class-specific mixture, likely reflecting
functional or historical constraints, contingencies, and forces guiding the
system's evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4290</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4290</id><created>2009-08-28</created><authors><author><keyname>Khalil</keyname><forenames>Khaled M.</forenames></author><author><keyname>Abdel-Aziz</keyname><forenames>M.</forenames></author><author><keyname>Nazmy</keyname><forenames>Taymour T.</forenames></author><author><keyname>Salem</keyname><forenames>Abdel-Badeeh M.</forenames></author></authors><title>Bridging the Gap between Crisis Response Operations and Systems</title><categories>cs.CY cs.MA</categories><comments>6 pages, 1 figure, 2 tables, accepted at The 9th International
  Conference on Artificial Intelligence and Digital Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There exist huge problems in the current practice of crisis response
operations. Response problems are projected as a combination of failure in
communication, failure in technology, failure in methodology, failure of
management, and finally failure of observation. In this paper we compare eight
crisis response systems namely: DrillSim [2, 13], DEFACTO [12, 17], ALADDIN [1,
6], RoboCup Rescue [11, 15], FireGrid [3, 8, 18], WIPER [16], D-AESOP [4], and
PLAN C [14]. Comparison results will disclose the cause of failure of current
crisis response operations (the response gap). Based on comparison results; we
provide recommendations for bridging this gap between response operations and
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4309</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4309</id><created>2009-08-28</created><authors><author><keyname>Chin</keyname><forenames>Francis</forenames></author><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author><author><keyname>Yan</keyname><forenames>Li</forenames></author></authors><title>Algorithms for Placing Monitors in a Flow Network</title><categories>cs.DS cs.CC cs.DM</categories><comments>13 pages, 5 figures. Preliminary version appeared in AAIM 2009</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Flow Edge-Monitor Problem, we are given an undirected graph G=(V,E),
an integer k &gt; 0 and some unknown circulation \psi on G. We want to find a set
of k edges in G, so that if we place k monitors on those edges to measure the
flow along them, the total number of edges for which the flow can be uniquely
determined is maximized. In this paper, we first show that the Flow
Edge-Monitor Problem is NP-hard, and then we give two approximation algorithms:
a 3-approximation algorithm with running time O((m+n)^2) and a 2-approximation
algorithm with running time O((m+n)^3), where n = |V| and m=|E|.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4310</identifier>
 <datestamp>2011-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4310</id><created>2009-08-28</created><updated>2011-12-06</updated><authors><author><keyname>Marron</keyname><forenames>Beatriz</forenames></author></authors><title>Co-occurrence Matrix and Fractal Dimension for Image Segmentation</title><categories>stat.AP cs.CV</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important tasks in image processing problem and machine
vision is object recognition, and the success of many proposed methods relies
on a suitable choice of algorithm for the segmentation of an image. This paper
focuses on how to apply texture operators based on the concept of fractal
dimension and cooccurence matrix, to the problem of object recognition and a
new method based on fractal dimension is introduced. Several images, in which
the result of the segmentation can be shown, are used to illustrate the use of
each method and a comparative study of each operator is made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4325</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4325</id><created>2009-08-29</created><authors><author><keyname>Genge</keyname><forenames>Bela</forenames></author><author><keyname>Ignat</keyname><forenames>Iosif</forenames></author><author><keyname>Haller</keyname><forenames>Piroska</forenames></author></authors><title>Automated Composition of Security Protocols</title><categories>cs.CR cs.NI</categories><comments>2009 IEEE International Conference on Intelligent Communication and
  Processing (ICCP 2009), Cluj-Napoca, Romania, pp. 251-258 (ISBN
  978-1-4244-5007-7)</comments><acm-class>D.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining if two protocols can be securely composed requires analyzing not
only their additive properties but also their destructive properties. In this
paper we propose a new composition method for constructing protocols based on
existing ones found in the literature that can be fully automatized. The
additive properties of the composed protocols are ensured by the composition of
protocol preconditions and effects, denoting, respectively, the conditions that
must hold for protocols to be executed and the conditions that hold after
executing the protocols. The non-destructive property of the final composed
protocol is verified by analyzing the independence of the involved protocols, a
method proposed by the authors in their previous work. The fully automatized
property is ensured by constructing a rich protocol model that contains
explicit description of protocol preconditions, effects, generated terms and
exchanged messages. The proposed method is validated by composing 17 protocol
pairs and by verifying the correctness of the composed protocols with an
existing tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4353</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4353</id><created>2009-08-29</created><authors><author><keyname>Ayofe</keyname><forenames>Azeez Nureni</forenames></author><author><keyname>Ajetola</keyname><forenames>Azeez Raheem</forenames></author></authors><title>Exploration of the Gap Between Computer Science Curriculum and
  Industrial I.T Skills Requirements</title><categories>cs.GL cs.CY</categories><comments>10 pages IEEE Format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper sets out to examine the skills gaps between the industrial
application of Information Technology and university academic programmes
(curriculum). It looks at some of the causes, and considers the probable
solutions for bridging the gap between them and suggests the possibilities of
exploring a new role for our universities and employers of labor. It also
highlights strategies to abolish the misalignment between university and
industry. The main concept is to blend the academic rigidity with the
industrial relevance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4373</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4373</id><created>2009-08-31</created><updated>2009-09-13</updated><authors><author><keyname>Hill</keyname><forenames>Charles D.</forenames></author><author><keyname>Flitney</keyname><forenames>Adrian P.</forenames></author><author><keyname>Menicucci</keyname><forenames>Nicolas C.</forenames></author></authors><title>A competitive game whose maximal Nash-equilibrium payoff requires
  quantum resources for its achievement</title><categories>quant-ph cs.GT</categories><comments>8 pages, revtex4</comments><journal-ref>Phys. Lett. A 374 (2010) 3619-3624</journal-ref><doi>10.1016/j.physleta.2010.07.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While it is known that shared quantum entanglement can offer improved
solutions to a number of purely cooperative tasks for groups of remote agents,
controversy remains regarding the legitimacy of quantum games in a competitive
setting--in particular, whether they offer any advantage beyond what is
achievable using classical resources. We construct a competitive game between
four players based on the minority game where the maximal Nash-equilibrium
payoff when played with the appropriate quantum resource is greater than that
obtainable by classical means, assuming a local hidden variable model. The game
is constructed in a manner analogous to a Bell inequality. This result is
important in confirming the legitimacy of quantum games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4374</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4374</id><created>2009-08-30</created><authors><author><keyname>Jain</keyname><forenames>Ratnesh Kumar</forenames></author><author><keyname>Jain</keyname><forenames>Dr. Suresh</forenames></author><author><keyname>Kasana</keyname><forenames>Dr. R. S.</forenames></author></authors><title>Visualization of Mined Pattern and Its Human Aspects</title><categories>cs.HC cs.GR</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers got success in mining the Web usage data effectively and
efficiently. But representation of the mined patterns is often not in a form
suitable for direct human consumption. Hence mechanisms and tools that can
represent mined patterns in easily understandable format are utilized.
Different techniques are used for pattern analysis, one of them is
visualization. Visualization can provide valuable assistance for data analysis
and decision making tasks. In the data visualization process, technical
representations of web pages are replaced by user attractive text
interpretations. Experiments with the real world problems showed that the
visualization can significantly increase the quality and usefulness of web log
mining results. However, how decision makers perceive and interact with a
visual representation can strongly influence their understanding of the data as
well as the usefulness of the visual presentation. Human factors therefore
contribute significantly to the visualization process and should play an
important role in the design and evaluation of visualization tools. This
electronic document is a live template. The various components of your paper,
title, text, heads, etc., are already defined on the style sheet, as
illustrated by the portions given in this document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4386</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4386</id><created>2009-08-30</created><authors><author><keyname>Ahangar</keyname><forenames>Reza Gharoie</forenames></author><author><keyname>Ahangar</keyname><forenames>Mohammad Farajpoor</forenames></author></authors><title>Handwritten Farsi Character Recognition using Artificial Neural Network</title><categories>cs.CV</categories><comments>4 pages IEEE format, International Journal Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural Networks are being used for character recognition from last many years
but most of the work was confined to English character recognition. Till date,
a very little work has been reported for Handwritten Farsi Character
recognition. In this paper, we have made an attempt to recognize handwritten
Farsi characters by using a multilayer perceptron with one hidden layer. The
error backpropagation algorithm has been used to train the MLP network. In
addition, an analysis has been carried out to determine the number of hidden
nodes to achieve high performance of backpropagation network in the recognition
of handwritten Farsi characters. The system has been trained using several
different forms of handwriting provided by both male and female participants of
different age groups. Finally, this rigorous training results an automatic HCR
system using MLP network. In this work, the experiments were carried out on two
hundred fifty samples of five writers. The results showed that the MLP networks
trained by the error backpropagation algorithm are superior in recognition
accuracy and memory usage. The result indicates that the backpropagation
network provides good recognition accuracy of more than 80% of handwritten
Farsi characters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4413</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4413</id><created>2009-08-30</created><authors><author><keyname>Lopez</keyname><forenames>Patrice</forenames><affiliation>IDSL</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>IDSL, INRIA Saclay - Ile de France</affiliation></author></authors><title>Multiple Retrieval Models and Regression Models for Prior Art Search</title><categories>cs.CL</categories><proxy>ccsd hal-00411835</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the system called PATATRAS (PATent and Article Tracking,
Retrieval and AnalysiS) realized for the IP track of CLEF 2009. Our approach
presents three main characteristics: 1. The usage of multiple retrieval models
(KL, Okapi) and term index definitions (lemma, phrase, concept) for the three
languages considered in the present track (English, French, German) producing
ten different sets of ranked results. 2. The merging of the different results
based on multiple regression models using an additional validation set created
from the patent collection. 3. The exploitation of patent metadata and of the
citation structures for creating restricted initial working sets of patents and
for producing a final re-ranking regression model. As we exploit specific
metadata of the patent documents and the citation relations only at the
creation of initial working sets and during the final post ranking step, our
architecture remains generic and easy to extend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4419</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4419</id><created>2009-08-30</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Darwish</keyname><forenames>Hager S.</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Zidan</keyname><forenames>Mahmoud</forenames></author></authors><title>Distributed Flooding-based Storage Algorithms for Large-scale Sensor
  Networks</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose distributed flooding-based storage algorithms for
large-scale wireless sensor networks. Assume a wireless sensor network with $n$
nodes that have limited power, memory, and bandwidth. Each node is capable of
both sensing and storing data. Such sensor nodes might disappear from the
network due to failures or battery depletion. Hence it is desired to design
efficient schemes to collect data from these $n$ nodes. We propose two
distributed storage algorithms (DSA's) that utilize network flooding to solve
this problem. In the first algorithm, DSA-I, we assume that every node utilizes
network flooding to disseminate its data throughout the network using a mixing
time of approximately O(n). We show that this algorithm is efficient in terms
of the encoding and decoding operations. In the second algorithm, DSA-II, we
assume that the total number of nodes is not known to every sensor; hence
dissemination of the data does not depend on $n$. The encoding operations in
this case take $O(C\mu^2)$, where $\mu$ is the mean degree of the network graph
and $C$ is a system parameter. We evaluate the performance of the proposed
algorithms through analysis and simulation, and show that their performance
matches the derived theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4420</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4420</id><created>2009-08-30</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>Spreadsheets and the Financial Collapse</title><categories>cs.CY cs.HC</categories><comments>17 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 145-161
  ISBN 978-1-905617-89-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We briefly review the well-known risks, weaknesses and limitations of
spreadsheets and then introduce some more. We review and slightly extend our
previous work on the importance and criticality of spreadsheets in the City of
London, introducing the notions of ubiquity, centrality, legality and
contagion. We identify the sector of the financial market that we believed in
2005 to be highly dependant on the use of spreadsheets and relate this to its
recent catastrophic financial performance. We outline the role of spreadsheets
in the collapse of the Jamaican banking system in the late 1990's and then
review the UK financial regulator's knowledge of the risks of spreadsheets in
the contemporary financial system. We summarise the available evidence and
suggest that there is a link between the use of spreadsheets and the recent
collapse of the global financial system. We provide governments and regulating
authorities with some simple recommendations to reduce the risks of continued
overdependence on unreliable spreadsheets. We conclude with three fundamental
lessons from a century of human error research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4427</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4427</id><created>2009-08-30</created><authors><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author><author><keyname>Karpeev</keyname><forenames>Dmitry A.</forenames></author></authors><title>Mesh Algorithms for PDE with Sieve I: Mesh Distribution</title><categories>cs.CE cs.MS</categories><comments>36 pages, 22 figures</comments><acm-class>G.1.8; G.4; J.2; E.2</acm-class><journal-ref>Scientific Programming, 17(3), 215-230, 2009</journal-ref><doi>10.3233/SPR-2009-0249</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed a new programming framework, called Sieve, to support
parallel numerical PDE algorithms operating over distributed meshes. We have
also developed a reference implementation of Sieve in C++ as a library of
generic algorithms operating on distributed containers conforming to the Sieve
interface. Sieve makes instances of the incidence relation, or \emph{arrows},
the conceptual first-class objects represented in the containers. Further,
generic algorithms acting on this arrow container are systematically used to
provide natural geometric operations on the topology and also, through duality,
on the data. Finally, coverings and duality are used to encode not only
individual meshes, but all types of hierarchies underlying PDE data structures,
including multigrid and mesh partitions.
  In order to demonstrate the usefulness of the framework, we show how the mesh
partition data can be represented and manipulated using the same fundamental
mechanisms used to represent meshes. We present the complete description of an
algorithm to encode a mesh partition and then distribute a mesh, which is
independent of the mesh dimension, element shape, or embedding. Moreover, data
associated with the mesh can be similarly distributed with exactly the same
algorithm. The use of a high level of abstraction within the Sieve leads to
several benefits in terms of code reuse, simplicity, and extensibility. We
discuss these benefits and compare our approach to other existing mesh
libraries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4431</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4431</id><created>2009-08-30</created><authors><author><keyname>Pillai</keyname><forenames>B Prabhulla Chandran</forenames></author></authors><title>An OLAC Extension for Dravidian Languages</title><categories>cs.CL</categories><comments>4 Pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  OLAC was founded in 2000 for creating online databases of language resources.
This paper intends to review the bottom-up distributed character of the project
and proposes an extension of the architecture for Dravidian languages. An
ontological structure is considered for effective natural language processing
(NLP) and its advantages over statistical methods are reviewed
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4445</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4445</id><created>2009-08-30</created><authors><author><keyname>Wu</keyname><forenames>Xiugang</forenames></author><author><keyname>Xie</keyname><forenames>Liang-Liang</forenames></author></authors><title>Asymptotic Equipartition Property of Output when Rate is above Capacity</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The output distribution, when rate is above capacity, is investigated. It is
shown that there is an asymptotic equipartition property (AEP) of the typical
output sequences, independently of the specific codebook used, as long as the
codebook is typical according to the standard random codebook generation. This
equipartition of the typical output sequences is caused by the mixup of input
sequences when there are too many of them, namely, when the rate is above
capacity. This discovery sheds some light on the optimal design of the
compress-and-forward relay schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4453</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4453</id><created>2009-08-30</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>Depth-Independent Lower bounds on the Communication Complexity of
  Read-Once Boolean Formulas</title><categories>cs.CC quant-ph</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show lower bounds of $\Omega(\sqrt{n})$ and $\Omega(n^{1/4})$ on the
randomized and quantum communication complexity, respectively, of all
$n$-variable read-once Boolean formulas. Our results complement the recent
lower bound of $\Omega(n/8^d)$ by Leonardos and Saks and
$\Omega(n/2^{\Omega(d\log d)})$ by Jayram, Kopparty and Raghavendra for
randomized communication complexity of read-once Boolean formulas with depth
$d$. We obtain our result by &quot;embedding&quot; either the Disjointness problem or its
complement in any given read-once Boolean formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4457</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4457</id><created>2009-08-31</created><authors><author><keyname>Bauwens</keyname><forenames>Bruno</forenames></author></authors><title>Additivity of on-line decision complexity is violated by a linear term
  in the length of a binary string</title><categories>cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there are infinitely many binary strings z, such that the sum of
the on-line decision complexity of predicting the even bits of z given the
previous uneven bits, and the decision complexity of predicting the uneven bits
given the previous event bits, exceeds the Kolmogorov complexity of z by a
linear term in the length of z.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4464</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4464</id><created>2009-08-31</created><updated>2009-09-02</updated><authors><author><keyname>Boyer</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Lemoine</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>The eel-like robot</title><categories>cs.RO physics.class-ph</categories><proxy>ccsd hal-00411844</proxy><journal-ref>ASME Design Engineering Technical Conferences, San Diego : United
  States (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this project is to design, study and build an &quot;eel-like robot&quot;
prototype able to swim in three dimensions. The study is based on the analysis
of eel swimming and results in the realization of a prototype with 12
vertebrae, a skin and a head with two fins. To reach these objectives, a
multidisciplinary group of teams and laboratories has been formed in the
framework of two French projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4491</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4491</id><created>2009-08-31</created><authors><author><keyname>Dominguez</keyname><forenames>C&#xe9;sar</forenames><affiliation>LJK</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author></authors><title>A parameterization process, functorially</title><categories>cs.LO math.CT</categories><proxy>ccsd hal-00411936</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parameterization process used in the symbolic computation systems Kenzo
and EAT is studied here as a general construction in a categorical framework.
This parameterization process starts from a given specification and builds a
parameterized specification by adding a parameter as a new variable to some
operations. Given a model of the parameterized specification, each
interpretation of the parameter, called an argument, provides a model of the
given specification. Moreover, under some relevant terminality assumption, this
correspondence between the arguments and the models of the given specification
is a bijection. It is proved in this paper that the parameterization process is
provided by a functor and the subsequent parameter passing process by a natural
transformation. Various categorical notions are used, mainly adjoint functors,
pushouts and lax colimits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4494</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4494</id><created>2009-08-31</created><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>Learning, complexity and information density</title><categories>cs.IT cs.CC math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is the relationship between the complexity of a learner and the
randomness of his mistakes? This question was posed in \cite{rat0903} who
showed that the more complex the learner the higher the possibility that his
mistakes deviate from a true random sequence. In the current paper we report on
an empirical investigation of this problem. We investigate two characteristics
of randomness, the stochastic and algorithmic complexity of the binary sequence
of mistakes. A learner with a Markov model of order $k$ is trained on a finite
binary sequence produced by a Markov source of order $k^{*}$ and is tested on a
different random sequence. As a measure of learner's complexity we define a
quantity called the \emph{sysRatio}, denoted by $\rho$, which is the ratio
between the compressed and uncompressed lengths of the binary string whose
$i^{th}$ bit represents the maximum \emph{a posteriori} decision made at state
$i$ of the learner's model. The quantity $\rho$ is a measure of information
density. The main result of the paper shows that this ratio is crucial in
answering the above posed question. The result indicates that there is a
critical threshold $\rho^{*}$ such that when $\rho\leq\rho^{*}$ the sequence of
mistakes possesses the following features: (1)\emph{}low divergence $\Delta$
from a random sequence, (2) low variance in algorithmic complexity. When
$\rho&gt;\rho^{*}$, the characteristics of the mistake sequence changes sharply
towards a\emph{}high\emph{$\Delta$} and high variance in algorithmic
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4499</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4499</id><created>2009-08-31</created><updated>2011-01-29</updated><authors><author><keyname>Strozecki</keyname><forenames>Yann</forenames></author></authors><title>Monadic second-order model-checking on decomposable matroids</title><categories>cs.DM cs.DS cs.LO</categories><comments>32 pages, journal paper. Revision: the last part has been removed and
  the writing improved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A notion of branch-width, which generalizes the one known for graphs, can be
defined for matroids. We first give a proof of the polynomial time
model-checking of monadic second-order formulas on representable matroids of
bounded branch-width, by reduction to monadic second-order formulas on trees.
This proof is much simpler than the one previously known. We also provide a
link between our logical approach and a grammar that allows to build matroids
of bounded branch-width. Finally, we introduce a new class of non-necessarily
representable matroids, described by a grammar and on which monadic
second-order formulas can be checked in linear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0908.4580</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0908.4580</id><created>2009-08-31</created><authors><author><keyname>Hasanhodzic</keyname><forenames>Jasmina</forenames></author><author><keyname>Lo</keyname><forenames>Andrew W.</forenames></author><author><keyname>Viola</keyname><forenames>Emanuele</forenames></author></authors><title>A Computational View of Market Efficiency</title><categories>cs.CE cs.CC q-fin.TR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to study market efficiency from a computational viewpoint.
Borrowing from theoretical computer science, we define a market to be
\emph{efficient with respect to resources $S$} (e.g., time, memory) if no
strategy using resources $S$ can make a profit. As a first step, we consider
memory-$m$ strategies whose action at time $t$ depends only on the $m$ previous
observations at times $t-m,...,t-1$. We introduce and study a simple model of
market evolution, where strategies impact the market by their decision to buy
or sell. We show that the effect of optimal strategies using memory $m$ can
lead to &quot;market conditions&quot; that were not present initially, such as (1) market
bubbles and (2) the possibility for a strategy using memory $m' &gt; m$ to make a
bigger profit than was initially possible. We suggest ours as a framework to
rationalize the technological arms race of quantitative trading firms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0067</identifier>
 <datestamp>2012-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0067</id><created>2009-08-31</created><updated>2012-11-05</updated><authors><author><keyname>Abreu</keyname><forenames>L. D.</forenames></author><author><keyname>Ciaurri</keyname><forenames>&#xd3;.</forenames></author><author><keyname>Varona</keyname><forenames>J. L.</forenames></author></authors><title>Bilinear biorthogonal expansions and the Dunkl kernel on the real line</title><categories>math.FA cs.IT math.IT</categories><comments>16 pages</comments><msc-class>94A20, 42A38, 42C10, 33D45</msc-class><journal-ref>Expo. Math. 30 (2012), 32-48</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an extension of the classical Paley-Wiener space structure, which is
based on bilinear expansions of integral kernels into biorthogonal sequences of
functions. The structure includes both sampling expansions and Fourier-Neumann
type series as special cases, and it also provides a bilinear expansion for the
Dunkl kernel (in the rank 1 case) which is a Dunkl analogue of Gegenbauer's
expansion of the plane wave and the corresponding sampling expansions. In fact,
we show how to derive sampling and Fourier-Neumann type expansions from the
results related to the bilinear expansion for the Dunkl kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0074</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0074</id><created>2009-08-31</created><authors><author><keyname>Jegede</keyname><forenames>Philip Olu</forenames></author></authors><title>Predictors Of Java Programming Self Efficacy Among Engineering Students
  In A Nigerian University</title><categories>cs.CY</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study examined the relationship between Java programming self-efficacy
and programming background of engineering students in a Nigerian University.
One hundred and ninety two final year engineering students randomly selected
from six engineering departments of the university participated in the study.
Two research instruments: Programming Background Questionnaire and Java
Programming Self-Efficacy Scale were used in collecting relevant information
from the subjects. The resulting data were analyzed using Pearson product
correlation and Multiple regression analysis. Findings revealed that Java
Programming self-efficacy has no significant relationship with each of the
computing and programming background factors. It was additionally obtained that
the number of programming courses offered and programming courses weighed
scores were the only predictors of Java self-efficacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0093</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0093</id><created>2009-09-01</created><authors><author><keyname>Mikki</keyname><forenames>Mohammad A.</forenames></author></authors><title>Energy Efficient Location Aided Routing Protocol for Wireless MANETs</title><categories>cs.NI</categories><comments>9 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Mobile Ad-Hoc Network (MANET) is a collection of wireless mobile nodes
forming a temporary network without using any centralized access point,
infrastructure, or centralized administration. In this paper we introduce an
Energy Efficient Location Aided Routing (EELAR) Protocol for MANETs that is
based on the Location Aided Routing (LAR). EELAR makes significant reduction in
the energy consumption of the mobile nodes batteries by limiting the area of
discovering a new route to a smaller zone. Thus, control packets overhead is
significantly reduced. In EELAR a reference wireless base station is used and
the network's circular area centered at the base station is divided into six
equal sub-areas. At route discovery instead of flooding control packets to the
whole network area, they are flooded to only the sub-area of the destination
mobile node. The base station stores locations of the mobile nodes in a
position table. To show the efficiency of the proposed protocol we present
simulations using NS-2. Simulation results show that EELAR protocol makes an
improvement in control packet overhead and delivery ratio compared to AODV,
LAR, and DSR protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0095</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0095</id><created>2009-09-01</created><updated>2009-09-01</updated><authors><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Narayanaswamy</keyname><forenames>N. S.</forenames></author></authors><title>Online Algorithms for Self-Organizing Sequential Search - A Survey</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of this survey is to present the important theoretical and
experimental results contributed till date in the area of online algorithms for
the self organizing sequential search problem, also popularly known as the List
Update Problem(LUP) in a chronological way. The survey includes competitiveness
results of deterministic and randomized online algorithms and complexity
results of optimal off line algorithms for the list update problem. We also
present the results associated with list update with look ahead, list update
with locality of reference and other variants of the list update problem. We
investigate research issues, explore scope of future work associated with each
issue so that future researchers can find it useful to work on.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0097</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0097</id><created>2009-09-01</created><authors><author><keyname>Biswas</keyname><forenames>Kamanashis</forenames></author><author><keyname>Harun</keyname><forenames>S. A. M.</forenames></author></authors><title>Constraint Minimum Vertex Cover in K Partite Graph, Approximation
  Algorithm and Complexity Analysis</title><categories>cs.DS cs.CC</categories><comments>5 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generally, a graph G, an independent set is a subset S of vertices in G such
that no two vertices in S are adjacent (connected by an edge) and a vertex
cover is a subset S of vertices such that each edge of G has at least one of
its endpoints in S. Again, the minimum vertex cover problem is to find a vertex
cover with the smallest number of vertices. This study shows that the
constrained minimum vertex cover problem in k-partite graph (MIN CVCK) is
NP-Complete which is an important property of k partite graph. Many
combinatorial problems on general graphs are NP-complete, but when restricted
to k partite graph with at most k vertices then many of these problems can be
solved in polynomial time. This paper also illustrates an approximation
algorithm for MIN CVCK and analyzes its complexity. In future work section, we
specified a number of dimensions which may be interesting for the researchers
such as developing algorithm for maximum matching and polynomial algorithm for
constructing k-partite graph from general graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0099</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0099</id><created>2009-09-01</created><authors><author><keyname>Biswas</keyname><forenames>Kamanashis</forenames></author><author><keyname>Islam</keyname><forenames>Md. Ashraful</forenames></author></authors><title>Hardware Virtualization Support In INTEL, AMD And IBM Power Processors</title><categories>cs.AR</categories><comments>6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present, the mostly used and developed mechanism is hardware
virtualization which provides a common platform to run multiple operating
systems and applications in independent partitions. More precisely, it is all
about resource virtualization as the term hardware virtualization is
emphasized. In this paper, the aim is to find out the advantages and
limitations of current virtualization techniques, analyze their cost and
performance and also depict which forthcoming hardware virtualization
techniques will able to provide efficient solutions for multiprocessor
operating systems. This is done by making a methodical literature survey and
statistical analysis of the benchmark reports provided by SPEC (Standard
Performance Evaluation Corporation) and TPC (Transaction processing Performance
Council). Finally, this paper presents the current aspects of hardware
virtualization which will help the IT managers of the large organizations to
take effective decision while choosing server with virtualization support.
Again, the future works described in section 4 of this paper focuses on some
real world challenges such as abstraction of multiple servers, language level
virtualization, pre-virtualization etc. which may be point of great interest
for the researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0105</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0105</id><created>2009-09-01</created><updated>2011-02-21</updated><authors><author><keyname>Chance</keyname><forenames>Zachary</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author></authors><title>Concatenated Coding for the AWGN Channel with Noisy Feedback</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Trans. on Information Theory, January 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of open-loop coding can be easily extended to a closed-loop
concatenated code if the channel has access to feedback. This can be done by
introducing a feedback transmission scheme as an inner code. In this paper,
this process is investigated for the case when a linear feedback scheme is
implemented as an inner code and, in particular, over an additive white
Gaussian noise (AWGN) channel with noisy feedback. To begin, we look to derive
an optimal linear feedback scheme by optimizing over the received
signal-to-noise ratio. From this optimization, an asymptotically optimal linear
feedback scheme is produced and compared to other well-known schemes. Then, the
linear feedback scheme is implemented as an inner code to a concatenated code
over the AWGN channel with noisy feedback. This code shows improvements not
only in error exponent bounds, but also in bit-error-rate and frame-error-rate.
It is also shown that the if the concatenated code has total blocklength L and
the inner code has blocklength, N, the inner code blocklength should scale as N
= O(C/R), where C is the capacity of the channel and R is the rate of the
concatenated code. Simulations with low density parity check (LDPC) and turbo
codes are provided to display practical applications and their error rate
benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0108</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0108</id><created>2009-09-01</created><authors><author><keyname>Briot</keyname><forenames>S&#xe9;bastien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>On the optimal design of parallel robots taking into account their
  deformations and natural frequencies</title><categories>cs.RO</categories><proxy>ccsd hal-00411845</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the utility of using simple stiffness and vibrations
models, based on the Jacobian matrix of a manipulator and only the rigidity of
the actuators, whenever its geometry is optimised. In many works, these
simplified models are used to propose optimal design of robots. However, the
elasticity of the drive system is often negligible in comparison with the
elasticity of the elements, especially in applications where high dynamic
performances are needed. Therefore, the use of such a simplified model may lead
to the creation of robots with long legs, which will be submitted to large
bending and twisting deformations. This paper presents an example of
manipulator for which it is preferable to use a complete stiffness or vibration
model to obtain the most suitable design and shows that the use of simplified
models can lead to mechanisms with poorer rigidity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0109</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0109</id><created>2009-09-01</created><updated>2013-10-18</updated><authors><author><keyname>Li</keyname><forenames>Sanjiang</forenames></author></authors><title>On the Internal Topological Structure of Plane Regions</title><categories>cs.AI cs.CG</categories><comments>A short version appeared in KR-10. Several results have been
  rephrased and omitted proofs are given here. (Sanjiang Li. A Layered Graph
  Representation for Complex Regions, in Proceedings of the 12th International
  Conference on the Principles of Knowledge Representation and Reasoning
  (KR-10), pages 581-583, Toronto, Canada, May 9-13, 2010)</comments><msc-class>68T30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of topological information of spatial objects has for a long time
been a focus of research in disciplines like computational geometry, spatial
reasoning, cognitive science, and robotics. While the majority of these
researches emphasised the topological relations between spatial objects, this
work studies the internal topological structure of bounded plane regions, which
could consist of multiple pieces and/or have holes and islands to any finite
level. The insufficiency of simple regions (regions homeomorphic to closed
disks) to cope with the variety and complexity of spatial entities and
phenomena has been widely acknowledged. Another significant drawback of simple
regions is that they are not closed under set operations union, intersection,
and difference. This paper considers bounded semi-algebraic regions, which are
closed under set operations and can closely approximate most plane regions
arising in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0118</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0118</id><created>2009-09-01</created><authors><author><keyname>Sivaraman</keyname><forenames>R.</forenames></author><author><keyname>Prabakaran</keyname><forenames>R.</forenames></author><author><keyname>Sujatha</keyname><forenames>S.</forenames></author></authors><title>Dynamic Multimedia Content Retrieval System in Distributed Environment</title><categories>cs.MM cs.IR</categories><comments>4 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WiCoM enables remote management of web resources. Our application Mobile
reporter is aimed at Journalist, who will be able to capture the events in
real-time using their mobile phones and update their web server on the latest
event. WiCoM has been developed using J2ME technology on the client side and
PHP on the server side. The communication between the client and the server is
established through GPRS. Mobile reporter will be able to upload, edit and
remove both textual as well as multimedia contents in the server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0122</identifier>
 <datestamp>2013-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0122</id><created>2009-09-01</created><authors><author><keyname>Li</keyname><forenames>Sanjiang</forenames></author><author><keyname>Cohn</keyname><forenames>Anthony G.</forenames></author></authors><title>Reasoning with Topological and Directional Spatial Information</title><categories>cs.AI</categories><journal-ref>Computational Intelligence, 2012, 28(4):579-616</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current research on qualitative spatial representation and reasoning mainly
focuses on one single aspect of space. In real world applications, however,
multiple spatial aspects are often involved simultaneously.
  This paper investigates problems arising in reasoning with combined
topological and directional information. We use the RCC8 algebra and the
Rectangle Algebra (RA) for expressing topological and directional information
respectively. We give examples to show that the bipath-consistency algorithm
BIPATH is incomplete for solving even basic RCC8 and RA constraints. If
topological constraints are taken from some maximal tractable subclasses of
RCC8, and directional constraints are taken from a subalgebra, termed DIR49, of
RA, then we show that BIPATH is able to separate topological constraints from
directional ones. This means, given a set of hybrid topological and directional
constraints from the above subclasses of RCC8 and RA, we can transfer the joint
satisfaction problem in polynomial time to two independent satisfaction
problems in RCC8 and RA. For general RA constraints, we give a method to
compute solutions that satisfy all topological constraints and approximately
satisfy each RA constraint to any prescribed precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0138</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0138</id><created>2009-09-01</created><authors><author><keyname>Zhang</keyname><forenames>Xiaotong</forenames></author><author><keyname>Liu</keyname><forenames>Weiming</forenames></author><author><keyname>Li</keyname><forenames>Sanjiang</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Reasoning about Cardinal Directions between Extended Objects</title><categories>cs.AI</categories><journal-ref>Artificial Intelligence, Volume 174, Issues 12-13, August 2010,
  Pages 951-983</journal-ref><doi>10.1016/j.artint.2010.05.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direction relations between extended spatial objects are important
commonsense knowledge. Recently, Goyal and Egenhofer proposed a formal model,
known as Cardinal Direction Calculus (CDC), for representing direction
relations between connected plane regions. CDC is perhaps the most expressive
qualitative calculus for directional information, and has attracted increasing
interest from areas such as artificial intelligence, geographical information
science, and image retrieval. Given a network of CDC constraints, the
consistency problem is deciding if the network is realizable by connected
regions in the real plane. This paper provides a cubic algorithm for checking
consistency of basic CDC constraint networks, and proves that reasoning with
CDC is in general an NP-Complete problem. For a consistent network of basic CDC
constraints, our algorithm also returns a 'canonical' solution in cubic time.
This cubic algorithm is also adapted to cope with cardinal directions between
possibly disconnected regions, in which case currently the best algorithm is of
time complexity O(n^5).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0171</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0171</id><created>2009-09-01</created><updated>2010-09-14</updated><authors><author><keyname>Gehrke</keyname><forenames>Mai</forenames></author><author><keyname>Vosmaer</keyname><forenames>Jacob</forenames></author></authors><title>Canonical extension and canonicity via DCPO presentations</title><categories>cs.LO</categories><comments>17 pages. Definition 5 was revised slightly, without changing any of
  the results</comments><journal-ref>Theoretical Computer Science 412(25), pp. 2714-2723, 2011</journal-ref><doi>10.1016/j.tcs.2010.12.032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The canonical extension of a lattice is in an essential way a two-sided
completion. Domain theory, on the contrary, is primarily concerned with
one-sided completeness. In this paper, we show two things. Firstly, that the
canonical extension of a lattice can be given an asymmetric description in two
stages: a free co-directed meet completion, followed by a completion by
\emph{selected} directed joins. Secondly, we show that the general techniques
for dcpo presentations of dcpo algebras used in the second stage of the
construction immediately give us the well-known canonicity result for bounded
lattices with operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0173</identifier>
 <datestamp>2012-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0173</id><created>2009-09-01</created><updated>2012-09-11</updated><authors><author><keyname>Shour</keyname><forenames>Robert</forenames></author></authors><title>A theory of intelligence: networked problem solving in animal societies</title><categories>cs.AI nlin.AO</categories><comments>83 pages; v 2-8 correct proofreading errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A society's single emergent, increasing intelligence arises partly from the
thermodynamic advantages of networking the innate intelligence of different
individuals, and partly from the accumulation of solved problems. Economic
growth is proportional to the square of the network entropy of a society's
population times the network entropy of the number of the society's solved
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0174</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0174</id><created>2009-09-01</created><authors><author><keyname>Basagiannis</keyname><forenames>Stylianos</forenames></author><author><keyname>Katsaros</keyname><forenames>Panagiotis</forenames></author><author><keyname>Pombortsis</keyname><forenames>Andrew</forenames></author></authors><title>State Space Reduction with Message Inspection in Security Protocol Model
  Checking</title><categories>cs.CR</categories><comments>15 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model checking is a widespread automatic formal analysis that has been
successful in discovering flaws in security protocols. However existing
possibilities for state space explosion still hinder analyses of complex
protocols and protocol configurations. Message Inspection, is a technique that
delimits the branching of the state space due to the intruder model without
excluding possible attacks. In a preliminary simulation, the intruder model
tags the eavesdropped messages with specific metadata that enable validation of
feasibility of possible attack actions. The Message Inspection algorithm then
decides based on these metadata, which attacks will certainly fail according to
known security principles. Thus, it is a priori known that i.e. an encryption
scheme attack cannot succeed if the intruder does not posses the right key in
his knowledge. The simulation terminates with a report of the attack actions
that can be safely removed, resulting in a model with a reduced state space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0206</identifier>
 <datestamp>2012-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0206</id><created>2009-09-01</created><updated>2012-05-29</updated><authors><author><keyname>Datta</keyname><forenames>Somantika</forenames></author><author><keyname>Howard</keyname><forenames>Stephen</forenames></author><author><keyname>Cochran</keyname><forenames>Douglas</forenames></author></authors><title>Geometry of the Welch Bounds</title><categories>cs.IT math.IT</categories><comments>changes from previous version include: correction of typos,
  additional references added, new Example 3.3</comments><msc-class>15Axx, 42C15, 94Axx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A geometric perspective involving Grammian and frame operators is used to
derive the entire family of Welch bounds. This perspective unifies a number of
observations that have been made regarding tightness of the bounds and their
connections to symmetric k-tensors, tight frames, homogeneous polynomials, and
t-designs. In particular. a connection has been drawn between sampling of
homogeneous polynomials and frames of symmetric k-tensors. It is also shown
that tightness of the bounds requires tight frames. The lack of tight frames in
symmetric k-tensors in many cases, however, leads to consideration of sets that
come as close as possible to attaining the bounds. The geometric derivation is
then extended in the setting of generalized or continuous frames. The Welch
bounds for finite sets and countably infinite sets become special cases of this
general setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0236</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0236</id><created>2009-09-01</created><authors><author><keyname>Dunand</keyname><forenames>Clement</forenames></author><author><keyname>Lercier</keyname><forenames>Reynald</forenames></author></authors><title>Normal Elliptic Bases and Torus-Based Cryptography</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider representations of algebraic tori $T_n(F_q)$ over finite fields.
We make use of normal elliptic bases to show that, for infinitely many
squarefree integers $n$ and infinitely many values of $q$, we can encode $m$
torus elements, to a small fixed overhead and to $m$ $\phi(n)$-tuples of $F_q$
elements, in quasi-linear time in $\log q$.
  This improves upon previously known algorithms, which all have a
quasi-quadratic complexity. As a result, the cost of the encoding phase is now
negligible in Diffie-Hellman cryptographic schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0237</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0237</id><created>2009-09-01</created><updated>2009-11-07</updated><authors><author><keyname>Kostakos</keyname><forenames>Vassilis</forenames></author></authors><title>Is the crowd's wisdom biased? A quantitative asessment of three online
  communities</title><categories>cs.HC</categories><comments>17 pages, 6 tagles</comments><journal-ref>Computational Science and Engineering, p. 251-255, 2009</journal-ref><doi>10.1109/CSE.2009.491</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a study of user voting on three websites: Imdb, Amazon
and BookCrossings. It reports on an expert evaluation of the voting mechanisms
of each website and a quantitative data analysis of users' aggregate voting
behavior. The results suggest that voting follows different patterns across the
websites, with higher barrier to vote introducing a more of one-off voters and
attracting mostly experts. The results also show that that one-off voters tend
to vote on popular items, while experts mostly vote for obscure, low-rated
items. The study concludes with design suggestions to address the &quot;wisdom of
the crowd&quot; bias.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0245</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0245</id><created>2009-09-01</created><authors><author><keyname>Rungta</keyname><forenames>Sourabh</forenames></author><author><keyname>Verma</keyname><forenames>Kshitij</forenames></author><author><keyname>Tripathi</keyname><forenames>Neeta</forenames></author><author><keyname>Shukla</keyname><forenames>Anupam</forenames></author></authors><title>Enhanced Mode Selection Algorithm for H.264 encoder for Application in
  Low Computational power devices</title><categories>cs.MM</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intent of the H.264 AVC project was to create a standard capable of
providing good video quality at substantially lower bit rates than previous
standards without increasing the complexity of design so much that it would be
impractical or excessively expensive to implement. An additional goal was to
provide enough flexibility to allow the standard to be applied to a wide
variety of applications. To achieve better coding efficiency, H.264 AVC uses
several techniques such as inter mode and intra mode prediction with variable
size motion compensation, which adopts Rate Distortion Optimization (RDO). This
increases the computational complexity of the encoder especially for devices
with lower processing capabilities such as mobile and other handheld devices.
In this paper, we propose an algorithm to reduce the number of mode and sub
mode evaluations in inter mode prediction. Experimental results show that this
fast intra mode selection algorithm can lessen about 75 percent encoding time
with little loss of bit rate and visual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0247</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0247</id><created>2009-09-01</created><updated>2009-09-07</updated><authors><author><keyname>Arif</keyname><forenames>Abu Shamim Mohammad</forenames></author><author><keyname>Mahamud</keyname><forenames>Asif</forenames></author><author><keyname>Islam</keyname><forenames>Rashedul</forenames></author></authors><title>An Enhanced Static Data Compression Scheme Of Bengali Short Message</title><categories>cs.IT math.IT</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns a modified approach of compressing Short Bengali Text
Message for small devices. The prime objective of this research technique is to
establish a low complexity compression scheme suitable for small devices having
small memory and relatively lower processing speed. The basic aim is not to
compress text of any size up to its maximum level without having any constraint
on space and time, rather than the main target is to compress short messages up
to an optimal level which needs minimum space, consume less time and the
processor requirement is lower. We have implemented Character Masking,
Dictionary Matching, Associative rule of data mining and Hyphenation algorithm
for syllable based compression in hierarchical steps to achieve low complexity
lossless compression of text message for any mobile devices. The scheme to
choose the diagrams are performed on the basis of extensive statistical model
and the static Huffman coding is done through the same context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0251</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0251</id><created>2009-09-01</created><updated>2010-04-30</updated><authors><author><keyname>Huq</keyname><forenames>Kazi Mohammed Saidul</forenames></author><author><keyname>Bergano</keyname><forenames>Miguel</forenames></author><author><keyname>Gameiro</keyname><forenames>Atilio</forenames></author><author><keyname>Arefin</keyname><forenames>Md. Taslim</forenames></author></authors><title>Channel Equalization in Digital Transmission</title><categories>cs.IT math.IT</categories><comments>not published</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  not required
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0347</identifier>
 <datestamp>2009-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0347</id><created>2009-09-02</created><authors><author><keyname>Harks</keyname><forenames>Tobias</forenames></author><author><keyname>Klimm</keyname><forenames>Max</forenames></author><author><keyname>Moehring</keyname><forenames>Rolf H.</forenames></author></authors><title>Strong Nash Equilibria in Games with the Lexicographical Improvement
  Property</title><categories>cs.GT cs.DM</categories><report-no>Preprint 011-2009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a class of finite strategic games with the property that every
deviation of a coalition of players that is profitable to each of its members
strictly decreases the lexicographical order of a certain function defined on
the set of strategy profiles. We call this property the Lexicographical
Improvement Property (LIP) and show that it implies the existence of a
generalized strong ordinal potential function. We use this characterization to
derive existence, efficiency and fairness properties of strong Nash equilibria.
We then study a class of games that generalizes congestion games with
bottleneck objectives that we call bottleneck congestion games. We show that
these games possess the LIP and thus the above mentioned properties. For
bottleneck congestion games in networks, we identify cases in which the
potential function associated with the LIP leads to polynomial time algorithms
computing a strong Nash equilibrium. Finally, we investigate the LIP for
infinite games. We show that the LIP does not imply the existence of a
generalized strong ordinal potential, thus, the existence of SNE does not
follow. Assuming that the function associated with the LIP is continuous,
however, we prove existence of SNE. As a consequence, we prove that bottleneck
congestion games with infinite strategy spaces and continuous cost functions
possess a strong Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0393</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0393</id><created>2009-09-02</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author><author><keyname>Simonnet</keyname><forenames>Pierre</forenames><affiliation>SPE</affiliation></author></authors><title>On Recognizable Tree Languages Beyond the Borel Hierarchy</title><categories>math.LO cs.CC cs.LO</categories><comments>To appear in Fundamenta Informaticae</comments><proxy>ccsd hal-00412638</proxy><journal-ref>Fundamenta Informaticae 95, 2-3 (2009) 287-303</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the topological complexity of non Borel recognizable tree
languages with regard to the difference hierarchy of analytic sets. We show
that, for each integer $n \geq 1$, there is a $D_{\omega^n}({\bf
\Sigma}^1_1)$-complete tree language L_n accepted by a (non deterministic)
Muller tree automaton. On the other hand, we prove that a tree language
accepted by an unambiguous B\&quot;uchi tree automaton must be Borel. Then we
consider the game tree languages $W_{(i,k)}$, for Mostowski-Rabin indices $(i,
k)$. We prove that the $D_{\omega^n}({\bf \Sigma}^1_1)$-complete tree languages
L_n are Wadge reducible to the game tree language $W_{(i, k)}$ for $k-i \geq
2$. In particular these languages $W_{(i, k)}$ are not in any class
$D_{\alpha}({\bf \Sigma}^1_1)$ for $\alpha &lt; \omega^\omega$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0400</identifier>
 <datestamp>2009-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0400</id><created>2009-09-02</created><authors><author><keyname>Shental</keyname><forenames>Noam</forenames></author><author><keyname>Amir</keyname><forenames>Amnon</forenames></author><author><keyname>Zuk</keyname><forenames>Or</forenames></author></authors><title>Rare-Allele Detection Using Compressed Se(que)nsing</title><categories>q-bio.GN cs.IT cs.LG math.IT q-bio.QM stat.AP stat.ML</categories><comments>29 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of rare variants by resequencing is important for the
identification of individuals carrying disease variants. Rapid sequencing by
new technologies enables low-cost resequencing of target regions, although it
is still prohibitive to test more than a few individuals. In order to improve
cost trade-offs, it has recently been suggested to apply pooling designs which
enable the detection of carriers of rare alleles in groups of individuals.
However, this was shown to hold only for a relatively low number of individuals
in a pool, and requires the design of pooling schemes for particular cases.
  We propose a novel pooling design, based on a compressed sensing approach,
which is both general, simple and efficient. We model the experimental
procedure and show via computer simulations that it enables the recovery of
rare allele carriers out of larger groups than were possible before, especially
in situations where high coverage is obtained for each individual.
  Our approach can also be combined with barcoding techniques to enhance
performance and provide a feasible solution based on current resequencing
costs. For example, when targeting a small enough genomic region (~100
base-pairs) and using only ~10 sequencing lanes and ~10 distinct barcodes, one
can recover the identity of 4 rare allele carriers out of a population of over
4000 individuals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0442</identifier>
 <datestamp>2009-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0442</id><created>2009-09-02</created><authors><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Kinematic analysis of a class of analytic planar 3-RPR parallel
  manipulators</title><categories>cs.RO</categories><proxy>ccsd hal-00412923</proxy><journal-ref>International Workshop on Computational Kinematics, Duisburg :
  Germany (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of analytic planar 3-RPR manipulators is analyzed in this paper.
These manipulators have congruent base and moving platforms and the moving
platform is rotated of 180 deg about an axis in the plane. The forward
kinematics is reduced to the solution of a 3rd-degree polynomial and a
quadratic equation in sequence. The singularities are calculated and plotted in
the joint space. The second-order singularities (cups points), which play an
important role in non-singular change of assembly-mode motions, are also
analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0481</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0481</id><created>2009-09-02</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Contreras</keyname><forenames>Pedro</forenames></author><author><keyname>Starck</keyname><forenames>Jean-Luc</forenames></author></authors><title>Scale-Based Gaussian Coverings: Combining Intra and Inter Mixture Models
  in Image Segmentation</title><categories>cs.CV</categories><comments>20 pages, 5 figures</comments><acm-class>I.4.6</acm-class><journal-ref>Entropy, 11 (3), 513-528, 2009</journal-ref><doi>10.3390/e11030513</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By a &quot;covering&quot; we mean a Gaussian mixture model fit to observed data.
Approximations of the Bayes factor can be availed of to judge model fit to the
data within a given Gaussian mixture model. Between families of Gaussian
mixture models, we propose the R\'enyi quadratic entropy as an excellent and
tractable model comparison framework. We exemplify this using the segmentation
of an MRI image volume, based (1) on a direct Gaussian mixture model applied to
the marginal distribution function, and (2) Gaussian model fit through k-means
applied to the 4D multivalued image volume furnished by the wavelet transform.
Visual preference for one model over another is not immediate. The R\'enyi
quadratic entropy allows us to show clearly that one of these modelings is
superior to the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0537</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0537</id><created>2009-09-02</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Clarkson</keyname><forenames>Kenneth L.</forenames></author><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>On the Set Multi-Cover Problem in Geometric Settings</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the set multi-cover problem in geometric settings. Given a set of
points P and a collection of geometric shapes (or sets) F, we wish to find a
minimum cardinality subset of F such that each point p in P is covered by
(contained in) at least d(p) sets. Here d(p) is an integer demand (requirement)
for p. When the demands d(p)=1 for all p, this is the standard set cover
problem. The set cover problem in geometric settings admits an approximation
ratio that is better than that for the general version. In this paper, we show
that similar improvements can be obtained for the multi-cover problem as well.
In particular, we obtain an O(log Opt) approximation for set systems of bounded
VC-dimension, where Opt is the cardinality of an optimal solution, and an O(1)
approximation for covering points by half-spaces in three dimensions and for
some other classes of shapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0549</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0549</id><created>2009-09-03</created><updated>2009-10-23</updated><authors><author><keyname>Sarvepalli</keyname><forenames>Pradeep</forenames></author><author><keyname>Raussendorf</keyname><forenames>Robert</forenames></author></authors><title>Matroids and Quantum Secret Sharing Schemes</title><categories>quant-ph cs.CR</categories><journal-ref>Phys. Rev. A 81, 052333 (2010)</journal-ref><doi>10.1103/PhysRevA.81.052333</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A secret sharing scheme is a cryptographic protocol to distribute a secret
state in an encoded form among a group of players such that only authorized
subsets of the players can reconstruct the secret. Classically, efficient
secret sharing schemes have been shown to be induced by matroids. Furthermore,
access structures of such schemes can be characterized by an excluded minor
relation. No such relations are known for quantum secret sharing schemes. In
this paper we take the first steps toward a matroidal characterization of
quantum secret sharing schemes. In addition to providing a new perspective on
quantum secret sharing schemes, this characterization has important benefits.
While previous work has shown how to construct quantum secret sharing schemes
for general access structures, these schemes are not claimed to be efficient.
In this context the present results prove to be useful; they enable us to
construct efficient quantum secret sharing schemes for many general access
structures. More precisely, we show that an identically self-dual matroid that
is representable over a finite field induces a pure state quantum secret
sharing scheme with information rate one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0553</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0553</id><created>2009-09-02</created><updated>2011-05-09</updated><authors><author><keyname>Luo</keyname><forenames>Jie</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author></authors><title>A New Approach to Random Access: Reliable Communication and Reliable
  Collision Detection</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper applies Information Theoretic analysis to packet-based random
multiple access communication systems. A new channel coding approach is
proposed for coding within each data packet with built-in support for bursty
traffic properties, such as message underflow, and for random access
properties, such as packet collision detection. The coding approach does not
require joint communication rate determination either among the transmitters or
between the transmitters and the receiver. Its performance limitation is
characterized by an achievable region defined in terms of communication rates,
such that reliable packet recovery is supported for all rates inside the region
and reliable collision detection is supported for all rates outside the region.
For random access communication over a discrete-time memoryless channel, it is
shown that the achievable rate region of the introduced coding approach equals
the Shannon information rate region without a convex hull operation. Further
connections between the achievable rate region and the Shannon information rate
region are developed and explained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0555</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0555</id><created>2009-09-02</created><updated>2012-01-30</updated><authors><author><keyname>Li</keyname><forenames>Boyu</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Reduced Complexity Sphere Decoding</title><categories>cs.IT math.IT</categories><comments>accepted to Journal. arXiv admin note: substantial text overlap with
  arXiv:1009.3514</comments><journal-ref>Wiley WCMC, Vol. 11, No. 12, pages 1518-1527, Dec. 2011</journal-ref><doi>10.1002/wcm.1216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Multiple-Input Multiple-Output (MIMO) systems, Sphere Decoding (SD) can
achieve performance equivalent to full search Maximum Likelihood (ML) decoding,
with reduced complexity. Several researchers reported techniques that reduce
the complexity of SD further. In this paper, a new technique is introduced
which decreases the computational complexity of SD substantially, without
sacrificing performance. The reduction is accomplished by deconstructing the
decoding metric to decrease the number of computations and exploiting the
structure of a lattice representation. Furthermore, an application of SD,
employing a proposed smart implementation with very low computational
complexity is introduced. This application calculates the soft bit metrics of a
bit-interleaved convolutional-coded MIMO system in an efficient manner. Based
on the reduced complexity SD, the proposed smart implementation employs the
initial radius acquired by Zero-Forcing Decision Feedback Equalization (ZF-DFE)
which ensures no empty spheres. Other than that, a technique of a particular
data structure is also incorporated to efficiently reduce the number of
executions carried out by SD. Simulation results show that these approaches
achieve substantial gains in terms of the computational complexity for both
uncoded and coded MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0571</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0571</id><created>2009-09-03</created><authors><author><keyname>Khan</keyname><forenames>Saad Ahmad</forenames></author><author><keyname>Arshad</keyname><forenames>Sheheryar Ali</forenames></author></authors><title>QoS Provisioning Using Hybrid FSO RF Based Hierarchical Model for
  Wireless Multimedia Sensor Networks</title><categories>cs.NI</categories><comments>6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our objective is to provide guaranteed packet delivery service in time
constrained sensor networks. The wireless network is a highly variable
environment, where available link bandwidth may vary with network load. Since
multimedia applications require higher bandwidth so we use FSO links for their
transmission. The main advantage of FSO links is that they offer higher
bandwidth and security, while RF links offer more reliability. The routing in
this multitier network is based on directional geographic routing protocol, in
which sensors route their data via multihop paths, to a powerful base station,
through a cluster head. Some modifications have also been incorporated in the
MAC layer to improve the QoS of such systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0572</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0572</id><created>2009-09-03</created><authors><author><keyname>Mirzal</keyname><forenames>Andri</forenames></author><author><keyname>Furukawa</keyname><forenames>Masashi</forenames></author></authors><title>A Method for Accelerating the HITS Algorithm</title><categories>cs.IR</categories><comments>10 pages, 3 figures, to be appear in Journal of Advanced
  Computational Intelligence and Intelligent Informatics, Vol. 14 No. 1, 2010</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present a new method to accelerate the HITS algorithm by exploiting
hyperlink structure of the web graph. The proposed algorithm extends the idea
of authority and hub scores from HITS by introducing two diagonal matrices
which contain constants that act as weights to make authority pages more
authoritative and hub pages more hubby. This method works because in the web
graph good authorities are pointed to by good hubs and good hubs point to good
authorities. Consequently, these pages will collect their scores faster under
the proposed algorithm than under the standard HITS. We show that the authority
and hub vectors of the proposed algorithm exist but are not necessarily be
unique, and then give a treatment to ensure the uniqueness property of the
vectors. The experimental results show that the proposed algorithm can improve
HITS computations, especially for back button datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0573</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0573</id><created>2009-09-03</created><authors><author><keyname>Bani</keyname><forenames>Jalpa</forenames></author><author><keyname>Rizvi</keyname><forenames>Syed S.</forenames></author></authors><title>Minimizing Cache Timing Attack Using Dynamic Cache Flushing (DCF)
  Algorithm</title><categories>cs.CR</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rijndael algorithm was unanimously chosen as the Advanced Encryption Standard
(AES) by the panel of researchers at National Institute of Standards and
Technology (NIST) in October 2000. Since then, Rijndael was destined to be used
massively in various software as well as hardware entities for encrypting data.
However, a few years back, Daniel Bernstein devised a cache timing attack that
was capable enough to break Rijndael seal that encapsulates the encryption key.
In this paper, we propose a new Dynamic Cache Flushing (DCF) algorithm which
shows a set of pragmatic software measures that would make Rijndael impregnable
to cache timing attack. The simulation results demonstrate that the proposed
DCF algorithm provides better security by encrypting key at a constant time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0576</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0576</id><created>2009-09-03</created><authors><author><keyname>Padmavathi</keyname><forenames>Dr. G.</forenames></author><author><keyname>Shanmugapriya</keyname><forenames>Mrs. D.</forenames></author></authors><title>A Survey of Attacks, Security Mechanisms and Challenges in Wireless
  Sensor Networks</title><categories>cs.CR</categories><comments>9 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor networks (WSN) is an emerging technology and have great
potential to be employed in critical situations like battlefields and
commercial applications such as building, traffic surveillance, habitat
monitoring and smart homes and many more scenarios. One of the major challenges
wireless sensor networks face today is security. While the deployment of sensor
nodes in an unattended environment makes the networks vulnerable to a variety
of potential attacks, the inherent power and memory limitations of sensor nodes
makes conventional security solutions unfeasible. The sensing technology
combined with processing power and wireless communication makes it profitable
for being exploited in great quantity in future. The wireless communication
technology also acquires various types of security threats. This paper
discusses a wide variety of attacks in WSN and their classification mechanisms
and different securities available to handle them including the challenges
faced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0583</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0583</id><created>2009-09-03</created><authors><author><keyname>Hashmi</keyname><forenames>Raheel Maqsood</forenames></author><author><keyname>Siddiqui</keyname><forenames>Arooj Mubashara</forenames></author><author><keyname>Jabeen</keyname><forenames>Memoona</forenames></author><author><keyname>Alimgeer</keyname><forenames>Khurram S.</forenames></author><author><keyname>Khan</keyname><forenames>Shahid A.</forenames></author></authors><title>Computational Complexities and Breaches in Authentication Frameworks of
  Broadband Wireless Access</title><categories>cs.CR</categories><comments>5 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor
  0.423,http://sites.google.com/site/ijcsis/</comments><report-no>ISSn 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure access of communication networks has become an increasingly important
area of consideration for the communication service providers of present day.
Broadband Wireless Access (BWA) networks are proving to be an efficient and
cost effective solution for the provisioning of high rate wireless traffic
links in static and mobile domains. The secure access of these networks is
necessary to ensure their superior operation and revenue efficacy. Although
authentication process is a key to secure access in BWA networks, the breaches
present in them limit the networks performance. In this paper, the
vulnerabilities in the authentication frameworks of BWA networks have been
unveiled. Moreover, this paper also describes the limitations of these
protocols and of the solutions proposed to them due to the involved
computational complexities and overheads. The possible attacks on privacy and
performance of BWA networks have been discussed and explained in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0588</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0588</id><created>2009-09-03</created><authors><author><keyname>Curto</keyname><forenames>Jose Ignacio Iglesias</forenames></author><author><keyname>Helmke</keyname><forenames>Uwe</forenames></author></authors><title>Receding horizon decoding of convolutional codes</title><categories>cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decoding of convolutional codes poses a significant challenge for coding
theory. Classical methods, based on e.g. Viterbi decoding, suffer from being
computationally expensive and are restricted therefore to codes of small
complexity. Based on analogies with model predictive optimal control, we
propose a new iterative method for convolutional decoding that is cheaper to
implement than established algorithms, while still offering significant error
correction capabilities. The algorithm is particularly well-suited for decoding
special types of convolutional codes, such as e.g. cyclic convolutional codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0599</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0599</id><created>2009-09-03</created><authors><author><keyname>Islam</keyname><forenames>Md. Rabiul</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Fayzur</forenames></author></authors><title>Codebook Design Method for Noise Robust Speaker Identification based on
  Genetic Algorithm</title><categories>cs.SD cs.NE</categories><comments>5 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor
  0.423,http://sites.google.com/site/ijcsis/</comments><report-no>ISSn 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel method of designing a codebook for noise robust
speaker identification purpose utilizing Genetic Algorithm has been proposed.
Wiener filter has been used to remove the background noises from the source
speech utterances. Speech features have been extracted using standard speech
parameterization method such as LPC, LPCC, RCC, MFCC, (delta)MFCC and
(delta)(delta) MFCC. For each of these techniques, the performance of the
proposed system has been compared. In this codebook design method, Genetic
Algorithm has the capability of getting global optimal result and hence
improves the quality of the codebook. Comparing with the NOIZEOUS speech
database, the experimental result shows that 79.62 percent accuracy has been
achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0611</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0611</id><created>2009-09-03</created><updated>2010-07-04</updated><authors><author><keyname>Yoshida</keyname><forenames>Katsutoshi</forenames></author><author><keyname>Higeta</keyname><forenames>Atsushi</forenames></author><author><keyname>Watanabe</keyname><forenames>Shinichi</forenames></author></authors><title>Effects of Mechanical Coupling on the Dynamics of Balancing Tasks</title><categories>cs.CE</categories><comments>18 pages, 16 figures</comments><journal-ref>International Journal of Innovative Computing, Information and
  Control, Vol.7, No.4, April 2011, pp.1661-1674</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coupled human balancing tasks are investigated based on both pseudo-neural
controllers characterized by time-delayed feedback with random gain and natural
human balancing tasks. It is shown numerically that, compared to single
balancing tasks, balancing tasks coupled by mechanical structures exhibit
enhanced stability against balancing errors in terms of both amplitude and
velocity and also improve the tracking ability of the controllers. We then
perform an experiment in which numerical pseudo-neural controllers are replaced
with natural human balancing tasks carried out using computer mice. The results
reveal that the coupling structure generates asymmetric tracking abilities in
subjects whose tracking abilities are nearly symmetric in their single
balancing tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0633</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0633</id><created>2009-09-03</created><authors><author><keyname>Rizk</keyname><forenames>Amr</forenames></author><author><keyname>Fidler</keyname><forenames>Markus</forenames></author></authors><title>Statistical End-to-end Performance Bounds for Networks under Long Memory
  FBM Cross Traffic</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractional Brownian motion (fBm) emerged as a useful model for self-similar
and long-range dependent Internet traffic. Approximate performance measures are
known from large deviations theory for single queuing systems with fBm through
traffic. In this paper we derive end-to-end performance bounds for a through
flow in a network of tandem queues under fBm cross traffic. To this end, we
prove a rigorous sample path envelope for fBm that complements previous
approximate results. We find that both approaches agree in their outcome that
overflow probabilities for fBm traffic have a Weibullian tail. We employ the
sample path envelope and the concept of leftover service curves to model the
remaining service after scheduling fBm cross traffic at a system. Using
composition results for tandem systems from the stochastic network calculus we
derive end-to-end statistical performance bounds for individual flows in
networks under fBm cross traffic. We discover that these bounds grow in O(n
(log n)^(1/(2-2H))) for n systems in series where H is the Hurst parameter of
the fBm cross traffic. We show numerical results on the impact of the
variability and the correlation of fBm traffic on network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0635</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0635</id><created>2009-09-03</created><authors><author><keyname>Verleysen</keyname><forenames>Michel</forenames><affiliation>DICE - MLG</affiliation></author><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>LTCI</affiliation></author><author><keyname>Fran&#xe7;ois</keyname><forenames>Damien</forenames><affiliation>CESAME</affiliation></author></authors><title>Advances in Feature Selection with Mutual Information</title><categories>cs.LG cs.IT math.IT</categories><proxy>ccsd hal-00413154</proxy><journal-ref>Similarity-Based Clustering, Villmann, Th.; Biehl, M.; Hammer, B.;
  Verleysen, M. (Ed.) (2009) 52-69</journal-ref><doi>10.1007/978-3-642-01805-3_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The selection of features that are relevant for a prediction or
classification problem is an important problem in many domains involving
high-dimensional data. Selecting features helps fighting the curse of
dimensionality, improving the performances of prediction or classification
methods, and interpreting the application. In a nonlinear context, the mutual
information is widely used as relevance criterion for features and sets of
features. Nevertheless, it suffers from at least three major limitations:
mutual information estimators depend on smoothing parameters, there is no
theoretically justified stopping criterion in the feature selection greedy
procedure, and the estimation itself suffers from the curse of dimensionality.
This chapter shows how to deal with these problems. The two first ones are
addressed by using resampling techniques that provide a statistical basis to
select the estimator parameters and to stop the search procedure. The third one
is addressed by modifying the mutual information criterion into a measure of
how features are complementary (and not only informative) for the problem at
hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0638</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0638</id><created>2009-09-03</created><authors><author><keyname>Hammer</keyname><forenames>Barbara</forenames><affiliation>LTCI</affiliation></author><author><keyname>Hasenfu&#xdf;</keyname><forenames>Alexander</forenames><affiliation>LTCI</affiliation></author><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>LTCI</affiliation></author></authors><title>Median topographic maps for biomedical data sets</title><categories>cs.LG q-bio.QM</categories><proxy>ccsd hal-00413148</proxy><journal-ref>Similarity-Based Clustering, Villmann, Th.; Biehl, M.; Hammer, B.;
  Verleysen, M. (Ed.) (2009) 92-117</journal-ref><doi>10.1007/978-3-642-01805-3_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Median clustering extends popular neural data analysis methods such as the
self-organizing map or neural gas to general data structures given by a
dissimilarity matrix only. This offers flexible and robust global data
inspection methods which are particularly suited for a variety of data as
occurs in biomedical domains. In this chapter, we give an overview about median
clustering and its properties and extensions, with a particular focus on
efficient implementations adapted to large scale data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0641</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0641</id><created>2009-09-03</created><updated>2010-07-15</updated><authors><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Yu</keyname><forenames>Yaming</forenames></author></authors><title>Monotonicity, thinning and discrete versions of the Entropy Power
  Inequality</title><categories>cs.IT math.IT</categories><comments>9 pages (revised to take account of referees' comments)</comments><journal-ref>IEEE Transactions on Information Theory, Vol 56/11, 2010, pages
  5387-5395</journal-ref><doi>10.1109/TIT.2010.2070570</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the entropy of sums of independent discrete random variables, in
analogy with Shannon's Entropy Power Inequality, where equality holds for
normals. In our case, infinite divisibility suggests that equality should hold
for Poisson variables. We show that some natural analogues of the Entropy Power
Inequality do not in fact hold, but propose an alternative formulation which
does always hold. The key to many proofs of Shannon's Entropy Power Inequality
is the behaviour of entropy on scaling of continuous random variables. We
believe that R\'{e}nyi's operation of thinning discrete random variables plays
a similar role to scaling, and give a sharp bound on how the entropy of ultra
log-concave random variables behaves on thinning. In the spirit of the
monotonicity results established by Artstein, Ball, Barthe and Naor, we prove a
stronger version of concavity of entropy, which implies a strengthened form of
our discrete Entropy Power Inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0682</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0682</id><created>2009-09-03</created><authors><author><keyname>Sohrabi</keyname><forenames>Shirin</forenames></author><author><keyname>McIlraith</keyname><forenames>Sheila A.</forenames></author></authors><title>On Planning with Preferences in HTN</title><categories>cs.AI</categories><comments>This paper appears in Twelfth International Workshop on Non-Monotonic
  Reasoning (NMR08). An earlier version of this paper appears in Fourth
  Multidisciplinary Workshop on Advances in Preference Handling (M-Pref08) at
  AAAI-08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of generating preferred plans by
combining the procedural control knowledge specified by Hierarchical Task
Networks (HTNs) with rich qualitative user preferences. The outcome of our work
is a language for specifyin user preferences, tailored to HTN planning,
together with a provably optimal preference-based planner, HTNPLAN, that is
implemented as an extension of SHOP2. To compute preferred plans, we propose an
approach based on forward-chaining heuristic search. Our heuristic uses an
admissible evaluation function measuring the satisfaction of preferences over
partial plans. Our empirical evaluation demonstrates the effectiveness of our
HTNPLAN heuristics. We prove our approach sound and optimal with respect to the
plans it generates by appealing to a situation calculus semantics of our
preference language and of HTN planning. While our implementation builds on
SHOP2, the language and techniques proposed here are relevant to a broad range
of HTN planners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0685</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0685</id><created>2009-09-03</created><authors><author><keyname>Branch</keyname><forenames>Joel W.</forenames></author><author><keyname>Giannella</keyname><forenames>Chris</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw</forenames></author><author><keyname>Wolff</keyname><forenames>Ran</forenames></author><author><keyname>Kargupta</keyname><forenames>Hillol</forenames></author></authors><title>In-Network Outlier Detection in Wireless Sensor Networks</title><categories>cs.DB cs.NI</categories><comments>Extended version of a paper appearing in the Int'l Conference on
  Distributed Computing Systems 2006</comments><journal-ref>Knowledge and Information Systems 34(1) January, 2013, pp. 23-54</journal-ref><doi>10.1007/s10115-011-0474-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To address the problem of unsupervised outlier detection in wireless sensor
networks, we develop an approach that (1) is flexible with respect to the
outlier definition, (2) computes the result in-network to reduce both bandwidth
and energy usage,(3) only uses single hop communication thus permitting very
simple node failure detection and message reliability assurance mechanisms
(e.g., carrier-sense), and (4) seamlessly accommodates dynamic updates to data.
We examine performance using simulation with real sensor data streams. Our
results demonstrate that our approach is accurate and imposes a reasonable
communication load and level of power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0704</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0704</id><created>2009-09-03</created><updated>2010-06-23</updated><authors><author><keyname>Nguyen</keyname><forenames>Ha Q.</forenames></author><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author></authors><title>Concentric Permutation Source Codes</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Communications, vol. 58, no. 11, pp.
  3154-3164, November 2010</journal-ref><doi>10.1109/TCOMM.2010.101210.090535</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Permutation codes are a class of structured vector quantizers with a
computationally-simple encoding procedure based on sorting the scalar
components. Using a codebook comprising several permutation codes as subcodes
preserves the simplicity of encoding while increasing the number of
rate-distortion operating points, improving the convex hull of operating
points, and increasing design complexity. We show that when the subcodes are
designed with the same composition, optimization of the codebook reduces to a
lower-dimensional vector quantizer design within a single cone. Heuristics for
reducing design complexity are presented, including an optimization of the rate
allocation in a shape-gain vector quantizer with gain-dependent wrapped
spherical shape codebook.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0717</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0717</id><created>2009-09-03</created><updated>2010-01-24</updated><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>Relative $(p,\epsilon)$-Approximations in Geometry</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We re-examine the notion of relative $(p,\eps)$-approximations, recently
introduced in [CKMS06], and establish upper bounds on their size, in general
range spaces of finite VC-dimension, using the sampling theory developed in
[LLS01] and in several earlier studies [Pol86, Hau92, Tal94]. We also survey
the different notions of sampling, used in computational geometry, learning,
and other areas, and show how they relate to each other. We then give
constructions of smaller-size relative $(p,\eps)$-approximations for range
spaces that involve points and halfspaces in two and higher dimensions. The
planar construction is based on a new structure--spanning trees with small
relative crossing number, which we believe to be of independent interest.
Relative $(p,\eps)$-approximations arise in several geometric problems, such as
approximate range counting, and we apply our new structures to obtain efficient
solutions for approximate range counting in three dimensions. We also present a
simple solution for the planar case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0732</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0732</id><created>2009-09-03</created><authors><author><keyname>Hussain</keyname><forenames>Shahid</forenames></author><author><keyname>Asghar</keyname><forenames>Muhammad Zubair</forenames></author><author><keyname>Ahmad</keyname><forenames>Bashir</forenames></author><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author></authors><title>A Step towards Software Corrective Maintenance Using RCM model</title><categories>cs.SE</categories><comments>6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From the preliminary stage of software engineering, selection of appropriate
enforcement of standards remained a challenge for stakeholders during entire
cycle of software development, but it can lead to reduce the efforts desired
for software maintenance phase. Corrective maintenance is the reactive
modification of a software product performed after delivery to correct
discovered faults. Studies conducted by different researchers reveal that
approximately 50 to 75 percent of the effort is spent on maintenance, out of
which about 17 to 21 percent is exercised on corrective maintenance. In this
paper, authors proposed a RCM (Reduce Corrective Maintenance) model which
represents the implementation process of number of checklists to guide the
stakeholders of all phases of software development. These check lists will be
filled by corresponding stake holder of all phases before its start. More
precise usage of the check list in relevant phase ensures successful
enforcement of analysis, design, coding and testing standards for reducing
errors in operation stage. Moreover authors represent the step by step
integration of checklists in software development life cycle through RCM model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0736</identifier>
 <datestamp>2009-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0736</id><created>2009-09-03</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author><author><keyname>Lecomte</keyname><forenames>Dominique</forenames><affiliation>IMJ</affiliation></author></authors><title>Decision Problems For Turing Machines</title><categories>cs.LO cs.CC math.LO</categories><comments>To appear in Information Processing Letters</comments><proxy>ccsd hal-00413331</proxy><journal-ref>Information Processing Letters 109, 23-24 (2009) 1223-1226</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We answer two questions posed by Castro and Cucker, giving the exact
complexities of two decision problems about cardinalities of omega-languages of
Turing machines. Firstly, it is $D_2(\Sigma_1^1)$-complete to determine whether
the omega-language of a given Turing machine is countably infinite, where
$D_2(\Sigma_1^1)$ is the class of 2-differences of $\Sigma_1^1$-sets. Secondly,
it is $\Sigma_1^1$-complete to determine whether the omega-language of a given
Turing machine is uncountable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0737</identifier>
 <datestamp>2012-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0737</id><created>2009-09-03</created><updated>2012-10-16</updated><authors><author><keyname>Lam</keyname><forenames>Tin Yin</forenames></author><author><keyname>Meyer</keyname><forenames>Irmtraud M.</forenames></author></authors><title>Efficient algorithms for training the parameters of hidden Markov models
  using stochastic expectation maximization EM training and Viterbi training</title><categories>q-bio.QM cs.LG q-bio.GN</categories><comments>32 pages including 9 figures and 2 tables</comments><journal-ref>BMC Algorithms for Molecular Biology (2010) 5:38</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Hidden Markov models are widely employed by numerous
bioinformatics programs used today. Applications range widely from comparative
gene prediction to time-series analyses of micro-array data. The parameters of
the underlying models need to be adjusted for specific data sets, for example
the genome of a particular species, in order to maximize the prediction
accuracy. Computationally efficient algorithms for parameter training are thus
key to maximizing the usability of a wide range of bioinformatics applications.
  Results: We introduce two computationally efficient training algorithms, one
for Viterbi training and one for stochastic expectation maximization (EM)
training, which render the memory requirements independent of the sequence
length. Unlike the existing algorithms for Viterbi and stochastic EM training
which require a two-step procedure, our two new algorithms require only one
step and scan the input sequence in only one direction. We also implement these
two new algorithms and the already published linear-memory algorithm for EM
training into the hidden Markov model compiler HMM-Converter and examine their
respective practical merits for three small example models.
  Conclusions: Bioinformatics applications employing hidden Markov models can
use the two algorithms in order to make Viterbi training and stochastic EM
training more computationally efficient. Using these algorithms, parameter
training can thus be attempted for more complex models and longer training
sequences. The two new algorithms have the added advantage of being easier to
implement than the corresponding default algorithms for Viterbi training and
stochastic EM training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0760</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0760</id><created>2009-09-03</created><authors><author><keyname>Marques</keyname><forenames>Antonio G.</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author><author><keyname>Ramos</keyname><forenames>Javier</forenames></author></authors><title>Optimizing Orthogonal Multiple Access based on Quantized Channel State
  Information</title><categories>cs.IT math.IT</categories><comments>30 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of systems where multiple users communicate over wireless
fading links benefits from channel-adaptive allocation of the available
resources. Different from most existing approaches that allocate resources
based on perfect channel state information, this work optimizes channel
scheduling along with per user rate and power loadings over orthogonal fading
channels, when both terminals and scheduler rely on quantized channel state
information. Channel-adaptive policies are designed to optimize an average
transmit-performance criterion subject to average quality of service
requirements. While the resultant optimal policy per fading realization shows
that the individual rate and power loadings can be obtained separately for each
user, the optimal scheduling is slightly more complicated. Specifically, per
fading realization each channel is allocated either to a single (winner) user,
or, to a small group of winner users whose percentage of shared resources is
found by solving a linear program. A single scheduling scheme combining both
alternatives becomes possible by smoothing the original disjoint scheme. The
smooth scheduling is asymptotically optimal and incurs reduced computational
complexity. Different alternatives to obtain the Lagrange multipliers required
to implement the channel-adaptive policies are proposed, including stochastic
iterations that are provably convergent and do not require knowledge of the
channel distribution. The development of the optimal channel-adaptive
allocation is complemented with discussions on the overhead required to
implement the novel policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0763</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0763</id><created>2009-09-03</created><authors><author><keyname>Ying</keyname><forenames>Lei</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author></authors><title>The Asymptotic Behavior of Minimum Buffer Size Requirements in Large P2P
  Streaming Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growth of real-time content streaming over the Internet has resulted in
the use of peer-to-peer (P2P) approaches for scalable content delivery. In such
P2P streaming systems, each peer maintains a playout buffer of content chunks
which it attempts to fill by contacting other peers in the network. The
objective is to ensure that the chunk to be played out is available with high
probability while keeping the buffer size small. Given that a particular peer
has been selected, a \emph{policy} is a rule that suggests which chunks should
be requested by the peer from other peers.. We consider consider a number of
recently suggested policies consistent with buffer minimization for a given
target of skip free playout. We first study a \emph{rarest-first} policy that
attempts to obtain chunks farthest from playout, and a \emph{greedy} policy
that attempts to obtain chunks nearest to playout. We show that they both have
similar buffer scalings (as a function of the number of peers of target
probability of skip-free probability). We then study a hybrid policy which
achieves order sense improvements over both policies and can achieve order
optimal performance. We validate our results using simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0764</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0764</id><created>2009-09-03</created><authors><author><keyname>Wu</keyname><forenames>Aihua</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Object-Oriented Intensional Programming: Intensional Classes Using Java
  and Lucid</title><categories>cs.PL cs.DC</categories><comments>27 pages, 8 listings, 2 tables, 5 figures</comments><acm-class>D.3.1; D.3.2; D.3.3; H.3.4</acm-class><doi>10.1109/SERA.2010.29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces Object-Oriented Intensional Programming (OO-IP), a
new hybrid language between Object-Oriented and Intensional Programming
Languages in the sense of the latest evolutions of Lucid. This new hybrid
language combines the essential characteristics of Lucid and Java, and
introduces the notion of object streams which makes it is possible that each
element in a Lucid stream to be an object with embedded intensional properties.
Interestingly, this hybrid language also brings to Java objects the power to
explicitly express and manipulate the notion of context, creating the novel
concept of intensional object, i.e. objects whose evaluation is
context-dependent, which are here demonstrated to be translatable into standard
objects. By this new approach, we extend the use and meaning of the notion of
intensional objects and enrich the meaning of object streams in Lucid and
semantics of intensional objects in Java.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0777</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0777</id><created>2009-09-03</created><authors><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Donoho</keyname><forenames>David L.</forenames></author></authors><title>Optimally Tuned Iterative Reconstruction Algorithms for Compressed
  Sensing</title><categories>cs.NA cs.IT cs.MS math.IT</categories><comments>12 pages, 14 figures</comments><doi>10.1109/JSTSP.2009.2039176</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We conducted an extensive computational experiment, lasting multiple
CPU-years, to optimally select parameters for two important classes of
algorithms for finding sparse solutions of underdetermined systems of linear
equations. We make the optimally tuned implementations available at {\tt
sparselab.stanford.edu}; they run `out of the box' with no user tuning: it is
not necessary to select thresholds or know the likely degree of sparsity. Our
class of algorithms includes iterative hard and soft thresholding with or
without relaxation, as well as CoSaMP, subspace pursuit and some natural
extensions. As a result, our optimally tuned algorithms dominate such
proposals. Our notion of optimality is defined in terms of phase transitions,
i.e. we maximize the number of nonzeros at which the algorithm can successfully
operate. We show that the phase transition is a well-defined quantity with our
suite of random underdetermined linear systems. Our tuning gives the highest
transition possible within each class of algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0801</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0801</id><created>2009-09-03</created><updated>2010-12-26</updated><authors><author><keyname>Veness</keyname><forenames>Joel</forenames></author><author><keyname>Ng</keyname><forenames>Kee Siong</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Uther</keyname><forenames>William</forenames></author><author><keyname>Silver</keyname><forenames>David</forenames></author></authors><title>A Monte Carlo AIXI Approximation</title><categories>cs.AI cs.IT cs.LG math.IT</categories><comments>51 LaTeX pages, 11 figures, 6 tables, 4 algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a principled approach for the design of a scalable
general reinforcement learning agent. Our approach is based on a direct
approximation of AIXI, a Bayesian optimality notion for general reinforcement
learning agents. Previously, it has been unclear whether the theory of AIXI
could motivate the design of practical algorithms. We answer this hitherto open
question in the affirmative, by providing the first computationally feasible
approximation to the AIXI agent. To develop our approximation, we introduce a
new Monte-Carlo Tree Search algorithm along with an agent-specific extension to
the Context Tree Weighting algorithm. Empirically, we present a set of
encouraging results on a variety of stochastic and partially observable
domains. We conclude by proposing a number of directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0809</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0809</id><created>2009-09-04</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>An Infinite Family of Recursive Formulas Generating Power Moments of
  Kloosterman Sums with Trace One Arguments: O(2n+1,2^r) Case</title><categories>math.NT cs.IT math.IT</categories><comments>14 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct an infinite family of binary linear codes
associated with double cosets with respect to certain maximal parabolic
subgroup of the orthogonal group O(2n+1,q). Here q is a power of two. Then we
obtain an infinite family of recursive formulas generating the odd power
moments of Kloosterman sums with trace one arguments in terms of the
frequencies of weights in the codes associated with those double cosets in
O(2n+1,q) and in the codes associated with similar double cosets in the
symplectic group Sp(2n,q). This is done via Pless power moment identity and by
utilizing the explicit expressions of exponential sums over those double cosets
related to the evaluations of &quot;Gauss sums&quot; for the orthogonal group O(2n+1,q).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0811</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0811</id><created>2009-09-04</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Ternary Codes Associated with O^-(2n,q) and Power Moments of Kloosterman
  Sums with Square Arguments</title><categories>math.NT cs.IT math.IT</categories><comments>16 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct three ternary linear codes associated with the
orthogonal group O^-(2,q) and the special orthogonal groups SO^-(2,q) and
SO^-(4,q). Here q is a power of three. Then we obtain recursive formulas for
the power moments of Kloosterman sums with square arguments and for the even
power moments of those in terms of the frequencies of weights in the codes.
This is done via Pless power moment identity and by utilizing the explicit
expressions of &quot;Gauss sums&quot; for the orthogonal and special orthogonal groups
O^-(2n,q) and SO^-(2n,q).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0814</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0814</id><created>2009-09-04</created><authors><author><keyname>Bhattacharya</keyname><forenames>Binay</forenames></author><author><keyname>Bishnu</keyname><forenames>Arijit</forenames></author><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Das</keyname><forenames>Sandip</forenames></author><author><keyname>Karmakar</keyname><forenames>Arindam</forenames></author><author><keyname>Snoeyink</keyname><forenames>Jack</forenames></author></authors><title>On Finding Non-dominated Points using Compact Voronoi Diagrams</title><categories>cs.CG cs.DS</categories><comments>11 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss in this paper a method of finding skyline or non-dominated points
in a set $P$ of $n_P$ points with respect to a set $S$ of $n_S$ sites. A point
$p_i \in P$ is non-dominated if and only if for each $p_j \in P$, $j \not= i$,
there exists at least one point $s \in S$ that is closer to $p_i$ than $p_j$.
We reduce this problem of determining non-dominated points to the problem of
finding sites that have non-empty cells in an additive Voronoi diagram with a
convex distance function. The weights of the additive Voronoi diagram are
derived from the co-ordinates of the points of $P$ and the convex distance
function is derived from $S$. In the 2-dimensional plane, this reduction gives
a $O((n_S + n_P)\log n_S + n_P \log n_P)$-time randomized incremental algorithm
to find the non-dominated points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0844</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0844</id><created>2009-09-04</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>High-Dimensional Non-Linear Variable Selection through Hierarchical
  Kernel Learning</title><categories>cs.LG math.ST stat.TH</categories><proxy>ccsd hal-00413473</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of high-dimensional non-linear variable selection for
supervised learning. Our approach is based on performing linear selection among
exponentially many appropriately defined positive definite kernels that
characterize non-linear interactions between the original variables. To select
efficiently from these many kernels, we use the natural hierarchical structure
of the problem to extend the multiple kernel learning framework to kernels that
can be embedded in a directed acyclic graph; we show that it is then possible
to perform kernel selection through a graph-adapted sparsity-inducing norm, in
polynomial time in the number of selected kernels. Moreover, we study the
consistency of variable selection in high-dimensional settings, showing that
under certain assumptions, our regularization framework allows a number of
irrelevant variables which is exponential in the number of observations. Our
simulations on synthetic datasets and datasets from the UCI repository show
state-of-the-art predictive performance for non-linear regression problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0884</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0884</id><created>2009-09-04</created><updated>2010-02-05</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>Inferring Loop Invariants using Postconditions</title><categories>cs.SE cs.LO</categories><comments>Slightly revised version</comments><journal-ref>Fields of Logic and Computation: Essays Dedicated to Yuri Gurevich
  on the Occasion of His 70th Birthday. Lecture Notes in Computer Science,
  6300:277--300, Springer, August 2010</journal-ref><doi>10.1007/978-3-642-15025-8_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the obstacles in automatic program proving is to obtain suitable loop
invariants.
  The invariant of a loop is a weakened form of its postcondition (the loop's
goal, also known as its contract); the present work takes advantage of this
observation by using the postcondition as the basis for invariant inference,
using various heuristics such as &quot;uncoupling&quot; which prove useful in many
important algorithms.
  Thanks to these heuristics, the technique is able to infer invariants for a
large variety of loop examples.
  We present the theory behind the technique, its implementation (freely
available for download and currently relying on Microsoft Research's Boogie
tool), and the results obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0892</identifier>
 <datestamp>2014-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0892</id><created>2009-09-04</created><updated>2014-11-30</updated><authors><author><keyname>Lucier</keyname><forenames>Brendan</forenames><affiliation>University of Toronto</affiliation></author><author><keyname>Borodin</keyname><forenames>Allan</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Price of Anarchy for Greedy Auctions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider auctions in which greedy algorithms, paired with first-price or
critical-price payment rules, are used to resolve multi-parameter combinatorial
allocation problems. We study the price of anarchy for social welfare in such
auctions. We show for a variety of equilibrium concepts, including Bayes-Nash
equilibrium and correlated equilibrium, the resulting price of anarchy bound is
close to the approximation factor of the underlying greedy algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0901</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0901</id><created>2009-09-04</created><authors><author><keyname>Staab</keyname><forenames>Eugen</forenames></author><author><keyname>Caminada</keyname><forenames>Martin</forenames></author></authors><title>Assessing the Impact of Informedness on a Consultant's Profit</title><categories>cs.AI</categories><comments>20 pages, 42 figures, Technical Report, University of Luxembourg</comments><report-no>ISBN 978-2-87971-027-3</report-no><acm-class>H.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the notion of informedness in a client-consultant setting. Using a
software simulator, we examine the extent to which it pays off for consultants
to provide their clients with advice that is well-informed, or with advice that
is merely meant to appear to be well-informed. The latter strategy is
beneficial in that it costs less resources to keep up-to-date, but carries the
risk of a decreased reputation if the clients discover the low level of
informedness of the consultant. Our experimental results indicate that under
different circumstances, different strategies yield the optimal results (net
profit) for the consultants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0941</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0941</id><created>2009-09-04</created><authors><author><keyname>Goemans</keyname><forenames>Michel X.</forenames></author><author><keyname>Harvey</keyname><forenames>Nicholas J. A.</forenames></author><author><keyname>Jain</keyname><forenames>Kamal</forenames></author><author><keyname>Singh</keyname><forenames>Mohit</forenames></author></authors><title>A Randomized Rounding Algorithm for the Asymmetric Traveling Salesman
  Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for the asymmetric traveling salesman problem on
instances which satisfy the triangle inequality. Like several existing
algorithms, it achieves approximation ratio O(log n). Unlike previous
algorithms, it uses randomized rounding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.0996</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.0996</id><created>2009-09-05</created><updated>2011-01-05</updated><authors><author><keyname>Sukhavasi</keyname><forenames>Ravi Teja</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>The Kalman Like Particle Filter : Optimal Estimation With Quantized
  Innovations/Measurements</title><categories>cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of optimal estimation and control of linear systems
using quantized measurements, with a focus on applications over sensor
networks. We show that the state conditioned on a causal quantization of the
measurements can be expressed as the sum of a Gaussian random vector and a
certain truncated Gaussian vector. This structure bears close resemblance to
the full information Kalman filter and so allows us to effectively combine the
Kalman structure with a particle filter to recursively compute the state
estimate. We call the resulting filter the Kalman like particle filter (KLPF)
and observe that it delivers close to optimal performance using far fewer
particles than that of a particle filter directly applied to the original
problem. We show that the conditional state density follows a, so called,
generalized closed skew-normal (GCSN) distribution. We further show that for
such systems the classical separation property between control and estimation
holds and that the certainty equivalent control law is LQG optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1011</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1011</id><created>2009-09-05</created><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Bits About the Channel: Multi-round Protocols for Two-way Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol.57, no.6,
  pp.3352,3370, June 2011</journal-ref><doi>10.1109/TIT.2011.2137090</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most communication systems use some form of feedback, often related to
channel state information. In this paper, we study diversity multiplexing
tradeoff for both FDD and TDD systems, when both receiver and transmitter
knowledge about the channel is noisy and potentially mismatched. For FDD
systems, we first extend the achievable tradeoff region for 1.5 rounds of
message passing to get higher diversity compared to the best known scheme, in
the regime of higher multiplexing gains. We then break the mold of all current
channel state based protocols by using multiple rounds of conferencing to
extract more bits about the actual channel. This iterative refinement of the
channel increases the diversity order with every round of communication. The
protocols are on-demand in nature, using high powers for training and feedback
only when the channel is in poor states. The key result is that the diversity
multiplexing tradeoff with perfect training and K levels of perfect feedback
can be achieved, even when there are errors in training the receiver and errors
in the feedback link, with a multi-round protocol which has K rounds of
training and K-1 rounds of binary feedback. The above result can be viewed as a
generalization of Zheng and Tse, and Aggarwal and Sabharwal, where the result
was shown to hold for K=1 and K=2 respectively. For TDD systems, we also
develop new achievable strategies with multiple rounds of communication between
the transmitter and the receiver, which use the reciprocity of the forward and
the feedback channel. The multi-round TDD protocol achieves a
diversity-multiplexing tradeoff which uniformly dominates its FDD counterparts,
where no channel reciprocity is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1021</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1021</id><created>2009-09-05</created><authors><author><keyname>Tranouez</keyname><forenames>Pierrick</forenames><affiliation>LITIS</affiliation></author><author><keyname>Langlois</keyname><forenames>Patrice</forenames><affiliation>IDEES</affiliation></author><author><keyname>Daud&#xe9;</keyname><forenames>Eric</forenames><affiliation>IDEES</affiliation></author></authors><title>A multiagent urban traffic simulation Part I: dealing with the ordinary</title><categories>cs.AI</categories><proxy>ccsd hal-00413713</proxy><journal-ref>ICCSA 2009, France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe in this article a multiagent urban traffic simulation, as we
believe individual-based modeling is necessary to encompass the complex
influence the actions of an individual vehicle can have on the overall flow of
vehicles. We first describe how we build a graph description of the network
from purely geometric data, ESRI shapefiles. We then explain how we include
traffic related data to this graph. We go on after that with the model of the
vehicle agents: origin and destination, driving behavior, multiple lanes,
crossroads, and interactions with the other vehicles in day-to-day, ?ordinary?
traffic. We conclude with the presentation of the resulting simulation of this
model on the Rouen agglomeration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1030</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1030</id><created>2009-09-05</created><authors><author><keyname>Ben-Amram</keyname><forenames>Amir M.</forenames></author></authors><title>The Euler Path to Static Level-Ancestors</title><categories>cs.DS</categories><comments>11 pages</comments><acm-class>E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that a rooted tree T is given for preprocessing. The Level-Ancestor
Problem is to answer quickly queries of the following form. Given a vertex v
and an integer i &gt; 0, find the i-th vertex on the path from the root to v.
Algorithms that achieve a linear time bound for preprocessing and a constant
time bound for a query have been published by Dietz (1991), Alstrup and Holm
(2000), and Bender and Farach (2002). The first two algorithms address dynamic
versions of the problem; the last addresses the static version only and is the
simplest so far. The purpose of this note is to expose another simple
algorithm, derived from a complicated PRAM algorithm by Berkman and Vishkin
(1990,1994). We further show some easy extensions of its functionality, adding
queries for descendants and level successors as well as ancestors, extensions
for which the formerly known algorithms are less suitable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1037</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1037</id><created>2009-09-05</created><updated>2010-08-04</updated><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Randomized Shellsort: A Simple Oblivious Sorting Algorithm</title><categories>cs.DS</categories><comments>Version of paper accepted to 2010 ACM-SIAM Symposium on Discrete
  Algorithms (SODA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe randomized Shellsort--a simple, randomized,
data-oblivious version of the Shellsort algorithm that always runs in O(n log
n) time and, as we show, succeeds in sorting any given input permutation with
very high probability. Thus, randomized Shellsort is simultaneously simple,
time-optimal, and data-oblivious. Taken together, these properties imply
applications in the design of new efficient privacy-preserving computations
based on the secure multi-party computation (SMC) paradigm. In addition, by a
trivial conversion of this Monte Carlo algorithm to its Las Vegas equivalent,
one gets the first version of Shellsort with a running time that is provably
O(n log n) with very high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1045</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1045</id><created>2009-09-05</created><authors><author><keyname>de Aguiar</keyname><forenames>Alexei Barbosa</forenames></author><author><keyname>Pinheiro</keyname><forenames>Placido Rogerio</forenames></author><author><keyname>Neto</keyname><forenames>Alvaro de Menezes S.</forenames></author><author><keyname>Cunha</keyname><forenames>Ruddy P. P.</forenames></author><author><keyname>Pinheiro</keyname><forenames>Rebecca F.</forenames></author></authors><title>A Novel Model for Optimized GSM Network Design</title><categories>cs.NI</categories><comments>6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSn 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GSM networks are very expensive. The network design process requires too many
decisions in a combinatorial explosion. For this reason, the larger is the
network, the harder is to achieve a totally human based optimized solution. The
BSC (Base Station Control) nodes have to be geographically well allocated to
reduce the transmission costs. There are decisions of association between BTS
and BSC those impacts in the correct dimensioning of these BSC. The choice of
BSC quantity and model capable of carrying the cumulated traffic of its
affiliated BTS nodes in turn reflects on the total cost. In addition, the last
component of the total cost is due to transmission for linking BSC nodes to
MSC. These trunks have a major significance since the number of required E1
lines is larger than BTS to BSC link. This work presents an integer programming
model and a computational tool for designing GSM (Global System for Mobile
Communications) networks, regarding BSS (Base Station Subsystem) with optimized
cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1049</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1049</id><created>2009-09-05</created><authors><author><keyname>Doja</keyname><forenames>M. N.</forenames></author><author><keyname>Saini</keyname><forenames>Dharmender</forenames></author></authors><title>Electronic Authority Variation</title><categories>cs.CR</categories><comments>5 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a person joins in an organization, he becomes authorize to take some
decisions on behalf of that organization; means he is given some authority to
exercise. After some time, on the basis of his performance in the organization,
he is given promotion and he becomes eligible to exercise to some higher
authorities. And further, he may get some higher promotion or he may leave the
organization. So, during his stay in the organization, the authority of that
person varies from the time he joins the organization until he/she leaves the
organization. This paper presents the variation in authorities of a person in
the organization. The method implements the queuing model to analyze the
various people in the queue of their promotion and looks at various parameters
like average waiting time etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1051</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1051</id><created>2009-09-05</created><authors><author><keyname>Kabatiansky</keyname><forenames>G.</forenames><affiliation>Dobrushin Mathematical Laboratory, Institute of Information Transmission Problems, Moscow, Russia</affiliation><affiliation>Laboratory J.-V. Poncelet, Independent University of Moscow, Russia</affiliation></author><author><keyname>Oshanin</keyname><forenames>G.</forenames><affiliation>Laboratory J.-V. Poncelet, Independent University of Moscow, Russia</affiliation><affiliation>LPTMC, University Pierre &amp; Marie Curie, Paris, France</affiliation></author></authors><title>Finding passwords by random walks: How long does it take?</title><categories>cs.CR cond-mat.other cs.DS math.PR</categories><comments>To appear in J. Phys. A, special issue on &quot;Random Search Problem:
  Trends and Perspectives&quot;, eds.: MEG da Luz, E Raposo, GM Viswanathan and A
  Grosberg</comments><journal-ref>J. Phys. A 42 No 43, 434016 (2009)</journal-ref><doi>10.1088/1751-8113/42/43/434016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare an efficiency of a deterministic &quot;lawnmower&quot; and random search
strategies for finding a prescribed sequence of letters (a password) of length
M in which all letters are taken from the same Q-ary alphabet. We show that at
best a random search takes two times longer than a &quot;lawnmower&quot; search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1062</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1062</id><created>2009-09-05</created><updated>2010-09-14</updated><authors><author><keyname>Saha</keyname><forenames>Ankan</forenames><affiliation>University of Chicago</affiliation></author><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Zhang</keyname><forenames>Xinhua</forenames><affiliation>University of Alberta</affiliation></author></authors><title>New Approximation Algorithms for Minimum Enclosing Convex Shapes</title><categories>cs.CG cs.DS cs.LG</categories><comments>18 Pages Accepted in SODA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given $n$ points in a $d$ dimensional Euclidean space, the Minimum Enclosing
Ball (MEB) problem is to find the ball with the smallest radius which contains
all $n$ points. We give a $O(nd\Qcal/\sqrt{\epsilon})$ approximation algorithm
for producing an enclosing ball whose radius is at most $\epsilon$ away from
the optimum (where $\Qcal$ is an upper bound on the norm of the points). This
improves existing results using \emph{coresets}, which yield a $O(nd/\epsilon)$
greedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is a
related problem wherein a convex polytope of a fixed shape is given and the aim
is to find the smallest magnification of the polytope which encloses the given
points. For this problem we present a $O(mnd\Qcal/\epsilon)$ approximation
algorithm, where $m$ is the number of faces of the polytope. Our algorithms
borrow heavily from convex duality and recently developed techniques in
non-smooth optimization, and are in contrast with existing methods which rely
on geometric arguments. In particular, we specialize the excessive gap
framework of \citet{Nesterov05a} to obtain our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1072</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1072</id><created>2009-09-06</created><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Fiat</keyname><forenames>Amos</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Olonetsky</keyname><forenames>Svetlana</forenames></author></authors><title>Envy-Free Makespan Approximation</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study envy-free mechanisms for scheduling tasks on unrelated machines
(agents) that approximately minimize the makespan. For indivisible tasks, we
put forward an envy-free poly-time mechanism that approximates the minimal
makespan to within a factor of $O(\log m)$, where $m$ is the number of
machines. We also show a lower bound of $\Omega(\log m / \log\log m)$. This
improves the recent result of Hartline {\sl et al.} \cite{Ahuva:2008} who give
an upper bound of $(m+1)/2$, and a lower bound of $2-1/m$. For divisible tasks,
we show that there always exists an envy-free poly-time mechanism with optimal
makespan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1102</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1102</id><created>2009-09-06</created><authors><author><keyname>G&#xf6;ller</keyname><forenames>Stefan</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author></authors><title>Branching-time model checking of one-counter processes</title><categories>cs.LO cs.CC</categories><acm-class>F.4.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-counter processes (OCPs) are pushdown processes which operate only on a
unary stack alphabet. We study the computational complexity of model checking
computation tree logic (CTL) over OCPs. A PSPACE upper bound is inherited from
the modal mu-calculus for this problem. First, we analyze the periodic
behaviour of CTL over OCPs and derive a model checking algorithm whose running
time is exponential only in the number of control locations and a syntactic
notion of the formula that we call leftward until depth. Thus, model checking
fixed OCPs against CTL formulas with a fixed leftward until depth is in P. This
generalizes a result of the first author, Mayr, and To for the expression
complexity of CTL's fragment EF. Second, we prove that already over some fixed
OCP, CTL model checking is PSPACE-hard. Third, we show that there already
exists a fixed CTL formula for which model checking of OCPs is PSPACE-hard. To
obtain the latter result, we employ two results from complexity theory: (i)
Converting a natural number in Chinese remainder presentation into binary
presentation is in logspace-uniform NC^1 and (ii) PSPACE is AC^0-serializable.
We demonstrate that our approach can be used to obtain further results. We show
that model-checking CTL's fragment EF over OCPs is hard for P^NP, thus
establishing a matching lower bound and answering an open question of the first
author, Mayr, and To. We moreover show that the following problem is hard for
PSPACE: Given a one-counter Markov decision process, a set of target states
with counter value zero each, and an initial state, to decide whether the
probability that the initial state will eventually reach one of the target
states is arbitrarily close to 1. This improves a previously known lower bound
for every level of the Boolean hierarchy by Brazdil et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1115</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1115</id><created>2009-09-06</created><authors><author><keyname>Zhu</keyname><forenames>Yan</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Capacity Region of Layered Erasure One-sided Interference Channels
  without CSIT</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a layered erasure interference channel model, which is a
simplification of the Gaussian interference channel with fading using the
deterministic model approach. In particular, the capacity region of the layered
erasure one-sided interference channel is completely determined, assuming that
the channel state information (CSI) is known to the receivers, but there is no
CSI at transmitters (CSIT). The result holds for arbitrary fading statistics.
Previous results of Aggarwal, Sankar, Calderbank and Poor on the capacity
region or sum capacity under several interference configurations are shown to
be special cases of the capacity region shown in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1127</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1127</id><created>2009-09-06</created><authors><author><keyname>Wong</keyname><forenames>Raymond Chi-Wing</forenames></author><author><keyname>Fu</keyname><forenames>Ada Wai-Chee</forenames></author><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Xu</keyname><forenames>Yabo</forenames></author><author><keyname>Pei</keyname><forenames>Jian</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author></authors><title>Anonymization with Worst-Case Distribution-Based Background Knowledge</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background knowledge is an important factor in privacy preserving data
publishing. Distribution-based background knowledge is one of the well studied
background knowledge. However, to the best of our knowledge, there is no
existing work considering the distribution-based background knowledge in the
worst case scenario, by which we mean that the adversary has accurate knowledge
about the distribution of sensitive values according to some tuple attributes.
Considering this worst case scenario is essential because we cannot overlook
any breaching possibility. In this paper, we propose an algorithm to anonymize
dataset in order to protect individual privacy by considering this background
knowledge. We prove that the anonymized datasets generated by our proposed
algorithm protects individual privacy. Our empirical studies show that our
method preserves high utility for the published data at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1138</identifier>
 <datestamp>2009-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1138</id><created>2009-09-06</created><updated>2009-11-01</updated><authors><author><keyname>Diamond</keyname><forenames>Richard V.</forenames></author></authors><title>User Experience, Software Interfaces, and The Unconscious</title><categories>cs.HC</categories><comments>Under Review</comments><acm-class>A.1; C.4; H.1.2; H.5.2; K.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Ideas about how to increase the unconscious participation in interaction
between 'a human' and 'a computer' are developed in this paper. Evidence of
impact of the unconscious functioning is presented. The unconscious is
characterised as being a responsive, contextual, and autonomous participant of
human-computer interaction. The unconscious participation occurs independently
of one's cognitive and educational levels and, if ignored, leads to learning
inefficiencies and compulsive behaviours, illustrations of which are provided.
Three practical approaches to a study of subjective user experience are
outlined as follows: (a) tracing operant conditioning effects of software, (b)
registering signs of brain activity psychological or information processing
meaning of which is well-explored and (c) exploring submodality interfaces.
Implications for improvement of current usability study methods, such as
eye-tracking, are generally considered. Conclusions consider advantages and
disadvantages of unconscious-embracing design and remind about a loss of human
evolutionary choices if unconscious participation is ignored, complicated or
blocked in interaction with computer interfaces and built environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1145</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1145</id><created>2009-09-07</created><authors><author><keyname>Thaw</keyname><forenames>Yi Yi</forenames></author><author><keyname>Mahmood</keyname><forenames>Ahmad Kamil</forenames></author><author><keyname>Dominic</keyname><forenames>P. Dhanapal Durai</forenames></author></authors><title>A Study on the Factors That Influence the Consumers Trust on Ecommerce
  Adoption</title><categories>cs.CY</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of electronic commerce is characterized with anonymity,
uncertainty, lack of control and potential opportunism. Therefore, the success
of electronic commerce significantly depends on providing security and privacy
for its consumers sensitive personal data. Consumers lack of acceptance in
electronic commerce adoption today is not merely due to the concern on security
and privacy of their personal data, but also lack of trust and reliability of
Web vendors. Consumers trust in online transactions is crucial for the
continuous growth and development of electronic commerce. Since Business to
Consumer (B2C) ecommerce requires the consumers to engage the technologies, the
consumers face a variety of security risks. This study addressed the role of
security, privacy and risk perceptions of consumers to shop online in order to
establish a consensus among them. The analyses provided descriptive frequencies
for the research variables and for each of the study s research constructs. In
addition, the analyses were completed with factor analysis and Pearson
correlation coefficients. The findings suggested that perceived privacy of
online transaction on trust is mediated by perceived security, and consumers
trust in online transaction is significantly related with the trustworthiness
of Web vendors. Also, consumers trust is negatively associated with perceived
risks in online transactions. However, there is no significant impact from
perceived security and perceived privacy to trust in online transactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1146</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1146</id><created>2009-09-07</created><authors><author><keyname>Garg</keyname><forenames>Saurabh Kumar</forenames></author><author><keyname>Yeo</keyname><forenames>Chee Shin</forenames></author><author><keyname>Anandasivam</keyname><forenames>Arun</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Energy-Efficient Scheduling of HPC Applications in Cloud Computing
  Environments</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of High Performance Computing (HPC) in commercial and consumer IT
applications is becoming popular. They need the ability to gain rapid and
scalable access to high-end computing capabilities. Cloud computing promises to
deliver such a computing infrastructure using data centers so that HPC users
can access applications and data from a Cloud anywhere in the world on demand
and pay based on what they use. However, the growing demand drastically
increases the energy consumption of data centers, which has become a critical
issue. High energy consumption not only translates to high energy cost, which
will reduce the profit margin of Cloud providers, but also high carbon
emissions which is not environmentally sustainable. Hence, energy-efficient
solutions are required that can address the high increase in the energy
consumption from the perspective of not only Cloud provider but also from the
environment. To address this issue we propose near-optimal scheduling policies
that exploits heterogeneity across multiple data centers for a Cloud provider.
We consider a number of energy efficiency factors such as energy cost, carbon
emission rate, workload, and CPU power efficiency which changes across
different data center depending on their location, architectural design, and
management system. Our carbon/energy based scheduling policies are able to
achieve on average up to 30% of energy savings in comparison to profit based
scheduling policies leading to higher profit and less carbon emissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1147</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1147</id><created>2009-09-07</created><authors><author><keyname>Pillai</keyname><forenames>B Prabhulla Chandran</forenames></author></authors><title>Empowering OLAC Extension using Anusaaraka and Effective text processing
  using Double Byte coding</title><categories>cs.CL</categories><comments>5 Pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper reviews the hurdles while trying to implement the OLAC extension
for Dravidian / Indian languages. The paper further explores the possibilities
which could minimise or solve these problems. In this context, the Chinese
system of text processing and the anusaaraka system are scrutinised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1151</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1151</id><created>2009-09-07</created><authors><author><keyname>Sallantin</keyname><forenames>Jean</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Seilles</keyname><forenames>Antoine</forenames><affiliation>LIRMM</affiliation></author></authors><title>n-Opposition theory to structure debates</title><categories>cs.AI</categories><proxy>ccsd hal-00412280</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  2007 was the first international congress on the ?square of oppositions?. A
first attempt to structure debate using n-opposition theory was presented along
with the results of a first experiment on the web. Our proposal for this paper
is to define relations between arguments through a structure of opposition
(square of oppositions is one structure of opposition). We will be trying to
answer the following questions: How to organize debates on the web 2.0? How to
structure them in a logical way? What is the role of n-opposition theory, in
this context? We present in this paper results of three experiments
(Betapolitique 2007, ECAP 2008, Intermed 2008).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1153</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1153</id><created>2009-09-07</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Recursive formulas generating power moments of multi-dimensional
  Kloosterman sums and $m$-multiple power moments of Kloosterman sums</title><categories>math.NT cs.IT math.IT</categories><comments>14 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct two binary linear codes associated with
multi-dimensional and $m -$multiple power Kloosterman sums (for any fixed $m$)
over the finite field $\mathbb{F}_{q}$. Here $q$ is a power of two. The former
codes are dual to a subcode of the binary hyper-Kloosterman code. Then we
obtain two recursive formulas for the power moments of multi-dimensional
Kloosterman sums and for the $m$-multiple power moments of Kloosterman sums in
terms of the frequencies of weights in the respective codes. This is done via
Pless power moment identity and yields, in the case of power moments of
multi-dimensional Kloosterman sums, much simpler recursive formulas than those
associated with finite special linear groups obtained previously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1156</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1156</id><created>2009-09-07</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Ternary Codes Associated with $O(3,3^r)$ and Power Moments of
  Kloosterman Sums with Trace Nonzero Square Arguments</title><categories>math.NT cs.IT math.IT</categories><comments>15 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct two ternary linear codes $C(SO(3,q))$ and
$C(O(3,q))$, respectively associated with the orthogonal groups $SO(3,q)$ and
$O(3,q)$. Here $q$ is a power of three. Then we obtain two recursive formulas
for the power moments of Kloosterman sums with $``$trace nonzero square
arguments&quot; in terms of the frequencies of weights in the codes. This is done
via Pless power moment identity and by utilizing the explicit expressions of
Gauss sums for the orthogonal groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1175</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1175</id><created>2009-09-07</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Infinite Families of Recursive Formulas Generating Power Moments of
  Ternary Kloosterman Sums with Trace Nonzero Square Arguments: $O(2n+1,2^{r})$
  Case</title><categories>math.NT cs.IT math.IT</categories><comments>19 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct four infinite families of ternary linear codes
associated with double cosets in $O(2n+1,q)$ with respect to certain maximal
parabolic subgroup of the special orthogonal group $SO(2n+1,q)$. Here $q$ is a
power of three. Then we obtain two infinite families of recursive formulas, the
one generating the power moments of Kloosterman sums with $``$trace nonzero
square arguments&quot; and the other generating the even power moments of those.
Both of these families are expressed in terms of the frequencies of weights in
the codes associated with those double cosets in $O(2n+1,q)$ and in the codes
associated with similar double cosets in the symplectic group $Sp(2n,q)$. This
is done via Pless power moment identity and by utilizing the explicit
expressions of exponential sums over those double cosets related to the
evaluations of $&quot;$Gauss sums&quot; for the orthogonal group $O(2n+1,q)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1178</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1178</id><created>2009-09-07</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Infinite Families of Recursive Formulas Generating Power Moments of
  Ternary Kloosterman Sums with Square Arguments Associated with
  $O^{-}_{}(2n,q)$</title><categories>math.NT cs.IT math.IT</categories><comments>20 pages</comments><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct eight infinite families of ternary linear codes
associated with double cosets with respect to certain maximal parabolic
subgroup of the special orthogonal group $SO^{-}(2n,q)$. Here ${q}$ is a power
of three. Then we obtain four infinite families of recursive formulas for power
moments of Kloosterman sums with square arguments and four infinite families of
recursive formulas for even power moments of those in terms of the frequencies
of weights in the codes. This is done via Pless power moment identity and by
utilizing the explicit expressions of exponential sums over those double cosets
related to the evaluations of $&quot;$Gauss sums&quot; for the orthogonal groups
$O^{-}(2n,q)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1186</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1186</id><created>2009-09-07</created><authors><author><keyname>Yukalov</keyname><forenames>V. I.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Scheme of thinking quantum systems</title><categories>quant-ph cond-mat.quant-gas cs.AI</categories><comments>Latex file, 15 pages, 1 figure</comments><journal-ref>Laser Phys. Lett. 6 (2009) 833-839</journal-ref><doi>10.1002/lapl.200910086</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general approach describing quantum decision procedures is developed. The
approach can be applied to quantum information processing, quantum computing,
creation of artificial quantum intelligence, as well as to analyzing decision
processes of human decision makers. Our basic point is to consider an active
quantum system possessing its own strategic state. Processing information by
such a system is analogous to the cognitive processes associated to decision
making by humans. The algebra of probability operators, associated with the
possible options available to the decision maker, plays the role of the algebra
of observables in quantum theory of measurements. A scheme is advanced for a
practical realization of decision procedures by thinking quantum systems. Such
thinking quantum systems can be realized by using spin lattices, systems of
magnetic molecules, cold atoms trapped in optical lattices, ensembles of
quantum dots, or multilevel atomic systems interacting with electromagnetic
field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1187</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1187</id><created>2009-09-07</created><authors><author><keyname>Aldinucci</keyname><forenames>Marco</forenames></author><author><keyname>Torquati</keyname><forenames>Massimo</forenames></author><author><keyname>Meneghin</keyname><forenames>Massimiliano</forenames></author></authors><title>FastFlow: Efficient Parallel Streaming Applications on Multi-core</title><categories>cs.DC cs.PL</categories><comments>23 pages + cover</comments><report-no>TR-09-12</report-no><acm-class>D.1.3; D.3.2; C.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shared memory multiprocessors come back to popularity thanks to rapid
spreading of commodity multi-core architectures. As ever, shared memory
programs are fairly easy to write and quite hard to optimise; providing
multi-core programmers with optimising tools and programming frameworks is a
nowadays challenge. Few efforts have been done to support effective streaming
applications on these architectures. In this paper we introduce FastFlow, a
low-level programming framework based on lock-free queues explicitly designed
to support high-level languages for streaming applications. We compare FastFlow
with state-of-the-art programming frameworks such as Cilk, OpenMP, and Intel
TBB. We experimentally demonstrate that FastFlow is always more efficient than
all of them in a set of micro-benchmarks and on a real world application; the
speedup edge of FastFlow over other solutions might be bold for fine grain
tasks, as an example +35% on OpenMP, +226% on Cilk, +96% on TBB for the
alignment of protein P01111 against UniProt DB using Smith-Waterman algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1198</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1198</id><created>2009-09-07</created><updated>2009-09-24</updated><authors><author><keyname>Normann</keyname><forenames>Dag</forenames></author></authors><title>A rich hierarchy of functionals of finite types</title><categories>cs.LO</categories><comments>21 pages</comments><acm-class>F.1.1; F.4.1; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (September
  24, 2009) lmcs:954</journal-ref><doi>10.2168/LMCS-5(3:11)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are considering typed hierarchies of total, continuous functionals using
complete, separable metric spaces at the base types. We pay special attention
to the so called Urysohn space constructed by P. Urysohn. One of the properties
of the Urysohn space is that every other separable metric space can be
isometrically embedded into it. We discuss why the Urysohn space may be
considered as the universal model of possibly infinitary outputs of algorithms.
The main result is that all our typed hierarchies may be topologically
embedded, type by type, into the corresponding hierarchy over the Urysohn
space. As a preparation for this, we prove an effective density theorem that is
also of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1209</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1209</id><created>2009-09-07</created><authors><author><keyname>Redlich</keyname><forenames>Oded</forenames></author><author><keyname>Ezri</keyname><forenames>Doron</forenames></author><author><keyname>Wulich</keyname><forenames>Dov</forenames></author></authors><title>SNR Estimation in Maximum Likelihood Decoded Spatial Multiplexing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link adaptation is a crucial part of many modern communications systems,
allowing the system to adapt the transmission and reception strategies to
changes in channel conditions. One of the fundamental components of the link
adaptation mechanism is signal to noise ratio (SNR) estimation, measuring the
instantaneous (mostly post processing) SNR at the receiver. That is, the SNR at
the decoder input, which is an important metric for the prediction of decoder
performance. In linearly decoded MIMO, which is the common MIMO decoding
strategy, the post processing SNR is well defined. However, this is not the
case in optimal maximum likelihood (ML) decoding applied to spatial
multiplexing (SM). This gap is interesting since ML decoded SM is gaining ever
growing interest in recent research and practice due to the rapid increase in
computation power, and available near optimal low complexity schemes. In this
paper we close the gap and provide SNR estimation schemes for ML decoded SM,
which are based on various approximations of the &quot;per stream&quot; error
probability. The proposed methods are applicable for both horizonal and
vertical decoding. Moreover, we propose a very low complexity implementation
for the SNR estimation mechanism employing the ML decoder itself with
negligible overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1241</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1241</id><created>2009-09-07</created><authors><author><keyname>Shah</keyname><forenames>Virag</forenames></author><author><keyname>Mehta</keyname><forenames>Neelesh B.</forenames></author><author><keyname>Yim</keyname><forenames>Raymond</forenames></author></authors><title>Optimal Timer Based Selection Schemes</title><categories>cs.NI</categories><comments>21 pages, 6 figures, 1 table, submitted to IEEE Transactions on
  Communications, uses stackrel.sty</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timer-based mechanisms are often used to help a given (sink) node select the
best helper node among many available nodes. Specifically, a node transmits a
packet when its timer expires, and the timer value is a monotone non-increasing
function of its local suitability metric. The best node is selected
successfully if no other node's timer expires within a 'vulnerability' window
after its timer expiry, and so long as the sink can hear the available nodes.
In this paper, we show that the optimal metric-to-timer mapping that (i)
maximizes the probability of success or (ii) minimizes the average selection
time subject to a minimum constraint on the probability of success, maps the
metric into a set of discrete timer values. We specify, in closed-form, the
optimal scheme as a function of the maximum selection duration, the
vulnerability window, and the number of nodes. An asymptotic characterization
of the optimal scheme turns out to be elegant and insightful. For any
probability distribution function of the metric, the optimal scheme is
scalable, distributed, and performs much better than the popular inverse metric
timer mapping. It even compares favorably with splitting-based selection, when
the latter's feedback overhead is accounted for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1257</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1257</id><created>2009-09-07</created><updated>2010-02-25</updated><authors><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author><author><keyname>Joosten</keyname><forenames>Rieks</forenames></author></authors><title>Practical Schemes For Privacy &amp; Security Enhanced RFID</title><categories>cs.CR</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proper privacy protection in RFID systems is important. However, many of the
schemes known are impractical, either because they use hash functions instead
of the more hardware efficient symmetric encryption schemes as a efficient
cryptographic primitive, or because they incur a rather costly key search time
penalty at the reader. Moreover, they do not allow for dynamic, fine-grained
access control to the tag that cater for more complex usage scenarios.
  In this paper we investigate such scenarios, and propose a model and
corresponding privacy friendly protocols for efficient and fine-grained
management of access permissions to tags. In particular we propose an efficient
mutual authentication protocol between a tag and a reader that achieves a
reasonable level of privacy, using only symmetric key cryptography on the tag,
while not requiring a costly key-search algorithm at the reader side. Moreover,
our protocol is able to recover from stolen readers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1305</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1305</id><created>2009-09-07</created><authors><author><keyname>Bobenko</keyname><forenames>Alexander I.</forenames><affiliation>IM TU-B</affiliation></author><author><keyname>Mercat</keyname><forenames>Christian</forenames><affiliation>LIRMM, I3M</affiliation></author><author><keyname>Schmies</keyname><forenames>Markus</forenames><affiliation>IM TU-B</affiliation></author></authors><title>Conformal Structures and Period Matrices of Polyhedral Surfaces</title><categories>math.DG cs.NA</categories><comments>1--13</comments><proxy>ccsd hal-00413643</proxy><msc-class>30G25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We recall the theory of linear discrete Riemann surfaces and show how to use
it in order to interpret a surface embedded in R^3 as a discrete Riemann
surface and compute its basis of holomorphic forms on it. We present numerical
examples, recovering known results to test the numerics and giving the yet
unknown period matrix of the Lawson genus-2 surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1308</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1308</id><created>2009-09-07</created><updated>2010-01-03</updated><authors><author><keyname>Sokolovska</keyname><forenames>Nataliya</forenames><affiliation>LTCI</affiliation></author><author><keyname>Lavergne</keyname><forenames>Thomas</forenames><affiliation>LIMSI</affiliation></author><author><keyname>Capp&#xe9;</keyname><forenames>Olivier</forenames><affiliation>LTCI</affiliation></author><author><keyname>Yvon</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIMSI</affiliation></author></authors><title>Efficient Learning of Sparse Conditional Random Fields for Supervised
  Sequence Labelling</title><categories>cs.LG cs.CL</categories><proxy>ccsd hal-00414107</proxy><doi>10.1109/JSTSP.2010.2076150</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional Random Fields (CRFs) constitute a popular and efficient approach
for supervised sequence labelling. CRFs can cope with large description spaces
and can integrate some form of structural dependency between labels. In this
contribution, we address the issue of efficient feature selection for CRFs
based on imposing sparsity through an L1 penalty. We first show how sparsity of
the parameter set can be exploited to significantly speed up training and
labelling. We then introduce coordinate descent parameter update schemes for
CRFs with L1 regularization. We finally provide some empirical comparisons of
the proposed approach with state-of-the-art CRF training strategies. In
particular, it is shown that the proposed approach is able to take profit of
the sparsity to speed up processing and hence potentially handle larger
dimensional models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1310</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1310</id><created>2009-09-07</created><authors><author><keyname>Bowley</keyname><forenames>James</forenames></author><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author></authors><title>Sparse image representation by discrete cosine/spline based dictionaries</title><categories>math.NA cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mixed dictionaries generated by cosine and B-spline functions are considered.
It is shown that, by highly nonlinear approaches such as Orthogonal Matching
Pursuit, the discrete version of the proposed dictionaries yields a significant
gain in the sparsity of an image representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1315</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1315</id><created>2009-09-07</created><authors><author><keyname>Anghel</keyname><forenames>Catalin</forenames></author></authors><title>Base Selection and Transmission Synchronization Algorithm in Quantum
  Cryptography</title><categories>cs.CR quant-ph</categories><comments>4 pages, 1 figure, [12]. Proceedings CSCS17 - 17th International
  Conference on Control Systems and Computer Science, Romania, Bucharest, May
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One Achilles heal of classical cryptographic communication systems is that
secret communication can only take place after a key is communicated in secret
over a totally secure communication channel. Here comes quantum key
distribution which takes advantage of certain phenomena that occur at the
subatomic level, so that any attempt by an enemy to obtain the bits in a key
not only fails, but gets detected as well. This paper proposes the idea of on
algorithm, intended to be a quantum network algorithm named Base Selection and
Transmission Synchronization - BSTS, which can realize a perfectly secure
communication between two computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1334</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1334</id><created>2009-09-07</created><updated>2009-09-08</updated><authors><author><keyname>Saha</keyname><forenames>Ankan</forenames><affiliation>University of Chicago</affiliation></author><author><keyname>Zhang</keyname><forenames>Xinhua</forenames><affiliation>Australian National University, NICTA</affiliation></author><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames><affiliation>Purdue University</affiliation></author></authors><title>Lower Bounds for BMRM and Faster Rates for Training SVMs</title><categories>cs.LG cs.AI cs.DS</categories><comments>21 pages, 49 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularized risk minimization with the binary hinge loss and its variants
lies at the heart of many machine learning problems. Bundle methods for
regularized risk minimization (BMRM) and the closely related SVMStruct are
considered the best general purpose solvers to tackle this problem. It was
recently shown that BMRM requires $O(1/\epsilon)$ iterations to converge to an
$\epsilon$ accurate solution. In the first part of the paper we use the
Hadamard matrix to construct a regularized risk minimization problem and show
that these rates cannot be improved. We then show how one can exploit the
structure of the objective function to devise an algorithm for the binary hinge
loss which converges to an $\epsilon$ accurate solution in
$O(1/\sqrt{\epsilon})$ iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1338</identifier>
 <datestamp>2012-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1338</id><created>2009-09-07</created><authors><author><keyname>Hirakawa</keyname><forenames>Keigo</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author></authors><title>&quot;Rewiring&quot; Filterbanks for Local Fourier Analysis: Theory and Practice</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, vol. 57, pp. 5360-5374,
  2011</journal-ref><doi>10.1109/TIT.2011.2158895</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a series of new results outlining equivalences between
certain &quot;rewirings&quot; of filterbank system block diagrams, and the corresponding
actions of convolution, modulation, and downsampling operators. This gives rise
to a general framework of reverse-order and convolution subband structures in
filterbank transforms, which we show to be well suited to the analysis of
filterbank coefficients arising from subsampled or multiplexed signals. These
results thus provide a means to understand time-localized aliasing and
modulation properties of such signals and their subband
representations--notions that are notably absent from the global viewpoint
afforded by Fourier analysis. The utility of filterbank rewirings is
demonstrated by the closed-form analysis of signals subject to degradations
such as missing data, spatially or temporally multiplexed data acquisition, or
signal-dependent noise, such as are often encountered in practical signal
processing applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1344</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1344</id><created>2009-09-07</created><updated>2010-03-01</updated><authors><author><keyname>Huh</keyname><forenames>Hoon</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Haralabos C.</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Multiuser MISO Transmitter Optimization for Inter-Cell Interference
  Mitigation</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, and 1 table. revised and resubmitted to IEEE
  Transactions on Signal Processing</comments><doi>10.1109/TSP.2010.2048564</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transmitter optimization (i.e., steering vectors and power allocation)
for a MISO Broadcast Channel (MISO-BC) subject to general linear constraints is
considered. Such constraints include, as special cases, the sum power, the
per-antenna or per-group-of-antennas power, and &quot;forbidden interference
direction&quot; constraints. We consider both the optimal dirty-paper coding and the
simple suboptimal linear zero-forcing beamforming strategies, and provide
numerically efficient algorithms that solve the problem in its most general
form. As an application, we consider a multi-cell scenario with partial cell
cooperation, where each cell optimizes its precoder by taking into account
interference constraints on specific users in adjacent cells. The effectiveness
of the proposed methods is evaluated in a simple system scenario including two
adjacent cells, under different fairness criteria that emphasize the bottleneck
role of users near the cell &quot;boundary&quot;. Our results show that &quot;active&quot;
Inter-Cell Interference (ICI) mitigation outperforms the conventional &quot;static&quot;
ICI mitigation based on fractional frequency reuse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1346</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1346</id><created>2009-09-07</created><updated>2011-02-22</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Kaser</keyname><forenames>Owen</forenames></author></authors><title>Reordering Columns for Smaller Indexes</title><categories>cs.DB</categories><comments>to appear in Information Sciences</comments><journal-ref>Daniel Lemire and Owen Kaser, Reordering Columns for Smaller
  Indexes, Information Sciences 181 (12), 2011</journal-ref><doi>10.1016/j.ins.2011.02.002</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Column-oriented indexes-such as projection or bitmap indexes-are compressed
by run-length encoding to reduce storage and increase speed. Sorting the tables
improves compression. On realistic data sets, permuting the columns in the
right order before sorting can reduce the number of runs by a factor of two or
more. Unfortunately, determining the best column order is NP-hard. For many
cases, we prove that the number of runs in table columns is minimized if we
sort columns by increasing cardinality. Experimentally, sorting based on
Hilbert space-filling curves is poor at minimizing the number of runs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1361</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1361</id><created>2009-09-08</created><authors><author><keyname>Le</keyname><forenames>Dai Tri Man</forenames></author></authors><title>Statechart Verification with iState</title><categories>cs.SE</categories><comments>11 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is the longer version of the extended abstract with the same name
published in FM 06. We describe in detail the algorithm to generate
verification conditions from statechart structures implemented in the iState
tool. This approach also suggests us a novel method to define a version of
predicate semantics for statecharts analogous to how we assign predicate
semantics to programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1364</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1364</id><created>2009-09-07</created><authors><author><keyname>Wang</keyname><forenames>Wenguang</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Xu</keyname><forenames>Yongping</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Chen</keyname><forenames>Xin</forenames><affiliation>Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China</affiliation><affiliation>State Key Laboratory for Complex Systems Simulation, Beijing, China</affiliation></author><author><keyname>Li</keyname><forenames>Qun</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Wang</keyname><forenames>Weiping</forenames><affiliation>College of Information System and Management, National University of Defense Technology, Changsha, China</affiliation></author></authors><title>High level architecture evolved modular federation object model</title><categories>cs.SE</categories><comments>11 pages, 3 figures, 1 table, Journal of Systems Engineering and
  Electronics, 2009, 20(3):625-635</comments><journal-ref>Journal of Systems Engineering and Electronics, 2009,
  20(3):625-635</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To improve the agility, dynamics, composability, reusability, and development
efficiency restricted by monolithic Federation Object Model (FOM), a modular
FOM was proposed by High Level Architecture (HLA) Evolved product development
group. This paper reviews the state-of-the-art of HLA Evolved modular FOM. In
particular, related concepts, the overall impact on HLA standards, extension
principles, and merging processes are discussed. Also permitted and restricted
combinations, and merging rules are provided, and the influence on HLA
interface specification is given. The comparison between modular FOM and Base
Object Model (BOM) is performed to illustrate the importance of their
combination. The applications of modular FOM are summarized. Finally, the
significance to facilitate composable simulation both in academia and practice
is presented and future directions are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1372</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1372</id><created>2009-09-07</created><authors><author><keyname>Kadhum</keyname><forenames>Mohammed M.</forenames></author><author><keyname>Hassan</keyname><forenames>Suhaidi</forenames></author></authors><title>The Uniformization Process of the Fast Congestion Notification (FN)</title><categories>cs.NI cs.DS</categories><comments>5 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500,Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast Congestion Notification (FN) is one of the proactive queue management
mechanisms that practices congestion avoidance to help avoid the beginning of
congestion by marking or dropping packets before the routers queue gets full;
and exercises congestion control, when congestion avoidance fails, by
increasing the rate of packet marking or dropping. Technically, FN avoids the
queue overflows by controlling the instantaneous queue size below the optimal
queue size, and control congestion by keeping the average arrival rate close to
the outgoing link capacity. Upon arrival of each packet, FN uses the
instantaneous queue size and the average arrival rate to calculate the packet
marking or dropping probability. FN marks or drops packets at fairly regular
intervals to avoid long intermarking intervals and clustered packet marks or
drops. Too many marked or dropped packets close together can cause global
synchronization, and also too long packet intermarking times between marked or
dropped packets can cause large queue sizes and congestion. This paper shows
how FN controls the queue size, avoids congestion, and reduces global
synchronization by uniformizing marked or dropped packet intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1374</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1374</id><created>2009-09-07</created><authors><author><keyname>Jung</keyname><forenames>Jean Pierre</forenames></author><author><keyname>Sakho</keyname><forenames>Ibrahima</forenames></author></authors><title>On The Optimality Of All To All Broadcast In k ary n dimensional Tori</title><categories>cs.NI cs.DS</categories><comments>8 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500,Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  All to all broadcast is a collective communication in a network with the
constraint that every node must send to each other certain piece of its data.
This paper addresses the problem of optimal all port all to all broadcast in
multidimensional tori. The optimality criteria considered are the minimum
exchange steps, no duplicated data in the sense that only new data are conveyed
to receivers and the balance of the communication links load. It is proved that
under these constraints, an optimal broadcast is not feasible in any
multidimensional torus. Then, the tori which are capable of optimal broadcasts
are characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1381</identifier>
 <datestamp>2015-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1381</id><created>2009-09-07</created><authors><author><keyname>Bhattacharya</keyname><forenames>Sayan</forenames></author><author><keyname>Paul</keyname><forenames>Goutam</forenames></author><author><keyname>Sanyal</keyname><forenames>Swagato</forenames></author></authors><title>On Necessary and Sufficient Number of Cops in the Game of Cops and
  Robber in Multidimensional Grids</title><categories>cs.DM</categories><comments>This is a revised and extended version of the poster paper with the
  same title that has been presented in the 8th Asian Symposium on Computer
  Mathematics (ASCM), December 15-17, 2007, Singapore</comments><journal-ref>Discrete Applied Mathematics, pages 1745--1751, vol. 158, no. 16,
  August 2010</journal-ref><doi>10.1016/j.dam.2010.06.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We theoretically analyze the Cops and Robber Game for the first time in a
multidimensional grid. It is shown that for an $n$-dimensional grid, at least
$n$ cops are necessary to ensure capture of the robber. We also present a set
of cop strategies for which $n$ cops are provably sufficient to catch the
robber. Further, for two-dimensional grid, we provide an efficient cop strategy
for which the robber is caught even by a single cop under certain conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1388</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1388</id><created>2009-09-08</created><updated>2009-09-09</updated><authors><author><keyname>Wang</keyname><forenames>Shengbao</forenames></author></authors><title>On the Relations Between Diffie-Hellman and ID-Based Key Agreement from
  Pairings</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper studies the relationships between the traditional Diffie-Hellman
key agreement protocol and the identity-based (ID-based) key agreement protocol
from pairings.
  For the Sakai-Ohgishi-Kasahara (SOK) ID-based key construction, we show that
identical to the Diffie-Hellman protocol, the SOK key agreement protocol also
has three variants, namely \emph{ephemeral}, \emph{semi-static} and
\emph{static} versions. Upon this, we build solid relations between
authenticated Diffie-Hellman (Auth-DH) protocols and ID-based authenticated key
agreement (IB-AK) protocols, whereby we present two \emph{substitution rules}
for this two types of protocols. The rules enable a conversion between the two
types of protocols. In particular, we obtain the \emph{real} ID-based version
of the well-known MQV (and HMQV) protocol.
  Similarly, for the Sakai-Kasahara (SK) key construction, we show that the key
transport protocol underlining the SK ID-based encryption scheme (which we call
the &quot;SK protocol&quot;) has its non-ID counterpart, namely the Hughes protocol.
Based on this observation, we establish relations between corresponding
ID-based and non-ID-based protocols. In particular, we propose a highly
enhanced version of the McCullagh-Barreto protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1392</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1392</id><created>2009-09-08</created><updated>2009-10-05</updated><authors><author><keyname>Dey</keyname><forenames>Dhananjoy</forenames></author><author><keyname>Mishra</keyname><forenames>Prasanna Raghaw</forenames></author><author><keyname>Sengupta</keyname><forenames>Indranath</forenames></author></authors><title>HF-hash : Hash Functions Using Restricted HFE Challenge-1</title><categories>cs.CR math.AC</categories><comments>44 pages including 32 pages appendix (list of polynomials) 2 figures,
  corrected Surname</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vulnerability of dedicated hash functions to various attacks has made the
task of designing hash function much more challenging. This provides us a
strong motivation to design a new cryptographic hash function viz. HF-hash.
This is a hash function, whose compression function is designed by using first
32 polynomials of HFE Challenge-1 with 64 variables by forcing remaining 16
variables as zero. HF-hash gives 256 bits message digest and is as efficient as
SHA-256. It is secure against the differential attack proposed by Chabaud and
Joux as well as by Wang et. al. applied to SHA-0 and SHA-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1397</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1397</id><created>2009-09-08</created><authors><author><keyname>Ataollahi</keyname><forenames>Iraj</forenames></author><author><keyname>Analoui</keyname><forenames>Mortza</forenames></author></authors><title>Resource Matchmaking Algorithm using Dynamic Rough Set in Grid
  Environment</title><categories>cs.DC cs.AI</categories><comments>10 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grid environment is a service oriented infrastructure in which many
heterogeneous resources participate to provide the high performance
computation. One of the bug issues in the grid environment is the vagueness and
uncertainty between advertised resources and requested resources. Furthermore,
in an environment such as grid dynamicity is considered as a crucial issue
which must be dealt with. Classical rough set have been used to deal with the
uncertainty and vagueness. But it can just be used on the static systems and
can not support dynamicity in a system. In this work we propose a solution,
called Dynamic Rough Set Resource Discovery (DRSRD), for dealing with cases of
vagueness and uncertainty problems based on Dynamic rough set theory which
considers dynamic features in this environment. In this way, requested resource
properties have a weight as priority according to which resource matchmaking
and ranking process is done. We also report the result of the solution obtained
from the simulation in GridSim simulator. The comparison has been made between
DRSRD, classical rough set theory based algorithm, and UDDI and OWL S combined
algorithm. DRSRD shows much better precision for the cases with vagueness and
uncertainty in a dynamic system such as the grid rather than the classical
rough set theory based algorithm, and UDDI and OWL S combined algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1402</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1402</id><created>2009-09-08</created><authors><author><keyname>Palanisamy</keyname><forenames>V.</forenames></author><author><keyname>Annadurai</keyname><forenames>P.</forenames></author></authors><title>Impact of Rushing attack on Multicast in Mobile Ad Hoc Network</title><categories>cs.CR cs.NI</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile ad hoc network (MANETs) is a self-organizing system of mobile nodes
that communicate with each other via wireless links with no fixed
infrastructure or centralized administration such as base station or access
points. Nodes in a MANETs operate both as host as well as routers to forward
packets for each other in a multihop fashion. For many applications in wireless
networks, multicasting is an important and frequent communication service. By
multicasting, since a single message can be delivered to multiple receivers
simultaneously. It greatly reduces the transmission cost when sending the same
packet to multiple recipients.
  The security issue of MANETs in group communications is even more challenging
because of involvement of multiple senders and multiple receivers. At that time
of multicasting, mobile ad hoc network are unprotected by the attacks of
malicious nodes because of vulnerabilities of routing protocols. Some of the
attacks are Rushing attack, Blackhole attack, Sybil attack, Neighbor attack and
Jellyfish attack.
  This paper is based on Rushing attack. In Rushing attack, the attacker
exploits the duplicate suppression mechanism by quickly forwarding route
discovery packets in order to gain access to the forwarding group and this will
affect the Average Attack Success Rate.
  In this paper, the goal is to measure the impact of Rushing attack and their
node positions which affect the performance metrics of Average Attack Success
Rate with respect to three scenarios: near sender, near receiver and anywhere
within the network. The performance of the Attack Success Rate with respect to
above three scenarios is also compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1405</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1405</id><created>2009-09-08</created><authors><author><keyname>lashkargir</keyname><forenames>Mohsen</forenames></author><author><keyname>Monadjemi</keyname><forenames>S. Amirhassan</forenames></author><author><keyname>Dastjerdi</keyname><forenames>Ahmad Baraani</forenames></author></authors><title>A Hybrid Multi Objective Particle Swarm Optimization Method to Discover
  Biclusters in Microarray Data</title><categories>cs.CE cs.NE</categories><comments>6 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</comments><report-no>ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, with the development of microarray technique, discovery of
useful knowledge from microarray data has become very important. Biclustering
is a very useful data mining technique for discovering genes which have similar
behavior. In microarray data, several objectives have to be optimized
simultaneously and often these objectives are in conflict with each other. A
Multi Objective model is capable of solving such problems. Our method proposes
a Hybrid algorithm which is based on the Multi Objective Particle Swarm
Optimization for discovering biclusters in gene expression data. In our method,
we will consider a low level of overlapping amongst the biclusters and try to
cover all elements of the gene expression matrix. Experimental results in the
bench mark database show a significant improvement in both overlap among
biclusters and coverage of elements in the gene expression matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1412</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1412</id><created>2009-09-08</created><authors><author><keyname>Agrawal</keyname><forenames>Munendra</forenames></author><author><keyname>Kushwah</keyname><forenames>Prashant</forenames></author><author><keyname>Lal</keyname><forenames>Sunder</forenames></author></authors><title>An Efficient and Publicly Verifiable Id-Based Multi-Signcryption Scheme</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-signcryption is used when different senders wants to authenticate a
single message without revealing it. This paper proposes a multi signcryption
scheme in which no pairing is computed on the signcryption stage and the
signatures can be verified publicly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1426</identifier>
 <datestamp>2012-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1426</id><created>2009-09-08</created><updated>2012-10-02</updated><authors><author><keyname>Chaudhury</keyname><forenames>Kunal N.</forenames></author></authors><title>L^p boundedness of the Hilbert transform</title><categories>cs.IT math.IT</categories><comments>Notes on the L^p boundedness of the Hilbert transform</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hilbert transform is essentially the \textit{only} singular operator in
one dimension. This undoubtedly makes it one of the the most important linear
operators in harmonic analysis. The Hilbert transform has had a profound
bearing on several theoretical and physical problems across a wide range of
disciplines; this includes problems in Fourier convergence, complex analysis,
potential theory, modulation theory, wavelet theory, aerofoil design,
dispersion relations and high-energy physics, to name a few.
  In this monograph, we revisit some of the established results concerning the
global behavior of the Hilbert transform, namely that it is is weakly bounded
on $\eL^1(\R)$, and strongly bounded on $\eL^p(\R)$ for $1 &lt; p &lt;\infty$, and
provide a self-contained derivation of the same using real-variable techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1428</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1428</id><created>2009-09-08</created><updated>2013-05-18</updated><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Li</keyname><forenames>Lvzhou</forenames></author><author><keyname>Mateus</keyname><forenames>Paulo</forenames></author><author><keyname>Sernadas</keyname><forenames>Amilcar</forenames></author></authors><title>Exponentially more concise quantum recognition of non-RMM regular
  languages</title><categories>quant-ph cs.CC</categories><comments>32 pages, 6 figures. We have added a number of results concerning the
  state complexity, and the proof methods for accepting languages and
  equivalence have been changed. Also, the title has been changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there are quantum devices that accept all regular languages and
that are exponentially more concise than deterministic finite automata (DFA).
For this purpose, we introduce a new computing model of {\it one-way quantum
finite automata} (1QFA), namely, {\it one-way quantum finite automata together
with classical states} (1QFAC), which extends naturally both measure-only 1QFA
and DFA and whose state complexity is upper-bounded by both. The original
contributions of the paper are the following. First, we show that the set of
languages accepted by 1QFAC with bounded error consists precisely of all
regular languages. Second, we prove that 1QFAC are at most exponentially more
concise than DFA. Third, we show that the previous bound is tight for families
of regular languages that are not recognized by measure-once (RMO),
measure-many (RMM) and multi-letter 1QFA. % More concretely we exhibit regular
languages $L^0(m)$ for $m$ prime such that: (i) $L^0(m)$ cannot be recognized
by measure-once, measure-many and multi-letter 1QFA; (ii) the minimal DFA that
accepts $L^0(m)$ has $O(m)$ states; (iii) there is a 1QFAC with constant
classical states and $O(\log(m))$ quantum basis that accepts $L^0(m)$. Fourth,
we give a polynomial-time algorithm for determining whether any two 1QFAC are
equivalent. Finally, we show that state minimization of 1QFAC is decidable
within EXPSPACE. We conclude the paper by posing some open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1460</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1460</id><created>2009-09-08</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Accuracy Improvement for Stiffness Modeling of Parallel Manipulators</title><categories>cs.RO</categories><proxy>ccsd hal-00414207</proxy><journal-ref>42\`eme CIRP Conference on Manufacturing Systems, Grenoble :
  France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on the accuracy improvement of stiffness models for
parallel manipulators, which are employed in high-speed precision machining. It
is based on the integrated methodology that combines analytical and numerical
techniques and deals with multidimensional lumped-parameter models of the
links. The latter replace the link flexibility by localized 6-dof virtual
springs describing both translational/rotational compliance and the coupling
between them. There is presented detailed accuracy analysis of the stiffness
identification procedures employed in the commercial CAD systems (including
statistical analysis of round-off errors, evaluating the confidence intervals
for stiffness matrices). The efficiency of the developed technique is confirmed
by application examples, which deal with stiffness analysis of translational
parallel manipulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1475</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1475</id><created>2009-09-08</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Design optimization of parallel manipulators for high-speed precision
  machining applications</title><categories>cs.RO</categories><proxy>ccsd hal-00414240</proxy><journal-ref>13th IFAC Symposium on Information Control Problems in
  Manufacturing, Moscou : Russian Federation (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes an integrated approach to the design optimization of
parallel manipulators, which is based on the concept of the workspace grid and
utilizes the goal-attainment formulation for the global optimization. To
combine the non-homogenous design specification, the developed optimization
technique transforms all constraints and objectives into similar performance
indices related to the maximum size of the prescribed shape workspace. This
transformation is based on the dedicated dynamic programming procedures that
satisfy computational requirements of modern CAD. Efficiency of the developed
technique is demonstrated via two case studies that deal with optimization of
the kinematical and stiffness performances for parallel manipulators of the
Orthoglide family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1517</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1517</id><created>2009-09-08</created><authors><author><keyname>Aldinucci</keyname><forenames>Marco</forenames></author><author><keyname>Danelutto</keyname><forenames>Marco</forenames></author><author><keyname>Kilpatrick</keyname><forenames>Peter</forenames></author></authors><title>Autonomic management of multiple non-functional concerns in behavioural
  skeletons</title><categories>cs.DC</categories><comments>20 pages + cover page</comments><report-no>TR-09-10</report-no><acm-class>D.1.3; F.1.1; D.2.2; D.2.3</acm-class><doi>10.1007/978-1-4419-6794-7_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and address the problem of concurrent autonomic management of
different non-functional concerns in parallel applications build as a
hierarchical composition of behavioural skeletons. We first define the problems
arising when multiple concerns are dealt with by independent managers, then we
propose a methodology supporting coordinated management, and finally we discuss
how autonomic management of multiple concerns may be implemented in a typical
use case. The paper concludes with an outline of the challenges involved in
realizing the proposed methodology on distributed target architectures such as
clusters and grids. Being based on the behavioural skeleton concept proposed in
the CoreGRID GCM, it is anticipated that the methodology will be readily
integrated into the current reference implementation of GCM based on Java
ProActive and running on top of major grid middleware systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1525</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1525</id><created>2009-09-08</created><updated>2009-09-15</updated><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Training-Embedded, Single-Symbol ML-Decodable, Distributed STBCs for
  Relay Networks</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a special class of complex designs called Training-Embedded Complex
Orthogonal Designs (TE-CODs) has been introduced to construct single-symbol
Maximum Likelihood (ML) decodable (SSD) distributed space-time block codes
(DSTBCs) for two-hop wireless relay networks using the amplify and forward
protocol. However, to implement DSTBCs from square TE-CODs, the overhead due to
the transmission of training symbols becomes prohibitively large as the number
of relays increase. In this paper, we propose TE-Coordinate Interleaved
Orthogonal Designs (TE-CIODs) to construct SSD DSTBCs. Exploiting the block
diagonal structure of TE-CIODs, we show that, the overhead due to the
transmission of training symbols to implement DSTBCs from TE-CIODs is smaller
than that for TE-CODs. We also show that DSTBCs from TE-CIODs offer higher rate
than those from TE-CODs for identical number of relays while maintaining the
SSD and full-diversity properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1552</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1552</id><created>2009-09-08</created><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Pach</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>Minimum clique partition in unit disk graphs</title><categories>cs.CG cs.DS</categories><comments>12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum clique partition (MCP) problem is that of partitioning the vertex
set of a given graph into a minimum number of cliques. Given $n$ points in the
plane, the corresponding unit disk graph (UDG) has these points as vertices,
and edges connecting points at distance at most~1. MCP in unit disk graphs is
known to be NP-hard and several constant factor approximations are known,
including a recent PTAS. We present two improved approximation algorithms for
minimum clique partition in unit disk graphs:
  (I) A polynomial time approximation scheme (PTAS) running in time
$n^{O(1/\eps^2)}$. This improves on a previous PTAS with $n^{O(1/\eps^4)}$
running time \cite{PS09}.
  (II) A randomized quadratic-time algorithm with approximation ratio 2.16.
This improves on a ratio 3 algorithm with $O(n^2)$ running time \cite{CFFP04}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1590</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1590</id><created>2009-09-08</created><authors><author><keyname>Xiong</keyname><forenames>Hu</forenames></author><author><keyname>Ripeanu</keyname><forenames>Matei</forenames></author><author><keyname>Qin</keyname><forenames>Zhiguang</forenames></author></authors><title>Efficient and Spontaneous Privacy-Preserving Protocol for Secure
  Vehicular Communications</title><categories>cs.CR cs.NI</categories><comments>8 pages, 4 figures, submitted to ICC 2009, uses amssymb.sty,
  amsmath.sty, booktabs.sty, mdwlist.sty, pdftex.sty, dvips.sty</comments><acm-class>C.2.0; K.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an efficient and spontaneous privacy-preserving
protocol for vehicular ad-hoc networks based on revocable ring signature. The
proposed protocol has three appealing characteristics: First, it offers
conditional privacy-preservation: while a receiver can verify that a message
issuer is an authorized participant in the system only a trusted authority can
reveal the true identity of a message sender. Second, it is spontaneous: safety
messages can be authenticated locally, without support from the roadside units
or contacting other vehicles. Third, it is efficient by offering fast message
authentication and verification, cost-effective identity tracking in case of a
dispute, and low storage requirements. We use extensive analysis to demonstrate
the merits of the proposed protocol and to contrast it with previously proposed
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1594</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1594</id><created>2009-09-08</created><authors><author><keyname>Kisil</keyname><forenames>Vladimir V.</forenames></author></authors><title>Computation and Dynamics: Classical and Quantum</title><categories>quant-ph cs.CC cs.FL</categories><comments>5 pages, 2 EPS figures, LaTeX2e, AMSLaTeX</comments><journal-ref>in &quot;Quantum Theory: Reconsideration of Foundations--5'' (A.Yu.
  Khrennikov, ed.), AIP Conference Proceedings, v.1232, Amer. Inst. Phys.,
  pp.306--312, 2010</journal-ref><doi>10.1063/1.3431506</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We discuss classical and quantum computations in terms of corresponding
Hamiltonian dynamics. This allows us to introduce quantum computations which
involve parallel processing of both: the data and programme instructions. Using
mixed quantum-classical dynamics we look for a full cost of computations on
quantum computers with classical terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1599</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1599</id><created>2009-09-08</created><updated>2010-11-22</updated><authors><author><keyname>Nguyen</keyname><forenames>Ha Q.</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author></authors><title>Frame Permutation Quantization</title><categories>cs.IT math.IT</categories><comments>29 pages, 5 figures; detailed added to proof of Theorem 4.3 and a few
  minor corrections</comments><journal-ref>Applied and Computational Harmonic Analysis, vol 31, no, 1, pp,.
  74-97, July 2011</journal-ref><doi>10.1016/j.acha.2010.10.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frame permutation quantization (FPQ) is a new vector quantization technique
using finite frames. In FPQ, a vector is encoded using a permutation source
code to quantize its frame expansion. This means that the encoding is a partial
ordering of the frame expansion coefficients. Compared to ordinary permutation
source coding, FPQ produces a greater number of possible quantization rates and
a higher maximum rate. Various representations for the partitions induced by
FPQ are presented, and reconstruction algorithms based on linear programming,
quadratic programming, and recursive orthogonal projection are derived.
Implementations of the linear and quadratic programming algorithms for uniform
and Gaussian sources show performance improvements over entropy-constrained
scalar quantization for certain combinations of vector dimension and coding
rate. Monte Carlo evaluation of the recursive algorithm shows that mean-squared
error (MSE) decays as 1/M^4 for an M-element frame, which is consistent with
previous results on optimal decay of MSE. Reconstruction using the canonical
dual frame is also studied, and several results relate properties of the
analysis frame to whether linear reconstruction techniques provide consistent
reconstructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1605</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1605</id><created>2009-09-08</created><authors><author><keyname>Chen</keyname><forenames>G.</forenames></author><author><keyname>Atev</keyname><forenames>S.</forenames></author><author><keyname>Lerman</keyname><forenames>G.</forenames></author></authors><title>Kernel Spectral Curvature Clustering (KSCC)</title><categories>cs.CV</categories><comments>accepted to 2009 ICCV Workshop on Dynamical Vision</comments><journal-ref>Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th
  International Conference on, 2009, pp. 765 - 772</journal-ref><doi>10.1109/ICCVW.2009.5457627</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-manifold modeling is increasingly used in segmentation and data
representation tasks in computer vision and related fields. While the general
problem, modeling data by mixtures of manifolds, is very challenging, several
approaches exist for modeling data by mixtures of affine subspaces (which is
often referred to as hybrid linear modeling). We translate some important
instances of multi-manifold modeling to hybrid linear modeling in embedded
spaces, without explicitly performing the embedding but applying the kernel
trick. The resulting algorithm, Kernel Spectral Curvature Clustering, uses
kernels at two levels - both as an implicit embedding method to linearize
nonflat manifolds and as a principled method to convert a multiway affinity
problem into a spectral clustering one. We demonstrate the effectiveness of the
method by comparing it with other state-of-the-art methods on both synthetic
data and a real-world problem of segmenting multiple motions from two
perspective camera views.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1608</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1608</id><created>2009-09-08</created><authors><author><keyname>Chen</keyname><forenames>G.</forenames></author><author><keyname>Lerman</keyname><forenames>G.</forenames></author></authors><title>Motion Segmentation by SCC on the Hopkins 155 Database</title><categories>cs.CV</categories><comments>Accepted to 2009 ICCV Workshop on Dynamical Vision</comments><journal-ref>Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th
  International Conference on, 2009, pp. 759 - 764</journal-ref><doi>10.1109/ICCVW.2009.5457626</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark
database of 155 motion sequences, and show that it outperforms all other
state-of-the-art methods. The average misclassification rate by SCC is 1.41%
for sequences having two motions and 4.85% for three motions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1623</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1623</id><created>2009-09-09</created><authors><author><keyname>Shinde</keyname><forenames>Sudarshan</forenames></author></authors><title>Two channel paraunitary filter banks based on linear canonical transform</title><categories>cs.IT math.IT</categories><comments>10 pages, IEEE format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a two channel paraunitary filter bank is proposed, which is
based on linear canonical transform, instead of discrete Fourier transform.
Input-output relation for such a filter bank are derived in terms of polyphase
matrices and modulation matrices. It is shown that like conventional filter
banks, the LCT based paraunitary filter banks need only one filter to be
designed and rest of the filters can be obtained from it. It is also shown that
LCT based paraunitary filter banks can be designed by using conventional
power-symmetric filter design in Fourier domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1626</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1626</id><created>2009-09-09</created><authors><author><keyname>Guerrini</keyname><forenames>Eleonora</forenames></author><author><keyname>Orsini</keyname><forenames>Emmanuela</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author></authors><title>Computing the distance distribution of systematic non-linear codes</title><categories>cs.DM cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most important families of non-linear codes are systematic. A brute-force
check is the only known method to compute their weight distribution and
distance distribution. On the other hand, it outputs also all closest word
pairs in the code. In the black-box complexity model, the check is optimal
among closest-pair algorithms. In this paper we provide a Groebner basis
technique to compute the weight/distance distribution of any systematic
non-linear code. Also our technique outputs all closest pairs. Unlike the
check, our method can be extended to work on code families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1638</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1638</id><created>2009-09-09</created><authors><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Single-generation Network Coding for Networks with Delay</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single-source network is said to be \textit{memory-free} if all of the
internal nodes (those except the source and the sinks) do not employ memory but
merely send linear combinations of the incoming symbols (received at their
incoming edges) on their outgoing edges. Memory-free networks with delay using
network coding are forced to do inter-generation network coding, as a result of
which the problem of some or all sinks requiring a large amount of memory for
decoding is faced. In this work, we address this problem by utilizing memory
elements at the internal nodes of the network also, which results in the
reduction of the number of memory elements used at the sinks. We give an
algorithm which employs memory at the nodes to achieve single-generation
network coding. For fixed latency, our algorithm reduces the total number of
memory elements used in the network to achieve single-generation network
coding. We also discuss the advantages of employing single-generation network
coding together with convolutional network-error correction codes (CNECCs) for
networks with unit-delay and illustrate the performance gain of CNECCs by using
memory at the intermediate nodes using simulations on an example network under
a probabilistic network error model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1639</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1639</id><created>2009-09-09</created><authors><author><keyname>Bela</keyname><forenames>Genge</forenames></author><author><keyname>Piroska</keyname><forenames>Haller</forenames></author></authors><title>Extending WS-Security to Implement Security Protocols for Web Services</title><categories>cs.CR cs.NI</categories><acm-class>D.4.2</acm-class><journal-ref>Acta Universitatis Sapientiae - Electrical and Mechanical
  Engineering, Vol. 1, pp. 105-112, 2009 (ISSN 2065-5916)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web services use tokens provided by the WS-Security standard to implement
security protocols. We propose several extensions to the WS-Security standard,
including name types, key and random number extensions. The extensions are used
to implement existing protocols such as ISO9798, Kerberos or BAN-Lowe. The
advantages of using these implementations rather than the existing, binary
ones, are inherited from the advantages of using Web service technologies, such
as extensibility and end-to-end security across multiple environments that do
not support a connection-based communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1640</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1640</id><created>2009-09-09</created><authors><author><keyname>Attila</keyname><forenames>Magyari</forenames></author><author><keyname>Bela</keyname><forenames>Genge</forenames></author><author><keyname>Piroska</keyname><forenames>Haller</forenames></author></authors><title>Certificate-based Single Sign-On Mechanism for Multi-Platform
  Distributed Systems</title><categories>cs.CR cs.NI</categories><acm-class>D.4.2</acm-class><journal-ref>Acta Universitatis Sapientiae - Electrical and Mechanical
  Engineering, Vol. 1, pp. 113-123, 2009 (ISSN 2065-5916)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a certificate-based single sign-on mechanism in distributed
systems. The proposed security protocols and authentication mechanisms are
integrated in a middleware. The novelty of our middleware lies on the use of
XPCOM components, this way we provide a different services that can be used on
every platform where Mozilla is available. The componen based architecture of
the implemented services allows using the authentication components separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1645</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1645</id><created>2009-09-09</created><updated>2010-06-09</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Qualitative Analysis of Partially-observable Markov Decision Processes</title><categories>cs.LO</categories><doi>10.1007/978-3-642-15155-2_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study observation-based strategies for partially-observable Markov
decision processes (POMDPs) with omega-regular objectives. An observation-based
strategy relies on partial information about the history of a play, namely, on
the past sequence of observations. We consider the qualitative analysis
problem: given a POMDP with an omega-regular objective, whether there is an
observation-based strategy to achieve the objective with probability~1
(almost-sure winning), or with positive probability (positive winning). Our
main results are twofold. First, we present a complete picture of the
computational complexity of the qualitative analysis of POMDP s with parity
objectives (a canonical form to express omega-regular objectives) and its
subclasses. Our contribution consists in establishing several upper and lower
bounds that were not known in literature. Second, we present optimal bounds
(matching upper and lower bounds) on the memory required by pure and randomized
observation-based strategies for the qualitative analysis of POMDP s with
parity objectives and its subclasses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1647</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1647</id><created>2009-09-09</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Probabilistic Weighted Automata</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nondeterministic weighted automata are finite automata with numerical weights
on transitions. They define quantitative languages L that assign to each word w
a real number L(w). The value of an infinite word w is computed as the maximal
value of all runs over w, and the value of a run as the maximum, limsup,
liminf, limit average, or discounted sum of the transition weights. We
introduce probabilistic weighted automata, in which the transitions are chosen
in a randomized (rather than nondeterministic) fashion. Under almost-sure
semantics (resp. positive semantics), the value of a word w is the largest real
v such that the runs over w have value at least v with probability 1 (resp.
positive probability).
  We study the classical questions of automata theory for probabilistic
weighted automata: emptiness and universality, expressiveness, and closure
under various operations on languages. For quantitative languages, emptiness
and universality are defined as whether the value of some (resp. every) word
exceeds a given threshold. We prove some of these questions to be decidable,
and others undecidable. Regarding expressive power, we show that probabilities
allow us to define a wide variety of new classes of quantitative languages,
except for discounted-sum automata, where probabilistic choice is no more
expressive than nondeterminism. Finally, we give an almost complete picture of
the closure of various classes of probabilistic weighted automata for the
following pointwise operations on quantitative languages: max, min, sum, and
numerical complement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1709</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1709</id><created>2009-09-09</created><updated>2010-03-23</updated><authors><author><keyname>Hsiao</keyname><forenames>Ching-an</forenames></author></authors><title>How does certainty enter into the mind?</title><categories>cs.OH</categories><comments>7 pages, 1 figure, revised references</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Any problem is concerned with the mind, but what do minds make a decision on?
Here we show that there are three conditions for the mind to make a certain
answer. We found that some difficulties in physics and mathematics are in fact
introduced by infinity, which can not be rightly expressed by minds. Based on
this point, we suggest a general observation system, where we use region (a
type of infinity) to substitute for infinitesimal (another type of infinity)
and thus get a consistent image with the mind. Furthermore, we declare that
without world pictures we can never have ideas to any expressive events, which
is the primary condition for a wave function like mind to collapse to a series
of numbers. A following observation by expanding algorithm brings the final
collapse: classifying the numbers and coming up with a certain yes or no
answer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1713</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1713</id><created>2009-09-09</created><authors><author><keyname>Hegde</keyname><forenames>Nidhi</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Mathieu</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Perino</keyname><forenames>Diego</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Size Does Matter (in P2P Live Streaming)</title><categories>cs.NI</categories><proxy>ccsd inria-00414674</proxy><report-no>RR-7032</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal dissemination schemes have previously been studied for peer-to-peer
live streaming applications. Live streaming being a delay-sensitive
application, fine tuning of dissemination parameters is crucial. In this
report, we investigate optimal sizing of chunks, the units of data exchange,
and probe sets, the number peers a given node probes before transmitting
chunks. Chunk size can have significant impact on diffusion rate (chunk miss
ratio), diffusion delay, and overhead. The size of the probe set can also
affect these metrics, primarily through the choices available for chunk
dissemination. We perform extensive simulations on the so-called random-peer,
latest-useful dissemination scheme. Our results show that size does matter,
with the optimal size being not too small in both cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1758</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1758</id><created>2009-09-09</created><authors><author><keyname>Bruno</keyname><forenames>Nicolas</forenames><affiliation>Microsoft</affiliation></author></authors><title>Teaching an Old Elephant New Tricks</title><categories>cs.DB cs.DS cs.PF</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In recent years, column stores (or C-stores for short) have emerged as a
novel approach to deal with read-mostly data warehousing applications.
Experimental evidence suggests that, for certain types of queries, the new
features of C-stores result in orders of magnitude improvement over traditional
relational engines. At the same time, some C-store proponents argue that
C-stores are fundamentally different from traditional engines, and therefore
their benefits cannot be incorporated into a relational engine short of a
complete rewrite. In this paper we challenge this claim and show that many of
the benefits of C-stores can indeed be simulated in traditional engines with no
changes whatsoever. We then identify some limitations of our ?pure-simulation?
approach for the case of more complex queries. Finally, we predict that
traditional relational engines will eventually leverage most of the benefits of
C-stores natively, as is currently happening in other domains such as XML data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1759</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1759</id><created>2009-09-09</created><authors><author><keyname>Marczak</keyname><forenames>William</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Zook</keyname><forenames>David</forenames><affiliation>LogicBlox</affiliation></author><author><keyname>Zhou</keyname><forenames>Wenchao</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Aref</keyname><forenames>Molham</forenames><affiliation>LogicBlox</affiliation></author><author><keyname>Loo</keyname><forenames>Boon Thau</forenames><affiliation>U. Pennsylvania</affiliation></author></authors><title>Declarative Reconfigurable Trust Management</title><categories>cs.CR cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In recent years, there has been a proliferation of declarative logic-based
trust management languages and systems proposed to ease the description,
configuration, and enforcement of security policies. These systems have
different tradeoffs in expressiveness and complexity, depending on the security
constructs (e.g. authentication, delegation, secrecy, etc.) that are supported,
and the assumed trust level and scale of the execution environment. In this
paper, we present LBTrust, a unified declarative system for reconfigurable
trust management, where various security constructs can be customized and
composed in a declarative fashion. We present an initial proof-of-concept
implementation of LBTrust using LogicBlox, an emerging commercial Datalog-based
platform for enterprise software systems. The LogicBlox language enhances
Datalog in a variety of ways, including constraints and meta-programming, as
well as support for programmer defined constraints which on the meta-model
itself ? meta-constraints ? which act to restrict the set of allowable
programs. LBTrust utilizes LogicBlox?s meta-programming and meta-constraints to
enable customizable cryptographic, partitioning and distribution strategies
based on the execution environment. We present uses cases of LBTrust based on
three trust management systems (Binder, D1LP, and Secure Network Datalog), and
provide a preliminary evaluation of a Binder-based trust management system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1760</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1760</id><created>2009-09-09</created><authors><author><keyname>Wang</keyname><forenames>Xiaodan</forenames><affiliation>Johns Hopkins University</affiliation></author><author><keyname>Burns</keyname><forenames>Randal</forenames><affiliation>Johns Hopkins</affiliation></author><author><keyname>Malik</keyname><forenames>Tanu</forenames><affiliation>Purdue University</affiliation></author></authors><title>LifeRaft: Data-Driven, Batch Processing for the Exploration of
  Scientific Databases</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Workloads that comb through vast amounts of data are gaining importance in
the sciences. These workloads consist of &quot;needle in a haystack&quot; queries that
are long running and data intensive so that query throughput limits
performance. To maximize throughput for data-intensive queries, we put forth
LifeRaft: a query processing system that batches queries with overlapping data
requirements. Rather than scheduling queries in arrival order, LifeRaft
executes queries concurrently against an ordering of the data that maximizes
data sharing among queries. This decreases I/O and increases cache utility.
However, such batch processing can increase query response time by starving
interactive workloads. LifeRaft addresses starvation using techniques inspired
by head scheduling in disk drives. Depending upon the workload saturation and
queuing times, the system adaptively and incrementally trades-off processing
queries in arrival order and data-driven batch processing. Evaluating LifeRaft
in the SkyQuery federation of astronomy databases reveals a two-fold
improvement in query throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1763</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1763</id><created>2009-09-09</created><authors><author><keyname>Hasan</keyname><forenames>Ragib</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Sion</keyname><forenames>Radu</forenames><affiliation>Stony Brook University</affiliation></author><author><keyname>Winslett</keyname><forenames>Marianne</forenames><affiliation>University of Illinois</affiliation></author></authors><title>Remembrance: The Unbearable Sentience of Being Digital</title><categories>cs.DB cs.OS</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce a world vision in which data is endowed with memory. In this
data-centric systems paradigm, data items can be enabled to retain all or some
of their previous values. We call this ability &quot;remembrance&quot; and posit that it
empowers significant leaps in the security, availability, and general
operational dimensions of systems. With the explosion in cheap, fast memories
and storage, large-scale remembrance will soon become practical. Here, we
introduce and explore the advantages of such a paradigm and the challenges in
making it a reality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1764</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1764</id><created>2009-09-09</created><authors><author><keyname>Roehm</keyname><forenames>Uwe</forenames><affiliation>University of Sydney</affiliation></author><author><keyname>Blakeley</keyname><forenames>Jose</forenames><affiliation>Microsoft</affiliation></author></authors><title>Data Management for High-Throughput Genomics</title><categories>cs.DB q-bio.GN</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Today's sequencing technology allows sequencing an individual genome within a
few weeks for a fraction of the costs of the original Human Genome project.
Genomics labs are faced with dozens of TB of data per week that have to be
automatically processed and made available to scientists for further analysis.
This paper explores the potential and the limitations of using relational
database systems as the data processing platform for high-throughput genomics.
In particular, we are interested in the storage management for high-throughput
sequence data and in leveraging SQL and user-defined functions for data
analysis inside a database system. We give an overview of a database design for
high-throughput genomics, how we used a SQL Server database in some
unconventional ways to prototype this scenario, and we will discuss some
initial findings about the scalability and performance of such a more
database-centric approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1765</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1765</id><created>2009-09-09</created><authors><author><keyname>Nandi</keyname><forenames>Arnab</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Jagadish</keyname><forenames>H V</forenames><affiliation>University of Michigan</affiliation></author></authors><title>Qunits: queried units in database search</title><categories>cs.DB cs.IR</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Keyword search against structured databases has become a popular topic of
investigation, since many users find structured queries too hard to express,
and enjoy the freedom of a ``Google-like'' query box into which search terms
can be entered. Attempts to address this problem face a fundamental dilemma.
Database querying is based on the logic of predicate evaluation, with a
precisely defined answer set for a given query. On the other hand, in an
information retrieval approach, ranked query results have long been accepted as
far superior to results based on boolean query evaluation. As a consequence,
when keyword queries are attempted against databases, relatively ad-hoc ranking
mechanisms are invented (if ranking is used at all), and there is little
leverage from the large body of IR literature regarding how to rank query
results.
  Our proposal is to create a clear separation between ranking and database
querying. This divides the problem into two parts, and allows us to address
these separately. The first task is to represent the database, conceptually, as
a collection of independent ``queried units'', or ``qunits'', each of which
represents the desired result for some query against the database. The second
task is to evaluate keyword queries against a collection of qunits, which can
be treated as independent documents for query purposes, thereby permitting the
use of standard IR techniques. We provide insights that encourage the use of
this query paradigm, and discuss preliminary investigations into the efficacy
of a qunits-based framework based on a prototype implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1766</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1766</id><created>2009-09-09</created><authors><author><keyname>Zhang</keyname><forenames>Yi</forenames><affiliation>Duke University</affiliation></author><author><keyname>Herodotou</keyname><forenames>Herodotos</forenames><affiliation>Duke</affiliation></author><author><keyname>Yang</keyname><forenames>Jun</forenames><affiliation>Duke</affiliation></author></authors><title>RIOT: I/O-Efficient Numerical Computing without SQL</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  R is a numerical computing environment that is widely popular for statistical
data analysis. Like many such environments, R performs poorly for large
datasets whose sizes exceed that of physical memory. We present our vision of
RIOT (R with I/O Transparency), a system that makes R programs I/O-efficient in
a way transparent to the users. We describe our experience with RIOT-DB, an
initial prototype that uses a relational database system as a backend. Despite
the overhead and inadequacy of generic database systems in handling array data
and numerical computation, RIOT-DB significantly outperforms R in many
large-data scenarios, thanks to a suite of high-level, inter-operation
optimizations that integrate seamlessly into R. While many techniques in RIOT
are inspired by databases (and, for RIOT-DB, realized by a database system),
RIOT users are insulated from anything database related. Compared with previous
approaches that require users to learn new languages and rewrite their programs
to interface with a database, RIOT will, we believe, be easier to adopt by the
majority of the R users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1767</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1767</id><created>2009-09-09</created><authors><author><keyname>Lang</keyname><forenames>Willis</forenames><affiliation>University of Wisconsin-Madiso</affiliation></author><author><keyname>Patel</keyname><forenames>Jignesh</forenames><affiliation>Wisconsin</affiliation></author></authors><title>Towards Eco-friendly Database Management Systems</title><categories>cs.DB</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Database management systems (DBMSs) have largely ignored the task of managing
the energy consumed during query processing. Both economical and environmental
factors now require that DBMSs pay close attention to energy consumption. In
this paper we approach this issue by considering energy consumption as a
first-class performance goal for query processing in a DBMS. We present two
concrete techniques that can be used by a DBMS to directly manage the energy
consumption. Both techniques trade energy consumption for performance. The
first technique, called PVC, leverages the ability of modern processors to
execute at lower processor voltage and frequency. The second technique, called
QED, uses query aggregation to leverage common components of queries in a
workload. Using experiments run on a commercial DBMS and MySQL, we show that
PVC can reduce the processor energy consumption by 49% of the original
consumption while increasing the response time by only 3%. On MySQL, PVC can
reduce energy consumption by 20% with a response time penalty of only 6%. For
simple selection queries with no predicate overlap, we show that QED can be
used to gracefully trade response time for energy, reducing energy consumption
by 54% for a 43% increase in average response time. In this paper we also
highlight some research issues in the emerging area of energy-efficient data
processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1768</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1768</id><created>2009-09-09</created><authors><author><keyname>Lomet</keyname><forenames>David</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Fekete</keyname><forenames>Alan</forenames><affiliation>University of Sydney</affiliation></author><author><keyname>Weikum</keyname><forenames>Gerhard</forenames><affiliation>Max Plank Institute</affiliation></author><author><keyname>Zwilling</keyname><forenames>Mike</forenames><affiliation>Microsoft SQL Server</affiliation></author></authors><title>Unbundling Transaction Services in the Cloud</title><categories>cs.DB cs.DC</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The traditional architecture for a DBMS engine has the recovery, concurrency
control and access method code tightly bound together in a storage engine for
records. We propose a different approach, where the storage engine is factored
into two layers (each of which might have multiple heterogeneous instances). A
Transactional Component (TC) works at a logical level only: it knows about
transactions and their &quot;logical&quot; concurrency control and undo/redo recovery,
but it does not know about page layout, B-trees etc. A Data Component (DC)
knows about the physical storage structure. It supports a record oriented
interface that provides atomic operations, but it does not know about
transactions. Providing atomic record operations may itself involve DC-local
concurrency control and recovery, which can be implemented using system
transactions. The interaction of the mechanisms in TC and DC leads to
multi-level redo (unlike the repeat history paradigm for redo in integrated
engines). This refactoring of the system architecture could allow easier
deployment of application-specific physical structures and may also be helpful
to exploit multi-core hardware. Particularly promising is its potential to
enable flexible transactions in cloud database deployments. We describe the
necessary principles for unbundled recovery, and discuss implementation issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0909.1769</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0909.1769</id><created>2009-09-09</created><authors><author><keyname>Ives</keyname><forenames>Zachary</forenames><affiliation>University Of Pennsylvania</affiliation></author><author><keyname>Knoblock</keyname><forenames>Craig</forenames><affiliation>University of Southern California - Information Sciences Institute</affiliation></author><author><keyname>Minton</keyname><forenames>Steve</forenames><affiliation>Fetch Technologies</affiliation></author><author><keyname>Jacob</keyname><forenames>Marie</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Talukdar</keyname><forenames>Partha</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Tuchinda</keyname><forenames>Rattapoom</forenames><affiliation>University of Southern California - Information Sciences Institute</affiliation></author><author><keyname>Ambite</keyname><forenames>Jose Luis</forenames><affiliation>University of Southern California - Information Sciences Institute</affiliation></author><author><keyname>Muslea</keyname><forenames>Maria</forenames><affiliation>University of Southern California - Information Sciences Institute</affiliation></author><author><keyname>Gazen</keyname><forenames>Cenk</forenames><affiliation>Fetch Technologies</affiliation></author></authors><title>Interactive Data Integration through Smart Copy &amp; Paste</title><categories>cs.DB cs.AI</categories><comments>CIDR 2009</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In many scenarios, such as emergency response or ad hoc collaboration, it is
critical to reduce the overhead in integrating data. Ideally, one could perform
the entire process interactively under one unified interface: defining
extractors and wrappers for sources, creating a mediated schema, and adding
schema mappings ? while seeing how these impact the integrated view of the
data, and refining the design accordingly.
  We propose a novel smart copy and paste (SCP) model and architecture for
seamlessly combining the design-time and run-time aspects of data integration,
and we describe an initial prototype, the CopyCat system. In CopyCat, the user
does not need special tools for the different stages of integration: instead,
the system watches as the user copies data from applications (including the Web
browser) and pastes them into CopyCat?s spreadsheet-like workspace. CopyCat
generalizes these actions and presents proposed auto-completions, each with an
explanation in the form of provenance. The user provides feedback on these
suggestions ? through either direct interactions or further copy-and-paste
operations ? and the system learns from this feedback. This paper provides an
overview of our prototype system, and identifies key research challenges in
achieving SCP in its full generality.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="8000" completeListSize="102538">1122234|9001</resumptionToken>
</ListRecords>
</OAI-PMH>
