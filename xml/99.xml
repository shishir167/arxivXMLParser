<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T04:07:32Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|98001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505003</id><created>2005-04-30</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>A New Kind of Hopfield Networks for Finding Global Optimum</title><categories>cs.NE</categories><comments>6 pages, accepted by International Joint Conference on Neural
  Networks 2005</comments><abstract>  The Hopfield network has been applied to solve optimization problems over
decades. However, it still has many limitations in accomplishing this task.
Most of them are inherited from the optimization algorithms it implements. The
computation of a Hopfield network, defined by a set of difference equations,
can easily be trapped into one local optimum or another, sensitive to initial
conditions, perturbations, and neuron update orders. It doesn't know how long
it will take to converge, as well as if the final solution is a global optimum,
or not. In this paper, we present a Hopfield network with a new set of
difference equations to fix those problems. The difference equations directly
implement a new powerful optimization algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505004</id><created>2005-04-30</created><authors><author><keyname>Kojarski</keyname><forenames>Sergei</forenames></author><author><keyname>Lorenz</keyname><forenames>David H.</forenames></author></authors><title>Pluggable AOP: Designing Aspect Mechanisms for Third-party Composition</title><categories>cs.SE cs.PL</categories><acm-class>D.1.5; D.2.10; D.2.12; D.3.1; D.3.4</acm-class><journal-ref>(new version) In Proceedings of the 20th Annual ACM SIGPLAN
  Conference on Object Oriented Programming Systems Languages and Applications
  (San Diego, CA, USA, October 16 - 20, 2005). OOPSLA '05. ACM Press, New
  York, NY, 247-263.</journal-ref><doi>10.1145/1094811.1094831</doi><abstract>  Studies of Aspect-Oriented Programming (AOP) usually focus on a language in
which a specific aspect extension is integrated with a base language. Languages
specified in this manner have a fixed, non-extensible AOP functionality. In
this paper we consider the more general case of integrating a base language
with a set of domain specific third-party aspect extensions for that language.
We present a general mixin-based method for implementing aspect extensions in
such a way that multiple, independently developed, dynamic aspect extensions
can be subject to third-party composition and work collaboratively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505005</id><created>2005-05-01</created><authors><author><keyname>van der Veen</keyname><forenames>Jan</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Ahmadinia</keyname><forenames>Ali</forenames></author><author><keyname>Bobda</keyname><forenames>Christophe</forenames></author><author><keyname>Hannig</keyname><forenames>Frank</forenames></author><author><keyname>Teich</keyname><forenames>Juergen</forenames></author></authors><title>Defragmenting the Module Layout of a Partially Reconfigurable Device</title><categories>cs.AR cs.DS</categories><comments>10 pages, 11 figures, 1 table, Latex, to appear in &quot;Engineering of
  Reconfigurable Systems and Algorithms&quot; as a &quot;Distinguished Paper&quot;</comments><acm-class>B.7; C.5; C.3</acm-class><abstract>  Modern generations of field-programmable gate arrays (FPGAs) allow for
partial reconfiguration. In an online context, where the sequence of modules to
be loaded on the FPGA is unknown beforehand, repeated insertion and deletion of
modules leads to progressive fragmentation of the available space, making
defragmentation an important issue. We address this problem by propose an
online and an offline component for the defragmentation of the available space.
We consider defragmenting the module layout on a reconfigurable device. This
corresponds to solving a two-dimensional strip packing problem. Problems of
this type are NP-hard in the strong sense, and previous algorithmic results are
rather limited. Based on a graph-theoretic characterization of feasible
packings, we develop a method that can solve two-dimensional defragmentation
instances of practical size to optimality. Our approach is validated for a set
of benchmark instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505006</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505006</id><created>2005-05-01</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Searching for image information content, its discovery, extraction, and
  representation</title><categories>cs.CV</categories><journal-ref>Journal of Electronic Imaging, vol. 14, issue 1, article 013016,
  Jan-Mar 2005</journal-ref><doi>10.1117/1.1867476</doi><abstract>  Image information content is known to be a complicated and controvercial
problem. This paper posits a new image information content definition.
Following the theory of Solomonoff-Kolmogorov-Chaitin's complexity, we define
image information content as a set of descriptions of imafe data structures.
Three levels of such description can be generally distinguished: 1)the global
level, where the coarse structure of the entire scene is initially outlined; 2)
the intermediate level, where structures of separate, non-overlapping image
regions usually associated with individual scene objects are deliniated; and 3)
the low-level description, where local image structures observed in a limited
and restricted field of view are resolved. A technique for creating such image
information content descriptors is developed. Its algorithm is presented and
elucidated with some examples, which demonstrate the effectiveness of the
proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505007</id><created>2005-05-02</created><authors><author><keyname>Trinca</keyname><forenames>Dragos</forenames></author></authors><title>Adaptive Codes: A New Class of Non-standard Variable-length Codes</title><categories>cs.DS</categories><comments>10 pages</comments><acm-class>E.4; F.4.3</acm-class><abstract>  We introduce a new class of non-standard variable-length codes, called
adaptive codes. This class of codes associates a variable-length codeword to
the symbol being encoded depending on the previous symbols in the input data
string. An efficient algorithm for constructing adaptive codes of order one is
presented. Then, we introduce a natural generalization of adaptive codes,
called GA codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505008</id><created>2005-05-02</created><authors><author><keyname>Kuhlmann</keyname><forenames>A.</forenames></author><author><keyname>Vetter</keyname><forenames>R. -M.</forenames></author><author><keyname>Luebbing</keyname><forenames>Ch.</forenames></author><author><keyname>Thole</keyname><forenames>C. -A.</forenames></author></authors><title>Data Mining on Crash Simulation Data</title><categories>cs.IR cs.CE</categories><comments>12 pages, 10 figures. Accepted for Lecture Notes in Computer Science
  (LNCS)</comments><acm-class>H.2.8; D.2.2</acm-class><journal-ref>Lecture Notes in Computer Science, Lecture Notes in Artificial
  Intelligence, Proceedings Conference MLDM 2005, Leipzig/Germany, Springer
  Verlag, LNAI 3587, ISBN: 3-540-26923-1, 2005</journal-ref><abstract>  The work presented in this paper is part of the cooperative research project
AUTO-OPT carried out by twelve partners from the automotive industries. One
major work package concerns the application of data mining methods in the area
of automotive design. Suitable methods for data preparation and data analysis
are developed. The objective of the work is the re-use of data stored in the
crash-simulation department at BMW in order to gain deeper insight into the
interrelations between the geometric variations of the car during its design
and its performance in crash testing. In this paper a method for data analysis
of finite element models and results from crash simulation is proposed and
application to recent data from the industrial partner BMW is demonstrated. All
necessary steps from data pre-processing to re-integration into the working
environment of the engineer are covered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505009</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505009</id><created>2005-05-03</created><updated>2009-06-16</updated><authors><author><keyname>Mitra</keyname><forenames>Arindam</forenames></author></authors><title>Human being is a living random number generator</title><categories>cs.DS</categories><comments>PDF, Revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General wisdom is, mathematical operation is needed to generate number by
numbers. It is pointed out that without any mathematical operation true random
numbers can be generated by numbers through algorithmic process. It implies
that human brain itself is a living true random number generator. Human brain
can meet the enormous human demand of true random numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505010</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505010</id><created>2005-05-04</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author><author><keyname>Ziv</keyname><forenames>Jacob</forenames></author></authors><title>On the Wyner-Ziv problem for individual sequences</title><categories>cs.IT math.IT</categories><comments>21 pages</comments><report-no>CCIT Report #517, Department of Electrical Engineering, Technion,
  February 2005</report-no><abstract>  We consider a variation of the Wyner-Ziv problem pertaining to lossy
compression of individual sequences using finite-state encoders and decoders.
There are two main results in this paper. The first characterizes the
relationship between the performance of the best $M$-state encoder-decoder pair
to that of the best block code of size $\ell$ for every input sequence, and
shows that the loss of the latter relative to the former (in terms of both rate
and distortion) never exceeds the order of $(\log M)/\ell$, independently of
the input sequence. Thus, in the limit of large $M$, the best rate-distortion
performance of every infinite source sequence can be approached universally by
a sequence of block codes (which are also implementable by finite-state
machines). While this result assumes an asymptotic regime where the number of
states is fixed, and only the length $n$ of the input sequence grows without
bound, we then consider the case where the number of states $M=M_n$ is allowed
to grow concurrently with $n$. Our second result is then about the critical
growth rate of $M_n$ such that the rate-distortion performance of $M_n$-state
encoder-decoder pairs can still be matched by a universal code. We show that
this critical growth rate of $M_n$ is linear in $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505011</id><created>2005-05-04</created><authors><author><keyname>Chang</keyname><forenames>Tony</forenames></author><author><keyname>Cook</keyname><forenames>Damon</forenames></author><author><keyname>Su</keyname><forenames>Ramona</forenames></author></authors><title>SWiM: A Simple Window Mover</title><categories>cs.HC</categories><comments>7 pages, 4 figures</comments><abstract>  As computers become more ubiquitous, traditional two-dimensional interfaces
must be replaced with interfaces based on a three-dimensional metaphor.
However, these interfaces must still be as simple and functional as their
two-dimensional predecessors. This paper introduces SWiM, a new interface for
moving application windows between various screens, such as wall displays,
laptop monitors, and desktop displays, in a three-dimensional physical
environment. SWiM was designed based on the results of initial &quot;paper and
pencil&quot; user tests of three possible interfaces. The results of these tests led
to a map-like interface where users select the destination display for their
application from various icons. If the destination is a mobile display it is
not displayed on the map. Instead users can select the screen's name from a
list of all possible destination displays. User testing of SWiM was conducted
to discover whether it is easy to learn and use. Users that were asked to use
SWiM without any instructions found the interface as intuitive to use as users
who were given a demonstration. The results show that SWiM combines simplicity
and functionality to create an interface that is easy to learn and easy to use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505012</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505012</id><created>2005-05-05</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>On the Shannon cipher system with a capacity-limited key-distribution
  channel</title><categories>cs.IT math.IT</categories><comments>15 pages, 1 figure</comments><report-no>CCIT Report #530, Department of Electrical Engineering, Technion,
  May 2005</report-no><abstract>  We consider the Shannon cipher system in a setting where the secret key is
delivered to the legitimate receiver via a channel with limited capacity. For
this setting, we characterize the achievable region in the space of three
figures of merit: the security (measured in terms of the equivocation), the
compressibility of the cryptogram, and the distortion associated with the
reconstruction of the plaintext source. Although lossy reconstruction of the
plaintext does not rule out the option that the (noisy) decryption key would
differ, to a certain extent, from the encryption key, we show, nevertheless,
that the best strategy is to strive for perfect match between the two keys, by
applying reliable channel coding to the key bits, and to control the distortion
solely via rate-distortion coding of the plaintext source before the
encryption. In this sense, our result has a flavor similar to that of the
classical source-channel separation theorem. Some variations and extensions of
this model are discussed as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505013</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505013</id><created>2005-05-05</created><updated>2006-03-08</updated><authors><author><keyname>Nguyen</keyname><forenames>Phuong</forenames></author><author><keyname>Cook</keyname><forenames>Stephen</forenames></author></authors><title>Theories for TC0 and Other Small Complexity Classes</title><categories>cs.LO cs.CC</categories><comments>40 pages, Logical Methods in Computer Science</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 1 (March 7,
  2006) lmcs:679</journal-ref><doi>10.2168/LMCS-2(1:3)2006</doi><abstract>  We present a general method for introducing finitely axiomatizable &quot;minimal&quot;
two-sorted theories for various subclasses of P (problems solvable in
polynomial time). The two sorts are natural numbers and finite sets of natural
numbers. The latter are essentially the finite binary strings, which provide a
natural domain for defining the functions and sets in small complexity classes.
We concentrate on the complexity class TC^0, whose problems are defined by
uniform polynomial-size families of bounded-depth Boolean circuits with
majority gates. We present an elegant theory VTC^0 in which the provably-total
functions are those associated with TC^0, and then prove that VTC^0 is
&quot;isomorphic&quot; to a different-looking single-sorted theory introduced by
Johannsen and Pollet. The most technical part of the isomorphism proof is
defining binary number multiplication in terms a bit-counting function, and
showing how to formalize the proofs of its algebraic properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505014</id><created>2005-05-06</created><authors><author><keyname>Wang</keyname><forenames>Haibin</forenames></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Zhang</keyname><forenames>Yan-Qing</forenames></author><author><keyname>Sunderraman</keyname><forenames>Rajshekhar</forenames></author></authors><title>Interval Neutrosophic Sets and Logic: Theory and Applications in
  Computing</title><categories>cs.LO</categories><comments>12 figures, 100 pages, book in press</comments><abstract>  This book presents the advancements and applications of neutrosophics.
Chapter 1 first introduces the interval neutrosophic sets which is an instance
of neutrosophic sets. In this chapter, the definition of interval neutrosophic
sets and set-theoretic operators are given and various properties of interval
neutrosophic set are proved. Chapter 2 defines the interval neutrosophic logic
based on interval neutrosophic sets including the syntax and semantics of first
order interval neutrosophic propositional logic and first order interval
neutrosophic predicate logic. The interval neutrosophic logic can reason and
model fuzzy, incomplete and inconsistent information. In this chapter, we also
design an interval neutrosophic inference system based on first order interval
neutrosophic predicate logic. The interval neutrosophic inference system can be
applied to decision making. Chapter 3 gives one application of interval
neutrosophic sets and logic in the field of relational databases. Neutrosophic
data model is the generalization of fuzzy data model and paraconsistent data
model. Here, we generalize various set-theoretic and relation-theoretic
operations of fuzzy data model to neutrosophic data model. Chapter 4 gives
another application of interval neutrosophic logic. A soft semantic Web
Services agent framework is proposed to faciliate the registration and
discovery of high quality semantic Web Services agent. The intelligent
inference engine module of soft Semantic Web Services agent is implemented
using interval neutrosophic logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505015</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505015</id><created>2005-05-07</created><updated>2009-07-29</updated><authors><author><keyname>Suslo</keyname><forenames>Tomasz</forenames></author></authors><title>Complex Mean and Variance of Linear Regression Model for High-Noised
  Systems by Kriging</title><categories>cs.NA cs.DS</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of the paper is to derive the complex-valued least-squares estimator
for bias-noise mean and variance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505016</id><created>2005-05-07</created><authors><author><keyname>Araokar</keyname><forenames>Shashank</forenames></author></authors><title>Visual Character Recognition using Artificial Neural Networks</title><categories>cs.NE</categories><comments>7 pages, tutorial resource</comments><abstract>  The recognition of optical characters is known to be one of the earliest
applications of Artificial Neural Networks, which partially emulate human
thinking in the domain of artificial intelligence. In this paper, a simplified
neural approach to recognition of optical or visual characters is portrayed and
discussed. The document is expected to serve as a resource for learners and
amateur investigators in pattern recognition, neural networking and related
disciplines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505017</id><created>2005-05-08</created><authors><author><keyname>Abellanas</keyname><forenames>Manuel</forenames></author><author><keyname>Claverol</keyname><forenames>Merc&#xe8;</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author></authors><title>Point set stratification and Delaunay depth</title><categories>cs.CG</categories><comments>17 pages, 16 figures</comments><abstract>  In the study of depth functions it is important to decide whether we want
such a function to be sensitive to multimodality or not. In this paper we
analyze the Delaunay depth function, which is sensitive to multimodality and
compare this depth with others, as convex depth and location depth. We study
the stratification that Delaunay depth induces in the point set (layers) and in
the whole plane (levels), and we develop an algorithm for computing the
Delaunay depth contours, associated to a point set in the plane, with running
time O(n log^2 n). The depth of a query point p with respect to a data set S in
the plane is the depth of p in the union of S and p. When S and p are given in
the input the Delaunay depth can be computed in O(n log n), and we prove that
this value is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505018</id><created>2005-05-09</created><authors><author><keyname>Mari</keyname><forenames>Jean-Francois</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Ber</keyname><forenames>Florence Le</forenames><affiliation>CEVH</affiliation></author></authors><title>Temporal and Spatial Data Mining with Second-Order Hidden Models</title><categories>cs.AI</categories><proxy>ccsd inria-00000007</proxy><doi>10.1007/s00500-005-0501-0</doi><abstract>  In the frame of designing a knowledge discovery system, we have developed
stochastic models based on high-order hidden Markov models. These models are
capable to map sequences of data into a Markov chain in which the transitions
between the states depend on the \texttt{n} previous states according to the
order of the model. We study the process of achieving information extraction
fromspatial and temporal data by means of an unsupervised classification. We
use therefore a French national database related to the land use of a region,
named Teruti, which describes the land use both in the spatial and temporal
domain. Land-use categories (wheat, corn, forest, ...) are logged every year on
each site regularly spaced in the region. They constitute a temporal sequence
of images in which we look for spatial and temporal dependencies. The temporal
segmentation of the data is done by means of a second-order Hidden Markov Model
(\hmmd) that appears to have very good capabilities to locate stationary
segments, as shown in our previous work in speech recognition. Thespatial
classification is performed by defining a fractal scanning ofthe images with
the help of a Hilbert-Peano curve that introduces atotal order on the sites,
preserving the relation ofneighborhood between the sites. We show that the
\hmmd performs aclassification that is meaningful for the agronomists.Spatial
and temporal classification may be achieved simultaneously by means of a 2
levels \hmmd that measures the \aposteriori probability to map a temporal
sequence of images onto a set of hidden classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505019</id><created>2005-05-10</created><authors><author><keyname>Malik</keyname><forenames>Nitin</forenames></author></authors><title>Artificial Neural Networks and their Applications</title><categories>cs.NE</categories><comments>6 pages, 2 figures, 1 table</comments><abstract>  The Artificial Neural network is a functional imitation of simplified model
of the biological neurons and their goal is to construct useful computers for
real world problems. The ANN applications have increased dramatically in the
last few years fired by both theoretical and practical applications in a wide
variety of applications. A brief theory of ANN is presented and potential areas
are identified and future trends are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505020</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505020</id><created>2005-05-10</created><authors><author><keyname>Zemen</keyname><forenames>Thomas</forenames><affiliation>ftw. Forschungszentrum Telekommunikation Wien</affiliation></author><author><keyname>Moser</keyname><forenames>Stefan M.</forenames><affiliation>Signal and Information Processing Laboratory ETH Zurich</affiliation></author></authors><title>Asymptotic Capacity Results for Non-Stationary Time-Variant Channels
  Using Subspace Projections</title><categories>cs.IT math.IT</categories><comments>14 pages, 1 figure</comments><abstract>  In this paper we deal with a single-antenna discrete-time flat-fading
channel. The fading process is assumed to be stationary for the duration of a
single data block. From block to block the fading process is allowed to be
non-stationary. The number of scatterers bounds the rank of the channels
covariance matrix. The signal-to-noise ratio (SNR), the user velocity, and the
data block-length define the usable rank of the time-variant channel subspace.
The usable channel subspace grows with the SNR. This growth in dimensionality
must be taken into account for asymptotic capacity results in the high-SNR
regime. Using results from the theory of time-concentrated and band-limited
sequences we are able to define an SNR threshold below which the capacity grows
logarithmically. Above this threshold the capacity grows
double-logarithmically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505021</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505021</id><created>2005-05-10</created><updated>2007-06-08</updated><authors><author><keyname>Rataj</keyname><forenames>Artur</forenames></author></authors><title>Distant generalization by feedforward neural networks</title><categories>cs.NE</categories><comments>7 pages, 3 figures</comments><report-no>IITiS-2005-04-1-2.00</report-no><acm-class>I.2.6</acm-class><abstract>  This paper discusses the notion of generalization of training samples over
long distances in the input space of a feedforward neural network. Such a
generalization might occur in various ways, that differ in how great the
contribution of different training features should be.
  The structure of a neuron in a feedforward neural network is analyzed and it
is concluded, that the actual performance of the discussed generalization in
such neural networks may be problematic -- while such neural networks might be
capable for such a distant generalization, a random and spurious generalization
may occur as well.
  To illustrate the differences in generalizing of the same function by
different learning machines, results given by the support vector machines are
also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505022</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505022</id><created>2005-05-10</created><authors><author><keyname>Ochiai</keyname><forenames>Hideki</forenames></author><author><keyname>Mitran</keyname><forenames>Patrick</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Collaborative Beamforming for Distributed Wireless Ad Hoc Sensor Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in the IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2005.857028</doi><abstract>  The performance of collaborative beamforming is analyzed using the theory of
random arrays. The statistical average and distribution of the beampattern of
randomly generated phased arrays is derived in the framework of wireless ad hoc
sensor networks. Each sensor node is assumed to have a single isotropic antenna
and nodes in the cluster collaboratively transmit the signal such that the
signal in the target direction is coherently added in the far- eld region. It
is shown that with N sensor nodes uniformly distributed over a disk, the
directivity can approach N, provided that the nodes are located sparsely
enough. The distribution of the maximum sidelobe peak is also studied. With the
application to ad hoc networks in mind, two scenarios, closed-loop and
open-loop, are considered. Associated with these scenarios, the effects of
phase jitter and location estimation errors on the average beampattern are also
analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505023</id><created>2005-05-10</created><authors><author><keyname>Gardey</keyname><forenames>Guillaume</forenames></author><author><keyname>Roux</keyname><forenames>Olivier H.</forenames></author><author><keyname>Roux</keyname><forenames>Olivier F.</forenames></author></authors><title>State Space Computation and Analysis of Time Petri Nets</title><categories>cs.LO</categories><comments>21 pages</comments><abstract>  The theory of Petri Nets provides a general framework to specify the
behaviors of real-time reactive systems and Time Petri Nets were introduced to
take also temporal specifications into account. We present in this paper a
forward zone-based algorithm to compute the state space of a bounded Time Petri
Net: the method is different and more efficient than the classical State Class
Graph. We prove the algorithm to be exact with respect to the reachability
problem. Furthermore, we propose a translation of the computed state space into
a Timed Automaton, proved to be timed bisimilar to the original Time Petri Net.
As the method produce a single Timed Automaton, syntactical clocks reduction
methods (Daws and Yovine for instance) may be applied to produce an automaton
with fewer clocks. Then, our method allows to model-check TTPN by the use of
efficient Timed Automata tools.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505024</id><created>2005-05-10</created><authors><author><keyname>Pucella</keyname><forenames>Riccardo</forenames></author></authors><title>Logic Column 12: Logical Verification and Equational Verification</title><categories>cs.LO</categories><comments>11 pages</comments><acm-class>F.4.1; F.3.1</acm-class><journal-ref>SIGACT News, 36(2), pp. 77-88, 2005</journal-ref><abstract>  This article examines two approaches to verification, one based on using a
logic for expressing properties of a system, and one based on showing the
system equivalent to a simpler system that obviously has whatever property is
of interest. Using examples such as process calculi and regular programs, the
relationship between these two approaches is explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505025</id><created>2005-05-10</created><authors><author><keyname>Kucera</keyname><forenames>Antonin</forenames></author><author><keyname>Jancar</keyname><forenames>Petr</forenames></author></authors><title>Equivalence-Checking on Infinite-State Systems: Techniques and Results</title><categories>cs.LO</categories><abstract>  The paper presents a selection of recently developed and/or used techniques
for equivalence-checking on infinite-state systems, and an up-to-date overview
of existing results (as of September 2004).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505026</id><created>2005-05-11</created><authors><author><keyname>Falaschi</keyname><forenames>Moreno</forenames></author><author><keyname>Villanueva</keyname><forenames>Alicia</forenames></author></authors><title>Automatic Verification of Timed Concurrent Constraint Programs</title><categories>cs.LO</categories><abstract>  The language Timed Concurrent Constraint (tccp) is the extension over time of
the Concurrent Constraint Programming (cc) paradigm that allows us to specify
concurrent systems where timing is critical, for example reactive systems.
Systems which may have an infinite number of states can be specified in tccp.
Model checking is a technique which is able to verify finite-state systems with
a huge number of states in an automatic way. In the last years several studies
have investigated how to extend model checking techniques to systems with an
infinite number of states. In this paper we propose an approach which exploits
the computation model of tccp. Constraint based computations allow us to define
a methodology for applying a model checking algorithm to (a class of)
infinite-state systems. We extend the classical algorithm of model checking for
LTL to a specific logic defined for the verification of tccp and to the tccp
Structure which we define in this work for modeling the program behavior. We
define a restriction on the time in order to get a finite model and then we
develop some illustrative examples. To the best of our knowledge this is the
first approach that defines a model checking methodology for tccp.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505027</id><created>2005-05-11</created><authors><author><keyname>Lef&#xe8;vre</keyname><forenames>Vincent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>The Generic Multiple-Precision Floating-Point Addition With Exact
  Rounding (as in the MPFR Library)</title><categories>cs.DS</categories><comments>Conference website at http://cca-net.de/rnc6/</comments><proxy>ccsd inria-00000026</proxy><abstract>  We study the multiple-precision addition of two positive floating-point
numbers in base 2, with exact rounding, as specified in the MPFR library, i.e.
where each number has its own precision. We show how the best possible
complexity (up to a constant factor that depends on the implementation) can be
obtain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505028</id><created>2005-05-11</created><updated>2005-08-16</updated><authors><author><keyname>Miklos</keyname><forenames>Istvan</forenames></author><author><keyname>Meyer</keyname><forenames>Irmtraud M.</forenames></author></authors><title>A linear memory algorithm for Baum-Welch training</title><categories>cs.LG cs.DS q-bio.QM</categories><comments>14 pages, 1 figure version 2: fixed some errors, final version of
  paper</comments><acm-class>I.2.6; G.3</acm-class><journal-ref>BMC Bioinformatics (2005) 6:231</journal-ref><abstract>  Background: Baum-Welch training is an expectation-maximisation algorithm for
training the emission and transition probabilities of hidden Markov models in a
fully automated way.
  Methods and results: We introduce a linear space algorithm for Baum-Welch
training. For a hidden Markov model with M states, T free transition and E free
emission parameters, and an input sequence of length L, our new algorithm
requires O(M) memory and O(L M T_max (T + E)) time for one Baum-Welch
iteration, where T_max is the maximum number of states that any state is
connected to. The most memory efficient algorithm until now was the
checkpointing algorithm with O(log(L) M) memory and O(log(L) L M T_max) time
requirement. Our novel algorithm thus renders the memory requirement completely
independent of the length of the training sequences. More generally, for an
n-hidden Markov model and n input sequences of length L, the memory requirement
of O(log(L) L^(n-1) M) is reduced to O(L^(n-1) M) memory while the running time
is changed from O(log(L) L^n M T_max + L^n (T + E)) to O(L^n M T_max (T + E)).
  Conclusions: For the large class of hidden Markov models used for example in
gene prediction, whose number of states does not scale with the length of the
input sequence, our novel algorithm can thus be both faster and more
memory-efficient than any of the existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505029</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505029</id><created>2005-05-11</created><updated>2012-06-27</updated><authors><author><keyname>Ramachandran</keyname><forenames>Muthu</forenames></author></authors><title>Automated Improvement for Component Reuse</title><categories>cs.SE</categories><comments>INFOCOMP Journal of Computer Science. This paper has been withdrawn
  due to journal politics</comments><journal-ref>INFOCOMP Journal of Computer Science, 4(1), 2005</journal-ref><abstract>  Software component reuse is the key to significant gains in productivity.
However, the major problem is the lack of identifying and developing
potentially reusable components. This paper concentrates on our approach to the
development of reusable software components. A prototype tool has been
developed, known as the Reuse Assessor and Improver System (RAIS) which can
interactively identify, analyse, assess, and modify abstractions, attributes
and architectures that support reuse. Practical and objective reuse guidelines
are used to represent reuse knowledge and to do domain analysis. It takes
existing components, provides systematic reuse assessment which is based on
reuse advice and analysis, and produces components that are improved for reuse.
Our work on guidelines has been extended to a large scale industrial
application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505030</id><created>2005-05-11</created><authors><author><keyname>Storjohann</keyname><forenames>Arne</forenames><affiliation>UWO</affiliation></author><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Computing the Rank and a Small Nullspace Basis of a Polynomial Matrix</title><categories>cs.SC cs.CC</categories><comments>Research Report LIP RR2005-03, January 2005</comments><proxy>ccsd ccsd-00004832</proxy><acm-class>I.1; F.2.1</acm-class><journal-ref>Proceedings of the 2005 International Symposium on Symbolic and
  Algebraic Computation (2005) 309-316</journal-ref><abstract>  We reduce the problem of computing the rank and a nullspace basis of a
univariate polynomial matrix to polynomial matrix multiplication. For an input
n x n matrix of degree d over a field K we give a rank and nullspace algorithm
using about the same number of operations as for multiplying two matrices of
dimension n and degree d. If the latter multiplication is done in
MM(n,d)=softO(n^omega d) operations, with omega the exponent of matrix
multiplication over K, then the algorithm uses softO(MM(n,d)) operations in K.
The softO notation indicates some missing logarithmic factors. The method is
randomized with Las Vegas certification. We achieve our results in part through
a combination of matrix Hensel high-order lifting and matrix minimal fraction
reconstruction, and through the computation of minimal or small degree vectors
in the nullspace seen as a K[x]-module
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505031</id><created>2005-05-11</created><authors><author><keyname>Sampaio</keyname><forenames>Rudini M.</forenames></author><author><keyname>Yanasse</keyname><forenames>Horacio H.</forenames></author></authors><title>Estudo e Implementacao de Algoritmos de Roteamento sobre Grafos em um
  Sistema de Informacoes Geograficas</title><categories>cs.MS cs.DS</categories><comments>INFOCOMP Journal of Computer Science</comments><journal-ref>INFOCOMP Journal of Computer Science, 3(1), 2004</journal-ref><abstract>  This article presents an implementation of a graphical software with various
algorithms in Operations research, like minimum path, minimum tree, chinese
postman problem and travelling salesman.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505032</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505032</id><created>2005-05-11</created><updated>2006-11-01</updated><authors><author><keyname>Dabora</keyname><forenames>Ron</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Servetto</keyname><forenames>Sergio D.</forenames><affiliation>Cornell University</affiliation></author></authors><title>Broadcast Channels with Cooperating Decoders</title><categories>cs.IT math.IT</categories><comments>Final version, to appear in the IEEE Transactions on Information
  Theory -- contains (very) minor changes based on the last round of reviews</comments><journal-ref>IEEE Trans. Inform. Theory, 52(12):5438-5454, 2006.</journal-ref><abstract>  We consider the problem of communicating over the general discrete memoryless
broadcast channel (BC) with partially cooperating receivers. In our setup,
receivers are able to exchange messages over noiseless conference links of
finite capacities, prior to decoding the messages sent from the transmitter. In
this paper we formulate the general problem of broadcast with cooperation. We
first find the capacity region for the case where the BC is physically
degraded. Then, we give achievability results for the general broadcast
channel, for both the two independent messages case and the single common
message case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505033</id><created>2005-05-12</created><authors><author><keyname>Bouajjani</keyname><forenames>Ahmed</forenames></author><author><keyname>Merceron</keyname><forenames>Agathe</forenames></author></authors><title>Parametric Verification of a Group Membership Algorithm</title><categories>cs.LO</categories><comments>34 pages. To appear in Theory and Practice of Logic Programming (TPLP)</comments><abstract>  We address the problem of verifying clique avoidance in the TTP protocol. TTP
allows several stations embedded in a car to communicate. It has many
mechanisms to ensure robustness to faults. In particular, it has an algorithm
that allows a station to recognize itself as faulty and leave the
communication. This algorithm must satisfy the crucial 'non-clique' property:
it is impossible to have two or more disjoint groups of stations communicating
exclusively with stations in their own group.
  In this paper, we propose an automatic verification method for an arbitrary
number of stations $N$ and a given number of faults $k$. We give an abstraction
that allows to model the algorithm by means of unbounded (parametric) counter
automata. We have checked the non-clique property on this model in the case of
one fault, using the ALV tool as well as the LASH tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505034</identifier>
 <datestamp>2008-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505034</id><created>2005-05-12</created><updated>2006-05-11</updated><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>Essential Incompleteness of Arithmetic Verified by Coq</title><categories>cs.LO</categories><comments>This paper is part of the proceedings of the 18th International
  Conference on Theorem Proving in Higher Order Logics (TPHOLs 2005). For the
  associated Coq source files see the TeX sources, or see
  &lt;http://r6.ca/Goedel20050512.tar.gz&gt;</comments><journal-ref>Russell O'Connor, Essential Incompleteness of Arithmetic Verified
  by Coq, Lecture Notes in Computer Science, Volume 3603, Aug 2005, Pages 245 -
  260</journal-ref><doi>10.1007/11541868_16</doi><abstract>  A constructive proof of the Goedel-Rosser incompleteness theorem has been
completed using the Coq proof assistant. Some theory of classical first-order
logic over an arbitrary language is formalized. A development of primitive
recursive functions is given, and all primitive recursive functions are proved
to be representable in a weak axiom system. Formulas and proofs are encoded as
natural numbers, and functions operating on these codes are proved to be
primitive recursive. The weak axiom system is proved to be essentially
incomplete. In particular, Peano arithmetic is proved to be consistent in Coq's
type theory and therefore is incomplete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505035</id><created>2005-05-12</created><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author><author><keyname>Dalmau</keyname><forenames>Victor</forenames></author></authors><title>Beyond Hypertree Width: Decomposition Methods Without Decompositions</title><categories>cs.CC cs.AI</categories><abstract>  The general intractability of the constraint satisfaction problem has
motivated the study of restrictions on this problem that permit polynomial-time
solvability. One major line of work has focused on structural restrictions,
which arise from restricting the interaction among constraint scopes. In this
paper, we engage in a mathematical investigation of generalized hypertree
width, a structural measure that has up to recently eluded study. We obtain a
number of computational results, including a simple proof of the tractability
of CSP instances having bounded generalized hypertree width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505036</id><created>2005-05-12</created><authors><author><keyname>Matamala</keyname><forenames>Martin</forenames></author><author><keyname>Moreno</keyname><forenames>Eduardo</forenames></author></authors><title>Minimal Eulerian trail in a labeled digraph</title><categories>cs.DM</categories><comments>Tech. Report DIM-CMM, Universidad de Chile, August 2004</comments><report-no>CMM-B-04/08-108</report-no><abstract>  Let $G$ be an Eulerian directed graph with an arc-labeling such that arcs
going out from the same vertex have different labels. In this work, we present
an algorithm to construct the Eulerian trail starting at an arbitrary vertex
$v$ of minimum lexicographical label among labels of all Eulerian trails
starting at this vertex.
  We also show an application of this algorithm to construct the minimal de
Bruijn sequence of a language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505037</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505037</id><created>2005-05-13</created><updated>2005-09-29</updated><authors><author><keyname>Capretta</keyname><forenames>Venanzio</forenames></author></authors><title>General Recursion via Coinductive Types</title><categories>cs.LO</categories><comments>28 pages</comments><acm-class>F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 2 (July 13,
  2005) lmcs:834</journal-ref><doi>10.2168/LMCS-1(2:1)2005</doi><abstract>  A fertile field of research in theoretical computer science investigates the
representation of general recursive functions in intensional type theories.
Among the most successful approaches are: the use of wellfounded relations,
implementation of operational semantics, formalization of domain theory, and
inductive definition of domain predicates. Here, a different solution is
proposed: exploiting coinductive types to model infinite computations. To every
type A we associate a type of partial elements Partial(A), coinductively
generated by two constructors: the first, return(a) just returns an element
a:A; the second, step(x), adds a computation step to a recursive element
x:Partial(A). We show how this simple device is sufficient to formalize all
recursive functions between two given types. It allows the definition of fixed
points of finitary, that is, continuous, operators. We will compare this
approach to different ones from the literature. Finally, we mention that the
formalization, with appropriate structural maps, defines a strong monad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505038</id><created>2005-05-16</created><authors><author><keyname>Schmidt</keyname><forenames>Albrecht</forenames></author><author><keyname>Jensen</keyname><forenames>Christian S.</forenames></author></authors><title>Efficient Management of Short-Lived Data</title><categories>cs.DB</categories><comments>switched to TimeCenter latex style</comments><report-no>TimeCenter, TR-82</report-no><acm-class>H.2; H.2.2</acm-class><abstract>  Motivated by the increasing prominence of loosely-coupled systems, such as
mobile and sensor networks, which are characterised by intermittent
connectivity and volatile data, we study the tagging of data with so-called
expiration times. More specifically, when data are inserted into a database,
they may be tagged with time values indicating when they expire, i.e., when
they are regarded as stale or invalid and thus are no longer considered part of
the database. In a number of applications, expiration times are known and can
be assigned at insertion time. We present data structures and algorithms for
online management of data tagged with expiration times. The algorithms are
based on fully functional, persistent treaps, which are a combination of binary
search trees with respect to a primary attribute and heaps with respect to a
secondary attribute. The primary attribute implements primary keys, and the
secondary attribute stores expiration times in a minimum heap, thus keeping a
priority queue of tuples to expire. A detailed and comprehensive experimental
study demonstrates the well-behavedness and scalability of the approach as well
as its efficiency with respect to a number of competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505039</id><created>2005-05-14</created><authors><author><keyname>Bar-Ilan</keyname><forenames>Judit</forenames></author><author><keyname>Mat-Hassan</keyname><forenames>Mazlita</forenames></author><author><keyname>Levene</keyname><forenames>Mark</forenames></author></authors><title>Methods for comparing rankings of search engine results</title><categories>cs.IR</categories><comments>19 pages, 4 figures, 8 tables</comments><acm-class>H.3.3</acm-class><abstract>  In this paper we present a number of measures that compare rankings of search
engine results. We apply these measures to five queries that were monitored
daily for two periods of about 21 days each. Rankings of the different search
engines (Google, Yahoo and Teoma for text searches and Google, Yahoo and
Picsearch for image searches) are compared on a daily basis, in addition to
longitudinal comparisons of the same engine for the same query over time. The
results and rankings of the two periods are compared as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505040</id><created>2005-05-14</created><authors><author><keyname>Vlad</keyname><forenames>Serban E.</forenames></author></authors><title>Asynchronous pseudo-systems</title><categories>cs.OH</categories><comments>28 pages</comments><journal-ref>Analele Universitatii Oradea, Fasc. Matematica, Tom XI, 2004,
  133-174</journal-ref><abstract>  The paper introduces the concept of asynchronous pseudo-system. Its purpose
is to correct/generalize/continue the study of the asynchronous systems (the
models of the asynchronous circuits) that has been started in [1], [2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505041</id><created>2005-05-14</created><authors><author><keyname>Li</keyname><forenames>Yongming</forenames></author><author><keyname>Li</keyname><forenames>Sanjiang</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Relational reasoning in the region connection calculus</title><categories>cs.AI cs.LO</categories><comments>Latex2e, 35 pages, 2 figures</comments><abstract>  This paper is mainly concerned with the relation-algebraical aspects of the
well-known Region Connection Calculus (RCC). We show that the contact relation
algebra (CRA) of certain RCC model is not atomic complete and hence infinite.
So in general an extensional composition table for the RCC cannot be obtained
by simply refining the RCC8 relations. After having shown that each RCC model
is a consistent model of the RCC11 CT, we give an exhaustive investigation
about extensional interpretation of the RCC11 CT. More important, we show the
complemented closed disk algebra is a representation for the relation algebra
determined by the RCC11 table. The domain of this algebra contains two classes
of regions, the closed disks and closures of their complements in the real
plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505042</id><created>2005-05-15</created><authors><author><keyname>Earl</keyname><forenames>Matthew</forenames></author><author><keyname>D'Andrea</keyname><forenames>Raffaello</forenames></author></authors><title>Iterative MILP Methods for Vehicle Control Problems</title><categories>cs.RO</categories><comments>22 pages, 9 figures, submitted to IEEE Transactions on Robotics, for
  associated web page see http://control.mae.cornell.edu/earl/milp2</comments><acm-class>I.2.9; I.2.8; J.2</acm-class><journal-ref>M. G. Earl and R. D'Andrea, &quot;Iterative MILP Methods for Vehicle
  Control Problems,&quot; IEEE Transactions on Robotics, Volume 21, Issue 6, pages
  1158-1167, Dec. 2005.</journal-ref><abstract>  Mixed integer linear programming (MILP) is a powerful tool for planning and
control problems because of its modeling capability and the availability of
good solvers. However, for large models, MILP methods suffer computationally.
In this paper, we present iterative MILP algorithms that address this issue. We
consider trajectory generation problems with obstacle avoidance requirements
and minimum time trajectory generation problems. The algorithms use fewer
binary variables than standard MILP methods and require less computational
effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505043</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505043</id><created>2005-05-15</created><updated>2012-06-27</updated><authors><author><keyname>Tavares</keyname><forenames>Joao Manuel R. S.</forenames></author><author><keyname>Pinho</keyname><forenames>Raquel R.</forenames></author></authors><title>Estimacao Temporal da Deformacao entre Objectos utilizando uma
  Metodologia Fisica</title><categories>cs.GR cs.CG</categories><comments>INFOCOMP Journal of Computer Science. This paper has been withdrawn
  due to journal politics</comments><journal-ref>INFOCOMP Journal of Computer Science, 4(1), 2005</journal-ref><abstract>  In this paper, it is presented a methodology to estimate the deformation
involved between two objects attending to its physical properties. This
methodology can be used, for example, in Computational Vision or Computer
Graphics applications, and consists in physically modeling the objects, by
means of the Finite Elements Method, establishing correspondences between some
of its data points, by using Modal Matching, and finally, determining the
displacement field, that is the intermediate shapes, through the resolution of
the Lagrange Dynamic Equilibrium Equation. As in many of the possible
applications of the methodology to present, it is necessary to quantify the
existing deformation, as well as to estimate only the non rigid component of
the involved global deformation. The solutions adopted to satisfy such
intentions will be also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505044</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505044</id><created>2005-05-16</created><authors><author><keyname>Almeida</keyname><forenames>Luis B.</forenames></author></authors><title>Separating a Real-Life Nonlinear Image Mixture</title><categories>cs.NE cs.AI cs.IT math.IT</categories><comments>Submitted to the Journal of Machine Learning Research, May 2005 The
  copy stored in Arxiv has low-resolution images. To get a copy with
  full-resolution images download from:
  http://www.lx.it.pt/~lbalmeida/papers/AlmeidaJMLR05.pdf (7MB, a few artifacts
  in images) http://www.lx.it.pt/~lbalmeida/papers/AlmeidaJMLR05.ps.zip (14MB,
  no artifacts in images)</comments><abstract>  When acquiring an image of a paper document, the image printed on the back
page sometimes shows through. The mixture of the front- and back-page images
thus obtained is markedly nonlinear, and thus constitutes a good real-life test
case for nonlinear blind source separation.
  This paper addresses a difficult version of this problem, corresponding to
the use of &quot;onion skin&quot; paper, which results in a relatively strong
nonlinearity of the mixture, which becomes close to singular in the lighter
regions of the images. The separation is achieved through the MISEP technique,
which is an extension of the well known INFOMAX method. The separation results
are assessed with objective quality measures. They show an improvement over the
results obtained with linear separation, but have room for further improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505045</id><created>2005-05-17</created><authors><author><keyname>Krishna</keyname><forenames>K Madhava</forenames></author><author><keyname>Hexmoor</keyname><forenames>Henry</forenames></author><author><keyname>Sogani</keyname><forenames>Shravan</forenames></author></authors><title>A T Step Ahead Optimal Target Detection Algorithm for a Multi Sensor
  Surveillance System</title><categories>cs.MA cs.RO</categories><comments>7 pages, 3 figures, 2 tables</comments><abstract>  This paper presents a methodology for optimal target detection in a multi
sensor surveillance system. The system consists of mobile sensors that guard a
rectangular surveillance zone crisscrossed by moving targets. Targets percolate
the surveillance zone in a poisson fashion with uniform velocities. Under these
statistics this paper computes a motion strategy for a sensor that maximizes
target detections for the next T time steps. A coordination mechanism between
sensors ensures that overlapping areas between sensors is reduced. This
coordination mechanism is interleaved with the motion strategy computation to
reduce detections of the same target by more than one sensor. To avoid an
exhaustive search in the joint space of all sensors the coordination mechanism
constraints the search by assigning priorities to the sensors. A comparison of
this methodology with other multi target tracking schemes verifies its efficacy
in maximizing detections. A tabulation of these comparisons is reported in
results section of the paper
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505046</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505046</id><created>2005-05-18</created><authors><author><keyname>Melgar</keyname><forenames>Ignacio</forenames></author><author><keyname>Gomez</keyname><forenames>Jaime</forenames></author><author><keyname>Seijas</keyname><forenames>Juan</forenames></author></authors><title>Optimum Signal Linear Detector in the Discrete Wavelet Transform-Domain</title><categories>cs.IT cs.IR math.IT</categories><comments>6 pages</comments><journal-ref>WSEAS Transactions on Communications, ISSN 1109-2742, issue 3, vol
  2, p253-258, July-2003</journal-ref><abstract>  The problem of known signal detection in Additive White Gaussian Noise is
considered. In this paper a new detection algorithm based on Discrete Wavelet
Transform pre-processing and threshold comparison is introduced. Current
approaches described in [7] use the maximum value obtained in the wavelet
domain for decision. Here, we use all available information in the wavelet
domain with excellent results. Detector performance is presented in Probability
of detection curves for a fixed probability of false alarm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505047</id><created>2005-05-18</created><authors><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>A Simple Proof of the F{\'a}ry-Wagner Theorem</title><categories>cs.CG</categories><comments>2 pages</comments><abstract>  We give a simple proof of the following fundamental result independently due
to Fary (1948) and Wagner (1936): Every plane graph has a drawing in which
every edge is straight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505048</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505048</id><created>2005-05-18</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Hirschberg</keyname><forenames>Daniel S.</forenames></author></authors><title>Improved Combinatorial Group Testing Algorithms for Real-World Problem
  Sizes</title><categories>cs.DS</categories><comments>18 pages; an abbreviated version of this paper is to appear at the
  9th Worksh. Algorithms and Data Structures</comments><acm-class>F.2.2</acm-class><journal-ref>SIAM J. Computing 36(5):1360-1375, 2007</journal-ref><doi>10.1137/050631847</doi><abstract>  We study practically efficient methods for performing combinatorial group
testing. We present efficient non-adaptive and two-stage combinatorial group
testing algorithms, which identify the at most d items out of a given set of n
items that are defective, using fewer tests for all practical set sizes. For
example, our two-stage algorithm matches the information theoretic lower bound
for the number of tests in a combinatorial group testing regimen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505049</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505049</id><created>2005-05-18</created><authors><author><keyname>Ionescu</keyname><forenames>Dumitru Mihai</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Fading-Resilient Super-Orthogonal Space-Time Signal Sets: Can Good
  Constellations Survive in Fading?</title><categories>cs.IT math.IT</categories><comments>10 pages, 0 figures, 2 tables, uses IEEEtran.cls, submitted to IEEE
  Transactions on Information Theory</comments><acm-class>E.4; H.1.1</acm-class><journal-ref>IEEE Transactions on Information Theory, Vol. 53, No. 9, SEPTEMBER
  2007, pp. 3219-3225</journal-ref><doi>10.1109/TIT.2007.903148</doi><abstract>  In this correspondence, first-tier indirect (direct) discernible
constellation expansions are defined for generalized orthogonal designs. The
expanded signal constellation, leading to so-called super-orthogonal codes,
allows the achievement of coding gains in addition to diversity gains enabled
by orthogonal designs. Conditions that allow the shape of an expanded
multidimensional constellation to be preserved at the channel output, on an
instantaneous basis, are derived. It is further shown that, for such
constellations, the channel alters neither the relative distances nor the
angles between signal points in the expanded signal constellation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505050</id><created>2005-05-19</created><authors><author><keyname>Izquierdo</keyname><forenames>Manuel Arturo</forenames></author></authors><title>The QDF file format: an electronic system to describe ancient andean
  khipus</title><categories>cs.CY</categories><comments>LaTeX text, 12 pages</comments><abstract>  With the goal of bringing to reseachers of the ancient andean khipus with a
tool to share and process electronically the current corpus of these ancient
information devices, I present on this paper a proposal for a Quipu Description
Format (QDF), a XML based file format designed to describe such documents in a
systematic and computer standard way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505051</id><created>2005-05-20</created><authors><author><keyname>Gomez</keyname><forenames>Jaime</forenames></author><author><keyname>Melgar</keyname><forenames>Ignacio</forenames></author><author><keyname>Seijas</keyname><forenames>Juan</forenames></author><author><keyname>Andina</keyname><forenames>Diego</forenames></author></authors><title>Sub-Optimum Signal Linear Detector Using Wavelets and Support Vector
  Machines</title><categories>cs.IR cs.NE</categories><comments>6 pages</comments><journal-ref>WSEAS Transactions on Communications, ISSN 1109-2742, issue 4, vol
  2, p426-431, October-2003</journal-ref><abstract>  The problem of known signal detection in Additive White Gaussian Noise is
considered. In previous work, a new detection scheme was introduced by the
authors, and it was demonstrated that optimum performance cannot be reached in
a real implementation. In this paper we analyse Support Vector Machines (SVM)
as an alternative, evaluating the results in terms of Probability of detection
curves for a fixed Probability of false alarm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505052</id><created>2005-05-20</created><authors><author><keyname>Gomez</keyname><forenames>Jaime</forenames></author><author><keyname>Melgar</keyname><forenames>Ignacio</forenames></author><author><keyname>Seijas</keyname><forenames>Juan</forenames></author></authors><title>Upgrading Pulse Detection with Time Shift Properties Using Wavelets and
  Support Vector Machines</title><categories>cs.IR cs.NE</categories><comments>6 pages</comments><journal-ref>Proceedings of the World Automation Congress (WAC-04), Sevilla,
  Spain, June-2004</journal-ref><abstract>  Current approaches in pulse detection use domain transformations so as to
concentrate frequency related information that can be distinguishable from
noise. In real cases we do not know when the pulse will begin, so we need a
time search process in which time windows are scheduled and analysed. Each
window can contain the pulsed signal (either complete or incomplete) and / or
noise. In this paper a simple search process will be introduced, allowing the
algorithm to process more information, upgrading the capabilities in terms of
probability of detection (Pd) and probability of false alarm (Pfa).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505053</id><created>2005-05-20</created><authors><author><keyname>Gomez</keyname><forenames>Jaime</forenames></author><author><keyname>Melgar</keyname><forenames>Ignacio</forenames></author><author><keyname>Seijas</keyname><forenames>Juan</forenames></author></authors><title>Wavelet Time Shift Properties Integration with Support Vector Machines</title><categories>cs.IR cs.NE</categories><comments>11 pages</comments><journal-ref>LNAI-3131 Modeling Decisions for Artificial Intelligence, ISSN
  0302-9743, p49-59, Barcelona, Spain, August-2004</journal-ref><abstract>  This paper presents a short evaluation about the integration of information
derived from wavelet non-linear-time-invariant (non-LTI) projection properties
using Support Vector Machines (SVM). These properties may give additional
information for a classifier trying to detect known patterns hidden by noise.
In the experiments we present a simple electromagnetic pulsed signal
recognition scheme, where some improvement is achieved with respect to previous
work. SVMs are used as a tool for information integration, exploiting some
unique properties not easily found in neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505054</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505054</id><created>2005-05-20</created><authors><author><keyname>El-Khamy</keyname><forenames>Mostafa</forenames></author><author><keyname>McEliece</keyname><forenames>Robert J.</forenames></author></authors><title>The Partition Weight Enumerator of MDS Codes and its Applications</title><categories>cs.IT math.IT</categories><comments>This is a five page conference version of the paper which was
  accepted by ISIT 2005. For more information, please contact the authors</comments><acm-class>E.4</acm-class><abstract>  A closed form formula of the partition weight enumerator of maximum distance
separable (MDS) codes is derived for an arbitrary number of partitions. Using
this result, some properties of MDS codes are discussed. The results are
extended for the average binary image of MDS codes in finite fields of
characteristic two. As an application, we study the multiuser error probability
of Reed Solomon codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505055</id><created>2005-05-22</created><authors><author><keyname>Azimian</keyname><forenames>Kooshiar</forenames></author><author><keyname>Mohajeri</keyname><forenames>Javad</forenames></author><author><keyname>Salmasizadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Fayyaz</keyname><forenames>Siamak</forenames></author></authors><title>A Verifiable Partial Key Escrow, Based on McCurley Encryption Scheme</title><categories>cs.CR cs.CC</categories><abstract>  In this paper, firstly we propose two new concepts concerning the notion of
key escrow encryption schemes: provable partiality and independency. Roughly
speaking we say that a scheme has provable partiality if existing polynomial
time algorithm for recovering the secret knowing escrowed information implies a
polynomial time algorithm that can solve a well-known intractable problem. In
addition, we say that a scheme is independent if the secret key and the
escrowed information are independent. Finally, we propose a new verifiable
partial key escrow, which has both of above criteria. The new scheme use
McCurley encryption scheme as underlying scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505056</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505056</id><created>2005-05-23</created><authors><author><keyname>Khurana</keyname><forenames>Udayan</forenames><affiliation>Thapar Institute of Engineering and Technology</affiliation></author><author><keyname>Koul</keyname><forenames>Anirudh</forenames><affiliation>Thapar Institute of Engineering and Technology</affiliation></author></authors><title>Text Compression and Superfast Searching</title><categories>cs.IR cs.IT math.IT</categories><comments>11 pages, 5 tables</comments><acm-class>E.4</acm-class><abstract>  In this paper, a new compression scheme for text is presented. The same is
efficient in giving high compression ratios and enables super fast searching
within the compressed text. Typical compression ratios of 70-80% and reducing
the search time by 80-85% are the features of this paper. Till now, a trade-off
between high ratios and searchability within compressed text has been seen. In
this paper, we show that greater the compression, faster the search. This finds
applicability in so many places where data as natural language text is present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505057</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505057</id><created>2005-05-23</created><authors><author><keyname>Wiechman</keyname><forenames>Gil</forenames></author><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>Improved Bounds on the Parity-Check Density and Achievable Rates of
  Binary Linear Block Codes with Applications to LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory (May 23rd, 2005)</comments><abstract>  We derive bounds on the asymptotic density of parity-check matrices and the
achievable rates of binary linear block codes transmitted over memoryless
binary-input output-symmetric (MBIOS) channels. The lower bounds on the density
of arbitrary parity-check matrices are expressed in terms of the gap between
the rate of these codes for which reliable communication is achievable and the
channel capacity, and the bounds are valid for every sequence of binary linear
block codes. These bounds address the question, previously considered by Sason
and Urbanke, of how sparse can parity-check matrices of binary linear block
codes be as a function of the gap to capacity. Similarly to a previously
reported bound by Sason and Urbanke, the new lower bounds on the parity-check
density scale like the log of the inverse of the gap to capacity, but their
tightness is improved (except for a binary symmetric/erasure channel, where
they coincide with the previous bound). The new upper bounds on the achievable
rates of binary linear block codes tighten previously reported bounds by
Burshtein et al., and therefore enable to obtain tighter upper bounds on the
thresholds of sequences of binary linear block codes under ML decoding. The
bounds are applied to low-density parity-check (LDPC) codes, and the
improvement in their tightness is exemplified numerically. The upper bounds on
the achievable rates enable to assess the inherent loss in performance of
various iterative decoding algorithms as compared to optimal ML decoding. The
lower bounds on the asymptotic parity-check density are helpful in assessing
the inherent tradeoff between the asymptotic performance of LDPC codes and
their decoding complexity (per iteration) under message-passing decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505058</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505058</id><created>2005-05-23</created><authors><author><keyname>McGuire</keyname><forenames>Patrick C.</forenames></author><author><keyname>Diaz-Martinez</keyname><forenames>Enrique</forenames></author><author><keyname>Ormo</keyname><forenames>Jens</forenames></author><author><keyname>Gomez-Elvira</keyname><forenames>Javier</forenames></author><author><keyname>Rodriguez-Manfredi</keyname><forenames>Jose A.</forenames></author><author><keyname>Sebastian-Martinez</keyname><forenames>Eduardo</forenames></author><author><keyname>Ritter</keyname><forenames>Helge</forenames></author><author><keyname>Haschke</keyname><forenames>Robert</forenames></author><author><keyname>Oesker</keyname><forenames>Markus</forenames></author><author><keyname>Ontrup</keyname><forenames>Joerg</forenames></author></authors><title>The Cyborg Astrobiologist: Scouting Red Beds for Uncommon Features
  with Geological Significance</title><categories>cs.CV astro-ph cs.AI cs.CE cs.HC cs.RO cs.SE physics.ins-det q-bio.NC</categories><comments>to appear in Int'l J. Astrobiology, vol.4, iss.2 (June 2005); 19
  pages, 7 figs</comments><acm-class>I.2.10; I.4.6; I.4.8; I.4.9; I.2.9; I.5.4; I.5.5; J.2; J.3; D.2;
  D.1.7; D.4.7</acm-class><journal-ref>Int.J.Astrobiol.4:101-113,2005</journal-ref><doi>10.1017/S1473550405002533</doi><abstract>  The `Cyborg Astrobiologist' (CA) has undergone a second geological field
trial, at a red sandstone site in northern Guadalajara, Spain, near Riba de
Santiuste. The Cyborg Astrobiologist is a wearable computer and video camera
system that has demonstrated a capability to find uncommon interest points in
geological imagery in real-time in the field. The first (of three) geological
structures that we studied was an outcrop of nearly homogeneous sandstone,
which exhibits oxidized-iron impurities in red and and an absence of these iron
impurities in white. The white areas in these ``red beds'' have turned white
because the iron has been removed by chemical reduction, perhaps by a
biological agent. The computer vision system found in one instance several
(iron-free) white spots to be uncommon and therefore interesting, as well as
several small and dark nodules. The second geological structure contained
white, textured mineral deposits on the surface of the sandstone, which were
found by the CA to be interesting. The third geological structure was a 50 cm
thick paleosol layer, with fossilized root structures of some plants, which
were found by the CA to be interesting. A quasi-blind comparison of the Cyborg
Astrobiologist's interest points for these images with the interest points
determined afterwards by a human geologist shows that the Cyborg Astrobiologist
concurred with the human geologist 68% of the time (true positive rate), with a
32% false positive rate and a 32% false negative rate.
  (abstract has been abridged).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505059</id><created>2005-05-23</created><authors><author><keyname>Flesca</keyname><forenames>Sergio</forenames></author><author><keyname>Furfaro</keyname><forenames>Filippo</forenames></author><author><keyname>Parisi</keyname><forenames>Francesco</forenames></author></authors><title>Consistent query answers on numerical databases under aggregate
  constraints</title><categories>cs.DB</categories><abstract>  The problem of extracting consistent information from relational databases
violating integrity constraints on numerical data is addressed. In particular,
aggregate constraints defined as linear inequalities on aggregate-sum queries
on input data are considered. The notion of repair as consistent set of updates
at attribute-value level is exploited, and the characterization of several
complexity issues related to repairing data and computing consistent query
answers is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505060</id><created>2005-05-23</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author><author><keyname>Xu</keyname><forenames>Xiaofei</forenames></author><author><keyname>Deng</keyname><forenames>Shengchun</forenames></author></authors><title>A Unified Subspace Outlier Ensemble Framework for Outlier Detection in
  High Dimensional Spaces</title><categories>cs.DB cs.AI</categories><comments>17 pages</comments><report-no>TR-04-08</report-no><abstract>  The task of outlier detection is to find small groups of data objects that
are exceptional when compared with rest large amount of data. Detection of such
outliers is important for many applications such as fraud detection and
customer migration. Most such applications are high dimensional domains in
which the data may contain hundreds of dimensions. However, the outlier
detection problem itself is not well defined and none of the existing
definitions are widely accepted, especially in high dimensional space. In this
paper, our first contribution is to propose a unified framework for outlier
detection in high dimensional spaces from an ensemble-learning viewpoint. In
our new framework, the outlying-ness of each data object is measured by fusing
outlier factors in different subspaces using a combination function.
Accordingly, we show that all existing researches on outlier detection can be
regarded as special cases in the unified framework with respect to the set of
subspaces considered and the type of combination function used. In addition, to
demonstrate the usefulness of the ensemble-learning based outlier detection
framework, we developed a very simple and fast algorithm, namely SOE1 (Subspace
Outlier Ensemble using 1-dimensional Subspaces) in which only subspaces with
one dimension is used for mining outliers from large categorical datasets. The
SOE1 algorithm needs only two scans over the dataset and hence is very
appealing in real data mining applications. Experimental results on real
datasets and large synthetic datasets show that: (1) SOE1 has comparable
performance with respect to those state-of-art outlier detection algorithms on
identifying true outliers and (2) SOE1 can be an order of magnitude faster than
one of the fastest outlier detection algorithms known so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505061</id><created>2005-05-24</created><authors><author><keyname>Trinca</keyname><forenames>Dragos</forenames></author></authors><title>EAH: A New Encoder based on Adaptive Variable-length Codes</title><categories>cs.DS</categories><comments>16 pages</comments><acm-class>E.4; F.4.3</acm-class><abstract>  Adaptive variable-length codes associate a variable-length codeword to the
symbol being encoded depending on the previous symbols in the input string.
This class of codes has been recently presented in [Dragos Trinca,
arXiv:cs.DS/0505007] as a new class of non-standard variable-length codes. New
algorithms for data compression, based on adaptive variable-length codes of
order one and Huffman's algorithm, have been recently presented in [Dragos
Trinca, ITCC 2004]. In this paper, we extend the work done so far by the
following contributions: first, we propose an improved generalization of these
algorithms, called EAHn. Second, we compute the entropy bounds for EAHn, using
the well-known bounds for Huffman's algorithm. Third, we discuss implementation
details and give reports of experimental results obtained on some well-known
corpora. Finally, we describe a parallel version of EAHn using the PRAM model
of computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505062</id><created>2005-05-24</created><authors><author><keyname>Veerubhotla</keyname><forenames>Ravi S.</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author><author><keyname>Gulati</keyname><forenames>V. P.</forenames></author><author><keyname>Pujari</keyname><forenames>A. K.</forenames></author></authors><title>Gossip Codes for Fingerprinting: Construction, Erasure Analysis and
  Pirate Tracing</title><categories>cs.CR</categories><comments>28 pages</comments><journal-ref>Journal of Universal Computer Science, vol. 11, no. 1 (2005),
  122-149</journal-ref><abstract>  This work presents two new construction techniques for q-ary Gossip codes
from tdesigns and Traceability schemes. These Gossip codes achieve the shortest
code length specified in terms of code parameters and can withstand erasures in
digital fingerprinting applications. This work presents the construction of
embedded Gossip codes for extending an existing Gossip code into a bigger code.
It discusses the construction of concatenated codes and realisation of erasure
model through concatenated codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505063</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505063</id><created>2005-05-24</created><updated>2006-03-08</updated><authors><author><keyname>Gupta</keyname><forenames>Vineet</forenames></author><author><keyname>Jagadeesan</keyname><forenames>Radha</forenames></author><author><keyname>Panangaden</keyname><forenames>Prakash</forenames></author></authors><title>Approximate reasoning for real-time probabilistic processes</title><categories>cs.LO</categories><comments>Preliminary version appeared in QEST 04</comments><acm-class>D.2.4; D.2.8; D.4.8; G.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 1 (March 7,
  2006) lmcs:946</journal-ref><doi>10.2168/LMCS-2(1:4)2006</doi><abstract>  We develop a pseudo-metric analogue of bisimulation for generalized
semi-Markov processes. The kernel of this pseudo-metric corresponds to
bisimulation; thus we have extended bisimulation for continuous-time
probabilistic processes to a much broader class of distributions than
exponential distributions. This pseudo-metric gives a useful handle on
approximate reasoning in the presence of numerical information -- such as
probabilities and time -- in the model. We give a fixed point characterization
of the pseudo-metric. This makes available coinductive reasoning principles for
reasoning about distances. We demonstrate that our approach is insensitive to
potentially ad hoc articulations of distance by showing that it is intrinsic to
an underlying uniformity. We provide a logical characterization of this
uniformity using a real-valued modal logic. We show that several quantitative
properties of interest are continuous with respect to the pseudo-metric. Thus,
if two processes are metrically close, then observable quantitative properties
of interest are indeed close.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505064</id><created>2005-05-24</created><authors><author><keyname>McGuire</keyname><forenames>P. C.</forenames></author><author><keyname>Fritsch</keyname><forenames>J.</forenames></author><author><keyname>Steil</keyname><forenames>J. J.</forenames></author><author><keyname>Roethling</keyname><forenames>F.</forenames></author><author><keyname>Fink</keyname><forenames>G. A.</forenames></author><author><keyname>Wachsmuth</keyname><forenames>S.</forenames></author><author><keyname>Sagerer</keyname><forenames>G.</forenames></author><author><keyname>Ritter</keyname><forenames>H.</forenames></author></authors><title>Multi-Modal Human-Machine Communication for Instructing Robot Grasping
  Tasks</title><categories>cs.HC cs.AI cs.CV cs.LG cs.RO</categories><comments>7 pages, 8 figures</comments><acm-class>H.1.2; I.2.9; I.2.10; I.2.7; H.5.2; H.5.1; I.2.6; I.4.8; I.4.7;
  I.4.6</acm-class><journal-ref>Proceedings of the IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS), Lausanne, Switzerland, IEEE
  publications, pp. 1082-1089 (2002)</journal-ref><abstract>  A major challenge for the realization of intelligent robots is to supply them
with cognitive abilities in order to allow ordinary users to program them
easily and intuitively. One way of such programming is teaching work tasks by
interactive demonstration. To make this effective and convenient for the user,
the machine must be capable to establish a common focus of attention and be
able to use and integrate spoken instructions, visual perceptions, and
non-verbal clues like gestural commands. We report progress in building a
hybrid architecture that combines statistical methods, neural networks, and
finite state machines into an integrated system for instructing grasping tasks
by man-machine interaction. The system combines the GRAVIS-robot for visual
attention and gestural instruction with an intelligent interface for speech
recognition and linguistic interpretation, and an modality fusion module to
allow multi-modal task-oriented man-machine communication with respect to
dextrous robot manipulation of objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505065</id><created>2005-05-24</created><updated>2005-05-27</updated><authors><author><keyname>Xie</keyname><forenames>Xiao-Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Wen-Jun</forenames></author><author><keyname>Yang</keyname><forenames>Zhi-Lian</forenames></author></authors><title>A dissipative particle swarm optimization</title><categories>cs.NE</categories><comments>Proceedings of the 2002 Congress on Evolutionary Computation, 2002.
  Volume: 2, On page(s): 1456-1461</comments><abstract>  A dissipative particle swarm optimization is developed according to the
self-organization of dissipative structure. The negative entropy is introduced
to construct an opening dissipative system that is far-from-equilibrium so as
to driving the irreversible evolution process with better fitness. The testing
of two multimodal functions indicates it improves the performance effectively
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505066</id><created>2005-05-24</created><authors><author><keyname>Khuarana</keyname><forenames>Udayan</forenames></author></authors><title>Decision Sort and its Parallel Implementation</title><categories>cs.DS</categories><comments>5 pages, 3 tables, 1 figure, National Conference on Bioinformatics
  Computing'05</comments><abstract>  In this paper, a sorting technique is presented that takes as input a data
set whose primary key domain is known to the sorting algorithm, and works with
an time efficiency of O(n+k), where k is the primary key domain. It is shown
that the algorithm has applicability over a wide range of data sets. Later, a
parallel formulation of the same is proposed and its effectiveness is argued.
Though this algorithm is applicable over a wide range of general data sets, it
finds special application (much superior to others) in places where sorting
information that arrives in parts and in cases where input data is huge in
size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505067</id><created>2005-05-24</created><authors><author><keyname>Xie</keyname><forenames>Xiao-Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Wen-Jun</forenames></author><author><keyname>Bi</keyname><forenames>De-Chun</forenames></author></authors><title>Optimizing semiconductor devices by self-organizing particle swarm</title><categories>cs.NE</categories><comments>Congress on Evolutionary Computation, 2004. CEC2004. Volume: 2, On
  page(s): 2017- 2022 Vol.2</comments><abstract>  A self-organizing particle swarm is presented. It works in dissipative state
by employing the small inertia weight, according to experimental analysis on a
simplified model, which with fast convergence. Then by recognizing and
replacing inactive particles according to the process deviation information of
device parameters, the fluctuation is introduced so as to driving the
irreversible evolution process with better fitness. The testing on benchmark
functions and an application example for device optimization with designed
fitness function indicates it improves the performance effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505068</id><created>2005-05-24</created><authors><author><keyname>Xie</keyname><forenames>Xiao-Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Wen-Jun</forenames></author><author><keyname>Bi</keyname><forenames>De-Chun</forenames></author></authors><title>Handling equality constraints by adaptive relaxing rule for swarm
  algorithms</title><categories>cs.NE</categories><comments>Congress on Evolutionary Computation, 2004. CEC2004. Volume: 2, On
  page(s): 2012- 2016 Vol.2</comments><abstract>  The adaptive constraints relaxing rule for swarm algorithms to handle with
the problems with equality constraints is presented. The feasible space of such
problems may be similiar to ridge function class, which is hard for applying
swarm algorithms. To enter the solution space more easily, the relaxed quasi
feasible space is introduced and shrinked adaptively. The experimental results
on benchmark functions are compared with the performance of other algorithms,
which show its efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505069</id><created>2005-05-24</created><authors><author><keyname>Zhang</keyname><forenames>Wen-Jun</forenames></author><author><keyname>Xie</keyname><forenames>Xiao-Feng</forenames></author><author><keyname>Bi</keyname><forenames>De-Chun</forenames></author></authors><title>Handling boundary constraints for numerical optimization by particle
  swarm flying in periodic search space</title><categories>cs.NE</categories><comments>Congress on Evolutionary Computation, 2004. CEC2004. Volume: 2, On
  page(s): 2307- 2311 Vol.2</comments><abstract>  The periodic mode is analyzed together with two conventional boundary
handling modes for particle swarm. By providing an infinite space that
comprises periodic copies of original search space, it avoids possible
disorganizing of particle swarm that is induced by the undesired mutations at
the boundary. The results on benchmark functions show that particle swarm with
periodic mode is capable of improving the search performance significantly, by
compared with that of conventional modes and other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505070</id><created>2005-05-24</created><authors><author><keyname>Xie</keyname><forenames>Xiao-Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Wen-Jun</forenames></author></authors><title>SWAF: Swarm Algorithm Framework for Numerical Optimization</title><categories>cs.NE</categories><comments>Genetic and Evolutionary Computation Conference (GECCO), Part I,
  2004: 238-250 (LNCS 3102)</comments><abstract>  A swarm algorithm framework (SWAF), realized by agent-based modeling, is
presented to solve numerical optimization problems. Each agent is a bare bones
cognitive architecture, which learns knowledge by appropriately deploying a set
of simple rules in fast and frugal heuristics. Two essential categories of
rules, the generate-and-test and the problem-formulation rules, are
implemented, and both of the macro rules by simple combination and subsymbolic
deploying of multiple rules among them are also studied. Experimental results
on benchmark problems are presented, and performance comparison between SWAF
and other existing algorithms indicates that it is efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505071</id><created>2005-05-26</created><authors><author><keyname>Mielik&#xe4;inen</keyname><forenames>Taneli</forenames></author></authors><title>Summarization Techniques for Pattern Collections in Data Mining</title><categories>cs.DB cs.AI cs.DS</categories><comments>PhD Thesis, Department of Computer Science, University of Helsinki</comments><report-no>A-2005-1, Department of Computer Science, University of Helsinki</report-no><acm-class>E.4; F.2; H.2.8; I.2; I.2.4</acm-class><abstract>  Discovering patterns from data is an important task in data mining. There
exist techniques to find large collections of many kinds of patterns from data
very efficiently. A collection of patterns can be regarded as a summary of the
data. A major difficulty with patterns is that pattern collections summarizing
the data well are often very large.
  In this dissertation we describe methods for summarizing pattern collections
in order to make them also more understandable. More specifically, we focus on
the following themes: 1) Quality value simplifications. 2) Pattern orderings.
3) Pattern chains and antichains. 4) Change profiles. 5) Inverse pattern
discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505072</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505072</id><created>2005-05-26</created><authors><author><keyname>Zhang</keyname><forenames>Weiming</forenames></author><author><keyname>Li</keyname><forenames>Shiqu</forenames></author></authors><title>Steganographic Codes -- a New Problem of Coding Theory</title><categories>cs.CR</categories><comments>7 pages with 1 figure</comments><acm-class>D.2.11; E.4</acm-class><abstract>  To study how to design steganographic algorithm more efficiently, a new
coding problem -- steganographic codes (abbreviated stego-codes) -- is
presented in this paper. The stego-codes are defined over the field with
$q(q\ge2)$ elements. Firstly a method of constructing linear stego-codes is
proposed by using the direct sum of vector subspaces. And then the problem of
linear stego-codes is converted to an algebraic problem by introducing the
concept of $t$th dimension of vector space. And some bounds on the length of
stego-codes are obtained, from which the maximum length embeddable (MLE) code
is brought up. It is shown that there is a corresponding relation between MLE
codes and perfect error-correcting codes. Furthermore the classification of all
MLE codes and a lower bound on the number of binary MLE codes are obtained
based on the corresponding results on perfect codes. Finally hiding redundancy
is defined to value the performance of stego-codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505073</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505073</id><created>2005-05-26</created><updated>2006-08-16</updated><authors><author><keyname>Demri</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Nowak</keyname><forenames>David</forenames></author></authors><title>Reasoning about transfinite sequences</title><categories>cs.LO cs.CC</categories><comments>38 pages</comments><journal-ref>International Journal of Foundations of Computer Science,
  18(1):87-112, February 2007</journal-ref><doi>10.1142/S0129054107004589</doi><abstract>  We introduce a family of temporal logics to specify the behavior of systems
with Zeno behaviors. We extend linear-time temporal logic LTL to authorize
models admitting Zeno sequences of actions and quantitative temporal operators
indexed by ordinals replace the standard next-time and until future-time
operators. Our aim is to control such systems by designing controllers that
safely work on $\omega$-sequences but interact synchronously with the system in
order to restrict their behaviors. We show that the satisfiability problem for
the logics working on $\omega^k$-sequences is EXPSPACE-complete when the
integers are represented in binary, and PSPACE-complete with a unary
representation. To do so, we substantially extend standard results about LTL by
introducing a new class of succinct ordinal automata that can encode the
interaction between the different quantitative temporal operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505074</id><created>2005-05-26</created><authors><author><keyname>Dekeyser</keyname><forenames>Stijn</forenames></author><author><keyname>Hidders</keyname><forenames>Jan</forenames></author><author><keyname>Paredaens</keyname><forenames>Jan</forenames></author><author><keyname>Vercammen</keyname><forenames>Roel</forenames></author></authors><title>Instance-Independent View Serializability for Semistructured Databases</title><categories>cs.DB</categories><acm-class>H.2</acm-class><abstract>  Semistructured databases require tailor-made concurrency control mechanisms
since traditional solutions for the relational model have been shown to be
inadequate. Such mechanisms need to take full advantage of the hierarchical
structure of semistructured data, for instance allowing concurrent updates of
subtrees of, or even individual elements in, XML documents. We present an
approach for concurrency control which is document-independent in the sense
that two schedules of semistructured transactions are considered equivalent if
they are equivalent on all possible documents. We prove that it is decidable in
polynomial time whether two given schedules in this framework are equivalent.
This also solves the view serializability for semistructured schedules
polynomially in the size of the schedule and exponentially in the number of
transactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505075</id><created>2005-05-26</created><updated>2006-04-06</updated><authors><author><keyname>Cheng</keyname><forenames>Yongxi</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Yin</keyname><forenames>Yiqun Lisa</forenames></author></authors><title>On Searching a Table Consistent with Division Poset</title><categories>cs.DM cs.DS</categories><comments>16 pages, no figure; same results, representation improved, add
  references</comments><acm-class>G.2.1; F.2.2</acm-class><abstract>  Suppose $P_n=\{1,2,...,n\}$ is a partially ordered set with the partial order
defined by divisibility, that is, for any two distinct elements $i,j\in P_n$
satisfying $i$ divides $j$, $i&lt;_{P_n} j$. A table $A_n=\{a_i|i=1,2,...,n\}$ of
distinct real numbers is said to be \emph{consistent} with $P_n$, provided for
any two distinct elements $i,j\in \{1,2,...,n\}$ satisfying $i$ divides $j$,
$a_i&lt; a_j$. Given an real number $x$, we want to determine whether $x\in A_n$,
by comparing $x$ with as few entries of $A_n$ as possible. In this paper we
investigate the complexity $\tau(n)$, measured in the number of comparisons, of
the above search problem. We present a $\frac{55n}{72}+O(\ln^2 n)$ search
algorithm for $A_n$ and prove a lower bound $({3/4}+{17/2160})n+O(1)$ on
$\tau(n)$ by using an adversary argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505076</id><created>2005-05-26</created><authors><author><keyname>Golovkins</keyname><forenames>Marats</forenames></author></authors><title>On the Solution of Graph Isomorphism by Dynamical Algorithms</title><categories>cs.CC</categories><comments>20 pages</comments><acm-class>G.2.2</acm-class><abstract>  In the recent years, several polynomial algorithms of a dynamical nature have
been proposed to address the graph isomorphism problem. In this paper we
propose a generalization of an approach exposed in cond-mat/0209112 and find
that this dynamical algorithm is covered by a combinatorial approach. It is
possible to infer that polynomial dynamical algorithms addressing graph
isomorphism are covered by suitable polynomial combinatorial approaches and
thus are tackled by the same weaknesses as the last ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505077</id><created>2005-05-27</created><authors><author><keyname>Moran</keyname><forenames>Shlomo</forenames></author><author><keyname>Snir</keyname><forenames>Sagi</forenames></author></authors><title>Efficient Approximation of Convex Recolorings</title><categories>cs.DS</categories><abstract>  A coloring of a tree is convex if the vertices that pertain to any color
induce a connected subtree; a partial coloring (which assigns colors to some of
the vertices) is convex if it can be completed to a convex (total) coloring.
Convex coloring of trees arise in areas such as phylogenetics, linguistics,
etc. eg, a perfect phylogenetic tree is one in which the states of each
character induce a convex coloring of the tree. Research on perfect phylogeny
is usually focused on finding a tree so that few predetermined partial
colorings of its vertices are convex.
  When a coloring of a tree is not convex, it is desirable to know &quot;how far&quot; it
is from a convex one. In [19], a natural measure for this distance, called the
recoloring distance was defined: the minimal number of color changes at the
vertices needed to make the coloring convex. This can be viewed as minimizing
the number of &quot;exceptional vertices&quot; w.r.t. to a closest convex coloring. The
problem was proved to be NP-hard even for colored string.
  In this paper we continue the work of [19], and present a 2-approximation
algorithm of convex recoloring of strings whose running time O(cn), where c is
the number of colors and n is the size of the input, and an O(cn^2)-time
3-approximation algorithm for convex recoloring of trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505078</id><created>2005-05-30</created><updated>2005-07-04</updated><authors><author><keyname>Wiechman</keyname><forenames>Gil</forenames></author><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>On the Parity-Check Density and Achievable Rates of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>12 pages. Submitted to the Forty-Third Annual Allerton Conference on
  Communication, Control, and Computing, September 28--30, 2005. It is a
  shortened version of the paper: G. Wiechman and I. Sason, &quot;Improved bounds on
  the parity-check density and achievable rates of binary linear block codes
  with applications to LDPC codes,&quot; submitted to IEEE Trans. on Information
  Theory, May 2005. See http://arxiv.org/abs/cs.IT/0505057</comments><abstract>  The paper introduces new bounds on the asymptotic density of parity-check
matrices and the achievable rates under ML decoding of binary linear block
codes transmitted over memoryless binary-input output-symmetric channels. The
lower bounds on the parity-check density are expressed in terms of the gap
between the channel capacity and the rate of the codes for which reliable
communication is achievable, and are valid for every sequence of binary linear
block codes. The bounds address the question, previously considered by Sason
and Urbanke, of how sparse can parity-check matrices of binary linear block
codes be as a function of the gap to capacity. The new upper bounds on the
achievable rates of binary linear block codes tighten previously reported
bounds by Burshtein et al., and therefore enable to obtain tighter upper bounds
on the thresholds of sequences of binary linear block codes under ML decoding.
The bounds are applied to low-density parity-check (LDPC) codes, and the
improvement in their tightness is exemplified numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505079</id><created>2005-05-29</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Astola</keyname><forenames>Jaakko</forenames></author><author><keyname>Gammerman</keyname><forenames>Alex</forenames></author></authors><title>Application of Kolmogorov complexity and universal codes to identity
  testing and nonparametric testing of serial independence for time series</title><categories>cs.CC</categories><comments>submitted</comments><abstract>  We show that Kolmogorov complexity and such its estimators as universal codes
(or data compression methods) can be applied for hypotheses testing in a
framework of classical mathematical statistics. The methods for identity
testing and nonparametric testing of serial independence for time series are
suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505080</id><created>2005-05-29</created><authors><author><keyname>Roudenko</keyname><forenames>Olga</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Dominance Based Crossover Operator for Evolutionary Multi-objective
  Algorithms</title><categories>cs.AI cs.NA</categories><proxy>ccsd inria-00000095</proxy><journal-ref>Roudenko O., Schoenauer M. &quot;Dominance Based Crossover Operator for
  Evolutionary Multi-objective Algorithms&quot; Dans Parallel Problem Solving from
  Nature 2004 [OAI oai:hal.inria.fr:inria-00000095\_v1] -
  http://inria.ccsd.cnrs.fr/inria-00000095</journal-ref><abstract>  In spite of the recent quick growth of the Evolutionary Multi-objective
Optimization (EMO) research field, there has been few trials to adapt the
general variation operators to the particular context of the quest for the
Pareto-optimal set. The only exceptions are some mating restrictions that take
in account the distance between the potential mates - but contradictory
conclusions have been reported. This paper introduces a particular mating
restriction for Evolutionary Multi-objective Algorithms, based on the Pareto
dominance relation: the partner of a non-dominated individual will be
preferably chosen among the individuals of the population that it dominates.
Coupled with the BLX crossover operator, two different ways of generating
offspring are proposed. This recombination scheme is validated within the
well-known NSGA-II framework on three bi-objective benchmark problems and one
real-world bi-objective constrained optimization problem. An acceleration of
the progress of the population toward the Pareto set is observed on all
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505081</id><created>2005-05-30</created><authors><author><keyname>Bruaux</keyname><forenames>Sabine</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Kassel</keyname><forenames>Gilles</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Morel</keyname><forenames>Gilles</forenames><affiliation>LaRIA</affiliation></author></authors><title>An ontological approach to the construction of problem-solving models</title><categories>cs.AI</categories><proxy>ccsd ccsd-00005019</proxy><report-no>LRR 2005-03</report-no><acm-class>I.2.4</acm-class><abstract>  Our ongoing work aims at defining an ontology-centered approach for building
expertise models for the CommonKADS methodology. This approach (which we have
named &quot;OntoKADS&quot;) is founded on a core problem-solving ontology which
distinguishes between two conceptualization levels: at an object level, a set
of concepts enable us to define classes of problem-solving situations, and at a
meta level, a set of meta-concepts represent modeling primitives. In this
article, our presentation of OntoKADS will focus on the core ontology and, in
particular, on roles - the primitive situated at the interface between domain
knowledge and reasoning, and whose ontological status is still much debated. We
first propose a coherent, global, ontological framework which enables us to
account for this primitive. We then show how this novel characterization of the
primitive allows definition of new rules for the construction of expertise
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505082</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505082</id><created>2005-05-30</created><updated>2007-05-17</updated><authors><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>Fast generators for the Diffie-Hellman key agreement protocol and
  malicious standards</title><categories>cs.CR cs.CC</categories><comments>Small updates</comments><journal-ref>Information Processing Letters 99 (2006), 145--148</journal-ref><doi>10.1016/j.ipl.2005.11.025</doi><abstract>  The Diffie-Hellman key agreement protocol is based on taking large powers of
a generator of a prime-order cyclic group. Some generators allow faster
exponentiation. We show that to a large extent, using the fast generators is as
secure as using a randomly chosen generator. On the other hand, we show that if
there is some case in which fast generators are less secure, then this could be
used by a malicious authority to generate a standard for the Diffie-Hellman key
agreement protocol which has a hidden trapdoor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505083</id><created>2005-05-30</created><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author><author><keyname>Takemura</keyname><forenames>Akimichi</forenames></author><author><keyname>Shafer</keyname><forenames>Glenn</forenames></author></authors><title>Defensive forecasting</title><categories>cs.LG cs.AI</categories><comments>15 pages, 2 figures, to appear in the AIStats'2005 electronic
  proceedings</comments><acm-class>I.2.6; I.5.1</acm-class><journal-ref>Proceedings of the Tenth International Workshop on Artificial
  Intelligence and Statistics, 2005, pages 365--372.</journal-ref><abstract>  We consider how to make probability forecasts of binary labels. Our main
mathematical result is that for any continuous gambling strategy used for
detecting disagreement between the forecasts and the actual labels, there
exists a forecasting strategy whose forecasts are ideal as far as this gambling
strategy is concerned. A forecasting strategy obtained in this way from a
gambling strategy demonstrating a strong law of large numbers is simplified and
studied empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505084</id><created>2005-05-30</created><updated>2005-09-07</updated><authors><author><keyname>Brimkov</keyname><forenames>Valentin</forenames></author><author><keyname>Maimone</keyname><forenames>Angelo</forenames></author><author><keyname>Nordo</keyname><forenames>Giorgio</forenames></author></authors><title>An explicit formula for the number of tunnels in digital objects</title><categories>cs.DM cs.CG cs.CV</categories><comments>9 pages, 4 figures</comments><acm-class>G.2.1; F.2.2; I.4.6; I.5.1</acm-class><abstract>  An important concept in digital geometry for computer imagery is that of
tunnel. In this paper we obtain a formula for the number of tunnels as a
function of the number of the object vertices, pixels, holes, connected
components, and 2x2 grid squares. It can be used to test for tunnel-freedom a
digital object, in particular a digital curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505085</id><created>2005-05-31</created><authors><author><keyname>Schrijvers</keyname><forenames>Tom</forenames></author><author><keyname>de la Banda</keyname><forenames>Maria Garcia</forenames></author><author><keyname>Demoen</keyname><forenames>Bart</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author></authors><title>Improving PARMA Trailing</title><categories>cs.PL cs.PF</categories><comments>36 pages, 7 figures, 8 tables</comments><acm-class>D.3.4; D.1.6; D.3.3</acm-class><abstract>  Taylor introduced a variable binding scheme for logic variables in his PARMA
system, that uses cycles of bindings rather than the linear chains of bindings
used in the standard WAM representation. Both the HAL and dProlog languages
make use of the PARMA representation in their Herbrand constraint solvers.
Unfortunately, PARMA's trailing scheme is considerably more expensive in both
time and space consumption. The aim of this paper is to present several
techniques that lower the cost.
  First, we introduce a trailing analysis for HAL using the classic PARMA
trailing scheme that detects and eliminates unnecessary trailings. The
analysis, whose accuracy comes from HAL's determinism and mode declarations,
has been integrated in the HAL compiler and is shown to produce space
improvements as well as speed improvements. Second, we explain how to modify
the classic PARMA trailing scheme to halve its trailing cost. This technique is
illustrated and evaluated both in the context of dProlog and HAL. Finally, we
explain the modifications needed by the trailing analysis in order to be
combined with our modified PARMA trailing scheme. Empirical evidence shows that
the combination is more effective than any of the techniques when used in
isolation.
  To appear in Theory and Practice of Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505086</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505086</id><created>2005-05-31</created><authors><author><keyname>Llabres</keyname><forenames>Merce</forenames></author><author><keyname>Rocha</keyname><forenames>Jairo</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Valiente</keyname><forenames>Gabriel</forenames></author></authors><title>On the Ancestral Compatibility of Two Phylogenetic Trees with Nested
  Taxa</title><categories>cs.DM q-bio.OT</categories><comments>Submitted</comments><abstract>  Compatibility of phylogenetic trees is the most important concept underlying
widely-used methods for assessing the agreement of different phylogenetic trees
with overlapping taxa and combining them into common supertrees to reveal the
tree of life. The notion of ancestral compatibility of phylogenetic trees with
nested taxa was introduced by Semple et al in 2004. In this paper we analyze in
detail the meaning of this compatibility from the points of view of the local
structure of the trees, of the existence of embeddings into a common supertree,
and of the joint properties of their cluster representations. Our analysis
leads to a very simple polynomial-time algorithm for testing this
compatibility, which we have implemented and is freely available for download
from the BioPerl collection of Perl modules for computational biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505087</id><created>2005-05-31</created><authors><author><keyname>Soltys</keyname><forenames>Michael</forenames></author></authors><title>Feasible Proofs of Matrix Properties with Csanky's Algorithm</title><categories>cs.LO</categories><abstract>  We show that Csanky's fast parallel algorithm for computing the
characteristic polynomial of a matrix can be formalized in the logical theory
LAP, and can be proved correct in LAP from the principle of linear
independence. LAP is a natural theory for reasoning about linear algebra
introduced by Cook and Soltys. Further, we show that several principles of
matrix algebra, such as linear independence or the Cayley-Hamilton Theorem, can
be shown equivalent in the logical theory QLA. Applying the separation between
complexity classes AC^0[2] contained in DET(GF(2)), we show that these
principles are in fact not provable in QLA. In a nutshell, we show that linear
independence is ``all there is'' to elementary linear algebra (from a proof
complexity point of view), and furthermore, linear independence cannot be
proved trivially (again, from a proof complexity point of view).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0505088</identifier>
 <datestamp>2009-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0505088</id><created>2005-05-31</created><updated>2009-04-17</updated><authors><author><keyname>Leao</keyname><forenames>Rodrigo S. C.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>6-cycle double covers of cubic graphs</title><categories>cs.DM</categories><comments>This version fixes typos and minor technical problems, and updates
  references</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cycle double cover (CDC) of an undirected graph is a collection of the
graph's cycles such that every edge of the graph belongs to exactly two cycles.
We describe a constructive method for generating all the cubic graphs that have
a 6-CDC (a CDC in which every cycle has length 6). As an application of the
method, we prove that all such graphs have a Hamiltonian cycle. A sense of
direction is an edge labeling on graphs that follows a globally consistent
scheme and is known to considerably reduce the complexity of several
distributed problems. In [9], a particular instance of sense of direction,
called a chordal sense of direction (CSD), is studied and the class of
k-regular graphs that admit a CSD with exactly k labels (a minimal CSD) is
analyzed. We now show that nearly all the cubic graphs in this class have a
6-CDC, the only exception being K4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506001</id><created>2005-05-31</created><authors><author><keyname>Mogilevsky</keyname><forenames>Dmitry</forenames></author><author><keyname>Keller</keyname><forenames>Sean</forenames></author></authors><title>SafeMPI - Extending MPI for Byzantine Error Detection on Parallel
  Clusters</title><categories>cs.DC</categories><abstract>  Modern high-performance computing relies heavily on the use of commodity
processors arranged together in clusters. These clusters consist of individual
nodes (typically off-the-shelf single or dual processor machines) connected
together with a high speed interconnect. Using cluster computation has many
benefits, but also carries the liability of being failure prone due to the
sheer number of components involved. Many effective solutions have been
proposed to aid failure recovery in clusters, their one significant downside
being the failure models they support. Most of the work in the area has focused
on detecting and correcting fail-stop errors. We propose a system that will
also detect more general error models, such as Byzantine errors, thus allowing
existing failure recovery methods to handle them correctly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506002</id><created>2005-05-31</created><authors><author><keyname>Bonifati</keyname><forenames>Angela</forenames><affiliation>Icar CNR, Italy</affiliation></author><author><keyname>Chang</keyname><forenames>Elaine Qing</forenames><affiliation>UBC, Canada</affiliation></author><author><keyname>Ho</keyname><forenames>Terence</forenames><affiliation>UBC, Canada</affiliation></author><author><keyname>Lakshmanan</keyname><forenames>Laks V. S.</forenames><affiliation>UBC, Canada</affiliation></author></authors><title>HepToX: Heterogeneous Peer to Peer XML Databases</title><categories>cs.DB</categories><comments>11 pages plus cover page</comments><report-no>UBC TR-2005-15</report-no><acm-class>H.2.4; H.2.5</acm-class><abstract>  We study a collection of heterogeneous XML databases maintaining similar and
related information, exchanging data via a peer to peer overlay network. In
this setting, a mediated global schema is unrealistic. Yet, users/applications
wish to query the databases via one peer using its schema. We have recently
developed HepToX, a P2P Heterogeneous XML database system. A key idea is that
whenever a peer enters the system, it establishes an acquaintance with a small
number of peer databases, possibly with different schema. The peer
administrator provides correspondences between the local schema and the
acquaintance schema using an informal and intuitive notation of arrows and
boxes. We develop a novel algorithm that infers a set of precise mapping rules
between the schemas from these visual annotations. We pin down a semantics of
query translation given such mapping rules, and present a novel query
translation algorithm for a simple but expressive fragment of XQuery, that
employs the mapping rules in either direction. We show the translation
algorithm is correct. Finally, we demonstrate the utility and scalability of
our ideas and algorithms with a detailed set of experiments on top of the
Emulab, a large scale P2P network emulation testbed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506003</id><created>2005-06-01</created><authors><author><keyname>Pasquinucci</keyname><forenames>Andrea</forenames></author></authors><title>Authentication and routing in simple Quantum Key Distribution networks</title><categories>cs.NI cs.CR quant-ph</categories><comments>12 pages, latex, 6 eps figures</comments><abstract>  We consider various issues which arise as soon as one tries to practically
implement simple networks of quantum relays for QKD. In particular we discuss
authentication and routing which are essential ingredients of any QKD network.
This paper aims to address some gaps between quantum and networking aspects of
QKD networks usually reserved to specialist in physics and computer science
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506004</id><created>2005-06-01</created><updated>2006-07-01</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Non-asymptotic calibration and resolution</title><categories>cs.LG</categories><comments>20 pages</comments><acm-class>I.2.6; I.5.1</acm-class><abstract>  We analyze a new algorithm for probability forecasting of binary observations
on the basis of the available data, without making any assumptions about the
way the observations are generated. The algorithm is shown to be well
calibrated and to have good resolution for long enough sequences of
observations and for a suitable choice of its parameter, a kernel on the
Cartesian product of the forecast space $[0,1]$ and the data space. Our main
results are non-asymptotic: we establish explicit inequalities, shown to be
tight, for the performance of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506005</id><created>2005-06-01</created><authors><author><keyname>Zhou</keyname><forenames>Neng-Fa</forenames></author></authors><title>Programming Finite-Domain Constraint Propagators in Action Rules</title><categories>cs.PL</categories><journal-ref>TPLP Vol 5(4&amp;5) 2005</journal-ref><abstract>  In this paper, we propose a new language, called AR ({\it Action Rules}), and
describe how various propagators for finite-domain constraints can be
implemented in it. An action rule specifies a pattern for agents, an action
that the agents can carry out, and an event pattern for events that can
activate the agents. AR combines the goal-oriented execution model of logic
programming with the event-driven execution model. This hybrid execution model
facilitates programming constraint propagators. A propagator for a constraint
is an agent that maintains the consistency of the constraint and is activated
by the updates of the domain variables in the constraint. AR has a much
stronger descriptive power than {\it indexicals}, the language widely used in
the current finite-domain constraint systems, and is flexible for implementing
not only interval-consistency but also arc-consistency algorithms. As examples,
we present a weak arc-consistency propagator for the {\tt all\_distinct}
constraint and a hybrid algorithm for n-ary linear equality constraints.
B-Prolog has been extended to accommodate action rules. Benchmarking shows that
B-Prolog as a CLP(FD) system significantly outperforms other CLP(FD) systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506006</id><created>2005-06-02</created><authors><author><keyname>Capit</keyname><forenames>Nicolas</forenames><affiliation>ID - Imag, Inria Rh&#xf4;ne-Alpes / Id-Imag</affiliation></author><author><keyname>Da Costa</keyname><forenames>Georges</forenames><affiliation>ID - Imag, Inria Rh&#xf4;ne-Alpes / Id-Imag</affiliation></author><author><keyname>Georgiou</keyname><forenames>Yiannis</forenames><affiliation>ID - Imag, Inria Rh&#xf4;ne-Alpes / Id-Imag</affiliation></author><author><keyname>Huard</keyname><forenames>Guillaume</forenames><affiliation>ID - Imag, Inria Rh&#xf4;ne-Alpes / Id-Imag</affiliation></author><author><keyname>Martin</keyname><forenames>Cyrille</forenames><affiliation>ID - Imag</affiliation></author><author><keyname>Mouni&#xe9;</keyname><forenames>Gr&#xe9;gory</forenames><affiliation>ID - Imag, Inria Rh&#xf4;ne-Alpes / Id-Imag</affiliation></author><author><keyname>Neyron</keyname><forenames>Pierre</forenames><affiliation>ID - Imag</affiliation></author><author><keyname>Richard</keyname><forenames>Olivier</forenames><affiliation>ID - Imag, Inria Rh&#xf4;ne-Alpes / Id-Imag</affiliation></author></authors><title>A batch scheduler with high level components</title><categories>cs.DC</categories><proxy>ccsd ccsd-00005106</proxy><journal-ref>Cluster computing and Grid 2005 (CCGrid05), Royaume-Uni (2005)</journal-ref><abstract>  In this article we present the design choices and the evaluation of a batch
scheduler for large clusters, named OAR. This batch scheduler is based upon an
original design that emphasizes on low software complexity by using high level
tools. The global architecture is built upon the scripting language Perl and
the relational database engine Mysql. The goal of the project OAR is to prove
that it is possible today to build a complex system for ressource management
using such tools without sacrificing efficiency and scalability. Currently, our
system offers most of the important features implemented by other batch
schedulers such as priority scheduling (by queues), reservations, backfilling
and some global computing support. Despite the use of high level tools, our
experiments show that our system has performances close to other systems.
Furthermore, OAR is currently exploited for the management of 700 nodes (a
metropolitan GRID) and has shown good efficiency and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506007</id><created>2005-06-02</created><updated>2005-09-24</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author><author><keyname>Nouretdinov</keyname><forenames>Ilia</forenames></author><author><keyname>Takemura</keyname><forenames>Akimichi</forenames></author><author><keyname>Shafer</keyname><forenames>Glenn</forenames></author></authors><title>Defensive forecasting for linear protocols</title><categories>cs.LG</categories><comments>16 pages</comments><acm-class>I.2.6; I.5.1</acm-class><abstract>  We consider a general class of forecasting protocols, called &quot;linear
protocols&quot;, and discuss several important special cases, including multi-class
forecasting. Forecasting is formalized as a game between three players:
Reality, whose role is to generate observations; Forecaster, whose goal is to
predict the observations; and Skeptic, who tries to make money on any lack of
agreement between Forecaster's predictions and the actual observations. Our
main mathematical result is that for any continuous strategy for Skeptic in a
linear protocol there exists a strategy for Forecaster that does not allow
Skeptic's capital to grow. This result is a meta-theorem that allows one to
transform any continuous law of probability in a linear protocol into a
forecasting strategy whose predictions are guaranteed to satisfy this law. We
apply this meta-theorem to a weak law of large numbers in Hilbert spaces to
obtain a version of the K29 prediction algorithm for linear protocols and show
that this version also satisfies the attractive properties of proper
calibration and resolution under a suitable choice of its kernel parameter,
with no assumptions about the way the data is generated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506008</id><created>2005-06-02</created><authors><author><keyname>Klaedtke</keyname><forenames>Felix</forenames></author></authors><title>Bounds on the Automata Size for Presburger Arithmetic</title><categories>cs.LO</categories><acm-class>F.1.1; F.4.1</acm-class><abstract>  Automata provide a decision procedure for Presburger arithmetic. However,
until now only crude lower and upper bounds were known on the sizes of the
automata produced by this approach. In this paper, we prove an upper bound on
the the number of states of the minimal deterministic automaton for a
Presburger arithmetic formula. This bound depends on the length of the formula
and the quantifiers occurring in the formula. The upper bound is established by
comparing the automata for Presburger arithmetic formulas with the formulas
produced by a quantifier elimination method. We also show that our bound is
tight, even for nondeterministic automata. Moreover, we provide optimal
automata constructions for linear equations and inequations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506009</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506009</id><created>2005-06-03</created><authors><author><keyname>Madhu</keyname><forenames>A. S.</forenames></author><author><keyname>Shankar</keyname><forenames>Priti</forenames></author></authors><title>Approximate MAP Decoding on Tail-Biting Trellises</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, ISIT 2005</comments><abstract>  We propose two approximate algorithms for MAP decoding on tail-biting
trellises. The algorithms work on a subset of nodes of the tail-biting trellis,
judiciously selected. We report the results of simulations on an AWGN channel
using the approximate algorithms on tail-biting trellises for the $(24,12)$
Extended Golay Code and a rate 1/2 convolutional code with memory 6.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506010</id><created>2005-06-03</created><authors><author><keyname>Warner</keyname><forenames>Simeon</forenames><affiliation>Cornell University</affiliation></author></authors><title>The OAI Data-Provider Registration and Validation Service</title><categories>cs.DL</categories><acm-class>H.3.7</acm-class><abstract>  I present a summary of recent use of the Open Archives Initiative (OAI)
registration and validation services for data-providers. The registration
service has seen a steady stream of registrations since its launch in 2002, and
there are now over 220 registered repositories. I examine the validation logs
to produce a breakdown of reasons why repositories fail validation. This
breakdown highlights some common problems and will be used to guide work to
improve the validation service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506011</identifier>
 <datestamp>2007-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506011</id><created>2005-06-05</created><updated>2007-12-04</updated><authors><author><keyname>Sin</keyname><forenames>Peter</forenames></author><author><keyname>Xiang</keyname><forenames>Qing</forenames></author></authors><title>On the dimensions of certain LDPC codes based on q-regular bipartite
  graphs</title><categories>cs.IT cs.DM math.IT</categories><comments>3 pages corrected typos: in inequality (2) changed a minus sign to
  plus v3.corrected 2 typos in Lemma 3.5 and added Journal-ref</comments><acm-class>E.4</acm-class><journal-ref>IEEE Trans. Information Theory, 52 (8), (2006), 3735-3737</journal-ref><abstract>  An explicit construction of a family of binary LDPC codes called LU(3,q),
where q is a power of a prime, was recently given. A conjecture was made for
the dimensions of these codes when q is odd. The conjecture is proved in this
note. The proof involves the geometry of a 4-dimensional symplectic vector
space and the action of the symplectic group and its subgroups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506012</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506012</id><created>2005-06-05</created><authors><author><keyname>Meshkati</keyname><forenames>Farhad</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Schwartz</keyname><forenames>Stuart C.</forenames></author></authors><title>A Non-Cooperative Power Control Game in Delay-Constrained
  Multiple-Access Networks</title><categories>cs.IT math.IT</categories><comments>To apprear in the proceedings of the 2005 IEEE International
  Symposium on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  A game-theoretic approach for studying power control in multiple-access
networks with transmission delay constraints is proposed. A non-cooperative
power control game is considered in which each user seeks to choose a transmit
power that maximizes its own utility while satisfying the user's delay
requirements. The utility function measures the number of reliable bits
transmitted per joule of energy and the user's delay constraint is modeled as
an upper bound on the delay outage probability. The Nash equilibrium for the
proposed game is derived, and its existence and uniqueness are proved. Using a
large-system analysis, explicit expressions for the utilities achieved at
equilibrium are obtained for the matched filter, decorrelating and minimum mean
square error multiuser detectors. The effects of delay constraints on the
users' utilities (in bits/Joule) and network capacity (i.e., the maximum number
of users that can be supported) are quantified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506013</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506013</id><created>2005-06-05</created><authors><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>On the existence and characterization of the maxent distribution under
  general moment inequality constraints</title><categories>cs.IT math.IT</categories><comments>13 pages; accepted for publication in the IEEE Transactions on
  Information Theory</comments><abstract>  A broad set of sufficient conditions that guarantees the existence of the
maximum entropy (maxent) distribution consistent with specified bounds on
certain generalized moments is derived. Most results in the literature are
either focused on the minimum cross-entropy distribution or apply only to
distributions with a bounded-volume support or address only equality
constraints. The results of this work hold for general moment inequality
constraints for probability distributions with possibly unbounded support, and
the technical conditions are explicitly on the underlying generalized moment
functions. An analytical characterization of the maxent distribution is also
derived using results from the theory of constrained optimization in
infinite-dimensional normed linear spaces. Several auxiliary results of
independent interest pertaining to certain properties of convex coercive
functions are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506014</id><created>2005-06-06</created><authors><author><keyname>Engelfriet</keyname><forenames>Joost</forenames></author><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author></authors><title>The Equivalence Problem for Deterministic MSO Tree Transducers is
  Decidable</title><categories>cs.LO</categories><abstract>  It is decidable for deterministic MSO definable graph-to-string or
graph-to-tree transducers whether they are equivalent on a context-free set of
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506015</id><created>2005-06-06</created><authors><author><keyname>Gangishetti</keyname><forenames>Raju</forenames></author><author><keyname>Gorantla</keyname><forenames>M. Choudary</forenames></author><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Cryptanalysis of Key Issuing Protocols in ID-based Cryptosystems</title><categories>cs.CR</categories><comments>Submitted to National Workshop on Cryptology 2005, India</comments><abstract>  To remove key escrow problem and avoid the need of secure channel in ID based
cryptosystem Lee et al. proposed a secure key issuing protocol. However we show
that it suffers from impersonation, insider attacks and incompetency of the key
privacy authorities. We also cryptanalyze Sui et al.'s separable and anonymous
key issuing protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506016</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506016</id><created>2005-06-06</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>Compressing Probability Distributions</title><categories>cs.IT math.IT</categories><acm-class>E.4</acm-class><journal-ref>10.1016/j.ipl.2005.10.006</journal-ref><abstract>  We show how to store good approximations of probability distributions in
small space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506017</id><created>2005-06-06</created><authors><author><keyname>Messai</keyname><forenames>Nizar</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Devignes</keyname><forenames>Marie-Dominique</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Sma&#xef;l-Tabbone</keyname><forenames>Malika</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Napoli</keyname><forenames>Amedeo</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Treillis de concepts et ontologies pour l'interrogation d'un annuaire de
  sources de donn\'{e}es biologiques (BioRegistry)</title><categories>cs.DB cs.IR</categories><proxy>ccsd inria-00000101</proxy><abstract>  Bioinformatic data sources available on the web are multiple and
heterogenous. The lack of documentation and the difficulty of interaction with
these data sources require users competence in both informatics and biological
fields for an optimal use of sources contents that remain rather under
exploited. In this paper we present an approach based on formal concept
analysis to classify and search relevant bioinformatic data sources for a given
query. It consists in building the concept lattice from the binary relation
between bioinformatic data sources and their associated metadata. The concept
built from a given query is then merged into the concept lattice. The result is
given by the extraction of the set of sources belonging to the extents of the
query concept subsumers in the resulting concept lattice. The sources ranking
is given by the concept specificity order in the concept lattice. An
improvement of the approach consists in automatic query refinement thanks to
domain ontologies. Two forms of refinement are possible by generalisation and
by specialisation.
  -----
  Les sources de donn\'{e}es biologiques disponibles sur le web sont multiples
et h\'{e}t\'{e}rog\`{e}nes. L'utilisation optimale de ces ressources
n\'{e}cessite aujourd'hui de la part des utilisateurs des comp\'{e}tences \`{a}
la fois en informatique et en biologie, du fait du manque de documentation et
des difficult\'{e}s d'interaction avec les sources de donn\'{e}es. De fait, les
contenus de ces ressources restent souvent sous-exploit\'{e}s. Nous
pr\'{e}sentons ici une approche bas\'{e}e sur l'analyse de concepts formels,
pour organiser et rechercher des sources de donn\'{e}es biologiques pertinentes
pour une requ\^{e}te donn\'{e}e. Le travail consiste \`{a} construire un
treillis de concepts \`{a} partir des m\'{e}ta-donn\'{e}es associ\'{e}es aux
sources. Le concept construit \`{a} partir d'une requ\^{e}te donn\'{e}e est
alors int\'{e}gr\'{e} au treillis. La r\'{e}ponse \`{a} la requ\^{e}te est
ensuite fournie par l'extraction des sources de donn\'{e}es appartenant aux
extensions des concepts subsumant le concept requ\^{e}te dans le treillis. Les
sources ainsi retourn\'{e}es peuvent \^{e}tre tri\'{e}es selon l'ordre de
sp\'{e}cificit\'{e} des concepts dans le treillis. Une proc\'{e}dure de
raffinement de requ\^{e}te, bas\'{e}e sur des ontologies du domaine, permet
d'am\'{e}liorer le rappel par g\'{e}n\'{e}ralisation ou par sp\'{e}cialisation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506018</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506018</id><created>2005-06-06</created><authors><author><keyname>Azarian</keyname><forenames>Kambiz</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>On the Achievable Diversity-Multiplexing Tradeoffs in Half-Duplex
  Cooperative Channels</title><categories>cs.IT math.IT</categories><comments>40 pages, 12 figures, IEEE Transactions on Information Theory</comments><acm-class>E.4</acm-class><abstract>  In this paper, we propose novel cooperative transmission protocols for delay
limited coherent fading channels consisting of N (half-duplex and
single-antenna) partners and one cell site. In our work, we differentiate
between the relay, cooperative broadcast (down-link), and cooperative
multiple-access (up-link) channels. For the relay channel, we investigate two
classes of cooperation schemes; namely, Amplify and Forward (AF) protocols and
Decode and Forward (DF) protocols. For the first class, we establish an upper
bound on the achievable diversity-multiplexing tradeoff with a single relay. We
then construct a new AF protocol that achieves this upper bound. The proposed
algorithm is then extended to the general case with N-1 relays where it is
shown to outperform the space-time coded protocol of Laneman and Worenell
without requiring decoding/encoding at the relays. For the class of DF
protocols, we develop a dynamic decode and forward (DDF) protocol that achieves
the optimal tradeoff for multiplexing gains 0 &lt; r &lt; 1/N. Furthermore, with a
single relay, the DDF protocol is shown to dominate the class of AF protocols
for all multiplexing gains. The superiority of the DDF protocol is shown to be
more significant in the cooperative broadcast channel. The situation is
reversed in the cooperative multiple-access channel where we propose a new AF
protocol that achieves the optimal tradeoff for all multiplexing gains. A
distinguishing feature of the proposed protocols in the three scenarios is that
they do not rely on orthogonal subspaces, allowing for a more efficient use of
resources. In fact, using our results one can argue that the sub-optimality of
previously proposed protocols stems from their use of orthogonal subspaces
rather than the half-duplex constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506019</id><created>2005-06-07</created><updated>2006-07-02</updated><authors><author><keyname>Choi</keyname><forenames>Vicky</forenames></author><author><keyname>Goyal</keyname><forenames>Navin</forenames></author></authors><title>An Efficient Approximation Algorithm for Point Pattern Matching Under
  Noise</title><categories>cs.CV cs.CG</categories><comments>18 pages</comments><abstract>  Point pattern matching problems are of fundamental importance in various
areas including computer vision and structural bioinformatics. In this paper,
we study one of the more general problems, known as LCP (largest common point
set problem): Let $\PP$ and $\QQ$ be two point sets in $\mathbb{R}^3$, and let
$\epsilon \geq 0$ be a tolerance parameter, the problem is to find a rigid
motion $\mu$ that maximizes the cardinality of subset $\II$ of $Q$, such that
the Hausdorff distance $\distance(\PP,\mu(\II)) \leq \epsilon$. We denote the
size of the optimal solution to the above problem by $\LCP(P,Q)$. The problem
is called exact-LCP for $\epsilon=0$, and \tolerant-LCP when $\epsilon&gt;0$ and
the minimum interpoint distance is greater than $2\epsilon$. A
$\beta$-distance-approximation algorithm for tolerant-LCP finds a subset $I
\subseteq \QQ$ such that $|I|\geq \LCP(P,Q)$ and $\distance(\PP,\mu(\II)) \leq
\beta \epsilon$ for some $\beta \ge 1$.
  This paper has three main contributions. (1) We introduce a new algorithm,
called {\DA}, which gives the fastest known deterministic
4-distance-approximation algorithm for \tolerant-LCP. (2) For the exact-LCP,
when the matched set is required to be large, we give a simple sampling
strategy that improves the running times of all known deterministic algorithms,
yielding the fastest known deterministic algorithm for this problem. (3) We use
expander graphs to speed-up the \DA algorithm for \tolerant-LCP when the size
of the matched set is required to be large, at the expense of approximation in
the matched set size. Our algorithms also work when the transformation $\mu$ is
allowed to be scaling transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506020</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506020</id><created>2005-06-07</created><authors><author><keyname>Gopala</keyname><forenames>Praveen Kumar</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On the Throughput-Delay Tradeoff in Cellular Multicast</title><categories>cs.IT math.IT</categories><comments>32 pages, 6 figures, Submitted to the joint special issue of
  Transactions on Information Theory and Transactions on Networking</comments><abstract>  In this paper, we adopt a cross layer design approach for analyzing the
throughput-delay tradeoff of the multicast channel in a single cell system. To
illustrate the main ideas, we start with the single group case, i.e., pure
multicast, where a common information stream is requested by all the users. We
consider three classes of scheduling algorithms with progressively increasing
complexity. The first class strives for minimum complexity by resorting to a
static scheduling strategy along with memoryless decoding. Our analysis for
this class of scheduling algorithms reveals the existence of a static
scheduling policy that achieves the optimal scaling law of the throughput at
the expense of a delay that increases exponentially with the number of users.
The second scheduling policy resorts to a higher complexity incremental
redundancy encoding/decoding strategy to achieve a superior throughput-delay
tradeoff. The third, and most complex, scheduling strategy benefits from the
cooperation between the different users to minimize the delay while achieving
the optimal scaling law of the throughput. In particular, the proposed
cooperative multicast strategy is shown to simultaneously achieve the optimal
scaling laws of both throughput and delay. Then, we generalize our scheduling
algorithms to exploit the multi-group diversity available when different
information streams are requested by different subsets of the user population.
Finally, we discuss the effect of the potential gains of equipping the base
station with multi-transmit antennas and present simulation results that
validate our theoretical claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506021</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506021</id><created>2005-06-07</created><authors><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author><author><keyname>Wei</keyname><forenames>Shuangqing</forenames></author></authors><title>Analysis of Relationship between Strategic and Aggregate Energy
  Minimization in Delay-Constrained Wireless Networks</title><categories>cs.NI cs.GT</categories><comments>5Pages, 3 figures, Conference Version</comments><abstract>  We formulate two versions of the power control problem for wireless networks
with latency constraints arising from duty cycle allocations In the first
version, strategic power optimization, wireless nodes are modeled as rational
agents in a power game, who strategically adjust their powers to minimize their
own energy. In the other version, joint power optimization, wireless nodes
jointly minimize the aggregate energy expenditure. Our analysis of these models
yields insights into the different energy outcomes of strategic versus joint
power optimization. We derive analytical solutions for power allocation under
both models and study how they are affected by data loads and channel quality.
We derive simple necessary conditions for the existence of Nash equilibria in
the power game and also provide numerical examples of optimal power allocation
under both models. Finally, we show that joint optimization can (sometimes) be
Pareto-optimal and dominate strategic optimization, i.e the energy expenditure
of all nodes is lower than if they were using strategic optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506022</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506022</id><created>2005-06-08</created><authors><author><keyname>Poland</keyname><forenames>Jan</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Asymptotics of Discrete MDL for Online Prediction</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>34 pages</comments><report-no>IDSIA-13-05</report-no><acm-class>I.2.6; E.4; G.3</acm-class><journal-ref>IEEE Transactions on Information Theory, 51:11 (2005) 3780-3795</journal-ref><doi>10.1109/TIT.2005.856956</doi><abstract>  Minimum Description Length (MDL) is an important principle for induction and
prediction, with strong relations to optimal Bayesian learning. This paper
deals with learning non-i.i.d. processes by means of two-part MDL, where the
underlying model class is countable. We consider the online learning framework,
i.e. observations come in one by one, and the predictor is allowed to update
his state of mind after each time step. We identify two ways of predicting by
MDL for this setup, namely a static} and a dynamic one. (A third variant,
hybrid MDL, will turn out inferior.) We will prove that under the only
assumption that the data is generated by a distribution contained in the model
class, the MDL predictions converge to the true values almost surely. This is
accomplished by proving finite bounds on the quadratic, the Hellinger, and the
Kullback-Leibler loss of the MDL learner, which are however exponentially worse
than for Bayesian prediction. We demonstrate that these bounds are sharp, even
for model classes containing only Bernoulli distributions. We show how these
bounds imply regret bounds for arbitrary loss functions. Our results apply to a
wide range of setups, namely sequence prediction, pattern classification,
regression, and universal induction in the sense of Algorithmic Information
Theory among others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506023</id><created>2005-06-08</created><authors><author><keyname>Banerjee</keyname><forenames>Onureena</forenames></author><author><keyname>d'Aspremont</keyname><forenames>Alexandre</forenames></author><author><keyname>Ghaoui</keyname><forenames>Laurent El</forenames></author></authors><title>Sparse Covariance Selection via Robust Maximum Likelihood Estimation</title><categories>cs.CE cs.AI</categories><comments>Submitted to NIPS 2005</comments><acm-class>F.2.1; G.1.3; G.1.6; G.3; J.3</acm-class><abstract>  We address a problem of covariance selection, where we seek a trade-off
between a high likelihood against the number of non-zero elements in the
inverse covariance matrix. We solve a maximum likelihood problem with a penalty
term given by the sum of absolute values of the elements of the inverse
covariance matrix, and allow for imposing bounds on the condition number of the
solution. The problem is directly amenable to now standard interior-point
algorithms for convex optimization, but remains challenging due to its size. We
first give some results on the theoretical computational complexity of the
problem, by showing that a recent methodology for non-smooth convex
optimization due to Nesterov can be applied to this problem, to greatly improve
on the complexity estimate given by interior-point algorithms. We then examine
two practical algorithms aimed at solving large-scale, noisy (hence dense)
instances: one is based on a block-coordinate descent approach, where columns
and rows are updated sequentially, another applies a dual version of Nesterov's
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506024</id><created>2005-06-08</created><updated>2005-06-17</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>The Hyper-Cortex of Human Collective-Intelligence Systems</title><categories>cs.CY cs.AI cs.DL cs.NE</categories><comments>ECCO Working Paper 06-2005 (17-pages) This paper will be shortened to
  just the multi-layered digital-library hyper-cortex</comments><abstract>  Individual-intelligence research, from a neurological perspective, discusses
the hierarchical layers of the cortex as a structure that performs conceptual
abstraction and specification. This theory has been used to explain how
motor-cortex regions responsible for different behavioral modalities such as
writing and speaking can be utilized to express the same general concept
represented higher in the cortical hierarchy. For example, the concept of a
dog, represented across a region of high-level cortical-neurons, can either be
written or spoken about depending on the individual's context. The higher-layer
cortical areas project down the hierarchy, sending abstract information to
specific regions of the motor-cortex for contextual implementation. In this
paper, this idea is expanded to incorporate collective-intelligence within a
hyper-cortical construct. This hyper-cortex is a multi-layered network used to
represent abstract collective concepts. These ideas play an important role in
understanding how collective-intelligence systems can be engineered to handle
problem abstraction and solution specification. Finally, a collection of common
problems in the scientific community are solved using an artificial
hyper-cortex generated from digital-library metadata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506025</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506025</id><created>2005-06-08</created><updated>2006-11-20</updated><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>Dynamic Asymmetric Communication</title><categories>cs.IT math.IT</categories><comments>Previous versions appeared at DCC 06 and SIROCCO 06; current version
  is preliminary journal version</comments><acm-class>E.4</acm-class><doi>10.1109/DCC.2006.29</doi><abstract>  We show how any dynamic instantaneous compression algorithm can be converted
to an asymmetric communication protocol, with which a server with high
bandwidth can help clients with low bandwidth send it messages. Unlike previous
authors, we do not assume the server knows the messages' distribution, and our
protocols are the first to use only one round of communication for each
message.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506026</id><created>2005-06-08</created><authors><author><keyname>Chirkova</keyname><forenames>Rada</forenames></author><author><keyname>Genesereth</keyname><forenames>Michael R.</forenames></author></authors><title>Database Reformulation with Integrity Constraints (extended abstract)</title><categories>cs.DB</categories><comments>In the proceedings of the the Logic and Computational Complexity
  Workshop, in conjunction with of the Logic in Computer Science Conference
  (LICS), Chicago, June 2005</comments><abstract>  In this paper we study the problem of reducing the evaluation costs of
queries on finite databases in presence of integrity constraints, by designing
and materializing views. Given a database schema, a set of queries defined on
the schema, a set of integrity constraints, and a storage limit, to find a
solution to this problem means to find a set of views that satisfies the
storage limit, provides equivalent rewritings of the queries under the
constraints (this requirement is weaker than equivalence in the absence of
constraints), and reduces the total costs of evaluating the queries. This
problem, database reformulation, is important for many applications, including
data warehousing and query optimization. We give complexity results and
algorithms for database reformulation in presence of constraints, for
conjunctive queries, views, and rewritings and for several types of
constraints, including functional and inclusion dependencies. To obtain better
complexity results, we introduce an unchase technique, which reduces the
problem of query equivalence under constraints to equivalence in the absence of
constraints without increasing query size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506027</id><created>2005-06-08</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>Sorting a Low-Entropy Sequence</title><categories>cs.DS</categories><acm-class>E.4; E.5</acm-class><abstract>  We give the first sorting algorithm with bounds in terms of higher-order
entropies: let $S$ be a sequence of length $m$ containing $n$ distinct elements
and let (H_\ell (S)) be the $\ell$th-order empirical entropy of $S$, with
(n^{\ell + 1} \log n \in O (m)); our algorithm sorts $S$ using ((H_\ell (S) + O
(1)) m) comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506028</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506028</id><created>2005-06-08</created><updated>2006-01-04</updated><authors><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Neyman-Pearson Detection of Gauss-Markov Signals in Noise: Closed-Form
  Error Exponent and Properties</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  The performance of Neyman-Pearson detection of correlated stochastic signals
using noisy observations is investigated via the error exponent for the miss
probability with a fixed level. Using the state-space structure of the signal
and observation model, a closed-form expression for the error exponent is
derived, and the connection between the asymptotic behavior of the optimal
detector and that of the Kalman filter is established. The properties of the
error exponent are investigated for the scalar case. It is shown that the error
exponent has distinct characteristics with respect to correlation strength: for
signal-to-noise ratio (SNR) &gt;1 the error exponent decreases monotonically as
the correlation becomes stronger, whereas for SNR &lt;1 there is an optimal
correlation that maximizes the error exponent for a given SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506029</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506029</id><created>2005-06-09</created><authors><author><keyname>Murugan</keyname><forenames>Arul D.</forenames><affiliation>The Ohio State University</affiliation></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames><affiliation>The Ohio State University</affiliation></author><author><keyname>Damen</keyname><forenames>Mohamed Oussama</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames><affiliation>Institut Eurecom</affiliation></author></authors><title>A Unified Framework for Tree Search Decoding : Rediscovering the
  Sequential Decoder</title><categories>cs.IT math.IT</categories><comments>37 pages, 9 figures, submitted to IEEE Transactions on Information
  Theory</comments><abstract>  We consider receiver design for coded transmission over linear Gaussian
channels. We restrict ourselves to the class of lattice codes and formulate the
joint detection and decoding problem as a closest lattice point search (CLPS).
Here, a tree search framework for solving the CLPS is adopted. In our
framework, the CLPS algorithm decomposes into the preprocessing and tree search
stages. The role of the preprocessing stage is to expose the tree structure in
a form {\em matched} to the search stage. We argue that the minimum mean square
error decision feedback (MMSE-DFE) frontend is instrumental for solving the
joint detection and decoding problem in a single search stage. It is further
shown that MMSE-DFE filtering allows for using lattice reduction methods to
reduce complexity, at the expense of a marginal performance loss, and solving
under-determined linear systems. For the search stage, we present a generic
method, based on the branch and bound (BB) algorithm, and show that it
encompasses all existing sphere decoders as special cases. The proposed generic
algorithm further allows for an interesting classification of tree search
decoders, sheds more light on the structural properties of all known sphere
decoders, and inspires the design of more efficient decoders. In particular, an
efficient decoding algorithm that resembles the well known Fano sequential
decoder is identified. The excellent performance-complexity tradeoff achieved
by the proposed MMSE-Fano decoder is established via simulation results and
analytical arguments in several MIMO and ISI scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506030</id><created>2005-06-09</created><updated>2007-04-08</updated><authors><author><keyname>Ben-Naim</keyname><forenames>Jonathan</forenames><affiliation>LIF</affiliation></author></authors><title>Preferential and Preferential-discriminative Consequence relations</title><categories>cs.AI cs.LO</categories><comments>team Logic and Complexity, written in 2004-2005</comments><journal-ref>Journal of Logic and Computation 15 (2005) number 3, pp. 263-294</journal-ref><doi>10.1093/logcom/exi013</doi><abstract>  The present paper investigates consequence relations that are both
non-monotonic and paraconsistent. More precisely, we put the focus on
preferential consequence relations, i.e. those relations that can be defined by
a binary preference relation on states labelled by valuations. We worked with a
general notion of valuation that covers e.g. the classical valuations as well
as certain kinds of many-valued valuations. In the many-valued cases,
preferential consequence relations are paraconsistant (in addition to be
non-monotonic), i.e. they are capable of drawing reasonable conclusions which
contain contradictions. The first purpose of this paper is to provide in our
general framework syntactic characterizations of several families of
preferential relations. The second and main purpose is to provide, again in our
general framework, characterizations of several families of preferential
discriminative consequence relations. They are defined exactly as the plain
version, but any conclusion such that its negation is also a conclusion is
rejected (these relations bring something new essentially in the many-valued
cases).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506031</id><created>2005-06-09</created><authors><author><keyname>Albert</keyname><forenames>Patrick</forenames></author><author><keyname>Henocque</keyname><forenames>Laurent</forenames></author><author><keyname>Kleiner</keyname><forenames>Mathias</forenames></author></authors><title>A Constrained Object Model for Configuration Based Workflow Composition</title><categories>cs.AI</categories><comments>This is an extended version of the article published at BPM'05, Third
  International Conference on Business Process Management, Nancy France</comments><acm-class>C.0; D.2.1; D.3.1; F.4.1</acm-class><abstract>  Automatic or assisted workflow composition is a field of intense research for
applications to the world wide web or to business process modeling. Workflow
composition is traditionally addressed in various ways, generally via theorem
proving techniques. Recent research observed that building a composite workflow
bears strong relationships with finite model search, and that some workflow
languages can be defined as constrained object metamodels . This lead to
consider the viability of applying configuration techniques to this problem,
which was proven feasible. Constrained based configuration expects a
constrained object model as input. The purpose of this document is to formally
specify the constrained object model involved in ongoing experiments and
research using the Z specification language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506032</id><created>2005-06-10</created><authors><author><keyname>Shankar</keyname><forenames>R.</forenames></author></authors><title>Framework for Hopfield Network based Adaptive routing - A design level
  approach for adaptive routing phenomena with Artificial Neural Network</title><categories>cs.NE</categories><comments>(13 pages, 7 figures, code)</comments><abstract>  Routing, as a basic phenomena, by itself, has got umpteen scopes to analyse,
discuss and arrive at an optimal solution for the technocrats over years.
Routing is analysed based on many factors; few key constraints that decide the
factors are communication medium, time dependency, information source nature.
Parametric routing has become the requirement of the day, with some kind of
adaptation to the underlying network environment. Satellite constellations,
particularly LEO satellite constellations have become a reality in operational
to have a non-breaking voice/data communication around the world.Routing in
these constellations has to be treated in a non conventional way, taking their
network geometry into consideration. One of the efficient methods of
optimization is putting Neural Networks to use. Few Artificial Neural Network
models are very much suitable for the adaptive control mechanism, by their
nature of network arrangement. One such efficient model is Hopfield Network
model.
  This paper is an attempt to design a framework for the Hopfield Network based
adaptive routing phenomena in satellite constellations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506033</identifier>
 <datestamp>2011-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506033</id><created>2005-06-10</created><updated>2011-08-28</updated><authors><author><keyname>Filla</keyname><forenames>Reno</forenames><affiliation>Volvo Wheel Loaders AB</affiliation></author></authors><title>An Event-driven Operator Model for Dynamic Simulation of Construction
  Machinery</title><categories>cs.CE</categories><comments>11 pages, 18 figures, SICFP'05 conference; Proceedings of SICFP 2005</comments><acm-class>I.6.3; I.6.5; J.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prediction and optimisation of a wheel loader's dynamic behaviour is a
challenge due to tightly coupled, non-linear subsystems of different technical
domains. Furthermore, a simulation regarding performance, efficiency, and
operability cannot be limited to the machine itself, but has to include
operator, environment, and work task. This paper presents some results of our
approach to an event-driven simulation model of a human operator. Describing
the task and the operator model independently of the machine's technical
parameters, gives the possibility to change whole sub-system characteristics
without compromising the relevance and validity of the simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506034</id><created>2005-06-10</created><authors><author><keyname>Venugopal</keyname><forenames>Srikumar</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Ramamohanarao</keyname><forenames>Kotagiri</forenames></author></authors><title>A Taxonomy of Data Grids for Distributed Data Sharing, Management and
  Processing</title><categories>cs.DC cs.CE</categories><comments>46 pages, 16 figures, Technical Report</comments><report-no>GRIDS-TR-2005-3</report-no><acm-class>A.1; C.2.4; J.2</acm-class><abstract>  Data Grids have been adopted as the platform for scientific communities that
need to share, access, transport, process and manage large data collections
distributed worldwide. They combine high-end computing technologies with
high-performance networking and wide-area storage management techniques. In
this paper, we discuss the key concepts behind Data Grids and compare them with
other data sharing and distribution paradigms such as content delivery
networks, peer-to-peer networks and distributed databases. We then provide
comprehensive taxonomies that cover various aspects of architecture, data
transportation, data replication and resource allocation and scheduling.
Finally, we map the proposed taxonomy to various Data Grid systems not only to
validate the taxonomy but also to identify areas for future exploration.
Through this taxonomy, we aim to categorise existing systems to better
understand their goals and their methodology. This would help evaluate their
applicability for solving similar problems. This taxonomy also provides a &quot;gap
analysis&quot; of this area through which researchers can potentially identify new
issues for investigation. Finally, we hope that the proposed taxonomy and
mapping also helps to provide an easy way for new practitioners to understand
this complex area of research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506035</id><created>2005-06-10</created><authors><author><keyname>Collin</keyname><forenames>Jerome</forenames><affiliation>Computer Engineering, Ecole Polytechnique de Montreal</affiliation></author><author><keyname>Dagenais</keyname><forenames>Michel</forenames><affiliation>Computer Engineering, Ecole Polytechnique de Montreal</affiliation></author></authors><title>Fast Recompilation of Object Oriented Modules</title><categories>cs.PL</categories><abstract>  Once a program file is modified, the recompilation time should be minimized,
without sacrificing execution speed or high level object oriented features. The
recompilation time is often a problem for the large graphical interactive
distributed applications tackled by modern OO languages. A compilation server
and fast code generator were developed and integrated with the SRC Modula-3
compiler and Linux ELF dynamic linker. The resulting compilation and
recompilation speedups are impressive. The impact of different language
features, processor speed, and application size are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506036</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506036</id><created>2005-06-10</created><authors><author><keyname>Dalai</keyname><forenames>Marco</forenames></author><author><keyname>Leonardi</keyname><forenames>Riccardo</forenames></author></authors><title>Non prefix-free codes for constrained sequences</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures. To be presented at the 2005 IEEE International
  Symposium on Information Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  In this paper we consider the use of variable length non prefix-free codes
for coding constrained sequences of symbols. We suppose to have a Markov source
where some state transitions are impossible, i.e. the stochastic matrix
associated with the Markov chain has some null entries. We show that classic
Kraft inequality is not a necessary condition, in general, for unique
decodability under the above hypothesis and we propose a relaxed necessary
inequality condition. This allows, in some cases, the use of non prefix-free
codes that can give very good performance, both in terms of compression and
computational efficiency. Some considerations are made on the relation between
the proposed approach and other existing coding paradigms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506037</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506037</id><created>2005-06-10</created><authors><author><keyname>Kizhakkemadam</keyname><forenames>Sriram N.</forenames></author><author><keyname>Papamichalis</keyname><forenames>Panos</forenames></author><author><keyname>Srinath</keyname><forenames>Mandyam</forenames></author><author><keyname>Rajan</keyname><forenames>Dinesh</forenames></author></authors><title>Tradeoff Between Source and Channel Coding for Erasure Channels</title><categories>cs.IT math.IT</categories><comments>International Symposium on Information Theory, Adelaide, Sept.
  2005(accepted)</comments><abstract>  In this paper, we investigate the optimal tradeoff between source and channel
coding for channels with bit or packet erasure. Upper and Lower bounds on the
optimal channel coding rate are computed to achieve minimal end-to-end
distortion. The bounds are calculated based on a combination of sphere packing,
straight line and expurgated error exponents and also high rate vector
quantization theory. By modeling a packet erasure channel in terms of an
equivalent bit erasure channel, we obtain bounds on the packet size for a
specified limit on the distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506038</id><created>2005-06-10</created><authors><author><keyname>Ding</keyname><forenames>Wen</forenames></author><author><keyname>Yurcik</keyname><forenames>William</forenames></author></authors><title>A Game Theoretic Economics Framework to understanding Information
  Security Oursourcing Market</title><categories>cs.GT</categories><comments>16 pages, 2 figures</comments><abstract>  On information security outsourcing market, an important reason that firms do
not want to let outside firms(usually called MSSPs-Managed Security Service
Providers) to take care of their security need is that they worry about service
quality MSSPs provide because they cannot monitor effort of the MSSPs. Since
MSSPs action is unobservable to buyers, MSSPs can lower cost by working less
hard than required in the contract and get higher profit. In the asymmetric
information literature, this possible secret shirking behavior is termed as
moral hazard problem. This paper considers a game theoretic economic framework
to show that under information asymmetry, an optimal contract can be designed
so that MSSPs will stick to their promised effort level. We also show that the
optimal contract should be performance-based, i.e., payment to MSSP should base
on performance of MSSP's security service period by period. For comparison, we
also showed that if the moral hazard problem does not exist, the optimal
contract does not depend on MSSP's performance. A contract that specifies
constant payment to MSSP will be optimal. Besides these, we show that for no
matter under perfect information scenario or imperfect information scenario,
the higher the transaction cost is, the lower payment to MSSPs will be.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506039</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506039</id><created>2005-06-10</created><authors><author><keyname>Zhu</keyname><forenames>Weijun</forenames></author><author><keyname>Lee</keyname><forenames>Heechoon</forenames></author><author><keyname>Liu</keyname><forenames>Daniel</forenames></author><author><keyname>Fitz</keyname><forenames>Michael P.</forenames></author></authors><title>Antenna array geometry and coding performance</title><categories>cs.IT math.IT</categories><comments>5 pages, 7 figures, ISIT 2005</comments><abstract>  This paper provides details about experiments in realistic, urban, and
frequency flat channels with space-time coding that specifically examines the
impact of the number of receive antennas and the design criteria for code
selection on the performance. Also the performance characteristics are examined
of the coded modulations in the presence of finite size array geometries. This
paper gives some insight into which of the theories are most useful in
realistic deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506040</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506040</id><created>2005-06-12</created><authors><author><keyname>Liu</keyname><forenames>Jie</forenames></author><author><keyname>Bao</keyname><forenames>Sheng</forenames></author><author><keyname>Jing</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Chen</keyname><forenames>Shi</forenames></author></authors><title>A Fixed-Length Coding Algorithm for DNA Sequence Compression</title><categories>cs.IT math.IT</categories><comments>2 pages,2 tables,using Bioinformatics Latex template,no more
  relationship between us and that magazine</comments><acm-class>J.3; E.4</acm-class><abstract>  While achieving a compression ratio of 2.0 bits/base, the new algorithm codes
non-N bases in fixed length. It dramatically reduces the time of coding and
decoding than previous DNA compression algorithms and some universal
compression programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506041</id><created>2005-06-11</created><updated>2005-09-02</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Competitive on-line learning with a convex loss function</title><categories>cs.LG cs.AI</categories><comments>26 pages</comments><acm-class>I.2.6; I.5.1</acm-class><abstract>  We consider the problem of sequential decision making under uncertainty in
which the loss caused by a decision depends on the following binary
observation. In competitive on-line learning, the goal is to design decision
algorithms that are almost as good as the best decision rules in a wide
benchmark class, without making any assumptions about the way the observations
are generated. However, standard algorithms in this area can only deal with
finite-dimensional (often countable) benchmark classes. In this paper we give
similar results for decision rules ranging over an arbitrary reproducing kernel
Hilbert space. For example, it is shown that for a wide class of loss functions
(including the standard square, absolute, and log loss functions) the average
loss of the master algorithm, over the first $N$ observations, does not exceed
the average loss of the best decision rule with a bounded norm plus
$O(N^{-1/2})$. Our proof technique is very different from the standard ones and
is based on recent results about defensive forecasting. Given the probabilities
produced by a defensive forecasting algorithm, which are known to be well
calibrated and to have good resolution in the long run, we use the expected
loss minimization principle to find a suitable decision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506042</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506042</id><created>2005-06-12</created><authors><author><keyname>Sridhara</keyname><forenames>Deepak</forenames></author><author><keyname>Kelley</keyname><forenames>Christine</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Tree-Based Construction of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 12 figures. To appear in the Proceedings of IEEE
  International Symposium on Information Theory, Sept. 4-9, 2005, Adelaide,
  Australia</comments><abstract>  We present a construction of LDPC codes that have minimum pseudocodeword
weight equal to the minimum distance, and perform well with iterative decoding.
The construction involves enumerating a d-regular tree for a fixed number of
layers and employing a connection algorithm based on mutually orthogonal Latin
squares to close the tree. Methods are presented for degrees d=p^s and d =
p^s+1, for p a prime, -- one of which includes the well-known
finite-geometry-based LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506043</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506043</id><created>2005-06-13</created><authors><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author><author><keyname>Bhattad</keyname><forenames>Kapil</forenames></author></authors><title>A Decision Feedback Based Scheme for Slepian-Wolf Coding of sources with
  Hidden Markov Correlation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Comm. Letters</comments><abstract>  We consider the problem of compression of two memoryless binary sources, the
correlation between which is defined by a Hidden Markov Model (HMM). We propose
a Decision Feedback (DF) based scheme which when used with low density parity
check codes results in compression close to the Slepian Wolf limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506044</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506044</id><created>2005-06-12</created><authors><author><keyname>Bhattad</keyname><forenames>Kapil</forenames></author><author><keyname>Ratnakar</keyname><forenames>Niranjan</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Minimal Network Coding for Multicast</title><categories>cs.IT math.IT</categories><comments>accepted for publication at ISIT 2005</comments><abstract>  We give an information flow interpretation for multicasting using network
coding. This generalizes the fluid model used to represent flows to a single
receiver. Using the generalized model, we present a decentralized algorithm to
minimize the number of packets that undergo network coding. We also propose a
decentralized algorithm to construct capacity achieving multicast codes when
the processing at some nodes is restricted to routing. The proposed algorithms
can be coupled with existing decentralized schemes to achieve minimum cost
muticast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506045</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506045</id><created>2005-06-12</created><authors><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author><author><keyname>Bhattad</keyname><forenames>Kapil</forenames></author></authors><title>Decision Feedback Based Scheme for Slepian-Wolf Coding of sources with
  Hidden Markov Correlation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Comm. Letters</comments><abstract>  We consider the problem of compression of two memoryless binary sources, the
correlation between which is defined by a Hidden Markov Model (HMM). We propose
a Decision Feedback (DF) based scheme which when used with low density parity
check codes results in compression close to the Slepian Wolf limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506046</id><created>2005-06-12</created><authors><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>ISC</affiliation></author></authors><title>Dictionaries merger for text expansion in question answering</title><categories>cs.DL</categories><comments>4 pp</comments><proxy>ccsd ccsd-00005103</proxy><acm-class>H.3; H.5</acm-class><journal-ref>Proceedings of COLING 2004 (2004) 1398</journal-ref><abstract>  This paper presents an original way to add new data in a reference dictionary
from several other lexical resources, without loosing any consistence. This
operation is carried in order to get lexical information classified by the
sense of the entry. This classification makes it possible to enrich utterances
(in QA: the queries) following the meaning, and to reduce noise. An analysis of
the experienced problems shows the interest of this method, and insists on the
points that have to be tackled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506047</id><created>2005-06-12</created><authors><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>ISC</affiliation></author></authors><title>Analyse et expansion des textes en question-r\'{e}ponse</title><categories>cs.IR</categories><comments>11 pp</comments><proxy>ccsd ccsd-00005123</proxy><acm-class>H.3; H.4; H.5</acm-class><journal-ref>Le poids des mots. Actes des 7es journ\'{e}es internationales
  d'Analyse statistique des Donn\'{e}es Textuelles (2004) 1219</journal-ref><abstract>  This paper presents an original methodology to consider question answering.
We noticed that query expansion is often incorrect because of a bad
understanding of the question. But the automatic good understanding of an
utterance is linked to the context length, and the question are often short.
This methodology proposes to analyse the documents and to construct an
informative structure from the results of the analysis and from a semantic text
expansion. The linguistic analysis identifies words (tokenization and
morphological analysis), links between words (syntactic analysis) and word
sense (semantic disambiguation). The text expansion adds to each word the
synonyms matching its sense and replaces the words in the utterances by
derivatives, modifying the syntactic schema if necessary. In this way, whatever
enrichment may be, the text keeps the same meaning, but each piece of
information matches many realisations. The questioning method consists in
constructing a local informative structure without enrichment, and matches it
with the documentary structure. If a sentence in the informative structure
matches the question structure, this sentence is the answer to the question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506048</id><created>2005-06-12</created><authors><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>ISC</affiliation></author><author><keyname>Brun</keyname><forenames>Caroline</forenames></author><author><keyname>Roux</keyname><forenames>Claude</forenames></author></authors><title>Enriching a Text by Semantic Disambiguation for Information Extraction</title><categories>cs.IR</categories><comments>7 pp</comments><proxy>ccsd ccsd-00005128</proxy><acm-class>H.3; H.4; H.5</acm-class><journal-ref>LREC 2002 Workshop Proceedings &quot;Using semantics for informaiton
  retrival and filtering&quot; (2002) 45-51</journal-ref><abstract>  External linguistic resources have been used for a very long time in
information extraction. These methods enrich a document with data that are
semantically equivalent, in order to improve recall. For instance, some of
these methods use synonym dictionaries. These dictionaries enrich a sentence
with words that have a similar meaning. However, these methods present some
serious drawbacks, since words are usually synonyms only in restricted
contexts. The method we propose here consists of using word sense
disambiguation rules (WSD) to restrict the selection of synonyms to only these
that match a specific syntactico-semantic context. We show how WSD rules are
built and how information extraction techniques can benefit from the
application of these rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506049</id><created>2005-06-12</created><authors><author><keyname>Brun</keyname><forenames>Caroline</forenames><affiliation>XRCE</affiliation></author><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>ISC, XRCE</affiliation></author><author><keyname>Segond</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames><affiliation>XRCE</affiliation></author></authors><title>Exploitation de dictionnaires \'{e}lectroniques pour la
  d\'{e}sambigu\&quot;{i}sation s\'{e}mantique lexicale</title><categories>cs.DL</categories><comments>25 pp</comments><proxy>ccsd ccsd-00005129</proxy><acm-class>H.3; H.4; H.5</acm-class><journal-ref>Traitement Automatique des Langues (TAL) 42, no. 3 (2001) pp.
  667-690</journal-ref><abstract>  This paper presents a lexical disambiguation system, initially developed for
English and now adapted to French. This system associates a word with its
meaning in a given context using electronic dictionaries as semantically
annotated corpora in order to extract semantic disambiguation rules. We
describe the rule extraction and application process as well as the evaluation
of the system. The results for French give us insight information on some
possible improvments of the nature and content of lexical resources adapted for
disambiguation in this framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506050</id><created>2005-06-13</created><authors><author><keyname>Wiesmaier</keyname><forenames>A.</forenames></author><author><keyname>Karatsiolis</keyname><forenames>V.</forenames></author><author><keyname>Lippert</keyname><forenames>M.</forenames></author><author><keyname>Buchmann</keyname><forenames>J.</forenames></author></authors><title>The Workshop - Implementing Well Structured Enterprise Applications</title><categories>cs.SE</categories><comments>7 pages (ieee), 1 figure, accepted for SERP'05</comments><journal-ref>Proceedings of &quot;The 2005 International Conference on Software
  Engineering Research and Practice&quot;; June 2005</journal-ref><abstract>  We specify an abstraction layer to be used between an enterprise application
and the utilized enterprise framework (like J2EE or .NET). This specification
is called the Workshop. It provides an intuitive metaphor supporting the
programmer in designing easy understandable code. We present an implementation
of this specification. It is based upon the J2EE framework and is called the
JWorkshop. As a proof of concept we implement a special certification authority
called the Key Authority based upon the JWorkshop. The mentioned certification
authority runs very successfully in a variety of different real world projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506051</id><created>2005-06-13</created><updated>2005-11-11</updated><authors><author><keyname>Herrmann</keyname><forenames>Heiko</forenames></author><author><keyname>Rueckner</keyname><forenames>Gunnar</forenames></author></authors><title>Comparison of two different implementations of a
  finite-difference-method for first-order pde in mathematica and matlab</title><categories>cs.CE cs.DM</categories><comments>LaTeX, 6 pages, 9 eps-figures, v2: minor additions/corrections</comments><abstract>  In this article two implementations of a symmetric finite difference
algorithm for a first-order partial differential equation are discussed. The
considered partial differential equation discribes the time evolution of the
crack length distribution of microcracks in brittle materia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506052</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506052</id><created>2005-06-13</created><updated>2005-11-22</updated><authors><author><keyname>Sethuraman</keyname><forenames>Vignesh</forenames></author><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author></authors><title>Comments on `Bit Interleaved Coded Modulation'</title><categories>cs.IT math.IT</categories><comments>This is the version after review (shorter, better etc)</comments><abstract>  Caire, Taricco and Biglieri presented a detailed analysis of bit interleaved
coded modulation, a simple and popular technique used to improve system
performance, especially in the context of fading channels. They derived an
upper bound to the probability of error, called the expurgated bound. In this
correspondence, the proof of the expurgated bound is shown to be flawed. A new
upper bound is also derived. It is not known whether the original expurgated
bound is valid for the important special case of square QAM with Gray labeling,
but the new bound is very close to, and slightly tighter than, the original
bound for a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506053</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506053</id><created>2005-06-13</created><authors><author><keyname>Zhang</keyname><forenames>Hongyuan</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author><author><keyname>Zhou</keyname><forenames>Quan</forenames></author><author><keyname>Hughes</keyname><forenames>Brian L.</forenames></author></authors><title>Analysis on Transmit Antenna Selection for Spatial Multiplexing Systems:
  A Geometrical Approach</title><categories>cs.IT math.IT</categories><comments>28 Pages, Submitted IEEE Trans. Info. Theory</comments><abstract>  Recently, the remarkable potential of a multiple-input multiple-output (MIMO)
wireless communication system was unveiled for its ability to provide spatial
diversity or multiplexing gains. For MIMO diversity schemes, it is already
known that. by the optimal antenna selection maximizing the post-processing
signal-to-noise ratio, the diversity order of the full system can be
maintained. On the other hand, the diversity order achieved by antenna
selection in spatial multiplexing systems, especially those exploiting
practical coding and decoding schemes, has not been rigorously analyzed thus
far. In this paper, from a geometric standpoint, we propose a new framework for
theoretically analyzing the diversity order achieved by transmit antenna
selection for separately encoded spatial multiplexing systems with linear and
decision-feedback receivers. We rigorously show that a diversity order of
(Nt-1)(Nr-1) can be achieved for an Nr by Nt SM system when L=2 antennas are
selected from the transmit side; while for L&gt;2 scenarios, we give bounds for
the achievable diversity order and show that the optimal diversity order is at
least (Nt-L+1)(Nr-L+1) . Furthermore, the same geometrical approach can be used
to evaluate the diversity-multiplexing tradeoff curves for the considered
spatial multiplexing systems with transmit antenna selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506054</id><created>2005-06-13</created><authors><author><keyname>Johari</keyname><forenames>Ramesh</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Mannor</keyname><forenames>Shie</forenames><affiliation>McGill University</affiliation></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames><affiliation>MIT</affiliation></author></authors><title>Efficiency Loss in a Network Resource Allocation Game: The Case of
  Elastic Supply</title><categories>cs.GT</categories><comments>Originally Laboratory for Information and Decision Systems (MIT)
  Publication 2605</comments><abstract>  We consider a resource allocation problem where individual users wish to send
data across a network to maximize their utility, and a cost is incurred at each
link that depends on the total rate sent through the link. It is known that as
long as users do not anticipate the effect of their actions on prices, a simple
proportional pricing mechanism can maximize the sum of users' utilities minus
the cost (called aggregate surplus). Continuing previous efforts to quantify
the effects of selfish behavior in network pricing mechanisms, we consider the
possibility that users anticipate the effect of their actions on link prices.
Under the assumption that the links' marginal cost functions are convex, we
establish existence of a Nash equilibrium. We show that the aggregate surplus
at a Nash equilibrium is no worse than a factor of 4*sqrt{2} - 5 times the
optimal aggregate surplus; thus, the efficiency loss when users are selfish is
no more than approximately 34%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506055</id><created>2005-06-13</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author></authors><title>The Complexity of Kings</title><categories>cs.CC cs.DM</categories><report-no>URCS-TR-2005-870</report-no><acm-class>F.1.3; F.2.2</acm-class><abstract>  A king in a directed graph is a node from which each node in the graph can be
reached via paths of length at most two. There is a broad literature on
tournaments (completely oriented digraphs), and it has been known for more than
half a century that all tournaments have at least one king [Lan53]. Recently,
kings have proven useful in theoretical computer science, in particular in the
study of the complexity of the semifeasible sets [HNP98,HT05] and in the study
of the complexity of reachability problems [Tan01,NT02].
  In this paper, we study the complexity of recognizing kings. For each
succinctly specified family of tournaments, the king problem is known to belong
to $\Pi_2^p$ [HOZZ]. We prove that this bound is optimal: We construct a
succinctly specified tournament family whose king problem is
$\Pi_2^p$-complete. It follows easily from our proof approach that the problem
of testing kingship in succinctly specified graphs (which need not be
tournaments) is $\Pi_2^p$-complete. We also obtain $\Pi_2^p$-completeness
results for k-kings in succinctly specified j-partite tournaments, $k,j \geq
2$, and we generalize our main construction to show that $\Pi_2^p$-completeness
holds for testing k-kingship in succinctly specified families of tournaments
for all $k \geq 2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506056</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506056</id><created>2005-06-13</created><updated>2006-03-09</updated><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>Large Alphabets and Incompressibility</title><categories>cs.IT math.IT</categories><acm-class>E.4</acm-class><doi>10.1016/j.ipl.2006.04.008</doi><abstract>  We briefly survey some concepts related to empirical entropy -- normal
numbers, de Bruijn sequences and Markov processes -- and investigate how well
it approximates Kolmogorov complexity. Our results suggest $\ell$th-order
empirical entropy stops being a reasonable complexity metric for almost all
strings of length $m$ over alphabets of size $n$ about when $n^\ell$ surpasses
$m$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506057</id><created>2005-06-14</created><updated>2005-07-20</updated><authors><author><keyname>Victor</keyname><forenames>Kromer</forenames></author></authors><title>About one 3-parameter Model of Testing</title><categories>cs.LG</categories><comments>9 pages; in Russian; Paper with changed content</comments><acm-class>I.2.6; K.3.2</acm-class><abstract>  This article offers a 3-parameter model of testing, with 1) the difference
between the ability level of the examinee and item difficulty; 2) the examinee
discrimination and 3) the item discrimination as model parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506058</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506058</id><created>2005-06-14</created><authors><author><keyname>Bhattad</keyname><forenames>Kapil</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna</forenames></author></authors><title>An MSE Based Ttransfer Chart to Analyze Iterative Decoding Schemes</title><categories>cs.IT math.IT</categories><abstract>  An alternative to extrinsic information transfer (EXIT) charts called mean
squared error (MSE) charts that use a measure related to the MSE instead of
mutual information is proposed. Using the relationship between mutual
information and minimum mean squared error (MMSE), a relationship between the
rate of any code and the area under a plot of MSE versus signal to noise ratio
(SNR) is obtained, when the log likelihood ratios (LLR) can be assumed to be
from a Gaussian channel. Using this result, a theoretical justification is
provided for designing concatenated codes by matching the EXIT charts of the
inner and outer decoders, when the LLRs are Gaussian which is typically assumed
for code design using EXIT charts. Finally, for the special case of AWGN
channel it is shown that any capacity achieving code has an EXIT curve that is
flat. This extends Ashikhmin et als results for erasure channels to the
Gaussian channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506059</id><created>2005-06-14</created><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author></authors><title>Existentially Restricted Quantified Constraint Satisfaction</title><categories>cs.CC cs.LO</categories><abstract>  The quantified constraint satisfaction problem (QCSP) is a powerful framework
for modelling computational problems. The general intractability of the QCSP
has motivated the pursuit of restricted cases that avoid its maximal
complexity. In this paper, we introduce and study a new model for investigating
QCSP complexity in which the types of constraints given by the existentially
quantified variables, is restricted. Our primary technical contribution is the
development and application of a general technology for proving positive
results on parameterizations of the model, of inclusion in the complexity class
coNP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506060</id><created>2005-06-14</created><updated>2005-06-15</updated><authors><author><keyname>Luo</keyname><forenames>Yong</forenames></author></authors><title>Yet another normalisation proof for Martin-Lof's logical
  framework--Terms with correct arities are strongly normalising</title><categories>cs.LO</categories><comments>19 pages</comments><abstract>  In this paper, we prove the strong normalisation for Martin-L\&quot;{o}f's Logical
Framework, and suggest that {}``correct arity'', a condition weaker than
well-typedness, will also guarantee the strong normalisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506061</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506061</id><created>2005-06-14</created><updated>2008-10-07</updated><authors><author><keyname>Gorla</keyname><forenames>Daniele</forenames></author><author><keyname>Hennessy</keyname><forenames>Matthew</forenames></author><author><keyname>Sassone</keyname><forenames>Vladimiro</forenames></author></authors><title>Security Policies as Membranes in Systems for Global Computing</title><categories>cs.PL cs.LO</categories><comments>23 pages; to appear in Logical Methods in Computer Science</comments><acm-class>D.2.4; D.3.1; F.3.2; F.3.3; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 3 (December
  20, 2005) lmcs:1133</journal-ref><doi>10.2168/LMCS-1(3:2)2005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple global computing framework, whose main concern is code
migration. Systems are structured in sites, and each site is divided into two
parts: a computing body, and a membrane, which regulates the interactions
between the computing body and the external environment. More precisely,
membranes are filters which control access to the associated site, and they
also rely on the well-established notion of trust between sites. We develop a
basic theory to express and enforce security policies via membranes. Initially,
these only control the actions incoming agents intend to perform locally. We
then adapt the basic theory to encompass more sophisticated policies, where the
number of actions an agent wants to perform, and also their order, are
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506062</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506062</id><created>2005-06-14</created><updated>2005-07-23</updated><authors><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>A CDMA multiuser detection algorithm based on survey propagation</title><categories>cs.IT math.IT</categories><comments>Abstract for my presentation at Randomness and Computation Joint
  Workshop ``New Horizons in Computing'' and ``Statistical Mechanical Approach
  to Probabilistic Information Processing'' (18-21 July, 2005, Sendai, Japan)</comments><abstract>  A computationally tractable CDMA multiuser detection algorithm is developed
based on survey propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506063</id><created>2005-06-14</created><authors><author><keyname>Staworko</keyname><forenames>Slawomir</forenames></author><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author></authors><title>Priority-Based Conflict Resolution in Inconsistent Relational Databases</title><categories>cs.DB</categories><report-no>UB CSE Technical Report 2005-11</report-no><acm-class>H.2.8</acm-class><abstract>  We study here the impact of priorities on conflict resolution in inconsistent
relational databases. We extend the framework of repairs and consistent query
answers. We propose a set of postulates that an extended framework should
satisfy and consider two instantiations of the framework: (locally preferred)
l-repairs and (globally preferred) g-repairs. We study the relationships
between them and the impact each notion of repair has on the computational
complexity of repair checking and consistent query answers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506064</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506064</id><created>2005-06-15</created><authors><author><keyname>Iwamoto</keyname><forenames>Mitsugu</forenames></author><author><keyname>Yamamoto</keyname><forenames>Hirosuke</forenames></author><author><keyname>Ogawa</keyname><forenames>Hirohisa</forenames></author></authors><title>Optimal multiple assignments based on integer programming in secret
  sharing schemes with general access structures</title><categories>cs.CR cs.IT math.IT</categories><abstract>  It is known that for any general access structure, a secret sharing scheme
(SSS) can be constructed from an (m,m)-threshold scheme by using the so-called
cumulative map or from a (t,m)-threshold SSS by a modified cumulative map.
However, such constructed SSSs are not efficient generally. In this paper, we
propose a new method to construct a SSS from a $(t,m)$-threshold scheme for any
given general access structure. In the proposed method, integer programming is
used to distribute optimally the shares of (t,m)-threshold scheme to each
participant of the general access structure. From the optimality, it can always
attain lower coding rate than the cumulative maps except the cases that they
give the optimal distribution. The same method is also applied to construct
SSSs for incomplete access structures and/or ramp access structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506065</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506065</id><created>2005-06-15</created><authors><author><keyname>Iwamoto</keyname><forenames>Mitsugu</forenames></author><author><keyname>Yamamoto</keyname><forenames>Hirosuke</forenames></author></authors><title>Strongly secure ramp secret sharing schemes for general access structures</title><categories>cs.CR cs.IT math.IT</categories><abstract>  Ramp secret sharing (SS) schemes can be classified into strong ramp SS
schemes and weak ramp SS schemes. The strong ramp SS schemes do not leak out
any part of a secret explicitly even in the case where some information about
the secret leaks from a non-qualified set of shares, and hence, they are more
desirable than weak ramp SS schemes. However, it is not known how to construct
the strong ramp SS schemes in the case of general access structures. In this
paper, it is shown that a strong ramp SS scheme can always be constructed from
a SS scheme with plural secrets for any feasible general access structure. As a
byproduct, it is pointed out that threshold ramp SS schemes based on Shamir's
polynomial interpolation method are {\em not} always strong.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506066</id><created>2005-06-15</created><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author><author><keyname>Lee</keyname><forenames>Dongman</forenames></author></authors><title>Impersonation with the Echo Protocol</title><categories>cs.CR cs.NI</categories><comments>submitted to ACM Workshop on Wireless Security (2005)</comments><abstract>  The Echo protocol tries to do secure location verification using physical
limits imposed by the speeds of light and sound. While the protocol is able to
guarantee that a certain object is within a certain region, it cannot ensure
the authenticity of further messages from the object without using
cryptography. This paper describes an impersonation attack against the protocol
based on this weakness. It also describes a couple of approaches which can be
used to defend against the attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506067</id><created>2005-06-15</created><authors><author><keyname>Amor</keyname><forenames>Juan Jose</forenames></author><author><keyname>Robles</keyname><forenames>Gregorio</forenames></author><author><keyname>Gonzalez-Barahona</keyname><forenames>Jesus</forenames></author></authors><title>Measuring Woody: The Size of Debian 3.0</title><categories>cs.SE</categories><abstract>  Debian is possibly the largest free software distribution, with well over
4,500 source packages in the latest stable release (Debian 3.0) and more than
8,000 source packages in the release currently in preparation. However, we wish
to know what these numbers mean. In this paper, we use David A. Wheeler's
SLOCCount system to determine the number of physical source lines of code
(SLOC) of Debian 3.0 (aka woody). We show that Debian 3.0 includes more than
105,000,000 physical SLOC (almost twice than Red Hat 9, released about 8 months
later), showing that the Debian development model (based on the work of a large
group of voluntary developers spread around the world) is at least as capable
as other development methods (like the more centralized one, based on the work
of employees, used by Red Hat or Microsoft) to manage distributions of this
size.
  It is also shown that if Debian had been developed using traditional
proprietary methods, the COCOMO model estimates that its cost would be close to
$6.1 billion USD to develop Debian 3.0. In addition, we offer both an analysis
of the programming languages used in the distribution (C amounts for about 65%,
C++ for about 12%, Shell for about 8% and LISP is around 4%, with many others
to follow), and the largest packages (The Linux kernel, Mozilla, XFree86, PM3,
etc.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506068</id><created>2005-06-15</created><authors><author><keyname>Marriott</keyname><forenames>Chris</forenames></author><author><keyname>Watrous</keyname><forenames>John</forenames></author></authors><title>Quantum Arthur-Merlin Games</title><categories>cs.CC quant-ph</categories><comments>22 pages</comments><acm-class>F.1.2; F.1.3</acm-class><journal-ref>Computational Complexity, 14(2): 122 - 152, 2005</journal-ref><abstract>  This paper studies quantum Arthur-Merlin games, which are Arthur-Merlin games
in which Arthur and Merlin can perform quantum computations and Merlin can send
Arthur quantum information. As in the classical case, messages from Arthur to
Merlin are restricted to be strings of uniformly generated random bits. It is
proved that for one-message quantum Arthur-Merlin games, which correspond to
the complexity class QMA, completeness and soundness errors can be reduced
exponentially without increasing the length of Merlin's message. Previous
constructions for reducing error required a polynomial increase in the length
of Merlin's message. Applications of this fact include a proof that logarithmic
length quantum certificates yield no increase in power over BQP and a simple
proof that QMA is contained in PP. Other facts that are proved include the
equivalence of three (or more) message quantum Arthur-Merlin games with
ordinary quantum interactive proof systems and some basic properties concerning
two-message quantum Arthur-Merlin games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506069</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506069</id><created>2005-06-16</created><authors><author><keyname>Monasson</keyname><forenames>Remi</forenames><affiliation>LPTENS</affiliation></author></authors><title>A generating function method for the average-case analysis of DPLL</title><categories>cs.CC cond-mat.dis-nn</categories><comments>RANDOM 2005, Berkeley, August 22-24</comments><proxy>ccsd ccsd-00005399</proxy><journal-ref>RANDOM 2005, Berkeley, CA, \'Etats-Unis d'Am\'erique, p.402-413</journal-ref><abstract>  A method to calculate the average size of Davis-Putnam-Loveland-Logemann
(DPLL) search trees for random computational problems is introduced, and
applied to the satisfiability of random CNF formulas (SAT) and the coloring of
random graph (COL) problems. We establish recursion relations for the
generating functions of the average numbers of (variable or color) assignments
at a given height in the search tree, which allow us to derive the asymptotics
of the expected DPLL tree size, 2^{N w + o(N)}, where N is the instance size. w
is calculated as a function of the input distribution parameters (ratio of
clauses per variable for SAT, average vertex degree for COL), and the branching
heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506070</id><created>2005-06-16</created><authors><author><keyname>Chashkov</keyname><forenames>Ph. D. Yuriy A.</forenames></author></authors><title>Data Visualization on Shared Usage Multi-Screen Environment</title><categories>cs.MM</categories><comments>4 pages, 1 figure</comments><acm-class>D.1.1; H.5.1</acm-class><abstract>  The modern multimedia technologies based on the whole palette of hardware and
software facilities of real-time high-speed information processing, in a
combination with effective facilities of the remote access to information
resources, allow us to visualize diverse types of information. Data
visualization facilities &amp;#8211; is the face of the Automated Control System on
whom often judge about their efficiency. They take a special place, providing
visualization of the diverse information necessary for decision-making by a
final control link - the person allocated by certain powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506071</id><created>2005-06-16</created><updated>2005-06-21</updated><authors><author><keyname>Reznykov</keyname><forenames>Yu.</forenames></author></authors><title>Signal transmission on lossy lines as a dissipative quantum state
  propagation</title><categories>cs.NI</categories><comments>6 pages, revtex4</comments><report-no>BTU LTP-05-06</report-no><acm-class>B.4.3</acm-class><abstract>  The transmission of electric signals on a coupled line with distributed
RLC-parameters is considered as a propagation of a dissipative quasi particle.
A calculation technique is developed, alternative to the one, accepted for
lumped lines. The relativistic wave equation for the transient response is
deduced following the common Ohm-low-type considerations. The exact expressions
for the Green function, for information transfer velocity and for time delay
are obtained on this base. The fundamental restrictions on the measurement
accuracy of the time delay are pointed out. The obtained results are naturally
generalized for the multilevel networks of the arbitrary dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506072</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506072</id><created>2005-06-16</created><authors><author><keyname>Jiang</keyname><forenames>Jing</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Performance Analysis of Algebraic Soft Decoding of Reed-Solomon Codes
  over Binary Symmetric and Erasure Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><abstract>  In this paper, we characterize the decoding region of algebraic soft decoding
(ASD) of Reed-Solomon (RS) codes over erasure channels and binary symmetric
channel (BSC). Optimal multiplicity assignment strategies (MAS) are
investigated and tight bounds are derived to show the ASD can significantly
outperform conventional Berlekamp Massey (BM) decoding over these channels for
a wide code rate range. The analysis technique can also be extended to other
channel models, e.g., RS coded modulation over erasure channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506073</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506073</id><created>2005-06-16</created><updated>2006-03-30</updated><authors><author><keyname>Jiang</keyname><forenames>Jing</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Iterative Soft Input Soft Output Decoding of Reed-Solomon Codes by
  Adapting the Parity Check Matrix</title><categories>cs.IT math.IT</categories><comments>10 pages, 10 figures, final version accepted by IEEE Trans. on
  Information Theory</comments><abstract>  An iterative algorithm is presented for soft-input-soft-output (SISO)
decoding of Reed-Solomon (RS) codes. The proposed iterative algorithm uses the
sum product algorithm (SPA) in conjunction with a binary parity check matrix of
the RS code. The novelty is in reducing a submatrix of the binary parity check
matrix that corresponds to less reliable bits to a sparse nature before the SPA
is applied at each iteration. The proposed algorithm can be geometrically
interpreted as a two-stage gradient descent with an adaptive potential
function. This adaptive procedure is crucial to the convergence behavior of the
gradient descent algorithm and, therefore, significantly improves the
performance. Simulation results show that the proposed decoding algorithm and
its variations provide significant gain over hard decision decoding (HDD) and
compare favorably with other popular soft decision decoding methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506074</id><created>2005-06-17</created><updated>2005-06-21</updated><authors><author><keyname>Liberatore</keyname><forenames>Paolo</forenames></author></authors><title>Redundancy in Logic II: 2CNF and Horn Propositional Formulae</title><categories>cs.AI cs.LO</categories><comments>Corrected figures on Theorem 10; added and modified some references</comments><abstract>  We report complexity results about redundancy of formulae in 2CNF form. We
first consider the problem of checking redundancy and show some algorithms that
are slightly better than the trivial one. We then analyze problems related to
finding irredundant equivalent subsets (I.E.S.) of a given set. The concept of
cyclicity proved to be relevant to the complexity of these problems. Some
results about Horn formulae are also shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506075</id><created>2005-06-17</created><authors><author><keyname>Pang</keyname><forenames>Bo</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author></authors><title>Seeing stars: Exploiting class relationships for sentiment
  categorization with respect to rating scales</title><categories>cs.CL cs.LG</categories><comments>To appear, Proceedings of ACL 2005</comments><acm-class>I.2.7; I.2.6</acm-class><abstract>  We address the rating-inference problem, wherein rather than simply decide
whether a review is &quot;thumbs up&quot; or &quot;thumbs down&quot;, as in previous sentiment
analysis work, one must determine an author's evaluation with respect to a
multi-point scale (e.g., one to five &quot;stars&quot;). This task represents an
interesting twist on standard multi-class text categorization because there are
several different degrees of similarity between class labels; for example,
&quot;three stars&quot; is intuitively closer to &quot;four stars&quot; than to &quot;one star&quot;. We
first evaluate human performance at the task. Then, we apply a meta-algorithm,
based on a metric labeling formulation of the problem, that alters a given
n-ary classifier's output in an explicit attempt to ensure that similar items
receive similar labels. We show that the meta-algorithm can provide significant
improvements over both multi-class and regression versions of SVMs when we
employ a novel similarity measure appropriate to the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506076</id><created>2005-06-18</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>Alternative security architecture for IP Telephony based on digital
  watermarking</title><categories>cs.CR cs.MM</categories><comments>10 pages, 5 figures</comments><acm-class>C.2.0; K.4.6</acm-class><journal-ref>Lecture Notes in Computer Science 4166, pp. 170 - 181, Springer,
  Heidelberg 2006. ISBN 978-3-540-45762-6</journal-ref><abstract>  Problems with securing IP Telephony systems, insufficient standardization and
lack of security mechanisms emerged the need for new approaches and solutions.
In this paper a new, alternative security architecture for voice-systems is
presented. It is based on digital watermarking: a new, flexible and powerful
technology that is increasingly gaining more and more attention. Besides known
applications e.g. to solve copyright protection problems, we propose to use
digital watermarking to secure not only transmitted audio but also signaling
protocol that IP Telephony is based on.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506077</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506077</id><created>2005-06-20</created><updated>2005-07-26</updated><authors><author><keyname>Sayee</keyname><forenames>KCV Kalyanarama Sesha</forenames></author><author><keyname>Mukherji</keyname><forenames>Utpal</forenames></author></authors><title>Stability of Scheduled Multi-access Communication over Quasi-static Flat
  Fading Channels with Random Coding and Independent Decoding</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, To be presented at 2005 IEEE International
  Symposium on Information Theory, corrected version</comments><abstract>  The stability of scheduled multiaccess communication with random coding and
independent decoding of messages is investigated. The number of messages that
may be scheduled for simultaneous transmission is limited to a given maximum
value, and the channels from transmitters to receiver are quasi-static, flat,
and have independent fades. Requests for message transmissions are assumed to
arrive according to an i.i.d. arrival process. Then, we show the following: (1)
in the limit of large message alphabet size, the stability region has an
interference limited information-theoretic capacity interpretation, (2)
state-independent scheduling policies achieve this asymptotic stability region,
and (3) in the asymptotic limit corresponding to immediate access, the
stability region for non-idling scheduling policies is shown to be identical
irrespective of received signal powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506078</id><created>2005-06-20</created><authors><author><keyname>Dominguez</keyname><forenames>David</forenames></author><author><keyname>Koroutchev</keyname><forenames>Kostadin</forenames></author><author><keyname>Serrano</keyname><forenames>Eduardo</forenames></author><author><keyname>Rodriguez</keyname><forenames>Francisco B.</forenames></author></authors><title>Dynamical Neural Network: Information and Topology</title><categories>cs.IR cs.NE</categories><comments>10pg, 5fig</comments><abstract>  A neural network works as an associative memory device if it has large
storage capacity and the quality of the retrieval is good enough. The learning
and attractor abilities of the network both can be measured by the mutual
information (MI), between patterns and retrieval states. This paper deals with
a search for an optimal topology, of a Hebb network, in the sense of the
maximal MI. We use small-world topology. The connectivity $\gamma$ ranges from
an extremely diluted to the fully connected network; the randomness $\omega$
ranges from purely local to completely random neighbors. It is found that,
while stability implies an optimal $MI(\gamma,\omega)$ at
$\gamma_{opt}(\omega)\to 0$, for the dynamics, the optimal topology holds at
certain $\gamma_{opt}&gt;0$ whenever $0\leq\omega&lt;0.3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506079</id><created>2005-06-20</created><updated>2005-10-25</updated><authors><author><keyname>Lago</keyname><forenames>U. Dal</forenames></author><author><keyname>Hofmann</keyname><forenames>M.</forenames></author></authors><title>Quantitative Models and Implicit Complexity</title><categories>cs.LO cs.CC</categories><comments>29 pages</comments><acm-class>F.4.1</acm-class><abstract>  We give new proofs of soundness (all representable functions on base types
lies in certain complexity classes) for Elementary Affine Logic, LFPL (a
language for polytime computation close to realistic functional programming
introduced by one of us), Light Affine Logic and Soft Affine Logic. The proofs
are based on a common semantical framework which is merely instantiated in four
different ways. The framework consists of an innovative modification of
realizability which allows us to use resource-bounded computations as realisers
as opposed to including all Turing computable functions as is usually the case
in realizability constructions. For example, all realisers in the model for
LFPL are polynomially bounded computations whence soundness holds by
construction of the model. The work then lies in being able to interpret all
the required constructs in the model. While being the first entirely semantical
proof of polytime soundness for light logi cs, our proof also provides a
notable simplification of the original already semantical proof of polytime
soundness for LFPL. A new result made possible by the semantic framework is the
addition of polymorphism and a modality to LFPL thus allowing for an internal
definition of inductive datatypes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506080</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506080</id><created>2005-06-20</created><updated>2006-10-04</updated><authors><author><keyname>Lago</keyname><forenames>U. Dal</forenames></author></authors><title>The Geometry of Linear Higher-Order Recursion</title><categories>cs.LO cs.CC</categories><comments>23 pages, extended version of a paper appearing in LICS 2005
  proceedings</comments><acm-class>F.4.1</acm-class><abstract>  Linearity and ramification constraints have been widely used to weaken
higher-order (primitive) recursion in such a way that the class of
representable functions equals the class of polytime functions. We show that
fine-tuning these two constraints leads to different expressive strengths, some
of them lying well beyond polynomial time. This is done by introducing a new
semantics, called algebraic context semantics. The framework stems from
Gonthier's original work and turns out to be a versatile and powerful tool for
the quantitative analysis of normalization in presence of constants and
higher-order recursion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506081</id><created>2005-06-20</created><updated>2005-06-20</updated><authors><author><keyname>Midrijanis</keyname><forenames>Gatis</forenames></author></authors><title>Three lines proof of the lower bound for the matrix rigidity</title><categories>cs.CC</categories><comments>4 pages</comments><abstract>  The rigidity of a matrix describes the minimal number of entries one has to
change to reduce matrix's rank to r. We give very simple combinatorial proof of
the lower bound for the rigidity of Sylvester (special case of Hadamard) matrix
that matches the best known result by de Wolf(2005) for Hadamard matrices
proved by quantum information theoretical arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506082</id><created>2005-06-20</created><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>Open Questions in the Theory of Semifeasible Computation</title><categories>cs.CC</categories><report-no>URCS-TR-2005-872</report-no><acm-class>F.1.3</acm-class><abstract>  The study of semifeasible algorithms was initiated by Selman's work a quarter
of century ago [Sel79,Sel81,Sel82]. Informally put, this research stream
studies the power of those sets L for which there is a deterministic (or in
some cases, the function may belong to one of various nondeterministic function
classes) polynomial-time function f such that when at least one of x and y
belongs to L, then f(x,y) \in L \cap \{x,y\}. The intuition here is that it is
saying: ``Regarding membership in L, if you put a gun to my head and forced me
to bet on one of x or y as belonging to L, my money would be on f(x,y).''
  In this article, we present a number of open problems from the theory of
semifeasible algorithms. For each we present its background and review what
partial results, if any, are known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506083</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506083</id><created>2005-06-21</created><authors><author><keyname>Measson</keyname><forenames>Cyril</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>Maxwell Construction: The Hidden Bridge between Iterative and Maximum a
  Posteriori Decoding</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>29 pages, 77 ps files</comments><abstract>  There is a fundamental relationship between belief propagation and maximum a
posteriori decoding. A decoding algorithm, which we call the Maxwell decoder,
is introduced and provides a constructive description of this relationship.
Both, the algorithm itself and the analysis of the new decoder are reminiscent
of the Maxwell construction in thermodynamics. This paper investigates in
detail the case of transmission over the binary erasure channel, while the
extension to general binary memoryless channels is discussed in a companion
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506084</id><created>2005-06-22</created><authors><author><keyname>Holt</keyname><forenames>Jason E.</forenames><affiliation>BYU</affiliation></author></authors><title>The One Page Model Checker</title><categories>cs.LO</categories><comments>12 pages</comments><acm-class>F.3.1</acm-class><abstract>  We show how standard IPC mechanisms can be used with the fork() system call
to perform explicit state model checking on all interleavings of a
multithreaded application. We specifically show how to check for deadlock and
race conditions in programs with two threads. Our techniques are easy to apply
to other languages, and require only the most rudimentary parsing of the target
language. Our fundamental system fits in one page of C code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506085</id><created>2005-06-22</created><authors><author><keyname>Holt</keyname><forenames>Jason E.</forenames><affiliation>BYU</affiliation></author></authors><title>On the Job Training</title><categories>cs.LG</categories><comments>8 pages, submitted to NIPS 2005</comments><acm-class>K.3.2</acm-class><abstract>  We propose a new framework for building and evaluating machine learning
algorithms. We argue that many real-world problems require an agent which must
quickly learn to respond to demands, yet can continue to perform and respond to
new training throughout its useful life. We give a framework for how such
agents can be built, describe several metrics for evaluating them, and show
that subtle changes in system construction can significantly affect agent
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506086</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506086</id><created>2005-06-22</created><authors><author><keyname>Jayaweera</keyname><forenames>Sudharman K.</forenames></author></authors><title>Large System Decentralized Detection Performance Under Communication
  Constraints</title><categories>cs.IT math.IT</categories><comments>3 pages, 2 figures, to be published in IEEE Communication Letters</comments><abstract>  The problem of decentralized detection in a sensor network subjected to a
total average power constraint and all nodes sharing a common bandwidth is
investigated. The bandwidth constraint is taken into account by assuming
non-orthogonal communication between sensors and the data fusion center via
direct-sequence code-division multiple-access (DS-CDMA). In the case of large
sensor systems and random spreading, the asymptotic decentralized detection
performance is derived assuming independent and identically distributed (iid)
sensor observations via random matrix theory. The results show that, even under
both power and bandwidth constraints, it is better to combine many not-so-good
local decisions rather than relying on one (or a few) very-good local
decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506087</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506087</id><created>2005-06-24</created><updated>2006-06-12</updated><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Kurosawa</keyname><forenames>Kaoru</forenames></author><author><keyname>Itoh</keyname><forenames>Toshiya</forenames></author><author><keyname>Konno</keyname><forenames>Toshimitsu</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author></authors><title>Primal-dual distance bounds of linear codes with application to
  cryptography</title><categories>cs.IT cs.CR math.IT</categories><comments>6 pages, using IEEEtran.cls. To appear in IEEE Trans. Inform. Theory,
  Sept. 2006. Two authors were added in the revised version</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 52, no. 9, pp. 4251-4256, Sept.
  2006</journal-ref><doi>10.1109/TIT.2006.880050</doi><abstract>  Let $N(d,d^\perp)$ denote the minimum length $n$ of a linear code $C$ with
$d$ and $d^{\bot}$, where $d$ is the minimum Hamming distance of $C$ and
$d^{\bot}$ is the minimum Hamming distance of $C^{\bot}$. In this paper, we
show a lower bound and an upper bound on $N(d,d^\perp)$. Further, for small
values of $d$ and $d^\perp$, we determine $N(d,d^\perp)$ and give a generator
matrix of the optimum linear code. This problem is directly related to the
design method of cryptographic Boolean functions suggested by Kurosawa et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506088</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506088</id><created>2005-06-24</created><updated>2007-01-11</updated><authors><author><keyname>Rioul</keyname><forenames>Olivier</forenames></author></authors><title>An Alternative to Huffman's Algorithm for Constructing Variable-Length
  Codes</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506089</id><created>2005-06-24</created><authors><author><keyname>McGuire</keyname><forenames>Patrick C.</forenames></author><author><keyname>Gomez-Elvira</keyname><forenames>Javier</forenames></author><author><keyname>Rodriguez-Manfredi</keyname><forenames>Jose Antonio</forenames></author><author><keyname>Sebastian-Martinez</keyname><forenames>Eduardo</forenames></author><author><keyname>Ormo</keyname><forenames>Jens</forenames></author><author><keyname>Diaz-Martinez</keyname><forenames>Enrique</forenames></author><author><keyname>Oesker</keyname><forenames>Markus</forenames></author><author><keyname>Haschke</keyname><forenames>Robert</forenames></author><author><keyname>Ontrup</keyname><forenames>Joerg</forenames></author><author><keyname>Ritter</keyname><forenames>Helge</forenames></author></authors><title>Field geology with a wearable computer: 1st results of the Cyborg
  Astrobiologist System</title><categories>cs.CV astro-ph cs.AI cs.CE cs.HC cs.RO</categories><comments>accepted by ICINCO 2005, 2nd International Conference on
  Informatics in Control, Automation and Robotics, 14-17 September 2005,
  Barcelona, Spain. 9 pages, 7 figures</comments><journal-ref>&quot;Proceedings of the &lt;a
  href=&quot;http://www.icinco.org&quot;&gt;ICINCO&lt;/a&gt;'2005 (International Conference on
  Informatics in Control, Automation and Robotics)&quot;, September 14-17,
  Barcelona, Spain, vol. 3, pp. 283-291 (2005).</journal-ref><abstract>  We present results from the first geological field tests of the `Cyborg
Astrobiologist', which is a wearable computer and video camcorder system that
we are using to test and train a computer-vision system towards having some of
the autonomous decision-making capabilities of a field-geologist. The Cyborg
Astrobiologist platform has thus far been used for testing and development of
these algorithms and systems: robotic acquisition of quasi-mosaics of images,
real-time image segmentation, and real-time determination of interesting points
in the image mosaics. This work is more of a test of the whole system, rather
than of any one part of the system. However, beyond the concept of the system
itself, the uncommon map (despite its simplicity) is the main innovative part
of the system. The uncommon map helps to determine interest-points in a
context-free manner. Overall, the hardware and software systems function
reliably, and the computer-vision algorithms are adequate for the first field
tests. In addition to the proof-of-concept aspect of these field tests, the
main result of these field tests is the enumeration of those issues that we can
improve in the future, including: dealing with structural shadow and
microtexture, and also, controlling the camera's zoom lens in an intelligent
manner. Nonetheless, despite these and other technical inadequacies, this
Cyborg Astrobiologist system, consisting of a camera-equipped wearable-computer
and its computer-vision algorithms, has demonstrated its ability of finding
genuinely interesting points in real-time in the geological scenery, and then
gathering more information about these interest points in an automated manner.
We use these capabilities for autonomous guidance towards geological
points-of-interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506090</id><created>2005-06-24</created><authors><author><keyname>Riege</keyname><forenames>Tobias</forenames></author><author><keyname>Rothe</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>An Exact 2.9416^n Algorithm for the Three Domatic Number Problem</title><categories>cs.CC</categories><comments>20 pages, 1 figure</comments><acm-class>F.2.2</acm-class><abstract>  The three domatic number problem asks whether a given undirected graph can be
partitioned into at least three dominating sets, i.e., sets whose closed
neighborhood equals the vertex set of the graph. Since this problem is
NP-complete, no polynomial-time algorithm is known for it. The naive
deterministic algorithm for this problem runs in time 3^n, up to polynomial
factors. In this paper, we design an exact deterministic algorithm for this
problem running in time 2.9416^n. Thus, our algorithm can handle problem
instances of larger size than the naive algorithm in the same amount of time.
We also present another deterministic and a randomized algorithm for this
problem that both have an even better performance for graphs with small maximum
degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506091</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506091</id><created>2005-06-24</created><authors><author><keyname>Takeshita</keyname><forenames>Oscar Y.</forenames></author></authors><title>A New Construction for LDPC Codes using Permutation Polynomials over
  Integer Rings</title><categories>cs.IT math.IT</categories><comments>12 pages, 4 figures, submitted to IEEE Transactions on Information
  Theory</comments><abstract>  A new construction is proposed for low density parity check (LDPC) codes
using quadratic permutation polynomials over finite integer rings. The
associated graphs for the new codes have both algebraic and pseudo-random
nature, and the new codes are quasi-cyclic. Graph isomorphisms and
automorphisms are identified and used in an efficient search for good codes.
Graphs with girth as large as 12 were found. Upper bounds on the minimum
Hamming distance are found both analytically and algorithmically. The bounds
indicate that the minimum distance grows with block length. Near-codewords are
one of the causes for error floors in LDPC codes; the new construction provides
a good framework for studying near-codewords in LDPC codes. Nine example codes
are given, and computer simulation results show the excellent error performance
of these codes. Finally, connections are made between this new LDPC
construction and turbo codes using interleavers generated by quadratic
permutation polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506092</id><created>2005-06-24</created><authors><author><keyname>Lux</keyname><forenames>Thomas</forenames></author></authors><title>Emergent Statistical Wealth Distributions in Simple Monetary Exchange
  Models: A Critical Review</title><categories>cs.MA</categories><abstract>  This paper reviews recent attempts at modelling inequality of wealth as an
emergent phenomenon of interacting-agent processes. We point out that recent
models of wealth condensation which draw their inspiration from molecular
dynamics have, in fact, reinvented a process introduced quite some time ago by
Angle (1986) in the sociological literature. We emphasize some problematic
aspects of simple wealth exchange models and contrast them with a monetary
model based on economic principles of market mediated exchange. The paper also
reports new results on the influence of market power on the wealth distribution
in statistical equilibrium. As it turns out, inequality increases but market
power alone is not sufficient for changing the exponential tails of simple
exchange models into Pareto tails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506093</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506093</id><created>2005-06-24</created><updated>2005-11-01</updated><authors><author><keyname>Takeshita</keyname><forenames>Oscar Y.</forenames></author></authors><title>On Maximum Contention-Free Interleavers and Permutation Polynomials over
  Integer Rings</title><categories>cs.IT math.IT</categories><comments>13 pages, 2 figures, submitted as a correspondence to the IEEE
  Transactions on Information Theory, revised version</comments><abstract>  An interleaver is a critical component for the channel coding performance of
turbo codes. Algebraic constructions are of particular interest because they
admit analytical designs and simple, practical hardware implementation.
Contention-free interleavers have been recently shown to be suitable for
parallel decoding of turbo codes. In this correspondence, it is shown that
permutation polynomials generate maximum contention-free interleavers, i.e.,
every factor of the interleaver length becomes a possible degree of parallel
processing of the decoder. Further, it is shown by computer simulations that
turbo codes using these interleavers perform very well for the 3rd Generation
Partnership Project (3GPP) standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506094</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506094</id><created>2005-06-26</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Astola</keyname><forenames>Jaakko</forenames></author></authors><title>Universal Codes as a Basis for Nonparametric Testing of Serial
  Independence for Time Series</title><categories>cs.IT math.IT</categories><comments>accepted for ISIT'05</comments><abstract>  We consider a stationary and ergodic source $p$ generated symbols $x_1 ...
x_t$ from some finite set $A$ and a null hypothesis $H_0$ that $p$ is Markovian
source with memory (or connectivity) not larger than $m, (m &gt;= 0).$ The
alternative hypothesis $H_1$ is that the sequence is generated by a stationary
and ergodic source, which differs from the source under $H_0$. In particular,
if $m= 0$ we have the null hypothesis $H_0$ that the sequence is generated by
Bernoully source (or the hypothesis that $x_1 ...x_t$ are independent.) Some
new tests which are based on universal codes and universal predictors, are
suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506095</id><created>2005-06-27</created><authors><author><keyname>Shen</keyname><forenames>Y. D.</forenames></author><author><keyname>Yang</keyname><forenames>Q.</forenames></author><author><keyname>You</keyname><forenames>J. H.</forenames></author><author><keyname>Yuan</keyname><forenames>L. Y.</forenames></author></authors><title>Deriving a Stationary Dynamic Bayesian Network from a Logic Program with
  Recursive Loops</title><categories>cs.AI cs.LG cs.LO</categories><comments>29 pages</comments><abstract>  Recursive loops in a logic program present a challenging problem to the PLP
framework. On the one hand, they loop forever so that the PLP backward-chaining
inferences would never stop. On the other hand, they generate cyclic
influences, which are disallowed in Bayesian networks. Therefore, in existing
PLP approaches logic programs with recursive loops are considered to be
problematic and thus are excluded. In this paper, we propose an approach that
makes use of recursive loops to build a stationary dynamic Bayesian network.
Our work stems from an observation that recursive loops in a logic program
imply a time sequence and thus can be used to model a stationary dynamic
Bayesian network without using explicit time parameters. We introduce a
Bayesian knowledge base with logic clauses of the form $A \leftarrow
A_1,...,A_l, true, Context, Types$, which naturally represents the knowledge
that the $A_i$s have direct influences on $A$ in the context $Context$ under
the type constraints $Types$. We then use the well-founded model of a logic
program to define the direct influence relation and apply SLG-resolution to
compute the space of random variables together with their parental connections.
We introduce a novel notion of influence clauses, based on which a declarative
semantics for a Bayesian knowledge base is established and algorithms for
building a two-slice dynamic Bayesian network from a logic program are
developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506096</id><created>2005-06-27</created><authors><author><keyname>Baudru</keyname><forenames>Nicolas</forenames><affiliation>LIF</affiliation></author><author><keyname>Morin</keyname><forenames>R&#xe9;mi</forenames><affiliation>LIF</affiliation></author></authors><title>Polynomial Synthesis of Asynchronous Automata</title><categories>cs.CC cs.LO</categories><comments>The MOdelling and VErification (MOVE) team</comments><proxy>ccsd ccsd-00005587</proxy><abstract>  Zielonka's theorem shows that each regular set of Mazurkiewicz traces can be
implemented as a system of synchronized processes with a distributed control
structure called asynchronous automaton. This paper gives a polynomial
algorithm for the synthesis of a non-deterministic asynchronous automaton from
a regular Mazurkiewicz trace language. This new construction is based on an
unfolding approach that improves the complexity of Zielonka's and Pighizzini's
techniques in terms of the number of states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506097</id><created>2005-06-27</created><authors><author><keyname>Thibault</keyname><forenames>Samuel</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>A Flexible Thread Scheduler for Hierarchical Multiprocessor Machines</title><categories>cs.DC</categories><proxy>ccsd inria-00000138</proxy><abstract>  With the current trend of multiprocessor machines towards more and more
hierarchical architectures, exploiting the full computational power requires
careful distribution of execution threads and data so as to limit expensive
remote memory accesses. Existing multi-threaded libraries provide only limited
facilities to let applications express distribution indications, so that
programmers end up with explicitly distributing tasks according to the
underlying architecture, which is difficult and not portable. In this article,
we present: (1) a model for dynamically expressing the structure of the
computation; (2) a scheduler interpreting this model so as to make judicious
hierarchical distribution decisions; (3) an implementation within the Marcel
user-level thread library. We experimented our proposal on a scientific
application running on a ccNUMA Bull NovaScale with 16 Intel Itanium II
processors; results show a 30% gain compared to a classical scheduler, and are
similar to what a handmade scheduler achieves in a non-portable way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506098</id><created>2005-06-27</created><updated>2007-04-02</updated><authors><author><keyname>Berenbrink</keyname><forenames>Petra</forenames></author><author><keyname>Friedetzky</keyname><forenames>Tom</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Goldberg</keyname><forenames>Paul</forenames></author><author><keyname>Hu</keyname><forenames>Zengjian</forenames></author><author><keyname>Martin</keyname><forenames>Russell</forenames></author></authors><title>Distributed Selfish Load Balancing</title><categories>cs.GT math.OC</categories><abstract>  Suppose that a set of $m$ tasks are to be shared as equally as possible
amongst a set of $n$ resources. A game-theoretic mechanism to find a suitable
allocation is to associate each task with a ``selfish agent'', and require each
agent to select a resource, with the cost of a resource being the number of
agents to select it. Agents would then be expected to migrate from overloaded
to underloaded resources, until the allocation becomes balanced.
  Recent work has studied the question of how this can take place within a
distributed setting in which agents migrate selfishly without any centralized
control. In this paper we discuss a natural protocol for the agents which
combines the following desirable features: It can be implemented in a strongly
distributed setting, uses no central control, and has good convergence
properties. For $m\gg n$, the system becomes approximately balanced (an
$\epsilon$-Nash equilibrium) in expected time $O(\log\log m)$. We show using a
martingale technique that the process converges to a perfectly balanced
allocation in expected time $O(\log\log m+n^4)$. We also give a lower bound of
$\Omega(\max\{\log\log m,n\})$ for the convergence time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506099</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506099</id><created>2005-06-28</created><authors><author><keyname>Shavitt</keyname><forenames>Yuval</forenames></author><author><keyname>Shir</keyname><forenames>Eran</forenames></author></authors><title>DIMES: Let the Internet Measure Itself</title><categories>cs.NI</categories><comments>10 pages, 12 figures</comments><abstract>  Today's Internet maps, which are all collected from a small number of vantage
points, are falling short of being accurate. We suggest here a paradigm shift
for this task. DIMES is a distributed measurement infrastructure for the
Internet that is based on the deployment of thousands of light weight
measurement agents around the globe.
  We describe the rationale behind DIMES deployment, discuss its design
trade-offs and algorithmic challenges, and analyze the structure of the
Internet as it seen with DIMES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506100</id><created>2005-06-29</created><authors><author><keyname>Sima</keyname><forenames>Jiri</forenames></author><author><keyname>Schaeffer</keyname><forenames>Satu Elisa</forenames></author></authors><title>On the NP-Completeness of Some Graph Cluster Measures</title><categories>cs.CC</categories><comments>9 pages, no figures</comments><abstract>  Graph clustering is the problem of identifying sparsely connected dense
subgraphs (clusters) in a given graph. Proposed clustering algorithms usually
optimize various fitness functions that measure the quality of a cluster within
the graph. Examples of such cluster measures include the conductance, the local
and relative densities, and single cluster editing. We prove that the decision
problems associated with the optimization tasks of finding the clusters that
are optimal with respect to these fitness measures are NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506101</id><created>2005-06-29</created><authors><author><keyname>Haffner</keyname><forenames>Patrick</forenames></author><author><keyname>Phillips</keyname><forenames>Steven</forenames></author><author><keyname>Schapire</keyname><forenames>Rob</forenames></author></authors><title>Efficient Multiclass Implementations of L1-Regularized Maximum Entropy</title><categories>cs.LG cs.CL</categories><comments>13 pages, describes new conditional maxent algorithm, to be submitted</comments><abstract>  This paper discusses the application of L1-regularized maximum entropy
modeling or SL1-Max [9] to multiclass categorization problems. A new
modification to the SL1-Max fast sequential learning algorithm is proposed to
handle conditional distributions. Furthermore, unlike most previous studies,
the present research goes beyond a single type of conditional distribution. It
describes and compares a variety of modeling assumptions about the class
distribution (independent or exclusive) and various types of joint or
conditional distributions. It results in a new methodology for combining binary
regularized classifiers to achieve multiclass categorization. In this context,
Maximum Entropy can be considered as a generic and efficient regularized
classification tool that matches or outperforms the state-of-the art
represented by AdaBoost and SVMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506102</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506102</id><created>2005-06-29</created><updated>2005-07-25</updated><authors><author><keyname>Little</keyname><forenames>John</forenames></author><author><keyname>Schwarz</keyname><forenames>Ryan</forenames></author></authors><title>On $m$-dimensional toric codes</title><categories>cs.IT math.AC math.AG math.IT</categories><comments>17 pages, 4 figures; typos corrected</comments><abstract>  Toric codes are a class of $m$-dimensional cyclic codes introduced recently
by J. Hansen. They may be defined as evaluation codes obtained from monomials
corresponding to integer lattice points in an integral convex polytope $P
\subseteq \R^m$. As such, they are in a sense a natural extension of
Reed-Solomon codes. Several authors have used intersection theory on toric
surfaces to derive bounds on the minimum distance of some toric codes with $m =
2$. In this paper, we will provide a more elementary approach that applies
equally well to many toric codes for all $m \ge 2$. Our methods are based on a
sort of multivariate generalization of Vandermonde determinants that has also
been used in the study of multivariate polynomial interpolation. We use these
Vandermonde determinants to determine the minimum distance of toric codes from
rectangular polytopes and simplices. We also prove a general result showing
that if there is a unimodular integer affine transformation taking one polytope
$P_1$ to a second polytope $P_2$, then the corresponding toric codes are
monomially equivalent (hence have the same parameters). We use this to begin a
classification of two-dimensional toric codes with small dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506103</id><created>2005-06-29</created><authors><author><keyname>Zwierko</keyname><forenames>Aneta</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>Security of mobile agents: a new concept of the integrity protection</title><categories>cs.CR</categories><comments>11 pages, 2 figures</comments><abstract>  The recent developments in the mobile technology (mobile phones, middleware)
created a need for new methods of protecting the code transmitted through the
network. The proposed mechanisms not only secure the compiled program, but also
the data, that can be gathered during its &quot;journey&quot;. The oldest and the
simplest methods are more concentrated on integrity of the code itself and on
the detection of unauthorized manipulation. Other, more advanced proposals
protect not only the code but also the execution state and the collected data.
The paper is divided into two parts. The first one is mostly devoted to
different methods of securing the code and protecting its integrity; starting
from watermarking and fingerprinting, up to methods designed specially for
mobile agent systems: encrypted function, cryptographic traces, time limited
black-box security, chained-MAC protocol, publicly-verifiable chained digital
signatures The second part presents new concept for providing mobile agents
with integrity protection, based on a zero-knowledge proof system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506104</id><created>2005-06-29</created><authors><author><keyname>Lonc</keyname><forenames>Z.</forenames></author><author><keyname>Truszczynski</keyname><forenames>M.</forenames></author></authors><title>Computing minimal models, stable models and answer sets</title><categories>cs.LO cs.DS</categories><comments>55 pages, 1 figure. To appear in Theory and Practice of Logic
  Programming (TPLP)</comments><acm-class>D.1.6</acm-class><abstract>  We propose and study algorithms to compute minimal models, stable models and
answer sets of t-CNF theories, and normal and disjunctive t-programs. We are
especially interested in algorithms with non-trivial worst-case performance
bounds. The bulk of the paper is concerned with the classes of 2- and 3-CNF
theories, and normal and disjunctive 2- and 3-programs, for which we obtain
significantly stronger results than those implied by our general
considerations. We show that one can find all minimal models of 2-CNF theories
and all answer sets of disjunctive 2-programs in time O(m 1.4422..^n). Our main
results concern computing stable models of normal 3-programs, minimal models of
3-CNF theories and answer sets of disjunctive 3-programs. We design algorithms
that run in time O(m 1.6701..^n), in the case of the first problem, and in time
O(mn^2 2.2782..^n), in the case of the latter two. All these bounds improve by
exponential factors the best algorithms known previously. We also obtain
closely related upper bounds on the number of minimal models, stable models and
answer sets a t-CNF theory, a normal t-program or a disjunctive t-program may
have.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0506105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0506105</id><created>2005-06-29</created><authors><author><keyname>Wang</keyname><forenames>Ren-Chiun</forenames></author><author><keyname>Yang</keyname><forenames>Chou-Chen</forenames></author><author><keyname>Mo</keyname><forenames>Kun-Ru</forenames></author></authors><title>A protected password change protocol</title><categories>cs.CR</categories><abstract>  Some protected password change protocols were proposed. However, the previous
protocols were easily vulnerable to several attacks such as denial of service,
password guessing, stolen-verifier and impersonation atacks etc. Recently,
Chang et al. proposed a simple authenticated key agreement and protected
password change protocol for enhancing the security and efficiency. In this
paper, authors shall show that password guessing, denial of service and
known-key attacks can work in their password change protocol. At the same time,
authors shall propose a new password change protocol to withstand all the
threats of security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507001</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507001</id><created>2005-06-30</created><authors><author><keyname>Sakai</keyname><forenames>Hideyuki</forenames></author><author><keyname>Yamamoto</keyname><forenames>Hirosuke</forenames></author></authors><title>Asymptotically Optimal Tree-based Group Key Management Schemes</title><categories>cs.IT cs.CR math.IT</categories><comments>15 pages including 1 figure and 2 tables, submitted to the IEEE
  Transactions on Information Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  In key management schemes that realize secure multicast communications
encrypted by group keys on a public network, tree structures are often used to
update the group keys efficiently. Selcuk and Sidhu have proposed an efficient
scheme which updates dynamically the tree structures based on the withdrawal
probabilities of members. In this paper, it is shown that Selcuk-Sidhu scheme
is asymptotically optimal for the cost of withdrawal. Furthermore, a new key
management scheme, which takes account of key update costs of joining in
addition to withdrawal, is proposed. It is proved that the proposed scheme is
also asymptotically optimal, and it is shown by simulation that it can attain
good performance for nonasymptotic cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507002</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507002</id><created>2005-06-30</created><authors><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Liu</keyname><forenames>Ke</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>The Three Node Wireless Network: Achievable Rates and Cooperation
  Strategies</title><categories>cs.IT math.IT</categories><comments>52 pages</comments><abstract>  We consider a wireless network composed of three nodes and limited by the
half-duplex and total power constraints. This formulation encompasses many of
the special cases studied in the literature and allows for capturing the common
features shared by them. Here, we focus on three special cases, namely 1) Relay
Channel, 2) Multicast Channel, and 3) Conference Channel. These special cases
are judicially chosen to reflect varying degrees of complexity while
highlighting the common ground shared by the different variants of the three
node wireless network. For the relay channel, we propose a new cooperation
scheme that exploits the wireless feedback gain. This scheme combines the
benefits of decode-and-forward and compress-and-forward strategies and avoids
the idealistic feedback assumption adopted in earlier works. Our analysis of
the achievable rate of this scheme reveals the diminishing feedback gain at
both the low and high signal-to-noise ratio regimes. Inspired by the proposed
feedback strategy, we identify a greedy cooperation framework applicable to
both the multicast and conference channels. Our performance analysis reveals
several nice properties of the proposed greedy approach and the central role of
cooperative source-channel coding in exploiting the receiver side information
in the wireless network setting. Our proofs for the cooperative multicast with
side-information rely on novel nested and independent binning encoders along
with a list decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507003</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507003</id><created>2005-07-01</created><updated>2005-12-11</updated><authors><author><keyname>Shiekh</keyname><forenames>A. Y.</forenames></author></authors><title>The role of Quantum Interference in Quantum Computing</title><categories>cs.CC quant-ph</categories><comments>3 pages, no figures (citation added)</comments><journal-ref>Int. Jour. of Theo. Phys., 45, 1653, 2006</journal-ref><doi>10.1007/s10773-005-9025-8</doi><abstract>  Quantum interference is proposed as a tool to augment Quantum Computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507004</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507004</id><created>2005-07-03</created><updated>2006-05-01</updated><authors><author><keyname>Fidler</keyname><forenames>Markus</forenames></author></authors><title>An End-to-End Probabilistic Network Calculus with Moment Generating
  Functions</title><categories>cs.IT cs.PF math.IT</categories><journal-ref>IWQoS 2006</journal-ref><abstract>  Network calculus is a min-plus system theory for performance evaluation of
queuing networks. Its elegance stems from intuitive convolution formulas for
concatenation of deterministic servers. Recent research dispenses with the
worst-case assumptions of network calculus to develop a probabilistic
equivalent that benefits from statistical multiplexing. Significant
achievements have been made, owing for example to the theory of effective
bandwidths, however, the outstanding scalability set up by concatenation of
deterministic servers has not been shown.
  This paper establishes a concise, probabilistic network calculus with moment
generating functions. The presented work features closed-form, end-to-end,
probabilistic performance bounds that achieve the objective of scaling linearly
in the number of servers in series. The consistent application of moment
generating functions put forth in this paper utilizes independence beyond the
scope of current statistical multiplexing of flows. A relevant additional gain
is demonstrated for tandem servers with independent cross-traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507005</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507005</id><created>2005-07-04</created><authors><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hisashi</forenames></author></authors><title>A Genetic Algorithm Based Finger Selection Scheme for UWB MMSE Rake
  Receivers</title><categories>cs.IT math.IT</categories><comments>To appear in the Proc. IEEE International Conference on Ultrawideband
  (ICU-2005)</comments><abstract>  Due to a large number of multipath components in a typical ultra wideband
(UWB) system, selective Rake (SRake) receivers, which combine energy from a
subset of multipath components, are commonly employed. In order to optimize
system performance, an optimal selection of multipath components to be employed
at fingers of an SRake receiver needs to be considered. In this paper, this
finger selection problem is investigated for a minimum mean square error (MMSE)
UWB SRake receiver. Since the optimal solution is NP hard, a genetic algorithm
(GA) based iterative scheme is proposed, which can achieve near-optimal
performance after a reasonable number of iterations. Simulation results are
presented to compare the performance of the proposed finger selection algorithm
with those of the conventional and optimal schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507006</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507006</id><created>2005-07-04</created><authors><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author><author><keyname>Sahinoglu</keyname><forenames>Zafer</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hisashi</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A Two-Step Time of Arrival Estimation Algorithm for Impulse Radio Ultra
  Wideband Systems</title><categories>cs.IT math.IT</categories><comments>To appear in the Proc. of EUSIPCO 2005, Antalya, Turkey</comments><abstract>  High time resolution of ultra wideband (UWB) signals facilitates very precise
positioning capabilities based on time-of-arrival (TOA) measurements. Although
the theoretical lower bound for TOA estimation can be achieved by the maximum
likelihood principle, it is impractical due to the need for extremely high-rate
sampling and the presence of large number of multipath components. On the other
hand, the conventional correlation-based algorithm, which serially searches
possible signal delays, takes a very long time to estimate the TOA of a
received UWB signal. Moreover, the first signal path does not always have the
strongest correlation output. Therefore, first path detection algorithms need
to be considered. In this paper, a data-aided two-step TOA estimation algorithm
is proposed. In order to speed up the estimation process, the first step
estimates the rough TOA of the received signal based on received signal energy.
Then, in the second step, the arrival time of the first signal path is
estimated by considering a hypothesis testing approach. The proposed scheme
uses low-rate correlation outputs, and is able to perform accurate TOA
estimation in reasonable time intervals. The simulation results are presented
to analyze the performance of the estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507007</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507007</id><created>2005-07-04</created><updated>2005-09-28</updated><authors><author><keyname>Berger</keyname><forenames>Ulrich</forenames></author></authors><title>Strong normalisation for applied lambda calculi</title><categories>cs.GT</categories><comments>14 pages, paper acceptet at electronic journal LMCS</comments><acm-class>D.1.1; F.3.2; F.3.3; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 2 (October 5,
  2005) lmcs:951</journal-ref><doi>10.2168/LMCS-1(2:3)2005</doi><abstract>  We consider the untyped lambda calculus with constructors and recursively
defined constants. We construct a domain-theoretic model such that any term not
denoting bottom is strongly normalising provided all its `stratified
approximations' are. From this we derive a general normalisation theorem for
applied typed lambda-calculi: If all constants have a total value, then all
typeable terms are strongly normalising. We apply this result to extensions of
G\&quot;odel's system T and system F extended by various forms of bar recursion for
which strong normalisation was hitherto unknown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507008</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507008</id><created>2005-07-05</created><updated>2012-06-24</updated><authors><author><keyname>Feinstein</keyname><forenames>Craig Alan</forenames></author></authors><title>Complexity Science for Simpletons</title><categories>cs.CC cs.GL</categories><comments>10 pages, made a minor correction</comments><acm-class>F.1.3; F.2.2</acm-class><journal-ref>Progress in Physics, 2006, v. 3, 35-42</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we shall describe some of the most interesting topics in the
subject of Complexity Science for a general audience. Anyone with a solid
foundation in high school mathematics (with some calculus) and an elementary
understanding of computer programming will be able to follow this article.
First, we shall explain the significance of the P versus NP problem and solve
it. Next, we shall describe two other famous mathematics problems, the Collatz
3n+1 Conjecture and the Riemann Hypothesis, and show how both Chaitin's
incompleteness theorem and Wolfram's notion of &quot;computational irreducibility&quot;
are important for understanding why no one has, as of yet, solved these two
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507009</id><created>2005-07-04</created><authors><author><keyname>Zhao</keyname><forenames>Ming</forenames></author><author><keyname>Chen</keyname><forenames>Zhigang</forenames></author><author><keyname>Deng</keyname><forenames>Xiaoheng</forenames></author><author><keyname>Zhang</keyname><forenames>Lianming</forenames></author><author><keyname>Liu</keyname><forenames>Anfeng</forenames></author><author><keyname>Huang</keyname><forenames>Guosheng</forenames></author></authors><title>MAEC : A Movement-Assisted Energy Conserving Method in Event Driven
  Wireless Sensor Networks</title><categories>cs.NI</categories><comments>IEEE International Conference on Wireless Communications, Networking
  and Mobile Computing, 2005, to appear</comments><abstract>  Energy is one of the most important resources in wireless sensor networks.
Recently, the mobility of base station has been exploited to preserve the
energy. But in event driven networks, the mobility issue is quite different
from the continuous monitoring one because only a small portion of sensor node
has data to send at one time. The number of sensor node that forward traffic
should be minimized to prolong the network lifetime. In this paper, we propose
a movement-assisted energy conserving method which tries to reduce the amount
of forwarding sensor node by directing the base station to move close to the
hotspots. This method achieves good performance especially when applied to a
network with a set of cooperative mobile base station. Extensive simulation has
been done to verify the effectiveness of the propose schema.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507010</id><created>2005-07-05</created><authors><author><keyname>Wang</keyname><forenames>Jiayang</forenames></author></authors><title>A Study for the Feature Core of Dynamic Reduct</title><categories>cs.AI</categories><comments>9 pages</comments><acm-class>I.2.4</acm-class><abstract>  To the reduct problems of decision system, the paper proposes the notion of
dynamic core according to the dynamic reduct model. It describes various formal
definitions of dynamic core, and discusses some properties about dynamic core.
All of these show that dynamic core possesses the essential characters of the
feature core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507011</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507011</id><created>2005-07-05</created><authors><author><keyname>Meshkati</keyname><forenames>Farhad</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Schwartz</keyname><forenames>Stuart C.</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan B.</forenames></author></authors><title>A Utility-Based Approach to Power Control and Receiver Design in
  Wireless Data Networks</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Communications</comments><abstract>  In this work, the cross-layer design problem of joint multiuser detection and
power control is studied using a game-theoretic approach. The uplink of a
direct-sequence code division multiple access (DS-CDMA) data network is
considered and a non-cooperative game is proposed in which users in the network
are allowed to choose their uplink receivers as well as their transmit powers
to maximize their own utilities. The utility function measures the number of
reliable bits transmitted by the user per joule of energy consumed. Focusing on
linear receivers, the Nash equilibrium for the proposed game is derived. It is
shown that the equilibrium is one where the powers are SIR-balanced with the
minimum mean square error (MMSE) detector as the receiver. In addition, this
framework is used to study power control games for the matched filter, the
decorrelator, and the MMSE detector; and the receivers' performance is compared
in terms of the utilities achieved at equilibrium (in bits/Joule). The optimal
cooperative solution is also discussed and compared with the non-cooperative
approach. Extensions of the results to the case of multiple receive antennas
are also presented. In addition, an admission control scheme based on
maximizing the total utility in the network is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507012</id><created>2005-07-05</created><authors><author><keyname>Giraldi</keyname><forenames>Gilson A.</forenames></author><author><keyname>Xavier</keyname><forenames>Adilson V.</forenames></author><author><keyname>Apolinario</keyname><forenames>Antonio L.</forenames><suffix>Jr</suffix></author><author><keyname>Rodrigues</keyname><forenames>Paulo S.</forenames></author></authors><title>Lattice Gas Cellular Automata for Computational Fluid Animation</title><categories>cs.GR</categories><abstract>  The past two decades showed a rapid growing of physically-based modeling of
fluids for computer graphics applications. In this area, a common top down
approach is to model the fluid dynamics by Navier-Stokes equations and apply a
numerical techniques such as Finite Differences or Finite Elements for the
simulation. In this paper we focus on fluid modeling through Lattice Gas
Cellular Automata (LGCA) for computer graphics applications. LGCA are discrete
models based on point particles that move on a lattice, according to suitable
and simple rules in order to mimic a fully molecular dynamics. By
Chapman-Enskog expansion, a known multiscale technique in this area, it can be
demonstrated that the Navier-Stokes model can be reproduced by the LGCA
technique. Thus, with LGCA we get a fluid model that does not require solution
of complicated equations. Therefore, we combine the advantage of the low
computational cost of LGCA and its ability to mimic the realistic fluid
dynamics to develop a new animating framework for computer graphics
applications. In this work, we discuss the theoretical elements of our proposal
and show experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507013</id><created>2005-07-05</created><updated>2005-07-05</updated><authors><author><keyname>Colannino</keyname><forenames>Justin</forenames></author><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Meijer</keyname><forenames>Henk</forenames></author><author><keyname>Ramaswami</keyname><forenames>Suneeta</forenames></author><author><keyname>Toussaint</keyname><forenames>Godfried</forenames></author></authors><title>An O(n log n)-Time Algorithm for the Restricted Scaffold Assignment</title><categories>cs.CG cs.DM</categories><comments>13 pages, 8 figures</comments><acm-class>F.2.2; G.2.2</acm-class><abstract>  The assignment problem takes as input two finite point sets S and T and
establishes a correspondence between points in S and points in T, such that
each point in S maps to exactly one point in T, and each point in T maps to at
least one point in S. In this paper we show that this problem has an O(n log
n)-time solution, provided that the points in S and T are restricted to lie on
a line (linear time, if S and T are presorted).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507014</id><created>2005-07-06</created><authors><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>Isomorphism of graphs-a polynomial test</title><categories>cs.DS</categories><abstract>  An explicit algorithm is presented for testing whether two non-directed
graphs are isomorphic or not. It is shown that for a graph of n vertices, the
number of n independent operations needed for the test is polynomial in n. A
proof that the algorithm actually performs the test is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507015</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507015</id><created>2005-07-06</created><authors><author><keyname>Cohen</keyname><forenames>G&#xe9;rard</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Duality between Packings and Coverings of the Hamming Space</title><categories>cs.IT cs.DM math.IT</categories><comments>5 pages</comments><acm-class>E.2; G.2.1</acm-class><abstract>  We investigate the packing and covering densities of linear and nonlinear
binary codes, and establish a number of duality relationships between the
packing and covering problems. Specifically, we prove that if almost all codes
(in the class of linear or nonlinear codes) are good packings, then only a
vanishing fraction of codes are good coverings, and vice versa: if almost all
codes are good coverings, then at most a vanishing fraction of codes are good
packings. We also show that any specific maximal binary code is either a good
packing or a good covering, in a certain well-defined sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507016</id><created>2005-07-06</created><authors><author><keyname>Fondrevelle</keyname><forenames>Julien</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Oulamara</keyname><forenames>Ammar</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Portmann</keyname><forenames>Marie-Claude</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Minimizing makespan in flowshop with time lags</title><categories>cs.DM</categories><comments>2 pages. Also available at http://hal.inria.fr/inria-00000149</comments><proxy>ccsd inria-00000149</proxy><journal-ref>Fondrevelle J., Oulamara A., Portmann M.-C. &quot;Minimizing makespan
  in flowshop with time lags&quot; Dans MAPSP'2005 [OAI:
  oai:hal.inria.fr:inria-00000149\_v1]</journal-ref><abstract>  We consider the problem of minimizing the makespan in a flowshop involving
maximal and minimal time lags. Time lag constraints generalize the classical
precedence constraints between operations. We assume that such constraints are
only defined between operations of the same job. We propose a solution method
and present several extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507017</id><created>2005-07-06</created><updated>2005-08-24</updated><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Rafiey</keyname><forenames>A.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>Minimum Cost and List Homomorphisms to Semicomplete Digraphs</title><categories>cs.DM</categories><comments>8 pages</comments><abstract>  The following optimization problem was introduced in \cite{gutinDAM}, where
it was motivated by a real-world problem in defence logistics. Suppose we are
given a pair of digraphs $D,H$ and a positive cost $c_i(u)$ for each $u\in
V(D)$ and $i\in V(H)$. The cost of a homomorphism $f$ of $D$ to $H$ is
$\sum_{u\in V(D)}c_{f(u)}(u)$. For a fixed digraph $H$, the minimum cost
homomorphism problem for $H$, MinHOMP($H$), is stated as follows: For an input
digraph $D$ and costs $c_i(u)$ for each $u\in V(D)$ and $i\in V(H)$, verify
whether there is a homomorphism of $D$ to $H$ and, if it exists, find such a
homomorphism of minimum cost.
  We obtain dichotomy classifications of the computational complexity of the
list homomorphism problem and MinHOMP($H$), when $H$ is a semicomplete digraph
(a digraph in which every two vertices have at least one arc between them). Our
dichotomy for the list homomorphism problem coincides with the one obtained by
Bang-Jensen, Hell and MacGillivray in 1988 for the homomorphism problem when
$H$ is a semicomplete digraph: both problems are polynomial solvable if $H$ has
at most one cycle; otherwise, both problems are NP-complete. The dichotomy for
\MiP is different: the problem is polynomial time solvable if $H$ is acyclic or
$H$ is a cycle of length 2 or 3; otherwise, the problem is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507018</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507018</id><created>2005-07-06</created><authors><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Optimal and Suboptimal Detection of Gaussian Signals in Noise:
  Asymptotic Relative Efficiency</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the SPIE Conference on Advanced
  Signal Processing Algorithms, Architectures and Implementations XV, San
  Diego, CA, Jul. 1 - Aug. 4, 2005</comments><acm-class>E.4</acm-class><doi>10.1117/12.620177</doi><abstract>  The performance of Bayesian detection of Gaussian signals using noisy
observations is investigated via the error exponent for the average error
probability. Under unknown signal correlation structure or limited processing
capability it is reasonable to use the simple quadratic detector that is
optimal in the case of an independent and identically distributed (i.i.d.)
signal. Using the large deviations principle, the performance of this detector
(which is suboptimal for non-i.i.d. signals) is compared with that of the
optimal detector for correlated signals via the asymptotic relative efficiency
defined as the ratio between sample sizes of two detectors required for the
same performance in the large-sample-size regime. The effects of SNR on the ARE
are investigated. It is shown that the asymptotic efficiency of the simple
quadratic detector relative to the optimal detector converges to one as the SNR
increases without bound for any bounded spectrum, and that the simple quadratic
detector performs as well as the optimal detector for a wide range of the
correlation values at high SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507019</identifier>
 <datestamp>2008-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507019</id><created>2005-07-06</created><authors><author><keyname>Aoki</keyname><forenames>Paul M.</forenames></author><author><keyname>Woodruff</keyname><forenames>Allison</forenames></author></authors><title>Making Space for Stories: Ambiguity in the Design of Personal
  Communication Systems</title><categories>cs.HC</categories><comments>10 pages</comments><acm-class>H.4.3</acm-class><journal-ref>Proc. ACM SIGCHI Conf. on Human Factors in Computing Systems,
  Portland, OR, Apr. 2005, 181-190. ACM Press.</journal-ref><doi>10.1145/1054972.1054998</doi><abstract>  Pervasive personal communication technologies offer the potential for
important social benefits for individual users, but also the potential for
significant social difficulties and costs. In research on face-to-face social
interaction, ambiguity is often identified as an important resource for
resolving social difficulties. In this paper, we discuss two design cases of
personal communication systems, one based on fieldwork of a commercial system
and another based on an unrealized design concept. The cases illustrate how
user behavior concerning a particular social difficulty, unexplained
unresponsiveness, can be influenced by technological issues that result in
interactional ambiguity. The cases also highlight the need to balance the
utility of ambiguity against the utility of usability and communicative
clarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507020</id><created>2005-07-07</created><authors><author><keyname>Durand</keyname><forenames>Arnaud</forenames></author><author><keyname>Grandjean</keyname><forenames>Etienne</forenames></author></authors><title>First-order queries on structures of bounded degree are computable with
  constant delay</title><categories>cs.LO cs.CC</categories><comments>18 pages, 1 figure</comments><abstract>  A bounded degree structure is either a relational structure all of whose
relations are of bounded degree or a functional structure involving bijective
functions only. In this paper, we revisit the complexity of the evaluation
problem of not necessarily Boolean first-order queries over structures of
bounded degree. Query evaluation is considered here as a dynamical process. We
prove that any query on bounded degree structures is $\constantdelaylin$, i.e.,
can be computed by an algorithm that has two separate parts: it has a
precomputation step of linear time in the size of the structure and then, it
outputs all tuples one by one with a constant (i.e. depending on the size of
the formula only) delay between each. Seen as a global process, this implies
that queries on bounded structures can be evaluated in total time
$O(f(|\phi|).(|\calS|+|\phi(\calS)|))$ and space $O(f(|\phi|).|\calS|)$ where
$\calS$ is the structure, $\phi$ is the formula, $\phi(\calS)$ is the result of
the query and $f$ is some function.
  Among other things, our results generalize a result of \cite{Seese-96} on the
data complexity of the model-checking problem for bounded degree structures.
Besides, the originality of our approach compared to that \cite{Seese-96} and
comparable results is that it does not rely on the Hanf's model-theoretic
technic (see \cite{Hanf-65}) and is completely effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507021</id><created>2005-07-07</created><authors><author><keyname>Dutra</keyname><forenames>Renato C.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Finding routes in anonymous sensor networks</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>Information Processing Letters 98 (2006), 139-144</journal-ref><doi>10.1016/j.ipl.2006.01.001</doi><abstract>  We consider networks of anonymous sensors and address the problem of
constructing routes for the delivery of information from a group of sensors in
response to a query by a sink. In order to circumvent the restrictions imposed
by anonymity, we rely on using the power level perceived by the sensors in the
query from the sink. We introduce a simple distributed algorithm to achieve the
building of routes to the sink and evaluate its performance by means of
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507022</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507022</id><created>2005-07-07</created><authors><author><keyname>D&#x229;bowski</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>On Hilberg's Law and Its Links with Guiraud's Law</title><categories>cs.CL cs.IT math.IT</categories><comments>To appear in Journal of Quantitative Linguistics</comments><journal-ref>Journal of Quantitative Linguistics, 2006, Volume 13, Number 1,
  pp. 81-109</journal-ref><doi>10.1080/09296170500500637</doi><abstract>  Hilberg (1990) supposed that finite-order excess entropy of a random human
text is proportional to the square root of the text length. Assuming that
Hilberg's hypothesis is true, we derive Guiraud's law, which states that the
number of word types in a text is greater than proportional to the square root
of the text length. Our derivation is based on some mathematical conjecture in
coding theory and on several experiments suggesting that words can be defined
approximately as the nonterminals of the shortest context-free grammar for the
text. Such operational definition of words can be applied even to texts
deprived of spaces, which do not allow for Mandelbrot's ``intermittent
silence'' explanation of Zipf's and Guiraud's laws. In contrast to
Mandelbrot's, our model assumes some probabilistic long-memory effects in human
narration and might be capable of explaining Menzerath's law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507023</id><created>2005-07-08</created><authors><author><keyname>Rigo</keyname><forenames>Luis O.</forenames><suffix>Jr.</suffix></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Two-dimensional cellular automata and the analysis of correlated time
  series</title><categories>cs.AI</categories><acm-class>B.6.1; G.3</acm-class><journal-ref>Pattern Recognition Letters 27 (2006), 1353-1360</journal-ref><doi>10.1016/j.patrec.2006.01.005</doi><abstract>  Correlated time series are time series that, by virtue of the underlying
process to which they refer, are expected to influence each other strongly. We
introduce a novel approach to handle such time series, one that models their
interaction as a two-dimensional cellular automaton and therefore allows them
to be treated as a single entity. We apply our approach to the problems of
filling gaps and predicting values in rainfall time series. Computational
results show that the new approach compares favorably to Kalman smoothing and
filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507024</id><created>2005-07-08</created><updated>2005-08-09</updated><authors><author><keyname>Despeyroux</keyname><forenames>Thierry</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Lechevallier</keyname><forenames>Yves</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Trousse</keyname><forenames>Brigitte</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Vercoustre</keyname><forenames>Anne-Marie</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>Experiments in Clustering Homogeneous XML Documents to Validate an
  Existing Typology</title><categories>cs.IR</categories><comments>(postprint); This version corrects a couple of errors in authors'
  names in the bibliography</comments><proxy>ccsd inria-00000002</proxy><abstract>  This paper presents some experiments in clustering homogeneous XMLdocuments
to validate an existing classification or more generally anorganisational
structure. Our approach integrates techniques for extracting knowledge from
documents with unsupervised classification (clustering) of documents. We focus
on the feature selection used for representing documents and its impact on the
emerging classification. We mix the selection of structured features with fine
textual selection based on syntactic characteristics.We illustrate and evaluate
this approach with a collection of Inria activity reports for the year 2003.
The objective is to cluster projects into larger groups (Themes), based on the
keywords or different chapters of these activity reports. We then compare the
results of clustering using different feature selections, with the official
theme structure used by Inria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507025</id><created>2005-07-08</created><authors><author><keyname>Douc</keyname><forenames>Randal</forenames><affiliation>CMAP</affiliation></author><author><keyname>Capp&#xe9;</keyname><forenames>Olivier</forenames><affiliation>LTCI</affiliation></author><author><keyname>Moulines</keyname><forenames>Eric</forenames><affiliation>LTCI</affiliation></author></authors><title>Comparison of Resampling Schemes for Particle Filtering</title><categories>cs.CE</categories><proxy>ccsd ccsd-00005883</proxy><journal-ref>Image and Signal Processing and Analysis, 2005. ISPA 2005.
  Proceedings of the 4th International Symposium on (2005) 64-69</journal-ref><abstract>  This contribution is devoted to the comparison of various resampling
approaches that have been proposed in the literature on particle filtering. It
is first shown using simple arguments that the so-called residual and
stratified methods do yield an improvement over the basic multinomial
resampling approach. A simple counter-example showing that this property does
not hold true for systematic resampling is given. Finally, some results on the
large-sample behavior of the simple bootstrap filter algorithm are given. In
particular, a central limit theorem is established for the case where
resampling is performed using the residual approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507026</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507026</id><created>2005-07-08</created><authors><author><keyname>Cheng</keyname><forenames>Qi</forenames></author></authors><title>Hard Problems of Algebraic Geometry Codes</title><categories>cs.IT math.IT</categories><comments>13 pages, No figure</comments><acm-class>E.4</acm-class><abstract>  The minimum distance is one of the most important combinatorial
characterizations of a code. The maximum likelihood decoding problem is one of
the most important algorithmic problems of a code. While these problems are
known to be hard for general linear codes, the techniques used to prove their
hardness often rely on the construction of artificial codes. In general, much
less is known about the hardness of the specific classes of natural linear
codes. In this paper, we show that both problems are
 NP-hard for algebraic geometry codes. We achieve this by reducing a well-known
NP-complete problem to these problems using a randomized algorithm. The family
of codes in the reductions are based on elliptic curves. They have positive
rates, but the alphabet sizes are exponential in the block lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507027</id><created>2005-07-09</created><updated>2006-03-16</updated><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Anyone but Him: The Complexity of Precluding an Alternative</title><categories>cs.GT cs.CC cs.MA</categories><comments>Preliminary version appeared in AAAI '05. Also appears as
  URCS-TR-2005-873</comments><acm-class>I.2.11; F.2.2; F.1.3</acm-class><abstract>  Preference aggregation in a multiagent setting is a central issue in both
human and computer contexts. In this paper, we study in terms of complexity the
vulnerability of preference aggregation to destructive control. That is, we
study the ability of an election's chair to, through such mechanisms as
voter/candidate addition/suppression/partition, ensure that a particular
candidate (equivalently, alternative) does not win. And we study the extent to
which election systems can make it impossible, or computationally costly
(NP-complete), for the chair to execute such control. Among the systems we
study--plurality, Condorcet, and approval voting--we find cases where systems
immune or computationally resistant to a chair choosing the winner nonetheless
are vulnerable to the chair blocking a victory. Beyond that, we see that among
our studied systems no one system offers the best protection against
destructive control. Rather, the choice of a preference aggregation system will
depend closely on which types of control one wishes to be protected against. We
also find concrete cases where the complexity of or susceptibility to control
varies dramatically based on the choice among natural tie-handling rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507028</id><created>2005-07-10</created><authors><author><keyname>Milson</keyname><forenames>Robert</forenames></author><author><keyname>Krowne</keyname><forenames>Aaron</forenames></author></authors><title>Adapting CBPP platforms for instructional use</title><categories>cs.DL cs.HC</categories><comments>Will be presented at the 2005, Emory university symposium on Free
  Culture and the Digital Library</comments><acm-class>H.3.7; J.2</acm-class><abstract>  Commons based peer-production (CBPP) is the de-centralized, net-based
approach to the creation and dissemination of information resources. Underlying
every CBPP system is a virtual community brought together by an internet tool
(such as a web site) and structured by a specific collaboration protocol. In
this talk we will argue that the value of such platforms can be leveraged by
adapting them for pedagogical purposes.
  We report on one such recent adaptation. The Noosphere system is a web-based
collaboration environment that underlies the popular Planetmath website, a
collaboratively written encyclopedia of mathematics licensed under the GNU Free
Documentation License (FDL). Recently, the system was used to host a
graduate-level mathematics course at Dalhousie University, in Halifax, Canada.
The course consisted of regular lectures and assignment problems. The students
in the course collaborated on a set of course notes, encapsulating the lecture
content and giving solutions of assigned problems. The successful outcome of
this experiment demonstrated that a dedicated Noosphere system is well suited
for classroom applications. We argue that this ``proof of concept'' experience
also strongly suggests that every successful CBPP platform possesses latent
pedagogical value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507029</id><created>2005-07-11</created><authors><author><keyname>Landau</keyname><forenames>Samuel</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Sigaud</keyname><forenames>Olivier</forenames><affiliation>LIP6</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>ATNoSFERES revisited</title><categories>cs.AI</categories><proxy>ccsd inria-00000158</proxy><journal-ref>Landau S., Sigaud O., Schoenauer M. &quot;ATNoSFERES revisited&quot; Dans
  Proceedings of the Genetic and Evolutionary Computation Conference,
  GECCO-2005 [OAI: oai:hal.inria.fr:inria-00000158\_v1] -
  http://hal.inria.fr/inria-00000158</journal-ref><abstract>  ATNoSFERES is a Pittsburgh style Learning Classifier System (LCS) in which
the rules are represented as edges of an Augmented Transition Network.
Genotypes are strings of tokens of a stack-based language, whose execution
builds the labeled graph. The original ATNoSFERES, using a bitstring to
represent the language tokens, has been favorably compared in previous work to
several Michigan style LCSs architectures in the context of Non Markov
problems. Several modifications of ATNoSFERES are proposed here: the most
important one conceptually being a representational change: each token is now
represented by an integer, hence the genotype is a string of integers; several
other modifications of the underlying grammar language are also proposed. The
resulting ATNoSFERES-II is validated on several standard animat Non Markov
problems, on which it outperforms all previously published results in the LCS
literature. The reasons for these improvement are carefully analyzed, and some
assumptions are proposed on the underlying mechanisms in order to explain these
good results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507030</id><created>2005-07-11</created><updated>2006-06-21</updated><authors><author><keyname>Barany</keyname><forenames>Imre</forenames></author><author><keyname>Rote</keyname><forenames>Guenter</forenames></author></authors><title>Strictly convex drawings of planar graphs</title><categories>cs.CG cs.DM</categories><comments>20 pages, 13 figures. to be published in Documenta Mathematica. The
  revision includes numerous small additions, corrections, and improvements, in
  particular: - a discussion of the constants in the O-notation, after the
  statement of thm.1. - a different set-up and clarification of the case
  distinction for Lemma 1</comments><acm-class>F.2.2; G.2.2</acm-class><journal-ref>DOCUMENTA MATHEMATICA, Vol. 11 (2006), 369-391</journal-ref><abstract>  Every three-connected planar graph with n vertices has a drawing on an O(n^2)
x O(n^2) grid in which all faces are strictly convex polygons. These drawings
are obtained by perturbing (not strictly) convex drawings on O(n) x O(n) grids.
More generally, a strictly convex drawing exists on a grid of size O(W) x
O(n^4/W), for any choice of a parameter W in the range n&lt;W&lt;n^2. Tighter bounds
are obtained when the faces have fewer sides.
  In the proof, we derive an explicit lower bound on the number of primitive
vectors in a triangle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507031</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507031</id><created>2005-07-11</created><updated>2005-10-03</updated><authors><author><keyname>Stepanov</keyname><forenames>M. G.</forenames></author><author><keyname>Chertkov</keyname><forenames>M.</forenames></author></authors><title>The error-floor of LDPC codes in the Laplacian channel</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>43rd Allerton Conference (September 28-30, 2005, Allerton, IL)</comments><report-no>LA-UR-05-5131</report-no><abstract>  We analyze the performance of Low-Density-Parity-Check codes in the
error-floor domain where the Signal-to-Noise-Ratio, s, is large, s &gt;&gt; 1. We
describe how the instanton method of theoretical physics, recently adapted to
coding theory, solves the problem of characterizing the error-floor domain in
the Laplacian channel. An example of the (155,64,20) LDPC code with four
iterations (each iteration consisting of two semi-steps: from bits-to-checks
and from checks-to-bits) of the min-sum decoding is discussed. A generalized
computational tree analysis is devised to explain the rational structure of the
leading instantons. The asymptotic for the symbol Bit-Error-Rate in the
error-floor domain is comprised of individual instanton contributions, each
estimated as ~ \exp(-l_{inst;L} s), where the effective distances, l_{inst;L},
of the the leading instantons are 7.6, 8.0 and 8.0 respectively. (The Hamming
distance of the code is 20.) The analysis shows that the instantons are
distinctly different from the ones found for the same coding/decoding scheme
performing over the Gaussian channel. We validate instanton results against
direct simulations and offer an explanation for remarkable performance of the
instanton approximation not only in the extremal, s -&gt; \infty, limit but also
at the moderate s values of practical interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507032</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507032</id><created>2005-07-12</created><updated>2005-11-03</updated><authors><author><keyname>Ogden</keyname><forenames>R. D.</forenames></author></authors><title>Introduction to Quantum Message Space</title><categories>cs.IT math.IT math.OA quant-ph</categories><comments>LaTeX, 19 pages</comments><acm-class>E.4; H.1.1</acm-class><abstract>  This paper develops the quantum analog of the message ensemble of classical
information theory as developed by Shannon and Khinchin. The principal
mathematical tool is harmonic analysis on the free group with two generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507033</id><created>2005-07-13</created><updated>2005-11-14</updated><authors><author><keyname>Cuturi</keyname><forenames>Marco</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author></authors><title>Multiresolution Kernels</title><categories>cs.LG</categories><comments>8 pages</comments><proxy>ccsd ccsd-00007489</proxy><abstract>  We present in this work a new methodology to design kernels on data which is
structured with smaller components, such as text, images or sequences. This
methodology is a template procedure which can be applied on most kernels on
measures and takes advantage of a more detailed &quot;bag of components&quot;
representation of the objects. To obtain such a detailed description, we
consider possible decompositions of the original bag into a collection of
nested bags, following a prior knowledge on the objects' structure. We then
consider these smaller bags to compare two objects both in a detailed
perspective, stressing local matches between the smaller bags, and in a global
or coarse perspective, by considering the entire bag. This multiresolution
approach is likely to be best suited for tasks where the coarse approach is not
precise enough, and where a more subtle mixture of both local and global
similarities is necessary to compare objects. The approach presented here would
not be computationally tractable without a factorization trick that we
introduce before presenting promising results on an image retrieval task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507034</id><created>2005-07-13</created><authors><author><keyname>Abraham</keyname><forenames>Ittai</forenames></author><author><keyname>Malkhi</keyname><forenames>Dahlia</forenames></author><author><keyname>Manku</keyname><forenames>Gurmeet Singh</forenames></author></authors><title>Papillon: Greedy Routing in Rings</title><categories>cs.DC cs.NI</categories><abstract>  We study {\sc greedy} routing over $n$ nodes placed in a ring, with the
\emph{distance} between two nodes defined to be the clockwise or the absolute
distance between them along the ring. Such graphs arise in the context of
modeling social networks and in routing networks for peer-to-peer systems. We
construct the first network over $n$ nodes in which {\sc greedy} routing takes
$O(\log n / \log d)$ hops in the worst-case, with $d$ out-going links per node.
Our result has the first asymptotically optimal greedy routing complexity.
Previous constructions required $O(\frac{\log^2 n}{d})$ hops.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507035</id><created>2005-07-14</created><authors><author><keyname>Shen</keyname><forenames>Yi-Dong</forenames></author><author><keyname>You</keyname><forenames>Jia-Huai</forenames></author><author><keyname>Yuan</keyname><forenames>Li-Yan</forenames></author></authors><title>Enhancing Global SLS-Resolution with Loop Cutting and Tabling Mechanisms</title><categories>cs.LO cs.AI</categories><journal-ref>Theoretical Computer Science 328(3):271-287, 2004</journal-ref><abstract>  Global SLS-resolution is a well-known procedural semantics for top-down
computation of queries under the well-founded model. It inherits from
SLDNF-resolution the {\em linearity} property of derivations, which makes it
easy and efficient to implement using a simple stack-based memory structure.
However, like SLDNF-resolution it suffers from the problem of infinite loops
and redundant computations. To resolve this problem, in this paper we develop a
new procedural semantics, called {\em SLTNF-resolution}, by enhancing Global
SLS-resolution with loop cutting and tabling mechanisms. SLTNF-resolution is
sound and complete w.r.t. the well-founded semantics for logic programs with
the bounded-term-size property, and is superior to existing linear tabling
procedural semantics such as SLT-resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507036</id><created>2005-07-14</created><authors><author><keyname>Stuckey</keyname><forenames>Peter J</forenames></author><author><keyname>Sulzmann</keyname><forenames>Martin</forenames></author><author><keyname>Wazny</keyname><forenames>Jeremy</forenames></author></authors><title>Improved Inference for Checking Annotations</title><categories>cs.PL cs.LO</categories><abstract>  We consider type inference in the Hindley/Milner system extended with type
annotations and constraints with a particular focus on Haskell-style type
classes. We observe that standard inference algorithms are incomplete in the
presence of nested type annotations. To improve the situation we introduce a
novel inference scheme for checking type annotations. Our inference scheme is
also incomplete in general but improves over existing implementations as found
e.g. in the Glasgow Haskell Compiler (GHC). For certain cases (e.g. Haskell 98)
our inference scheme is complete. Our approach has been fully implemented as
part of the Chameleon system (experimental version of Haskell).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507037</id><created>2005-07-14</created><authors><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author><author><keyname>Sulzmann</keyname><forenames>Martin</forenames></author></authors><title>Type Inference for Guarded Recursive Data Types</title><categories>cs.PL cs.LO</categories><abstract>  We consider type inference for guarded recursive data types (GRDTs) -- a
recent generalization of algebraic data types. We reduce type inference for
GRDTs to unification under a mixed prefix. Thus, we obtain efficient type
inference. Inference is incomplete because the set of type constraints allowed
to appear in the type system is only a subset of those type constraints
generated by type inference. Hence, inference only succeeds if the program is
sufficiently type annotated. We present refined procedures to infer types
incrementally and to assist the user in identifying which pieces of type
information are missing. Additionally, we introduce procedures to test if a
type is not principal and to find a principal type if one exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507038</id><created>2005-07-14</created><authors><author><keyname>Elbassioni</keyname><forenames>Khaled</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author><author><keyname>Seidel</keyname><forenames>Raimund</forenames></author></authors><title>Upper Bound on the Number of Vertices of Polyhedra with $0,1$-Constraint
  Matrices</title><categories>cs.CG</categories><comments>3 pages</comments><acm-class>G.1.6</acm-class><abstract>  In this note we show that the maximum number of vertices in any polyhedron
$P=\{x\in \mathbb{R}^d : Ax\leq b\}$ with $0,1$-constraint matrix $A$ and a
real vector $b$ is at most $d!$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507039</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507039</id><created>2005-07-17</created><authors><author><keyname>Predd</keyname><forenames>Joel B.</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Distributed Regression in Sensor Networks: Training Distributively with
  Alternating Projections</title><categories>cs.LG cs.AI cs.CV cs.DC cs.IT math.IT</categories><comments>To appear in the Proceedings of the SPIE Conference on Advanced
  Signal Processing Algorithms, Architectures and Implementations XV, San
  Diego, CA, July 31 - August 4, 2005</comments><doi>10.1117/12.620194</doi><abstract>  Wireless sensor networks (WSNs) have attracted considerable attention in
recent years and motivate a host of new challenges for distributed signal
processing. The problem of distributed or decentralized estimation has often
been considered in the context of parametric models. However, the success of
parametric methods is limited by the appropriateness of the strong statistical
assumptions made by the models. In this paper, a more flexible nonparametric
model for distributed regression is considered that is applicable in a variety
of WSN applications including field estimation. Here, starting with the
standard regularized kernel least-squares estimator, a message-passing
algorithm for distributed estimation in WSNs is derived. The algorithm can be
viewed as an instantiation of the successive orthogonal projection (SOP)
algorithm. Various practical aspects of the algorithm are discussed and several
numerical simulations validate the potential of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507040</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507040</id><created>2005-07-18</created><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author></authors><title>Pattern Recognition for Conditionally Independent Data</title><categories>cs.LG cs.AI cs.CV</categories><comments>parts of results published at ALT'04 and ICML'04</comments><journal-ref>Journal of Machine Learning Research 7(Apr):645-664, 2006</journal-ref><abstract>  In this work we consider the task of relaxing the i.i.d assumption in pattern
recognition (or classification), aiming to make existing learning algorithms
applicable to a wider range of tasks. Pattern recognition is guessing a
discrete label of some object based on a set of given examples (pairs of
objects and labels). We consider the case of deterministically defined labels.
Traditionally, this task is studied under the assumption that examples are
independent and identically distributed. However, it turns out that many
results of pattern recognition theory carry over a weaker assumption. Namely,
under the assumption of conditional independence and identical distribution of
objects, while the only assumption on the distribution of labels is that the
rate of occurrence of each label should be above some positive threshold.
  We find a broad class of learning algorithms for which estimations of the
probability of a classification error achieved under the classical i.i.d.
assumption can be generalised to the similar estimates for the case of
conditionally i.i.d. examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507041</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507041</id><created>2005-07-18</created><authors><author><keyname>Chernov</keyname><forenames>Alexey</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Monotone Conditional Complexity Bounds on Future Prediction Errors</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>16 LaTeX pages</comments><report-no>IDSIA-16-05</report-no><acm-class>I.2.6; E.4; G.3; F.1.3</acm-class><journal-ref>Proc. 16th International Conf. on Algorithmic Learning Theory (ALT
  2005) 414-428</journal-ref><abstract>  We bound the future loss when predicting any (computably) stochastic sequence
online. Solomonoff finitely bounded the total deviation of his universal
predictor M from the true distribution m by the algorithmic complexity of m.
Here we assume we are at a time t&gt;1 and already observed x=x_1...x_t. We bound
the future prediction performance on x_{t+1}x_{t+2}... by a new variant of
algorithmic complexity of m given x, plus the complexity of the randomness
deficiency of x. The new complexity is monotone in its condition in the sense
that this complexity can only decrease if the condition is prolonged. We also
briefly discuss potential generalizations to Bayesian model classes and to
classification problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507042</id><created>2005-07-18</created><authors><author><keyname>Estrella</keyname><forenames>Florida</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Rogulin</keyname><forenames>Dmitry</forenames></author></authors><title>The MammoGrid Virtual Organisation - Federating Distributed Mammograms</title><categories>cs.DC cs.DB</categories><comments>^ pages, 3 figures, 2 tables</comments><report-no>Medical Informatics Europe MIE2005 paper publication</report-no><acm-class>H.2.4; J.3</acm-class><abstract>  The MammoGrid project aims to deliver a prototype which enables the effective
collaboration between radiologists using grid, service-orientation and database
solutions. The grid technologies and service-based database management solution
provide the platform for integrating diverse and distributed resources,
creating what is called a virtual organisation. The MammoGrid Virtual
Organisation facilitates the sharing and coordinated access to mammography
data, medical imaging software and computing resources of participating
hospitals. Hospitals manage their local database of mammograms, but in
addition, radiologists who are part of this organisation can share mammograms,
reports, results and image analysis software. The MammoGrid Virtual
Organisation is a federation of autonomous multi-centres sites which transcends
national boundaries. This paper outlines the service-based approach in the
creation and management of the federated distributed mammography database and
discusses the role of virtual organisations in distributed image analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507043</id><created>2005-07-18</created><updated>2006-03-16</updated><authors><author><keyname>Feng</keyname><forenames>Yuan</forenames></author><author><keyname>Duan</keyname><forenames>Runyao</forenames></author><author><keyname>Ji</keyname><forenames>Zhengfeng</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Proof rules for purely quantum programs</title><categories>cs.PL quant-ph</categories><comments>Now 12 pages, introduction and Section 3 rewritten, some errors
  corrected</comments><acm-class>D.3.1; F.3.1</acm-class><abstract>  We apply the notion of quantum predicate proposed by D'Hondt and Panangaden
to analyze a purely quantum language fragment which describes the quantum part
of a future quantum computer in Knill's architecture. The denotational
semantics, weakest precondition semantics, and weakest liberal precondition
semantics of this language fragment are introduced. To help reasoning about
quantum programs involving quantum loops, we extend proof rules for classical
probabilistic programs to our purely quantum programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507044</id><created>2005-07-18</created><authors><author><keyname>Poland</keyname><forenames>Jan</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Defensive Universal Learning with Experts</title><categories>cs.LG</categories><comments>15 LaTeX pages</comments><report-no>IDSIA-15-05</report-no><acm-class>I.2.6; G.3</acm-class><journal-ref>Proc. 16th International Conf. on Algorithmic Learning Theory (ALT
  2005) 356-370</journal-ref><abstract>  This paper shows how universal learning can be achieved with expert advice.
To this aim, we specify an experts algorithm with the following
characteristics: (a) it uses only feedback from the actions actually chosen
(bandit setup), (b) it can be applied with countably infinite expert classes,
and (c) it copes with losses that may grow in time appropriately slowly. We
prove loss bounds against an adaptive adversary. From this, we obtain a master
algorithm for &quot;reactive&quot; experts problems, which means that the master's
actions may influence the behavior of the adversary. Our algorithm can
significantly outperform standard experts algorithms on such problems. Finally,
we combine it with a universal expert class. The resulting universal learner
performs -- in a certain sense -- almost as well as any computable strategy,
for any online decision problem. We also specify the (worst-case) convergence
speed, which is very slow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507045</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507045</id><created>2005-07-18</created><updated>2008-10-24</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>In the beginning was game semantics</title><categories>cs.LO cs.AI math.LO</categories><comments>To appear in: &quot;Games: Unifying Logic, Language and Philosophy&quot;. O.
  Majer, A.-V. Pietarinen and T. Tulenheimo, eds. Springer Verlag, Berlin</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Games: Unifying Logic, Language and Philosophy. O. Majer, A.-V.
  Pietarinen and T. Tulenheimo, eds. Springer 2009, pp. 249-350</journal-ref><doi>10.1007/978-1-4020-9374-6_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents an overview of computability logic -- the
game-semantically constructed logic of interactive computational tasks and
resources. There is only one non-overview, technical section in it, devoted to
a proof of the soundness of affine logic with respect to the semantics of
computability logic. A comprehensive online source on the subject can be found
at http://www.cis.upenn.edu/~giorgi/cl.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507046</id><created>2005-07-19</created><authors><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Riley</keyname><forenames>George</forenames></author></authors><title>Revisiting Internet AS-level Topology Discovery</title><categories>cs.NI</categories><journal-ref>PAM 2005; LNCS 3431, p. 177, 2005</journal-ref><doi>10.1007/b135479</doi><abstract>  The development of veracious models of the Internet topology has received a
lot of attention in the last few years. Many proposed models are based on
topologies derived from RouteViews BGP table dumps (BTDs). However, BTDs do not
capture all AS-links of the Internet topology and most importantly the number
of the hidden AS-links is unknown, resulting in AS-graphs of questionable
quality. As a first step to address this problem, we introduce a new
AS-topology discovery methodology that results in more complete and accurate
graphs. Moreover, we use data available from existing measurement facilities,
circumventing the burden of additional measurement infrastructure. We deploy
our methodology and construct an AS-topology that has at least 61.5% more
AS-links than BTD-derived AS-topologies we examined. Finally, we analyze the
temporal and topological properties of the augmented graph and pinpoint the
differences from BTD-derived AS-topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507047</id><created>2005-07-19</created><authors><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Huffaker</keyname><forenames>Bradley</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author><author><keyname>Riley</keyname><forenames>George</forenames></author></authors><title>Inferring AS Relationships: Dead End or Lively Beginning?</title><categories>cs.NI cs.DS</categories><journal-ref>WEA 2005; LNCS 3503, p. 113, 2005</journal-ref><doi>10.1007/11427186_12</doi><abstract>  Recent techniques for inferring business relationships between ASs have
yielded maps that have extremely few invalid BGP paths in the terminology of
Gao. However, some relationships inferred by these newer algorithms are
incorrect, leading to the deduction of unrealistic AS hierarchies. We
investigate this problem and discover what causes it. Having obtained such
insight, we generalize the problem of AS relationship inference as a
multiobjective optimization problem with node-degree-based corrections to the
original objective function of minimizing the number of invalid paths. We solve
the generalized version of the problem using the semidefinite programming
relaxation of the MAX2SAT problem. Keeping the number of invalid paths small,
we obtain a more veracious solution than that yielded by recent heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507048</id><created>2005-07-19</created><updated>2005-10-12</updated><authors><author><keyname>Liberatore</keyname><forenames>Paolo</forenames></author></authors><title>Redundancy in Logic III: Non-Mononotonic Reasoning</title><categories>cs.LO cs.AI cs.CC</categories><comments>minor corrections</comments><abstract>  Results about the redundancy of circumscriptive and default theories are
presented. In particular, the complexity of establishing whether a given theory
is redundant is establihsed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507049</id><created>2005-07-19</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Sun</keyname><forenames>Jonathan Z.</forenames></author></authors><title>The Skip Quadtree: A Simple Dynamic Data Structure for Multidimensional
  Data</title><categories>cs.CG</categories><comments>12 pages, 3 figures. A preliminary version of this paper appeared in
  the 21st ACM Symp. Comp. Geom., Pisa, 2005, pp. 296-305</comments><acm-class>F.2.2</acm-class><abstract>  We present a new multi-dimensional data structure, which we call the skip
quadtree (for point data in R^2) or the skip octree (for point data in R^d,
with constant d&gt;2). Our data structure combines the best features of two
well-known data structures, in that it has the well-defined &quot;box&quot;-shaped
regions of region quadtrees and the logarithmic-height search and update
hierarchical structure of skip lists. Indeed, the bottom level of our structure
is exactly a region quadtree (or octree for higher dimensional data). We
describe efficient algorithms for inserting and deleting points in a skip
quadtree, as well as fast methods for performing point location and approximate
range queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507050</id><created>2005-07-19</created><authors><author><keyname>Arge</keyname><forenames>Lars</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Skip-Webs: Efficient Distributed Data Structures for Multi-Dimensional
  Data Sets</title><categories>cs.DC cs.CG cs.DS</categories><comments>8 pages, 4 figures. Appearing at 24th ACM SIGACT-SIGOPS Symp.
  Principles of Distributed Computing (PODC 2005), Las Vegas</comments><acm-class>F.2.2</acm-class><abstract>  We present a framework for designing efficient distributed data structures
for multi-dimensional data. Our structures, which we call skip-webs, extend and
improve previous randomized distributed data structures, including skipnets and
skip graphs. Our framework applies to a general class of data querying
scenarios, which include linear (one-dimensional) data, such as sorted sets, as
well as multi-dimensional data, such as d-dimensional octrees and digital tries
of character strings defined over a fixed alphabet. We show how to perform a
query over such a set of n items spread among n hosts using O(log n / log log
n) messages for one-dimensional data, or O(log n) messages for
fixed-dimensional data, while using only O(log n) space per host. We also show
how to make such structures dynamic so as to allow for insertions and deletions
in O(log n) messages for quadtrees, octrees, and digital tries, and O(log n /
log log n) messages for one-dimensional data. Finally, we show how to apply a
blocking strategy to skip-webs to further improve message complexity for
one-dimensional data when hosts can store more data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507051</identifier>
 <datestamp>2007-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507051</id><created>2005-07-19</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Meng</keyname><forenames>Jeremy Yu</forenames></author></authors><title>Confluent Layered Drawings</title><categories>cs.CG cs.DS</categories><comments>11 pages, 6 figures. A preliminary version of this paper appeared in
  Proc. 12th Int. Symp. Graph Drawing, New York, 2004, Lecture Notes in Comp.
  Sci. 3383, 2004, pp. 184-194</comments><acm-class>F.2.2</acm-class><journal-ref>Algorithmica 47(4):439-452, 2007</journal-ref><doi>10.1007/s00453-006-0159-8</doi><abstract>  We combine the idea of confluent drawings with Sugiyama style drawings, in
order to reduce the edge crossings in the resultant drawings. Furthermore, it
is easier to understand the structures of graphs from the mixed style drawings.
The basic idea is to cover a layered graph by complete bipartite subgraphs
(bicliques), then replace bicliques with tree-like structures. The biclique
cover problem is reduced to a special edge coloring problem and solved by
heuristic coloring algorithms. Our method can be extended to obtain multi-depth
confluent layered drawings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507052</identifier>
 <datestamp>2008-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507052</id><created>2005-07-20</created><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Xie</keyname><forenames>Hui-Min</forenames></author></authors><title>Finite automata for testing uniqueness of Eulerian trails</title><categories>cs.CC cs.LO</categories><acm-class>F.4.3</acm-class><journal-ref>J. Comput. System Sci., 2008. 74(5): 870-874</journal-ref><doi>10.1016/j.jcss.2007.10.004</doi><abstract>  We investigate the condition under which the Eulerian trail of a digraph is
unique, and design a finite automaton to examine it. The algorithm is
effective, for if the condition is violated, it will be noticed immediately
without the need to trace through the whole trail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507053</id><created>2005-07-20</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Nonrepetitive Paths and Cycles in Graphs with Application to Sudoku</title><categories>cs.DS cs.AI</categories><comments>17 pages, 11 figures</comments><acm-class>F.2.2; I.2.1</acm-class><abstract>  We provide a simple linear time transformation from a directed or undirected
graph with labeled edges to an unlabeled digraph, such that paths in the input
graph in which no two consecutive edges have the same label correspond to paths
in the transformed graph and vice versa. Using this transformation, we provide
efficient algorithms for finding paths and cycles with no two consecutive equal
labels. We also consider related problems where the paths and cycles are
required to be simple; we find efficient algorithms for the undirected case of
these problems but show the directed case to be NP-complete. We apply our path
and cycle finding algorithms in a program for generating and solving Sudoku
puzzles, and show experimentally that they lead to effective puzzle-solving
rules that may also be of interest to human Sudoku puzzle solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507054</id><created>2005-07-21</created><updated>2006-01-23</updated><authors><author><keyname>Siver</keyname><forenames>A. S.</forenames></author></authors><title>f2mma: FORTRAN to Mathematica translator</title><categories>cs.OH</categories><abstract>  f2mma program can be used to translate programs written in some subset of the
FORTRAN language into {\sl Mathematica} system's programming language. This
subset have been enough to translate GAPP (Global Analysis of Particle
Properties) programm into {\sl Mathematica} language automatically. Observables
table calculated with GAPP({\sl Mathematica}) is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507055</id><created>2005-07-21</created><updated>2005-08-02</updated><authors><author><keyname>Siver</keyname><forenames>A. S.</forenames></author></authors><title>ReacProc: A Tool to Process Reactions Describing Particle Interactions</title><categories>cs.CE</categories><comments>5 pages</comments><abstract>  ReacProc is a program written in C/C++ programming language which can be used
(1) to check out of reactions describing particles interactions against
conservation laws and (2) to reduce input reaction into some canonical form. A
table with particles properties is available within ReacProc package.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507056</id><created>2005-07-21</created><authors><author><keyname>Sidner</keyname><forenames>Candace L.</forenames></author><author><keyname>Lee</keyname><forenames>Christopher</forenames></author><author><keyname>Kidd</keyname><forenames>Cory</forenames></author><author><keyname>Lesh</keyname><forenames>Neal</forenames></author><author><keyname>Rich</keyname><forenames>Charles</forenames></author></authors><title>Explorations in engagement for humans and robots</title><categories>cs.AI cs.CL cs.RO</categories><comments>31 pages, 5 figures, 3 tables</comments><report-no>MERL TR2005-017</report-no><acm-class>I.2.7; I.2.9</acm-class><journal-ref>Artificial Intelligence, volume 166, issues 1-2, August 2005, pp.
  140-164</journal-ref><abstract>  This paper explores the concept of engagement, the process by which
individuals in an interaction start, maintain and end their perceived
connection to one another. The paper reports on one aspect of engagement among
human interactors--the effect of tracking faces during an interaction. It also
describes the architecture of a robot that can participate in conversational,
collaborative interactions with engagement gestures. Finally, the paper reports
on findings of experiments with human participants who interacted with a robot
when it either performed or did not perform engagement gestures. Results of the
human-robot studies indicate that people become engaged with robots: they
direct their attention to the robot more often in interactions where engagement
gestures are present, and they find interactions more appropriate when
engagement gestures are present than when they are not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507057</id><created>2005-07-21</created><authors><author><keyname>Tusarova</keyname><forenames>Tereza</forenames></author></authors><title>A new sibling of BQP</title><categories>cs.CC</categories><comments>extended abstract, submitted to UC'05</comments><abstract>  We present a new quantum complexity class, called MQ^2, which is contained in
AWPP. This class has a compact and simple mathematical definition, involving
only polynomial-time computable functions and a unitarity condition. It
contains both Deutsch-Jozsa's and Shor's algorithm, while its relation to BQP
is unknown. This shows that in the complexity class hierarchy, BQP is not an
extraordinary isolated island, but has ''siblings'' which as well can solve
prime-factorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507058</id><created>2005-07-22</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Paving the Way for Image Understanding: A New Kind of Image
  Decomposition is Desired</title><categories>cs.CV</categories><comments>14th Scandinavian Conference on Image Analysis (SCIA 2005)</comments><journal-ref>LNCS vol. 3540, pp. 17-24, Springer Verlag, 2005</journal-ref><abstract>  In this paper we present an unconventional image segmentation approach which
is devised to meet the requirements of image understanding and pattern
recognition tasks. Generally image understanding assumes interplay of two
sub-processes: image information content discovery and image information
content interpretation. Despite of its widespread use, the notion of &quot;image
information content&quot; is still ill defined, intuitive, and ambiguous. Most
often, it is used in the Shannon's sense, which means information content
assessment averaged over the whole signal ensemble. Humans, however,rarely
resort to such estimates. They are very effective in decomposing images into
their meaningful constituents and focusing attention to the perceptually
relevant image parts. We posit that following the latest findings in human
attention vision studies and the concepts of Kolmogorov's complexity theory an
unorthodox segmentation approach can be proposed that provides effective image
decomposition to information preserving image fragments well suited for
subsequent image interpretation. We provide some illustrative examples,
demonstrating effectiveness of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507059</id><created>2005-07-22</created><authors><author><keyname>de la Fuente</keyname><forenames>M. Magdalena Ortiz</forenames></author><author><keyname>Calvanese</keyname><forenames>Diego</forenames></author><author><keyname>Eiter</keyname><forenames>Thomas</forenames></author><author><keyname>Franconi</keyname><forenames>Enrico</forenames></author></authors><title>Data complexity of answering conjunctive queries over SHIQ knowledge
  bases</title><categories>cs.LO cs.AI cs.CC</categories><comments>Technical Report, 22 pages</comments><abstract>  An algorithm for answering conjunctive queries over SHIQ knowledge bases that
is coNP in data complexity is given. The algorithm is based on the tableau
algorithm for reasoning with individuals in SHIQ. The blocking conditions of
the tableau are weakened in such a way that the set of models the modified
algorithm yields suffices to check query entailment. The modified blocking
conditions are based on the ones proposed by Levy and Rousset for reasoning
with Horn Rules in the description logic ALCNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507060</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507060</id><created>2005-07-23</created><authors><author><keyname>Zuk</keyname><forenames>O.</forenames></author><author><keyname>Kanter</keyname><forenames>I.</forenames></author><author><keyname>Domany</keyname><forenames>E.</forenames></author></authors><title>The Entropy of a Binary Hidden Markov Process</title><categories>cs.IT cond-mat.stat-mech math.IT math.ST stat.TH</categories><doi>10.1007/s10955-005-7576-y</doi><abstract>  The entropy of a binary symmetric Hidden Markov Process is calculated as an
expansion in the noise parameter epsilon. We map the problem onto a
one-dimensional Ising model in a large field of random signs and calculate the
expansion coefficients up to second order in epsilon. Using a conjecture we
extend the calculation to 11th order and discuss the convergence of the
resulting series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507061</id><created>2005-07-24</created><authors><author><keyname>Adrian</keyname><forenames>Andre</forenames></author></authors><title>Software Architecture Overview</title><categories>cs.SE</categories><comments>9 pages, version 23jul2005</comments><acm-class>C.0; C.5</acm-class><abstract>  What is Software Architecture? The rules, paradigmen, pattern that help to
construct, build and test a serious piece of software. It is the practical
experience boiled down to abstract level. Software Architecture builds on
System Engineering and the scientific method as established by Galileo Galilei:
Measure what you can and make measureable what you can not. The experiment
(test) is more important then the deduction. Pieces of information about
software architecture are all over the internet. This paper uses citation as
much as possible. The aim is to bring together an overview, not to rephrase the
wording.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507062</id><created>2005-07-26</created><authors><author><keyname>Poland</keyname><forenames>Jan</forenames></author></authors><title>FPL Analysis for Adaptive Bandits</title><categories>cs.LG</categories><abstract>  A main problem of &quot;Follow the Perturbed Leader&quot; strategies for online
decision problems is that regret bounds are typically proven against oblivious
adversary. In partial observation cases, it was not clear how to obtain
performance guarantees against adaptive adversary, without worsening the
bounds. We propose a conceptually simple argument to resolve this problem.
Using this, a regret bound of O(t^(2/3)) for FPL in the adversarial multi-armed
bandit problem is shown. This bound holds for the common FPL variant using only
the observations from designated exploration rounds. Using all observations
allows for the stronger bound of O(t^(1/2)), matching the best bound known so
far (and essentially the known lower bound) for adversarial bandits.
Surprisingly, this variant does not even need explicit exploration, it is
self-stabilizing. However the sampling probabilities have to be either
externally provided or approximated to sufficient accuracy, using O(t^2 log t)
samples in each step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507063</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507063</id><created>2005-07-26</created><updated>2007-05-20</updated><authors><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>Theoretical cryptanalysis of the Klimov-Shamir number generator TF-1</title><categories>cs.CR cs.CC</categories><comments>To appear in JoC</comments><journal-ref>Journal of Cryptology 20 (2007), 389-392</journal-ref><doi>10.1007/s00145-007-0564-4</doi><abstract>  The internal state of the Klimov-Shamir number generator TF-1 consists of
four words of size w bits each, whereas its intended strength is 2^{2w}. We
exploit an asymmetry in its output function to show that the internal state can
be recovered after having 2^w outputs, using 2^{1.5w} operations. For w=32 the
attack is practical, but for their recommended w=64 it is only of theoretical
interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507064</id><created>2005-07-26</created><authors><author><keyname>Gnaedig</keyname><forenames>Isabelle</forenames></author><author><keyname>Kirchner</keyname><forenames>Helene</forenames></author></authors><title>Termination of rewriting strategies: a generic approach</title><categories>cs.LO</categories><comments>49 pages</comments><acm-class>F.3.1; F.4.2; F.4.3; I.1.3; I.2.2; I.2.3; D.3.1; D.2.4</acm-class><abstract>  We propose a generic termination proof method for rewriting under strategies,
based on an explicit induction on the termination property. Rewriting trees on
ground terms are modeled by proof trees, generated by alternatively applying
narrowing and abstracting steps. The induction principle is applied through the
abstraction mechanism, where terms are replaced by variables representing any
of their normal forms. The induction ordering is not given a priori, but
defined with ordering constraints, incrementally set during the proof.
Abstraction constraints can be used to control the narrowing mechanism, well
known to easily diverge. The generic method is then instantiated for the
innermost, outermost and local strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507065</id><created>2005-07-26</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author><author><keyname>Xu</keyname><forenames>Xiaofei</forenames></author><author><keyname>Deng</keyname><forenames>Shengchun</forenames></author></authors><title>A Fast Greedy Algorithm for Outlier Mining</title><categories>cs.DB cs.AI</categories><comments>11 pages</comments><report-no>Tr-05-0406</report-no><abstract>  The task of outlier detection is to find small groups of data objects that
are exceptional when compared with rest large amount of data. In [38], the
problem of outlier detection in categorical data is defined as an optimization
problem and a local-search heuristic based algorithm (LSA) is presented.
However, as is the case with most iterative type algorithms, the LSA algorithm
is still very time-consuming on very large datasets. In this paper, we present
a very fast greedy algorithm for mining outliers under the same optimization
model. Experimental results on real datasets and large synthetic datasets show
that: (1) Our algorithm has comparable performance with respect to those
state-of-art outlier detection algorithms on identifying true outliers and (2)
Our algorithm can be an order of magnitude faster than LSA algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507066</id><created>2005-07-27</created><authors><author><keyname>Lal</keyname><forenames>Sunder</forenames><affiliation>Department of Mathematics Institute of Basic Science</affiliation></author><author><keyname>Chaturvedi</keyname><forenames>Atul</forenames><affiliation>Department of Mathematics Institute of Basic Science</affiliation></author></authors><title>Authentication Schemes Using Braid Groups</title><categories>cs.CR cs.CY</categories><comments>6 pages, 2 figures</comments><abstract>  In this paper we proposed two identification schemes based on the root
problem. The proposed schemes are secure against passive attacks assuming that
the root problem (RP) is hard in braid groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507067</id><created>2005-07-28</created><authors><author><keyname>Calvanese</keyname><forenames>Diego</forenames></author><author><keyname>De Giacomo</keyname><forenames>Giuseppe</forenames></author><author><keyname>Lenzerini</keyname><forenames>Maurizio</forenames></author></authors><title>Conjunctive Query Containment and Answering under Description Logics
  Constraints</title><categories>cs.DB cs.AI</categories><acm-class>I.2.4; F.4.1</acm-class><abstract>  Query containment and query answering are two important computational tasks
in databases. While query answering amounts to compute the result of a query
over a database, query containment is the problem of checking whether for every
database, the result of one query is a subset of the result of another query.
  In this paper, we deal with unions of conjunctive queries, and we address
query containment and query answering under Description Logic constraints.
Every such constraint is essentially an inclusion dependencies between concepts
and relations, and their expressive power is due to the possibility of using
complex expressions, e.g., intersection and difference of relations, special
forms of quantification, regular expressions over binary relations, in the
specification of the dependencies. These types of constraints capture a great
variety of data models, including the relational, the entity-relationship, and
the object-oriented model, all extended with various forms of constraints, and
also the basic features of the ontology languages used in the context of the
Semantic Web.
  We present the following results on both query containment and query
answering. We provide a method for query containment under Description Logic
constraints, thus showing that the problem is decidable, and analyze its
computational complexity. We prove that query containment is undecidable in the
case where we allow inequalities in the right-hand side query, even for very
simple constraints and queries. We show that query answering under Description
Logic constraints can be reduced to query containment, and illustrate how such
a reduction provides upper bound results with respect to both combined and data
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507068</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507068</id><created>2005-07-28</created><authors><author><keyname>Hollmann</keyname><forenames>Henk D. L.</forenames><affiliation>Philips Research Laboratories, Eindhoven, Netherlands</affiliation></author><author><keyname>Tolhuizen</keyname><forenames>Ludo M. G. M.</forenames><affiliation>Philips Research Laboratories, Eindhoven, Netherlands</affiliation></author></authors><title>On parity check collections for iterative erasure decoding that correct
  all correctable erasure patterns of a given size</title><categories>cs.IT cs.DM math.IT</categories><comments>13 pages, no figures. Submitted to IEEE Transactions on Information
  Theory, July 28, 2005</comments><report-no>PR-MS 25.332</report-no><abstract>  Recently there has been interest in the construction of small parity check
sets for iterative decoding of the Hamming code with the property that each
uncorrectable (or stopping) set of size three is the support of a codeword and
hence uncorrectable anyway. Here we reformulate and generalise the problem, and
improve on this construction. First we show that a parity check collection that
corrects all correctable erasure patterns of size m for the r-th order Hamming
code (i.e, the Hamming code with codimension r) provides for all codes of
codimension $r$ a corresponding ``generic'' parity check collection with this
property. This leads naturally to a necessary and sufficient condition on such
generic parity check collections. We use this condition to construct a generic
parity check collection for codes of codimension r correcting all correctable
erasure patterns of size at most m, for all r and m &lt;= r, thus generalising the
known construction for m=3. Then we discussoptimality of our construction and
show that it can be improved for m&gt;=3 and r large enough. Finally we discuss
some directions for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507069</id><created>2005-07-28</created><authors><author><keyname>Pehcevski</keyname><forenames>Jovan</forenames><affiliation>RMIT</affiliation></author><author><keyname>Thom</keyname><forenames>James A.</forenames><affiliation>RMIT</affiliation></author><author><keyname>Vercoustre</keyname><forenames>Anne-Marie</forenames></author></authors><title>Users and Assessors in the Context of INEX: Are Relevance Dimensions
  Relevant?</title><categories>cs.IR</categories><proxy>ccsd inria-00000182</proxy><journal-ref>Pehcevski J., Thom J., Vercoustre A.-M. &quot;Users and Assessors in
  the Context of INEX: Are Relevance Dimensions Relevant?&quot; Dans INEX 2005
  Workshop on Element Retrieval Methodology [OAI :
  oai:hal.inria.fr:inria-00000182\_v1] - http://hal.inria.fr/inria-00000182</journal-ref><abstract>  The main aspects of XML retrieval are identified by analysing and comparing
the following two behaviours: the behaviour of the assessor when judging the
relevance of returned document components; and the behaviour of users when
interacting with components of XML documents. We argue that the two INEX
relevance dimensions, Exhaustivity and Specificity, are not orthogonal
dimensions; indeed, an empirical analysis of each dimension reveals that the
grades of the two dimensions are correlated to each other. By analysing the
level of agreement between the assessor and the users, we aim at identifying
the best units of retrieval. The results of our analysis show that the highest
level of agreement is on highly relevant and on non-relevant document
components, suggesting that only the end points of the INEX 10-point relevance
scale are perceived in the same way by both the assessor and the users. We
propose a new definition of relevance for XML retrieval and argue that its
corresponding relevance scale would be a better choice for INEX.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507070</id><created>2005-07-28</created><authors><author><keyname>Pehcevski</keyname><forenames>Jovan</forenames><affiliation>RMIT</affiliation></author><author><keyname>Thom</keyname><forenames>James A.</forenames><affiliation>RMIT</affiliation></author><author><keyname>Vercoustre</keyname><forenames>Anne-Marie</forenames></author></authors><title>Hybrid XML Retrieval: Combining Information Retrieval and a Native XML
  Database</title><categories>cs.IR</categories><comments>Postprint version. The editor version can be accessed through the DOI</comments><proxy>ccsd inria-00000183</proxy><doi>10.1007/s10791-005-0748-1</doi><abstract>  This paper investigates the impact of three approaches to XML retrieval:
using Zettair, a full-text information retrieval system; using eXist, a native
XML database; and using a hybrid system that takes full article answers from
Zettair and uses eXist to extract elements from those articles. For the
content-only topics, we undertake a preliminary analysis of the INEX 2003
relevance assessments in order to identify the types of highly relevant
document components. Further analysis identifies two complementary sub-cases of
relevance assessments (&quot;General&quot; and &quot;Specific&quot;) and two categories of topics
(&quot;Broad&quot; and &quot;Narrow&quot;). We develop a novel retrieval module that for a
content-only topic utilises the information from the resulting answer list of a
native XML database and dynamically determines the preferable units of
retrieval, which we call &quot;Coherent Retrieval Elements&quot;. The results of our
experiments show that -- when each of the three systems is evaluated against
different retrieval scenarios (such as different cases of relevance
assessments, different topic categories and different choices of evaluation
metrics) -- the XML retrieval systems exhibit varying behaviour and the best
performance can be reached for different values of the retrieval parameters. In
the case of INEX 2003 relevance assessments for the content-only topics, our
newly developed hybrid XML retrieval system is substantially more effective
than either Zettair or eXist, and yields a robust and a very effective XML
retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507071</id><created>2005-07-29</created><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Rauch</keyname><forenames>Thomas</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Security for Distributed Web-Applications via Aspect-Oriented
  Programming</title><categories>cs.CR</categories><comments>Refereed contribution to the Conference Information Security South
  Africa (ISSA 2005) Sandton, South Africa, 29. June - 1. July 2005</comments><acm-class>K.6.5; D.1.5; D.2</acm-class><abstract>  Identity Management is becoming more and more important in business systems
as they are opened for third parties including trading partners, consumers and
suppliers. This paper presents an approach securing a system without any
knowledge of the system source code. The security module adds to the existing
system authentication and authorisation based on aspect oriented programming
and the liberty alliance framework, an upcoming industrie standard providing
single sign on. In an initial training phase the module is adapted to the
application which is to be secured. Moreover the use of hardware tokens and
proactive computing is demonstrated. The high modularisation is achived through
use of AspectJ, a programming language extension of Java.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507072</id><created>2005-07-29</created><updated>2005-08-02</updated><authors><author><keyname>Leslie</keyname><forenames>Matthew</forenames></author></authors><title>Reliable Data Storage in Distributed Hash Tables</title><categories>cs.DC cs.NI</categories><abstract>  Distributed Hash Tables offer a resilient lookup service for unstable
distributed environments. Resilient data storage, however, requires additional
data replication and maintenance algorithms. These algorithms can have an
impact on both the performance and the scalability of the system. In this
paper, we describe the goals and design space of these replication algorithms.
  We examine an existing replication algorithm, and present a new analysis of
its reliability. We then present a new dynamic replication algorithm which can
operate in unstable environments. We give several possible replica placement
strategies for this algorithm, and show how they impact reliability and
performance.
  Finally we compare all replication algorithms through simulation, showing
quantitatively the difference between their bandwidth use, fault tolerance and
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0507073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0507073</id><created>2005-07-29</created><authors><author><keyname>Dagenais</keyname><forenames>Michel R.</forenames><affiliation>Dept. of Computer Engineering, Ecole Polytechnique, Montreal, Canada</affiliation></author><author><keyname>Yaghmour</keyname><forenames>Karim</forenames><affiliation>Opersys, Montreal, Canada</affiliation></author><author><keyname>Levert</keyname><forenames>Charles</forenames><affiliation>Ericsson Research, Montreal, Canada</affiliation></author><author><keyname>Pourzandi</keyname><forenames>Makan</forenames><affiliation>Ericsson Research, Montreal, Canada</affiliation></author></authors><title>Software Performance Analysis</title><categories>cs.PF cs.OS</categories><abstract>  The key to speeding up applications is often understanding where the elapsed
time is spent, and why. This document reviews in depth the full array of
performance analysis tools and techniques available on Linux for this task,
from the traditional tools like gcov and gprof, to the more advanced tools
still under development like oprofile and the Linux Trace Toolkit. The focus is
more on the underlying data collection and processing algorithms, and their
overhead and precision, than on the cosmetic details of the graphical user
interface frontends.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508001</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508001</id><created>2005-07-30</created><authors><author><keyname>Gu</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>Dimensions of Copeland-Erdos Sequences</title><categories>cs.CC cs.IT math.IT</categories><comments>19 pages</comments><abstract>  The base-$k$ {\em Copeland-Erd\&quot;os sequence} given by an infinite set $A$ of
positive integers is the infinite sequence $\CE_k(A)$ formed by concatenating
the base-$k$ representations of the elements of $A$ in numerical order. This
paper concerns the following four quantities.
  The {\em finite-state dimension} $\dimfs (\CE_k(A))$, a finite-state version
of classical Hausdorff dimension introduced in 2001.
  The {\em finite-state strong dimension} $\Dimfs(\CE_k(A))$, a finite-state
version of classical packing dimension introduced in 2004. This is a dual of
$\dimfs(\CE_k(A))$ satisfying $\Dimfs(\CE_k(A))$ $\geq \dimfs(\CE_k(A))$.
  The {\em zeta-dimension} $\Dimzeta(A)$, a kind of discrete fractal dimension
discovered many times over the past few decades.
  The {\em lower zeta-dimension} $\dimzeta(A)$, a dual of $\Dimzeta(A)$
satisfying $\dimzeta(A)\leq \Dimzeta(A)$.
  We prove the following.
  $\dimfs(\CE_k(A))\geq \dimzeta(A)$. This extends the 1946 proof by Copeland
and Erd\&quot;os that the sequence $\CE_k(\mathrm{PRIMES})$ is Borel normal.
  $\Dimfs(\CE_k(A))\geq \Dimzeta(A)$.
  These bounds are tight in the strong sense that these four quantities can
have (simultaneously) any four values in $[0,1]$ satisfying the four
above-mentioned inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508002</id><created>2005-07-30</created><authors><author><keyname>Giraldi</keyname><forenames>Gilson A.</forenames></author><author><keyname>da Costa</keyname><forenames>Luis C.</forenames></author><author><keyname>Xavier</keyname><forenames>Adilson V.</forenames></author><author><keyname>Rodrigues</keyname><forenames>Paulo S.</forenames></author></authors><title>Methods for Analytical Understanding of Agent-Based Modeling of Complex
  Systems</title><categories>cs.GR</categories><abstract>  Von Neuman's work on universal machines and the hardware development have
allowed the simulation of dynamical systems through a large set of interacting
agents. This is a bottom-up approach which tries to derive global properties of
a complex system through local interaction rules and agent behaviour.
Traditionally, such systems are modeled and simulated through top-down methods
based on differential equations. Agent-Based Modeling has the advantage of
simplicity and low computational cost. However, unlike differential equations,
there is no standard way to express agent behaviour. Besides, it is not clear
how to analytically predict the results obtained by the simulation. In this
paper we survey some of these methods. For expressing agent behaviour formal
methods, like Stochastic Process Algebras have been used. Such approach is
useful if the global properties of interest can be expressed as a function of
stochastic time series. However, if space variables must be considered, we
shall change the focus. In this case, multiscale techniques, based on
Chapman-Enskog expansion, was used to establish the connection between the
microscopic dynamics and the macroscopic observables. Also, we use data mining
techniques,like Principal Component Analysis (PCA), to study agent systems like
Cellular Automata. With the help of these tools we will discuss a simple
society model, a Lattice Gas Automaton for fluid modeling, and knowledge
discovery in CA databases. Besides, we show the capabilities of the NetLogo, a
software for agent simulation of complex system and show our experience about.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508003</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508003</id><created>2005-07-31</created><updated>2006-03-09</updated><authors><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Kucera</keyname><forenames>Antonin</forenames></author><author><keyname>Mayr</keyname><forenames>Richard</forenames></author></authors><title>Model Checking Probabilistic Pushdown Automata</title><categories>cs.LO</categories><acm-class>D.2.4; F.1.1; G.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 1 (March 7,
  2006) lmcs:678</journal-ref><doi>10.2168/LMCS-2(1:2)2006</doi><abstract>  We consider the model checking problem for probabilistic pushdown automata
(pPDA) and properties expressible in various probabilistic logics. We start
with properties that can be formulated as instances of a generalized random
walk problem. We prove that both qualitative and quantitative model checking
for this class of properties and pPDA is decidable. Then we show that model
checking for the qualitative fragment of the logic PCTL and pPDA is also
decidable. Moreover, we develop an error-tolerant model checking algorithm for
PCTL and the subclass of stateless pPDA. Finally, we consider the class of
omega-regular properties and show that both qualitative and quantitative model
checking for pPDA is decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508004</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508004</id><created>2005-08-01</created><authors><author><keyname>Naish</keyname><forenames>Lee</forenames></author></authors><title>A three-valued semantics for logic programmers</title><categories>cs.LO</categories><comments>31 pages, 5 figures</comments><acm-class>F.3.1; F.3.2</acm-class><journal-ref>Theory and Practice of Logic Programming 6(5), September 2006, pp.
  509-538.</journal-ref><abstract>  This paper describes a simpler way for programmers to reason about the
correctness of their code. The study of semantics of logic programs has shown
strong links between the model theoretic semantics (truth and falsity of atoms
in the programmer's interpretation of a program), procedural semantics (for
example, SLD resolution) and fixpoint semantics (which is useful for program
analysis and alternative execution mechanisms). Most of this work assumes that
intended interpretations are two-valued: a ground atom is true (and should
succeed according to the procedural semantics) or false (and should not
succeed). In reality, intended interpretations are less precise. Programmers
consider that some atoms &quot;should not occur&quot; or are &quot;ill-typed&quot; or
&quot;inadmissible&quot;. Programmers don't know and don't care whether such atoms
succeed. In this paper we propose a three-valued semantics for (essentially)
pure Prolog programs with (ground) negation as failure which reflects this. The
semantics of Fitting is similar but only associates the third truth value with
non-termination. We provide tools to reason about correctness of programs
without the need for unnatural precision or undue restrictions on programming
style. As well as theoretical results, we provide a programmer-oriented
synopsis. This work has come out of work on declarative debugging, where it has
been recognised that inadmissible calls are important. This paper has been
accepted to appear in Theory and Practice of Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508005</id><created>2005-08-01</created><authors><author><keyname>Papanikolaou</keyname><forenames>Nick</forenames></author></authors><title>Logic Column 13: Reasoning Formally about Quantum Systems: An Overview</title><categories>cs.LO</categories><comments>17 pages</comments><acm-class>F.4.1; F.3.1</acm-class><journal-ref>SIGACT News, 36(3), pp. 51-66, 2005</journal-ref><abstract>  This article is intended as an introduction to the subject of quantum logic,
and as a brief survey of the relevant literature. Also discussed here are
logics for specification and analysis of quantum information systems, in
particular, recent work by P. Mateus and A. Sernadas, and also by R. van der
Meyden and M. Patra. Overall, our objective is to provide a high-level
presentation of the logical aspects of quantum theory. Mateus' and Sernadas'
EQPL logic is illustrated with a small example, namely the state of an
entangled pair of qubits. The &quot;KT&quot; logic of van der Meyden and Patra is
demonstrated briefly in the context of the B92 protocol for quantum key
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508006</id><created>2005-08-01</created><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Kaufmann</keyname><forenames>Michael</forenames></author><author><keyname>Kroeller</keyname><forenames>Alexander</forenames></author><author><keyname>Lehmann</keyname><forenames>Katharina</forenames></author></authors><title>A New Approach for Boundary Recognition in Geometric Sensor Networks</title><categories>cs.DS cs.DC</categories><comments>4 pages, 5 figures, Latex, to appear in Canadian Conference on
  Computational Geometry (CCCG 2005)</comments><acm-class>C.2.1; F.2.2; G.3</acm-class><abstract>  We describe a new approach for dealing with the following central problem in
the self-organization of a geometric sensor network: Given a polygonal region
R, and a large, dense set of sensor nodes that are scattered uniformly at
random in R. There is no central control unit, and nodes can only communicate
locally by wireless radio to all other nodes that are within communication
radius r, without knowing their coordinates or distances to other nodes. The
objective is to develop a simple distributed protocol that allows nodes to
identify themselves as being located near the boundary of R and form connected
pieces of the boundary. We give a comparison of several centrality measures
commonly used in the analysis of social networks and show that restricted
stress centrality is particularly suited for geometric networks; we provide
mathematical as well as experimental evidence for the quality of this measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508007</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508007</id><created>2005-08-01</created><updated>2010-12-27</updated><authors><author><keyname>Harringer</keyname><forenames>Manfred</forenames></author></authors><title>Regularity of Position Sequences</title><categories>cs.CV cs.AI cs.LG q-bio.NC</categories><comments>14 pages</comments><acm-class>I.5.1; I.6.8; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A person is given a numbered sequence of positions on a sheet of paper. The
person is asked, &quot;Which will be the next (or the next after that) position?&quot;
Everyone has an opinion as to how he or she would proceed. There are regular
sequences for which there is general agreement on how to continue. However,
there are less regular sequences for which this assessment is less certain.
There are sequences for which every continuation is perceived to be arbitrary.
I would like to present a mathematical model that reflects these opinions and
perceptions with the aid of a valuation function. It is necessary to apply a
rich set of invariant features of position sequences to ensure the quality of
this model. All other properties of the model are arbitrary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508008</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508008</id><created>2005-08-02</created><updated>2005-11-08</updated><authors><author><keyname>Kondo</keyname><forenames>Kentaro</forenames></author></authors><title>The accurate optimal-success/error-rate calculations applied to the
  realizations of the reliable and short-period integer ambiguity resolution in
  carrier-phase GPS/GNSS positioning</title><categories>cs.IT math.IT</categories><comments>LaTeX, 17 pages, 7 figures. Submitted to IEEE Transactions on
  Information Theory</comments><abstract>  The maximum-marginal-a-posteriori success rate of statistical decision under
multivariate Gaussian error distribution on an integer lattice is almost
rigorously calculated by using union-bound approximation and Monte Carlo
integration. These calculations are applied to the revelation of the various
possible realizations of the reliable and short-period integer ambiguity
resolution in precise carrier-phase relative positioning by GPS/GNSS. The
theoretical foundation and efficient methodology are systematically developed,
and two types of the enhancement of union-bound approximation are proposed and
examined.
  The results revealed include an extremely high reliability under the
condition of accurate carrier-phase measurements and a large number of visible
satellites, its heavy degradation caused by the slight amount of differentiated
ionospheric delays due to the nonvanishing baseline length between rover and
reference receivers, and the advantages of the use of the multiple carrier
frequencies. The succeeding initialization of the integer ambiguities is shown
to overcome the disadvantageous condition of the nonvanishing baseline length
effectively due to the reasonably assumed temporal and spatial constancy of
differentiated ionospheric delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508009</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508009</id><created>2005-08-01</created><authors><author><keyname>Hsu</keyname><forenames>Wei-jen</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>IMPACT: Investigation of Mobile-user Patterns Across University Campuses
  using WLAN Trace Analysis</title><categories>cs.NI</categories><comments>16 pages, 31 figures</comments><acm-class>C.2.1</acm-class><abstract>  We conduct the most comprehensive study of WLAN traces to date. Measurements
collected from four major university campuses are analyzed with the aim of
developing fundamental understanding of realistic user behavior in wireless
networks. Both individual user and inter-node (group) behaviors are
investigated and two classes of metrics are devised to capture the underlying
structure of such behaviors.
  For individual user behavior we observe distinct patterns in which most users
are 'on' for a small fraction of the time, the number of access points visited
is very small and the overall on-line user mobility is quite low. We clearly
identify categories of heavy and light users. In general, users exhibit high
degree of similarity over days and weeks.
  For group behavior, we define metrics for encounter patterns and friendship.
Surprisingly, we find that a user, on average, encounters less than 6% of the
network user population within a month, and that encounter and friendship
relations are highly asymmetric. We establish that number of encounters follows
a biPareto distribution, while friendship indexes follow an exponential
distribution. We capture the encounter graph using a small world model, the
characteristics of which reach steady state after only one day.
  We hope for our study to have a great impact on realistic modeling of network
usage and mobility patterns in wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508010</id><created>2005-08-02</created><authors><author><keyname>Kim</keyname><forenames>Yongjin</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>ATTENTION: ATTackEr traceback using MAC layer abNormality detecTION</title><categories>cs.NI</categories><abstract>  Denial-of-Service (DoS) and Distributed DoS (DDoS) attacks can cause serious
problems in wireless networks due to limited network and host resources.
Attacker traceback is a promising solution to take a proper countermeasure near
the attack origins, to discourage attackers from launching attacks, and for
forensics. However, attacker traceback in Mobile Ad-hoc Networks (MANETs) is a
challenging problem due to the dynamic topology, and limited network resources.
It is especially difficult to trace back attacker(s) when they are moving to
avoid traceback. In this paper, we introduce the ATTENTION protocol framework,
which pays special attention to MAC layer abnormal activity under attack.
ATTENTION consists of three classes, namely, coarse-grained traceback,
fine-grained traceback and spatio-temporal fusion architecture. For
energy-efficient attacker searching in MANETs, we also utilize small-world
model. Our simulation analysis shows 79% of success rate in DoS attacker
traceback with coarse-grained attack signature. In addition, with fine-grained
attack signature, it shows 97% of success rate in DoS attacker traceback and
83% of success rate in DDoS attacker traceback. We also show that ATTENTION has
robustness against node collusion and mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508011</id><created>2005-08-02</created><authors><author><keyname>Ogawa</keyname><forenames>Kazuto</forenames></author><author><keyname>Hanaoka</keyname><forenames>Goichiro</forenames></author><author><keyname>Imai</keyname><forenames>Hideki</forenames></author></authors><title>A Secure Traitor Tracing Scheme against Key Exposure</title><categories>cs.CR</categories><comments>5 pages, IEEE International Symposium on Information Theory 2005
  (ISIT 2005)</comments><abstract>  Copyright protection is a major issue in distributing digital content. On the
other hand, improvements to usability are sought by content users. In this
paper, we propose a secure {\it traitor tracing scheme against key exposure
(TTaKE)} which contains the properties of both a traitor tracing scheme and a
forward secure public key cryptosystem. Its structure fits current digital
broadcasting systems and it may be useful in preventing traitors from making
illegal decoders and in minimizing the damage from accidental key exposure. It
can improve usability through these properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508012</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508012</id><created>2005-08-02</created><authors><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Heusdens</keyname><forenames>Richard</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>n-Channel Asymmetric Multiple-Description Lattice Vector Quantization</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  We present analytical expressions for optimal entropy-constrained
multiple-description lattice vector quantizers which, under high-resolutions
assumptions, minimize the expected distortion for given packet-loss
probabilities. We consider the asymmetric case where packet-loss probabilities
and side entropies are allowed to be unequal and find optimal quantizers for
any number of descriptions in any dimension. We show that the normalized second
moments of the side-quantizers are given by that of an $L$-dimensional sphere
independent of the choice of lattices. Furthermore, we show that the optimal
bit-distribution among the descriptions is not unique. In fact, within certain
limits, bits can be arbitrarily distributed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508013</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508013</id><created>2005-08-02</created><authors><author><keyname>Yasunaga</keyname><forenames>Kenji</forenames></author><author><keyname>Fujiwara</keyname><forenames>Toru</forenames></author></authors><title>Relations between the Local Weight Distributions of a Linear Block Code,
  Its Extended Code, and Its Even Weight Subcode</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures. To appear in the Proceedings of IEEE
  International Symposium on Information Theory, Sept. 4-9, 2005, Adelaide,
  Australia</comments><abstract>  Relations between the local weight distributions of a binary linear code, its
extended code, and its even weight subcode are presented. In particular, for a
code of which the extended code is transitive invariant and contains only
codewords with weight multiples of four, the local weight distribution can be
obtained from that of the extended code. Using the relations, the local weight
distributions of the $(127,k)$ primitive BCH codes for $k\leq50$, the
$(127,64)$ punctured third-order Reed-Muller, and their even weight subcodes
are obtained from the local weight distribution of the $(128,k)$ extended
primitive BCH codes for $k\leq50$ and the $(128,64)$ third-order Reed-Muller
code. We also show an approach to improve an algorithm for computing the local
weight distribution proposed before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508014</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508014</id><created>2005-08-02</created><authors><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>The Benefit of Thresholding in LP Decoding of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. 2005 IEEE International Symposium on Information
  Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  Consider data transmission over a binary-input additive white Gaussian noise
channel using a binary low-density parity-check code. We ask the following
question: Given a decoder that takes log-likelihood ratios as input, does it
help to modify the log-likelihood ratios before decoding? If we use an optimal
decoder then it is clear that modifying the log-likelihoods cannot possibly
help the decoder's performance, and so the answer is &quot;no.&quot; However, for a
suboptimal decoder like the linear programming decoder, the answer might be
&quot;yes&quot;: In this paper we prove that for certain interesting classes of
low-density parity-check codes and large enough SNRs, it is advantageous to
truncate the log-likelihood ratios before passing them to the linear
programming decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508015</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508015</id><created>2005-08-02</created><updated>2005-11-08</updated><authors><author><keyname>Bulygin</keyname><forenames>Stanislav</forenames></author></authors><title>Chosen-ciphertext attack on noncommutative Polly Cracker</title><categories>cs.IT cs.CR math.IT</categories><abstract>  We propose a chosen-ciphertext attack on recently presented noncommutative
variant of the well-known Polly Cracker cryptosystem. We show that if one
chooses parameters for this noncommutative Polly Cracker as initially proposed,
than the system should be claimed as insecure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508016</id><created>2005-08-02</created><authors><author><keyname>Lee</keyname><forenames>Jang-Won</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Calderbank</keyname><forenames>A. Robert</forenames></author></authors><title>Distributed Algorithms for Optimal Rate-Reliability Tradeoff in Networks</title><categories>cs.NI</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  The current framework of network utility maximization for distributed rate
allocation assumes fixed channel code rates. However, by adapting the physical
layer channel coding, different rate-reliability tradeoffs can be achieved on
each link and for each end user. Consider a network where each user has a
utility function that depends on both signal quality and data rate, and each
link may provide a `fatter' (`thinner') information `pipe' by allowing a higher
(lower) decoding error probability. We propose two distributed, pricing-based
algorithms to attain optimal rate-reliability tradeoff, with an interpretation
that each user provides its willingness to pay for reliability to the network
and the network feeds back congestion prices to users. The proposed algorithms
converge to a tradeoff point between rate and reliability, which is proved to
be globally optimal for codes with sufficiently large codeword lengths and user
utilities with sufficiently negative curvatures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508017</id><created>2005-08-02</created><authors><author><keyname>Pehcevski</keyname><forenames>Jovan</forenames><affiliation>RMIT</affiliation></author><author><keyname>Thom</keyname><forenames>James A.</forenames><affiliation>RMIT</affiliation></author><author><keyname>Vercoustre</keyname><forenames>Anne-Marie</forenames></author></authors><title>Enhancing Content-And-Structure Information Retrieval using a Native XML
  Database</title><categories>cs.IR</categories><proxy>ccsd inria-00000185</proxy><abstract>  Three approaches to content-and-structure XML retrieval are analysed in this
paper: first by using Zettair, a full-text information retrieval system; second
by using eXist, a native XML database, and third by using a hybrid XML
retrieval system that uses eXist to produce the final answers from likely
relevant articles retrieved by Zettair. INEX 2003 content-and-structure topics
can be classified in two categories: the first retrieving full articles as
final answers, and the second retrieving more specific elements within articles
as final answers. We show that for both topic categories our initial hybrid
system improves the retrieval effectiveness of a native XML database. For
ranking the final answer elements, we propose and evaluate a novel retrieval
model that utilises the structural relationships between the answer elements of
a native XML database and retrieves Coherent Retrieval Elements. The final
results of our experiments show that when the XML retrieval task focusses on
highly relevant elements our hybrid XML retrieval system with the Coherent
Retrieval Elements module is 1.8 times more effective than Zettair and 3 times
more effective than eXist, and yields an effective content-and-structure XML
retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508018</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508018</id><created>2005-08-02</created><authors><author><keyname>Boche</keyname><forenames>Holger</forenames></author><author><keyname>Pohl</keyname><forenames>Volker</forenames></author></authors><title>Spectral Factorization, Whitening- and Estimation Filter -- Stability,
  Smoothness Properties and FIR Approximation Behavior</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the IEEE International Symposium on
  Information Theory, Adelaide, Astralia, Sept. 4-9, 2005</comments><abstract>  A Wiener filter can be interpreted as a cascade of a whitening- and an
estimation filter. This paper gives a detailed investigates of the properties
of these two filters. Then the practical consequences for the overall Wiener
filter are ascertained. It is shown that if the given spectral densities are
smooth (Hoelder continuous) functions, the resulting Wiener filter will always
be stable and can be approximated arbitrarily well by a finite impulse response
(FIR) filter. Moreover, the smoothness of the spectral densities characterizes
how fast the FIR filter approximates the desired filter characteristic. If on
the other hand the spectral densities are continuous but not smooth enough, the
resulting Wiener filter may not be stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508019</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508019</id><created>2005-08-02</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Kiyavash</keyname><forenames>Negar</forenames></author><author><keyname>Teutsch</keyname><forenames>Jason</forenames></author><author><keyname>Vukobratovic</keyname><forenames>Dejan</forenames></author></authors><title>On the Minimal Pseudo-Codewords of Codes from Finite Geometries</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in Proc. 2005 IEEE International Symposium on Information
  Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  In order to understand the performance of a code under maximum-likelihood
(ML) decoding, it is crucial to know the minimal codewords. In the context of
linear programming (LP) decoding, it turns out to be necessary to know the
minimal pseudo-codewords. This paper studies the minimal codewords and minimal
pseudo-codewords of some families of codes derived from projective and
Euclidean planes. Although our numerical results are only for codes of very
modest length, they suggest that these code families exhibit an interesting
property. Namely, all minimal pseudo-codewords that are not multiples of a
minimal codeword have an AWGNC pseudo-weight that is strictly larger than the
minimum Hamming weight of the code. This observation has positive consequences
not only for LP decoding but also for iterative decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508020</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508020</id><created>2005-08-02</created><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>Capacity Gain from Transmitter and Receiver Cooperation</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  Capacity gain from transmitter and receiver cooperation are compared in a
relay network where the cooperating nodes are close together. When all nodes
have equal average transmit power along with full channel state information
(CSI), it is proved that transmitter cooperation outperforms receiver
cooperation, whereas the opposite is true when power is optimally allocated
among the nodes but only receiver phase CSI is available. In addition, when the
nodes have equal average power with receiver phase CSI only, cooperation is
shown to offer no capacity improvement over a non-cooperative scheme with the
same average network power. When the system is under optimal power allocation
with full CSI, the decode-and-forward transmitter cooperation rate is close to
its cut-set capacity upper bound, and outperforms compress-and-forward receiver
cooperation. Moreover, it is shown that full CSI is essential in transmitter
cooperation, while optimal power allocation is essential in receiver
cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508021</id><created>2005-08-02</created><authors><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author></authors><title>Toward Compact Interdomain Routing</title><categories>cs.NI</categories><abstract>  Despite prevailing concerns that the current Internet interdomain routing
system will not scale to meet the needs of the 21st century global Internet,
networking research has not yet led to the construction of a new routing
architecture with satisfactory and mathematically provable scalability
characteristics. Worse, continuing empirical trends of the existing routing and
topology structure of the Internet are alarming: the foundational principles of
the current routing and addressing architecture are an inherently bad match for
the naturally evolving structure of Internet interdomain topology. We are
fortunate that a sister discipline, theory of distributed computation, has
developed routing algorithms that offer promising potential for genuinely
scalable routing on realistic Internet-like topologies. Indeed, there are many
recent breakthroughs in the area of compact routing, which has been shown to
drastically outperform, in terms of efficiency and scalability, even the
boldest proposals developed in networking research. Many open questions remain,
but we believe the applicability of compact routing techniques to Internet
interdomain routing is a research area whose potential payoff for the future of
networking is too high to ignore.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508022</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508022</id><created>2005-08-02</created><authors><author><keyname>Tirkel</keyname><forenames>Andrew Z</forenames></author><author><keyname>Hall</keyname><forenames>Tom E</forenames></author></authors><title>Matrix Construction Using Cyclic Shifts of a Column</title><categories>cs.DM cs.CR cs.IT math.IT</categories><abstract>  This paper describes the synthesis of matrices with good correlation, from
cyclic shifts of pseudonoise columns. Optimum matrices result whenever the
shift sequence satisfies the constant difference property. Known shift
sequences with the constant (or almost constant) difference property are:
Quadratic (Polynomial) and Reciprocal Shift modulo prime, Exponential Shift,
Legendre Shift, Zech Logarithm Shift, and the shift sequences of some m-arrays.
We use these shift sequences to produce arrays for watermarking of digital
images. Matrices can also be unfolded into long sequences by diagonal unfolding
(with no deterioration in correlation) or row-by-row unfolding, with some
degradation in correlation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508023</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508023</id><created>2005-08-03</created><updated>2005-10-02</updated><authors><author><keyname>Veldhuizen</keyname><forenames>Todd L.</forenames></author></authors><title>Software Libraries and Their Reuse: Entropy, Kolmogorov Complexity,
  and Zipf's Law</title><categories>cs.SE cs.IT cs.PL math.IT</categories><acm-class>D.2.8; E.4; D.2.13</acm-class><journal-ref>Library-Centric Software Design (LCSD 2005), an OOPSLA 2005
  workshop</journal-ref><abstract>  We analyze software reuse from the perspective of information theory and
Kolmogorov complexity, assessing our ability to ``compress'' programs by
expressing them in terms of software components reused from libraries. A common
theme in the software reuse literature is that if we can only get the right
environment in place-- the right tools, the right generalizations, economic
incentives, a ``culture of reuse'' -- then reuse of software will soar, with
consequent improvements in productivity and software quality. The analysis
developed in this paper paints a different picture: the extent to which
software reuse can occur is an intrinsic property of a problem domain, and
better tools and culture can have only marginal impact on reuse rates if the
domain is inherently resistant to reuse. We define an entropy parameter $H \in
[0,1]$ of problem domains that measures program diversity, and deduce from this
upper bounds on code reuse and the scale of components with which we may work.
For ``low entropy'' domains with $H$ near 0, programs are highly similar to one
another and the domain is amenable to the Component-Based Software Engineering
(CBSE) dream of programming by composing large-scale components. For problem
domains with $H$ near 1, programs require substantial quantities of new code,
with only a modest proportion of an application comprised of reused,
small-scale components. Preliminary empirical results from Unix platforms
support some of the predictions of our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508024</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508024</id><created>2005-08-03</created><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author><author><keyname>Finger</keyname><forenames>Adolf</forenames></author></authors><title>New Codes for OFDM with Low PMEPR</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of IEEE International Symposium on
  Information Theory, Sept. 4-9, 2005, Adelaide, Australia</comments><abstract>  In this paper new codes for orthogonal frequency-division multiplexing (OFDM)
with tightly controlled peak-to-mean envelope power ratio (PMEPR) are proposed.
We identify a new family of sequences occuring in complementary sets and show
that such sequences form subsets of a new generalization of the Reed--Muller
codes. Contrarily to previous constructions we present a compact description of
such codes, which makes them suitable even for larger block lengths. We also
show that some previous constructions just occur as special cases in our
construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508025</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508025</id><created>2005-08-03</created><authors><author><keyname>Gy&#x151;ri</keyname><forenames>S&#xe1;ndor</forenames></author></authors><title>Signature coding for OR channel with asynchronous access</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  Signature coding for multiple access OR channel is considered. We prove that
in block asynchronous case the upper bound on the minimum code length
asymptotically is the same as in the case of synchronous access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508026</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508026</id><created>2005-08-03</created><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author><author><keyname>Finger</keyname><forenames>Adolf</forenames></author></authors><title>Simple Maximum-Likelihood Decoding of Generalized First-order
  Reed-Muller Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, accepted for publication in IEEE Communications Letters</comments><journal-ref>IEEE Commun. Lett., vol. 9, no. 10, pp. 912-914, Oct. 2005</journal-ref><abstract>  An efficient decoder for the generalized first-order Reed-Muller code
RM_q(1,m) is essential for the decoding of various block-coding schemes for
orthogonal frequency-division multiplexing with reduced peak-to-mean power
ratio. We present an efficient and simple maximum-likelihood decoding algorithm
for RM_q(1,m). It is shown that this algorithm has lower complexity than other
previously known maximum-likelihood decoders for RM_q(1,m).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508027</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508027</id><created>2005-08-03</created><authors><author><keyname>Dauwels</keyname><forenames>J.</forenames></author><author><keyname>Korl</keyname><forenames>S.</forenames></author><author><keyname>Loeliger</keyname><forenames>H. -A.</forenames></author></authors><title>Expectation maximization as message passing</title><categories>cs.IT cs.LG math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  Based on prior work by Eckford, it is shown how expectation maximization (EM)
may be viewed, and used, as a message passing algorithm in factor graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508028</id><created>2005-08-03</created><authors><author><keyname>Wu</keyname><forenames>Fang</forenames></author><author><keyname>Zhang</keyname><forenames>Zi</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Truth-telling Reservations</title><categories>cs.GT cond-mat.stat-mech cs.MA</categories><abstract>  We present a mechanism for reservations of bursty resources that is both
truthful and robust. It consists of option contracts whose pricing structure
induces users to reveal the true likelihoods that they will purchase a given
resource. Users are also allowed to adjust their options as their likelihood
changes. This scheme helps users save cost and the providers to plan ahead so
as to reduce the risk of under-utilization and overbooking. The mechanism
extracts revenue similar to that of a monopoly provider practicing temporal
pricing discrimination with a user population whose preference distribution is
known in advance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508029</id><created>2005-08-03</created><authors><author><keyname>Schneider</keyname><forenames>Johannes J.</forenames></author><author><keyname>Kirkpatrick</keyname><forenames>Scott</forenames></author></authors><title>Selfish vs. Unselfish Optimization of Network Creation</title><categories>cs.NI cs.AR cs.MA</categories><comments>16 pages, 6 figures</comments><doi>10.1088/1742-5468/2005/08/P08007</doi><abstract>  We investigate several variants of a network creation model: a group of
agents builds up a network between them while trying to keep the costs of this
network small. The cost function consists of two addends, namely (i) a constant
amount for each edge an agent buys and (ii) the minimum number of hops it takes
sending messages to other agents. Despite the simplicity of this model, various
complex network structures emerge depending on the weight between the two
addends of the cost function and on the selfish or unselfish behaviour of the
agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508030</id><created>2005-08-03</created><authors><author><keyname>Lentmaier</keyname><forenames>Michael</forenames></author><author><keyname>Sridharan</keyname><forenames>Arvind</forenames></author><author><keyname>Zigangirov</keyname><forenames>Kamil Sh.</forenames></author><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Terminated LDPC Convolutional Codes with Thresholds Close to Capacity</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  An ensemble of LDPC convolutional codes with parity-check matrices composed
of permutation matrices is considered. The convergence of the iterative belief
propagation based decoder for terminated convolutional codes in the ensemble is
analyzed for binary-input output-symmetric memoryless channels using density
evolution techniques. We observe that the structured irregularity in the Tanner
graph of the codes leads to significantly better thresholds when compared to
corresponding LDPC block codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508031</identifier>
 <datestamp>2011-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508031</id><created>2005-08-03</created><authors><author><keyname>Yard</keyname><forenames>Jon</forenames></author><author><keyname>Devetak</keyname><forenames>Igor</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author></authors><title>Capacity Theorems for Quantum Multiple Access Channels</title><categories>cs.IT math.IT quant-ph</categories><comments>5 pages. Conference version of quant-ph/0501045, to appear in the
  proceedings of the IEEE International Symposium on Information Theory,
  Adelaide, Australia, 2005</comments><journal-ref>Proceedings of the IEEE Symposium on Information Theory, Adelaide,
  pp. 884-888, 2005</journal-ref><doi>10.1109/ISIT.2005.1523464</doi><abstract>  We consider quantum channels with two senders and one receiver. For an
arbitrary such channel, we give multi-letter characterizations of two different
two-dimensional capacity regions. The first region characterizes the rates at
which it is possible for one sender to send classical information while the
other sends quantum information. The second region gives the rates at which
each sender can send quantum information. We give an example of a channel for
which each region has a single-letter description, concluding with a
characterization of the rates at which each user can simultaneously send
classical and quantum information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508032</id><created>2005-08-03</created><authors><author><keyname>Messie</keyname><forenames>Derek</forenames><affiliation>Syracuse University</affiliation></author><author><keyname>Oh</keyname><forenames>Jae C.</forenames><affiliation>Syracuse University</affiliation></author></authors><title>Polymorphic Self-* Agents for Stigmergic Fault Mitigation in Large-Scale
  Real-Time Embedded Systems</title><categories>cs.AI cs.MA</categories><comments>Fourth International Joint Conference on Autonomous Agents and
  Multi-Agent Systems (AAMAS), Utrecht, Netherlands, July, 2005</comments><abstract>  Organization and coordination of agents within large-scale, complex,
distributed environments is one of the primary challenges in the field of
multi-agent systems. A lot of interest has surfaced recently around self-*
(self-organizing, self-managing, self-optimizing, self-protecting) agents. This
paper presents polymorphic self-* agents that evolve a core set of roles and
behavior based on environmental cues. The agents adapt these roles based on the
changing demands of the environment, and are directly implementable in computer
systems applications. The design combines strategies from game theory,
stigmergy, and other biologically inspired models to address fault mitigation
in large-scale, real-time, distributed systems. The agents are embedded within
the individual digital signal processors of BTeV, a High Energy Physics
experiment consisting of 2500 such processors. Results obtained using a SWARM
simulation of the BTeV environment demonstrate the polymorphic character of the
agents, and show how this design exceeds performance and reliability metrics
obtained from comparable centralized, and even traditional decentralized
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508033</id><created>2005-08-03</created><authors><author><keyname>Mahadevan</keyname><forenames>Priya</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Fomenkov</keyname><forenames>Marina</forenames></author><author><keyname>Huffaker</keyname><forenames>Bradley</forenames></author><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author><author><keyname>Vahdat</keyname><forenames>Amin</forenames></author></authors><title>Lessons from Three Views of the Internet Topology</title><categories>cs.NI physics.soc-ph</categories><report-no>CAIDA-TR-2005-02</report-no><abstract>  Network topology plays a vital role in understanding the performance of
network applications and protocols. Thus, recently there has been tremendous
interest in generating realistic network topologies. Such work must begin with
an understanding of existing network topologies, which today typically consists
of a relatively small number of data sources. In this paper, we calculate an
extensive set of important characteristics of Internet AS-level topologies
extracted from the three data sources most frequently used by the research
community: traceroutes, BGP, and WHOIS. We find that traceroute and BGP
topologies are similar to one another but differ substantially from the WHOIS
topology. We discuss the interplay between the properties of the data sources
that result from specific data collection mechanisms and the resulting topology
views. We find that, among metrics widely considered, the joint degree
distribution appears to fundamentally characterize Internet AS-topologies: it
narrowly defines values for other important metrics. We also introduce an
evaluation criteria for the accuracy of topology generators and verify previous
observations that generators solely reproducing degree distributions cannot
capture the full spectrum of critical topological characteristics of any of the
three topologies. Finally, we release to the community the input topology
datasets, along with the scripts and output of our calculations. This
supplement should enable researchers to validate their models against real data
and to make more informed selection of topology data sources for their specific
needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508034</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508034</id><created>2005-08-04</created><authors><author><keyname>Arikan</keyname><forenames>Erdal</forenames></author></authors><title>Channel combining and splitting for cutoff rate improvement</title><categories>cs.IT math.IT</categories><comments>5 pages, 7 figures, 2005 IEEE International Symposium on Information
  Theory, Adelaide, Sept. 4-9, 2005</comments><abstract>  The cutoff rate $R_0(W)$ of a discrete memoryless channel (DMC) $W$ is often
used as a figure of merit, alongside the channel capacity $C(W)$. Given a
channel $W$ consisting of two possibly correlated subchannels $W_1$, $W_2$, the
capacity function always satisfies $C(W_1)+C(W_2) \le C(W)$, while there are
examples for which $R_0(W_1)+R_0(W_2) &gt; R_0(W)$. This fact that cutoff rate can
be ``created'' by channel splitting was noticed by Massey in his study of an
optical modulation system modeled as a $M$'ary erasure channel. This paper
demonstrates that similar gains in cutoff rate can be achieved for general
DMC's by methods of channel combining and splitting. Relation of the proposed
method to Pinsker's early work on cutoff rate improvement and to Imai-Hirakawa
multi-level coding are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508035</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508035</id><created>2005-08-04</created><authors><author><keyname>Naydenova</keyname><forenames>Irina</forenames></author><author><keyname>Klove</keyname><forenames>Torleiv</forenames></author></authors><title>Codes for error detection, good or not good</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><acm-class>E.4</acm-class><abstract>  Linear codes for error detection on a q-ary symmetric channel are studied. It
is shown that for given dimension k and minimum distance d, there exists a
value \mu(d,k) such that if C is a code of length n &gt;= \mu(d,k), then neither C
nor its dual are good for error detection. For d &gt;&gt; k or k &lt;&lt; d good
approximations for \mu(d,k) are given. A generalization to non-linear codes is
also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508036</id><created>2005-08-04</created><updated>2005-08-09</updated><authors><author><keyname>Despeyroux</keyname><forenames>Thierry</forenames></author><author><keyname>Lechevallier</keyname><forenames>Yves</forenames></author><author><keyname>Trousse</keyname><forenames>Brigitte</forenames></author><author><keyname>Vercoustre</keyname><forenames>Anne-Marie</forenames></author></authors><title>Exp\'{e}riences de classification d'une collection de documents XML de
  structure homog\`{e}ne</title><categories>cs.IR</categories><comments>Cette version corrige des erreurs dans le nom de 2 auteurs cites dans
  la bibliographie</comments><proxy>ccsd inria-00000186</proxy><journal-ref>Dans 5\`{e}me Journ\'{e}es d' Extraction et de Gestion des
  Connaissances (EGC 2005)</journal-ref><abstract>  This paper presents some experiments in clustering homogeneous XMLdocuments
to validate an existing classification or more generally anorganisational
structure. Our approach integrates techniques for extracting knowledge from
documents with unsupervised classification (clustering) of documents. We focus
on the feature selection used for representing documents and its impact on the
emerging classification. We mix the selection of structured features with fine
textual selection based on syntactic characteristics.We illustrate and evaluate
this approach with a collection of Inria activity reports for the year 2003.
The objective is to cluster projects into larger groups (Themes), based on the
keywords or different chapters of these activity reports. We then compare the
results of clustering using different feature selections, with the official
theme structure used by Inria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508037</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508037</id><created>2005-08-04</created><updated>2008-10-08</updated><authors><author><keyname>Kalapala</keyname><forenames>Vamsi</forenames></author><author><keyname>Moore</keyname><forenames>Cris</forenames></author></authors><title>The Phase Transition in Exact Cover</title><categories>cs.CC</categories><comments>9 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study EC3, a variant of Exact Cover which is equivalent to Positive 1-in-3
SAT. Random instances of EC3 were recently used as benchmarks for simulations
of an adiabatic quantum algorithm. Empirical results suggest that EC3 has a
phase transition from satisfiability to unsatisfiability when the number of
clauses per variable r exceeds some threshold r* ~= 0.62 +- 0.01. Using the
method of differential equations, we show that if r &lt;= 0.546 w.h.p. a random
instance of EC3 is satisfiable. Combined with previous results this limits the
location of the threshold, if it exists, to the range 0.546 &lt; r* &lt; 0.644.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508038</id><created>2005-08-04</created><authors><author><keyname>Burger</keyname><forenames>John Robert</forenames></author></authors><title>Quantum Algorithm Processor For Finding Exact Divisors</title><categories>cs.AR</categories><acm-class>B.7.1; C.1.2</acm-class><abstract>  Wiring diagrams are given for a quantum algorithm processor in CMOS to
compute, in parallel, all divisors of an n-bit integer. Lines required in a
wiring diagram are proportional to n. Execution time is proportional to the
square of n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508039</identifier>
 <datestamp>2012-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508039</id><created>2005-08-04</created><updated>2012-06-14</updated><authors><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Pakzad</keyname><forenames>Payam</forenames></author><author><keyname>Kakhbod</keyname><forenames>Ali</forenames></author></authors><title>Tight Bounds on the Redundancy of Huffman Codes</title><categories>cs.IT math.IT</categories><comments>23 pages, 7 figures, accepted for publication in IEEE Transaction on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the redundancy of Huffman codes. In particular, we
consider sources for which the probability of one of the source symbols is
known. We prove a conjecture of Ye and Yeung regarding the upper bound on the
redundancy of such Huffman codes, which yields in a tight upper bound. We also
derive a tight lower bound for the redundancy under the same assumption.
  We further apply the method introduced in this paper to other related
problems. It is shown that several other previously known bounds with different
constraints follow immediately from our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508040</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508040</id><created>2005-08-04</created><authors><author><keyname>Cunha</keyname><forenames>Daniel C.</forenames></author><author><keyname>Portugheis</keyname><forenames>Jaime</forenames></author></authors><title>Bounds on the Capacity of the Blockwise Noncoherent APSK-AWGN Channels</title><categories>cs.IT math.IT</categories><comments>4 pages, 5 figures, to appear in Proceedings of the 2005 IEEE
  International Symposium on Information Theory, Adelaide, Australia, September
  4-9, 2005</comments><abstract>  Capacity of M-ary Amplitude and Phase-Shift Keying(M-APSK) over an Additive
White Gaussian Noise(AWGN) channel that also introduces an unknown carrier
phase rotation is considered. The phase remains constant over a block of L
symbols and it is independent from block to block. Aiming to design codes with
equally probable symbols, uniformly distributed channel inputs are assumed.
Based on results of Peleg and Shamai for M-ary Phase Shift Keying(M-PSK)
modulation, easily computable upper and lower bounds on the effective M-APSK
capacity are derived. For moderate M and L and a broad range of Signal-to-Noise
Ratios(SNR's), the bounds come close together. As in the case of M-PSK
modulation, for large L the coherent capacity is approached.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508041</id><created>2005-08-04</created><updated>2006-06-29</updated><authors><author><keyname>Jiang</keyname><forenames>Tian-Jian</forenames></author><author><keyname>Deng-Liu</keyname></author><author><keyname>Liu</keyname><forenames>Kang-min</forenames></author><author><keyname>Yang</keyname><forenames>Weizhong</forenames></author><author><keyname>Tan</keyname><forenames>Pek-tiong</forenames></author><author><keyname>Hsieh</keyname><forenames>Mengjuei</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-hsiang</forenames></author><author><keyname>Hsu</keyname><forenames>Wen-Lien</forenames></author></authors><title>OpenVanilla - A Non-Intrusive Plug-In Framework of Text Services</title><categories>cs.HC</categories><comments>4 pages</comments><acm-class>H.5.2</acm-class><abstract>  Input method (IM) is a sine qua non for text entry of many Asian languages,
but its potential applications on other languages remain under-explored. This
paper proposes a philosophy of input method design by seeing it as a
nonintrusive plug-in text service framework. Such design allows new
functionalities of text processing to be attached onto a running application
without any tweaking of code. We also introduce OpenVanilla, a cross-platform
framework that is designed with the above-mentioned model in mind. Frameworks
like OpenVanilla have shown that an input method can be more than just a text
entry tool: it offers a convenient way for developing various text service and
language tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508042</id><created>2005-08-04</created><updated>2006-06-29</updated><authors><author><keyname>Chiang</keyname><forenames>Tien-chien</forenames></author><author><keyname>Deng-Liu</keyname></author><author><keyname>Liu</keyname><forenames>Kang-min</forenames></author><author><keyname>Yang</keyname><forenames>Weizhong</forenames></author><author><keyname>Tan</keyname><forenames>Pek-tiong</forenames></author><author><keyname>Hsieh</keyname><forenames>Mengjuei</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-hsiang</forenames></author><author><keyname>Hsu</keyname><forenames>Wen-Lien</forenames></author></authors><title>OpenVanilla - A Non-Intrusive Plug-In Framework of Text Services</title><categories>cs.HC</categories><comments>This paper has been withdrawn</comments><acm-class>H.5.2</acm-class><abstract>  This paper has been withdrawn by the author, because it was merged into
cs.HC/0508041
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508043</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508043</id><created>2005-08-05</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Sequential Predictions based on Algorithmic Complexity</title><categories>cs.IT cs.LG math.IT</categories><comments>26 pages, LaTeX</comments><report-no>IDSIA-16-04</report-no><acm-class>G.3; G.1.2; I.2.6; E.4</acm-class><journal-ref>Journal of Computer and System Sciences, 72:1 (2006) pages 95-117</journal-ref><abstract>  This paper studies sequence prediction based on the monotone Kolmogorov
complexity Km=-log m, i.e. based on universal deterministic/one-part MDL. m is
extremely close to Solomonoff's universal prior M, the latter being an
excellent predictor in deterministic as well as probabilistic environments,
where performance is measured in terms of convergence of posteriors or losses.
Despite this closeness to M, it is difficult to assess the prediction quality
of m, since little is known about the closeness of their posteriors, which are
the important quantities for prediction. We show that for deterministic
computable environments, the &quot;posterior&quot; and losses of m converge, but rapid
convergence could only be shown on-sequence; the off-sequence convergence can
be slow. In probabilistic environments, neither the posterior nor the losses
converge, in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508044</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508044</id><created>2005-08-05</created><updated>2008-10-07</updated><authors><author><keyname>Seshia</keyname><forenames>Sanjit A.</forenames></author><author><keyname>Bryant</keyname><forenames>Randal E.</forenames></author></authors><title>Deciding Quantifier-Free Presburger Formulas Using Parameterized
  Solution Bounds</title><categories>cs.LO</categories><comments>26 pages</comments><acm-class>I.2.3; F.4.1; F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 2 (December
  19, 2005) lmcs:677</journal-ref><doi>10.2168/LMCS-1(2:6)2005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a formula in quantifier-free Presburger arithmetic, if it has a
satisfying solution, there is one whose size, measured in bits, is polynomially
bounded in the size of the formula. In this paper, we consider a special class
of quantifier-free Presburger formulas in which most linear constraints are
difference (separation) constraints, and the non-difference constraints are
sparse. This class has been observed to commonly occur in software
verification. We derive a new solution bound in terms of parameters
characterizing the sparseness of linear constraints and the number of
non-difference constraints, in addition to traditional measures of formula
size. In particular, we show that the number of bits needed per integer
variable is linear in the number of non-difference constraints and logarithmic
in the number and size of non-zero coefficients in them, but is otherwise
independent of the total number of linear constraints in the formula. The
derived bound can be used in a decision procedure based on instantiating
integer variables over a finite domain and translating the input
quantifier-free Presburger formula to an equi-satisfiable Boolean formula,
which is then checked using a Boolean satisfiability solver. In addition to our
main theoretical result, we discuss several optimizations for deriving tighter
bounds in practice. Empirical evidence indicates that our decision procedure
can greatly outperform other decision procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508045</id><created>2005-08-06</created><authors><author><keyname>Albrecht</keyname><forenames>Christoph</forenames></author><author><keyname>Kahng</keyname><forenames>Andrew B.</forenames></author><author><keyname>Mandoiu</keyname><forenames>Ion I.</forenames></author><author><keyname>Zelikovsky</keyname><forenames>Alexander</forenames></author></authors><title>Multicommodity Flow Algorithms for Buffered Global Routing</title><categories>cs.DS</categories><acm-class>B.7.2; F.2.2</acm-class><abstract>  In this paper we describe a new algorithm for buffered global routing
according to a prescribed buffer site map. Specifically, we describe a provably
good multi-commodity flow based algorithm that finds a global routing
minimizing buffer and wire congestion subject to given constraints on routing
area (wirelength and number of buffers) and sink delays. Our algorithm allows
computing the tradeoff curve between routing area and wire/buffer congestion
under any combination of delay and capacity constraints, and simultaneously
performs buffer/wire sizing, as well as layer and pin assignment. Experimental
results show that near-optimal results are obtained with a practical runtime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508046</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508046</id><created>2005-08-07</created><authors><author><keyname>Chaichanavong</keyname><forenames>Panu</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Relaxation Bounds on the Minimum Pseudo-Weight of Linear Block Codes</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  Just as the Hamming weight spectrum of a linear block code sheds light on the
performance of a maximum likelihood decoder, the pseudo-weight spectrum
provides insight into the performance of a linear programming decoder. Using
properties of polyhedral cones, we find the pseudo-weight spectrum of some
short codes. We also present two general lower bounds on the minimum
pseudo-weight. The first bound is based on the column weight of the
parity-check matrix. The second bound is computed by solving an optimization
problem. In some cases, this bound is more tractable to compute than previously
known bounds and thus can be applied to longer codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508047</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508047</id><created>2005-08-07</created><authors><author><keyname>Lun</keyname><forenames>Desmond S.</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>Further Results on Coding for Reliable Communication over Packet
  Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>5 pages; to appear in Proc. 2005 IEEE International Symposium on
  Information Theory (ISIT 2005)</comments><journal-ref>Proc. 2005 IEEE International Symposium on Information Theory
  (ISIT 2005), pages 1848-1852, September 2005</journal-ref><doi>10.1109/ISIT.2005.1523665</doi><abstract>  In &quot;On Coding for Reliable Communication over Packet Networks&quot; (Lun, Medard,
and Effros, Proc. 42nd Annu. Allerton Conf. Communication, Control, and
Computing, 2004), a capacity-achieving coding scheme for unicast or multicast
over lossy wireline or wireless packet networks is presented. We extend that
paper's results in two ways: First, we extend the network model to allow
packets received on a link to arrive according to any process with an average
rate, as opposed to the assumption of Poisson traffic with i.i.d. losses that
was previously made. Second, in the case of Poisson traffic with i.i.d. losses,
we derive error exponents that quantify the rate at which the probability of
error decays with coding delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508048</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508048</id><created>2005-08-08</created><updated>2005-12-08</updated><authors><author><keyname>Biernacka</keyname><forenames>Malgorzata</forenames></author><author><keyname>Biernacki</keyname><forenames>Dariusz</forenames></author><author><keyname>Danvy</keyname><forenames>Olivier</forenames></author></authors><title>An Operational Foundation for Delimited Continuations in&lt;br&gt;&lt;br&gt;
  the&lt;br&gt;&lt;br&gt;&lt;br&gt; CPS&lt;br&gt;&lt;br&gt; Hierarchy</title><categories>cs.LO cs.PL</categories><comments>39 pages</comments><acm-class>D.1.1; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 2 (November
  8, 2005) lmcs:1054</journal-ref><doi>10.2168/LMCS-1(2:5)2005</doi><abstract>  We present an abstract machine and a reduction semantics for the
lambda-calculus extended with control operators that give access to delimited
continuations in the CPS hierarchy. The abstract machine is derived from an
evaluator in continuation-passing style (CPS); the reduction semantics (i.e., a
small-step operational semantics with an explicit representation of evaluation
contexts) is constructed from the abstract machine; and the control operators
are the shift and reset family. We also present new applications of delimited
continuations in the CPS hierarchy: finding list prefixes and normalization by
evaluation for a hierarchical language of units and products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508049</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508049</id><created>2005-08-08</created><updated>2005-08-17</updated><authors><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Li</keyname><forenames>Wen-Ching W.</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Walker</keyname><forenames>Judy L.</forenames></author></authors><title>Characterizations of Pseudo-Codewords of LDPC Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>Submitted, August 2005</comments><abstract>  An important property of high-performance, low complexity codes is the
existence of highly efficient algorithms for their decoding. Many of the most
efficient, recent graph-based algorithms, e.g. message passing algorithms and
decoding based on linear programming, crucially depend on the efficient
representation of a code in a graphical model. In order to understand the
performance of these algorithms, we argue for the characterization of codes in
terms of a so called fundamental cone in Euclidean space which is a function of
a given parity check matrix of a code, rather than of the code itself. We give
a number of properties of this fundamental cone derived from its connection to
unramified covers of the graphical models on which the decoding algorithms
operate. For the class of cycle codes, these developments naturally lead to a
characterization of the fundamental polytope as the Newton polytope of the
Hashimoto edge zeta function of the underlying graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508050</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508050</id><created>2005-08-08</created><authors><author><keyname>Cover</keyname><forenames>T. M.</forenames></author><author><keyname>Chiang</keyname><forenames>M.</forenames></author></authors><title>Duality between channel capacity and rate distortion with two-sided
  state information</title><categories>cs.IT math.IT</categories><abstract>  We show that the duality between channel capacity and data compression is
retained when state information is available to the sender, to the receiver, to
both, or to neither. We present a unified theory for eight special cases of
channel capacity and rate distortion with state information, which also extends
existing results to arbitrary pairs of independent and identically distributed
(i.i.d.) correlated state information available at the sender and at the
receiver, respectively. In particular, the resulting general formula for
channel capacity assumes the same form as the generalized Wyner Ziv rate
distortion function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508051</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508051</id><created>2005-08-10</created><authors><author><keyname>Mietzner</keyname><forenames>Jan</forenames></author><author><keyname>Badri-Hoeher</keyname><forenames>Sabah</forenames></author><author><keyname>Land</keyname><forenames>Ingmar</forenames></author><author><keyname>Hoeher</keyname><forenames>Peter A.</forenames></author></authors><title>Trellis-Based Equalization for Sparse ISI Channels Revisited</title><categories>cs.IT math.IT</categories><comments>To be presented at the 2005 IEEE Int. Symp. Inform. Theory (ISIT
  2005), September 4-9, 2005, Adelaide, Australia</comments><abstract>  Sparse intersymbol-interference (ISI) channels are encountered in a variety
of high-data-rate communication systems. Such channels have a large channel
memory length, but only a small number of significant channel coefficients. In
this paper, trellis-based equalization of sparse ISI channels is revisited. Due
to the large channel memory length, the complexity of maximum-likelihood
detection, e.g., by means of the Viterbi algorithm (VA), is normally
prohibitive. In the first part of the paper, a unified framework based on
factor graphs is presented for complexity reduction without loss of optimality.
In this new context, two known reduced-complexity algorithms for sparse ISI
channels are recapitulated: The multi-trellis VA (M-VA) and the
parallel-trellis VA (P-VA). It is shown that the M-VA, although claimed, does
not lead to a reduced computational complexity. The P-VA, on the other hand,
leads to a significant complexity reduction, but can only be applied for a
certain class of sparse channels. In the second part of the paper, a unified
approach is investigated to tackle general sparse channels: It is shown that
the use of a linear filter at the receiver renders the application of standard
reduced-state trellis-based equalizer algorithms feasible, without significant
loss of optimality. Numerical results verify the efficiency of the proposed
receiver structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508052</id><created>2005-08-10</created><authors><author><keyname>Leone</keyname><forenames>Pierre</forenames></author><author><keyname>Powell</keyname><forenames>Olivier</forenames></author><author><keyname>Rolim</keyname><forenames>Jose</forenames></author></authors><title>Energy Optimal Data Propagation in Wireless Sensor Networks</title><categories>cs.DC</categories><comments>19 pages</comments><acm-class>C.2.1</acm-class><journal-ref>Journal of Parallel and Distributed Computing Volume 67, Issue 3 ,
  March 2007, Pages 302-317</journal-ref><doi>10.1016/j.jpdc.2006.10.007</doi><abstract>  We propose an algorithm which produces a randomized strategy reaching optimal
data propagation in wireless sensor networks (WSN).In [6] and [8], an energy
balanced solution is sought using an approximation algorithm. Our algorithm
improves by (a) when an energy-balanced solution does not exist, it still finds
an optimal solution (whereas previous algorithms did not consider this case and
provide no useful solution) (b) instead of being an approximation algorithm, it
finds the exact solution in one pass. We also provide a rigorous proof of the
optimality of our solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508053</id><created>2005-08-10</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames><affiliation>National Research Council of Canada</affiliation></author></authors><title>Measuring Semantic Similarity by Latent Relational Analysis</title><categories>cs.LG cs.CL cs.IR</categories><comments>6 pages, related work available at http://purl.org/peter.turney/</comments><report-no>NRC-48255</report-no><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Proceedings of the Nineteenth International Joint Conference on
  Artificial Intelligence (IJCAI-05), (2005), Edinburgh, Scotland, 1136-1141</journal-ref><abstract>  This paper introduces Latent Relational Analysis (LRA), a method for
measuring semantic similarity. LRA measures similarity in the semantic
relations between two pairs of words. When two pairs have a high degree of
relational similarity, they are analogous. For example, the pair cat:meow is
analogous to the pair dog:bark. There is evidence from cognitive science that
relational similarity is fundamental to many cognitive and linguistic tasks
(e.g., analogical reasoning). In the Vector Space Model (VSM) approach to
measuring relational similarity, the similarity between two pairs is calculated
by the cosine of the angle between the vectors that represent the two pairs.
The elements in the vectors are based on the frequencies of manually
constructed patterns in a large corpus. LRA extends the VSM approach in three
ways: (1) patterns are derived automatically from the corpus, (2) Singular
Value Decomposition is used to smooth the frequency data, and (3) synonyms are
used to reformulate word pairs. This paper describes the LRA algorithm and
experimentally compares LRA to VSM on two tasks, answering college-level
multiple-choice word analogy questions and classifying semantic relations in
noun-modifier expressions. LRA achieves state-of-the-art results, reaching
human-level performance on the analogy questions and significantly exceeding
VSM performance on both tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508054</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508054</id><created>2005-08-10</created><authors><author><keyname>Rachlin</keyname><forenames>Yaron</forenames></author><author><keyname>Negi</keyname><forenames>Rohit</forenames></author><author><keyname>Khosla</keyname><forenames>Pradeep</forenames></author></authors><title>Sensing Capacity for Markov Random Fields</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  This paper computes the sensing capacity of a sensor network, with sensors of
limited range, sensing a two-dimensional Markov random field, by modeling the
sensing operation as an encoder. Sensor observations are dependent across
sensors, and the sensor network output across different states of the
environment is neither identically nor independently distributed. Using a
random coding argument, based on the theory of types, we prove a lower bound on
the sensing capacity of the network, which characterizes the ability of the
sensor network to distinguish among environments with Markov structure, to
within a desired accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508055</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508055</id><created>2005-08-10</created><authors><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author></authors><title>DNA Codes that Avoid Secondary Structures</title><categories>cs.DM cs.IT math.IT</categories><comments>to appear in Proc. 2005 IEEE International Symposium on Information
  Theory, Adelaide, Australia, Sept. 4-9, 2005; 5 pages</comments><abstract>  In this paper, we consider the problem of designing DNA sequences (codewords)
for DNA storage systems and DNA computing that are unlikely to fold back onto
themselves to form undesirable secondary structures. The paper addresses both
the issue of enumerating the sequences with such properties and the problem of
practical code construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508056</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508056</id><created>2005-08-11</created><authors><author><keyname>Stay</keyname><forenames>Michael</forenames></author></authors><title>Very Simple Chaitin Machines for Concrete AIT</title><categories>cs.IT math.IT</categories><report-no>CDMTCS Report 265</report-no><journal-ref>Fundamenta Informaticae 68 (3) 2005. pp. 231--247</journal-ref><abstract>  In 1975, Chaitin introduced his celebrated Omega number, the halting
probability of a universal Chaitin machine, a universal Turing machine with a
prefix-free domain. The Omega number's bits are {\em algorithmically
random}--there is no reason the bits should be the way they are, if we define
``reason'' to be a computable explanation smaller than the data itself. Since
that time, only {\em two} explicit universal Chaitin machines have been
proposed, both by Chaitin himself.
  Concrete algorithmic information theory involves the study of particular
universal Turing machines, about which one can state theorems with specific
numerical bounds, rather than include terms like O(1). We present several new
tiny Chaitin machines (those with a prefix-free domain) suitable for the study
of concrete algorithmic information theory. One of the machines, which we call
Keraia, is a binary encoding of lambda calculus based on a curried lambda
operator. Source code is included in the appendices.
  We also give an algorithm for restricting the domain of blank-endmarker
machines to a prefix-free domain over an alphabet that does not include the
endmarker; this allows one to take many universal Turing machines and construct
universal Chaitin machines from them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508057</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508057</id><created>2005-08-11</created><authors><author><keyname>Rodrigues</keyname><forenames>M. R. D.</forenames></author><author><keyname>Chatzigeorgiou</keyname><forenames>I.</forenames></author><author><keyname>Wassell</keyname><forenames>I. J.</forenames></author><author><keyname>Carrasco</keyname><forenames>R.</forenames></author></authors><title>On the Performance of Turbo Codes in Quasi-Static Fading Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  In this paper, we investigate in detail the performance of turbo codes in
quasi-static fading channels both with and without antenna diversity. First, we
develop a simple and accurate analytic technique to evaluate the performance of
turbo codes in quasi-static fading channels. The proposed analytic technique
relates the frame error rate of a turbo code to the iterative decoder
convergence threshold, rather than to the turbo code distance spectrum.
Subsequently, we compare the performance of various turbo codes in quasi-static
fading channels. We show that, in contrast to the situation in the AWGN
channel, turbo codes with different interleaver sizes or turbo codes based on
RSC codes with different constraint lengths and generator polynomials exhibit
identical performance. Moreover, we also compare the performance of turbo codes
and convolutional codes in quasi-static fading channels under the condition of
identical decoding complexity. In particular, we show that turbo codes do not
outperform convolutional codes in quasi-static fading channels with no antenna
diversity; and that turbo codes only outperform convolutional codes in
quasi-static fading channels with antenna diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508058</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508058</id><created>2005-08-11</created><authors><author><keyname>Jegou</keyname><forenames>Herve</forenames></author><author><keyname>Guillemot</keyname><forenames>Christine</forenames></author></authors><title>Entropy coding with Variable Length Re-writing Systems</title><categories>cs.IT math.IT</categories><comments>6 pages, To appear in the proceedings of the 2005 IEEE International
  Symposium on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  This paper describes a new set of block source codes well suited for data
compression. These codes are defined by sets of productions rules of the form
a.l-&gt;b, where a in A represents a value from the source alphabet A and l, b are
-small- sequences of bits. These codes naturally encompass other Variable
Length Codes (VLCs) such as Huffman codes. It is shown that these codes may
have a similar or even a shorter mean description length than Huffman codes for
the same encoding and decoding complexity. A first code design method allowing
to preserve the lexicographic order in the bit domain is described. The
corresponding codes have the same mean description length (mdl) as Huffman
codes from which they are constructed. Therefore, they outperform from a
compression point of view the Hu-Tucker codes designed to offer the
lexicographic property in the bit domain. A second construction method allows
to obtain codes such that the marginal bit probability converges to 0.5 as the
sequence length increases and this is achieved even if the probability
distribution function is not known by the encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508059</identifier>
 <datestamp>2008-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508059</id><created>2005-08-11</created><updated>2008-12-27</updated><authors><author><keyname>Mitra</keyname><forenames>Arindam</forenames></author></authors><title>Honesty can be the best policy within quantum mechanics</title><categories>cs.CR</categories><comments>One of the referees (Phys. Rev. Lett.) observed that manuscript &quot;
  deserves to be widely read and analyzed&quot;. Acknowledgement is due</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Honesty has never been scientifically proved to be the best policy in any
case. It is pointed out that only honest person can prevent his dishonest
partner to bias the outcome of quantum coin tossing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508060</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508060</id><created>2005-08-11</created><authors><author><keyname>Gemelos</keyname><forenames>George</forenames></author><author><keyname>Sigurjonsson</keyname><forenames>Styrmir</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Algorithms for Discrete Denoising Under Channel Uncertainty</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Trans. on Signal Processing</comments><doi>10.1109/TSP.2006.874295</doi><abstract>  The goal of a denoising algorithm is to reconstruct a signal from its
noise-corrupted observations. Perfect reconstruction is seldom possible and
performance is measured under a given fidelity criterion. In a recent work, the
authors addressed the problem of denoising unknown discrete signals corrupted
by a discrete memoryless channel when the channel, rather than being completely
known, is only known to lie in some uncertainty set of possible channels. A
sequence of denoisers was derived for this case and shown to be asymptotically
optimal with respect to a worst-case criterion argued most relevant to this
setting. In the present work we address the implementation and complexity of
this denoiser for channels parametrized by a scalar, establishing its
practicality. We show that for symmetric channels, the problem can be mapped
into a convex optimization problem, which can be solved efficiently. We also
present empirical results suggesting the potential of these schemes to do well
in practice. A key component of our schemes is an estimator of the subset of
channels in the uncertainty set that are feasible in the sense of being able to
give rise to the noise-corrupted signal statistics for some channel input
distribution. We establish the efficiency of this estimator, both
algorithmically and experimentally. We also present a modification of the
recently developed discrete universal denoiser (DUDE) that assumes a channel
based on the said estimator, and show that, in practice, the resulting scheme
performs well. For concreteness, we focus on the binary alphabet case and
binary symmetric channels, but also discuss the extensions of the algorithms to
general finite alphabets and to general channels parameterized by a scalar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508061</id><created>2005-08-11</created><authors><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>SciBlog : A Tool for Scientific Collaboration</title><categories>cs.CY</categories><comments>4 figures, invited talk at the Workshop on Knowledge Management (6-9
  December 2004)</comments><report-no>FISIKALIPI-04013</report-no><journal-ref>Proceeding of the WKM 2004</journal-ref><abstract>  I describe a newly developed online scientific web-log (SciBlog). The online
facility consists of several moduls needed in a common and conventional
research activity. I show that this enables scientists around the world to
perform an online collaboration over the net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508062</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508062</id><created>2005-08-12</created><updated>2007-01-22</updated><authors><author><keyname>Ashikhmin</keyname><forenames>Alexei</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author></authors><title>Decoding of Expander Codes at Rates Close to Capacity</title><categories>cs.IT math.IT</categories><comments>Appears in IEEE Transactions on Information Theory, December 2006.
  The short version of this paper appears in the proceedings of the 2005 IEEE
  International Symposium on Information Theory, Adelaide, Australia, September
  4-9, 2005</comments><abstract>  The decoding error probability of codes is studied as a function of their
block length. It is shown that the existence of codes with a polynomially small
decoding error probability implies the existence of codes with an exponentially
small decoding error probability. Specifically, it is assumed that there exists
a family of codes of length N and rate R=(1-\epsilon)C (C is a capacity of a
binary symmetric channel), whose decoding probability decreases polynomially in
1/N. It is shown that if the decoding probability decreases sufficiently fast,
but still only polynomially fast in 1/N, then there exists another such family
of codes whose decoding error probability decreases exponentially fast in N.
Moreover, if the decoding time complexity of the assumed family of codes is
polynomial in N and 1/\epsilon, then the decoding time complexity of the
presented family is linear in N and polynomial in 1/\epsilon. These codes are
compared to the recently presented codes of Barg and Zemor, ``Error Exponents
of Expander Codes,'' IEEE Trans. Inform. Theory, 2002, and ``Concatenated
Codes: Serial and Parallel,'' IEEE Trans. Inform. Theory, 2005. It is shown
that the latter families can not be tuned to have exponentially decaying (in N)
error probability, and at the same time to have decoding time complexity linear
in N and polynomial in 1/\epsilon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508063</id><created>2005-08-12</created><authors><author><keyname>Dagenais</keyname><forenames>Michel R.</forenames><affiliation>Dept. of Computer Engineering, Ecole Polytechnique, Montreal, Canada</affiliation></author></authors><title>Disks, Partitions, Volumes and RAID Performance with the Linux Operating
  System</title><categories>cs.PF cs.OS</categories><abstract>  Block devices in computer operating systems typically correspond to disks or
disk partitions, and are used to store files in a filesystem. Disks are not the
only real or virtual device which adhere to the block accessible stream of
bytes block device model. Files, remote devices, or even RAM may be used as a
virtual disks. This article examines several common combinations of block
device layers used as virtual disks in the Linux operating system: disk
partitions, loopback files, software RAID, Logical Volume Manager, and Network
Block Devices. It measures their relative performance using different
filesystems: Ext2, Ext3, ReiserFS, JFS, XFS,NFS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508064</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508064</id><created>2005-08-12</created><updated>2005-10-21</updated><authors><author><keyname>Siti</keyname><forenames>Massimiliano</forenames></author><author><keyname>Fitz</keyname><forenames>Michael P.</forenames></author></authors><title>Layered Orthogonal Lattice Detector for Two Transmit Antenna
  Communications</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. of &quot;Forty-Third Annual Allerton Conference on
  Communication, Control, and Computing&quot; (Sept. 28th-30th 2005). 13 pages 2
  figures (4 plots)</comments><abstract>  A novel detector for multiple-input multiple-output (MIMO) communications is
presented. The algorithm belongs to the class of the lattice detectors, i.e. it
finds a reduced complexity solution to the problem of finding the closest
vector to the received observations. The algorithm achieves optimal
maximum-likelihood (ML) performance in case of two transmit antennas, at the
same time keeping a complexity much lower than the exhaustive search-based ML
detection technique. Also, differently from the state-of-art lattice detector
(namely sphere decoder), the proposed algorithm is suitable for a highly
parallel hardware architecture and for a reliable bit soft-output information
generation, thus making it a promising option for real-time high-data rate
transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508065</id><created>2005-08-12</created><authors><author><keyname>Bekaert</keyname><forenames>Jeroen</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Representing Digital Assets using MPEG-21 Digital Item Declaration</title><categories>cs.DL cs.AR</categories><comments>27 pages, accepted submission to the special edition on complex
  objects of the International Journal on Digital Libraries</comments><abstract>  Various XML-based approaches aimed at representing compound digital assets
have emerged over the last several years. Approaches that are of specific
relevance to the digital library community include the Metadata Encoding and
Transmission Standard (METS), the IMS Content Packaging XML Binding, and the
XML Formatted Data Units (XFDU) developed by CCSDS Panel 2. The MPEG-21 Digital
Item Declaration (MPEG-21 DID) is another standard specifying the
representation of digital assets in XML that, so far, has received little
attention in the digital library community. This article gives a brief insight
into the MPEG-21 standardization effort, highlights the major characteristics
of the MPEG-21 DID Abstract Model, and describes the MPEG-21 Digital Item
Declaration Language (MPEG-21 DIDL), an XML syntax for the representation of
digital assets based on the MPEG-21 DID Abstract Model. Also, it briefly
demonstrates the potential relevance of MPEG-21 DID to the digital library
community by describing its use in the aDORe repository environment at the
Research Library of the Los Alamos National Laboratory (LANL) for the
representation of digital assets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508066</id><created>2005-08-13</created><authors><author><keyname>Filippini-Fantoni</keyname><forenames>Silvia</forenames></author><author><keyname>Bowen</keyname><forenames>Jonathan P.</forenames></author></authors><title>Can Small Museums Develop Compelling, Educational and Accessible Web
  Resources? The Case of Accademia Carrara</title><categories>cs.MM cs.CY cs.DL cs.IR</categories><comments>14 pages, 6 figures</comments><acm-class>H.3.5; H.3.7; H.4.3; H.5.1; H.5.2; H.5.3; H.5.4; K.3.1; K.4.0</acm-class><journal-ref>In James Hemsley, Vito Cappellini and Gerd Stanke (eds.), EVA 2005
  London Conference Proceedings, University College London, UK, 25-29 July
  2005, pages 18.1-18.14. ISBN: 0-9543146-6-2</journal-ref><abstract>  Due to the lack of budget, competence, personnel and time, small museums are
often unable to develop compelling, educational and accessible web resources
for their permanent collections or temporary exhibitions. In an attempt to
prove that investing in these types of resources can be very fruitful even for
small institutions, we will illustrate the case of Accademia Carrara, a museum
in Bergamo, northern Italy, which, for a current temporary exhibition on
Cezanne and Renoir's masterpieces from the Paul Guillaume collection, developed
a series of multimedia applications, including an accessible website, rich in
content and educational material [www.cezannerenoir.it].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508067</id><created>2005-08-13</created><authors><author><keyname>Numerico</keyname><forenames>Teresa</forenames></author><author><keyname>Bowen</keyname><forenames>Jonathan P.</forenames></author></authors><title>Copyright and Promotion: Oxymoron or Opportunity?</title><categories>cs.CY cs.DL</categories><comments>10 pages, 0 figures</comments><acm-class>H.3.5; H.3.7; K.3.1; K.4.1; K.4.2; K.5.1; K.5.2</acm-class><journal-ref>In James Hemsley, Vito Cappellini and Gerd Stanke (eds.), EVA 2005
  London Conference Proceedings, University College London, UK, 25-29 July
  2005, pages 25.1-25.10. ISBN: 0-9543146-6-2</journal-ref><abstract>  Copyright in the cultural sphere can act as a barrier to the dissemination of
high-quality information. On the other hand it protects works of art that might
not be made available otherwise. This dichotomy makes the area of copyright
difficult, especially when it applies to the digital arena of the web where
copying is so easy and natural. Here we present a snapshot of the issues for
online copyright, with particular emphasis on the relevance to cultural
institutions. We concentrate on Europe and the US; as an example we include a
special section dedicated to the situation in Italy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508068</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508068</id><created>2005-08-14</created><authors><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Maneva</keyname><forenames>Elitza</forenames></author></authors><title>Lossy source encoding via message-passing and decimation over
  generalized codewords of LDGM codes</title><categories>cs.IT cs.AI math.IT</categories><comments>To appear in the Proceedings of the International Symposium on
  Information Theory, Adelaide, Australia; September, 2005</comments><abstract>  We describe message-passing and decimation approaches for lossy source coding
using low-density generator matrix (LDGM) codes. In particular, this paper
addresses the problem of encoding a Bernoulli(0.5) source: for randomly
generated LDGM codes with suitably irregular degree distributions, our methods
yield performance very close to the rate distortion limit over a range of
rates. Our approach is inspired by the survey propagation (SP) algorithm,
originally developed by Mezard et al. for solving random satisfiability
problems. Previous work by Maneva et al. shows how SP can be understood as
belief propagation (BP) for an alternative representation of satisfiability
problems. In analogy to this connection, our approach is to define a family of
Markov random fields over generalized codewords, from which local
message-passing rules can be derived in the standard way. The overall source
encoding method is based on message-passing, setting a subset of bits to their
preferred values (decimation), and reducing the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508069</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508069</id><created>2005-08-15</created><updated>2006-02-22</updated><authors><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Real Hypercomputation and Continuity</title><categories>cs.LO cs.CC</categories><comments>previous version (extended abstract) has appeared in pp.562-571 of
  &quot;Proc. 1st Conference on Computability in Europe&quot; (CiE'05), Springer LNCS
  vol.3526</comments><acm-class>F.1.1; F.1.2; F.4.1</acm-class><journal-ref>pp.177-206 in Theory of Computing Systems vol.41 (2007)</journal-ref><doi>10.1007/s00224-006-1343-6</doi><abstract>  By the sometimes so-called 'Main Theorem' of Recursive Analysis, every
computable real function is necessarily continuous. We wonder whether and which
kinds of HYPERcomputation allow for the effective evaluation of also
discontinuous f:R-&gt;R. More precisely the present work considers the following
three super-Turing notions of real function computability:
  * relativized computation; specifically given oracle access to the Halting
Problem 0' or its jump 0'';
  * encoding real input x and/or output y=f(x) in weaker ways also related to
the Arithmetic Hierarchy;
  * non-deterministic computation.
  It turns out that any f:R-&gt;R computable in the first or second sense is still
necessarily continuous whereas the third type of hypercomputation does provide
the required power to evaluate for instance the discontinuous sign function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508070</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508070</id><created>2005-08-15</created><authors><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Jaakkola</keyname><forenames>Tommi S.</forenames></author><author><keyname>Willsky</keyname><forenames>Alan S.</forenames></author></authors><title>MAP estimation via agreement on (hyper)trees: Message-passing and linear
  programming</title><categories>cs.IT cs.AI math.IT</categories><comments>Presented in part at the Allerton Conference on Communication,
  Computing and Control in October 2002. Full journal version appear in the
  IEEE Transactions on Information Theory, November 2005</comments><abstract>  We develop and analyze methods for computing provably optimal {\em maximum a
posteriori} (MAP) configurations for a subclass of Markov random fields defined
on graphs with cycles. By decomposing the original distribution into a convex
combination of tree-structured distributions, we obtain an upper bound on the
optimal value of the original problem (i.e., the log probability of the MAP
assignment) in terms of the combined optimal values of the tree problems. We
prove that this upper bound is tight if and only if all the tree distributions
share an optimal configuration in common. An important implication is that any
such shared configuration must also be a MAP configuration for the original
distribution. Next we develop two approaches to attempting to obtain tight
upper bounds: (a) a {\em tree-relaxed linear program} (LP), which is derived
from the Lagrangian dual of the upper bounds; and (b) a {\em tree-reweighted
max-product message-passing algorithm} that is related to but distinct from the
max-product algorithm. In this way, we establish a connection between a certain
LP relaxation of the mode-finding problem, and a reweighted form of the
max-product (min-sum) message-passing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508071</id><created>2005-08-15</created><authors><author><keyname>O'Donnell</keyname><forenames>Ryan</forenames></author><author><keyname>Saks</keyname><forenames>Michael</forenames></author><author><keyname>Schramm</keyname><forenames>Oded</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author></authors><title>Every decision tree has an influential variable</title><categories>cs.CC cs.DM math.PR</categories><comments>This paper is posted by permission from the IEEE Computer Society. To
  appear in FOCS 2005</comments><abstract>  We prove that for any decision tree calculating a boolean function
$f:\{-1,1\}^n\to\{-1,1\}$, \[ \Var[f] \le \sum_{i=1}^n \delta_i \Inf_i(f), \]
where $\delta_i$ is the probability that the $i$th input variable is read and
$\Inf_i(f)$ is the influence of the $i$th variable on $f$. The variance,
influence and probability are taken with respect to an arbitrary product
measure on $\{-1,1\}^n$. It follows that the minimum depth of a decision tree
calculating a given balanced function is at least the reciprocal of the largest
influence of any input variable. Likewise, any balanced boolean function with a
decision tree of depth $d$ has a variable with influence at least
$\frac{1}{d}$. The only previous nontrivial lower bound known was $\Omega(d
2^{-d})$. Our inequality has many generalizations, allowing us to prove
influence lower bounds for randomized decision trees, decision trees on
arbitrary product probability spaces, and decision trees with non-boolean
outputs. As an application of our results we give a very easy proof that the
randomized query complexity of nontrivial monotone graph properties is at least
$\Omega(v^{4/3}/p^{1/3})$, where $v$ is the number of vertices and $p \leq
\half$ is the critical threshold probability. This supersedes the milestone
$\Omega(v^{4/3})$ bound of Hajnal and is sometimes superior to the best known
lower bounds of Chakrabarti-Khot and Friedgut-Kahn-Wigderson.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508072</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508072</id><created>2005-08-16</created><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author><author><keyname>Wiechman</keyname><forenames>Gil</forenames></author></authors><title>On Achievable Rates and Complexity of LDPC Codes for Parallel Channels
  with Application to Puncturing</title><categories>cs.IT math.IT</categories><comments>35 pages, 1 figure. Submitted to IEEE Trans. on Information Theory</comments><abstract>  This paper considers the achievable rates and decoding complexity of
low-density parity-check (LDPC) codes over statistically independent parallel
channels. The paper starts with the derivation of bounds on the conditional
entropy of the transmitted codeword given the received sequence at the output
of the parallel channels; the component channels are considered to be
memoryless, binary-input, and output-symmetric (MBIOS). These results serve for
the derivation of an upper bound on the achievable rates of ensembles of LDPC
codes under optimal maximum-likelihood (ML) decoding when their transmission
takes place over parallel MBIOS channels. The paper relies on the latter bound
for obtaining upper bounds on the achievable rates of ensembles of randomly and
intentionally punctured LDPC codes over MBIOS channels. The paper also provides
a lower bound on the decoding complexity (per iteration) of ensembles of LDPC
codes under message-passing iterative decoding over parallel MBIOS channels;
the bound is given in terms of the gap between the rate of these codes for
which reliable communication is achievable and the channel capacity. The paper
presents a diagram which shows interconnections between the theorems introduced
in this paper and some other previously reported results. The setting which
serves for the derivation of the bounds on the achievable rates and decoding
complexity is general, and the bounds can be applied to other scenarios which
can be treated as different forms of communication over parallel channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508073</id><created>2005-08-16</created><authors><author><keyname>Poland</keyname><forenames>Jan</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Universal Learning of Repeated Matrix Games</title><categories>cs.LG cs.AI</categories><comments>16 LaTeX pages, 8 eps figures</comments><report-no>IDSIA-18-05</report-no><journal-ref>Proc. 15th Annual Machine Learning Conf. of Belgium and The
  Netherlands (Benelearn 2006) pages 7-14</journal-ref><abstract>  We study and compare the learning dynamics of two universal learning
algorithms, one based on Bayesian learning and the other on prediction with
expert advice. Both approaches have strong asymptotic performance guarantees.
When confronted with the task of finding good long-term strategies in repeated
2x2 matrix games, they behave quite differently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508074</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508074</id><created>2005-08-16</created><authors><author><keyname>Mammen</keyname><forenames>James</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>Throughput and Delay in Random Wireless Networks with Restricted
  Mobility</title><categories>cs.IT cs.NI math.IT</categories><comments>14 pages, 4 figures, submitted to IEEE Transactions on Information
  Theory</comments><acm-class>C.2.1</acm-class><abstract>  Grossglauser and Tse (2001) introduced a mobile random network model where
each node moves independently on a unit disk according to a stationary uniform
distribution and showed that a throughput of $\Theta(1)$ is achievable. El
Gamal, Mammen, Prabhakar and Shah (2004) showed that the delay associated with
this throughput scales as $\Theta(n\log n)$, when each node moves according to
an independent random walk. In a later work, Diggavi, Grossglauser and Tse
(2002) considered a random network on a sphere with a restricted mobility
model, where each node moves along a randomly chosen great circle on the unit
sphere. They showed that even with this one-dimensional restriction on
mobility, constant throughput scaling is achievable. Thus, this particular
mobility restriction does not affect the throughput scaling. This raises the
question whether this mobility restriction affects the delay scaling.
  This paper studies the delay scaling at $\Theta(1)$ throughput for a random
network with restricted mobility. First, a variant of the scheme presented by
Diggavi, Grossglauser and Tse (2002) is presented and it is shown to achieve
$\Theta(1)$ throughput using different (and perhaps simpler) techniques. The
exact order of delay scaling for this scheme is determined, somewhat
surprisingly, to be of $\Theta(n\log n)$, which is the same as that without the
mobility restriction. Thus, this particular mobility restriction \emph{does
not} affect either the maximal throughput scaling or the corresponding delay
scaling of the network. This happens because under this 1-D restriction, each
node is in the proximity of every other node in essentially the same manner as
without this restriction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508075</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508075</id><created>2005-08-16</created><authors><author><keyname>Standish</keyname><forenames>Russell K.</forenames></author></authors><title>Complexity of Networks</title><categories>cs.IT math.IT</categories><comments>Accepted for Australian Conference on Artificial Life (ACAL05). To
  appear in Advances in Natural Computation (World Scientific)</comments><acm-class>G.2.2</acm-class><journal-ref>in Recent Advances in Artificial Life, Abbass et al. (eds) (World
  Scientific: Singapore) p253 (2005).</journal-ref><abstract>  Network or graph structures are ubiquitous in the study of complex systems.
Often, we are interested in complexity trends of these system as it evolves
under some dynamic. An example might be looking at the complexity of a food web
as species enter an ecosystem via migration or speciation, and leave via
extinction.
  In this paper, a complexity measure of networks is proposed based on the {\em
complexity is information content} paradigm. To apply this paradigm to any
object, one must fix two things: a representation language, in which strings of
symbols from some alphabet describe, or stand for the objects being considered;
and a means of determining when two such descriptions refer to the same object.
With these two things set, the information content of an object can be computed
in principle from the number of equivalent descriptions describing a particular
object.
  I propose a simple representation language for undirected graphs that can be
encoded as a bitstring, and equivalence is a topological equivalence. I also
present an algorithm for computing the complexity of an arbitrary undirected
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508076</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508076</id><created>2005-08-16</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Myopic Coding in Multiple Relay Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><journal-ref>Proceedings of the 2005 IEEE International Symposium on
  Information Theory (ISIT 2005), Adelaide Convention Centre, Adelaide,
  Australia, pp. 1091-1095, Sep. 4-9 2005.</journal-ref><doi>10.1109/ISIT.2005.1523508</doi><abstract>  In this paper, we investigate achievable rates for data transmission from
sources to sinks through multiple relay networks. We consider myopic coding, a
constrained communication strategy in which each node has only a local view of
the network, meaning that nodes can only transmit to and decode from
neighboring nodes. We compare this with omniscient coding, in which every node
has a global view of the network and all nodes can cooperate. Using Gaussian
channels as examples, we find that when the nodes transmit at low power, the
rates achievable with two-hop myopic coding are as large as that under
omniscient coding in a five-node multiple relay channel and close to that under
omniscient coding in a six-node multiple relay channel. These results suggest
that we may do local coding and cooperation without compromising much on the
transmission rate. Practically, myopic coding schemes are more robust to
topology changes because encoding and decoding at a node are not affected when
there are changes at remote nodes. Furthermore, myopic coding mitigates the
high computational complexity and large buffer/memory requirements of
omniscient coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508077</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508077</id><created>2005-08-17</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Lequeu</keyname><forenames>Emmanuel</forenames></author></authors><title>Families of unitary matrices achieving full diversity</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  This paper presents an algebraic construction of families of unitary matrices
that achieve full diversity. They are obtained as subsets of cyclic division
algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508078</id><created>2005-08-17</created><updated>2005-08-25</updated><authors><author><keyname>Serebrenik</keyname><forenames>Alexander</forenames></author><author><keyname>Munoz-Hernandez</keyname><forenames>Susana</forenames></author></authors><title>Proceedings of the 15th Workshop on Logic-based methods in Programming
  Environments WLPE'05 -- October 5, 2005 -- Sitges (Barcelona), Spain</title><categories>cs.PL cs.LO cs.SE</categories><comments>Seven accepted papers</comments><acm-class>D.2.6; D.1.6</acm-class><abstract>  This volume contains papers presented at WLPE 2005, 15th International
Workshop on Logic-based methods in Programming Environments.
  The aim of the workshop is to provide an informal meeting for the researchers
working on logic-based tools for development and analysis of programs. This
year we emphasized two aspects: on one hand the presentation, pragmatics and
experiences of tools for logic programming environments; on the other one,
logic-based environmental tools for programming in general.
  The workshop took place in Sitges (Barcelona), Spain as a satellite workshop
of the 21th International Conference on Logic Programming (ICLP 2005). This
workshop continues the series of successful international workshops on logic
programming environments held in Ohio, USA (1989), Eilat, Israel (1990), Paris,
France (1991), Washington, USA (1992), Vancouver, Canada (1993), Santa
Margherita Ligure, Italy (1994), Portland, USA (1995), Leuven, Belgium and Port
Jefferson, USA (1997), Las Cruces, USA (1999), Paphos, Cyprus (2001),
Copenhagen, Denmark (2002), Mumbai, India (2003) and Saint Malo, France (2004).
  We have received eight submissions (2 from France, 2 Spain-US cooperations,
one Spain-Argentina cooperation, one from Japan, one from the United Kingdom
and one Sweden-France cooperation). Program committee has decided to accept
seven papers. This volume contains revised versions of the accepted papers.
  We are grateful to the authors of the papers, the reviewers and the members
of the Program Committee for the help and fruitful discussions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508079</id><created>2005-08-18</created><authors><author><keyname>Nagaraj</keyname><forenames>Nithin</forenames></author><author><keyname>Vaidya</keyname><forenames>Vivek</forenames></author><author><keyname>Vaidya</keyname><forenames>Prabhakar G</forenames></author></authors><title>Re-visiting the One-Time Pad</title><categories>cs.CR</categories><comments>13 pages, 3 figures, submitted for publication to IndoCrypt 2005
  conference</comments><abstract>  In 1949, Shannon proved the perfect secrecy of the Vernam cryptographic
system,also popularly known as the One-Time Pad (OTP). Since then, it has been
believed that the perfectly random and uncompressible OTP which is transmitted
needs to have a length equal to the message length for this result to be true.
In this paper, we prove that the length of the transmitted OTP which actually
contains useful information need not be compromised and could be less than the
message length without sacrificing perfect secrecy. We also provide a new
interpretation for the OTP encryption by treating the message bits as making
True/False statements about the pad, which we define as a private-object. We
introduce the paradigm of private-object cryptography where messages are
transmitted by verifying statements about a secret-object. We conclude by
suggesting the use of Formal Axiomatic Systems for investing N bits of secret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508080</id><created>2005-08-18</created><authors><author><keyname>Chawla</keyname><forenames>Kirti</forenames></author></authors><title>A 3D RGB Axis-based Color-oriented Cryptography</title><categories>cs.CR</categories><comments>16 Pages, 12 figures</comments><abstract>  In this document, a formal approach to encrypt, decrypt, transmit and receive
information using colors is explored. A piece of information consists of set of
symbols with a definite property imposed on the generating set. The symbols are
usually encoded using ascii scheme. A linear to 3d transformation is presented.
The change of axis from traditional xyz to rgb is highlighted and its effect
are studied. A point in this new axis is then represented as a unique color and
a vector or matrix is associated with it, making it amenable to standard vector
or matrix operations. A formal notion on hybrid cryptography is introduced as
the algorithm lies on the boundary of symmetric and asymmetric cryptography. No
discussion is complete, without mentioning reference to communication aspects
of secure information in a channel. Transmission scheme pertaining to light as
carrier is introduced and studied. Key-exchanges do not come under the scope of
current frame of document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508081</id><created>2005-08-18</created><authors><author><keyname>Chawla</keyname><forenames>Kirti</forenames></author></authors><title>ZEUS - A Domain-Oriented Fact Comparison Based Authentication Protocol</title><categories>cs.CR</categories><comments>5 Pages</comments><abstract>  In this paper, facts existing in different domains are explored, which are
comparable by their end result. Properties of various domains and the facts
that are part of such a unit are also presented, examples of comparison and
methods of usage as means of zero-knowledge protocols are given, finally a
zero-knowledge protocol based on afore-mentioned concept is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508082</id><created>2005-08-18</created><authors><author><keyname>Golder</keyname><forenames>Scott</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>The Structure of Collaborative Tagging Systems</title><categories>cs.DL cs.CY</categories><abstract>  Collaborative tagging describes the process by which many users add metadata
in the form of keywords to shared content. Recently, collaborative tagging has
grown in popularity on the web, on sites that allow users to tag bookmarks,
photographs and other content. In this paper we analyze the structure of
collaborative tagging systems as well as their dynamical aspects. Specifically,
we discovered regularities in user activity, tag frequencies, kinds of tags
used, bursts of popularity in bookmarking and a remarkable stability in the
relative proportions of tags within a given url. We also present a dynamical
model of collaborative tagging that predicts these stable patterns and relates
them to imitation and shared knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508083</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508083</id><created>2005-08-18</created><updated>2005-11-01</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>A General Framework for Codes Involving Redundancy Minimization</title><categories>cs.IT cs.DS math.IT</categories><comments>7 pages, 5 figures, submitted to IEEE Trans. Inform. Theory</comments><acm-class>E.4; H.1.1</acm-class><journal-ref>IEEE Transactions on Information Theory (2006)</journal-ref><doi>10.1109/TIT.2005.860469</doi><abstract>  A framework with two scalar parameters is introduced for various problems of
finding a prefix code minimizing a coding penalty function. The framework
encompasses problems previously proposed by Huffman, Campbell, Nath, and Drmota
and Szpankowski, shedding light on the relationships among these problems. In
particular, Nath's range of problems can be seen as bridging the minimum
average redundancy problem of Huffman with the minimum maximum pointwise
redundancy problem of Drmota and Szpankowski. Using this framework, two
linear-time Huffman-like algorithms are devised for the minimum maximum
pointwise redundancy problem, the only one in the framework not previously
solved with a Huffman-like algorithm. Both algorithms provide solutions common
to this problem and a subrange of Nath's problems, the second algorithm being
distinguished by its ability to find the minimum variance solution among all
solutions common to the minimum maximum pointwise redundancy and Nath problems.
Simple redundancy bounds are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508084</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508084</id><created>2005-08-18</created><updated>2006-05-22</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Source Coding for Quasiarithmetic Penalties</title><categories>cs.IT cs.DS math.IT</categories><comments>22 pages, 3 figures, submitted to IEEE Trans. Inform. Theory, revised
  per suggestions of readers</comments><acm-class>E.4; H.1.1</acm-class><journal-ref>IEEE Transactions on Information Theory (2006)</journal-ref><doi>10.1109/TIT.2006.881728</doi><abstract>  Huffman coding finds a prefix code that minimizes mean codeword length for a
given probability distribution over a finite number of items. Campbell
generalized the Huffman problem to a family of problems in which the goal is to
minimize not mean codeword length but rather a generalized mean known as a
quasiarithmetic or quasilinear mean. Such generalized means have a number of
diverse applications, including applications in queueing. Several
quasiarithmetic-mean problems have novel simple redundancy bounds in terms of a
generalized entropy. A related property involves the existence of optimal
codes: For ``well-behaved'' cost functions, optimal codes always exist for
(possibly infinite-alphabet) sources having finite generalized entropy. Solving
finite instances of such problems is done by generalizing an algorithm for
finding length-limited binary codes to a new algorithm for finding optimal
binary codes for any quasiarithmetic mean with a convex cost function. This
algorithm can be performed using quadratic time and linear space, and can be
extended to other penalty functions, some of which are solvable with similar
space and time complexity, and others of which are solvable with slightly
greater complexity. This reduces the computational complexity of a problem
involving minimum delay in a queue, allows combinations of previously
considered problems to be optimized, and greatly expands the space of problems
solvable in quadratic time and linear space. The algorithm can be extended for
purposes such as breaking ties among possibly different optimal codes, as with
bottom-merge Huffman coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508085</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508085</id><created>2005-08-20</created><authors><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>On the Asymptotic Performance of Iterative Decoders for Product Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in The International Symposium on Information Theory 2005
  (ISIT2005)</comments><acm-class>E.4</acm-class><abstract>  We consider hard-decision iterative decoders for product codes over the
erasure channel, which employ repeated rounds of decoding rows and columns
alternatingly. We derive the exact asymptotic probability of decoding failure
as a function of the error-correction capabilities of the row and column codes,
the number of decoding rounds, and the channel erasure probability. We examine
both the case of codes capable of correcting a constant amount of errors, and
the case of codes capable of correcting a constant fraction of their length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508086</id><created>2005-08-21</created><authors><author><keyname>Trinca</keyname><forenames>Dragos</forenames></author></authors><title>High-performance BWT-based Encoders</title><categories>cs.DS</categories><comments>12 pages</comments><acm-class>E.4; F.4.3</acm-class><abstract>  In 1994, Burrows and Wheeler developed a data compression algorithm which
performs significantly better than Lempel-Ziv based algorithms. Since then, a
lot of work has been done in order to improve their algorithm, which is based
on a reversible transformation of the input string, called BWT (the
Burrows-Wheeler transformation). In this paper, we propose a compression scheme
based on BWT, MTF (move-to-front coding), and a version of the algorithms
presented in [Dragos Trinca, ITCC-2004].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508087</id><created>2005-08-21</created><authors><author><keyname>Trinca</keyname><forenames>Dragos</forenames></author></authors><title>Modelling the Eulerian Path Problem using a String Matching Framework</title><categories>cs.DS</categories><comments>10 pages</comments><acm-class>E.1; F.2.2; G.2.2</acm-class><abstract>  The well-known Eulerian path problem can be solved in polynomial time (more
exactly, there exists a linear time algorithm for this problem). In this paper,
we model the problem using a string matching framework, and then initiate an
algorithmic study on a variant of this problem, called the (2,1)-STRING-MATCH
problem (which is actually a generalization of the Eulerian path problem).
Then, we present a polynomial-time algorithm for the (2,1)-STRING-MATCH
problem, which is the most important result of this paper. Specifically, we get
a lower bound of Omega(n), and an upper bound of O(n^{2}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508088</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508088</id><created>2005-08-21</created><authors><author><keyname>Trinca</keyname><forenames>Dragos</forenames></author></authors><title>Special Cases of Encodings by Generalized Adaptive Codes</title><categories>cs.IT math.IT</categories><comments>17 pages</comments><acm-class>D.3.1; E.4; F.4.3</acm-class><abstract>  Adaptive (variable-length) codes associate variable-length codewords to
symbols being encoded depending on the previous symbols in the input data
string. This class of codes has been presented in [Dragos Trinca,
cs.DS/0505007] as a new class of non-standard variable-length codes.
Generalized adaptive codes (GA codes, for short) have been also presented in
[Dragos Trinca, cs.DS/0505007] not only as a new class of non-standard
variable-length codes, but also as a natural generalization of adaptive codes
of any order. This paper is intended to continue developing the theory of
variable-length codes by establishing several interesting connections between
adaptive codes and other classes of codes. The connections are discussed not
only from a theoretical point of view (by proving new results), but also from
an applicative one (by proposing several applications). First, we prove that
adaptive Huffman encodings and Lempel-Ziv encodings are particular cases of
encodings by GA codes. Second, we show that any (n,1,m) convolutional code
satisfying certain conditions can be modelled as an adaptive code of order m.
Third, we describe a cryptographic scheme based on the connection between
adaptive codes and convolutional codes, and present an insightful analysis of
this scheme. Finally, we conclude by generalizing adaptive codes to
(p,q)-adaptive codes, and discussing connections between adaptive codes and
time-varying codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508089</id><created>2005-08-21</created><authors><author><keyname>Trinca</keyname><forenames>Dragos</forenames></author></authors><title>Modelling the EAH Data Compression Algorithm using Graph Theory</title><categories>cs.DS</categories><comments>10 pages</comments><acm-class>E.4; G.2.2</acm-class><abstract>  Adaptive codes associate variable-length codewords to symbols being encoded
depending on the previous symbols in the input data string. This class of codes
has been introduced in [Dragos Trinca, cs.DS/0505007] as a new class of
non-standard variable-length codes. New algorithms for data compression, based
on adaptive codes of order one, have been presented in [Dragos Trinca,
ITCC-2004], where we have behaviorally shown that for a large class of input
data strings, these algorithms substantially outperform the Lempel-Ziv
universal data compression algorithm. EAH has been introduced in [Dragos
Trinca, cs.DS/0505061], as an improved generalization of these algorithms. In
this paper, we present a translation of the EAH algorithm into the graph
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508090</id><created>2005-08-21</created><authors><author><keyname>Trinca</keyname><forenames>Dragos</forenames></author></authors><title>Translating the EAH Data Compression Algorithm into Automata Theory</title><categories>cs.DS</categories><comments>9 pages</comments><abstract>  Adaptive codes have been introduced in [Dragos Trinca, cs.DS/0505007] as a
new class of non-standard variable-length codes. These codes associate
variable-length codewords to symbols being encoded depending on the previous
symbols in the input data string. A new data compression algorithm, called EAH,
has been introduced in [Dragos Trinca, cs.DS/0505061], where we have
behaviorally shown that for a large class of input data strings, this algorithm
substantially outperforms the well-known Lempel-Ziv universal data compression
algorithm. In this paper, we translate the EAH encoder into automata theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508091</id><created>2005-08-22</created><authors><author><keyname>Munoz-Hernandez</keyname><forenames>Susana</forenames></author><author><keyname>Vaucheret</keyname><forenames>Claudio</forenames></author></authors><title>Extending Prolog with Incomplete Fuzzy Information</title><categories>cs.PL cs.SE</categories><acm-class>D.2.6</acm-class><abstract>  Incomplete information is a problem in many aspects of actual environments.
Furthermore, in many sceneries the knowledge is not represented in a crisp way.
It is common to find fuzzy concepts or problems with some level of uncertainty.
There are not many practical systems which handle fuzziness and uncertainty and
the few examples that we can find are used by a minority. To extend a popular
system (which many programmers are using) with the ability of combining crisp
and fuzzy knowledge representations seems to be an interesting issue.
  Our first work (Fuzzy Prolog) was a language that models
$\mathcal{B}([0,1])$-valued Fuzzy Logic. In the Borel algebra,
$\mathcal{B}([0,1])$, truth value is represented using unions of intervals of
real numbers. This work was more general in truth value representation and
propagation than previous works.
  An interpreter for this language using Constraint Logic Programming over Real
numbers (CLP(${\cal R}$)) was implemented and is available in the Ciao system.
  Now, we enhance our former approach by using default knowledge to represent
incomplete information in Logic Programming. We also provide the implementation
of this new framework. This new release of Fuzzy Prolog handles incomplete
information, it has a complete semantics (the previous one was incomplete as
Prolog) and moreover it is able to combine crisp and fuzzy logic in Prolog
programs. Therefore, new Fuzzy Prolog is more expressive to represent real
world.
  Fuzzy Prolog inherited from Prolog its incompleteness. The incorporation of
default reasoning to Fuzzy Prolog removes this problem and requires a richer
semantics which we discuss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508092</id><created>2005-08-22</created><authors><author><keyname>Afantenos</keyname><forenames>Stergos D.</forenames></author><author><keyname>Karkaletsis</keyname><forenames>Vangelis</forenames></author><author><keyname>Stamatopoulos</keyname><forenames>Panagiotis</forenames></author></authors><title>Summarizing Reports on Evolving Events; Part I: Linear Evolution</title><categories>cs.CL cs.IR</categories><comments>7 pages. Published on the Conference Recent Advances in Natural
  Language Processing (RANLP, 2005)</comments><journal-ref>Edited by Galia Angelova, Kalina Bontcheva, Ruslan Mitkov, Nicolas
  Nicolov, and Nikolai Nikolov, Recent Advances in Natural Language Processing
  (RANLP 2005). Borovets, Bulgaria: INCOMA, 18-24.</journal-ref><abstract>  We present an approach for summarization from multiple documents which report
on events that evolve through time, taking into account the different document
sources. We distinguish the evolution of an event into linear and non-linear.
According to our approach, each document is represented by a collection of
messages which are then used in order to instantiate the cross-document
relations that determine the summary content. The paper presents the
summarization system that implements this approach through a case study on
linear evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508093</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508093</id><created>2005-08-22</created><authors><author><keyname>Porrat</keyname><forenames>Dana</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Performance of PPM Multipath Synchronization in the Limit of Large
  Bandwidth</title><categories>cs.IT math.IT</categories><comments>11 pages, submitted to 2005 Allerton conference on communication,
  control, and computing</comments><abstract>  The acquisition, or synchronization, of the multipath profile for an
ultrawideband pulse position modulation (PPM) communication systems is
considered. Synchronization is critical for the proper operation of PPM based
For the multipath channel, it is assumed that channel gains are known, but path
delays are unknown. In the limit of large bandwidth, W, it is assumed that the
number of paths, L, grows. The delay spread of the channel, M, is proportional
to the bandwidth. The rate of growth of L versus M determines whether
synchronization can occur. It is shown that if L/sqrt(M) --&gt; 0, then the
maximum likelihood synchronizer cannot acquire any of the paths and
alternatively if L/M --&gt; 0, the maximum likelihood synchronizer is guaranteed
to miss at least one path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508094</identifier>
 <datestamp>2008-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508094</id><created>2005-08-22</created><authors><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Lo</keyname><forenames>Hoi-Kwong</forenames></author></authors><title>Conference Key Agreement and Quantum Sharing of Classical Secrets with
  Noisy GHZ States</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, to appear in Proc. 2005 IEEE International Symposium on
  Information Theory (ISIT 2005, Adelaide, Australia)</comments><report-no>CQIQC-ISIT 2005-CL1</report-no><journal-ref>Information Theory, 2005. ISIT 2005. Proceedings. International
  Symposium on 4-9 Sept. 2005 Page(s):1607 - 1611</journal-ref><doi>10.1109/ISIT.2005.1523616</doi><abstract>  We propose a wide class of distillation schemes for multi-partite entangled
states that are CSS-states. Our proposal provides not only superior efficiency,
but also new insights on the connection between CSS-states and bipartite graph
states. We then consider the applications of our distillation schemes for two
cryptographic tasks--namely, (a) conference key agreement and (b) quantum
sharing of classical secrets. In particular, we construct
``prepare-and-measure'' protocols. Also we study the yield of those protocols
and the threshold value of the fidelity above which the protocols can function
securely. Surprisingly, our protocols will function securely even when the
initial state does not violate the standard Bell-inequalities for GHZ states.
Experimental realization involving only bi-partite entanglement is also
suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508095</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508095</id><created>2005-08-22</created><authors><author><keyname>Negi</keyname><forenames>Rohit</forenames></author><author><keyname>Rajeswaran</keyname><forenames>Arjunan</forenames></author></authors><title>Capacity of Ultra Wide Band Wireless Ad Hoc Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>12 pages,2 figures</comments><abstract>  Throughput capacity is a critical parameter for the design and evaluation of
ad-hoc wireless networks. Consider n identical randomly located nodes, on a
unit area, forming an ad-hoc wireless network. Assuming a fixed per node
transmission capability of T bits per second at a fixed range, it has been
shown that the uniform throughput capacity per node r(n) is Theta((T)/(sqrt{n
log n})), a decreasing function of node density n.
  However an alternate communication model may also be considered, with each
node constrained to a maximum transmit power P_0 and capable of utilizing W Hz
of bandwidth. Under the limiting case W rightarrow infinity, such as in Ultra
Wide Band (UWB) networks, the uniform throughput per node is O ((n log
n)^{(alpha-1}/2}) (upper bound) and Omega((n^{(alpha-1)/2})/((log n)^{(alpha
+1)/2})) (achievable lower bound).
  These bounds demonstrate that throughput increases with node density $n$, in
contrast to previously published results. This is the result of the large
bandwidth, and the assumed power and rate adaptation, which alleviate
interference. Thus, the effect of physical layer properties on the capacity of
ad hoc wireless networks is demonstrated. Further, the promise of UWB as a
physical layer technology for ad-hoc networks is justified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508096</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508096</id><created>2005-08-22</created><authors><author><keyname>Sigurjonsson</keyname><forenames>Styrmir</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>On Multiple User Channels with Causal State Information at the
  Transmitters</title><categories>cs.IT math.IT</categories><abstract>  We extend Shannon's result on the capacity of channels with state information
to multiple user channels. More specifically, we characterize the capacity
(region) of degraded broadcast channels and physically degraded relay channels
where the channel state information is causally available at the transmitters.
We also obtain inner and outer bounds on the capacity region for multiple
access channels with causal state information at the transmitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508097</identifier>
 <datestamp>2008-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508097</id><created>2005-08-22</created><updated>2008-04-11</updated><authors><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>Tightness of LP via Max-product Belief Propagation</title><categories>cs.DS cs.DM</categories><abstract>  We investigate the question of tightness of linear programming (LP)
relaxation for finding a maximum weight independent set (MWIS) in sparse random
weighted graphs. We show that an edge-based LP relaxation is asymptotically
tight for Erdos-Renyi graph $G(n,c/n)$ for $c \leq 2e$ and random regular graph
$G(n,r)$ for $r\leq 4$ when node weights are i.i.d. with exponential
distribution of mean 1. We establish these results, through a precise relation
between the tightness of LP relaxation and convergence of the max-product
belief propagation algorithm. We believe that this novel method of
understanding structural properties of combinatorial problems through
properties of iterative procedure such as the max-product should be of interest
in its own right.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508098</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508098</id><created>2005-08-22</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Ganesan</keyname><forenames>Ashwin</forenames></author></authors><title>An Explicit Construction of Universally Decodable Matrices</title><categories>cs.IT cs.DM math.IT</categories><abstract>  Universally decodable matrices can be used for coding purposes when
transmitting over slow fading channels. These matrices are parameterized by
positive integers $L$ and $n$ and a prime power $q$. Based on Pascal's triangle
we give an explicit construction of universally decodable matrices for any
non-zero integers $L$ and $n$ and any prime power $q$ where $L \leq q+1$. This
is the largest set of possible parameter values since for any list of
universally decodable matrices the value $L$ is upper bounded by $q+1$, except
for the trivial case $n = 1$. For the proof of our construction we use
properties of Hasse derivatives, and it turns out that our construction has
connections to Reed-Solomon codes, Reed-Muller codes, and so-called
repeated-root cyclic codes. Additionally, we show how universally decodable
matrices can be modified so that they remain universally decodable matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508099</id><created>2005-08-23</created><authors><author><keyname>Bajic</keyname><forenames>Dragana</forenames></author><author><keyname>Stefanovic</keyname><forenames>Cedomir</forenames></author><author><keyname>Vukobratovic</keyname><forenames>Dejan</forenames></author></authors><title>Search Process and Probabilistic Bifix Approach</title><categories>cs.IT cs.CV math.IT</categories><comments>4 pages, 2 figures, to appear in Proceedings of the 2005 IEEE
  International Symposium on Information Theory, Adelaide, Australia, September
  4-9, 2005</comments><abstract>  An analytical approach to a search process is a mathematical prerequisite for
digital synchronization acquisition analysis and optimization. A search is
performed for an arbitrary set of sequences within random but not equiprobable
L-ary data. This paper derives in detail an expression for probability
distribution function, from which other statistical parameters - expected value
and variance - can be obtained. The probabilistic nature of (cross-) bifix
indicators is shown and application examples are outlined, ranging beyond the
usual telecommunication field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508100</id><created>2005-08-23</created><authors><author><keyname>Provetti</keyname><forenames>Alessandro</forenames></author></authors><title>A primer on Answer Set Programming</title><categories>cs.AI cs.LO</categories><comments>6 pages</comments><acm-class>D.1.6; I.2.3</acm-class><abstract>  A introduction to the syntax and Semantics of Answer Set Programming intended
as an handout to [under]graduate students taking Artificial Intlligence or
Logic Programming classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508101</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508101</id><created>2005-08-23</created><updated>2007-04-07</updated><authors><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Sharma</keyname><forenames>Mayank</forenames></author></authors><title>Maximum Weight Matching via Max-Product Belief Propagation</title><categories>cs.IT cs.AI math.IT</categories><comments>In the proceedings of the 2005 IEEE International Symposium on
  Information Theory</comments><acm-class>G.2.2; G.3; I.2.6</acm-class><journal-ref>IEEE Transactions on Information Theory, Vol 54 (3), 2008</journal-ref><doi>10.1109/TIT.2007.915695</doi><abstract>  Max-product &quot;belief propagation&quot; is an iterative, local, message-passing
algorithm for finding the maximum a posteriori (MAP) assignment of a discrete
probability distribution specified by a graphical model. Despite the
spectacular success of the algorithm in many application areas such as
iterative decoding, computer vision and combinatorial optimization which
involve graphs with many cycles, theoretical results about both correctness and
convergence of the algorithm are known in few cases (Weiss-Freeman Wainwright,
Yeddidia-Weiss-Freeman, Richardson-Urbanke}.
  In this paper we consider the problem of finding the Maximum Weight Matching
(MWM) in a weighted complete bipartite graph. We define a probability
distribution on the bipartite graph whose MAP assignment corresponds to the
MWM. We use the max-product algorithm for finding the MAP of this distribution
or equivalently, the MWM on the bipartite graph. Even though the underlying
bipartite graph has many short cycles, we find that surprisingly, the
max-product algorithm always converges to the correct MAP assignment as long as
the MAP assignment is unique. We provide a bound on the number of iterations
required by the algorithm and evaluate the computational cost of the algorithm.
We find that for a graph of size $n$, the computational cost of the algorithm
scales as $O(n^3)$, which is the same as the computational cost of the best
known algorithm. Finally, we establish the precise relation between the
max-product algorithm and the celebrated {\em auction} algorithm proposed by
Bertsekas. This suggests possible connections between dual algorithm and
max-product algorithm for discrete optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508102</id><created>2005-08-23</created><authors><author><keyname>Stone</keyname><forenames>Emily</forenames></author><author><keyname>Ahmed</keyname><forenames>Suhail</forenames></author><author><keyname>Askari</keyname><forenames>Abe</forenames></author><author><keyname>Tat</keyname><forenames>Hong</forenames></author></authors><title>Investigations of Process Damping Forces in Metal Cutting</title><categories>cs.CE</categories><comments>27 pages, 27 figures, submitted to Journal of Computational Methods
  in Science and Engineering, Feb. 2005</comments><acm-class>I.6.3; I.6.4</acm-class><abstract>  Using finite element software developed for metal cutting by Third Wave
Systems we investigate the forces involved in chatter, a self-sustained
oscillation of the cutting tool. The phenomena is decomposed into a vibrating
tool cutting a flat surface work piece, and motionless tool cutting a work
piece with a wavy surface. While cutting the wavy surface, the shearplane was
seen to oscillate in advance of the oscillation of the depth of cut, as were
the cutting, thrust, and shear plane forces. The vibrating tool was used to
investigate process damping through the interaction of the relief face of the
tool and the workpiece. Crushing forces are isolated and compared to the
contact length between the tool and workpiece. We found that the wavelength
dependence of the forces depended on the relative size of the wavelength to the
length of the relief face of the tool. The results indicate that the damping
force from crushing will be proportional to the cutting speed for short tools,
and inversely proportional for long tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508103</id><created>2005-08-23</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames><affiliation>National Research Council of Canada</affiliation></author><author><keyname>Littman</keyname><forenames>Michael L.</forenames><affiliation>Rutgers University</affiliation></author></authors><title>Corpus-based Learning of Analogies and Semantic Relations</title><categories>cs.LG cs.CL cs.IR</categories><comments>related work available at http://purl.org/peter.turney/ and
  http://www.cs.rutgers.edu/~mlittman/</comments><report-no>NRC-48273</report-no><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Machine Learning, (2005), 60(1-3), 251-278</journal-ref><abstract>  We present an algorithm for learning from unlabeled text, based on the Vector
Space Model (VSM) of information retrieval, that can solve verbal analogy
questions of the kind found in the SAT college entrance exam. A verbal analogy
has the form A:B::C:D, meaning &quot;A is to B as C is to D&quot;; for example,
mason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B,
and the problem is to select the most analogous word pair, C:D, from a set of
five choices. The VSM algorithm correctly answers 47% of a collection of 374
college-level analogy questions (random guessing would yield 20% correct; the
average college-bound senior high school student answers about 57% correctly).
We motivate this research by applying it to a difficult problem in natural
language processing, determining semantic relations in noun-modifier pairs. The
problem is to classify a noun-modifier pair, such as &quot;laser printer&quot;, according
to the semantic relation between the noun (printer) and the modifier (laser).
We use a supervised nearest-neighbour algorithm that assigns a class to a given
noun-modifier pair by finding the most analogous noun-modifier pair in the
training data. With 30 classes of semantic relations, on a collection of 600
labeled noun-modifier pairs, the learning algorithm attains an F value of 26.5%
(random guessing: 3.3%). With 5 classes of semantic relations, the F value is
43.2% (random: 20%). The performance is state-of-the-art for both verbal
analogies and noun-modifier relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508104</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508104</id><created>2005-08-23</created><authors><author><keyname>Horadam</keyname><forenames>K. J.</forenames></author></authors><title>A Generalised Hadamard Transform</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  A Generalised Hadamard Transform for multi-phase or multilevel signals is
introduced, which includes the Fourier, Generalised, Discrete Fourier,
Walsh-Hadamard and Reverse Jacket Transforms. The jacket construction is
formalised and shown to admit a tensor product decomposition. Primary matrices
under this decomposition are identified. New examples of primary jacket
matrices of orders 8 and 12 are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508105</id><created>2005-08-24</created><authors><author><keyname>Langevine</keyname><forenames>Ludovic</forenames></author><author><keyname>Ducasse</keyname><forenames>Mireille</forenames></author></authors><title>A Tracer Driver for Versatile Dynamic Analyses of Constraint Logic
  Programs</title><categories>cs.SE</categories><comments>In A. Serebrenik and S. Munoz-Hernandez (editors), Proceedings of the
  15th Workshop on Logic-based methods in Programming Environments, October
  2005, Spain. Whole proceedings: cs.PL/0508078. 15 pages</comments><acm-class>D.2; D.2.5; D.2.6</acm-class><abstract>  Programs with constraints are hard to debug. In this paper, we describe a
general architecture to help develop new debugging tools for constraint
programming. The possible tools are fed by a single general-purpose tracer. A
tracer-driver is used to adapt the actual content of the trace, according to
the needs of the tool. This enables the tools and the tracer to communicate in
a client-server scheme. Each tool describes its needs of execution data thanks
to event patterns. The tracer driver scrutinizes the execution according to
these event patterns and sends only the data that are relevant to the connected
tools. Experimental measures show that this approach leads to good performance
in the context of constraint logic programming, where a large variety of tools
exists and the trace is potentially huge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508106</id><created>2005-08-24</created><authors><author><keyname>Payet</keyname><forenames>Etienne</forenames></author><author><keyname>Mesnard</keyname><forenames>Fred</forenames></author></authors><title>An Improved Non-Termination Criterion for Binary Constraint Logic
  Programs</title><categories>cs.PL</categories><comments>In A. Serebrenik and S. Munoz-Hernandez (editors), Proceedings of the
  15th Workshop on Logic-based methods in Programming Environments October
  2005, Sitges. cs.PL/0508078</comments><acm-class>D.2.6</acm-class><abstract>  On one hand, termination analysis of logic programs is now a fairly
established research topic within the logic programming community. On the other
hand, non-termination analysis seems to remain a much less attractive subject.
If we divide this line of research into two kinds of approaches: dynamic versus
static analysis, this paper belongs to the latter. It proposes a criterion for
detecting non-terminating atomic queries with respect to binary CLP clauses,
which strictly generalizes our previous works on this subject. We give a
generic operational definition and a logical form of this criterion. Then we
show that the logical form is correct and complete with respect to the
operational definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508107</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508107</id><created>2005-08-24</created><authors><author><keyname>Mounits</keyname><forenames>Beniamin</forenames><affiliation>Technion - Israel Institute of Technology</affiliation></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames><affiliation>Technion - Israel Institute of Technology</affiliation></author><author><keyname>Litsyn</keyname><forenames>Simon</forenames><affiliation>Tel Aviv University</affiliation></author></authors><title>New Upper Bounds on A(n,d)</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  Upper bounds on the maximum number of codewords in a binary code of a given
length and minimum Hamming distance are considered. New bounds are derived by a
combination of linear programming and counting arguments. Some of these bounds
improve on the best known analytic bounds. Several new record bounds are
obtained for codes with small lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508108</id><created>2005-08-24</created><authors><author><keyname>Denmat</keyname><forenames>Tristan</forenames></author><author><keyname>Gotlieb</keyname><forenames>Arnaud</forenames></author><author><keyname>Ducasse</keyname><forenames>Mireille</forenames></author></authors><title>Proving or Disproving likely Invariants with Constraint Reasoning</title><categories>cs.SE cs.PL</categories><comments>In A. Serebrenik and S. Munoz-Hernandez (editors), Proceedings of the
  15th Workshop on Logic-based methods in Programming Environments October
  2005, Sitges. cs.PL/0508078</comments><acm-class>D.2.6</acm-class><abstract>  A program invariant is a property that holds for every execution of the
program. Recent work suggest to infer likely-only invariants, via dynamic
analysis. A likely invariant is a property that holds for some executions but
is not guaranteed to hold for all executions. In this paper, we present work in
progress addressing the challenging problem of automatically verifying that
likely invariants are actual invariants. We propose a constraint-based
reasoning approach that is able, unlike other approaches, to both prove or
disprove likely invariants. In the latter case, our approach provides
counter-examples. We illustrate the approach on a motivating example where
automatically generated likely invariants are verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508109</id><created>2005-08-24</created><authors><author><keyname>Heaven</keyname><forenames>William</forenames></author><author><keyname>Russo</keyname><forenames>Alessandra</forenames></author></authors><title>Enhancing the Alloy Analyzer with Patterns of Analysis</title><categories>cs.SE cs.LO</categories><comments>17 pages, 15th Workshop on Logic Programming Environments (WLPE05),
  Sitges (Barcelona), Spain, 2005</comments><journal-ref>15th Workshop on Logic Programming Environments (WLPE05), Sitges
  (Barcelona), Spain, 2005</journal-ref><abstract>  Formal techniques have been shown to be useful in the development of correct
software. But the level of expertise required of practitioners of these
techniques prohibits their widespread adoption. Formal techniques need to be
tailored to the commercial software developer. Alloy is a lightweight
specification language supported by the Alloy Analyzer (AA), a tool based on
off-the-shelf SAT technology. The tool allows a user to check interactively
whether given properties are consistent or valid with respect to a high-level
specification, providing an environment in which the correctness of such a
specification may be established. However, Alloy is not particularly suited to
expressing program specifications and the feedback provided by AA can be
misleading where the specification under analysis or the property being checked
contains inconsistencies. In this paper, we address these two shortcomings.
Firstly, we present a lightweight language called &quot;Loy&quot;, tailored to the
specification of object-oriented programs. An encoding of Loy into Alloy is
provided so that AA can be used for automated analysis of Loy program
specifications. Secondly, we present some &quot;patterns of analysis&quot; that guide a
developer through the analysis of a Loy specification in order to establish its
correctness before implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508110</id><created>2005-08-25</created><authors><author><keyname>Bagherzandi</keyname><forenames>Ali</forenames></author><author><keyname>Azimian</keyname><forenames>Kooshiar</forenames></author><author><keyname>Mohajeri</keyname><forenames>Javad</forenames></author><author><keyname>Salmasizadeh</keyname><forenames>Mahmoud</forenames></author></authors><title>Relations between semantic security and indistinguishability against
  cpa, non-adaptive cca and adaptive cca in comparison based framework</title><categories>cs.CR</categories><comments>8 pages, 1 figure</comments><abstract>  In this paper we try to unify the frameworks of definitions of semantic
security, indistinguishability and non-malleability by defining semantic
security in comparison based framework. This facilitates the study of relations
among these goals against different attack models and makes the proof of the
equivalence of semantic security and indistinguishability easier and more
understandable. Besides, our proof of the equivalence of semantic security and
indistinguishability does not need any intermediate goals such as non
devidability to change the definition framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508111</id><created>2005-08-24</created><authors><author><keyname>Puebla</keyname><forenames>German</forenames></author><author><keyname>Albert</keyname><forenames>Elvira</forenames></author><author><keyname>Hermenegildo</keyname><forenames>Manuel</forenames></author></authors><title>A Generic Framework for the Analysis and Specialization of Logic
  Programs</title><categories>cs.PL cs.SE</categories><comments>In A. Serebrenik and S. Munoz-Hernandez (editors), Proceedings of the
  15th Workshop on Logic-based methods in Programming Environments October
  2005, Sitges. cs.PL/0508078</comments><acm-class>D.2.6</acm-class><abstract>  The relationship between abstract interpretation and partial deduction has
received considerable attention and (partial) integrations have been proposed
starting from both the partial deduction and abstract interpretation
perspectives. In this work we present what we argue is the first fully
described generic algorithm for efficient and precise integration of abstract
interpretation and partial deduction. Taking as starting point state-of-the-art
algorithms for context-sensitive, polyvariant abstract interpretation and
(abstract) partial deduction, we present an algorithm which combines the best
of both worlds. Key ingredients include the accurate success propagation
inherent to abstract interpretation and the powerful program transformations
achievable by partial deduction. In our algorithm, the calls which appear in
the analysis graph are not analyzed w.r.t. the original definition of the
procedure but w.r.t. specialized definitions of these procedures. Such
specialized definitions are obtained by applying both unfolding and abstract
executability. Our framework is parametric w.r.t. different control strategies
and abstract domains. Different combinations of such parameters correspond to
existing algorithms for program analysis and specialization. Simultaneously,
our approach opens the door to the efficient computation of strictly more
precise results than those achievable by each of the individual techniques. The
algorithm is now one of the key components of the CiaoPP analysis and
specialization system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508112</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508112</id><created>2005-08-25</created><authors><author><keyname>Navas</keyname><forenames>Jorge</forenames></author><author><keyname>Bueno</keyname><forenames>Francisco</forenames></author><author><keyname>Hermenegildo</keyname><forenames>Manuel</forenames></author></authors><title>A study of set-sharing analysis via cliques</title><categories>cs.LO</categories><comments>15 pages, 0 figures</comments><abstract>  We study the problem of efficient, scalable set-sharing analysis of logic
programs. We use the idea of representing sharing information as a pair of
abstract substitutions, one of which is a worst-case sharing representation
called a clique set, which was previously proposed for the case of inferring
pair-sharing. We use the clique-set representation for (1) inferring actual
set-sharing information, and (2) analysis within a top-down framework. In
particular, we define the abstract functions required by standard top-down
analyses, both for sharing alone and also for the case of including freeness in
addition to sharing. Our experimental evaluation supports the conclusion that,
for inferring set-sharing, as it was the case for inferring pair-sharing,
precision losses are limited, while useful efficiency gains are obtained. At
the limit, the clique-set representation allowed analyzing some programs that
exceeded memory capacity using classical sharing representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508113</id><created>2005-08-25</created><authors><author><keyname>Jeannerod</keyname><forenames>Claude-Pierre</forenames><affiliation>LIP</affiliation></author><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Asymptotically fast polynomial matrix algorithms for multivariable
  systems</title><categories>cs.SC cs.CC</categories><proxy>ccsd ccsd-00008211</proxy><report-no>JeVi05</report-no><acm-class>I.1; F.2.1</acm-class><abstract>  We present the asymptotically fastest known algorithms for some basic
problems on univariate polynomial matrices: rank, nullspace, determinant,
generic inverse, reduced form. We show that they essentially can be reduced to
two computer algebra techniques, minimal basis computations and matrix fraction
expansion/reconstruction, and to polynomial matrix multiplication. Such
reductions eventually imply that all these problems can be solved in about the
same amount of time as polynomial matrix multiplication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508114</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508114</id><created>2005-08-25</created><updated>2005-09-26</updated><authors><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author><author><keyname>Liu</keyname><forenames>Qingchong</forenames></author></authors><title>A Family of Binary Sequences with Optimal Correlation Property and
  Large Linear Span</title><categories>cs.CR cs.IT math.IT</categories><comments>21 pages</comments><abstract>  A family of binary sequences is presented and proved to have optimal
correlation property and large linear span. It includes the small set of Kasami
sequences, No sequence set and TN sequence set as special cases. An explicit
lower bound expression on the linear span of sequences in the family is given.
With suitable choices of parameters, it is proved that the family has
exponentially larger linear spans than both No sequences and TN sequences. A
class of ideal autocorrelation sequences is also constructed and proved to have
large linear span.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508115</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508115</id><created>2005-08-25</created><authors><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author><author><keyname>Liu</keyname><forenames>Qingchong</forenames></author></authors><title>New Sequence Sets with Zero-Correlation Zone</title><categories>cs.IT math.IT</categories><comments>28 pages, submitted to IEEE-IT on May 18, 2005</comments><abstract>  A method for constructing sets of sequences with zero-correlation zone (ZCZ
sequences) and sequence sets with low cross correlation is proposed. The method
is to use families of short sequences and complete orthogonal sequence sets to
derive families of long sequences with desired correlation properties. It is a
unification of works of Matsufuji and Torii \emph{et al.}, and there are more
choices of parameters of sets for our method. In particular, ZCZ sequence sets
generated by the method can achieve a related ZCZ bound. Furthermore, the
proposed method can be utilized to derive new ZCZ sets with both longer ZCZ and
larger set size from known ZCZ sets. These sequence sets are applicable in
broadband satellite IP networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508116</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508116</id><created>2005-08-25</created><authors><author><keyname>Burger</keyname><forenames>John Robert</forenames></author></authors><title>Quantum Algorithm Processors to Reveal Hamiltonian Cycles</title><categories>cs.AR cs.CG</categories><comments>10 pages</comments><acm-class>B.7.1; C.1.2</acm-class><abstract>  Quantum computer versus quantum algorithm processor in CMOS are compared to
find (in parallel) all Hamiltonian cycles in a graph with m edges and n
vertices, each represented by k bits. A quantum computer uses quantum states
analogous to CMOS registers. With efficient initialization, number of CMOS
registers is proportional to (n-1)! Number of qubits in a quantum computer is
approximately proportional to kn+2mn in the approach below. Using CMOS, the
bits per register is about proportional to kn, which is less since bits can be
irreversibly reset. In either concept, number of gates, or operations to
identify Hamiltonian cycles is proportional to kmn. However, a quantum computer
needs an additional exponentially large number of operations to accomplish a
probabilistic readout. In contrast, CMOS is deterministic and readout is
comparable to ordinary memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508117</id><created>2005-08-26</created><authors><author><keyname>Shen</keyname><forenames>Xi</forenames><affiliation>Imperial College London, United Kingdom</affiliation></author><author><keyname>De Wilde</keyname><forenames>Philippe</forenames><affiliation>Heriot-Watt University, United Kingdom</affiliation></author></authors><title>Long-term neuronal behavior caused by two synaptic modification
  mechanisms</title><categories>cs.NE cs.CE</categories><comments>11 pages, 5 figures</comments><abstract>  We report the first results of simulating the coupling of neuronal,
astrocyte, and cerebrovascular activity. It is suggested that the dynamics of
the system is different from systems that only include neurons. In the
neuron-vascular coupling, distribution of synapse strengths affects neuronal
behavior and thus balance of the blood flow; oscillations are induced in the
neuron-to-astrocyte coupling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508118</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508118</id><created>2005-08-26</created><updated>2005-10-10</updated><authors><author><keyname>Jana</keyname><forenames>Soumya</forenames></author></authors><title>Unified Theory of Source Coding: Part I -- Two Terminal Problems</title><categories>cs.IT math.IT</categories><comments>38 pages, submitted to IEEE-T-Inform. Theory Corrections: Typos in
  proofs of lemmas 3.2 and 3.5 are fixed</comments><abstract>  Since the publication of Shannon's theory of one terminal source coding, a
number of interesting extensions have been derived by researchers such as
Slepian-Wolf, Wyner, Ahlswede-K\&quot;{o}rner, Wyner-Ziv and Berger-Yeung.
Specifically, the achievable rate or rate-distortion region has been described
by a first order information-theoretic functional of the source statistics in
each of the above cases. At the same time several problems have also remained
unsolved. Notable two terminal examples include the joint distortion problem,
where both sources are reconstructed under a combined distortion criterion, as
well as the partial side information problem, where one source is reconstructed
under a distortion criterion using information about the other (side
information) available at a certain rate (partially). In this paper we solve
both of these open problems. Specifically, we give an infinite order
description of the achievable rate-distortion region in each case. In our
analysis we set the above problems in a general framework and formulate a
unified methodology that solves not only the problems at hand but any two
terminal problem with noncooperative encoding. The key to such unification is
held by a fundamental source coding principle which we derive by extending the
typicality arguments of Shannon and Wyner-Ziv. Finally, we demonstrate the
expansive scope of our technique by re-deriving known coding theorems. We shall
observe that our infinite order descriptions simplify to the expected first
order in the known special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508119</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508119</id><created>2005-08-26</created><authors><author><keyname>Jana</keyname><forenames>Soumya</forenames></author></authors><title>Unified Theory of Source Coding: Part II -- Multiterminal Problems</title><categories>cs.IT math.IT</categories><comments>35 pages, submitted to IEEE-T-Inform. Theory</comments><abstract>  In the first paper of this two part communication, we solved in a unified
framework a variety of two terminal source coding problems with noncooperative
encoders, thereby consolidating works of Shannon, Slepian-Wolf, Wyner,
Ahlswede-K\&quot;{o}rner, Wyner-Ziv, Berger {\em et al.} and Berger-Yeung. To
achieve such unification we made use of a fundamental principle that
dissociates bulk of the analysis from the distortion criterion at hand (if any)
and extends the typicality arguments of Shannon and Wyner-Ziv. In this second
paper, we generalize the fundamental principle for any number of sources and on
its basis exhaustively solve all multiterminal source coding problems with
noncooperative encoders and one decoder. The distortion criteria, when
applicable, are required to apply to single letters and be bounded. Our
analysis includes cases where side information is, respectively, partially
available, completely available and altogether unavailable at the decoder. As
seen in our first paper, the achievable regions permit infinite order
information-theoretic descriptions. We also show that the entropy-constrained
multiterminal estimation problem can be solved as a special case of our theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508120</id><created>2005-08-26</created><authors><author><keyname>Berman</keyname><forenames>Gennady P.</forenames><affiliation>Theoretical Division, Los Alamos National Laboratory</affiliation></author><author><keyname>Gorshkov</keyname><forenames>Vyacheslav N.</forenames><affiliation>Theoretical Division, Los Alamos National Laboratory</affiliation></author><author><keyname>MacKerrow</keyname><forenames>Edward P.</forenames><affiliation>Theoretical Division, Los Alamos National Laboratory</affiliation></author><author><keyname>Wang</keyname><forenames>Xidi</forenames><affiliation>Global Consumer Bank, Citigroup</affiliation></author></authors><title>Iterative Algorithm for Finding Frequent Patterns in Transactional
  Databases</title><categories>cs.DB</categories><comments>13 pages, 8 tables and figures</comments><abstract>  A high-performance algorithm for searching for frequent patterns (FPs) in
transactional databases is presented. The search for FPs is carried out by
using an iterative sieve algorithm by computing the set of enclosed cycles. In
each inner cycle of level FPs composed of elements are generated. The assigned
number of enclosed cycles (the parameter of the problem) defines the maximum
length of the desired FPs. The efficiency of the algorithm is produced by (i)
the extremely simple logical searching scheme, (ii) the avoidance of recursive
procedures, and (iii) the usage of only one-dimensional arrays of integers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508121</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508121</id><created>2005-08-27</created><authors><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author></authors><title>How Good is Phase-Shift Keying for Peak-Limited Rayleigh Fading Channels
  in the Low-SNR Regime?</title><categories>cs.IT math.IT</categories><comments>22 pages, 7 figures, submitted to IEEE Trans. Inform. Theory</comments><abstract>  This paper investigates the achievable information rate of phase-shift keying
(PSK) over frequency non-selective Rayleigh fading channels without channel
state information (CSI). The fading process exhibits general temporal
correlation characterized by its spectral density function. We consider both
discrete-time and continuous-time channels, and find their asymptotics at low
signal-to-noise ratio (SNR). Compared to known capacity upper bounds under peak
constraints, these asymptotics usually lead to negligible rate loss in the
low-SNR regime for slowly time-varying fading channels. We further specialize
to case studies of Gauss-Markov and Clarke's fading models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508122</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508122</id><created>2005-08-27</created><updated>2005-08-29</updated><authors><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>McGregor</keyname><forenames>Andrew</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Streaming and Sublinear Approximation of Entropy and Information
  Distances</title><categories>cs.DS cs.IT math.IT</categories><comments>18 pages</comments><abstract>  In many problems in data mining and machine learning, data items that need to
be clustered or classified are not points in a high-dimensional space, but are
distributions (points on a high dimensional simplex). For distributions,
natural measures of distance are not the $\ell_p$ norms and variants, but
information-theoretic measures like the Kullback-Leibler distance, the
Hellinger distance, and others. Efficient estimation of these distances is a
key component in algorithms for manipulating distributions. Thus, sublinear
resource constraints, either in time (property testing) or space (streaming)
are crucial.
  We start by resolving two open questions regarding property testing of
distributions. Firstly, we show a tight bound for estimating bounded, symmetric
f-divergences between distributions in a general property testing (sublinear
time) framework (the so-called combined oracle model). This yields optimal
algorithms for estimating such well known distances as the Jensen-Shannon
divergence and the Hellinger distance. Secondly, we close a $(\log n)/H$ gap
between upper and lower bounds for estimating entropy $H$ in this model. In a
stream setting (sublinear space), we give the first algorithm for estimating
the entropy of a distribution. Our algorithm runs in polylogarithmic space and
yields an asymptotic constant factor approximation scheme. We also provide
other results along the space/time/approximation tradeoff curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508123</identifier>
 <datestamp>2013-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508123</id><created>2005-08-28</created><authors><author><keyname>Marnette</keyname><forenames>Bruno</forenames></author><author><keyname>Kuncak</keyname><forenames>Viktor</forenames></author><author><keyname>Rinard</keyname><forenames>Martin</forenames></author></authors><title>On Algorithms and Complexity for Sets with Cardinality Constraints</title><categories>cs.PL cs.LO cs.SE</categories><comments>20 pages. 12 figures</comments><report-no>MIT CSAIL Technical Report MIT-LCS-TR-997</report-no><abstract>  Typestate systems ensure many desirable properties of imperative programs,
including initialization of object fields and correct use of stateful library
interfaces. Abstract sets with cardinality constraints naturally generalize
typestate properties: relationships between the typestates of objects can be
expressed as subset and disjointness relations on sets, and elements of sets
can be represented as sets of cardinality one. Motivated by these applications,
this paper presents new algorithms and new complexity results for constraints
on sets and their cardinalities. We study several classes of constraints and
demonstrate a trade-off between their expressive power and their complexity.
  Our first result concerns a quantifier-free fragment of Boolean Algebra with
Presburger Arithmetic. We give a nondeterministic polynomial-time algorithm for
reducing the satisfiability of sets with symbolic cardinalities to constraints
on constant cardinalities, and give a polynomial-space algorithm for the
resulting problem.
  In a quest for more efficient fragments, we identify several subclasses of
sets with cardinality constraints whose satisfiability is NP-hard. Finally, we
identify a class of constraints that has polynomial-time satisfiability and
entailment problems and can serve as a foundation for efficient program
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508124</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508124</id><created>2005-08-29</created><authors><author><keyname>Pakzad</keyname><forenames>Payam</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames></author></authors><title>Coding Schemes for Line Networks</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE international Symposium
  on Information Theory, Adelaide, Australia, Sept. 4-9, 2005</comments><acm-class>H.1.1</acm-class><abstract>  We consider a simple network, where a source and destination node are
connected with a line of erasure channels. It is well known that in order to
achieve the min-cut capacity, the intermediate nodes are required to process
the information. We propose coding schemes for this setting, and discuss each
scheme in terms of complexity, delay, achievable rate, memory requirement, and
adaptability to unknown channel parameters. We also briefly discuss how these
schemes can be extended to more general networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508125</id><created>2005-08-29</created><authors><author><keyname>Bao</keyname><forenames>Sheng</forenames></author><author><keyname>Zheng</keyname><forenames>De-Shun</forenames></author></authors><title>A Sorting Algorithm Based on Calculation</title><categories>cs.DS</categories><abstract>  This article introduces an adaptive sorting algorithm that can relocate
elements accurately by substituting their values into a function which we name
it the guessing function. We focus on building this function which is the
mapping relationship between record values and their corresponding sorted
locations essentially. The time complexity of this algorithm O(n),when records
distributed uniformly. Additionally, similar approach can be used in the
searching algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508126</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508126</id><created>2005-08-29</created><authors><author><keyname>Laot</keyname><forenames>Christophe</forenames></author><author><keyname>Josse</keyname><forenames>Nicolas Le</forenames></author></authors><title>A Closed-Form Solution for the Finite Length Constant Modulus Receiver</title><categories>cs.GT cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  In this paper, a closed-form solution minimizing the Godard or Constant
Modulus (CM) cost function under the practical conditions of finite SNR and
finite equalizer length is derived. While previous work has been reported by
Zeng et al., IEEE Trans. Information Theory. 1998, to establish the link
between the constant modulus and Wiener receivers, we show that under the
Gaussian approximation of intersymbol interference at the output of the
equalizer, the CM finite-length receiver is equivalent to the nonblind MMSE
equalizer up to a complex gain factor. Some simulation results are provided to
support the Gaussian approximation assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508127</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508127</id><created>2005-08-29</created><authors><author><keyname>Ziv</keyname><forenames>Jacob</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>On context-tree prediction of individual sequences</title><categories>cs.IT math.IT</categories><comments>15 pages, submitted to the IEEE Transactions on Information Theory</comments><report-no>CCIT Technical Report no. 545, Dept. of EE, Technion, July 2005</report-no><abstract>  Motivated by the evident success of context-tree based methods in lossless
data compression, we explore, in this paper, methods of the same spirit in
universal prediction of individual sequences. By context-tree prediction, we
refer to a family of prediction schemes, where at each time instant $t$, after
having observed all outcomes of the data sequence $x_1,...,x_{t-1}$, but not
yet $x_t$, the prediction is based on a ``context'' (or a state) that consists
of the $k$ most recent past outcomes $x_{t-k},...,x_{t-1}$, where the choice of
$k$ may depend on the contents of a possibly longer, though limited, portion of
the observed past, $x_{t-k_{\max}},...x_{t-1}$. This is different from the
study reported in [1], where general finite-state predictors as well as
``Markov'' (finite-memory) predictors of fixed order, were studied in the
regime of individual sequences.
  Another important difference between this study and [1] is the asymptotic
regime. While in [1], the resources of the predictor (i.e., the number of
states or the memory size) were kept fixed regardless of the length $N$ of the
data sequence, here we investigate situations where the number of contexts or
states is allowed to grow concurrently with $N$. We are primarily interested in
the following fundamental question: What is the critical growth rate of the
number of contexts, below which the performance of the best context-tree
predictor is still universally achievable, but above which it is not? We show
that this critical growth rate is linear in $N$. In particular, we propose a
universal context-tree algorithm that essentially achieves optimum performance
as long as the growth rate is sublinear, and show that, on the other hand, this
is impossible in the linear case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508128</id><created>2005-08-29</created><authors><author><keyname>Zinoviev</keyname><forenames>Dmitry</forenames></author></authors><title>Mapping DEVS Models onto UML Models</title><categories>cs.OH</categories><comments>6 pages, 4 figures Presented at Simulation Multiconference 2005</comments><acm-class>I.6.1</acm-class><journal-ref>D. Zinoviev, &quot;Mapping DEVS Models onto UML Models,&quot; Proc. of the
  2005 DEVS Integrative M&amp;S Symposium, San Diego, CA, April 2005, pp. 101-106</journal-ref><abstract>  Discrete event simulation specification (DEVS) is a formalism designed to
describe both discrete state and continuous state systems. It is a powerful
abstract mathematical notation. However, until recently it lacked proper
graphical representation, which made computer simulation of DEVS models a
challenging issue. Unified modeling language (UML) is a multipurpose graphical
modeling language, a de-facto industrial modeling standard. There exist several
commercial and open-source UML editors and code generators. Most of them can
save UML models in XML-based XMI files ready for further automated processing.
In this paper, we propose a mapping of DEVS models onto UML state and component
diagrams. This mapping may lead to an eventual unification of the two modeling
formalisms, combining the abstractness of DEVS and expressive power and
``computer friendliness'' of the UML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508129</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508129</id><created>2005-08-30</created><authors><author><keyname>Erdem</keyname><forenames>Esra</forenames></author><author><keyname>Lifschitz</keyname><forenames>Vladimir</forenames></author><author><keyname>Ringe</keyname><forenames>Don</forenames></author></authors><title>Temporal Phylogenetic Networks and Logic Programming</title><categories>cs.LO cs.AI cs.PL</categories><abstract>  The concept of a temporal phylogenetic network is a mathematical model of
evolution of a family of natural languages. It takes into account the fact that
languages can trade their characteristics with each other when linguistic
communities are in contact, and also that a contact is only possible when the
languages are spoken at the same time. We show how computational methods of
answer set programming and constraint logic programming can be used to generate
plausible conjectures about contacts between prehistoric linguistic
communities, and illustrate our approach by applying it to the evolutionary
history of Indo-European languages.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508130</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508130</id><created>2005-08-30</created><authors><author><keyname>Baker</keyname><forenames>Mary</forenames></author><author><keyname>Shah</keyname><forenames>Mehul</forenames></author><author><keyname>Rosenthal</keyname><forenames>David S. H.</forenames></author><author><keyname>Roussopoulos</keyname><forenames>Mema</forenames></author><author><keyname>Maniatis</keyname><forenames>Petros</forenames></author><author><keyname>Giuli</keyname><forenames>TJ</forenames></author><author><keyname>Bungale</keyname><forenames>Prashanth</forenames></author></authors><title>A Fresh Look at the Reliability of Long-term Digital Storage</title><categories>cs.DL cs.DB cs.OS</categories><abstract>  Many emerging Web services, such as email, photo sharing, and web site
archives, need to preserve large amounts of quickly-accessible data
indefinitely into the future. In this paper, we make the case that these
applications' demands on large scale storage systems over long time horizons
require us to re-evaluate traditional storage system designs. We examine
threats to long-lived data from an end-to-end perspective, taking into account
not just hardware and software faults but also faults due to humans and
organizations. We present a simple model of long-term storage failures that
helps us reason about the various strategies for addressing these threats in a
cost-effective manner. Using this model we show that the most important
strategies for increasing the reliability of long-term storage are detecting
latent faults quickly, automating fault repair to make it faster and cheaper,
and increasing the independence of data replicas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508131</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508131</id><created>2005-08-31</created><authors><author><keyname>Gontis</keyname><forenames>V.</forenames></author><author><keyname>Kaulakys</keyname><forenames>B.</forenames></author><author><keyname>Ruseckas</keyname><forenames>J.</forenames></author></authors><title>Point Process Models of 1/f Noise and Internet Traffic</title><categories>cs.NI</categories><comments>6 pages, 2 figures, CNET2004 Proceedings AIP</comments><journal-ref>AIP Conf. Proc. 776, 144 (2005) 144-149</journal-ref><doi>10.1063/1.1985385</doi><abstract>  We present a simple model reproducing the long-range autocorrelations and the
power spectrum of the web traffic. The model assumes the traffic as Poisson
flow of files with size distributed according to the power-law. In this model
the long-range autocorrelations are independent of the network properties as
well as of inter-packet time distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508132</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508132</id><created>2005-08-31</created><authors><author><keyname>Son</keyname><forenames>Tran Cao</forenames></author><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author></authors><title>Planning with Preferences using Logic Programming</title><categories>cs.AI</categories><comments>47 pages, to appear in TPLP</comments><acm-class>F.4.1</acm-class><abstract>  We present a declarative language, PP, for the high-level specification of
preferences between possible solutions (or trajectories) of a planning problem.
This novel language allows users to elegantly express non-trivial,
multi-dimensional preferences and priorities over such preferences. The
semantics of PP allows the identification of most preferred trajectories for a
given goal. We also provide an answer set programming implementation of
planning problems with PP preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0508133</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0508133</id><created>2005-08-31</created><updated>2010-10-31</updated><authors><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>Decompositions of graphs of functions and efficient iterations of lookup
  tables</title><categories>cs.CC cs.CR</categories><comments>Small updates</comments><journal-ref>Discrete Applied Mathematics 155 (2007), 386--393</journal-ref><doi>10.1016/j.dam.2006.06.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every function f implemented as a lookup table can be
implemented such that the computational complexity of evaluating f^m(x) is
small, independently of m and x. The implementation only increases the storage
space by a small_constant_ factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509001</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509001</id><created>2005-08-31</created><authors><author><keyname>Wu</keyname><forenames>X.</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Asymptotic Behavior of Error Exponents in the Wideband Regime</title><categories>cs.IT math.IT</categories><comments>59 pages, 6 figures</comments><abstract>  In this paper, we complement Verd\'{u}'s work on spectral efficiency in the
wideband regime by investigating the fundamental tradeoff between rate and
bandwidth when a constraint is imposed on the error exponent. Specifically, we
consider both AWGN and Rayleigh-fading channels. For the AWGN channel model,
the optimal values of $R_z(0)$ and $\dot{R_z}(0)$ are calculated, where
$R_z(1/B)$ is the maximum rate at which information can be transmitted over a
channel with bandwidth $B/2$ when the error-exponent is constrained to be
greater than or equal to $z.$ Based on this calculation, we say that a sequence
of input distributions is near optimal if both $R_z(0)$ and $\dot{R_z}(0)$ are
achieved. We show that QPSK, a widely-used signaling scheme, is near-optimal
within a large class of input distributions for the AWGN channel. Similar
results are also established for a fading channel where full CSI is available
at the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509002</id><created>2005-08-31</created><authors><author><keyname>L&#xe1;z&#xe1;r</keyname><forenames>Zsolt I.</forenames></author><author><keyname>Heringa</keyname><forenames>Jouke R.</forenames></author><author><keyname>P&#xe2;rv</keyname><forenames>Bazil</forenames></author><author><keyname>de Leeuw</keyname><forenames>Simon W.</forenames></author></authors><title>Component Based Programming in Scientific Computing: The Viable Approach</title><categories>cs.CE cs.GL</categories><acm-class>D.2.13; D.2.12; D.2.11; D.2.9; D.2.6</acm-class><abstract>  Computational scientists are facing a new era where the old ways of
developing and reusing code have to be left behind and a few daring steps are
to be made towards new horizons. The present work analyzes the needs that drive
this change, the factors that contribute to the inertia of the community and
slow the transition, the status and perspective of present attempts, the
principle, practical and technical problems that are to be addressed in the
short and long run.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509003</id><created>2005-08-31</created><authors><author><keyname>L&#xe1;z&#xe1;r</keyname><forenames>Zsolt I.</forenames></author><author><keyname>Kov&#xe1;cs</keyname><forenames>Lehel Istv&#xe1;n</forenames></author><author><keyname>P&#xe2;rv</keyname><forenames>Bazil</forenames></author></authors><title>COMODI: Architecture for a Component-Based Scientific Computing System</title><categories>cs.CE</categories><comments>7 pages, 3 figures</comments><acm-class>D.2.13; D.2.12; D.2.11; D.2.9; D.2.6</acm-class><abstract>  The COmputational MODule Integrator (COMODI) is an initiative aiming at a
component based framework, component developer tool and component repository
for scientific computing. We identify the main ingredients to a solution that
would be sufficiently appealing to scientists and engineers to consider
alternatives to their deeply rooted programming traditions. The overall
structure of the complete solution is sketched with special emphasis on the
Component Developer Tool standing at the basis of COMODI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509004</identifier>
 <datestamp>2007-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509004</id><created>2005-09-02</created><authors><author><keyname>Jost</keyname><forenames>Vincent</forenames><affiliation>Leibniz - IMAG</affiliation></author><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames><affiliation>Leibniz - IMAG</affiliation></author><author><keyname>Maffray</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>Leibniz - IMAG</affiliation></author></authors><title>Precoloring co-Meyniel graphs</title><categories>cs.DM</categories><proxy>ccsd ccsd-00008354</proxy><journal-ref>Graphs and Combinatorics 23, 3 (07/07/2007) 291-301</journal-ref><doi>10.1007/s00373-007-0724-1</doi><abstract>  The pre-coloring extension problem consists, given a graph $G$ and a subset
of nodes to which some colors are already assigned, in finding a coloring of
$G$ with the minimum number of colors which respects the pre-coloring
assignment. This can be reduced to the usual coloring problem on a certain
contracted graph. We prove that pre-coloring extension is polynomial for
complements of Meyniel graphs. We answer a question of Hujter and Tuza by
showing that ``PrExt perfect'' graphs are exactly the co-Meyniel graphs, which
also generalizes results of Hujter and Tuza and of Hertz. Moreover we show
that, given a co-Meyniel graph, the corresponding contracted graph belongs to a
restricted class of perfect graphs (``co-Artemis'' graphs, which are
``co-perfectly contractile'' graphs), whose perfectness is easier to establish
than the strong perfect graph theorem. However, the polynomiality of our
algorithm still depends on the ellipsoid method for coloring perfect graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509005</id><created>2005-09-02</created><authors><author><keyname>McLean</keyname><forenames>Alistair</forenames><affiliation>CSIRO Ict Center</affiliation></author><author><keyname>Wu</keyname><forenames>Mingfang</forenames><affiliation>CSIRO Ict Center</affiliation></author><author><keyname>Vercoustre</keyname><forenames>Anne-Marie</forenames><affiliation>CSIRO Ict Center</affiliation></author></authors><title>Combining Structured Corporate Data and Document Content to Improve
  Expertise Finding</title><categories>cs.IR</categories><comments>long version of the ADCS'03 paper</comments><proxy>ccsd inria-00000193</proxy><abstract>  In this paper, we present an algorithm for automatically building expertise
evidence for finding experts within an organization by combining structured
corporate information with different content. We also describe our test data
collection and our evaluation method. Evaluation of the algorithm shows that
using organizational structure leads to a significant improvement in the
precision of finding an expert. Furthermore we evaluate the impact of using
different data sources on the quality of the results and conclude that Expert
Finding is not a &quot;one engine fits all&quot; solution. It requires an analysis of the
information space into which a solution will be placed and the appropriate
selection and weighting scheme of the data sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509006</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509006</id><created>2005-09-02</created><updated>2006-05-04</updated><authors><author><keyname>Yang</keyname><forenames>Sheng</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Optimal space-time codes for the MIMO amplify-and-forward cooperative
  channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory, revised version</comments><acm-class>H.1.1</acm-class><abstract>  In this work, we extend the non-orthogonal amplify-and-forward (NAF)
cooperative diversity scheme to the MIMO channel. A family of space-time block
codes for a half-duplex MIMO NAF fading cooperative channel with N relays is
constructed. The code construction is based on the non-vanishing determinant
criterion (NVD) and is shown to achieve the optimal diversity-multiplexing
tradeoff (DMT) of the channel. We provide a general explicit algebraic
construction, followed by some examples. In particular, in the single relay
case, it is proved that the Golden code and the 4x4 Perfect code are optimal
for the single-antenna and two-antenna case, respectively. Simulation results
reveal that a significant gain (up to 10dB) can be obtained with the proposed
codes, especially in the single-antenna case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509007</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509007</id><created>2005-09-03</created><authors><author><keyname>Brannstrom</keyname><forenames>Fredrik</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author></authors><title>Non-Data-Aided Parameter Estimation in an Additive White Gaussian Noise
  Channel</title><categories>cs.IT math.IT</categories><abstract>  Non-data-aided (NDA) parameter estimation is considered for
binary-phase-shift-keying transmission in an additive white Gaussian noise
channel. Cramer-Rao lower bounds (CRLBs) for signal amplitude, noise variance,
channel reliability constant and bit-error rate are derived and it is shown how
these parameters relate to the signal-to-noise ratio (SNR). An alternative
derivation of the iterative maximum likelihood (ML) SNR estimator is presented
together with a novel, low complexity NDA SNR estimator. The performance of the
proposed estimator is compared to previously suggested estimators and the CRLB.
The results show that the proposed estimator performs close to the iterative ML
estimator at significantly lower computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509008</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509008</id><created>2005-09-04</created><authors><author><keyname>Singla</keyname><forenames>N.</forenames></author><author><keyname>O'Sullivan</keyname><forenames>J. A.</forenames></author></authors><title>Joint Equalization and Decoding for Nonlinear Two-Dimensional
  Intersymbol Interference Channels with Application to Optical Storage</title><categories>cs.IT math.IT</categories><comments>12 pages, 4 figures, submitted to IEEE Transactions on Communications</comments><abstract>  An algorithm that performs joint equalization and decoding for nonlinear
two-dimensional intersymbol interference channels is presented. The algorithm
performs sum-product message-passing on a factor graph that represents the
underlying system. The two-dimensional optical storage (TWODOS) technology is
an example of a system with nonlinear two-dimensional intersymbol interference.
Simulations for the nonlinear channel model of TWODOS show significant
improvement in performance over uncoded performance. Noise tolerance thresholds
for the algorithm for the TWODOS channel, computed using density evolution, are
also presented and accurately predict the limiting performance of the algorithm
as the codeword length increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509009</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509009</id><created>2005-09-04</created><authors><author><keyname>Singla</keyname><forenames>N.</forenames></author><author><keyname>O'Sullivan</keyname><forenames>J. A.</forenames></author></authors><title>Joint Equalization and Decoding for Nonlinear Two-Dimensional
  Intersymbol Interference Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, 2005 International Symposium on Information
  Theory</comments><abstract>  An algorithm that performs joint equalization and decoding for channels with
nonlinear two-dimensional intersymbol interference is presented. The algorithm
performs sum-product message-passing on a factor graph that represents the
underlying system. The two-dimensional optical storage (TwoDOS) technology is
an example of a system with nonlinear two-dimensional intersymbol interference.
Simulations for the nonlinear channel model of TwoDOS show significant
improvement in performance over uncoded performance. Noise tolerance thresholds
for the TwoDOS channel computed using density evolution are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509010</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509010</id><created>2005-09-04</created><authors><author><keyname>Singla</keyname><forenames>N.</forenames></author><author><keyname>O'Sullivan</keyname><forenames>J. A.</forenames></author></authors><title>Minimum Mean-Square-Error Equalization using Priors for Two-Dimensional
  Intersymbol Interference</title><categories>cs.IT math.IT</categories><comments>12 pages, 4 figures, submitted to IEEE Transactions on Communications</comments><abstract>  Joint equalization and decoding schemes are described for two-dimensional
intersymbol interference (ISI) channels. Equalization is performed using the
minimum mean-square-error (MMSE) criterion. Low-density parity-check codes are
used for error correction. The MMSE schemes are the extension of those proposed
by Tuechler et al. (2002) for one-dimensional ISI channels. Extrinsic
information transfer charts, density evolution, and bit-error rate versus
signal-to-noise ratio curves are used to study the performance of the schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509011</id><created>2005-09-04</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author><author><keyname>Xu</keyname><forenames>Xiaofei</forenames></author><author><keyname>Deng</keyname><forenames>Shengchun</forenames></author></authors><title>Clustering Mixed Numeric and Categorical Data: A Cluster Ensemble
  Approach</title><categories>cs.AI</categories><comments>14 pages</comments><report-no>Tr-2002-10</report-no><abstract>  Clustering is a widely used technique in data mining applications for
discovering patterns in underlying data. Most traditional clustering algorithms
are limited to handling datasets that contain either numeric or categorical
attributes. However, datasets with mixed types of attributes are common in real
life data mining applications. In this paper, we propose a novel
divide-and-conquer technique to solve this problem. First, the original mixed
dataset is divided into two sub-datasets: the pure categorical dataset and the
pure numeric dataset. Next, existing well established clustering algorithms
designed for different types of datasets are employed to produce corresponding
clusters. Last, the clustering results on the categorical and numeric dataset
are combined as a categorical dataset, on which the categorical data clustering
algorithm is used to get the final clusters. Our contribution in this paper is
to provide an algorithm framework for the mixed attributes clustering problem,
in which existing clustering algorithms can be easily integrated, the
capabilities of different kinds of clustering algorithms and characteristics of
different types of datasets could be fully exploited. Comparisons with other
clustering algorithms on real life datasets illustrate the superiority of our
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509012</identifier>
 <datestamp>2009-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509012</id><created>2005-09-05</created><updated>2009-08-01</updated><authors><author><keyname>Suslo</keyname><forenames>T.</forenames></author></authors><title>Kriging Scenario For Capital Markets</title><categories>cs.CE</categories><comments>5 pages, 3 figures, attachments: source code and input files</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An introduction to numerical statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509013</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509013</id><created>2005-09-05</created><authors><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>On the variational distance of independently repeated experiments</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><abstract>  Let P and Q be two probability distributions which differ only for values
with non-zero probability. We show that the variational distance between the
n-fold product distributions P^n and Q^n cannot grow faster than the square
root of n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509014</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509014</id><created>2005-09-05</created><authors><author><keyname>Wang</keyname><forenames>C. -C.</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Kulkarni</keyname><forenames>S. R.</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Poor</keyname><forenames>H. V.</forenames><affiliation>Princeton University</affiliation></author></authors><title>Density Evolution for Asymmetric Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory</comments><doi>10.1109/TIT.2005.858931</doi><abstract>  Density evolution is one of the most powerful analytical tools for
low-density parity-check (LDPC) codes and graph codes with message passing
decoding algorithms. With channel symmetry as one of its fundamental
assumptions, density evolution (DE) has been widely and successfully applied to
different channels, including binary erasure channels, binary symmetric
channels, binary additive white Gaussian noise channels, etc. This paper
generalizes density evolution for non-symmetric memoryless channels, which in
turn broadens the applications to general memoryless channels, e.g. z-channels,
composite white Gaussian noise channels, etc. The central theorem underpinning
this generalization is the convergence to perfect projection for any fixed size
supporting tree. A new iterative formula of the same complexity is then
presented and the necessary theorems for the performance concentration theorems
are developed. Several properties of the new density evolution method are
explored, including stability results for general asymmetric memoryless
channels. Simulations, code optimizations, and possible new applications
suggested by this new density evolution method are also provided. This result
is also used to prove the typicality of linear LDPC codes among the coset code
ensemble when the minimum check node degree is sufficiently large. It is shown
that the convergence to perfect projection is essential to the belief
propagation algorithm even when only symmetric channels are considered. Hence
the proof of the convergence to perfect projection serves also as a completion
of the theory of classical density evolution for symmetric memoryless channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509015</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509015</id><created>2005-09-06</created><updated>2010-12-21</updated><authors><author><keyname>Belal</keyname><forenames>Ahmed</forenames></author><author><keyname>Elmasry</keyname><forenames>Amr</forenames></author></authors><title>Optimal Prefix Codes with Fewer Distinct Codeword Lengths are Easier to
  Construct</title><categories>cs.DS cs.IT math.IT</categories><comments>21 pages, a preliminary version appeared in STACS 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method for constructing minimum-redundancy binary prefix codes is
described. Our method does not explicitly build a Huffman tree; instead it uses
a property of optimal prefix codes to compute the codeword lengths
corresponding to the input weights. Let $n$ be the number of weights and $k$ be
the number of distinct codeword lengths. The running time of our algorithm is
$O(16^k \cdot n)$, which is asymptotically faster than Huffman's algorithm for
sufficiently small $k$. If the given weights were presorted, our algorithm
requires $O(9^k \cdot \log^{2k-1}{n})$ comparisons, which is sub-linear for
sufficiently small $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509016</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509016</id><created>2005-09-06</created><authors><author><keyname>Adib</keyname><forenames>A. B.</forenames></author></authors><title>NP-hardness of the cluster minimization problem revisited</title><categories>cs.CC cond-mat.stat-mech physics.chem-ph</categories><comments>8 pages, 2 figures, accepted to J. Phys. A: Math. and Gen</comments><journal-ref>J. Phys. A: Math. Gen. 38, 8487 (2005)</journal-ref><doi>10.1088/0305-4470/38/40/001</doi><abstract>  The computational complexity of the &quot;cluster minimization problem&quot; is
revisited [L. T. Wille and J. Vennik, J. Phys. A 18, L419 (1985)]. It is argued
that the original NP-hardness proof does not apply to pairwise potentials of
physical interest, such as those that depend on the geometric distance between
the particles. A geometric analog of the original problem is formulated, and a
new proof for such potentials is provided by polynomial time transformation
from the independent set problem for unit disk graphs. Limitations of this
formulation are pointed out, and new subproblems that bear more direct
consequences to the numerical study of clusters are suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509017</id><created>2005-09-06</created><authors><author><keyname>Daniel</keyname><forenames>Gilles</forenames></author><author><keyname>Muchnik</keyname><forenames>Lev</forenames></author><author><keyname>Solomon</keyname><forenames>Sorin</forenames></author></authors><title>Traders imprint themselves by adaptively updating their own avatar</title><categories>cs.MA cs.CE</categories><comments>12 pages, 4 figures, draft of a paper submitted to Artificial
  Economics 2005, September 15-16, Lille, France</comments><abstract>  Simulations of artificial stock markets were considered as early as 1964 and
multi-agent ones were introduced as early as 1989. Starting the early 90's,
collaborations of economists and physicists produced increasingly realistic
simulation platforms. Currently, the market stylized facts are easily
reproduced and one has now to address the realistic details of the Market
Microstructure and of the Traders Behaviour. This calls for new methods and
tools capable of bridging smoothly between simulations and experiments in
economics.
  We propose here the following Avatar-Based Method (ABM). The subjects
implement and maintain their Avatars (programs encoding their personal decision
making procedures) on NatLab, a market simulation platform. Once these
procedures are fed in a computer edible format, they can be operationally used
as such without the need for belabouring, interpreting or conceptualising them.
Thus ABM short-circuits the usual behavioural economics experiments that search
for the psychological mechanisms underlying the subjects behaviour. Finally,
ABM maintains a level of objectivity close to the classical behaviourism while
extending its scope to subjects' decision making mechanisms.
  We report on experiments where Avatars designed and maintained by humans from
different backgrounds (including real traders) compete in a continuous
double-auction market. We hope this unbiased way of capturing the adaptive
evolution of real subjects behaviour may lead to a new kind of behavioural
economics experiments with a high degree of reliability, analysability and
reproducibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509018</id><created>2005-09-06</created><updated>2005-09-06</updated><authors><author><keyname>Rosenthal</keyname><forenames>David S. H.</forenames></author><author><keyname>Robertson</keyname><forenames>Thomas S.</forenames></author><author><keyname>Lipkis</keyname><forenames>Tom</forenames></author><author><keyname>Reich</keyname><forenames>Vicky</forenames></author><author><keyname>Morabito</keyname><forenames>Seth</forenames></author></authors><title>Requirements for Digital Preservation Systems: A Bottom-Up Approach</title><categories>cs.DL</categories><acm-class>H.3.7</acm-class><abstract>  The field of digital preservation is being defined by a set of standards
developed top-down, starting with an abstract reference model (OAIS) and
gradually adding more specific detail. Systems claiming conformance to these
standards are entering production use. Work is underway to certify that systems
conform to requirements derived from OAIS.
  We complement these requirements derived top-down by presenting an alternate,
bottom-up view of the field. The fundamental goal of these systems is to ensure
that the information they contain remains accessible for the long term. We
develop a parallel set of requirements based on observations of how existing
systems handle this task, and on an analysis of the threats to achieving the
goal. On this basis we suggest disclosures that systems should provide as to
how they satisfy their goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509019</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509019</id><created>2005-09-07</created><updated>2005-09-28</updated><authors><author><keyname>Normann</keyname><forenames>Dag</forenames></author></authors><title>Comparing hierarchies of total functionals</title><categories>cs.LO</categories><comments>28 pages</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 2 (October 5,
  2005) lmcs:952</journal-ref><doi>10.2168/LMCS-1(2:4)2005</doi><abstract>  In this paper we consider two hierarchies of hereditarily total and
continuous functionals over the reals based on one extensional and one
intensional representation of real numbers, and we discuss under which
asumptions these hierarchies coincide. This coincidense problem is equivalent
to a statement about the topology of the Kleene-Kreisel continuous functionals.
As a tool of independent interest, we show that the Kleene-Kreisel functionals
may be embedded into both these hierarchies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509020</id><created>2005-09-07</created><authors><author><keyname>Stegmann</keyname><forenames>Johannes</forenames><affiliation>Charite, Berlin</affiliation></author><author><keyname>Grohmann</keyname><forenames>Guenter</forenames><affiliation>Charite, Berlin</affiliation></author></authors><title>Transitive Text Mining for Information Extraction and Hypothesis
  Generation</title><categories>cs.IR cs.AI</categories><comments>12 pages, 6 figures</comments><abstract>  Transitive text mining - also named Swanson Linking (SL) after its primary
and principal researcher - tries to establish meaningful links between
literature sets which are virtually disjoint in the sense that each does not
mention the main concept of the other. If successful, SL may give rise to the
development of new hypotheses. In this communication we describe our approach
to transitive text mining which employs co-occurrence analysis of the medical
subject headings (MeSH), the descriptors assigned to papers indexed in PubMed.
In addition, we will outline the current state of our web-based information
system which will enable our users to perform literature-driven hypothesis
building on their own.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509021</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509021</id><created>2005-09-07</created><authors><author><keyname>Azarian</keyname><forenames>Kambiz</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>The Throughput-Reliability Tradeoff in MIMO Channels</title><categories>cs.IT math.IT</categories><comments>30 pages, 15 figures, Submitted to IEEE transactions on Information
  Theory</comments><acm-class>E.4</acm-class><abstract>  In this paper, an outage limited MIMO channel is considered. We build on
Zheng and Tse's elegant formulation of the diversity-multiplexing tradeoff to
develop a better understanding of the asymptotic relationship between the
probability of error, transmission rate, and signal-to-noise ratio. In
particular, we identify the limitation imposed by the multiplexing gain notion
and develop a new formulation for the throughput-reliability tradeoff that
avoids this limitation. The new characterization is then used to elucidate the
asymptotic trends exhibited by the outage probability curves of MIMO channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509022</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509022</id><created>2005-09-08</created><authors><author><keyname>Westover</keyname><forenames>M. Brandon</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Joseph A.</forenames></author></authors><title>Achievable Rates for Pattern Recognition</title><categories>cs.IT cs.CV math.IT</categories><abstract>  Biological and machine pattern recognition systems face a common challenge:
Given sensory data about an unknown object, classify the object by comparing
the sensory data with a library of internal representations stored in memory.
In many cases of interest, the number of patterns to be discriminated and the
richness of the raw data force recognition systems to internally represent
memory and sensory information in a compressed format. However, these
representations must preserve enough information to accommodate the variability
and complexity of the environment, or else recognition will be unreliable.
Thus, there is an intrinsic tradeoff between the amount of resources devoted to
data representation and the complexity of the environment in which a
recognition system may reliably operate.
  In this paper we describe a general mathematical model for pattern
recognition systems subject to resource constraints, and show how the
aforementioned resource-complexity tradeoff can be characterized in terms of
three rates related to number of bits available for representing memory and
sensory data, and the number of patterns populating a given statistical
environment. We prove single-letter information theoretic bounds governing the
achievable rates, and illustrate the theory by analyzing the elementary cases
where the pattern data is either binary or Gaussian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509023</identifier>
 <datestamp>2007-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509023</id><created>2005-09-08</created><updated>2007-11-13</updated><authors><author><keyname>Cameron</keyname><forenames>Kathie</forenames><affiliation>WLU</affiliation></author><author><keyname>Edmonds</keyname><forenames>Jack</forenames><affiliation>EP INSTITUTE</affiliation></author><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames><affiliation>LGS</affiliation></author><author><keyname>Maffray</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LGS</affiliation></author></authors><title>Coloring vertices of a graph or finding a Meyniel obstruction</title><categories>cs.DM</categories><proxy>ccsd ccsd-00008557</proxy><abstract>  A Meyniel obstruction is an odd cycle with at least five vertices and at most
one chord. A graph is Meyniel if and only if it has no Meyniel obstruction as
an induced subgraph. Here we give a O(n^2) algorithm that, for any graph, finds
either a clique and coloring of the same size or a Meyniel obstruction. We also
give a O(n^3) algorithm that, for any graph, finds either aneasily recognizable
strong stable set or a Meyniel obstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509024</id><created>2005-09-08</created><updated>2006-05-15</updated><authors><author><keyname>Pelov</keyname><forenames>Nikolay</forenames></author><author><keyname>Denecker</keyname><forenames>Marc</forenames></author><author><keyname>Bruynooghe</keyname><forenames>Maurice</forenames></author></authors><title>Well-founded and Stable Semantics of Logic Programs with Aggregates</title><categories>cs.LO</categories><comments>54 pages; To appear in Theory and Practice of Logic Programming
  (TPLP)</comments><abstract>  In this paper, we present a framework for the semantics and the computation
of aggregates in the context of logic programming. In our study, an aggregate
can be an arbitrary interpreted second order predicate or function. We define
extensions of the Kripke-Kleene, the well-founded and the stable semantics for
aggregate programs. The semantics is based on the concept of a three-valued
immediate consequence operator of an aggregate program. Such an operator
approximates the standard two-valued immediate consequence operator of the
program, and induces a unique Kripke-Kleene model, a unique well-founded model
and a collection of stable models. We study different ways of defining such
operators and thus obtain a framework of semantics, offering different
trade-offs between precision and tractability. In particular, we investigate
conditions on the operator that guarantee that the computation of the three
types of semantics remains on the same level as for logic programs without
aggregates. Other results show that, in practice, even efficient three-valued
immediate consequence operators which are very low in the precision hierarchy,
still provide optimal precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509025</id><created>2005-09-09</created><updated>2006-04-06</updated><authors><author><keyname>Avigad</keyname><forenames>Jeremy</forenames></author><author><keyname>Donnelly</keyname><forenames>Kevin</forenames></author><author><keyname>Gray</keyname><forenames>David</forenames></author><author><keyname>Raff</keyname><forenames>Paul</forenames></author></authors><title>A formally verified proof of the prime number theorem</title><categories>cs.AI cs.LO cs.SC</categories><comments>23 pages</comments><acm-class>F.4.1; I.2.3</acm-class><abstract>  The prime number theorem, established by Hadamard and de la Vall'ee Poussin
independently in 1896, asserts that the density of primes in the positive
integers is asymptotic to 1 / ln x. Whereas their proofs made serious use of
the methods of complex analysis, elementary proofs were provided by Selberg and
Erd&quot;os in 1948. We describe a formally verified version of Selberg's proof,
obtained using the Isabelle proof assistant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509026</id><created>2005-09-09</created><authors><author><keyname>Duffield</keyname><forenames>Nick</forenames></author><author><keyname>Lund</keyname><forenames>Carsten</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>Sampling to estimate arbitrary subset sums</title><categories>cs.DS</categories><acm-class>C.2.3; E.1; F.2; G.3; H.3</acm-class><abstract>  Starting with a set of weighted items, we want to create a generic sample of
a certain size that we can later use to estimate the total weight of arbitrary
subsets. For this purpose, we propose priority sampling which tested on
Internet data performed better than previous methods by orders of magnitude.
  Priority sampling is simple to define and implement: we consider a steam of
items i=0,...,n-1 with weights w_i. For each item i, we generate a random
number r_i in (0,1) and create a priority q_i=w_i/r_i. The sample S consists of
the k highest priority items. Let t be the (k+1)th highest priority. Each
sampled item i in S gets a weight estimate W_i=max{w_i,t}, while non-sampled
items get weight estimate W_i=0.
  Magically, it turns out that the weight estimates are unbiased, that is,
E[W_i]=w_i, and by linearity of expectation, we get unbiased estimators over
any subset sum simply by adding the sampled weight estimates from the subset.
Also, we can estimate the variance of the estimates, and surpricingly, there is
no co-variance between different weight estimates W_i and W_j.
  We conjecture an extremely strong near-optimality; namely that for any weight
sequence, there exists no specialized scheme for sampling k items with unbiased
estimators that gets smaller total variance than priority sampling with k+1
items. Very recently Mario Szegedy has settled this conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509027</id><created>2005-09-10</created><authors><author><keyname>Kiselyov</keyname><forenames>Oleg</forenames></author><author><keyname>Laemmel</keyname><forenames>Ralf</forenames></author></authors><title>Haskell's overlooked object system</title><categories>cs.PL</categories><comments>79 pages; software available at
  http://homepages.cwi.nl/~ralf/OOHaskell/</comments><acm-class>D.1.5; D.1.1; D.2.3; D.3.3</acm-class><abstract>  Haskell provides type-class-bounded and parametric polymorphism as opposed to
subtype polymorphism of object-oriented languages such as Java and OCaml. It is
a contentious question whether Haskell 98 without extensions, or with common
extensions, or with new extensions can fully support conventional
object-oriented programming with encapsulation, mutable state, inheritance,
overriding, statically checked implicit and explicit subtyping, and so on. We
systematically substantiate that Haskell 98, with some common extensions,
supports all the conventional OO features plus more advanced ones, including
first-class lexically scoped classes, implicitly polymorphic classes, flexible
multiple inheritance, safe downcasts and safe co-variant arguments. Haskell
indeed can support width and depth, structural and nominal subtyping. We
address the particular challenge to preserve Haskell's type inference even for
objects and object-operating functions. The OO features are introduced in
Haskell as the OOHaskell library. OOHaskell lends itself as a sandbox for typed
OO language design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509028</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509028</id><created>2005-09-10</created><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Projecting the Forward Rate Flow onto a Finite Dimensional Manifold</title><categories>cs.CE cs.IT math.IT</categories><comments>To appear in the International Journal of Theoretical and Applied
  Finance</comments><acm-class>G.3</acm-class><abstract>  Given a Heath-Jarrow-Morton (HJM) interest rate model $\mathcal{M}$ and a
parametrized family of finite dimensional forward rate curves $\mathcal{G}$,
this paper provides a technique for projecting the infinite dimensional forward
rate curve $r_{t}$ given by $\mathcal{M}$ onto the finite dimensional manifold
$\mathcal{G}$.The Stratonovich dynamics of the projected finite dimensional
forward curve are derived and it is shown that, under the regularity
conditions, the given Stratonovich differential equation has a unique strong
solution. Moreover, this projection leads to an efficient algorithm for
implicit parametric estimation of the infinite dimensional HJM model. The
feasibility of this method is demonstrated by applying the generalized method
of moments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509029</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509029</id><created>2005-09-10</created><updated>2007-04-25</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Quickest detection of a minimum of disorder times</title><categories>cs.CE cs.IT math.IT</categories><comments>To appear in the SIAM Journal on Control and Optimization</comments><acm-class>G.3</acm-class><abstract>  A multi-source quickest detection problem is considered. Assume there are two
independent Poisson processes $X^{1}$ and $X^{2}$ with disorder times
$\theta_{1}$ and $\theta_{2}$, respectively; that is, the intensities of $X^1$
and $X^2$ change at random unobservable times $\theta_1$ and $\theta_2$,
respectively. $\theta_1$ and $\theta_2$ are independent of each other and are
exponentially distributed. Define $\theta \triangleq \theta_1 \wedge
\theta_2=\min\{\theta_{1},\theta_{2}\}$ . For any stopping time $\tau$ that is
measurable with respect to the filtration generated by the observations define
a penalty function of the form \[ R_{\tau}=\mathbb{P}(\tau&lt;\theta)+c
\mathbb{E}[(\tau-\theta)^{+}], \] where $c&gt;0$ and $(\tau-\theta)^{+}$ is the
positive part of $\tau-\theta$. It is of interest to find a stopping time
$\tau$ that minimizes the above performance index. Since both observations
$X^{1}$ and $X^{2}$ reveal information about the disorder time $\theta$, even
this simple problem is more involved than solving the disorder problems for
$X^{1}$ and $X^{2}$ separately. This problem is formulated in terms of a three
dimensional sufficient statistic, and the corresponding optimal stopping
problem is examined. A two dimensional optimal stopping problem whose optimal
stopping time turns out to coincide with the optimal stopping time of the
original problem for some range of parameters is also solved. The value
function of this problem serves as a tight upper bound for the original
problem's value function. The two solutions are characterized by iterating
suitable functional operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509030</id><created>2005-09-12</created><authors><author><keyname>Jun-Bao</keyname><forenames>Liu</forenames></author><author><keyname>Guo-Zhen</keyname><forenames>Xiao</forenames></author></authors><title>Multi-Proxy Multi-Signcryption Scheme from Pairings</title><categories>cs.CR</categories><comments>4 pages</comments><acm-class>D.4.6</acm-class><abstract>  A first multi-proxy multi-signcryption scheme from pairings, which
efficiently combines a multi-proxy multi-signature scheme with a signcryption,
is proposed. Its security is analyzed in detail. In our scheme, a proxy
signcrypter group could be authorized as a proxy agent by the cooperation of
all members in the original signcrypter group. Then the proxy signcryptions can
be generated by the cooperation of all the signcrypters in the authorized proxy
signcrypter group on behalf of the original signcrypter group. The correctness
and the security of this scheme are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509031</id><created>2005-09-12</created><authors><author><keyname>Csirik</keyname><forenames>Janos</forenames></author><author><keyname>Johnson</keyname><forenames>David S.</forenames></author><author><keyname>Kenyon</keyname><forenames>Claire</forenames></author></authors><title>On the Worst-case Performance of the Sum-of-Squares Algorithm for Bin
  Packing</title><categories>cs.DS</categories><acm-class>F.2.2</acm-class><abstract>  The Sum of Squares algorithm for bin packing was defined in [2] and studied
in great detail in [1], where it was proved that its worst case performance
ratio is at most 3. In this note, we improve the asymptotic worst case bound to
2.7777...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509032</id><created>2005-09-12</created><authors><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Boussemart</keyname><forenames>Frederic</forenames></author><author><keyname>Hemery</keyname><forenames>Fred</forenames></author><author><keyname>Lecoutre</keyname><forenames>Christophe</forenames></author></authors><title>A Simple Model to Generate Hard Satisfiable Instances</title><categories>cs.AI cond-mat.stat-mech cs.CC</categories><comments>Proc. of 19th IJCAI, pp.337-342, Edinburgh, Scotland, 2005. For
  more information, please click
  http://www.nlsde.buaa.edu.cn/~kexu/papers/ijcai05-abstract.htm</comments><acm-class>F.2.2; I.2.8</acm-class><abstract>  In this paper, we try to further demonstrate that the models of random CSP
instances proposed by [Xu and Li, 2000; 2003] are of theoretical and practical
interest. Indeed, these models, called RB and RD, present several nice
features. First, it is quite easy to generate random instances of any arity
since no particular structure has to be integrated, or property enforced, in
such instances. Then, the existence of an asymptotic phase transition can be
guaranteed while applying a limited restriction on domain size and on
constraint tightness. In that case, a threshold point can be precisely located
and all instances have the guarantee to be hard at the threshold, i.e., to have
an exponential tree-resolution complexity. Next, a formal analysis shows that
it is possible to generate forced satisfiable instances whose hardness is
similar to unforced satisfiable ones. This analysis is supported by some
representative results taken from an intensive experimentation that we have
carried out, using complete and incomplete search methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509033</id><created>2005-09-13</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author><author><keyname>Xu</keyname><forenames>Xiaofei</forenames></author><author><keyname>Deng</keyname><forenames>Shengchun</forenames></author><author><keyname>Dong</keyname><forenames>Bin</forenames></author></authors><title>K-Histograms: An Efficient Clustering Algorithm for Categorical Dataset</title><categories>cs.AI</categories><comments>11 pages</comments><report-no>Tr-2003-08</report-no><abstract>  Clustering categorical data is an integral part of data mining and has
attracted much attention recently. In this paper, we present k-histogram, a new
efficient algorithm for clustering categorical data. The k-histogram algorithm
extends the k-means algorithm to categorical domain by replacing the means of
clusters with histograms, and dynamically updates histograms in the clustering
process. Experimental results on real datasets show that k-histogram algorithm
can produce better clustering results than k-modes algorithm, the one related
with our work most closely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509034</id><created>2005-09-13</created><authors><author><keyname>Pouzet</keyname><forenames>Maurice</forenames><affiliation>ICJ</affiliation></author><author><keyname>Zaguia</keyname><forenames>Nejib</forenames><affiliation>SITE</affiliation></author></authors><title>N-free extensions of posets.Note on a theorem of P.A.Grillet</title><categories>cs.DM</categories><comments>7 pages, 4 pictures</comments><proxy>ccsd ccsd-00008643</proxy><acm-class>I.1.2; I.4.10; I.5</acm-class><abstract>  Let $S\_{N}(P)$ be the poset obtained by adding a dummy vertex on each
diagonal edge of the $N$'s of a finite poset $P$. We show that
$S\_{N}(S\_{N}(P))$ is $N$-free. It follows that this poset is the smallest
$N$-free barycentric subdivision of the diagram of $P$, poset whose existence
was proved by P.A. Grillet. This is also the poset obtained by the algorithm
starting with $P\_0:=P$ and consisting at step $m$ of adding a dummy vertex on
a diagonal edge of some $N$ in $P\_m$, proving that the result of this
algorithm does not depend upon the particular choice of the diagonal edge
choosen at each step. These results are linked to drawing of posets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509035</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509035</id><created>2005-09-13</created><updated>2007-10-24</updated><authors><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author><author><keyname>Cheung</keyname><forenames>Albert</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author></authors><title>Cryptanalysis of an MPEG-Video Encryption Scheme Based on Secret Huffman
  Tables</title><categories>cs.MM cs.CR</categories><comments>8 pages, 4 figures</comments><journal-ref>Advances in Image and Video Technology - Third Pacific Rim
  Symposium, PSIVT 2009, Tokyo, Japan, January 13-16, 2009. Proceedings,
  Lecture Notes in Computer Science, vol. 5414, pp. 898-909, 2009</journal-ref><doi>10.1007/978-3-540-92957-4_78</doi><abstract>  This paper studies the security of a recently-proposed MPEG-video encryption
scheme based on secret Huffman tables. Our cryptanalysis shows that: 1) the key
space of the encryption scheme is not sufficiently large against
divide-and-conquer (DAC) attack and known-plaintext attack; 2) it is possible
to decrypt a cipher-video with a partially-known key, thus dramatically
reducing the complexity of the DAC brute-force attack in some cases; 3) its
security against the chosen-plaintext attack is very weak. Some experimental
results are included to support the cryptanalytic results with a brief discuss
on how to improve this MPEG-video encryption scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509036</id><created>2005-09-13</created><updated>2006-06-25</updated><authors><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author></authors><title>Security Problems with Improper Implementations of Improved FEA-M</title><categories>cs.CR cs.MM</categories><comments>8 pages, elsart.cls</comments><journal-ref>Journal of Systems and Software, vol. 80, no. 5, pp. 791-794, 2007</journal-ref><doi>10.1016/j.jss.2006.05.002</doi><abstract>  This paper reports security problems with improper implementations of an
improved version of FEA-M (fast encryption algorithm for multimedia). It is
found that an implementation-dependent differential chosen-plaintext attack or
its chosen-ciphertext counterpart can reveal the secret key of the
cryptosystem, if the involved (pseudo-)random process can be tampered (for
example, through a public time service). The implementation-dependent
differential attack is very efficient in complexity and needs only $O(n^2)$
chosen plaintext or ciphertext bits. In addition, this paper also points out a
minor security problem with the selection of the session key. In real
implementations of the cryptosystem, these security problems should be
carefully avoided, or the cryptosystem has to be further enhanced to work under
such weak implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509037</id><created>2005-09-14</created><authors><author><keyname>Hales</keyname><forenames>David</forenames></author><author><keyname>Arteconi</keyname><forenames>Stefano</forenames></author></authors><title>Friends for Free: Self-Organizing Artificial Social Networks for Trust
  and Cooperation</title><categories>cs.MA</categories><abstract>  By harvesting friendship networks from e-mail contacts or instant message
&quot;buddy lists&quot; Peer-to-Peer (P2P) applications can improve performance in low
trust environments such as the Internet. However, natural social networks are
not always suitable, reliable or available. We propose an algorithm (SLACER)
that allows peer nodes to create and manage their own friendship networks.
  We evaluate performance using a canonical test application, requiring
cooperation between peers for socially optimal outcomes. The Artificial Social
Networks (ASN) produced are connected, cooperative and robust - possessing many
of the disable properties of human friendship networks such as trust between
friends (directly linked peers) and short paths linking everyone via a chain of
friends.
  In addition to new application possibilities, SLACER could supply ASN to P2P
applications that currently depend on human social networks thus transforming
them into fully autonomous, self-managing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509038</id><created>2005-09-14</created><authors><author><keyname>Dahllof</keyname><forenames>Vilhelm</forenames></author></authors><title>Algorithms for Max Hamming Exact Satisfiability</title><categories>cs.DS</categories><abstract>  We here study Max Hamming XSAT, ie, the problem of finding two XSAT models at
maximum Hamming distance. By using a recent XSAT solver as an auxiliary
function, an O(1.911^n) time algorithm can be constructed, where n is the
number of variables. This upper time bound can be further improved to
O(1.8348^n) by introducing a new kind of branching, more directly suited for
finding models at maximum Hamming distance. The techniques presented here are
likely to be of practical use as well as of theoretical value, proving that
there are non-trivial algorithms for maximum Hamming distance problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509039</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509039</id><created>2005-09-14</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Coding for the feedback Gel'fand-Pinsker channel and the feedforward
  Wyner-Ziv source</title><categories>cs.IT math.IT</categories><abstract>  We consider both channel coding and source coding, with perfect past
feedback/feedforward, in the presence of side information. It is first observed
that feedback does not increase the capacity of the Gel'fand-Pinsker channel,
nor does feedforward improve the achievable rate-distortion performance in the
Wyner-Ziv problem. We then focus on the Gaussian case showing that, as in the
absence of side information, feedback/feedforward allows to efficiently attain
the respective performance limits. In particular, we derive schemes via
variations on that of Schalkwijk and Kailath. These variants, which are as
simple as their origins and require no binning, are shown to achieve,
respectively, the capacity of Costa's channel, and the Wyner-Ziv rate
distortion function. Finally, we consider the finite-alphabet setting and
derive schemes for both the channel and the source coding problems that attain
the fundamental limits, using variations on schemes of Ahlswede and Ooi and
Wornell, and of Martinian and Wornell, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509040</id><created>2005-09-14</created><authors><author><keyname>Betz</keyname><forenames>Christian</forenames></author><author><keyname>Hoernlein</keyname><forenames>Alexander</forenames></author><author><keyname>Puppe</keyname><forenames>Frank</forenames></author></authors><title>Authoring case based training by document data extraction</title><categories>cs.AI cs.IR</categories><comments>11 pages, 10th ChEM Workshop, 2005; technical article</comments><abstract>  In this paper, we propose an scalable approach to modeling based upon word
processing documents, and we describe the tool Phoenix providing the technical
infrastructure.
  For our training environment d3web.Train, we developed a tool to extract case
knowledge from existing documents, usually dismissal records, extending Phoenix
to d3web.CaseImporter. Independent authors used this tool to develop training
systems, observing a significant decrease of time for setteling-in and a
decrease of time necessary for developing a case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509041</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509041</id><created>2005-09-14</created><authors><author><keyname>Bloch</keyname><forenames>Matthieu</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steven W.</forenames></author></authors><title>Efficient Reconciliation of Correlated Continuous Random Variables using
  LDPC Codes</title><categories>cs.IT math.IT</categories><comments>9 pages, 9 figures</comments><abstract>  This paper investigates an efficient and practical information reconciliation
method in the case where two parties have access to correlated continuous
random variables. We show that reconciliation is a special case of channel
coding and that existing coded modulation techniques can be adapted for
reconciliation. We describe an explicit reconciliation method based on LDPC
codes in the case of correlated Gaussian variables. We believe that the
proposed method can improve the efficiency of quantum key distribution
protocols based on continuous-spectrum quantum states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509042</id><created>2005-09-14</created><authors><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Cook</keyname><forenames>Stephen</forenames></author></authors><title>Computing over the Reals: Foundations for Scientific Computing</title><categories>cs.CC cs.LO</categories><acm-class>F.1.1; G.0</acm-class><abstract>  We give a detailed treatment of the ``bit-model'' of computability and
complexity of real functions and subsets of R^n, and argue that this is a good
way to formalize many problems of scientific computation. In the introduction
we also discuss the alternative Blum-Shub-Smale model. In the final section we
discuss the issue of whether physical systems could defeat the Church-Turing
Thesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509043</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509043</id><created>2005-09-14</created><authors><author><keyname>Feiten</keyname><forenames>Anke</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>Optimal Power Control for Multiuser CDMA Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4-9, 2005</comments><abstract>  In this paper, we define the power region as the set of power allocations for
K users such that everybody meets a minimum signal-to-interference ratio (SIR).
The SIR is modeled in a multiuser CDMA system with fixed linear receiver and
signature sequences. We show that the power region is convex in linear and
logarithmic scale. It furthermore has a componentwise minimal element. Power
constraints are included by the intersection with the set of all viable power
adjustments.
  In this framework, we aim at minimizing the total expended power by
minimizing a componentwise monotone functional. If the feasible power region is
nonempty, the minimum is attained. Otherwise, as a solution to balance
conflicting interests, we suggest the projection of the minimum point in the
power region onto the set of viable power settings. Finally, with an
appropriate utility function, the problem of minimizing the total expended
power can be seen as finding the Nash bargaining solution, which sheds light on
power assignment from a game theoretic point of view. Convexity and
componentwise monotonicity are essential prerequisites for this result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509044</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509044</id><created>2005-09-15</created><authors><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>Accumulate-Repeat-Accumulate Codes: Systematic Codes Achieving the
  Binary Erasure Channel Capacity with Bounded Complexity</title><categories>cs.IT math.IT</categories><comments>15 pages, 3 figures (please ignore the 16th page in the PDF file,
  which appears as a result of a temporary problem in the compilation of the
  PDF; however, the PS file is indeed 15 pages). The paper will be presented in
  the Forty-Third Annual Allerton Conference on Communication, Control and
  Computing, Monticello, IL, USA, Sept. 28-30, 2005</comments><abstract>  The paper introduces ensembles of accumulate-repeat-accumulate (ARA) codes
which asymptotically achieve capacity on the binary erasure channel (BEC) with
{\em bounded complexity} per information bit. It also introduces symmetry
properties which play a central role in the construction of capacity-achieving
ensembles for the BEC. The results here improve on the tradeoff between
performance and complexity provided by the first capacity-achieving ensembles
of irregular repeat-accumulate (IRA) codes with bounded complexity per
information bit; these IRA ensembles were previously constructed by Pfister,
Sason and Urbanke. The superiority of ARA codes with moderate to large block
length is exemplified by computer simulations which compare their performance
with those of previously reported capacity-achieving ensembles of LDPC and IRA
codes. The ARA codes also have the advantage of being systematic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509045</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509045</id><created>2005-09-15</created><authors><author><keyname>Lenstra</keyname><forenames>Hendrik W.</forenames></author><author><keyname>Seroussi</keyname><forenames>Gadiel</forenames></author></authors><title>On Hats and other Covers</title><categories>cs.IT math.IT</categories><comments>IEEE International Symposium on Information Theory, Lausanne,
  Switzerland, July 2002</comments><acm-class>E.4; H.1.1</acm-class><abstract>  We study a game puzzle that has enjoyed recent popularity among
mathematicians, computer scientist, coding theorists and even the mass press.
In the game, $n$ players are fitted with randomly assigned colored hats.
Individual players can see their teammates' hat colors, but not their own.
Based on this information, and without any further communication, each player
must attempt to guess his hat color, or pass. The team wins if there is at
least one correct guess, and no incorrect ones. The goal is to devise guessing
strategies that maximize the team winning probability. We show that for the
case of two hat colors, and for any value of $n$, playing strategies are
equivalent to binary covering codes of radius one. This link, in particular
with Hamming codes, had been observed for values of $n$ of the form $2^m-1$. We
extend the analysis to games with hats of $q$ colors, $q\geq 2$, where
1-coverings are not sufficient to characterize the best strategies. Instead, we
introduce the more appropriate notion of a {\em strong covering}, and show
efficient constructions of these coverings, which achieve winning probabilities
approaching unity. Finally, we briefly discuss results on variants of the
problem, including arbitrary input distributions, randomized playing
strategies, and symmetric strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509046</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509046</id><created>2005-09-15</created><updated>2007-07-15</updated><authors><author><keyname>Seroussi</keyname><forenames>Gadiel</forenames></author></authors><title>On the number of t-ary trees with a given path length</title><categories>cs.DM cs.IT math.IT</categories><comments>July 2007: added journal reference and DOI, updated references, minor
  typographical corrections</comments><acm-class>G.2.1; G.2.2; E.4; H.1.1</acm-class><journal-ref>Algorithmica, Vol. 46, No. 3, pp. 557--565, 2006</journal-ref><doi>10.1007/s00453-006-0122-8</doi><abstract>  We show that the number of $t$-ary trees with path length equal to $p$ is
$\exp(h(t^{-1})t\log t \frac{p}{\log p}(1+o(1)))$, where
$\entropy(x){=}{-}x\log x {-}(1{-}x)\log (1{-}x)$ is the binary entropy
function. Besides its intrinsic combinatorial interest, the question recently
arose in the context of information theory, where the number of $t$-ary trees
with path length $p$ estimates the number of universal types, or, equivalently,
the number of different possible Lempel-Ziv'78 dictionaries for sequences of
length $p$ over an alphabet of size $t$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509047</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509047</id><created>2005-09-16</created><authors><author><keyname>Kobayashi</keyname><forenames>Daisuke</forenames></author><author><keyname>Yamamoto</keyname><forenames>Hirosuke</forenames></author><author><keyname>Ogawa</keyname><forenames>Tomohiro</forenames></author></authors><title>Secure multiplex coding to attain the channel capacity in wiretap
  channels</title><categories>cs.IT cs.CR math.IT</categories><comments>15 pages, submitted to the IEEE Transactions on Information Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  It is known that a message can be transmitted safely against any wiretapper
via a noisy channel without a secret key if the coding rate is less than the
so-called secrecy capacity $C_S$, which is usually smaller than the channel
capacity $C$. In order to remove the loss $C - C_S$, we propose a multiplex
coding scheme with plural independent messages. In this paper, it is shown that
the proposed multiplex coding scheme can attain the channel capacity as the
total rate of the plural messages and the perfect secrecy for each message. The
coding theorem is proved by extending Hayashi's proof, in which the coding of
the channel resolvability is applied to wiretap channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509048</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509048</id><created>2005-09-16</created><authors><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author><author><keyname>Weiss</keyname><forenames>Anthony J.</forenames></author></authors><title>Capacity of Complexity-Constrained Noise-Free CDMA</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Communications Letters</comments><abstract>  An interference-limited noise-free CDMA downlink channel operating under a
complexity constraint on the receiver is introduced. According to this
paradigm, detected bits, obtained by performing hard decisions directly on the
channel's matched filter output, must be the same as the transmitted binary
inputs. This channel setting, allowing the use of the simplest receiver scheme,
seems to be worthless, making reliable communication at any rate impossible. We
prove, by adopting statistical mechanics notion, that in the large-system limit
such a complexity-constrained CDMA channel gives rise to a non-trivial
Shannon-theoretic capacity, rigorously analyzed and corroborated using
finite-size channel simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509049</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509049</id><created>2005-09-16</created><authors><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author><author><keyname>Weiss</keyname><forenames>Anthony J.</forenames></author></authors><title>On the Achievable Information Rates of CDMA Downlink with Trivial
  Receivers</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  A noisy CDMA downlink channel operating under a strict complexity constraint
on the receiver is introduced. According to this constraint, detected bits,
obtained by performing hard decisions directly on the channel's matched filter
output, must be the same as the transmitted binary inputs. This channel
setting, allowing the use of the simplest receiver scheme, seems to be
worthless, making reliable communication at any rate impossible. However,
recently this communication paradigm was shown to yield valuable information
rates in the case of a noiseless channel. This finding calls for the
investigation of this attractive complexity-constrained transmission scheme for
the more practical noisy channel case. By adopting the statistical mechanics
notion of metastable states of the renowned Hopfield model, it is proved that
under a bounded noise assumption such complexity-constrained CDMA channel gives
rise to a non-trivial Shannon-theoretic capacity, rigorously analyzed and
corroborated using finite-size channel simulations. For unbounded noise the
channel's outage capacity is addressed and specifically described for the
popular additive white Gaussian noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509050</id><created>2005-09-16</created><authors><author><keyname>Amos</keyname><forenames>Martyn</forenames></author><author><keyname>Wood</keyname><forenames>Andrew</forenames></author></authors><title>Effect of door delay on aircraft evacuation time</title><categories>cs.MA</categories><comments>8 pages, 2 figures</comments><abstract>  The recent commercial launch of twin-deck Very Large Transport Aircraft
(VLTA) such as the Airbus A380 has raised questions concerning the speed at
which they may be evacuated. The abnormal height of emergency exits on the
upper deck has led to speculation that emotional factors such as fear may lead
to door delay, and thus play a significant role in increasing overall
evacuation time. Full-scale evacuation tests are financially expensive and
potentially hazardous, and systematic studies of the evacuation of VLTA are
rare. Here we present a computationally cheap agent-based framework for the
general simulation of aircraft evacuation, and apply it to the particular case
of the Airbus A380. In particular, we investigate the effect of door delay, and
conclude that even a moderate average delay can lead to evacuation times that
exceed the maximum for safety certification. The model suggests practical ways
to minimise evacuation time, as well as providing a general framework for the
simulation of evacuation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509052</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509052</id><created>2005-09-18</created><authors><author><keyname>Ng</keyname><forenames>W. -Y.</forenames></author><author><keyname>Chiu</keyname><forenames>D. M.</forenames></author><author><keyname>Lin</keyname><forenames>W. K.</forenames></author></authors><title>Club Formation by Rational Sharing : Content, Viability and Community
  Structure</title><categories>cs.NI cond-mat.stat-mech physics.soc-ph</categories><comments>accepted in WINE2005, Hong Kong, December 15-17, 2005</comments><abstract>  A sharing community prospers when participation and contribution are both
high. We suggest the two, while being related decisions every peer makes,
should be given separate rational bases. Considered as such, a basic issue is
the viability of club formation, which necessitates the modelling of two major
sources of heterogeneity, namely, peers and shared content. This viability
perspective clearly explains why rational peers contribute (or free-ride when
they don't) and how their collective action determines viability as well as the
size of the club formed. It also exposes another fundamental source of
limitation to club formation apart from free-riding, in the community structure
in terms of the relation between peers' interest (demand) and sharing (supply).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509053</id><created>2005-09-18</created><authors><author><keyname>Holden</keyname><forenames>Joshua</forenames></author><author><keyname>Layton</keyname><forenames>Richard</forenames></author><author><keyname>Merkle</keyname><forenames>Laurence</forenames></author><author><keyname>Hudson</keyname><forenames>Tina</forenames></author></authors><title>Underwater Hacker Missile Wars: A Cryptography and Engineering Contest</title><categories>cs.CR cs.CE</categories><comments>11 pages, 3 figures, uses amsrefs.sty v2.0 and cryptologiabib.sty
  (included); to appear in Cryptologia</comments><journal-ref>Cryptologia, 30:69--77, 2006</journal-ref><abstract>  For a recent student conference, the authors developed a day-long design
problem and competition suitable for engineering, mathematics and science
undergraduates. The competition included a cryptography problem, for which a
workshop was run during the conference. This paper describes the competition,
focusing on the cryptography problem and the workshop. Notes from the workshop
and code for the computer programs are made available via the Internet. The
results of a personal self-evaluation (PSE) are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509054</id><created>2005-09-18</created><updated>2006-09-27</updated><authors><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Flatland</keyname><forenames>Robin</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Grid Vertex-Unfolding Orthogonal Polyhedra</title><categories>cs.CG cs.DM</categories><comments>Original: 12 pages, 8 figures, 11 references. Revised: 22 pages, 16
  figures, 12 references. New version is a substantial revision superceding the
  preliminary extended abstract that appeared in Lecture Notes in Computer
  Science, Volume 3884, Springer, Berlin/Heidelberg, Feb. 2006, pp. 264-276</comments><acm-class>F.2.2</acm-class><abstract>  An edge-unfolding of a polyhedron is produced by cutting along edges and
flattening the faces to a *net*, a connected planar piece with no overlaps. A
*grid unfolding* allows additional cuts along grid edges induced by coordinate
planes passing through every vertex. A vertex-unfolding permits faces in the
net to be connected at single vertices, not necessarily along edges. We show
that any orthogonal polyhedron of genus zero has a grid vertex-unfolding.
(There are orthogonal polyhedra that cannot be vertex-unfolded, so some type of
&quot;gridding&quot; of the faces is necessary.) For any orthogonal polyhedron P with n
vertices, we describe an algorithm that vertex-unfolds P in O(n^2) time.
Enroute to explaining this algorithm, we present a simpler vertex-unfolding
algorithm that requires a 3 x 1 refinement of the vertex grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509055</id><created>2005-09-19</created><authors><author><keyname>Hamine</keyname><forenames>Vikas</forenames></author><author><keyname>Helman</keyname><forenames>Paul</forenames></author></authors><title>Learning Optimal Augmented Bayes Networks</title><categories>cs.LG</categories><comments>4 pages, 1 figure</comments><report-no>TR-CS-2004-11</report-no><abstract>  Naive Bayes is a simple Bayesian classifier with strong independence
assumptions among the attributes. This classifier, desipte its strong
independence assumptions, often performs well in practice. It is believed that
relaxing the independence assumptions of a naive Bayes classifier may improve
the classification accuracy of the resulting structure. While finding an
optimal unconstrained Bayesian Network (for most any reasonable scoring
measure) is an NP-hard problem, it is possible to learn in polynomial time
optimal networks obeying various structural restrictions. Several authors have
examined the possibilities of adding augmenting arcs between attributes of a
Naive Bayes classifier. Friedman, Geiger and Goldszmidt define the TAN
structure in which the augmenting arcs form a tree on the attributes, and
present a polynomial time algorithm that learns an optimal TAN with respect to
MDL score. Keogh and Pazzani define Augmented Bayes Networks in which the
augmenting arcs form a forest on the attributes (a collection of trees, hence a
relaxation of the stuctural restriction of TAN), and present heuristic search
methods for learning good, though not optimal, augmenting arc sets. The
authors, however, evaluate the learned structure only in terms of observed
misclassification error and not against a scoring metric, such as MDL. In this
paper, we present a simple, polynomial time greedy algorithm for learning an
optimal Augmented Bayes Network with respect to MDL score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509056</id><created>2005-09-19</created><authors><author><keyname>Freeman</keyname><forenames>David</forenames></author></authors><title>Pairing-based identification schemes</title><categories>cs.CR</categories><acm-class>E.3</acm-class><abstract>  We propose four different identification schemes that make use of bilinear
pairings, and prove their security under certain computational assumptions.
Each of the schemes is more efficient and/or more secure than any known
pairing-based identification scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509057</id><created>2005-09-19</created><authors><author><keyname>Veldhuizen</keyname><forenames>Todd L.</forenames></author></authors><title>Language embeddings that preserve staging and safety</title><categories>cs.PL</categories><acm-class>D.3.4</acm-class><abstract>  We study embeddings of programming languages into one another that preserve
what reductions take place at compile-time, i.e., staging. A certain condition
-- what we call a `Turing complete kernel' -- is sufficient for a language to
be stage-universal in the sense that any language may be embedded in it while
preserving staging. A similar line of reasoning yields the notion of
safety-preserving embeddings, and a useful characterization of
safety-universality. Languages universal with respect to staging and safety are
good candidates for realizing domain-specific embedded languages (DSELs) and
`active libraries' that provide domain-specific optimizations and safety
checks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509058</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509058</id><created>2005-09-19</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Rego</keyname><forenames>Leandro C.</forenames></author></authors><title>Interactive Unawareness Revisited</title><categories>cs.AI cs.LO</categories><comments>26 pages</comments><abstract>  We analyze a model of interactive unawareness introduced by Heifetz, Meier
and Schipper (HMS). We consider two axiomatizations for their model, which
capture different notions of validity. These axiomatizations allow us to
compare the HMS approach to both the standard (S5) epistemic logic and two
other approaches to unawareness: that of Fagin and Halpern and that of Modica
and Rustichini. We show that the differences between the HMS approach and the
others are mainly due to the notion of validity used and the fact that the HMS
is based on a 3-valued propositional logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509059</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509059</id><created>2005-09-19</created><updated>2010-10-31</updated><authors><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>On an authentication scheme based on the Root Problem in the braid group</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author. One of the claims is
  incorrect as written. We are working on correcting and generalizing it. This
  will be published in another paper</comments><abstract>  Lal and Chaturvedi proposed two authentication schemes based on the
difficulty of the Root Problem in the braid group. We point out that the first
scheme is not really as secure as the Root Problem, and describe an efficient
way to crack it. The attack works for any group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509060</id><created>2005-09-19</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Homan</keyname><forenames>Christopher M.</forenames></author><author><keyname>Kosub</keyname><forenames>Sven</forenames></author></authors><title>Cluster Computing and the Power of Edge Recognition</title><categories>cs.CC cs.DM</categories><report-no>URCS-TR-2005-878</report-no><acm-class>F.1.3; F.1.1; F.1.2; G.2.1</acm-class><abstract>  We study the robustness--the invariance under definition changes--of the
cluster class CL#P [HHKW05]. This class contains each #P function that is
computed by a balanced Turing machine whose accepting paths always form a
cluster with respect to some length-respecting total order with efficient
adjacency checks. The definition of CL#P is heavily influenced by the defining
paper's focus on (global) orders. In contrast, we define a cluster class,
CLU#P, to capture what seems to us a more natural model of cluster computing.
We prove that the naturalness is costless: CL#P = CLU#P. Then we exploit the
more natural, flexible features of CLU#P to prove new robustness results for
CL#P and to expand what is known about the closure properties of CL#P.
  The complexity of recognizing edges--of an ordered collection of computation
paths or of a cluster of accepting computation paths--is central to this study.
Most particularly, our proofs exploit the power of unique discovery of
edges--the ability of nondeterministic functions to, in certain settings,
discover on exactly one (in some cases, on at most one) computation path a
critical piece of information regarding edges of orderings or clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509061</identifier>
 <datestamp>2007-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509061</id><created>2005-09-19</created><updated>2007-06-23</updated><authors><author><keyname>Homan</keyname><forenames>Christopher M.</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>Guarantees for the Success Frequency of an Algorithm for Finding
  Dodgson-Election Winners</title><categories>cs.DS cs.MA</categories><report-no>URCS-TR-2005-881</report-no><acm-class>F.2.2; I.2.8; J.4</acm-class><abstract>  In the year 1876 the mathematician Charles Dodgson, who wrote fiction under
the now more famous name of Lewis Carroll, devised a beautiful voting system
that has long fascinated political scientists. However, determining the winner
of a Dodgson election is known to be complete for the \Theta_2^p level of the
polynomial hierarchy. This implies that unless P=NP no polynomial-time solution
to this problem exists, and unless the polynomial hierarchy collapses to NP the
problem is not even in NP. Nonetheless, we prove that when the number of voters
is much greater than the number of candidates--although the number of voters
may still be polynomial in the number of candidates--a simple greedy algorithm
very frequently finds the Dodgson winners in such a way that it ``knows'' that
it has found them, and furthermore the algorithm never incorrectly declares a
nonwinner to be a winner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509062</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509062</id><created>2005-09-19</created><updated>2005-09-24</updated><authors><author><keyname>Hsu</keyname><forenames>Chun-Hao</forenames></author><author><keyname>Anastasopoulos</keyname><forenames>Achilleas</forenames></author></authors><title>Capacity-Achieving Codes with Bounded Graphical Complexity on Noisy
  Channels</title><categories>cs.IT math.IT</categories><comments>17 pages, 2 figures. This paper is to be presented in the 43rd
  Annual Allerton Conference on Communication, Control and Computing,
  Monticello, IL, USA, Sept. 28-30, 2005</comments><abstract>  We introduce a new family of concatenated codes with an outer low-density
parity-check (LDPC) code and an inner low-density generator matrix (LDGM) code,
and prove that these codes can achieve capacity under any memoryless
binary-input output-symmetric (MBIOS) channel using maximum-likelihood (ML)
decoding with bounded graphical complexity, i.e., the number of edges per
information bit in their graphical representation is bounded. In particular, we
also show that these codes can achieve capacity on the binary erasure channel
(BEC) under belief propagation (BP) decoding with bounded decoding complexity
per information bit per iteration for all erasure probabilities in (0, 1). By
deriving and analyzing the average weight distribution (AWD) and the
corresponding asymptotic growth rate of these codes with a rate-1 inner LDGM
code, we also show that these codes achieve the Gilbert-Varshamov bound with
asymptotically high probability. This result can be attributed to the presence
of the inner rate-1 LDGM code, which is demonstrated to help eliminate high
weight codewords in the LDPC code while maintaining a vanishingly small amount
of low weight codewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509063</id><created>2005-09-20</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>Order Independence and Rationalizability</title><categories>cs.GT</categories><comments>Appeared in: Proc. of the 10th conference on Theoretical Aspects of
  Rationality and Knowledge (TARK X), pp. 22-38 (2005)</comments><acm-class>J.4; I.2.11</acm-class><abstract>  Two natural strategy elimination procedures have been studied for strategic
games. The first one involves the notion of (strict, weak, etc) dominance and
the second the notion of rationalizability. In the case of dominance the
criterion of order independence allowed us to clarify which notions and under
what circumstances are robust. In the case of rationalizability this criterion
has not been considered. In this paper we investigate the problem of order
independence for rationalizability by focusing on three naturally entailed
reduction relations on games. These reduction relations are distinguished by
the adopted reference point for the notion of a better response. Additionally,
they are parametrized by the adopted system of beliefs. We show that for one
reduction relation the outcome of its (possibly transfinite) iterations does
not depend on the order of elimination of the strategies. This result does not
hold for the other two reduction relations. However, under a natural assumption
the iterations of all three reduction relations yield the same outcome. The
obtained order independence results apply to the frameworks considered in
Bernheim 84 and Pearce 84. For finite games the iterations of all three
reduction relations coincide and the order independence holds for three natural
systems of beliefs considered in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509064</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509064</id><created>2005-09-20</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>On joint coding for watermarking and encryption</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  In continuation to earlier works where the problem of joint information
embedding and lossless compression (of the composite signal) was studied in the
absence \cite{MM03} and in the presence \cite{MM04} of attacks, here we
consider the additional ingredient of protecting the secrecy of the watermark
against an unauthorized party, which has no access to a secret key shared by
the legitimate parties. In other words, we study the problem of joint coding
for three objectives: information embedding, compression, and encryption.Our
main result is a coding theorem that provides a single--letter characterization
of the best achievable tradeoffs among the following parameters: the distortion
between the composite signal and the covertext, the distortion in
reconstructing the watermark by the legitimate receiver, the compressibility of
the composite signal (with and without the key), and the equivocation of the
watermark, as well as its reconstructed version, given the composite signal. In
the attack--free case, if the key is independent of the covertext, this coding
theorem gives rise to a {\it threefold} separation principle that tells that
asymptotically, for long block codes, no optimality is lost by first applying a
rate--distortion code to the watermark source, then encrypting the compressed
codeword, and finally, embedding it into the covertext using the embedding
scheme of \cite{MM03}. In the more general case, however, this separation
principle is no longer valid, as the key plays an additional role of side
information used by the embedding unit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509065</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509065</id><created>2005-09-21</created><authors><author><keyname>Cheng</keyname><forenames>Qi</forenames></author><author><keyname>Murray</keyname><forenames>Elizabeth</forenames></author></authors><title>On Deciding Deep Holes of Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><abstract>  For generalized Reed-Solomon codes, it has been proved \cite{GuruswamiVa05}
that the problem of determining if a received word is a deep hole is
co-NP-complete. The reduction relies on the fact that the evaluation set of the
code can be exponential in the length of the code -- a property that practical
codes do not usually possess. In this paper, we first presented a much simpler
proof of the same result. We then consider the problem for standard
Reed-Solomon codes, i.e. the evaluation set consists of all the nonzero
elements in the field. We reduce the problem of identifying deep holes to
deciding whether an absolutely irreducible hypersurface over a finite field
contains a rational point whose coordinates are pairwise distinct and nonzero.
By applying Schmidt and Cafure-Matera estimation of rational points on
algebraic varieties, we prove that the received vector $(f(\alpha))_{\alpha \in
\F_q}$ for Reed-Solomon $[q,k]_q$, $k &lt; q^{1/7 - \epsilon}$, cannot be a deep
hole, whenever $f(x)$ is a polynomial of degree $k+d$ for $1\leq d &lt; q^{3/13
-\epsilon}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509066</id><created>2005-09-21</created><updated>2005-09-27</updated><authors><author><keyname>Manset</keyname><forenames>David</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Oquendo</keyname><forenames>Flavio</forenames></author><author><keyname>Verjus</keyname><forenames>Herve</forenames></author></authors><title>A Model-driven Approach for Grid Services Engineering</title><categories>cs.SE cs.DC</categories><comments>7 pages, 3 figures. Proc of the 18th international conference on
  Software and Systems Engineering and Applications. Paris November 2005</comments><acm-class>D.2.11</acm-class><abstract>  As a consequence to the hype of Grid computing, such systems have seldom been
designed using formal techniques. The complexity and rapidly growing demand
around Grid technologies has favour the use of classical development
techniques, resulting in no guidelines or rules and unstructured engineering
processes. This paper advocates a formal approach to Grid applications
development in an effort to contribute to the rigorous development of Grids
software architectures. This approach addresses cross-platform interoperability
and quality of service; the model-driven paradigm is applied to a formal
architecture-centric engineering method in order to benefit from the formal
semantic description power in addition to model-based transformations. The
result of such a novel combined concept promotes the re-use of design models
and eases developments in Grid computing by providing an adapted development
process and ensuring correctness at each design step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509067</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509067</id><created>2005-09-21</created><authors><author><keyname>Leykin</keyname><forenames>Anton</forenames></author><author><keyname>Verschelde</keyname><forenames>Jan</forenames></author></authors><title>Decomposing Solution Sets of Polynomial Systems: A New Parallel
  Monodromy Breakup Algorithm</title><categories>cs.DC cs.NA math.AG</categories><comments>15 pages</comments><abstract>  We consider the numerical irreducible decomposition of a positive dimensional
solution set of a polynomial system into irreducible factors. Path tracking
techniques computing loops around singularities connect points on the same
irreducible components. The computation of a linear trace for each factor
certifies the decomposition. This factorization method exhibits a good
practical performance on solution sets of relative high degrees.
  Using the same concepts of monodromy and linear trace, we present a new
monodromy breakup algorithm. It shows a better performance than the old method
which requires construction of permutations of witness points in order to break
up the solution set. In contrast, the new algorithm assumes a finer approach
allowing us to avoid tracking unnecessary homotopy paths.
  As we designed the serial algorithm keeping in mind distributed computing, an
additional advantage is that its parallel version can be easily built.
Synchronization issues resulted in a performance loss of the straightforward
parallel version of the old algorithm. Our parallel implementation of the new
approach bypasses these issues, therefore, exhibiting a better performance,
especially on solution sets of larger degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509068</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509068</id><created>2005-09-22</created><authors><author><keyname>Porrat</keyname><forenames>Dana</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author><author><keyname>Nacu</keyname><forenames>Serban</forenames></author></authors><title>Channel Uncertainty in Ultra Wideband Communication Systems</title><categories>cs.IT math.IT</categories><abstract>  Wide band systems operating over multipath channels may spread their power
over bandwidth if they use duty cycle. Channel uncertainty limits the
achievable data rates of power constrained wide band systems; Duty cycle
transmission reduces the channel uncertainty because the receiver has to
estimate the channel only when transmission takes place. The optimal choice of
the fraction of time used for transmission depends on the spectral efficiency
of the signal modulation. The general principle is demonstrated by comparing
the channel conditions that allow different modulations to achieve the capacity
in the limit. Direct sequence spread spectrum and pulse position modulation
systems with duty cycle achieve the channel capacity, if the increase of the
number of channel paths with the bandwidth is not too rapid. The higher
spectral efficiency of the spread spectrum modulation lets it achieve the
channel capacity in the limit, in environments where pulse position modulation
with non-vanishing symbol time cannot be used because of the large number of
channel paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509069</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509069</id><created>2005-09-22</created><updated>2008-09-22</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Farach-Colton</keyname><forenames>Martin</forenames></author></authors><title>Fast and Compact Regular Expression Matching</title><categories>cs.DS</categories><acm-class>F.2.2; F.2.0; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study 4 problems in string matching, namely, regular expression matching,
approximate regular expression matching, string edit distance, and subsequence
indexing, on a standard word RAM model of computation that allows
logarithmic-sized words to be manipulated in constant time. We show how to
improve the space and/or remove a dependency on the alphabet size for each
problem using either an improved tabulation technique of an existing algorithm
or by combining known algorithms in a new way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509070</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509070</id><created>2005-09-22</created><updated>2005-11-10</updated><authors><author><keyname>Gerdt</keyname><forenames>Vladimir P.</forenames></author><author><keyname>Robertz</keyname><forenames>Daniel</forenames></author></authors><title>A Maple Package for Computing Groebner Bases for Linear Recurrence
  Relations</title><categories>cs.SC cs.MS</categories><comments>5 pages, presented at ACAT-2005</comments><acm-class>I.1.4</acm-class><journal-ref>Nucl.Instrum.Meth. A559 (2006) 215-219</journal-ref><doi>10.1016/j.nima.2005.11.171</doi><abstract>  A Maple package for computing Groebner bases of linear difference ideals is
described. The underlying algorithm is based on Janet and Janet-like monomial
divisions associated with finite difference operators. The package can be used,
for example, for automatic generation of difference schemes for linear partial
differential equations and for reduction of multiloop Feynman integrals. These
two possible applications are illustrated by simple examples of the Laplace
equation and a one-loop scalar integral of propagator type
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509071</id><created>2005-09-22</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Rossi</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>K. Brent</forenames></author></authors><title>CP-nets and Nash equilibria</title><categories>cs.GT cs.AI</categories><comments>6 pages. in: roc. of the Third International Conference on
  Computational Intelligence, Robotics and Autonomous Systems (CIRAS '05). To
  appear</comments><acm-class>J.4; I.2.11</acm-class><abstract>  We relate here two formalisms that are used for different purposes in
reasoning about multi-agent systems. One of them are strategic games that are
used to capture the idea that agents interact with each other while pursuing
their own interest. The other are CP-nets that were introduced to express
qualitative and conditional preferences of the users and which aim at
facilitating the process of preference elicitation. To relate these two
formalisms we introduce a natural, qualitative, extension of the notion of a
strategic game. We show then that the optimal outcomes of a CP-net are exactly
the Nash equilibria of an appropriately defined strategic game in the above
sense. This allows us to use the techniques of game theory to search for
optimal outcomes of CP-nets and vice-versa, to use techniques developed for
CP-nets to search for Nash equilibria of the considered games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509072</id><created>2005-09-23</created><authors><author><keyname>Shen</keyname><forenames>Kaikai</forenames></author><author><keyname>Wu</keyname><forenames>Lide</forenames></author></authors><title>Folksonomy as a Complex Network</title><categories>cs.IR cs.DL physics.soc-ph</categories><abstract>  Folksonomy is an emerging technology that works to classify the information
over WWW through tagging the bookmarks, photos or other web-based contents. It
is understood to be organized by every user while not limited to the authors of
the contents and the professional editors. This study surveyed the folksonomy
as a complex network. The result indicates that the network, which is composed
of the tags from the folksonomy, displays both properties of small world and
scale-free. However, the statistics only shows a local and static slice of the
vast body of folksonomy which is still evolving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509073</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509073</id><created>2005-09-23</created><authors><author><keyname>Lee</keyname><forenames>Kwankyu</forenames></author></authors><title>Distance-Increasing Maps of All Length by Simple Mapping Algorithms</title><categories>cs.IT cs.DM math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  Distance-increasing maps from binary vectors to permutations, namely DIMs,
are useful for the construction of permutation arrays. While a simple mapping
algorithm defining DIMs of even length is known, existing DIMs of odd length
are either recursively constructed by merging shorter DIMs or defined by much
complicated mapping algorithms. In this paper, DIMs of all length defined by
simple mapping algorithms are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509074</id><created>2005-09-26</created><authors><author><keyname>Naor</keyname><forenames>Assaf</forenames></author><author><keyname>Schechtman</keyname><forenames>Gideon</forenames></author></authors><title>Planar Earthmover is not in $L_1$</title><categories>cs.CG math.FA</categories><abstract>  We show that any $L_1$ embedding of the transportation cost (a.k.a.
Earthmover) metric on probability measures supported on the grid
$\{0,1,...,n\}^2\subseteq \R^2$ incurs distortion $\Omega(\sqrt{\log n})$. We
also use Fourier analytic techniques to construct a simple $L_1$ embedding of
this space which has distortion $O(\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509075</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509075</id><created>2005-09-26</created><updated>2005-09-26</updated><authors><author><keyname>Shin</keyname><forenames>Hyundong</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author><author><keyname>Lee</keyname><forenames>Jae Hong</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>On the Capacity of Doubly Correlated MIMO Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Wireless Communications</comments><abstract>  In this paper, we analyze the capacity of multiple-input multiple-output
(MIMO) Rayleigh-fading channels in the presence of spatial fading correlation
at both the transmitter and the receiver, assuming that the channel is unknown
at the transmitter and perfectly known at the receiver. We first derive the
determinant representation for the exact characteristic function of the
capacity, which is then used to determine the trace representations for the
mean, variance, skewness, kurtosis, and other higher-order statistics (HOS).
These results allow us to exactly evaluate two relevant information-theoretic
capacity measures--ergodic capacity and outage capacity--and the HOS of the
capacity for such a MIMO channel. The analytical framework presented in the
paper is valid for arbitrary numbers of antennas and generalizes the previously
known results for independent and identically distributed or one-sided
correlated MIMO channels to the case when fading correlation exists on both
sides. We verify our analytical results by comparing them with Monte Carlo
simulations for a correlation model based on realistic channel measurements as
well as a classical exponential correlation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509076</id><created>2005-09-26</created><authors><author><keyname>Bazaz</keyname><forenames>Anil</forenames></author><author><keyname>Arthur</keyname><forenames>James D.</forenames></author></authors><title>On Vulnerabilities, Constraints and Assumptions</title><categories>cs.CR</categories><abstract>  This report presents a taxonomy of vulnerabilities created as a part of an
effort to develop a framework for deriving verification and validation
strategies to assess software security. This taxonomy is grounded in a
theoretical model of computing, which establishes the relationship between
vulnerabilities, software applications and the computer system resources. This
relationship illustrates that a software application is exploited by violating
constraints imposed by computer system resources and assumptions made about
their usage. In other words, a vulnerability exists in the software application
if it allows violation of these constraints and assumptions. The taxonomy
classifies these constraints and assumptions. The model also serves as a basis
for the classification scheme the taxonomy uses, in which the computer system
resources such as, memory, input/output, and cryptographic resources serve as
categories and subcategories. Vulnerabilities, which are expressed in the form
of constraints and assumptions, are classified according to these categories
and subcategories. This taxonomy is both novel and distinctively different from
other taxonomies found in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509077</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509077</id><created>2005-09-26</created><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Srinivasa</keyname><forenames>Sudhir</forenames></author></authors><title>Capacity Limits of Cognitive Radio with Distributed and Dynamic Spectral
  Activity</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><journal-ref>IEEE Journal on Selected Areas in Communications Special Issue on
  Adaptive, Spectrum Agile and Cognitive Wireless Networks, Volume 25, No. 3,
  April 2007, Pages: 529-537</journal-ref><abstract>  We investigate the capacity of opportunistic communication in the presence of
dynamic and distributed spectral activity, i.e. when the time varying spectral
holes sensed by the cognitive transmitter are correlated but not identical to
those sensed by the cognitive receiver. Using the information theoretic
framework of communication with causal and non-causal side information at the
transmitter and/or the receiver, we obtain analytical capacity expressions and
the corresponding numerical results. We find that cognitive radio communication
is robust to dynamic spectral environments even when the communication occurs
in bursts of only 3-5 symbols. The value of handshake overhead is investigated
for both lightly loaded and heavily loaded systems. We find that the capacity
benefits of overhead information flow from the transmitter to the receiver is
negligible while feedback information overhead in the opposite direction
significantly improves capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509078</id><created>2005-09-26</created><updated>2005-11-14</updated><authors><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>On the Feedback Capacity of Stationary Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>11 pages, v2: corrected a few typos, 43rd Annual Allerton Conference
  on Communication, Control and Computing, Monticello, IL, USA, Sept. 28-30,
  2005</comments><abstract>  The capacity of stationary additive Gaussian noise channels with feedback is
characterized as the solution to a variational problem. Toward this end, it is
proved that the optimal feedback coding scheme is stationary. When specialized
to the first-order autoregressive moving-average noise spectrum, this
variational characterization yields a closed-form expression for the feedback
capacity. In particular, this result shows that the celebrated
Schalkwijk--Kailath coding scheme achieves the feedback capacity for the
first-order autoregressive moving-average Gaussian channel, resolving a
long-standing open problem studied by Butman, Schalkwijk--Tiernan, Wolfowitz,
Ozarow, Ordentlich, Yang--Kavcic--Tatikonda, and others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509079</identifier>
 <datestamp>2007-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509079</id><created>2005-09-27</created><updated>2007-01-08</updated><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>The WSSUS Pulse Design Problem in Multicarrier Transmission</title><categories>cs.IT math.IT</categories><comments>24 pages (onecolumn,draft), 4 figures, accepted for publication in
  the IEEE Transactions on Communications</comments><journal-ref>IEEE Trans. on Comm., 2007, 55(10), 1918-1928</journal-ref><doi>10.1109/TCOMM.2007.906427</doi><abstract>  Optimal link adaption to the scattering function of wide sense stationary
uncorrelated mobile communication channels is still an unsolved problem despite
its importance for next-generation system design. In multicarrier transmission
such link adaption is performed by pulse shaping, i.e. by properly adjusting
the transmit and receive filters. For example pulse shaped Offset--QAM systems
have been recently shown to have superior performance over standard cyclic
prefix OFDM (while operating at higher spectral efficiency).In this paper we
establish a general mathematical framework for joint transmitter and receiver
pulse shape optimization for so-called Weyl--Heisenberg or Gabor signaling with
respect to the scattering function of the WSSUS channel. In our framework the
pulse shape optimization problem is translated to an optimization problem over
trace class operators which in turn is related to fidelity optimization in
quantum information processing. By convexity relaxation the problem is shown to
be equivalent to a \emph{convex constraint quasi-convex maximization problem}
thereby revealing the non-convex nature of the overall WSSUS pulse design
problem. We present several iterative algorithms for optimization providing
applicable results even for large--scale problem constellations. We show that
with transmitter-side knowledge of the channel statistics a gain of $3 - 6$dB
in $\SINR$ can be expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509080</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509080</id><created>2005-09-27</created><authors><author><keyname>Simon</keyname><forenames>Steven H.</forenames></author><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author><author><keyname>Marinelli</keyname><forenames>Luca</forenames></author></authors><title>Capacity and Character Expansions: Moment generating function and other
  exact results for MIMO correlated channels</title><categories>cs.IT cond-mat.mes-hall cond-mat.stat-mech hep-lat math-ph math.IT math.MP</categories><comments>submitted to IEEE Trans. Information Theory, March 2004 (under
  review); 23 pages, 2 figures; IEEEtran document class</comments><acm-class>H.1.1</acm-class><journal-ref>IEEETrans.Info.Theor.52:5336-5351,2006</journal-ref><doi>10.1109/TIT.2006.885519</doi><abstract>  We apply a promising new method from the field of representations of Lie
groups to calculate integrals over unitary groups, which are important for
multi-antenna communications. To demonstrate the power and simplicity of this
technique, we first re-derive a number of results that have been used recently
in the community of wireless information theory, using only a few simple steps.
In particular, we derive the joint probability distribution of eigenvalues of
the matrix GG*, with G a semicorrelated Gaussian random matrix or a Gaussian
random matrix with a non-zero mean (and G* its hermitian conjugate) . These
joint probability distribution functions can then be used to calculate the
moment generating function of the mutual information for Gaussian channels with
multiple antennas on both ends with this probability distribution of their
channel matrices G. We then turn to the previously unsolved problem of
calculating the moment generating function of the mutual information of MIMO
(multiple input-multiple output) channels, which are correlated at both the
receiver and the transmitter. From this moment generating function we obtain
the ergodic average of the mutual information and study the outage probability.
These methods can be applied to a number of other problems. As a particular
example, we examine unitary encoded space-time transmission of MIMO systems and
we derive the received signal distribution when the channel matrix is
correlated at the transmitter end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509081</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509081</id><created>2005-09-27</created><authors><author><keyname>Zana</keyname><forenames>Yossi</forenames></author><author><keyname>Cesar-Jr</keyname><forenames>Roberto M.</forenames></author><author><keyname>Barbosa</keyname><forenames>Regis de A.</forenames></author></authors><title>Automatic Face Recognition System Based on Local Fourier-Bessel Features</title><categories>cs.CV</categories><comments>2005, Brazilian Symposium on Computer Graphics and Image Processing,
  18 (SIBGRAPI)</comments><abstract>  We present an automatic face verification system inspired by known properties
of biological systems. In the proposed algorithm the whole image is converted
from the spatial to polar frequency domain by a Fourier-Bessel Transform (FBT).
Using the whole image is compared to the case where only face image regions
(local analysis) are considered. The resulting representations are embedded in
a dissimilarity space, where each image is represented by its distance to all
the other images, and a Pseudo-Fisher discriminator is built. Verification test
results on the FERET database showed that the local-based algorithm outperforms
the global-FBT version. The local-FBT algorithm performed as state-of-the-art
methods under different testing conditions, indicating that the proposed system
is highly robust for expression, age, and illumination variations. We also
evaluated the performance of the proposed system under strong occlusion
conditions and found that it is highly robust for up to 50% of face occlusion.
Finally, we automated completely the verification system by implementing face
and eye detection algorithms. Under this condition, the local approach was only
slightly superior to the global approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509082</id><created>2005-09-27</created><authors><author><keyname>Zana</keyname><forenames>Yossi</forenames></author><author><keyname>Cesar-JR</keyname><forenames>Roberto M.</forenames></author></authors><title>Face Recognition Based on Polar Frequency Features</title><categories>cs.CV</categories><comments>ACM Transactions on Applied Perception</comments><acm-class>I.4; I.5</acm-class><abstract>  A novel biologically motivated face recognition algorithm based on polar
frequency is presented. Polar frequency descriptors are extracted from face
images by Fourier-Bessel transform (FBT). Next, the Euclidean distance between
all images is computed and each image is now represented by its dissimilarity
to the other images. A Pseudo-Fisher Linear Discriminant was built on this
dissimilarity space. The performance of Discrete Fourier transform (DFT)
descriptors, and a combination of both feature types was also evaluated. The
algorithms were tested on a 40- and 1196-subjects face database (ORL and FERET,
respectively). With 5 images per subject in the training and test datasets,
error rate on the ORL database was 3.8, 1.25 and 0.2% for the FBT, DFT, and the
combined classifier, respectively, as compared to 2.6% achieved by the best
previous algorithm. The most informative polar frequency features were
concentrated at low-to-medium angular frequencies coupled to low radial
frequencies. On the FERET database, where an affine normalization
pre-processing was applied, the FBT algorithm outperformed only the PCA in a
rank recognition test. However, it achieved performance comparable to
state-of-the-art methods when evaluated by verification tests. These results
indicate the high informative value of the polar frequency content of face
images in relation to recognition and verification tasks, and that the
Cartesian frequency content can complement information about the subjects'
identity, but possibly only when the images are not pre-normalized. Possible
implications for human face recognition are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509083</id><created>2005-09-27</created><authors><author><keyname>Zana</keyname><forenames>Yossi</forenames></author><author><keyname>Cesar-Jr</keyname><forenames>Roberto M.</forenames></author><author><keyname>Feris</keyname><forenames>Rogerio S.</forenames></author><author><keyname>Turk</keyname><forenames>Matthew</forenames></author></authors><title>Face Verification in Polar Frequency Domain: a Biologically Motivated
  Approach</title><categories>cs.CV</categories><comments>2005, International Symposium on Visual Computing (ISVC)</comments><abstract>  We present a novel local-based face verification system whose components are
analogous to those of biological systems. In the proposed system, after global
registration and normalization, three eye regions are converted from the
spatial to polar frequency domain by a Fourier-Bessel Transform. The resulting
representations are embedded in a dissimilarity space, where each image is
represented by its distance to all the other images. In this dissimilarity
space a Pseudo-Fisher discriminator is built. ROC and equal error rate
verification test results on the FERET database showed that the system
performed at least as state-of-the-art methods and better than a system based
on polar Fourier features. The local-based system is especially robust to
facial expression and age variations, but sensitive to registration errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509084</id><created>2005-09-27</created><authors><author><keyname>Bekaert</keyname><forenames>Jeroen</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoming</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Representing Digital Assets for Long-Term Preservation using MPEG-21 DID</title><categories>cs.DL</categories><comments>Accepted paper for PV 2005 &quot;Ensuring Long-term Preservation and
  Adding Value to Scientific and Technical data&quot;
  (http://www.ukoln.ac.uk/events/pv-2005/)</comments><abstract>  Various efforts aimed at representing digital assets have emerged from
several communities over the last years, including the Metadata Encoding and
Transmission Standard (METS), the IMS Content Packaging (IMS-CP) XML Binding
and the XML Formatted Data Units (XFDU). The MPEG-21 Digital Item Declaration
(MPEG-21 DID) is another approach that can be used for the representation of
digital assets in XML. This paper will explore the potential of the MPEG-21 DID
in a Digital Preservation context, by looking at the core building blocks of
the OAIS Information Model and the way in which they map to the MPEG-21 DID
abstract model and the MPEG-21 DIDL XML syntax.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509085</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509085</id><created>2005-09-27</created><authors><author><keyname>Song</keyname><forenames>Sanquan</forenames></author><author><keyname>Goeckel</keyname><forenames>Dennis L.</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>An Improved Lower Bound to the Number of Neighbors Required for the
  Asymptotic Connectivity of Ad Hoc Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  Xue and Kumar have established that the number of neighbors required for
connectivity of wireless networks with N uniformly distributed nodes must grow
as log(N), and they also established that the actual number required lies
between 0.074log(N) and 5.1774log(N). In this short paper, by recognizing that
connectivity results for networks where the nodes are distributed according to
a Poisson point process can often be applied to the problem for a network with
N nodes, we are able to improve the lower bound. In particular, we show that a
network with nodes distributed in a unit square according to a 2D Poisson point
process of parameter N will be asymptotically disconnected with probability one
if the number of neighbors is less than 0.129log(N). Moreover, similar number
of neighbors is not enough for an asymptotically connected network with N nodes
uniformly in a unit square, hence improving the lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509086</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509086</id><created>2005-09-28</created><authors><author><keyname>Hosaka</keyname><forenames>Tadaaki</forenames></author><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>Statistical Mechanical Approach to Lossy Data Compression:Theory and
  Practice</title><categories>cs.IT math.IT</categories><comments>10 pages, 2 figures, REVTEX preprint</comments><doi>10.1016/j.physa.2006.01.013</doi><abstract>  The encoder and decoder for lossy data compression of binary memoryless
sources are developed on the basis of a specific-type nonmonotonic perceptron.
Statistical mechanical analysis indicates that the potential ability of the
perceptron-based code saturates the theoretically achievable limit in most
cases although exactly performing the compression is computationally difficult.
To resolve this difficulty, we provide a computationally tractable
approximation algorithm using belief propagation (BP), which is a current
standard algorithm of probabilistic inference. Introducing several
approximations and heuristics, the BP-based algorithm exhibits performance that
is close to the achievable limit in a practical time scale in optimal cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509087</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509087</id><created>2005-09-28</created><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>On Time-Variant Distortions in Multicarrier Transmission with
  Application to Frequency Offsets and Phase Noise</title><categories>cs.IT math.IT</categories><comments>10 pages (twocolumn), 5 figures</comments><journal-ref>IEEE Transactions on Communications Vol. 53 (9), Sep. 2005, pp.
  1561-1570</journal-ref><doi>10.1109/TCOMM.2005.855010</doi><abstract>  Phase noise and frequency offsets are due to their time-variant behavior one
of the most limiting disturbances in practical OFDM designs and therefore
intensively studied by many authors. In this paper we present a generalized
framework for the prediction of uncoded system performance in the presence of
time-variant distortions including the transmitter and receiver pulse shapes as
well as the channel. Therefore, unlike existing studies, our approach can be
employed for more general multicarrier schemes. To show the usefulness of our
approach, we apply the results to OFDM in the context of frequency offset and
Wiener phase noise, yielding improved bounds on the uncoded performance. In
particular, we obtain exact formulas for the averaged performance in AWGN and
time-invariant multipath channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509088</id><created>2005-09-28</created><authors><author><keyname>Afolabi</keyname><forenames>Babajide</forenames><affiliation>LORIA</affiliation></author><author><keyname>Thiery</keyname><forenames>Odile</forenames><affiliation>LORIA</affiliation></author></authors><title>Business intelligence systems and user's parameters: an application to
  a documents' database</title><categories>cs.DB</categories><proxy>ccsd inria-00000372</proxy><journal-ref>Dans Modelling Others for Observation A workshop of IJCAI 2005</journal-ref><abstract>  This article presents earlier results of our research works in the area of
modeling Business Intelligence Systems. The basic idea of this research area is
presented first. We then show the necessity of including certain users'
parameters in Information systems that are used in Business Intelligence
systems in order to integrate a better response from such systems. We
identified two main types of attributes that can be missing from a base and we
showed why they needed to be included. A user model that is based on a
cognitive user evolution is presented. This model when used together with a
good definition of the information needs of the user (decision maker) will
accelerate his decision making process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509089</id><created>2005-09-28</created><authors><author><keyname>Vitolins</keyname><forenames>Valdis</forenames></author><author><keyname>Kalnins</keyname><forenames>Audris</forenames></author></authors><title>Semantics of UML 2.0 Activity Diagram for Business Modeling by Means of
  Virtual Machine</title><categories>cs.CE cs.PL</categories><comments>12 pages, 7 figures, Proceedings of the conference &quot;EDOC 2005&quot;,
  19-23 September 2005</comments><journal-ref>Valdis Vitolins, Audris Kalnins, Proceedings Ninth IEEE
  International EDOC Enterprise Computing Conference, IEEE, 2005, pp. 181.-192</journal-ref><abstract>  The paper proposes a more formalized definition of UML 2.0 Activity Diagram
semantics. A subset of activity diagram constructs relevant for business
process modeling is considered. The semantics definition is based on the
original token flow methodology, but a more constructive approach is used. The
Activity Diagram Virtual machine is defined by means of a metamodel, with
operations defined by a mix of pseudocode and OCL pre- and postconditions. A
formal procedure is described which builds the virtual machine for any activity
diagram. The relatively complicated original token movement rules in control
nodes and edges are combined into paths from an action to action. A new
approach is the use of different (push and pull) engines, which move tokens
along the paths. Pull engines are used for paths containing join nodes, where
the movement of several tokens must be coordinated. The proposed virtual
machine approach makes the activity semantics definition more transparent where
the token movement can be easily traced. However, the main benefit of the
approach is the possibility to use the defined virtual machine as a basis for
UML activity diagram based workflow or simulation engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509090</id><created>2005-09-28</created><authors><author><keyname>Bekaert</keyname><forenames>Jeroen</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Access Interfaces for Open Archival Information Systems based on the
  OAI-PMH and the OpenURL Framework for Context-Sensitive Services</title><categories>cs.DL</categories><comments>Accepted paper for PV 2005 &quot;Ensuring Long-term Preservation and
  Adding Value to Scientific and Technical data&quot;
  (http://www.ukoln.ac.uk/events/pv-2005/)</comments><abstract>  In recent years, a variety of digital repository and archival systems have
been developed and adopted. All of these systems aim at hosting a variety of
compound digital assets and at providing tools for storing, managing and
accessing those assets. This paper will focus on the definition of common and
standardized access interfaces that could be deployed across such diverse
digital respository and archival systems. The proposed interfaces are based on
the two formal specifications that have recently emerged from the Digital
Library community: The Open Archive Initiative Protocol for Metadata Harvesting
(OAI-PMH) and the NISO OpenURL Framework for Context-Sensitive Services
(OpenURL Standard). As will be described, the former allows for the retrieval
of batches of XML-based representations of digital assets, while the latter
facilitates the retrieval of disseminations of a specific digital asset or of
one or more of its constituents. The core properties of the proposed interfaces
are explained in terms of the Reference Model for an Open Archival Information
System (OAIS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509091</id><created>2005-09-28</created><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Rafiey</keyname><forenames>A.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>Minimum Cost Homomorphisms to Semicomplete Multipartite Digraphs</title><categories>cs.DM</categories><abstract>  For digraphs $D$ and $H$, a mapping $f: V(D)\dom V(H)$ is a {\em homomorphism
of $D$ to $H$} if $uv\in A(D)$ implies $f(u)f(v)\in A(H).$ For a fixed directed
or undirected graph $H$ and an input graph $D$, the problem of verifying
whether there exists a homomorphism of $D$ to $H$ has been studied in a large
number of papers. We study an optimization version of this decision problem.
Our optimization problem is motivated by a real-world problem in defence
logistics and was introduced very recently by the authors and M. Tso.
  Suppose we are given a pair of digraphs $D,H$ and a positive integral cost
$c_i(u)$ for each $u\in V(D)$ and $i\in V(H)$. The cost of a homomorphism $f$
of $D$ to $H$ is $\sum_{u\in V(D)}c_{f(u)}(u)$. Let $H$ be a fixed digraph. The
minimum cost homomorphism problem for $H$, MinHOMP($H$), is stated as follows:
For input digraph $D$ and costs $c_i(u)$ for each $u\in V(D)$ and $i\in V(H)$,
verify whether there is a homomorphism of $D$ to $H$ and, if it does exist,
find such a homomorphism of minimum cost. In our previous paper we obtained a
dichotomy classification of the time complexity of \MiP for $H$ being a
semicomplete digraph. In this paper we extend the classification to
semicomplete $k$-partite digraphs, $k\ge 3$, and obtain such a classification
for bipartite tournaments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509092</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509092</id><created>2005-09-28</created><authors><author><keyname>Poibeau</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author></authors><title>Automatic extraction of paraphrastic phrases from medium size corpora</title><categories>cs.CL cs.AI</categories><proxy>ccsd ccsd-00009168</proxy><journal-ref>Actes de la conf\'{e}rence Computational Linguisitcs (COLING 2004)
  (2004) 638-644</journal-ref><abstract>  This paper presents a versatile system intended to acquire paraphrastic
phrases from a representative corpus. In order to decrease the time spent on
the elaboration of resources for NLP system (for example Information
Extraction, IE hereafter), we suggest to use a machine learning system that
helps defining new templates and associated resources. This knowledge is
automatically derived from the text collection, in interaction with a large
semantic network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509093</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509093</id><created>2005-09-28</created><authors><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author><author><keyname>Simon</keyname><forenames>Steven H.</forenames></author></authors><title>On the Outage Capacity of Correlated Multiple-Path MIMO Channels</title><categories>cs.IT math.IT</categories><comments>submitted for publication IEEE Trans. Information Theory; IEEEtran
  documentstyle</comments><acm-class>H.1.1</acm-class><abstract>  The use of multi-antenna arrays in both transmission and reception has been
shown to dramatically increase the throughput of wireless communication
systems. As a result there has been considerable interest in characterizing the
ergodic average of the mutual information for realistic correlated channels.
Here, an approach is presented that provides analytic expressions not only for
the average, but also the higher cumulant moments of the distribution of the
mutual information for zero-mean Gaussian (multiple-input multiple-output) MIMO
channels with the most general multipath covariance matrices when the channel
is known at the receiver. These channels include multi-tap delay paths, as well
as general channels with covariance matrices that cannot be written as a
Kronecker product, such as dual-polarized antenna arrays with general
correlations at both transmitter and receiver ends. The mathematical methods
are formally valid for large antenna numbers, in which limit it is shown that
all higher cumulant moments of the distribution, other than the first two scale
to zero. Thus, it is confirmed that the distribution of the mutual information
tends to a Gaussian, which enables one to calculate the outage capacity. These
results are quite accurate even in the case of a few antennas, which makes this
approach applicable to realistic situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509094</id><created>2005-09-28</created><updated>2005-10-19</updated><authors><author><keyname>Morris</keyname><forenames>Carol Minton</forenames></author></authors><title>Telling Great Stories: An NSDL Content and Communications System for
  Aggregation, Display, and Distribution of News and Features</title><categories>cs.DL cs.SE</categories><comments>3 pages, 2 figures</comments><acm-class>D.2.10</acm-class><abstract>  Education digital libraries contain cataloged resources as well as contextual
information about innovations in the use of educational technology, exemplar
stories about community activities, and news from various user communities that
include teachers, students, scholars, and developers. Long-standing library
traditions of service, preservation, democratization of knowledge, rich
discourse, equal access, and fair use are evident in library communications
models that both pull in and push out contextual information from multiple
sources integrated with editorial production processes. This paper argues that
a dynamic narrative flow [1] is enabled by effective management of complex
content and communications in a decentralized web-based education digital
library making publishing objects such as aggregations of resources, or
selected parts of objects [4] accessible through a Content and Communications
System. Providing services that encourage patrons to reuse, reflect out, and
contribute resources back [5] to the Library increases the reach and impact of
the National Science Digital Library (NSDL). This system is a model for
distributed content development and effective communications for education
digital libraries in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509095</id><created>2005-09-28</created><authors><author><keyname>Anwar</keyname><forenames>Zahid</forenames><affiliation>Department of Computer Science University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Yurcik</keyname><forenames>William</forenames><affiliation>Department of Computer Science University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Pandey</keyname><forenames>Vivek</forenames><affiliation>Department of Computer Science University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Shankar</keyname><forenames>Asim</forenames><affiliation>Department of Computer Science University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Gupta</keyname><forenames>Indranil</forenames><affiliation>Department of Computer Science University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Campbell</keyname><forenames>Roy H.</forenames><affiliation>Department of Computer Science University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Leveraging Social-Network Infrastructure to Improve Peer-to-Peer
  Overlay Performance: Results from Orkut</title><categories>cs.NI cs.CY</categories><comments>9 pages 8 figures</comments><acm-class>C.2.2</acm-class><abstract>  Application-level peer-to-peer (P2P) network overlays are an emerging
paradigm that facilitates decentralization and flexibility in the scalable
deployment of applications such as group communication, content delivery, and
data sharing. However the construction of the overlay graph topology optimized
for low latency, low link and node stress and lookup performance is still an
open problem. We present a design of an overlay constructed on top of a social
network and show that it gives a sizable improvement in lookups, average
round-trip delay and scalability as opposed to other overlay topologies. We
build our overlay on top of the topology of a popular real-world social network
namely Orkut. We show Orkuts suitability for our purposes by evaluating the
clustering behavior of its graph structure and the socializing pattern of its
members.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509096</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509096</id><created>2005-09-28</created><updated>2006-06-23</updated><authors><author><keyname>Snow</keyname><forenames>C.</forenames></author><author><keyname>Lampe</keyname><forenames>L.</forenames></author><author><keyname>Schober</keyname><forenames>R.</forenames></author></authors><title>Performance Analysis and Enhancement of Multiband OFDM for UWB
  Communications</title><categories>cs.IT math.IT</categories><comments>32 pages, 10 figures, 1 table. Submitted to the IEEE Transactions on
  Wireless Communications (Sep. 28, 2005). Minor revisions based on reviewers'
  comments (June 23, 2006)</comments><abstract>  In this paper, we analyze the frequency-hopping orthogonal frequency-division
multiplexing (OFDM) system known as Multiband OFDM for high-rate wireless
personal area networks (WPANs) based on ultra-wideband (UWB) transmission.
Besides considering the standard, we also propose and study system performance
enhancements through the application of Turbo and Repeat-Accumulate (RA) codes,
as well as OFDM bit-loading. Our methodology consists of (a) a study of the
channel model developed under IEEE 802.15 for UWB from a frequency-domain
perspective suited for OFDM transmission, (b) development and quantification of
appropriate information-theoretic performance measures, (c) comparison of these
measures with simulation results for the Multiband OFDM standard proposal as
well as our proposed extensions, and (d) the consideration of the influence of
practical, imperfect channel estimation on the performance. We find that the
current Multiband OFDM standard sufficiently exploits the frequency selectivity
of the UWB channel, and that the system performs in the vicinity of the channel
cutoff rate. Turbo codes and a reduced-complexity clustered bit-loading
algorithm improve the system power efficiency by over 6 dB at a data rate of
480 Mbps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509097</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509097</id><created>2005-09-29</created><authors><author><keyname>El-Khamy</keyname><forenames>Mostafa</forenames></author><author><keyname>McEliece</keyname><forenames>Robert J.</forenames></author></authors><title>Iterative Algebraic Soft-Decision List Decoding of Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE for publication in Jan 2005</comments><journal-ref>IEEE Journal on Selected Areas in Communications, Volume 24, Issue
  3, March 2006 Page(s):481 - 490</journal-ref><doi>10.1109/JSAC.2005.862399</doi><abstract>  In this paper, we present an iterative soft-decision decoding algorithm for
Reed-Solomon codes offering both complexity and performance advantages over
previously known decoding algorithms. Our algorithm is a list decoding
algorithm which combines two powerful soft decision decoding techniques which
were previously regarded in the literature as competitive, namely, the
Koetter-Vardy algebraic soft-decision decoding algorithm and belief-propagation
based on adaptive parity check matrices, recently proposed by Jiang and
Narayanan. Building on the Jiang-Narayanan algorithm, we present a
belief-propagation based algorithm with a significant reduction in
computational complexity. We introduce the concept of using a
belief-propagation based decoder to enhance the soft-input information prior to
decoding with an algebraic soft-decision decoder. Our algorithm can also be
viewed as an interpolation multiplicity assignment scheme for algebraic
soft-decision decoding of Reed-Solomon codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509098</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509098</id><created>2005-09-30</created><authors><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author></authors><title>Applications of correlation inequalities to low density graphical codes</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>11 pages, 3 figures</comments><doi>10.1140/epjb/e2006-00129-6</doi><abstract>  This contribution is based on the contents of a talk delivered at the
Next-SigmaPhi conference held in Crete in August 2005. It is adressed to an
audience of physicists with diverse horizons and does not assume any background
in communications theory. Capacity approaching error correcting codes for
channel communication known as Low Density Parity Check (LDPC) codes have
attracted considerable attention from coding theorists in the last decade.
Surprisingly strong connections with the theory of diluted spin glasses have
been discovered. In this work we elucidate one new connection, namely that a
class of correlation inequalities valid for gaussian spin glasses can be
applied to the theoretical analysis of LDPC codes. This allows for a rigorous
comparison between the so called (optimal) maximum a posteriori and the
computationaly efficient belief propagation decoders. The main ideas of the
proofs are explained and we refer to recent works for the more lengthy
technical details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509099</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509099</id><created>2005-09-30</created><updated>2006-11-27</updated><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author><author><keyname>Chen</keyname><forenames>Guoqing</forenames></author></authors><title>State-Based Control of Fuzzy Discrete Event Systems</title><categories>cs.DM cs.DC</categories><comments>14 double column pages; 4 figures; to be published in the IEEE
  Transactions on Systems, Man, and Cybernetics--Part B: Cybernetics</comments><acm-class>G.3; I.6.8</acm-class><journal-ref>IEEE Transactions on Systems, Man, and Cybernetics--Part B:
  Cybernetics, vol. 37, no. 2, pp. 410-424, April 2007.</journal-ref><abstract>  To effectively represent possibility arising from states and dynamics of a
system, fuzzy discrete event systems as a generalization of conventional
discrete event systems have been introduced recently. Supervisory control
theory based on event feedback has been well established for such systems.
Noting that the system state description, from the viewpoint of specification,
seems more convenient, we investigate the state-based control of fuzzy discrete
event systems in this paper. We first present an approach to finding all fuzzy
states that are reachable by controlling the system. After introducing the
notion of controllability for fuzzy states, we then provide a necessary and
sufficient condition for a set of fuzzy states to be controllable. We also find
that event-based control and state-based control are not equivalent and further
discuss the relationship between them. Finally, we examine the possibility of
driving a fuzzy discrete event system under control from a given initial state
to a prescribed set of fuzzy states and then keeping it there indefinitely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0509100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0509100</id><created>2005-09-30</created><authors><author><keyname>Erickson</keyname><forenames>Jeff</forenames><affiliation>Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA</affiliation></author><author><keyname>Thite</keyname><forenames>Shripad</forenames><affiliation>Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA</affiliation></author><author><keyname>Bunde</keyname><forenames>David P.</forenames><affiliation>Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA</affiliation></author></authors><title>Distance-2 Edge Coloring is NP-Complete</title><categories>cs.DM cs.CC</categories><comments>3 pages, 1 figure in color</comments><abstract>  We prove that it is NP-complete to determine whether there exists a
distance-2 edge coloring (strong edge coloring) with 5 colors of a bipartite
2-inductive graph with girth 6 and maximum degree 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510001</id><created>2005-09-30</created><updated>2006-05-11</updated><authors><author><keyname>Soares</keyname><forenames>Jo&#xe3;o V. B.</forenames></author><author><keyname>Leandro</keyname><forenames>Jorge J. G.</forenames></author><author><keyname>Cesar</keyname><forenames>Roberto M.</forenames><suffix>Jr.</suffix></author><author><keyname>Jelinek</keyname><forenames>Herbert F.</forenames></author><author><keyname>Cree</keyname><forenames>Michael J.</forenames></author></authors><title>Retinal Vessel Segmentation Using the 2-D Morlet Wavelet and Supervised
  Classification</title><categories>cs.CV</categories><comments>9 pages, 7 figures and 1 table. Accepted for publication in IEEE
  Trans Med Imag; added copyright notice</comments><journal-ref>IEEE Trans Med Imag, Vol. 25, no. 9, pp. 1214- 1222, Sep. 2006.</journal-ref><doi>10.1109/TMI.2006.879967</doi><abstract>  We present a method for automated segmentation of the vasculature in retinal
images. The method produces segmentations by classifying each image pixel as
vessel or non-vessel, based on the pixel's feature vector. Feature vectors are
composed of the pixel's intensity and continuous two-dimensional Morlet wavelet
transform responses taken at multiple scales. The Morlet wavelet is capable of
tuning to specific frequencies, thus allowing noise filtering and vessel
enhancement in a single step. We use a Bayesian classifier with
class-conditional probability density functions (likelihoods) described as
Gaussian mixtures, yielding a fast classification, while being able to model
complex decision surfaces and compare its performance with the linear minimum
squared error classifier. The probability distributions are estimated based on
a training set of labeled pixels obtained from manual segmentations. The
method's performance is evaluated on publicly available DRIVE and STARE
databases of manually labeled non-mydriatic images. On the DRIVE database, it
achieves an area under the receiver operating characteristic (ROC) curve of
0.9598, being slightly superior than that presented by the method of Staal et
al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510002</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510002</id><created>2005-09-30</created><updated>2006-07-05</updated><authors><author><keyname>Gomadam</keyname><forenames>Krishna Srikanth</forenames></author><author><keyname>Jafar</keyname><forenames>Syed Ali</forenames></author></authors><title>Optimal Relay Functionality for SNR Maximization in Memoryless Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>full paper</comments><abstract>  We explore the SNR-optimal relay functionality in a \emph{memoryless} relay
network, i.e. a network where, during each channel use, the signal transmitted
by a relay depends only on the last received symbol at that relay. We develop a
generalized notion of SNR for the class of memoryless relay functions. The
solution to the generalized SNR optimization problem leads to the novel concept
of minimum mean square uncorrelated error estimation(MMSUEE). For the elemental
case of a single relay, we show that MMSUEE is the SNR-optimal memoryless relay
function regardless of the source and relay transmit power, and the modulation
scheme. This scheme, that we call estimate and forward (EF), is also shown to
be SNR-optimal with PSK modulation in a parallel relay network. We demonstrate
that EF performs better than the best of amplify and forward (AF) and
demodulate and forward (DF), in both parallel and serial relay networks. We
also determine that AF is near-optimal at low transmit power in a parallel
network, while DF is near-optimal at high transmit power in a serial network.
For hybrid networks that contain both serial and parallel elements, and when
robust performance is desired, the advantage of EF over the best of AF and DF
is found to be significant. Error probabilities are provided to substantiate
the performance gain obtained through SNR optimality. We also show that, for
\emph{Gaussian} inputs, AF, DF and EF become identical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510003</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510003</id><created>2005-10-02</created><authors><author><keyname>de Abreu</keyname><forenames>Giuseppe Thadeu Freitas</forenames></author></authors><title>Generalized ABBA Space-Time Block Codes</title><categories>cs.IT math.IT</categories><comments>47 pages, 6 figures, Matlab codes included</comments><abstract>  Linear space-time block codes (STBCs) of unitary rate and full diversity,
systematically constructed over arbitrary constellations for any number of
transmit antennas are introduced. The codes are obtained by generalizing the
existing ABBA STBCs, a.k.a quasi-orthogonal STBCs (QO-STBCs). Furthermore, a
fully orthogonal (symbol-by-symbol) decoder for the new generalized ABBA
(GABBA) codes is provided. This remarkably low-complexity decoder relies on
partition orthogonality properties of the code structure to decompose the
received signal vector into lower-dimension tuples, each dependent only on
certain subsets of the transmitted symbols. Orthogonal decodability results
from the nested application of this technique, with no matrix inversion or
iterative signal processing required. The exact bit-error-rate probability of
GABBA codes over generalized fading channels with maximum likelihood (ML)
decoding is evaluated analytically and compared against simulation results
obtained with the proposed orthogonal decoder. The comparison reveals that the
proposed GABBA solution, despite its very low complexity, achieves nearly the
same performance of the bound corresponding to the ML-decoded system,
especially in systems with large numbers of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510004</id><created>2005-10-02</created><authors><author><keyname>Agarwal</keyname><forenames>Deepak</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>The Hunting of the Bump: On Maximizing Statistical Discrepancy</title><categories>cs.CG</categories><comments>11 pages. A short version of this paper will appear in SODA06.
  This full version contains an additional short appendix</comments><abstract>  Anomaly detection has important applications in biosurveilance and
environmental monitoring. When comparing measured data to data drawn from a
baseline distribution, merely, finding clusters in the measured data may not
actually represent true anomalies. These clusters may likely be the clusters of
the baseline distribution. Hence, a discrepancy function is often used to
examine how different measured data is to baseline data within a region. An
anomalous region is thus defined to be one with high discrepancy.
  In this paper, we present algorithms for maximizing statistical discrepancy
functions over the space of axis-parallel rectangles. We give provable
approximation guarantees, both additive and relative, and our methods apply to
any convex discrepancy function. Our algorithms work by connecting statistical
discrepancy to combinatorial discrepancy; roughly speaking, we show that in
order to maximize a convex discrepancy function over a class of shapes, one
needs only maximize a linear discrepancy function over the same set of shapes.
  We derive general discrepancy functions for data generated from a one-
parameter exponential family. This generalizes the widely-used Kulldorff scan
statistic for data from a Poisson distribution. We present an algorithm running
in $O(\smash[tb]{\frac{1}{\epsilon} n^2 \log^2 n})$ that computes the maximum
discrepancy rectangle to within additive error $\epsilon$, for the Kulldorff
scan statistic. Similar results hold for relative error and for discrepancy
functions for data coming from Gaussian, Bernoulli, and gamma distributions.
Prior to our work, the best known algorithms were exact and ran in time
$\smash[t]{O(n^4)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510005</identifier>
 <datestamp>2008-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510005</id><created>2005-10-03</created><authors><author><keyname>Zuk</keyname><forenames>Or</forenames></author><author><keyname>Domany</keyname><forenames>Eytan</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author><author><keyname>Aizenman</keyname><forenames>Michael</forenames></author></authors><title>Taylor series expansions for the entropy rate of Hidden Markov
  Processes</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><journal-ref>Proceedings 2006 IEEE International Conference on Communications
  (ICC 2006).</journal-ref><abstract>  Finding the entropy rate of Hidden Markov Processes is an active research
topic, of both theoretical and practical importance. A recently used approach
is studying the asymptotic behavior of the entropy rate in various regimes. In
this paper we generalize and prove a previous conjecture relating the entropy
rate to entropies of finite systems. Building on our new theorems, we establish
series expansions for the entropy rate in two different regimes. We also study
the radius of convergence of the two series expansions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510006</id><created>2005-10-03</created><authors><author><keyname>Bregni</keyname><forenames>Stefano</forenames></author><author><keyname>Primerano</keyname><forenames>Luca</forenames></author></authors><title>Using the Modified Allan Variance for Accurate Estimation of the
  Hurst Parameter of Long-Range Dependent Traffic</title><categories>cs.NI</categories><comments>Ver. I - Submitted to IEEE Transactions on Information Theory,
  Feb. 2005</comments><abstract>  Internet traffic exhibits self-similarity and long-range dependence (LRD) on
various time scales. A well studied issue is the estimation of statistical
parameters characterizing traffic self-similarity and LRD, such as the Hurst
parameter H. In this paper, we propose to adapt the Modified Allan Variance
(MAVAR), a time-domain quantity originally conceived to discriminate fractional
noise in frequency stability measurement, to estimate the Hurst parameter of
LRD traffic traces and, more generally, to identify fractional noise components
in network traffic. This novel method is validated by comparison to one of the
best techniques for analyzing self-similar and LRD traffic: the logscale
diagram based on wavelet analysis. Both methods are applied to pseudo-random
LRD data series, generated with assigned values of H. The superior spectral
sensitivity of MAVAR achieves outstanding accuracy in estimating H, even better
than the logscale method. The behaviour of MAVAR with most common deterministic
signals that yield nonstationarity in data under analysis is also studied.
Finally, both techniques are applied to a real IP traffic trace, providing a
sound example of the usefulness of MAVAR also in traffic characterization, to
complement other established techniques as the logscale method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510007</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510007</id><created>2005-10-03</created><authors><author><keyname>Viger</keyname><forenames>Fabien</forenames></author><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Dall'Asta</keyname><forenames>Luca</forenames></author><author><keyname>Zhang</keyname><forenames>Cun-Hui</forenames></author><author><keyname>Kolaczyk</keyname><forenames>Eric D.</forenames></author></authors><title>Network Inference from TraceRoute Measurements: Internet Topology
  `Species'</title><categories>cs.NI cond-mat.stat-mech math.ST physics.soc-ph stat.TH</categories><journal-ref>Phys. Rev. E 75 (2007) 056111</journal-ref><doi>10.1103/PhysRevE.75.056111</doi><abstract>  Internet mapping projects generally consist in sampling the network from a
limited set of sources by using traceroute probes. This methodology, akin to
the merging of spanning trees from the different sources to a set of
destinations, leads necessarily to a partial, incomplete map of the Internet.
Accordingly, determination of Internet topology characteristics from such
sampled maps is in part a problem of statistical inference. Our contribution
begins with the observation that the inference of many of the most basic
topological quantities -- including network size and degree characteristics --
from traceroute measurements is in fact a version of the so-called `species
problem' in statistics. This observation has important implications, since
species problems are often quite challenging. We focus here on the most
fundamental example of a traceroute internet species: the number of nodes in a
network. Specifically, we characterize the difficulty of estimating this
quantity through a set of analytical arguments, we use statistical subsampling
principles to derive two proposed estimators, and we illustrate the performance
of these estimators on networks with various topological characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510008</id><created>2005-10-03</created><authors><author><keyname>Miravet</keyname><forenames>Carlos</forenames></author><author><keyname>Rodriguez</keyname><forenames>Francisco B.</forenames></author></authors><title>Accurate and robust image superresolution by neural processing of
  local image representations</title><categories>cs.CV cs.NE</categories><comments>6 pages with 3 figures. ICANN 2005</comments><acm-class>I.4.5; I.2.6; I.5.1</acm-class><journal-ref>Lect. Notes Comput. Sc. 3696 (2005) 499-506</journal-ref><abstract>  Image superresolution involves the processing of an image sequence to
generate a still image with higher resolution. Classical approaches, such as
bayesian MAP methods, require iterative minimization procedures, with high
computational costs. Recently, the authors proposed a method to tackle this
problem, based on the use of a hybrid MLP-PNN architecture. In this paper, we
present a novel superresolution method, based on an evolution of this concept,
to incorporate the use of local image models. A neural processing stage
receives as input the value of model coefficients on local windows. The data
dimensionality is firstly reduced by application of PCA. An MLP, trained on
synthetic sequences with various amounts of noise, estimates the
high-resolution image data. The effect of varying the dimension of the network
input space is examined, showing a complex, structured behavior. Quantitative
results are presented showing the accuracy and robustness of the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510009</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510009</id><created>2005-10-03</created><updated>2006-11-29</updated><authors><author><keyname>Kelley</keyname><forenames>Christine</forenames></author><author><keyname>Sridhara</keyname><forenames>Deepak</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Tree-Based Construction of LDPC Codes Having Good Pseudocodeword Weights</title><categories>cs.IT math.IT</categories><comments>Submitted to Transactions on Information Theory. Submitted: Oct. 1,
  2005; Revised: May 1, 2006, Nov. 25, 2006</comments><abstract>  We present a tree-based construction of LDPC codes that have minimum
pseudocodeword weight equal to or almost equal to the minimum distance, and
perform well with iterative decoding. The construction involves enumerating a
$d$-regular tree for a fixed number of layers and employing a connection
algorithm based on permutations or mutually orthogonal Latin squares to close
the tree. Methods are presented for degrees $d=p^s$ and $d = p^s+1$, for $p$ a
prime. One class corresponds to the well-known finite-geometry and finite
generalized quadrangle LDPC codes; the other codes presented are new. We also
present some bounds on pseudocodeword weight for $p$-ary LDPC codes. Treating
these codes as $p$-ary LDPC codes rather than binary LDPC codes improves their
rates, minimum distances, and pseudocodeword weights, thereby giving a new
importance to the finite geometry LDPC codes where $p &gt; 2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510010</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510010</id><created>2005-10-04</created><updated>2006-03-30</updated><authors><author><keyname>Hirschkoff</keyname><forenames>Daniel</forenames><affiliation>LIP-ENS LYON</affiliation></author><author><keyname>Lozes</keyname><forenames>Etienne</forenames><affiliation>LSV</affiliation></author><author><keyname>Sangiorgi</keyname><forenames>Davide</forenames><affiliation>DSI BOLOGNA</affiliation></author></authors><title>On the Expressiveness of the Ambient Logic</title><categories>cs.LO</categories><proxy>ccsd ccsd-00009279</proxy><acm-class>F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 2 (March 30,
  2006) lmcs:681</journal-ref><doi>10.2168/LMCS-2(2:3)2006</doi><abstract>  The Ambient Logic (AL) has been proposed for expressing properties of process
mobility in the calculus of Mobile Ambients (MA), and as a basis for query
languages on semistructured data. In this paper, we study the expressiveness of
AL. We define formulas for capabilities and for communication in MA. We also
derive some formulas that capture finitess of a term, name occurrences and
persistence. We study extensions of the calculus involving more complex forms
of communications, and we define characteristic formulas for the equivalence
induced by the logic on a subcalculus of MA. This subcalculus is defined by
imposing an image-finiteness condition on the reducts of a MA process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510011</id><created>2005-10-04</created><authors><author><keyname>Delahaye</keyname><forenames>David</forenames><affiliation>CEDRIC</affiliation></author><author><keyname>Mayero</keyname><forenames>Micaela</forenames><affiliation>LIPN</affiliation></author></authors><title>Diophantus' 20th Problem and Fermat's Last Theorem for n=4:
  Formalization of Fermat's Proofs in the Coq Proof Assistant</title><categories>cs.LO cs.SE math.NT</categories><comments>16 pages</comments><proxy>ccsd ccsd-00009425</proxy><abstract>  We present the proof of Diophantus' 20th problem (book VI of Diophantus'
Arithmetica), which consists in wondering if there exist right triangles whose
sides may be measured as integers and whose surface may be a square. This
problem was negatively solved by Fermat in the 17th century, who used the
&quot;wonderful&quot; method (ipse dixit Fermat) of infinite descent. This method, which
is, historically, the first use of induction, consists in producing smaller and
smaller non-negative integer solutions assuming that one exists; this naturally
leads to a reductio ad absurdum reasoning because we are bounded by zero. We
describe the formalization of this proof which has been carried out in the Coq
proof assistant. Moreover, as a direct and no less historical application, we
also provide the proof (by Fermat) of Fermat's last theorem for n=4, as well as
the corresponding formalization made in Coq.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510012</id><created>2005-10-04</created><updated>2005-10-06</updated><authors><author><keyname>Afrati</keyname><forenames>Foto</forenames></author><author><keyname>Andronikos</keyname><forenames>Theodore</forenames></author><author><keyname>Pavlaki</keyname><forenames>Vassia</forenames></author><author><keyname>Foustoucos</keyname><forenames>Eugenie</forenames></author><author><keyname>Guessarian</keyname><forenames>Irene</forenames></author></authors><title>On relating CTL to Datalog</title><categories>cs.LO</categories><comments>34 pages, 1 figure (file .eps)</comments><abstract>  CTL is the dominant temporal specification language in practice mainly due to
the fact that it admits model checking in linear time. Logic programming and
the database query language Datalog are often used as an implementation
platform for logic languages. In this paper we present the exact relation
between CTL and Datalog and moreover we build on this relation and known
efficient algorithms for CTL to obtain efficient algorithms for fragments of
stratified Datalog. The contributions of this paper are: a) We embed CTL into
STD which is a proper fragment of stratified Datalog. Moreover we show that STD
expresses exactly CTL -- we prove that by embedding STD into CTL. Both
embeddings are linear. b) CTL can also be embedded to fragments of Datalog
without negation. We define a fragment of Datalog with the successor build-in
predicate that we call TDS and we embed CTL into TDS in linear time. We build
on the above relations to answer open problems of stratified Datalog. We prove
that query evaluation is linear and that containment and satisfiability
problems are both decidable. The results presented in this paper are the first
for fragments of stratified Datalog that are more general than those containing
only unary EDBs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510013</id><created>2005-10-05</created><authors><author><keyname>Bouganim</keyname><forenames>Luc</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Cremarenco</keyname><forenames>Cosmin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Ngoc</keyname><forenames>Fran&#xe7;ois Dang</forenames><affiliation>INRIA Rocquencourt, PRISM - UVSQ</affiliation></author><author><keyname>Dieu</keyname><forenames>Nicolas</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Pucheral</keyname><forenames>Philippe</forenames><affiliation>INRIA Rocquencourt, PRISM - UVSQ</affiliation></author></authors><title>Safe Data Sharing and Data Dissemination on Smart Devices</title><categories>cs.CR cs.DB</categories><proxy>ccsd inria-00000399</proxy><abstract>  The erosion of trust put in traditional database servers, the growing
interest for different forms of data dissemination and the concern for
protecting children from suspicious Internet content are different factors that
lead to move the access control from servers to clients. Several encryption
schemes can be used to serve this purpose but all suffer from a static way of
sharing data. In a precedent paper, we devised smarter client-based access
control managers exploiting hardware security elements on client devices. The
goal pursued is being able to evaluate dynamic and personalized access control
rules on a ciphered XML input document, with the benefit of dissociating access
rights from encryption. In this demonstration, we validate our solution using a
real smart card platform and explain how we deal with the constraints usually
met on hardware security elements (small memory and low throughput). Finally,
we illustrate the generality of the approach and the easiness of its deployment
through two different applications: a collaborative application and a parental
control application on video streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510014</id><created>2005-10-05</created><updated>2006-02-07</updated><authors><author><keyname>Pernet</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>LMC - IMAG</affiliation></author><author><keyname>Rondepierre</keyname><forenames>Aude</forenames><affiliation>LMC - IMAG</affiliation></author><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Computing the Kalman form</title><categories>cs.SC math.OC</categories><comments>10 pages</comments><proxy>ccsd ccsd-00009558</proxy><abstract>  We present two algorithms for the computation of the Kalman form of a linear
control system. The first one is based on the technique developed by
Keller-Gehrig for the computation of the characteristic polynomial. The cost is
a logarithmic number of matrix multiplications. To our knowledge, this improves
the best previously known algebraic complexity by an order of magnitude. Then
we also present a cubic algorithm proven to more efficient in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510015</id><created>2005-10-05</created><authors><author><keyname>Audibert</keyname><forenames>Laurent</forenames><affiliation>DELIC</affiliation></author></authors><title>Word sense disambiguation criteria: a systematic study</title><categories>cs.CL</categories><proxy>ccsd ccsd-00009560</proxy><journal-ref>20th International Conference on Computational Linguistics
  (COLING-2004) (2004) pp. 910-916</journal-ref><abstract>  This article describes the results of a systematic in-depth study of the
criteria used for word sense disambiguation. Our study is based on 60 target
words: 20 nouns, 20 adjectives and 20 verbs. Our results are not always in line
with some practices in the field. For example, we show that omitting
non-content words decreases performance and that bigrams yield better results
than unigrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510016</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510016</id><created>2005-10-06</created><authors><author><keyname>Zuk</keyname><forenames>Or</forenames></author><author><keyname>Domany</keyname><forenames>Eytan</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author><author><keyname>Aizenman</keyname><forenames>Michael</forenames></author></authors><title>From finite-system entropy to entropy rate for a Hidden Markov Process</title><categories>cs.IT math-ph math.IT math.MP</categories><journal-ref>IEEE Signal Processing Letters 13,517 (2006).</journal-ref><doi>10.1109/LSP.2006.874466</doi><abstract>  A recent result presented the expansion for the entropy rate of a Hidden
Markov Process (HMP) as a power series in the noise variable $\eps$. The
coefficients of the expansion around the noiseless ($\eps = 0$) limit were
calculated up to 11th order, using a conjecture that relates the entropy rate
of a HMP to the entropy of a process of finite length (which is calculated
analytically). In this communication we generalize and prove the validity of
the conjecture, and discuss the theoretical and practical consequences of our
new theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510017</id><created>2005-10-06</created><authors><author><keyname>Janson</keyname><forenames>Svante</forenames></author><author><keyname>Szpankowski</keyname><forenames>Wojciech</forenames></author></authors><title>Partial fillup and search time in LC tries</title><categories>cs.DS math.PR</categories><comments>13 pages</comments><acm-class>E.1</acm-class><abstract>  Andersson and Nilsson introduced in 1993 a level-compressed trie (in short:
LC trie) in which a full subtree of a node is compressed to a single node of
degree being the size of the subtree. Recent experimental results indicated a
'dramatic improvement' when full subtrees are replaced by partially filled
subtrees. In this paper, we provide a theoretical justification of these
experimental results showing, among others, a rather moderate improvement of
the search time over the original LC tries. For such an analysis, we assume
that n strings are generated independently by a binary memoryless source with p
denoting the probability of emitting a 1. We first prove that the so called
alpha-fillup level (i.e., the largest level in a trie with alpha fraction of
nodes present at this level) is concentrated on two values with high
probability. We give these values explicitly up to O(1), and observe that the
value of alpha (strictly between 0 and 1) does not affect the leading term.
  This result directly yields the typical depth (search time) in the alpha-LC
tries with p not equal to 1/2, which turns out to be C loglog n for an
explicitly given constant C (depending on p but not on alpha). This should be
compared with recently found typical depth in the original LC tries which is C'
loglog n for a larger constant C'. The search time in alpha-LC tries is thus
smaller but of the same order as in the original LC tries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510018</id><created>2005-10-06</created><authors><author><keyname>Gligoroski</keyname><forenames>Danilo</forenames></author></authors><title>Candidate One-Way Functions and One-Way Permutations Based on Quasigroup
  String Transformations</title><categories>cs.CR cs.CC</categories><comments>Submitetd to conference</comments><abstract>  In this paper we propose a definition and construction of a new family of
one-way candidate functions ${\cal R}_N:Q^N \to Q^N$, where $Q=\{0,1,...,s-1\}$
is an alphabet with $s$ elements. Special instances of these functions can have
the additional property to be permutations (i.e. one-way permutations). These
one-way functions have the property that for achieving the security level of
$2^n$ computations in order to invert them, only $n$ bits of input are needed.
The construction is based on quasigroup string transformations. Since
quasigroups in general do not have algebraic properties such as associativity,
commutativity, neutral elements, inverting these functions seems to require
exponentially many readings from the lookup table that defines them (a Latin
Square) in order to check the satisfiability for the initial conditions, thus
making them natural candidates for one-way functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510019</id><created>2005-10-06</created><updated>2005-11-04</updated><authors><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>Entropy based Nearest Neighbor Search in High Dimensions</title><categories>cs.DS</categories><abstract>  In this paper we study the problem of finding the approximate nearest
neighbor of a query point in the high dimensional space, focusing on the
Euclidean space. The earlier approaches use locality-preserving hash functions
(that tend to map nearby points to the same value) to construct several hash
tables to ensure that the query point hashes to the same bucket as its nearest
neighbor in at least one table. Our approach is different -- we use one (or a
few) hash table and hash several randomly chosen points in the neighborhood of
the query point showing that at least one of them will hash to the bucket
containing its nearest neighbor. We show that the number of randomly chosen
points in the neighborhood of the query point $q$ required depends on the
entropy of the hash value $h(p)$ of a random point $p$ at the same distance
from $q$ at its nearest neighbor, given $q$ and the locality preserving hash
function $h$ chosen randomly from the hash family. Precisely, we show that if
the entropy $I(h(p)|q,h) = M$ and $g$ is a bound on the probability that two
far-off points will hash to the same bucket, then we can find the approximate
nearest neighbor in $O(n^\rho)$ time and near linear $\tilde O(n)$ space where
$\rho = M/\log(1/g)$. Alternatively we can build a data structure of size
$\tilde O(n^{1/(1-\rho)})$ to answer queries in $\tilde O(d)$ time. By applying
this analysis to the locality preserving hash functions in and adjusting the
parameters we show that the $c$ nearest neighbor can be computed in time
$\tilde O(n^\rho)$ and near linear space where $\rho \approx 2.06/c$ as $c$
becomes large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510020</id><created>2005-10-07</created><authors><author><keyname>Poibeau</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author></authors><title>Sur le statut r\'{e}f\'{e}rentiel des entit\'{e}s nomm\'{e}es</title><categories>cs.AI cs.IR</categories><comments>11 pages</comments><proxy>ccsd</proxy><journal-ref>Conf\'{e}rence Traitement Automatique des Langues 2005, France
  (2005)</journal-ref><abstract>  We show in this paper that, on the one hand, named entities can be designated
using different denominations and that, on the second hand, names denoting
named entities are polysemous. The analysis cannot be limited to reference
resolution but should take into account naming strategies, which are mainly
based on two linguistic operations: synecdoche and metonymy. Lastly, we present
a model that explicitly represents the different denominations in discourse,
unifying the way to represent linguistic knowledge and world knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510021</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510021</id><created>2005-10-07</created><authors><author><keyname>Meshkati</keyname><forenames>Farhad</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Schwartz</keyname><forenames>Stuart C.</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>A Unified Power Control Algorithm for Multiuser Detectors in Large
  Systems: Convergence and Performance</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 43rd Annual Allerton Conference on Communication,
  Control and Computing, Monticello, IL, September 2005</comments><abstract>  A unified approach to energy-efficient power control, applicable to a large
family of receivers including the matched filter, the decorrelator, the
(linear) minimum-mean-square-error detector (MMSE), and the individually and
jointly optimal multiuser detectors, has recently been proposed for
code-division-multiple-access (CDMA) networks. This unified power control (UPC)
algorithm exploits the linear relationship that has been shown to exist between
the transmit power and the output signal-to-interference-plus-noise ratio (SIR)
in large systems. Based on this principle and by computing the multiuser
efficiency, the UPC algorithm updates the users' transmit powers in an
iterative way to achieve the desired target SIR. In this paper, the convergence
of the UPC algorithm is proved for the matched filter, the decorrelator, and
the MMSE detector. In addition, the performance of the algorithm in finite-size
systems is studied and compared with that of existing power control schemes.
The UPC algorithm is particularly suitable for systems with randomly generated
long spreading sequences (i.e., sequences whose period is longer than one
symbol duration).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510022</id><created>2005-10-08</created><authors><author><keyname>Bretheim</keyname><forenames>Sam</forenames></author></authors><title>Cryptographic Authentication of Navigation Protocols</title><categories>cs.CR</categories><comments>12 pages</comments><acm-class>C.2.0; E.3</acm-class><abstract>  We examine the security of existing radio navigation protocols and attempt to
define secure, scalable replacements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510023</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510023</id><created>2005-10-10</created><authors><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On the capacity of mobile ad hoc networks with delay constraints</title><categories>cs.IT cs.NI math.IT</categories><comments>to appear in the IEEE Transactions on Wireless Communications</comments><abstract>  Previous work on ad hoc network capacity has focused primarily on
source-destination throughput requirements for different models and
transmission scenarios, with an emphasis on delay tolerant applications. In
such problems, network capacity enhancement is achieved as a tradeoff with
transmission delay. In this paper, the capacity of ad hoc networks supporting
delay sensitive traffic is studied. First, a general framework is proposed for
characterizing the interactions between the physical and the network layer in
an ad hoc network. Then, CDMA ad hoc networks, in which advanced signal
processing techniques such as multiuser detection are relied upon to enhance
the user capacity, are analyzed. The network capacity is characterized using a
combination of geometric arguments and large scale analysis, for several
network scenarios employing matched filters, decorrelators and
minimum-mean-square-error receivers. Insight into the network performance for
finite systems is also provided by means of simulations. Both analysis and
simulations show a significant network capacity gain for ad hoc networks
employing multiuser detectors, compared with those using matched filter
receivers, as well as very good performance even under tight delay and
transmission power requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510024</id><created>2005-10-10</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Meng</keyname><forenames>Jeremy Yu</forenames></author></authors><title>Delta-confluent Drawings</title><categories>cs.CG</categories><comments>14 pages, 8 figures. A preliminary version of this work was presented
  at the 13th Int. Symp. Graph Drawing, Limerick, Ireland, September 2005</comments><acm-class>F.2.2</acm-class><abstract>  We generalize the tree-confluent graphs to a broader class of graphs called
Delta-confluent graphs. This class of graphs and distance-hereditary graphs, a
well-known class of graphs, coincide. Some results about the visualization of
Delta-confluent graphs are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510025</id><created>2005-10-11</created><authors><author><keyname>Despeyroux</keyname><forenames>Thierry</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>Practical Semantic Analysis of Web Sites and Documents</title><categories>cs.IR</categories><proxy>ccsd inria-00000421</proxy><abstract>  As Web sites are now ordinary products, it is necessary to explicit the
notion of quality of a Web site. The quality of a site may be linked to the
easiness of accessibility and also to other criteria such as the fact that the
site is up to date and coherent. This last quality is difficult to insure
because sites may be updated very frequently, may have many authors, may be
partially generated and in this context proof-reading is very difficult. The
same piece of information may be found in different occurrences, but also in
data or meta-data, leading to the need for consistency checking. In this paper
we make a parallel between programs and Web sites. We present some examples of
semantic constraints that one would like to specify (constraints between the
meaning of categories and sub-categories in a thematic directory, consistency
between the organization chart and the rest of the site in an academic site).
We present quickly the Natural Semantics, a way to specify the semantics of
programming languages that inspires our works. Then we propose a specification
language for semantic constraints in Web sites that, in conjunction with the
well known ``make'' program, permits to generate some site verification tools
by compiling the specification into Prolog code. We apply our method to a large
XML document which is the scientific part of our institute activity report,
tracking errors or inconsistencies and also constructing some indicators that
can be used by the management of the institute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510026</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510026</id><created>2005-10-11</created><authors><author><keyname>de Luna</keyname><forenames>Alvaro Enriquez</forenames></author><author><keyname>Miravet</keyname><forenames>Carlos</forenames></author><author><keyname>Otaduy</keyname><forenames>Deitze</forenames></author><author><keyname>Dorronsoro</keyname><forenames>Carlos</forenames></author></authors><title>A decision support system for ship identification based on the curvature
  scale space representation</title><categories>cs.CV</categories><comments>12 pages, 18 figures, 1 table, SPIE 5988 Electro-Optical Remote
  Sensing 2005</comments><doi>10.1117/12.630532</doi><abstract>  In this paper, a decision support system for ship identification is
presented. The system receives as input a silhouette of the vessel to be
identified, previously extracted from a side view of the object. This view
could have been acquired with imaging sensors operating at different spectral
ranges (CCD, FLIR, image intensifier). The input silhouette is preprocessed and
compared to those stored in a database, retrieving a small number of potential
matches ranked by their similarity to the target silhouette. This set of
potential matches is presented to the system operator, who makes the final ship
identification. This system makes use of an evolved version of the Curvature
Scale Space (CSS) representation. In the proposed approach, it is curvature
extrema, instead of zero crossings, that are tracked during silhouette
evolution, hence improving robustness and enabling to cope successfully with
cases where the standard CCS representation is found to be unstable. Also, the
use of local curvature was replaced with the more robust concept of lobe
concavity, with significant additional gains in performance. Experimental
results on actual operational imagery prove the excellent performance and
robustness of the developed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510027</id><created>2005-10-11</created><updated>2006-06-15</updated><authors><author><keyname>d'Aspremont</keyname><forenames>Alexandre</forenames></author></authors><title>A Market Test for the Positivity of Arrow-Debreu Prices</title><categories>cs.CE</categories><comments>New version, fixes a few minor errors and typos</comments><acm-class>J.4</acm-class><abstract>  We derive tractable necessary and sufficient conditions for the absence of
buy-and-hold arbitrage opportunities in a perfectly liquid, one period market.
We formulate the positivity of Arrow-Debreu prices as a generalized moment
problem to show that this no arbitrage condition is equivalent to the positive
semidefiniteness of matrices formed by the market price of tradeable securities
and their products. We apply this result to a market with multiple assets and
basket call options.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510028</id><created>2005-10-11</created><authors><author><keyname>Grishchenko</keyname><forenames>Victor S.</forenames></author></authors><title>Geo-aggregation permits low stretch and routing tables of logarithmical
  size</title><categories>cs.NI</categories><comments>6 pages</comments><acm-class>C.2.5</acm-class><abstract>  This article first addresses applicability of Euclidean models to the domain
of Internet routing. Those models are found (limitedly) applicable. Then a
simplistic model of routing is constructed for Euclidean plane densely covered
with points-routers. The model guarantees low stretch and logarithmical size of
routing tables at any node. The paper concludes with a discussion on
applicability of the model to real-world Internet routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510029</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510029</id><created>2005-10-11</created><authors><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author></authors><title>Conditionally independent random variables</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><abstract>  In this paper we investigate the notion of conditional independence and prove
several information inequalities for conditionally independent random
variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510030</id><created>2005-10-11</created><updated>2007-05-31</updated><authors><author><keyname>Mobasher</keyname><forenames>Amin</forenames></author><author><keyname>Taherzadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Sotirov</keyname><forenames>Renata</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>A Near Maximum Likelihood Decoding Algorithm for MIMO Systems Based on
  Semi-Definite Programming</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Info. Theory, Revised</comments><report-no>UW-E&amp;CE#2005-12</report-no><abstract>  In Multi-Input Multi-Output (MIMO) systems, Maximum-Likelihood (ML) decoding
is equivalent to finding the closest lattice point in an N-dimensional complex
space. In general, this problem is known to be NP hard. In this paper, we
propose a quasi-maximum likelihood algorithm based on Semi-Definite Programming
(SDP). We introduce several SDP relaxation models for MIMO systems, with
increasing complexity. We use interior-point methods for solving the models and
obtain a near-ML performance with polynomial computational complexity. Lattice
basis reduction is applied to further reduce the computational complexity of
solving these models. The proposed relaxation models are also used for soft
output decoding in MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510031</id><created>2005-10-13</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author></authors><title>Computing Pure Nash Equilibria via Markov Random Fields</title><categories>cs.GT</categories><abstract>  In this paper we present a novel generic mapping between Graphical Games and
Markov Random Fields so that pure Nash equilibria in the former can be found by
statistical inference on the latter. Thus, the problem of deciding whether a
graphical game has a pure Nash equilibrium, a well-known intractable problem,
can be attacked by well-established algorithms such as Belief Propagation,
Junction Trees, Markov Chain Monte Carlo and Simulated Annealing. Large classes
of graphical games become thus tractable, including all classes already known,
but also new classes such as the games with O(log n) treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510032</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510032</id><created>2005-10-13</created><authors><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>Polar Polytopes and Recovery of Sparse Representations</title><categories>cs.IT math.IT</categories><abstract>  Suppose we have a signal y which we wish to represent using a linear
combination of a number of basis atoms a_i, y=sum_i x_i a_i = Ax. The problem
of finding the minimum L0 norm representation for y is a hard problem. The
Basis Pursuit (BP) approach proposes to find the minimum L1 norm representation
instead, which corresponds to a linear program (LP) that can be solved using
modern LP techniques, and several recent authors have given conditions for the
BP (minimum L1 norm) and sparse (minimum L0 solutions) representations to be
identical. In this paper, we explore this sparse representation problem} using
the geometry of convex polytopes, as recently introduced into the field by
Donoho. By considering the dual LP we find that the so-called polar polytope P
of the centrally-symmetric polytope P whose vertices are the atom pairs +-a_i
is particularly helpful in providing us with geometrical insight into
optimality conditions given by Fuchs and Tropp for non-unit-norm atom sets. In
exploring this geometry we are able to tighten some of these earlier results,
showing for example that the Fuchs condition is both necessary and sufficient
for L1-unique-optimality, and that there are situations where Orthogonal
Matching Pursuit (OMP) can eventually find all L1-unique-optimal solutions with
m nonzeros even if ERC fails for m, if allowed to run for more than m steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510033</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510033</id><created>2005-10-13</created><authors><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Coding for the Optical Channel: the Ghost-Pulse Constraint</title><categories>cs.IT cs.DM math.IT</categories><comments>13 pages, 6 figures; accepted for publication in IEEE Transactions on
  Information Theory</comments><abstract>  We consider a number of constrained coding techniques that can be used to
mitigate a nonlinear effect in the optical fiber channel that causes the
formation of spurious pulses, called ``ghost pulses.'' Specifically, if $b_1
b_2 ... b_{n}$ is a sequence of bits sent across an optical channel, such that
$b_k=b_l=b_m=1$ for some $k,l,m$ (not necessarily all distinct) but $b_{k+l-m}
= 0$, then the ghost-pulse effect causes $b_{k+l-m}$ to change to 1, thereby
creating an error. We design and analyze several coding schemes using binary
and ternary sequences constrained so as to avoid patterns that give rise to
ghost pulses. We also discuss the design of encoders and decoders for these
coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510034</id><created>2005-10-13</created><authors><author><keyname>L&#xe1;z&#xe1;r</keyname><forenames>Zsolt I.</forenames></author><author><keyname>Fanea</keyname><forenames>Andreea</forenames></author><author><keyname>Petra&#x15f;cu</keyname><forenames>Drago&#x15f;</forenames></author><author><keyname>Ciobotariu-Boer</keyname><forenames>Vladiela</forenames></author><author><keyname>P&#xe2;rv</keyname><forenames>Bazil</forenames></author></authors><title>COMODI: On the Graphical User Interface</title><categories>cs.HC cs.CE cs.MS</categories><comments>5 pages, 5 figures, to be published as proceedings of SYNASC 2005</comments><acm-class>D.2.13; D.2.12; D.2.11; D.2.9; D.2.6</acm-class><abstract>  We propose a series of features for the graphical user interface (GUI) of the
COmputational MOdule Integrator (COMODI) \cite{Synasc05a}\cite{COMODI}. In view
of the special requirements that a COMODI type of framework for scientific
computing imposes and inspiring from existing solutions that provide advanced
graphical visual programming environments, we identify those elements and
associated behaviors that will have to find their way into the first release of
COMODI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510035</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510035</id><created>2005-10-14</created><authors><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Montorsi</keyname><forenames>Guido</forenames></author><author><keyname>Vatta</keyname><forenames>Francesca</forenames></author></authors><title>Design and Performance Analysis of a New Class of Rate Compatible Serial
  Concatenated Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><abstract>  In this paper, we provide a performance analysis of a new class of serial
concatenated convolutional codes (SCCC) where the inner encoder can be
punctured beyond the unitary rate. The puncturing of the inner encoder is not
limited to inner coded bits, but extended to systematic bits. Moreover, it is
split into two different puncturings, in correspondence with inner code
systematic bits and parity bits. We derive the analytical upper bounds to the
error probability of this particular code structure and address suitable design
guidelines for the inner code puncturing patterns. We show that the percentile
of systematic and parity bits to be deleted strongly depends on the SNR region
of interest. In particular, to lower the error floor it is advantageous to put
more puncturing on inner systematic bits. Furthermore, we show that puncturing
of inner systematic bits should be interleaver dependent. Based on these
considerations, we derive design guidelines to obtain well-performing
rate-compatible SCCC families. Throughout the paper, the performance of the
proposed codes are compared with analytical bounds, and with the performance of
PCCC and SCCC proposed in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510036</id><created>2005-10-14</created><authors><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author></authors><title>Semantic Optimization Techniques for Preference Queries</title><categories>cs.DB cs.AI cs.LO</categories><abstract>  Preference queries are relational algebra or SQL queries that contain
occurrences of the winnow operator (&quot;find the most preferred tuples in a given
relation&quot;). Such queries are parameterized by specific preference relations.
Semantic optimization techniques make use of integrity constraints holding in
the database. In the context of semantic optimization of preference queries, we
identify two fundamental properties: containment of preference relations
relative to integrity constraints and satisfaction of order axioms relative to
integrity constraints. We show numerous applications of those notions to
preference query evaluation and optimization. As integrity constraints, we
consider constraint-generating dependencies, a class generalizing functional
dependencies. We demonstrate that the problems of containment and satisfaction
of order axioms can be captured as specific instances of constraint-generating
dependency entailment. This makes it possible to formulate necessary and
sufficient conditions for the applicability of our techniques as constraint
validity problems. We characterize the computational complexity of such
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510037</id><created>2005-10-14</created><authors><author><keyname>Bendaoud</keyname><forenames>Rokia</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Toussaint</keyname><forenames>Yannick</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Napoli</keyname><forenames>Amedeo</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Hi\'{e}rarchisation des r\`{e}gles d'association en fouille de textes</title><categories>cs.IR cs.AI</categories><proxy>ccsd inria-00000436</proxy><abstract>  Extraction of association rules is widely used as a data mining method.
However, one of the limit of this approach comes from the large number of
extracted rules and the difficulty for a human expert to deal with the totality
of these rules. We propose to solve this problem by structuring the set of
rules into hierarchy. The expert can then therefore explore the rules, access
from one rule to another one more general when we raise up in the hierarchy,
and in other hand, or a more specific rules. Rules are structured at two
levels. The global level aims at building a hierarchy from the set of rules
extracted. Thus we define a first type of rule-subsomption relying on Galois
lattices. The second level consists in a local and more detailed analysis of
each rule. It generate for a given rule a set of generalization rules
structured into a local hierarchy. This leads to the definition of a second
type of subsomption. This subsomption comes from inductive logic programming
and integrates a terminological model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510038</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510038</id><created>2005-10-14</created><updated>2007-06-26</updated><authors><author><keyname>Atici</keyname><forenames>Alp</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author></authors><title>Learning Unions of $\omega(1)$-Dimensional Rectangles</title><categories>cs.LG</categories><comments>25 pages. Some corrections. Recipient of E. M. Gold award ALT 2006.
  To appear in Journal of Theoretical Computer Science</comments><acm-class>F.2.2; I.2.6</acm-class><journal-ref>Theoretical Computer Science, Vol. 405, No. 3, 209--222 (2008)</journal-ref><doi>10.1016/j.tcs.2008.06.036</doi><abstract>  We consider the problem of learning unions of rectangles over the domain
$[b]^n$, in the uniform distribution membership query learning setting, where
both b and n are &quot;large&quot;. We obtain poly$(n, \log b)$-time algorithms for the
following classes:
  - poly$(n \log b)$-way Majority of $O(\frac{\log(n \log b)} {\log \log(n \log
b)})$-dimensional rectangles.
  - Union of poly$(\log(n \log b))$ many $O(\frac{\log^2 (n \log b)} {(\log
\log(n \log b) \log \log \log (n \log b))^2})$-dimensional rectangles.
  - poly$(n \log b)$-way Majority of poly$(n \log b)$-Or of disjoint
$O(\frac{\log(n \log b)} {\log \log(n \log b)})$-dimensional rectangles.
  Our main algorithmic tool is an extension of Jackson's boosting- and
Fourier-based Harmonic Sieve algorithm [Jackson 1997] to the domain $[b]^n$,
building on work of [Akavia, Goldwasser, Safra 2003]. Other ingredients used to
obtain the results stated above are techniques from exact learning [Beimel,
Kushilevitz 1998] and ideas from recent work on learning augmented $AC^{0}$
circuits [Jackson, Klivans, Servedio 2002] and on representing Boolean
functions as thresholds of parities [Klivans, Servedio 2001].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510039</id><created>2005-10-14</created><authors><author><keyname>Bobda</keyname><forenames>Christophe</forenames></author><author><keyname>Ahmadinia</keyname><forenames>Ali</forenames></author><author><keyname>Majer</keyname><forenames>Mateusz</forenames></author><author><keyname>Teich</keyname><forenames>Juergen</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>van der Veen</keyname><forenames>Jan</forenames></author></authors><title>DyNoC: A Dynamic Infrastructure for Communication in Dynamically
  Reconfigurable Devices</title><categories>cs.AR</categories><comments>9 pages, 7 figures, 1 table, Latex, to appear in 15th International
  Conference on Field-Programmable Logic and Application</comments><acm-class>B.7; C.5; C.3</acm-class><abstract>  A new paradigm to support the communication among modules dynamically placed
on a reconfigurable device at run-time is presented. Based on the network on
chip (NoC) infrastructure, we developed a dynamic communication infrastructure
as well as routing methodologies capable to handle routing in a NoC with
obstacles created by dynamically placed components. We prove the unrestricted
reachability of components and pins, the deadlock-freeness and we finally show
the feasibility of our approach by means on real life example applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510040</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510040</id><created>2005-10-14</created><authors><author><keyname>Krechmer</keyname><forenames>Ken</forenames></author></authors><title>The &quot;...system of constraints&quot;</title><categories>cs.IT math.IT</categories><acm-class>H.1.1; C.0; K.1</acm-class><abstract>  This paper proposes that the mathematical relationship between an entropy
distribution and its limit offers some new insight into system performance.
This relationship is used to quantify variation among the entities of a system,
where variation is defined as tolerance, option, specification or
implementation variation among the entities of a system. Variation has a
significnt and increasing impact on communications system performance. This
paper introduces means to identify, quantify and reduce such performance
variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510041</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510041</id><created>2005-10-15</created><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Blasiak</keyname><forenames>Pawel</forenames><affiliation>LPTL</affiliation></author><author><keyname>Horzela</keyname><forenames>Andrzej</forenames><affiliation>LPTL</affiliation></author><author><keyname>Penson</keyname><forenames>Karol A.</forenames><affiliation>LPTL</affiliation></author><author><keyname>Solomon</keyname><forenames>Allan I.</forenames><affiliation>LPTL</affiliation></author></authors><title>Feynman graphs and related Hopf algebras</title><categories>cs.SC cs.DM math-ph math.CO math.MP quant-ph</categories><proxy>ccsd ccsd-00010155</proxy><acm-class>G.2.1</acm-class><doi>10.1088/1742-6596/30/1/014</doi><abstract>  In a recent series of communications we have shown that the reordering
problem of bosons leads to certain combinatorial structures. These structures
may be associated with a certain graphical description. In this paper, we show
that there is a Hopf Algebra structure associated with this problem which is,
in a certain sense, unique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510042</id><created>2005-10-15</created><authors><author><keyname>Naccache</keyname><forenames>David</forenames></author></authors><title>Secure and {\sl Practical} Identity-Based Encryption</title><categories>cs.CR</categories><acm-class>K.6.5</acm-class><abstract>  In this paper, we present a variant of Waters' Identity-Based Encryption
scheme with a much smaller public-key size (only a few kilobytes). We show that
this variant is semantically secure against passive adversaries in the standard
model.\smallskip
  In essence, the new scheme divides Waters' public key size by a factor $\ell$
at the cost of (negligibly) reducing security by $\ell$ bits. Therefore, our
construction settles an open question asked by Waters and constitutes the first
fully secure {\sl practical} Identity-Based Encryption scheme
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510043</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510043</id><created>2005-10-15</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author></authors><title>On Minimal Pseudo-Codewords of Tanner Graphs from Projective Planes</title><categories>cs.IT cs.DM math.IT</categories><comments>This paper is a slightly reformulated version of the paper that
  appeared in the proceedings of the 43rd Allerton Conference on
  Communications, Control, and Computing, Allerton House, Monticello, Illinois,
  USA, Sept. 28-30, 2005</comments><journal-ref>Proc. 43rd Allerton Conference on Communications, Control, and
  Computing, Allerton House, Monticello, Illinois, USA, Sept. 28-30, 2005</journal-ref><abstract>  We would like to better understand the fundamental cone of Tanner graphs
derived from finite projective planes. Towards this goal, we discuss bounds on
the AWGNC and BSC pseudo-weight of minimal pseudo-codewords of such Tanner
graphs, on one hand, and study the structure of minimal pseudo-codewords, on
the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510044</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510044</id><created>2005-10-16</created><updated>2006-05-22</updated><authors><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Prabhakar</keyname><forenames>Balaji</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Belief Propagation Based Multi--User Detection</title><categories>cs.IT math.IT</categories><comments>9 pages, 4 eps figures. Forty-third Allerton Conference on
  Communications, Control and Computing, invited paper</comments><abstract>  We apply belief propagation (BP) to multi--user detection in a spread
spectrum system, under the assumption of Gaussian symbols. We prove that BP is
both convergent and allows to estimate the correct conditional expectation of
the input symbols. It is therefore an optimal --minimum mean square error--
detection algorithm. This suggests the possibility of designing BP detection
algorithms for more general systems. As a byproduct we rederive the Tse-Hanly
formula for minimum mean square error without any recourse to random matrix
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510045</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510045</id><created>2005-10-16</created><authors><author><keyname>Measson</keyname><forenames>Cyril</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>Why We Can Not Surpass Capacity: The Matching Condition</title><categories>cs.IT math.IT</categories><comments>10 pages, 27 ps figures. Forty-third Allerton Conference on
  Communication, Control and Computing, invited paper</comments><abstract>  We show that iterative coding systems can not surpass capacity using only
quantities which naturally appear in density evolution. Although the result in
itself is trivial, the method which we apply shows that in order to achieve
capacity the various components in an iterative coding system have to be
perfectly matched. This generalizes the perfect matching condition which was
previously known for the case of transmission over the binary erasure channel
to the general class of binary-input memoryless output-symmetric channels.
Potential applications of this perfect matching condition are the construction
of capacity-achieving degree distributions and the determination of the number
required iterations as a function of the multiplicative gap to capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510046</id><created>2005-10-16</created><authors><author><keyname>Mogilevsky</keyname><forenames>Dmitry</forenames></author><author><keyname>Lee</keyname><forenames>Adam</forenames></author><author><keyname>Yurcik</keyname><forenames>William</forenames></author></authors><title>Defining a Comprehensive Threat Model for High Performance Computational
  Clusters</title><categories>cs.CR cs.DC</categories><abstract>  Over the past decade, high performance computational (HPC) clusters have
become mainstream in academic and industrial settings as accessible means of
computation. Throughout their proliferation, HPC security has been a secondary
concern to performance. It is evident, however, that ensuring HPC security
presents different challenges than the ones faced when dealing with traditional
networks. To design suitable security measures for high performance computing,
it is necessary to first realize the threats faced by such an environment. This
task can be accomplished by the means of constructing a comprehensive threat
model. To our knowledge, no such threat model exists with regards to Cluster
Computing. In this paper, we explore the unique challenges of securing HPCs and
propose a threat model based on the classical Confidentiality, Integrity and
Availability security principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510047</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510047</id><created>2005-10-17</created><updated>2006-12-05</updated><authors><author><keyname>Henkel</keyname><forenames>Oliver</forenames></author></authors><title>Geometrical relations between space time block code designs and
  complexity reduction</title><categories>cs.IT math.IT</categories><comments>final version, 11 pages, two-column</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 52, no. 12 (Dec 2006), 5324-5335</journal-ref><doi>10.1109/TIT.2006.885457</doi><abstract>  In this work, the geometric relation between space time block code design for
the coherent channel and its non-coherent counterpart is exploited to get an
analogue of the information theoretic inequality $I(X;S)\le I((X,H);S)$ in
terms of diversity. It provides a lower bound on the performance of
non-coherent codes when used in coherent scenarios. This leads in turn to a
code design decomposition result splitting coherent code design into two
complexity reduced sub tasks. Moreover a geometrical criterion for high
performance space time code design is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510048</id><created>2005-10-17</created><authors><author><keyname>Kroeller</keyname><forenames>Alexander</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Pfisterer</keyname><forenames>Dennis</forenames></author><author><keyname>Fischer</keyname><forenames>Stefan</forenames></author></authors><title>Deterministic boundary recognition and topology extraction for large
  sensor networks</title><categories>cs.DC cs.CG</categories><comments>10 pages, 9 figures, Latex, to appear in Symposium on Discrete
  Algorithms (SODA 2006)</comments><acm-class>C.2.1; F.2.2</acm-class><abstract>  We present a new framework for the crucial challenge of self-organization of
a large sensor network. The basic scenario can be described as follows: Given a
large swarm of immobile sensor nodes that have been scattered in a polygonal
region, such as a street network. Nodes have no knowledge of size or shape of
the environment or the position of other nodes. Moreover, they have no way of
measuring coordinates, geometric distances to other nodes, or their direction.
Their only way of interacting with other nodes is to send or to receive
messages from any node that is within communication range. The objective is to
develop algorithms and protocols that allow self-organization of the swarm into
large-scale structures that reflect the structure of the street network,
setting the stage for global routing, tracking and guiding algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510049</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510049</id><created>2005-10-17</created><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Wauer</keyname><forenames>Marcel</forenames></author></authors><title>Bounds on the Pseudo-Weight of Minimal Pseudo-Codewords of Projective
  Geometry Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>12 pages 1 figure, submitted</comments><abstract>  In this paper we focus our attention on a family of finite geometry codes,
called type-I projective geometry low-density parity-check (PG-LDPC) codes,
that are constructed based on the projective planes PG{2,q). In particular, we
study their minimal codewords and pseudo-codewords, as it is known that these
vectors characterize completely the code performance under maximum-likelihood
decoding and linear programming decoding, respectively. The main results of
this paper consist of upper and lower bounds on the pseudo-weight of the
minimal pseudo-codewords of type-I PG-LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510050</id><created>2005-10-18</created><authors><author><keyname>Kassel</keyname><forenames>Gilles</forenames><affiliation>LaRIA</affiliation></author></authors><title>Integration of the DOLCE top-level ontology into the OntoSpec
  methodology</title><categories>cs.AI</categories><proxy>ccsd ccsd-00012203</proxy><report-no>LRR-2005-08</report-no><abstract>  This report describes a new version of the OntoSpec methodology for ontology
building. Defined by the LaRIA Knowledge Engineering Team (University of
Picardie Jules Verne, Amiens, France), OntoSpec aims at helping builders to
model ontological knowledge (upstream of formal representation). The
methodology relies on a set of rigorously-defined modelling primitives and
principles. Its application leads to the elaboration of a semi-informal
ontology, which is independent of knowledge representation languages. We
recently enriched the OntoSpec methodology by endowing it with a new resource,
the DOLCE top-level ontology defined at the LOA (IST-CNR, Trento, Italy). The
goal of this integration is to provide modellers with additional help in
structuring application ontologies, while maintaining independence
vis-\`{a}-vis formal representation languages. In this report, we first provide
an overview of the OntoSpec methodology's general principles and then describe
the DOLCE re-engineering process. A complete version of DOLCE-OS (i.e. a
specification of DOLCE in the semi-informal OntoSpec language) is presented in
an appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510051</id><created>2005-10-18</created><authors><author><keyname>Argentini</keyname><forenames>Gianluca</forenames></author></authors><title>Numerical resolution of some BVP using Bernstein polynomials</title><categories>cs.NA cs.MS math.CA physics.comp-ph</categories><comments>7 pages, 3 figures</comments><acm-class>G.1.7</acm-class><journal-ref>Posted since 2005-11-29 at Applied Mathematics E-Notes,
  http://www.math.nthu.edu.tw/~amen/</journal-ref><abstract>  In this work we present a method, based on the use of Bernstein polynomials,
for the numerical resolution of some boundary values problems. The computations
have not need of particular approximations of derivatives, such as finite
differences, or particular techniques, such as finite elements. Also, the
method doesn't require the use of matrices, as in resolution of linear
algebraic systems, nor the use of like-Newton algorithms, as in resolution of
non linear sets of equations. An initial equation is resolved only once, then
the method is based on iterated evaluations of appropriate polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510052</id><created>2005-10-18</created><updated>2005-10-20</updated><authors><author><keyname>Grishchenko</keyname><forenames>Victor S.</forenames></author></authors><title>Remarks on &quot;Toward Compact Interdomain Routing&quot;</title><categories>cs.NI</categories><abstract>  This paper critically examines some propositions and arguments of
cs.NI/0508021 regarding applicability of hierarchical routing and perspectives
of compact routing. Arguments against the former are found to be inaccurate
while the latter is found to be equivalent to well-known deployed solutions.
Also, multiple (stacked) application of compact-routing solutions is found to
be equivalent to hierarchical routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510053</id><created>2005-10-18</created><updated>2005-11-01</updated><authors><author><keyname>Kutz</keyname><forenames>Martin</forenames></author></authors><title>A pair of trees without a simultaneous geometric embedding in the plane</title><categories>cs.CG</categories><comments>This paper has been withdrawn by the author because it had turned out
  that the result was already known before</comments><abstract>  Any planar graph has a crossing-free straight-line drawing in the plane. A
simultaneous geometric embedding of two n-vertex graphs is a straight-line
drawing of both graphs on a common set of n points, such that the edges withing
each individual graph do not cross. We consider simultaneous embeddings of two
labeled trees, with predescribed vertex correspondences, and present an
instance of such a pair that cannot be embedded. Further we provide an example
of a planar graph that cannot be embedded together with a path when vertex
correspondences are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510054</id><created>2005-10-19</created><authors><author><keyname>Zhao</keyname><forenames>Le</forenames></author><author><keyname>Zhang</keyname><forenames>Min</forenames></author><author><keyname>Ma</keyname><forenames>Shaoping</forenames></author></authors><title>The Nature of Novelty Detection</title><categories>cs.IR cs.CL</categories><comments>This paper pointed out the future direction for novelty detection
  research. 37 pages, double spaced version</comments><acm-class>H.3.3</acm-class><abstract>  Sentence level novelty detection aims at reducing redundant sentences from a
sentence list. In the task, sentences appearing later in the list with no new
meanings are eliminated. Aiming at a better accuracy for detecting redundancy,
this paper reveals the nature of the novelty detection task currently
overlooked by the Novelty community $-$ Novelty as a combination of the partial
overlap (PO, two sentences sharing common facts) and complete overlap (CO, the
first sentence covers all the facts of the second sentence) relations. By
formalizing novelty detection as a combination of the two relations between
sentences, new viewpoints toward techniques dealing with Novelty are proposed.
Among the methods discussed, the similarity, overlap, pool and language
modeling approaches are commonly used. Furthermore, a novel approach, selected
pool method is provided, which is immediate following the nature of the task.
Experimental results obtained on all the three currently available novelty
datasets showed that selected pool is significantly better or no worse than the
current methods. Knowledge about the nature of the task also affects the
evaluation methodologies. We propose new evaluation measures for Novelty
according to the nature of the task, as well as possible directions for future
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510055</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510055</id><created>2005-10-19</created><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Fakhereddin</keyname><forenames>Maralle J.</forenames></author></authors><title>Degrees of Freedom in Multiuser MIMO</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><abstract>  We explore the available degrees of freedom for various multiuser MIMO
communication scenarios such as the multiple access, broadcast, interference,
relay, X and Z channels. For the two user MIMO interference channel, we find a
general inner bound and a genie-aided outer bound that give us the exact number
of degrees of freedom in many cases. We also study a share-and-transmit scheme
for transmitter cooperation. For the share-and-transmit scheme, we show how the
gains of transmitter cooperation are entirely offset by the cost of enabling
that cooperation so that the available degrees of freedom are not increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510056</id><created>2005-10-19</created><authors><author><keyname>Jung</keyname><forenames>Yoon-Mo</forenames></author><author><keyname>Shen</keyname><forenames>Jianhong</forenames></author></authors><title>First-Order Modeling and Stability Analysis of Illusory Contours</title><categories>cs.CV cs.AI</categories><comments>21 pages</comments><acm-class>I.4.6; I.4.8</acm-class><abstract>  In visual cognition, illusions help elucidate certain intriguing latent
perceptual functions of the human vision system, and their proper mathematical
modeling and computational simulation are therefore deeply beneficial to both
biological and computer vision. Inspired by existent prior works, the current
paper proposes a first-order energy-based model for analyzing and simulating
illusory contours. The lower complexity of the proposed model facilitates
rigorous mathematical analysis on the detailed geometric structures of illusory
contours. After being asymptotically approximated by classical active contours,
the proposed model is then robustly computed using the celebrated level-set
method of Osher and Sethian (J. Comput. Phys., 79:12-49, 1988) with a natural
supervising scheme. Potential cognitive implications of the mathematical
results are addressed, and generic computational examples are demonstrated and
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510057</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510057</id><created>2005-10-20</created><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LMC - IMAG</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LMC - IMAG</affiliation></author></authors><title>Towards a diagrammatic modeling of the LinBox C++ linear algebra library</title><categories>cs.SC</categories><comments>Published in Langages et Mod\`eles \`a Objets, N\^imes : France
  (2006)</comments><proxy>ccsd ccsd-00012346</proxy><acm-class>D.2.12; I.6.5; D.1.5; D.3.3; G.4</acm-class><abstract>  We propose a new diagrammatic modeling language, DML. The paradigm used is
that of the category theory and in particular of the pushout tool. We show that
most of the object-oriented structures can be described with this tool and have
many examples in C++, ranging from virtual inheritance and polymorphism to
template genericity. With this powerful tool, we propose a quite simple
description of the C++ LinBox library. This library has been designed for
efficiency and genericity and therefore makes heavy usage of complex template
and polymorphic mecanism. Be reverse engineering, we are able to describe in a
simple manner the complex structure of archetypes in LinBox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510058</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510058</id><created>2005-10-20</created><updated>2006-01-16</updated><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author></authors><title>Precoding for 2x2 Doubly-Dispersive WSSUS Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 6th International ITG-Conference on Source and Channel
  Coding (SCC 2006), Apr., 2006, Munich, typos corrected</comments><abstract>  Optimal link adaption to the scattering function of wide sense stationary
uncorrelated scattering (WSSUS) mobile communication channels is still an
unsolved problem despite its importance for next-generation system design. In
multicarrier transmission such link adaption is performed by pulse shaping
which in turn is equivalent to precoding with respect to the second order
channel statistics. In the present framework a translation of the precoder
optimization problem into an optimization problem over trace class operators is
used. This problem which is also well-known in the context of quantum
information theory is unsolved in general due to its non-convex nature. However
in very low dimension the problem formulation reveals an additional analytic
structure which again admits the solution to the optimal precoder and
multiplexing scheme. Hence, in this contribution the analytic solution of the
problem for the 2x2 doubly--dispersive WSSUS channel is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510059</id><created>2005-10-20</created><authors><author><keyname>Parent</keyname><forenames>Michel</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>De La Fortelle</keyname><forenames>Arnaud</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Cybercars : Past, Present and Future of the Technology</title><categories>cs.RO</categories><proxy>ccsd inria-00000467</proxy><journal-ref>Dans ITS World Congress 2005</journal-ref><abstract>  Automobile has become the dominant transport mode in the world in the last
century. In order to meet a continuously growing demand for transport, one
solution is to change the control approach for vehicle to full driving
automation, which removes the driver from the control loop to improve
efficiency and reduce accidents. Recent work shows that there are several
realistic paths towards this deployment : driving assistance on passenger cars,
automated commercial vehicles on dedicated infrastructures, and new forms of
urban transport (car-sharing and cybercars). Cybercars have already been put
into operation in Europe, and it seems that this approach could lead the way
towards full automation on most urban, and later interurban infrastructures.
The European project CyberCars has brought many improvements in the technology
needed to operate cybercars over the last three years. A new, larger European
project is now being prepared to carry this work further in order to meet more
ambitious objectives in terms of safety and efficiency. This paper will present
past and present technologies and will focus on the future developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510060</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510060</id><created>2005-10-20</created><authors><author><keyname>Hanlen</keyname><forenames>Leif W</forenames></author><author><keyname>Grant</keyname><forenames>Alex J</forenames></author></authors><title>Optimal Transmit Covariance for Ergodic MIMO Channels</title><categories>cs.IT math.IT</categories><comments>22 pages, 14 figures, Submitted to IEEE Transactions on Information
  Theory</comments><abstract>  In this paper we consider the computation of channel capacity for ergodic
multiple-input multiple-output channels with additive white Gaussian noise. Two
scenarios are considered. Firstly, a time-varying channel is considered in
which both the transmitter and the receiver have knowledge of the channel
realization. The optimal transmission strategy is water-filling over space and
time. It is shown that this may be achieved in a causal, indeed instantaneous
fashion. In the second scenario, only the receiver has perfect knowledge of the
channel realization, while the transmitter has knowledge of the channel gain
probability law. In this case we determine an optimality condition on the input
covariance for ergodic Gaussian vector channels with arbitrary channel
distribution under the condition that the channel gains are independent of the
transmit signal. Using this optimality condition, we find an iterative
algorithm for numerical computation of optimal input covariance matrices.
Applications to correlated Rayleigh and Ricean channels are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510061</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510061</id><created>2005-10-21</created><authors><author><keyname>Czenko</keyname><forenames>M.</forenames></author><author><keyname>Tran</keyname><forenames>H.</forenames></author><author><keyname>Doumen</keyname><forenames>J.</forenames></author><author><keyname>Etalle</keyname><forenames>S.</forenames></author><author><keyname>Hartel</keyname><forenames>P.</forenames></author><author><keyname>Hartog</keyname><forenames>J. den</forenames></author></authors><title>Nonmonotonic Trust Management for P2P Applications</title><categories>cs.LO</categories><comments>This paper appears in the proceedings of the 1st International
  Workshop on Security and Trust Management (STM 2005). To appear in ENTCS</comments><report-no>TR-CTIT-05-22</report-no><acm-class>F.4.1; I.2.3; I.2.4</acm-class><abstract>  Community decisions about access control in virtual communities are
non-monotonic in nature. This means that they cannot be expressed in current,
monotonic trust management languages such as the family of Role Based Trust
Management languages (RT). To solve this problem we propose RT-, which adds a
restricted form of negation to the standard RT language, thus admitting a
controlled form of non-monotonicity. The semantics of RT- is discussed and
presented in terms of the well-founded semantics for Logic Programs. Finally we
discuss how chain discovery can be accomplished for RT-.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510062</id><created>2005-10-21</created><authors><author><keyname>Saboune</keyname><forenames>Jamal</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Charpillet</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Using Interval Particle Filtering for Marker less 3D Human Motion
  Capture</title><categories>cs.AI</categories><proxy>ccsd inria-00000475</proxy><abstract>  In this paper we present a new approach for marker less human motion capture
from conventional camera feeds. The aim of our study is to recover 3D positions
of key points of the body that can serve for gait analysis. Our approach is
based on foreground segmentation, an articulated body model and particle
filters. In order to be generic and simple no restrictive dynamic modelling was
used. A new modified particle filtering algorithm was introduced. It is used
efficiently to search the model configuration space. This new algorithm which
we call Interval Particle Filtering reorganizes the configurations search space
in an optimal deterministic way and proved to be efficient in tracking natural
human movement. Results for human motion capture from a single camera are
presented and compared to results obtained from a marker based system. The
system proved to be able to track motion successfully even in partial
occlusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510063</id><created>2005-10-21</created><authors><author><keyname>Saboune</keyname><forenames>Jamal</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Charpillet</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Markerless Human Motion Capture for Gait Analysis</title><categories>cs.AI</categories><proxy>ccsd inria-00000476</proxy><abstract>  The aim of our study is to detect balance disorders and a tendency towards
the falls in the elderly, knowing gait parameters. In this paper we present a
new tool for gait analysis based on markerless human motion capture, from
camera feeds. The system introduced here, recovers the 3D positions of several
key points of the human body while walking. Foreground segmentation, an
articulated body model and particle filtering are basic elements of our
approach. No dynamic model is used thus this system can be described as generic
and simple to implement. A modified particle filtering algorithm, which we call
Interval Particle Filtering, is used to reorganise and search through the
model's configurations search space in a deterministic optimal way. This
algorithm was able to perform human movement tracking with success. Results
from the treatment of a single cam feeds are shown and compared to results
obtained using a marker based human motion capture system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510064</identifier>
 <datestamp>2008-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510064</id><created>2005-10-21</created><authors><author><keyname>Figueiredo</keyname><forenames>Rosa M. V.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author><author><keyname>Maculan</keyname><forenames>Nelson</forenames></author><author><keyname>Souza</keyname><forenames>Cid C.</forenames></author></authors><title>Acyclic orientations with path constraints</title><categories>cs.DM</categories><acm-class>G.1.6</acm-class><journal-ref>RAIRO Operations Research 42 (2008), 455-467</journal-ref><doi>10.1051/ro:2008028</doi><abstract>  Many well-known combinatorial optimization problems can be stated over the
set of acyclic orientations of an undirected graph. For example, acyclic
orientations with certain diameter constraints are closely related to the
optimal solutions of the vertex coloring and frequency assignment problems. In
this paper we introduce a linear programming formulation of acyclic
orientations with path constraints, and discuss its use in the solution of the
vertex coloring problem and some versions of the frequency assignment problem.
A study of the polytope associated with the formulation is presented, including
proofs of which constraints of the formulation are facet-defining and the
introduction of new classes of valid inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510065</id><created>2005-10-22</created><authors><author><keyname>Wierzbicki</keyname><forenames>Adam</forenames></author><author><keyname>Zwierko</keyname><forenames>Aneta</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>A new authentication protocol for revocable anonymity in ad-hoc networks</title><categories>cs.CR cs.DC cs.NI</categories><comments>8 pages, 8 figures, this an extended version of paper accepted for
  IASTED conference CNIS'2005</comments><acm-class>C.2.0; C.2.4</acm-class><abstract>  This paper describes a new protocol for authentication in ad-hoc networks.
The protocol has been designed to meet specialized requirements of ad-hoc
networks, such as lack of direct communication between nodes or requirements
for revocable anonymity. At the same time, a ad-hoc authentication protocol
must be resistant to spoofing, eavesdropping and playback, and
man-in-the-middle attacks. The article analyzes existing authentication methods
based on the Public Key Infrastructure, and finds that they have several
drawbacks in ad-hoc networks. Therefore, a new authentication protocol, basing
on established cryptographic primitives (Merkle's puzzles and zero-knowledge
proofs) is proposed. The protocol is studied for a model ad-hoc chat
application that provides private conversations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510066</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510066</id><created>2005-10-22</created><updated>2006-03-23</updated><authors><author><keyname>Courcelle</keyname><forenames>Bruno</forenames></author></authors><title>The monadic second-order logic of graphs XVI : Canonical graph&lt;br&gt;
  decompositions</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 2 (March 23,
  2006) lmcs:779</journal-ref><doi>10.2168/LMCS-2(2:2)2006</doi><abstract>  This article establishes that the split decomposition of graphs introduced by
Cunnigham, is definable in Monadic Second-Order Logic.This result is actually
an instance of a more general result covering canonical graph decompositions
like the modular decomposition and the Tutte decomposition of 2-connected
graphs into 3-connected components. As an application, we prove that the set of
graphs having the same cycle matroid as a given 2-connected graph can be
defined from this graph by Monadic Second-Order formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510067</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510067</id><created>2005-10-23</created><authors><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author><author><keyname>Banerjee</keyname><forenames>Adrish</forenames></author><author><keyname>Chaturvedi</keyname><forenames>A K</forenames></author></authors><title>On the Spread of Random Interleaver</title><categories>cs.IT math.IT</categories><comments>5 pages, published in Proceedings of IEEE International Symposium on
  Information Theory 2005, Adelaide, Australia</comments><journal-ref>IEEE International Symposium on Information Theory 2005</journal-ref><doi>10.1109/ISIT.2005.1523372</doi><abstract>  For a given blocklength we determine the number of interleavers which have
spread equal to two. Using this, we find out the probability that a randomly
chosen interleaver has spread two. We show that as blocklength increases, this
probability increases but very quickly converges to the value $1-e^{-2} \approx
0.8647$. Subsequently, we determine a lower bound on the probability of an
interleaver having spread at least $s$. We show that this lower bound converges
to the value $e^{-2(s-2)^{2}}$, as the blocklength increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510068</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510068</id><created>2005-10-23</created><authors><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author><author><keyname>Sahinoglu</keyname><forenames>Zafer</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hisashi</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Ultra Wideband Impulse Radio Systems with Multiple Pulse Types</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Journal on Selected Areas in Communications -
  Special Issue on Ultrawideband Wireless Communications: Theory and
  Applications</comments><abstract>  In an ultra wideband (UWB) impulse radio (IR) system, a number of pulses,
each transmitted in an interval called a &quot;frame&quot;, is employed to represent one
information symbol. Conventionally, a single type of UWB pulse is used in all
frames of all users. In this paper, IR systems with multiple types of UWB
pulses are considered, where different types of pulses can be used in different
frames by different users. Both stored-reference (SR) and transmitted-reference
(TR) systems are considered. First, the spectral properties of a multi-pulse IR
system with polarity randomization is investigated. It is shown that the
average power spectral density is the average of the spectral contents of
different pulse shapes. Then, approximate closed-form expressions for the bit
error probability of a multi-pulse SR-IR system are derived for RAKE receivers
in asynchronous multiuser environments. The effects of both inter-frame
interference (IFI) and multiple-access interference (MAI) are analyzed. The
theoretical and simulation results indicate that SR-IR systems that are more
robust against IFI and MAI than a &quot;conventional&quot; SR-IR system can be designed
with multiple types of ultra-wideband pulses. Finally, extensions to
multi-pulse TR-IR systems are briefly described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510069</id><created>2005-10-23</created><authors><author><keyname>Boker</keyname><forenames>Udi</forenames></author><author><keyname>Dershowitz</keyname><forenames>Nachum</forenames></author></authors><title>Comparing Computational Power</title><categories>cs.LO</categories><comments>To appear in Logic Journal of the IGPL in 2006</comments><abstract>  It is common practice to compare the computational power of different models
of computation. For example, the recursive functions are strictly more powerful
than the primitive recursive functions, because the latter are a proper subset
of the former (which includes Ackermann's function). Side-by-side with this
&quot;containment&quot; method of measuring power, it is standard to use an approach
based on &quot;simulation&quot;. For example, one says that the (untyped) lambda calculus
is as powerful--computationally speaking--as the partial recursive functions,
because the lambda calculus can simulate all partial recursive functions by
encoding the natural numbers as Church numerals.
  The problem is that unbridled use of these two ways of comparing power allows
one to show that some computational models are strictly stronger than
themselves! We argue that a better definition is that model A is strictly
stronger than B if A can simulate B via some encoding, whereas B cannot
simulate A under any encoding. We then show that the recursive functions are
strictly stronger in this sense than the primitive recursive. We also prove
that the recursive functions, partial recursive functions, and Turing machines
are &quot;complete&quot;, in the sense that no injective encoding can make them
equivalent to any &quot;hypercomputational&quot; model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510070</identifier>
 <datestamp>2008-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510070</id><created>2005-10-23</created><updated>2007-01-02</updated><authors><author><keyname>Lun</keyname><forenames>Desmond S.</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>On Coding for Reliable Communication over Packet Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>33 pages, 6 figures; revised appendix</comments><journal-ref>Physical Communication, vol. 1, no. 1, pp. 3-20, March 2008.</journal-ref><doi>10.1016/j.phycom.2008.01.006</doi><abstract>  We present a capacity-achieving coding scheme for unicast or multicast over
lossy packet networks. In the scheme, intermediate nodes perform additional
coding yet do not decode nor even wait for a block of packets before sending
out coded packets. Rather, whenever they have a transmission opportunity, they
send out coded packets formed from random linear combinations of previously
received packets. All coding and decoding operations have polynomial
complexity.
  We show that the scheme is capacity-achieving as long as packets received on
a link arrive according to a process that has an average rate. Thus, packet
losses on a link may exhibit correlation in time or with losses on other links.
In the special case of Poisson traffic with i.i.d. losses, we give error
exponents that quantify the rate of decay of the probability of error with
coding delay. Our analysis of the scheme shows that it is not only
capacity-achieving, but that the propagation of packets carrying &quot;innovative&quot;
information follows the propagation of jobs through a queueing network, and
therefore fluid flow models yield good approximations. We consider networks
with both lossy point-to-point and broadcast links, allowing us to model both
wireline and wireless packet networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510071</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510071</id><created>2005-10-23</created><authors><author><keyname>Bletsas</keyname><forenames>Aggelos</forenames></author><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Reed</keyname><forenames>David P.</forenames></author><author><keyname>Lippman</keyname><forenames>Andrew</forenames></author></authors><title>A Simple Cooperative Diversity Method Based on Network Path Selection</title><categories>cs.IT math.IT</categories><comments>To appear, IEEE JSAC, special issue on 4G</comments><abstract>  Cooperative diversity has been recently proposed as a way to form virtual
antenna arrays that provide dramatic gains in slow fading wireless
environments. However most of the proposed solutions require distributed
space-time coding algorithms, the careful design of which is left for future
investigation if there is more than one cooperative relay. We propose a novel
scheme, that alleviates these problems and provides diversity gains on the
order of the number of relays in the network. Our scheme first selects the best
relay from a set of M available relays and then uses this best relay for
cooperation between the source and the destination. We develop and analyze a
distributed method to select the best relay that requires no topology
information and is based on local measurements of the instantaneous channel
conditions. This method also requires no explicit communication among the
relays. The success (or failure) to select the best available path depends on
the statistics of the wireless channel, and a methodology to evaluate
performance for any kind of wireless channel statistics, is provided.
Information theoretic analysis of outage probability shows that our scheme
achieves the same diversity-multiplexing tradeoff as achieved by more complex
protocols, where coordination and distributed space-time coding for M nodes is
required, such as those proposed in [7]. The simplicity of the technique,
allows for immediate implementation in existing radio hardware and its adoption
could provide for improved flexibility, reliability and efficiency in future 4G
wireless systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510072</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510072</id><created>2005-10-23</created><authors><author><keyname>Ionescu</keyname><forenames>Dumitru Mihai</forenames></author><author><keyname>Doan</keyname><forenames>Dung N.</forenames></author><author><keyname>Gray</keyname><forenames>Steven D.</forenames></author></authors><title>On Interleaving Techniques for MIMO Channels and Limitations of Bit
  Interleaved Coded Modulation</title><categories>cs.IT math.IT</categories><comments>20 pages, 11 figures, uses IEEEtran.cls</comments><acm-class>E.4; H.1.1</acm-class><abstract>  It is shown that while the mutual information curves for coded modulation
(CM) and bit interleaved coded modulation (BICM) overlap in the case of a
single input single output channel, the same is not true in multiple input
multiple output (MIMO) channels. A method for mitigating fading in the presence
of multiple transmit antennas, named coordinate interleaving (CI), is presented
as a generalization of component interleaving for a single transmit antenna.
The extent of any advantages of CI over BICM, relative to CM, is analyzed from
a mutual information perspective; the analysis is based on an equivalent
parallel channel model for CI. Several expressions for mutual information in
the presence of CI and multiple transmit and receive antennas are derived.
Results show that CI gives higher mutual information compared to that of BICM
if proper signal mappings are used. Effects like constellation rotation in the
presence of CI are also considered and illustrated; it is shown that
constellation rotation can increase the constrained capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510073</id><created>2005-10-24</created><authors><author><keyname>Attiogbe</keyname><forenames>Christian</forenames></author></authors><title>Semantic Embedding of Petri Nets into Event-B</title><categories>cs.LO</categories><comments>16 pages, 3 figures</comments><acm-class>D.2.2; D.2.4; F.3.1</acm-class><abstract>  We present an embedding of Petri nets into B abstract systems. The embedding
is achieved by translating both the static structure (modelling aspect) and the
evolution semantics of Petri nets. The static structure of a Petri-net is
captured within a B abstract system through a graph structure. This abstract
system is then included in another abstract system which captures the evolution
semantics of Petri-nets. The evolution semantics results in some B events
depending on the chosen policies: basic nets or high level Petri nets. The
current embedding enables one to use conjointly Petri nets and Event-B in the
same system development, but at different steps and for various analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510074</id><created>2005-10-24</created><authors><author><keyname>Fluet</keyname><forenames>Matthew</forenames></author><author><keyname>Pucella</keyname><forenames>Riccardo</forenames></author></authors><title>Practical Datatype Specializations with Phantom Types and Recursion
  Schemes</title><categories>cs.PL</categories><comments>25 pages. Appeared in the Proc. of the 2005 ACM SIGPLAN Workshop on
  ML</comments><acm-class>D.1.1; D.3.3; F.3.3</acm-class><abstract>  Datatype specialization is a form of subtyping that captures program
invariants on data structures that are expressed using the convenient and
intuitive datatype notation. Of particular interest are structural invariants
such as well-formedness. We investigate the use of phantom types for describing
datatype specializations. We show that it is possible to express
statically-checked specializations within the type system of Standard ML. We
also show that this can be done in a way that does not lose useful programming
facilities such as pattern matching in case expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510075</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510075</id><created>2005-10-24</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Verdu</keyname><forenames>Sergio</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On-Off Frequency-Shift-Keying for Wideband Fading Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the EURASIP Journal on Wireless Communications and
  Networking</comments><abstract>  M-ary On-Off Frequency-Shift-Keying (OOFSK) is a digital modulation format in
which M-ary FSK signaling is overlaid on On/Off keying. This paper investigates
the potential of this modulation format in the context of wideband fading
channels. First it is assumed that the receiver uses energy detection for the
reception of OOFSK signals. Capacity expressions are obtained for the cases in
which the receiver has perfect and imperfect fading side information. Power
efficiency is investigated when the transmitter is subject to a peak-to-average
power ratio (PAR) limitation or a peak power limitation. It is shown that under
a PAR limitation, it is extremely power inefficient to operate in the very low
SNR regime. On the other hand, if there is only a peak power limitation, it is
demonstrated that power efficiency improves as one operates with smaller SNR
and vanishing duty factor. Also studied are the capacity improvements that
accrue when the receiver can track phase shifts in the channel or if the
received signal has a specular component. To take advantage of those features,
the phase of the modulation is also allowed to carry information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510076</id><created>2005-10-25</created><authors><author><keyname>Pauplin</keyname><forenames>Olivier</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Louchet</keyname><forenames>Jean</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Lutton</keyname><forenames>Evelyne</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Parent</keyname><forenames>Michel</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Applying Evolutionary Optimisation to Robot Obstacle Avoidance</title><categories>cs.AI cs.RO</categories><proxy>ccsd inria-00000494</proxy><journal-ref>Dans ISCIIA 2004</journal-ref><abstract>  This paper presents an artificial evolutionbased method for stereo image
analysis and its application to real-time obstacle detection and avoidance for
a mobile robot. It uses the Parisian approach, which consists here in splitting
the representation of the robot's environment into a large number of simple
primitives, the &quot;flies&quot;, which are evolved following a biologically inspired
scheme and give a fast, low-cost solution to the obstacle detection problem in
mobile robotics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510077</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510077</id><created>2005-10-25</created><authors><author><keyname>Ajanki</keyname><forenames>Oskari</forenames></author><author><keyname>Knowles</keyname><forenames>Antti</forenames></author></authors><title>Connection state overhead in a dynamic linear network</title><categories>cs.IT cs.NI math.IT</categories><comments>8 pages, 3 figures, uses IEEEtran.cls</comments><acm-class>H.1.1</acm-class><abstract>  We consider a dynamical linear network where nearest neighbours communicate
via links whose states form binary (open/closed) valued independent and
identically distributed Markov processes. Our main result is the tight
information-theoretic lower bound on the network traffic required by the
connection state overhead, or the information required for all nodes to know
their connected neighbourhood. These results, and especially their possible
generalisations to more realistic network models, could give us valuable
understanding of the unavoidable protocol overheads in rapidly changing Ad hoc
and sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510078</id><created>2005-10-25</created><authors><author><keyname>Wang</keyname><forenames>H.</forenames></author><author><keyname>Viswanath</keyname><forenames>P.</forenames></author></authors><title>Vector Gaussian Multiple Description with Individual and Central
  Receivers</title><categories>cs.IT math.IT</categories><abstract>  L multiple descriptions of a vector Gaussian source for individual and
central receivers are investigated. The sum rate of the descriptions with
covariance distortion measure constraints, in a positive semidefinite ordering,
is exactly characterized. For two descriptions, the entire rate region is
characterized. Jointly Gaussian descriptions are optimal in achieving the
limiting rates. The key component of the solution is a novel
information-theoretic inequality that is used to lower bound the achievable
multiple description rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510079</id><created>2005-10-25</created><updated>2006-08-03</updated><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pucella</keyname><forenames>Riccardo</forenames></author></authors><title>Evidence with Uncertain Likelihoods</title><categories>cs.AI</categories><comments>21 pages. A preliminary version appeared in the Proceedings of UAI'05</comments><acm-class>I.2.3; G.3</acm-class><abstract>  An agent often has a number of hypotheses, and must choose among them based
on observations, or outcomes of experiments. Each of these observations can be
viewed as providing evidence for or against various hypotheses. All the
attempts to formalize this intuition up to now have assumed that associated
with each hypothesis h there is a likelihood function \mu_h, which is a
probability measure that intuitively describes how likely each observation is,
conditional on h being the correct hypothesis. We consider an extension of this
framework where there is uncertainty as to which of a number of likelihood
functions is appropriate, and discuss how one formal approach to defining
evidence, which views evidence as a function from priors to posteriors, can be
generalized to accommodate this uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510080</id><created>2005-10-25</created><authors><author><keyname>Grunwald</keyname><forenames>Peter D.</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>When Ignorance is Bliss</title><categories>cs.AI cs.LG</categories><comments>In Proceedings of the Twentieth Conference on Uncertainty in AI,
  2004, pp. 226-234</comments><acm-class>I.2.4</acm-class><abstract>  It is commonly-accepted wisdom that more information is better, and that
information should never be ignored. Here we argue, using both a Bayesian and a
non-Bayesian analysis, that in some situations you are better off ignoring
information if your uncertainty is represented by a set of probability
measures. These include situations in which the information is relevant for the
prediction task at hand. In the non-Bayesian analysis, we show how ignoring
information avoids dilation, the phenomenon that additional pieces of
information sometimes lead to an increase in uncertainty. In the Bayesian
analysis, we show that for small sample sizes and certain prediction tasks, the
Bayesian posterior based on a noninformative prior yields worse predictions
than simply ignoring the given information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510081</id><created>2005-10-26</created><authors><author><keyname>Nguyen</keyname><forenames>Toan</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Wang</keyname><forenames>Lizhe</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Selmin</keyname><forenames>Vittorio</forenames><affiliation>ALENIA Aeronautica</affiliation></author></authors><title>Virtual Environments for multiphysics code validation on Computing Grids</title><categories>cs.DC</categories><proxy>ccsd inria-00000510</proxy><abstract>  We advocate in this paper the use of grid-based infrastructures that are
designed for seamless approaches to the numerical expert users, i.e., the
multiphysics applications designers. It relies on sophisticated computing
environments based on computing grids, connecting heterogeneous computing
resources: mainframes, PC-clusters and workstations running multiphysics codes
and utility software, e.g., visualization tools. The approach is based on
concepts defined by the HEAVEN* consortium. HEAVEN is a European scientific
consortium including industrial partners from the aerospace, telecommunication
and software industries, as well as academic research institutes. Currently,
the HEAVEN consortium works on a project that aims to create advanced services
platforms. It is intended to enable &quot;virtual private grids&quot; supporting various
environments for users manipulating a suitable high-level interface. This will
become the basis for future generalized services allowing the integration of
various services without the need to deploy specific grid infrastructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510082</id><created>2005-10-26</created><authors><author><keyname>Alvarez-Hamelin</keyname><forenames>Jos&#xe9; Ignacio</forenames><affiliation>LPT, FIUBA</affiliation></author><author><keyname>Viana</keyname><forenames>Aline Carneiro</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author><author><keyname>De Amorim</keyname><forenames>Marcelo Dias</forenames><affiliation>LIP6</affiliation></author></authors><title>Architectural Considerations for a Self-Configuring Routing Scheme for
  Spontaneous Networks</title><categories>cs.NI</categories><proxy>ccsd ccsd-00012694</proxy><abstract>  Decoupling the permanent identifier of a node from the node's
topology-dependent address is a promising approach toward completely scalable
self-organizing networks. A group of proposals that have adopted such an
approach use the same structure to: address nodes, perform routing, and
implement location service. In this way, the consistency of the routing
protocol relies on the coherent sharing of the addressing space among all nodes
in the network. Such proposals use a logical tree-like structure where routes
in this space correspond to routes in the physical level. The advantage of
tree-like spaces is that it allows for simple address assignment and
management. Nevertheless, it has low route selection flexibility, which results
in low routing performance and poor resilience to failures. In this paper, we
propose to increase the number of paths using incomplete hypercubes. The design
of more complex structures, like multi-dimensional Cartesian spaces, improves
the resilience and routing performance due to the flexibility in route
selection. We present a framework for using hypercubes to implement indirect
routing. This framework allows to give a solution adapted to the dynamics of
the network, providing a proactive and reactive routing protocols, our major
contributions. We show that, contrary to traditional approaches, our proposal
supports more dynamic networks and is more robust to node failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510083</id><created>2005-10-26</created><authors><author><keyname>Kerkeni</keyname><forenames>Nizar</forenames><affiliation>TIM</affiliation></author><author><keyname>Alexandre</keyname><forenames>Frederic</forenames><affiliation>CORTEX</affiliation></author><author><keyname>Bedoui</keyname><forenames>Mohamed Hedi</forenames><affiliation>TIM</affiliation></author><author><keyname>Bougrain</keyname><forenames>Laurent</forenames><affiliation>CORTEX</affiliation></author><author><keyname>Dogui</keyname><forenames>Mohamed</forenames><affiliation>SAHLOUL</affiliation></author></authors><title>Neuronal Spectral Analysis of EEG and Expert Knowledge Integration for
  Automatic Classification of Sleep Stages</title><categories>cs.AI</categories><proxy>ccsd inria-00000511</proxy><abstract>  Being able to analyze and interpret signal coming from electroencephalogram
(EEG) recording can be of high interest for many applications including medical
diagnosis and Brain-Computer Interfaces. Indeed, human experts are today able
to extract from this signal many hints related to physiological as well as
cognitive states of the recorded subject and it would be very interesting to
perform such task automatically but today no completely automatic system
exists. In previous studies, we have compared human expertise and automatic
processing tools, including artificial neural networks (ANN), to better
understand the competences of each and determine which are the difficult
aspects to integrate in a fully automatic system. In this paper, we bring more
elements to that study in reporting the main results of a practical experiment
which was carried out in an hospital for sleep pathology study. An EEG
recording was studied and labeled by a human expert and an ANN. We describe
here the characteristics of the experiment, both human and neuronal procedure
of analysis, compare their performances and point out the main limitations
which arise from this study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510084</id><created>2005-10-26</created><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames></author></authors><title>R\'{e}flexions sur la question fr\'{e}quentielle en traitement du signal</title><categories>cs.CE cs.IR math-ph math.MP math.SP</categories><proxy>ccsd inria-00000461</proxy><abstract>  New definitions are suggested for frequencies which may be instantaneous or
not. The Heisenberg-Gabor inequality and the Shannon sampling theorem are
briefly discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510085</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510085</id><created>2005-10-26</created><authors><author><keyname>Rickard</keyname><forenames>Scott T.</forenames></author><author><keyname>Balan</keyname><forenames>Radu V.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Verdu</keyname><forenames>Sergio</forenames></author></authors><title>Canonical time-frequency, time-scale, and frequency-scale
  representations of time-varying channels</title><categories>cs.IT math.IT</categories><comments>To appear in Communications in Information and Systems - special
  issue in honor of Thomas Kailath's seventieth birthday</comments><acm-class>E.4; C.2.1</acm-class><abstract>  Mobile communication channels are often modeled as linear time-varying
filters or, equivalently, as time-frequency integral operators with finite
support in time and frequency. Such a characterization inherently assumes the
signals are narrowband and may not be appropriate for wideband signals. In this
paper time-scale characterizations are examined that are useful in wideband
time-varying channels, for which a time-scale integral operator is physically
justifiable. A review of these time-frequency and time-scale characterizations
is presented. Both the time-frequency and time-scale integral operators have a
two-dimensional discrete characterization which motivates the design of
time-frequency or time-scale rake receivers. These receivers have taps for both
time and frequency (or time and scale) shifts of the transmitted signal. A
general theory of these characterizations which generates, as specific cases,
the discrete time-frequency and time-scale models is presented here. The
interpretation of these models, namely, that they can be seen to arise from
processing assumptions on the transmit and receive waveforms is discussed. Out
of this discussion a third model arises: a frequency-scale continuous channel
model with an associated discrete frequency-scale characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510086</id><created>2005-10-27</created><authors><author><keyname>Kenthapadi</keyname><forenames>K.</forenames></author><author><keyname>Panigrahy</keyname><forenames>R.</forenames></author></authors><title>Balanced Allocation on Graphs</title><categories>cs.DS</categories><abstract>  In this paper, we study the two choice balls and bins process when balls are
not allowed to choose any two random bins, but only bins that are connected by
an edge in an underlying graph. We show that for $n$ balls and $n$ bins, if the
graph is almost regular with degree $n^\epsilon$, where $\epsilon$ is not too
small, the previous bounds on the maximum load continue to hold. Precisely, the
maximum load is $\log \log n + O(1/\epsilon) + O(1)$. For general
$\Delta$-regular graphs, we show that the maximum load is $\log\log n +
O(\frac{\log n}{\log (\Delta/\log^4 n)}) + O(1)$ and also provide an almost
matching lower bound of $\log \log n + \frac{\log n}{\log (\Delta \log n)}$.
  V{\&quot;o}cking [Voc99] showed that the maximum bin size with $d$ choice load
balancing can be further improved to $O(\log\log n /d)$ by breaking ties to the
left. This requires $d$ random bin choices. We show that such bounds can be
achieved by making only two random accesses and querying $d/2$ contiguous bins
in each access. By grouping a sequence of $n$ bins into $2n/d$ groups, each of
$d/2$ consecutive bins, if each ball chooses two groups at random and inserts
the new ball into the least-loaded bin in the lesser loaded group, then the
maximum load is $O(\log\log n/d)$ with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510087</id><created>2005-10-31</created><authors><author><keyname>Grosse</keyname><forenames>J.</forenames></author></authors><title>MathPSfrag: Creating Publication-Quality Labels in Mathematica Plots</title><categories>cs.GR</categories><comments>7 pages, 8 figures, for associated Mathematica package, see
  http://wwwth.mppmu.mpg.de/members/jgrosse/mathpsfrag/MathPSfrag-1.0.tar.gz</comments><report-no>LMU-ASC 70/05; MPP-2005-126</report-no><acm-class>I.3.4</acm-class><abstract>  This article introduces a Mathematica package providing a graphics export
function that automatically replaces Mathematica expressions in a graphic by
the corresponding LaTeX constructs and positions them correctly. It thus
facilitates the creation of publication-quality Enscapulated PostScript (EPS)
graphics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510088</id><created>2005-10-29</created><updated>2005-11-26</updated><authors><author><keyname>Motwani</keyname><forenames>Rajeev</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>Lower bounds on Locality Sensitive Hashing</title><categories>cs.CG</categories><abstract>  Given a metric space $(X,d_X)$, $c\ge 1$, $r&gt;0$, and $p,q\in [0,1]$, a
distribution over mappings $\h:X\to \mathbb N$ is called a
$(r,cr,p,q)$-sensitive hash family if any two points in $X$ at distance at most
$r$ are mapped by $\h$ to the same value with probability at least $p$, and any
two points at distance greater than $cr$ are mapped by $\h$ to the same value
with probability at most $q$. This notion was introduced by Indyk and Motwani
in 1998 as the basis for an efficient approximate nearest neighbor search
algorithm, and has since been used extensively for this purpose. The
performance of these algorithms is governed by the parameter
$\rho=\frac{\log(1/p)}{\log(1/q)}$, and constructing hash families with small
$\rho$ automatically yields improved nearest neighbor algorithms. Here we show
that for $X=\ell_1$ it is impossible to achieve $\rho\le \frac{1}{2c}$. This
almost matches the construction of Indyk and Motwani which achieves $\rho\le
\frac{1}{c}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510089</identifier>
 <datestamp>2007-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510089</id><created>2005-10-30</created><authors><author><keyname>Ghnemat</keyname><forenames>Rawan</forenames><affiliation>IT</affiliation></author><author><keyname>Khatatneh</keyname><forenames>Khalaf</forenames><affiliation>IT</affiliation></author><author><keyname>Oqeili</keyname><forenames>Saleh</forenames><affiliation>IT</affiliation></author><author><keyname>Bertelle</keyname><forenames>Cyrille</forenames><affiliation>LIH</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author></authors><title>Automata-based adaptive behavior for economic modeling using game theory</title><categories>cs.MA cs.DM</categories><proxy>ccsd ccsd-00012927</proxy><journal-ref>Dans EPNADS'05 within ECCS'05 - Emergent Properties in Natural and
  Artificial Dynamical Systems, Paris : France (2005)</journal-ref><abstract>  In this paper, we deal with some specific domains of applications to game
theory. This is one of the major class of models in the new approaches of
modelling in the economic domain. For that, we use genetic automata which allow
to buid adaptive strategies for the players. We explain how the automata-based
formalism proposed - matrix representation of automata with multiplicities -
allows to define a semi-distance between the strategy behaviors. With that
tools, we are able to generate an automatic processus to compute emergent
systems of entities whose behaviors are represented by these genetic automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510090</id><created>2005-10-30</created><authors><author><keyname>Wu</keyname><forenames>Jyh-Yang</forenames></author><author><keyname>Chen</keyname><forenames>Sheng-Gwo</forenames></author><author><keyname>Chi</keyname><forenames>Mei-Hsiu</forenames></author></authors><title>A simple effective method for curvatures estimation on triangular meshes</title><categories>cs.CG</categories><abstract>  To definite and compute differential invariants, like curvatures, for
triangular meshes (or polyhedral surfaces) is a key problem in CAGD and the
computer vision. The Gaussian curvature and the mean curvature are determined
by the differential of the Gauss map of the underlying surface. The Gauss map
assigns to each point in the surface the unit normal vector of the tangent
plane to the surface at this point. We follow the ideas developed in Chen and
Wu \cite{Chen2}(2004) and Wu, Chen and Chi\cite{Wu}(2005) to describe a new and
simple approach to estimate the differential of the Gauss map and curvatures
from the viewpoint of the gradient and the centroid weights. This will give us
a much better estimation of curvatures than Taubin's algorithm \cite{Taubin}
(1995).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510091</id><created>2005-10-31</created><authors><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Semet</keyname><forenames>Yann</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>An efficient memetic, permutation-based evolutionary algorithm for
  real-world train timetabling</title><categories>cs.AI</categories><proxy>ccsd inria-00000538</proxy><abstract>  Train timetabling is a difficult and very tightly constrained combinatorial
problem that deals with the construction of train schedules. We focus on the
particular problem of local reconstruction of the schedule following a small
perturbation, seeking minimisation of the total accumulated delay by adapting
times of departure and arrival for each train and allocation of resources
(tracks, routing nodes, etc.). We describe a permutation-based evolutionary
algorithm that relies on a semi-greedy heuristic to gradually reconstruct the
schedule by inserting trains one after the other following the permutation.
This algorithm can be hybridised with ILOG commercial MIP programming tool
CPLEX in a coarse-grained manner: the evolutionary part is used to quickly
obtain a good but suboptimal solution and this intermediate solution is refined
using CPLEX. Experimental results are presented on a large real-world case
involving more than one million variables and 2 million constraints. Results
are surprisingly good as the evolutionary algorithm, alone or hybridised,
produces excellent solutions much faster than CPLEX alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510092</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510092</id><created>2005-10-31</created><updated>2006-10-04</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author></authors><title>Context Semantics, Linear Logic and Computational Complexity</title><categories>cs.LO cs.CC</categories><comments>22 pages</comments><acm-class>F.4.1</acm-class><abstract>  We show that context semantics can be fruitfully applied to the quantitative
analysis of proof normalization in linear logic. In particular, context
semantics lets us define the weight of a proof-net as a measure of its inherent
complexity: it is both an upper bound to normalization time (modulo a
polynomial overhead, independently on the reduction strategy) and a lower bound
to the number of steps to normal form (for certain reduction strategies).
Weights are then exploited in proving strong soundness theorems for various
subsystems of linear logic, namely elementary linear logic, soft linear logic
and light linear logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510093</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510093</id><created>2005-10-31</created><authors><author><keyname>Tentyukov</keyname><forenames>M.</forenames></author><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author><author><keyname>Staudenmaier</keyname><forenames>H. M.</forenames></author></authors><title>ParFORM: recent development</title><categories>cs.SC</categories><comments>5 pages, 6 Encapsulated postscript figures, LaTeX2e, uses espcrc2.sty
  (included). Talk given at ACAT05</comments><acm-class>I.1; I.1.2; I.1.4</acm-class><doi>10.1016/j.nima.2005.11.142</doi><abstract>  We report on the status of our project of parallelization of the symbolic
manipulation program FORM. We have now parallel versions of FORM running on
Cluster- or SMP-architectures. These versions can be used to run arbitrary FORM
programs in parallel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510094</id><created>2005-10-31</created><authors><author><keyname>de Vicente</keyname><forenames>Angel</forenames></author><author><keyname>Rodriguez</keyname><forenames>Nayra</forenames></author></authors><title>Big Science with a Small Budget: Non-Embarrassingly Parallel
  Applications in a Non-Dedicated Network of Workstations</title><categories>cs.DC astro-ph</categories><comments>4 pages; to appear in Proceedings of ADASS XV
  (http://www.adass.org:8080/Conferences/2005/Venue/)</comments><abstract>  Many astronomers and astrophysicists require large computing resources for
their research, which are usually obtained via dedicated (and expensive)
parallel machines. Depending on the type of the problem to be solved, an
alternative solution can be provided by creating dynamically a computer cluster
out of non-dedicated workstations using the Condor High Throughput Computing
System and the Master-Worker (MW) framework. As an example of this we show in
this paper how a radiative transfer application previously coded with MPI is
solved using this solution without the need for dedicated machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0510095</identifier>
 <datestamp>2008-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0510095</id><created>2005-10-31</created><updated>2008-02-08</updated><authors><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author><author><keyname>Tavildar</keyname><forenames>Saurabha</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Rate Region of the Quadratic Gaussian Two-Encoder Source-Coding Problem</title><categories>cs.IT math.IT</categories><comments>Contains additional results. To appear in IEEE Trans. Inf. Theory</comments><acm-class>H.1.1; E.4</acm-class><abstract>  We determine the rate region of the quadratic Gaussian two-encoder
source-coding problem. This rate region is achieved by a simple architecture
that separates the analog and digital aspects of the compression. Furthermore,
this architecture requires higher rates to send a Gaussian source than it does
to send any other source with the same covariance. Our techniques can also be
used to determine the sum rate of some generalizations of this classical
problem. Our approach involves coupling the problem to a quadratic Gaussian
``CEO problem.''
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511001</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511001</id><created>2005-10-31</created><updated>2006-06-21</updated><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Capacity with Causal and Non-Causal Side Information - A Unified View</title><categories>cs.IT math.IT</categories><comments>This work was presented in part at the IEEE Communication Theory
  Workshop, June 12-15, 2005 and at the Forty-third Annual Allerton Conference
  on Communication, Control, and Computing, Sept. 28-30, 2005</comments><abstract>  We identify the common underlying form of the capacity expression that is
applicable to both cases where causal or non-causal side information is made
available to the transmitter. Using this common form we find that for the
single user channel, the multiple access channel, the degraded broadcast
channel, and the degraded relay channel, the sum capacity with causal and
non-causal side information are identical when all the transmitter side
information is also made available to all the receivers. A genie-aided
outerbound is developed that states that when a genie provides $n$ bits of side
information to a receiver the resulting capacity improvement can not be more
than $n$ bits. Combining these two results we are able to bound the relative
capacity advantage of non-causal side information over causal side information
for both single user as well as various multiple user communication scenarios.
Applications of these capacity bounds are demonstrated through examples of
random access channels. Interestingly, the capacity results indicate that the
excessive MAC layer overheads common in present wireless systems may be avoided
through coding across multiple access blocks. It is also shown that even one
bit of side information at the transmitter can result in unbounded capacity
improvement. As a side, we obtain the sum capacity for a multiple access
channel when the side information available to the transmitter is causal and
possibly correlated to the side information available to the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511002</id><created>2005-10-31</created><authors><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Henneken</keyname><forenames>Edwin</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Demleitner</keyname><forenames>Markus</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Bibliographic Classification using the ADS Databases</title><categories>cs.IR cs.DL</categories><comments>Latex, 4 pages, 1 Figure. To be published in the Proceedings of the
  Conference &quot;Astronomical Data Analysis Software &amp; Systems XV&quot; held October
  2-5, 2005, in San Lorenzo de El Escorial, Spain</comments><abstract>  We discuss two techniques used to characterize bibliographic records based on
their similarity to and relationship with the contents of the NASA Astrophysics
Data System (ADS) databases. The first method has been used to classify input
text as being relevant to one or more subject areas based on an analysis of the
frequency distribution of its individual words. The second method has been used
to classify existing records as being relevant to one or more databases based
on the distribution of the papers citing them. Both techniques have proven to
be valuable tools in assigning new and existing bibliographic records to
different disciplines within the ADS databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511003</identifier>
 <datestamp>2007-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511003</id><created>2005-11-01</created><updated>2007-11-25</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Optimal Prefix Codes for Infinite Alphabets with Nonlinear Costs</title><categories>cs.IT cs.DS math.IT</categories><comments>14 pages, 6 figures, accepted to IEEE Trans. Inform. Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  Let $P = \{p(i)\}$ be a measure of strictly positive probabilities on the set
of nonnegative integers. Although the countable number of inputs prevents usage
of the Huffman algorithm, there are nontrivial $P$ for which known methods find
a source code that is optimal in the sense of minimizing expected codeword
length. For some applications, however, a source code should instead minimize
one of a family of nonlinear objective functions, $\beta$-exponential means,
those of the form $\log_a \sum_i p(i) a^{n(i)}$, where $n(i)$ is the length of
the $i$th codeword and $a$ is a positive constant. Applications of such
minimizations include a novel problem of maximizing the chance of message
receipt in single-shot communications ($a&lt;1$) and a previously known problem of
minimizing the chance of buffer overflow in a queueing system ($a&gt;1$). This
paper introduces methods for finding codes optimal for such exponential means.
One method applies to geometric distributions, while another applies to
distributions with lighter tails. The latter algorithm is applied to Poisson
distributions and both are extended to alphabetic codes, as well as to
minimizing maximum pointwise redundancy. The aforementioned application of
minimizing the chance of buffer overflow is also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511004</id><created>2005-11-01</created><authors><author><keyname>Eiben</keyname><forenames>Aguston E.</forenames><affiliation>VU</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>FRACTALES</affiliation></author></authors><title>Evolutionary Computing</title><categories>cs.AI</categories><proxy>ccsd inria-00000542</proxy><abstract>  Evolutionary computing (EC) is an exciting development in Computer Science.
It amounts to building, applying and studying algorithms based on the Darwinian
principles of natural selection. In this paper we briefly introduce the main
concepts behind evolutionary computing. We present the main components all
evolutionary algorithms (EA), sketch the differences between different types of
EAs and survey application areas ranging from optimization, modeling and
simulation to entertainment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511005</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511005</id><created>2005-11-01</created><updated>2006-08-23</updated><authors><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>The egalitarian effect of search engines</title><categories>cs.CY cs.IR physics.soc-ph</categories><comments>9 pages, 8 figures, 2 appendices. The final version of this e-print
  has been published on the Proc. Natl. Acad. Sci. USA 103(34), 12684-12689
  (2006), http://www.pnas.org/cgi/content/abstract/103/34/12684</comments><acm-class>H.3.3; H.3.4; H.3.5; H.5.4; K.4.m</acm-class><doi>10.1073/pnas.0605525103</doi><abstract>  Search engines have become key media for our scientific, economic, and social
activities by enabling people to access information on the Web in spite of its
size and complexity. On the down side, search engines bias the traffic of users
according to their page-ranking strategies, and some have argued that they
create a vicious cycle that amplifies the dominance of established and already
popular sites. We show that, contrary to these prior claims and our own
intuition, the use of search engines actually has an egalitarian effect. We
reconcile theoretical arguments with empirical evidence showing that the
combination of retrieval by search engines and search behavior by users
mitigates the attraction of popular pages, directing more traffic toward less
popular sites, even in comparison to what would be expected from users randomly
surfing the Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511006</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511006</id><created>2005-11-01</created><updated>2008-03-04</updated><authors><author><keyname>Goubault-Larrecq</keyname><forenames>Jean</forenames></author><author><keyname>Lasota</keyname><forenames>Slawomir</forenames></author><author><keyname>Nowak</keyname><forenames>David</forenames></author></authors><title>Logical Relations for Monadic Types</title><categories>cs.LO</categories><comments>83 pages</comments><journal-ref>Mathematical Structures in Computer Science, 18(6):1169-1217,
  December 2008</journal-ref><doi>10.1017/S0960129508007172</doi><abstract>  Logical relations and their generalizations are a fundamental tool in proving
properties of lambda-calculi, e.g., yielding sound principles for observational
equivalence. We propose a natural notion of logical relations able to deal with
the monadic types of Moggi's computational lambda-calculus. The treatment is
categorical, and is based on notions of subsconing, mono factorization systems,
and monad morphisms. Our approach has a number of interesting applications,
including cases for lambda-calculi with non-determinism (where being in logical
relation means being bisimilar), dynamic name creation, and probabilistic
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511007</identifier>
 <datestamp>2008-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511007</id><created>2005-11-02</created><updated>2008-04-16</updated><authors><author><keyname>Alvarez-Hamelin</keyname><forenames>Jos&#xe9; Ignacio</forenames><affiliation>LPT</affiliation></author><author><keyname>Dall'Asta</keyname><forenames>Luca</forenames><affiliation>LPT</affiliation></author><author><keyname>Barrat</keyname><forenames>Alain</forenames><affiliation>LPT</affiliation></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>K-core decomposition of Internet graphs: hierarchies, self-similarity
  and measurement biases</title><categories>cs.NI cond-mat.stat-mech</categories><proxy>ccsd ccsd-00012974</proxy><journal-ref>Networks and Heterogeneous Media 3 (2008) 371</journal-ref><abstract>  We consider the $k$-core decomposition of network models and Internet graphs
at the autonomous system (AS) level. The $k$-core analysis allows to
characterize networks beyond the degree distribution and uncover structural
properties and hierarchies due to the specific architecture of the system. We
compare the $k$-core structure obtained for AS graphs with those of several
network models and discuss the differences and similarities with the real
Internet architecture. The presence of biases and the incompleteness of the
real maps are discussed and their effect on the $k$-core analysis is assessed
with numerical experiments simulating biased exploration on a wide range of
network models. We find that the $k$-core analysis provides an interesting
characterization of the fluctuations and incompleteness of maps as well as
information helping to discriminate the original underlying structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511008</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511008</id><created>2005-11-02</created><authors><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author></authors><title>Analysis of Stochastic Service Guarantees in Communication Networks: A
  Basic Calculus</title><categories>cs.PF cs.IT cs.NI math.IT</categories><acm-class>C.4; G.3</acm-class><abstract>  A basic calculus is presented for stochastic service guarantee analysis in
communication networks. Central to the calculus are two definitions,
maximum-(virtual)-backlog-centric (m.b.c) stochastic arrival curve and
stochastic service curve, which respectively generalize arrival curve and
service curve in the deterministic network calculus framework. With m.b.c
stochastic arrival curve and stochastic service curve, various basic results
are derived under the (min, +) algebra for the general case analysis, which are
crucial to the development of stochastic network calculus. These results
include (i) superposition of flows, (ii) concatenation of servers, (iii) output
characterization, (iv) per-flow service under aggregation, and (v) stochastic
backlog and delay guarantees. In addition, to perform independent case
analysis, stochastic strict server is defined, which uses an ideal service
process and an impairment process to characterize a server. The concept of
stochastic strict server not only allows us to improve the basic results (i) --
(v) under the independent case, but also provides a convenient way to find the
stochastic service curve of a serve. Moreover, an approach is introduced to
find the m.b.c stochastic arrival curve of a flow and the stochastic service
curve of a server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511009</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511009</id><created>2005-11-02</created><authors><author><keyname>Kontoyiannis</keyname><forenames>Ioannis</forenames><affiliation>Athens U of Econ &amp; Business</affiliation></author><author><keyname>Zamir</keyname><forenames>Rami</forenames><affiliation>Tel-Aviv University</affiliation></author></authors><title>Mismatched codebooks and the role of entropy-coding in lossy data
  compression</title><categories>cs.IT math.IT math.PR</categories><comments>35 pages, 37 references, no figures. Submitted to IEEE Transactions
  on Information Theory</comments><abstract>  We introduce a universal quantization scheme based on random coding, and we
analyze its performance. This scheme consists of a source-independent random
codebook (typically_mismatched_ to the source distribution), followed by
optimal entropy-coding that is_matched_ to the quantized codeword distribution.
A single-letter formula is derived for the rate achieved by this scheme at a
given distortion, in the limit of large codebook dimension. The rate reduction
due to entropy-coding is quantified, and it is shown that it can be arbitrarily
large. In the special case of &quot;almost uniform&quot; codebooks (e.g., an i.i.d.
Gaussian codebook with large variance) and difference distortion measures, a
novel connection is drawn between the compression achieved by the present
scheme and the performance of &quot;universal&quot; entropy-coded dithered lattice
quantizers. This connection generalizes the &quot;half-a-bit&quot; bound on the
redundancy of dithered lattice quantizers. Moreover, it demonstrates a strong
notion of universality where a single &quot;almost uniform&quot; codebook is near-optimal
for_any_ source and_any_ difference distortion measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511010</id><created>2005-11-02</created><authors><author><keyname>Kiyanclar</keyname><forenames>Nadir</forenames></author></authors><title>A Survey of Virtualization Techniques Focusing on Secure On-Demand
  Cluster Computing</title><categories>cs.OS</categories><acm-class>D.4.m</acm-class><abstract>  Virtualization, a technique once used to multiplex the resources of
high-priced mainframe hardware, is seeing a resurgence in applicability with
the increasing computing power of commodity computers. By inserting a layer of
software between the machine and traditional operating systems, this technology
allows access to a shared computing medium in a manner that is secure,
resource-controlled, and efficient. These properties are attractive in the
field of on-demand computing, where the fine-grained subdivision of resources
provided by virtualized systems allows potentially higher utilization of
computing resources.
  It this work, we survey a number of virtual machine systems with the goal of
finding an appropriate candidate to serve as the basis for the On-Demand Secure
Cluster Computing project at the National Center for Supercomputing
Applications. Contenders are reviewed on a number of desirable properties
including portability and security. We conclude with a comparison and
justification of our choice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511011</id><created>2005-11-02</created><authors><author><keyname>Link</keyname><forenames>Hamilton</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Lane</keyname><forenames>Terran</forenames></author><author><keyname>LaViolette</keyname><forenames>Randall A.</forenames></author></authors><title>The Impact of Social Networks on Multi-Agent Recommender Systems</title><categories>cs.LG cs.CC cs.MA</categories><comments>12 pages, 4 figures. Published in the Proceedings of the Workshop on
  Cooperative Multi-Agent Learning (ECML/PKDD '05). Resubmitted to fix
  citations and metadata</comments><acm-class>I.2.6; I.2.11</acm-class><abstract>  Awerbuch et al.'s approach to distributed recommender systems (DRSs) is to
have agents sample products at random while randomly querying one another for
the best item they have found; we improve upon this by adding a communication
network. Agents can only communicate with their immediate neighbors in the
network, but neighboring agents may or may not represent users with common
interests. We define two network structures: in the ``mailing-list model,''
agents representing similar users form cliques, while in the ``word-of-mouth
model'' the agents are distributed randomly in a scale-free network (SFN). In
both models, agents tell their neighbors about satisfactory products as they
are found. In the word-of-mouth model, knowledge of items propagates only
through interested agents, and the SFN parameters affect the system's
performance. We include a summary of our new results on the character and
parameters of random subgraphs of SFNs, in particular SFNs with power-law
degree distributions down to minimum degree 1. These networks are not as
resilient as Cohen et al. originally suggested. In the case of the widely-cited
``Internet resilience'' result, high failure rates actually lead to the
orphaning of half of the surviving nodes after 60% of the network has failed
and the complete disintegration of the network at 90%. We show that given an
appropriate network, the communication network reduces the number of sampled
items, the number of messages sent, and the amount of ``spam.'' We conclude
that in many cases DRSs will be useful for sharing information in a multi-agent
learning system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511012</id><created>2005-11-02</created><authors><author><keyname>Link</keyname><forenames>Hamilton</forenames></author><author><keyname>LaViolette</keyname><forenames>Randall A.</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Lane</keyname><forenames>Terran</forenames></author></authors><title>Parameters Affecting the Resilience of Scale-Free Networks to Random
  Failures</title><categories>cs.NI cs.AR cs.MA</categories><comments>12 pages, 7 figures. Submitting to Phys. Rev. Lett</comments><acm-class>C.2.1; C.4</acm-class><abstract>  It is commonly believed that scale-free networks are robust to massive
numbers of random node deletions. For example, Cohen et al. study scale-free
networks including some which approximate the measured degree distribution of
the Internet. Their results suggest that if each node in this network failed
independently with probability 0.99, the remaining network would continue to
have a giant component. In this paper, we show that a large and important
subclass of scale-free networks are not robust to massive numbers of random
node deletions for practical purposes. In particular, we study finite
scale-free networks which have minimum node degree of 1 and a power-law degree
distribution beginning with nodes of degree 1 (power-law networks). We show
that, in a power-law network approximating the Internet's reported
distribution, when the probability of deletion of each node is 0.5 only about
25% of the surviving nodes in the network remain connected in a giant
component, and the giant component does not persist beyond a critical failure
rate of 0.9. The new result is partially due to improved analytical
accommodation of the large number of degree-0 nodes that result after node
deletions. Our results apply to finite power-law networks with a wide range of
power-law exponents, including Internet-like networks. We give both analytical
and empirical evidence that such networks are not generally robust to massive
random node deletions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511013</id><created>2005-11-02</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author><author><keyname>Xu</keyname><forenames>Xiaofei</forenames></author><author><keyname>Deng</keyname><forenames>Shengchun</forenames></author></authors><title>K-ANMI: A Mutual Information Based Clustering Algorithm for Categorical
  Data</title><categories>cs.AI cs.DB</categories><comments>18 pages</comments><report-no>Tr-2004-03</report-no><abstract>  Clustering categorical data is an integral part of data mining and has
attracted much attention recently. In this paper, we present k-ANMI, a new
efficient algorithm for clustering categorical data. The k-ANMI algorithm works
in a way that is similar to the popular k-means algorithm, and the goodness of
clustering in each step is evaluated using a mutual information based criterion
(namely, Average Normalized Mutual Information-ANMI) borrowed from cluster
ensemble. Experimental results on real datasets show that k-ANMI algorithm is
competitive with those state-of-art categorical data clustering algorithms with
respect to clustering accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511014</id><created>2005-11-03</created><authors><author><keyname>Seidl</keyname><forenames>Helmut</forenames></author><author><keyname>Verma</keyname><forenames>Kumar Neeraj</forenames></author></authors><title>Flat and One-Variable Clauses: Complexity of Verifying Cryptographic
  Protocols with Single Blind Copying</title><categories>cs.LO cs.CR</categories><comments>Long version of paper presented at LPAR 2004</comments><abstract>  Cryptographic protocols with single blind copying were defined and modeled by
Comon and Cortier using the new class $\mathcal C$ of first order clauses. They
showed its satisfiability problem to be in 3-DEXPTIME. We improve this result
by showing that satisfiability for this class is NEXPTIME-complete, using new
resolution techniques. We show satisfiability to be DEXPTIME-complete if
clauses are Horn, which is what is required for modeling cryptographic
protocols. While translation to Horn clauses only gives a DEXPTIME upper bound
for the secrecy problem for these protocols, we further show that this secrecy
problem is actually DEXPTIME-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511015</id><created>2005-11-03</created><updated>2007-01-12</updated><authors><author><keyname>Prashant</keyname></author></authors><title>Towards a Hierarchical Model of Consciousness, Intelligence, Mind and
  Body</title><categories>cs.AI</categories><comments>12 pages, 2 figures</comments><abstract>  This article is taken out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511016</id><created>2005-11-03</created><authors><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>How to make the top ten: Approximating PageRank from in-degree</title><categories>cs.IR physics.soc-ph</categories><comments>8 pages, 7 figures, 2 tables</comments><acm-class>H.3.3; H.3.4; H.3.5; K.4.m</acm-class><abstract>  PageRank has become a key element in the success of search engines, allowing
to rank the most important hits in the top screen of results. One key aspect
that distinguishes PageRank from other prestige measures such as in-degree is
its global nature. From the information provider perspective, this makes it
difficult or impossible to predict how their pages will be ranked. Consequently
a market has emerged for the optimization of search engine results. Here we
study the accuracy with which PageRank can be approximated by in-degree, a
local measure made freely available by search engines. Theoretical and
empirical analyses lead to conclude that given the weak degree correlations in
the Web link graph, the approximation can be relatively accurate, giving
service and information providers an effective new marketing tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511017</id><created>2005-11-03</created><authors><author><keyname>Gutoski</keyname><forenames>Gus</forenames></author></authors><title>Short Quantum Games</title><categories>cs.CC quant-ph</categories><comments>MSc thesis, 79 pages single-spaced</comments><abstract>  In this thesis we introduce quantum refereed games, which are quantum
interactive proof systems with two competing provers. We focus on a restriction
of this model that we call &quot;short quantum games&quot; and we prove an upper bound
and a lower bound on the expressive power of these games.
  For the lower bound, we prove that every language having an ordinary quantum
interactive proof system also has a short quantum game. An important part of
this proof is the establishment of a quantum measurement that reliably
distinguishes between quantum states chosen from disjoint convex sets.
  For the upper bound, we show that certain types of quantum refereed games,
including short quantum games, are decidable in deterministic exponential time
by supplying a separation oracle for use with the ellipsoid method for convex
feasibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511018</id><created>2005-11-03</created><updated>2007-01-12</updated><authors><author><keyname>Prashant</keyname></author></authors><title>From General Systems to Soft Systems to Soft Computing: Applications for
  Large and Complex Real World Systems</title><categories>cs.SE</categories><comments>9 pages</comments><abstract>  This is article is taken out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511019</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511019</id><created>2005-11-03</created><authors><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>A Counterexample to Cover's 2P Conjecture on Gaussian Feedback Capacity</title><categories>cs.IT math.IT</categories><comments>2 pages, submitted to IEEE Transactions on Information Theory</comments><acm-class>H.1.1; E.4</acm-class><abstract>  We provide a counterexample to Cover's conjecture that the feedback capacity
$C_\textrm{FB}$ of an additive Gaussian noise channel under power constraint
$P$ be no greater than the nonfeedback capacity $C$ of the same channel under
power constraint $2P$, i.e., $C_\textrm{FB}(P) \le C(2P)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511020</id><created>2005-11-03</created><updated>2006-01-16</updated><authors><author><keyname>P&#x142;aneta</keyname><forenames>David S.</forenames></author></authors><title>Pbit and other list sorting algorithms</title><categories>cs.DS</categories><comments>25 pages, 4 tables</comments><report-no>TR2006-2013</report-no><acm-class>F.2.2</acm-class><journal-ref>Cornell University Computing and Information Science Technical
  Reports, 2006</journal-ref><abstract>  Pbit, besides its simplicity, is definitely the fastest list sorting
algorithm. It considerably surpasses all already known methods. Among many
advantages, it is stable, linear and be made to run in place. I will compare
Pbit with algorithm described by Donald E. Knuth in the third volume of ''The
Art of Computer Programming'' and other (QuickerSort, MergeSort) list sorting
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511021</id><created>2005-11-04</created><authors><author><keyname>Kannan</keyname><forenames>Ravi</forenames></author><author><keyname>Theobald</keyname><forenames>Thorsten</forenames></author></authors><title>Games of fixed rank: A hierarchy of bimatrix games</title><categories>cs.GT math.CO</categories><comments>13 pages</comments><abstract>  We propose a new hierarchical approach to understand the complexity of the
open problem of computing a Nash equilibrium in a bimatrix game. Specifically,
we investigate a hierarchy of bimatrix games $(A,B)$ which results from
restricting the rank of the matrix $A+B$ to be of fixed rank at most $k$. For
every fixed $k$, this class strictly generalizes the class of zero-sum games,
but is a very special case of general bimatrix games. We show that even for
$k=1$ the set of Nash equilibria of these games can consist of an arbitrarily
large number of connected components. While the question of exact polynomial
time algorithms to find a Nash equilibrium remains open for games of fixed
rank, we can provide polynomial time algorithms for finding an
$\epsilon$-approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511022</id><created>2005-11-04</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Does a Plane Imitate a Bird? Does Computer Vision Have to Follow
  Biological Paradigms?</title><categories>cs.NE</categories><comments>Proceedings of the 1st International Symposium on Brain, Vision, and
  Artificial Intelligence, 19-21 October 2005, Naples, Italy</comments><journal-ref>LNCS, vol. 3704, pp. 108-115, 2005, Springer Verlag Berlin
  Heidelberg 2005</journal-ref><abstract>  We posit a new paradigm for image information processing. For the last 25
years, this task was usually approached in the frame of Treisman's two-stage
paradigm [1]. The latter supposes an unsupervised, bottom-up directed process
of preliminary information pieces gathering at the lower processing stages and
a supervised, top-down directed process of information pieces binding and
grouping at the higher stages. It is acknowledged that these sub-processes
interact and intervene between them in a tricky and a complicated manner.
Notwithstanding the prevalence of this paradigm in biological and computer
vision, we nevertheless propose to replace it with a new one, which we would
like to designate as a two-part paradigm. In it, information contained in an
image is initially extracted in an independent top-down manner by one part of
the system, and then it is examined and interpreted by another, separate system
part. We argue that the new paradigm seems to be more plausible than its
forerunner. We provide evidence from human attention vision studies and
insights of Kolmogorov's complexity theory to support our arguments. We also
provide some reasons in favor of separate image interpretation issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511023</identifier>
 <datestamp>2012-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511023</id><created>2005-11-04</created><updated>2006-04-11</updated><authors><author><keyname>Baier</keyname><forenames>Christel</forenames></author><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames></author><author><keyname>Schnoebelen</keyname><forenames>Philippe</forenames></author></authors><title>Verifying nondeterministic probabilistic channel systems against
  $\omega$-regular linear-time properties</title><categories>cs.LO</categories><comments>39 pages</comments><journal-ref>ACM Trans. Computational Logic 9(1), 2007</journal-ref><doi>10.1145/1297658.1297663</doi><abstract>  Lossy channel systems (LCSs) are systems of finite state automata that
communicate via unreliable unbounded fifo channels. In order to circumvent the
undecidability of model checking for nondeterministic
  LCSs, probabilistic models have been introduced, where it can be decided
whether a linear-time property holds almost surely. However, such fully
probabilistic systems are not a faithful model of nondeterministic protocols.
  We study a hybrid model for LCSs where losses of messages are seen as faults
occurring with some given probability, and where the internal behavior of the
system remains nondeterministic. Thus the semantics is in terms of
infinite-state Markov decision processes. The purpose of this article is to
discuss the decidability of linear-time properties formalized by formulas of
linear temporal logic (LTL). Our focus is on the qualitative setting where one
asks, e.g., whether a LTL-formula holds almost surely or with zero probability
(in case the formula describes the bad behaviors). Surprisingly, it turns out
that -- in contrast to finite-state Markov decision processes -- the
satisfaction relation for LTL formulas depends on the chosen type of schedulers
that resolve the nondeterminism. While all variants of the qualitative LTL
model checking problem for the full class of history-dependent schedulers are
undecidable, the same questions for finite-memory scheduler can be solved
algorithmically. However, the restriction to reachability properties and
special kinds of recurrent reachability properties yields decidable
verification problems for the full class of schedulers, which -- for this
restricted class of properties -- are as powerful as finite-memory schedulers,
or even a subclass of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511024</id><created>2005-11-04</created><authors><author><keyname>Paul</keyname><forenames>Bourgade</forenames></author><author><keyname>Olivier</keyname><forenames>Croissant</forenames></author></authors><title>Heat kernel expansion for a family of stochastic volatility models :
  delta-geometry</title><categories>cs.CE</categories><abstract>  In this paper, we study a family of stochastic volatility processes; this
family features a mean reversion term for the volatility and a double CEV-like
exponent that generalizes SABR and Heston's models. We derive approximated
closed form formulas for the digital prices, the local and implied
volatilities. Our formulas are efficient for small maturities.
  Our method is based on differential geometry, especially small time
diffusions on riemanian spaces. This geometrical point of view can be extended
to other processes, and is very accurate to produce variate smiles for small
maturities and small moneyness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511025</id><created>2005-11-04</created><authors><author><keyname>Cheney</keyname><forenames>James</forenames></author></authors><title>Logic Column 14: Nominal Logic and Abstract Syntax</title><categories>cs.LO</categories><comments>24 pages</comments><acm-class>F.4.1; F.3.1</acm-class><journal-ref>SIGACT News 36 (4), pp. 47-69, 2005</journal-ref><abstract>  Formalizing syntactic proofs of properties of logics, programming languages,
security protocols, and other formal systems is a significant challenge, in
large part because of the obligation to handle name-binding correctly. We
present an approach called nominal abstract syntax that has attracted
considerable interest since its introduction approximately six years ago. After
an overview of other approaches, we describe nominal abstract syntax and
nominal logic, a logic for reasoning about nominal abstract syntax. We also
discuss applications of nominal techniques to programming, automated reasoning,
and identify some future directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511026</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511026</id><created>2005-11-05</created><authors><author><keyname>Mahajan</keyname><forenames>Aditya</forenames></author><author><keyname>Teneketzis</keyname><forenames>Demosthenis</forenames></author></authors><title>A Decision Theoretic Framework for Real-Time Communication</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure: Forty Third Allerton Conference of Control
  Communication and Computing</comments><abstract>  We consider a communication system in which the outputs of a Markov source
are encoded and decoded in \emph{real-time} by a finite memory receiver, and
the distortion measure does not tolerate delays. The objective is to choose
designs, i.e. real-time encoding, decoding and memory update strategies that
minimize a total expected distortion measure. This is a dynamic team problem
with non-classical information structure [Witsenhausen:1971]. We use the
structural results of [Teneketzis:2004] to develop a sequential decomposition
for the finite and infinite horizon problems. Thus, we obtain a systematic
methodology for the determination of jointly optimal encoding decoding and
memory update strategies for real-time point-to-point communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511027</id><created>2005-11-07</created><authors><author><keyname>Luttrell</keyname><forenames>Stephen</forenames></author></authors><title>Discrete Network Dynamics. Part 1: Operator Theory</title><categories>cs.NE</categories><comments>39 pages, 5 figures</comments><acm-class>F.1.2; G.2.1; G.2.2</acm-class><abstract>  An operator algebra implementation of Markov chain Monte Carlo algorithms for
simulating Markov random fields is proposed. It allows the dynamics of networks
whose nodes have discrete state spaces to be specified by the action of an
update operator that is composed of creation and annihilation operators. This
formulation of discrete network dynamics has properties that are similar to
those of a quantum field theory of bosons, which allows reuse of many
conceptual and theoretical structures from QFT. The equilibrium behaviour of
one of these generalised MRFs and of the adaptive cluster expansion network
(ACEnet) are shown to be equivalent, which provides a way of unifying these two
theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511028</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511028</id><created>2005-11-06</created><updated>2006-08-31</updated><authors><author><keyname>Shin</keyname><forenames>Hyundong</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>MIMO Diversity in the Presence of Double Scattering</title><categories>cs.IT math.IT</categories><comments>Revised for publication in the IEEE Transactions on Information
  Theory</comments><abstract>  The potential benefits of multiple-antenna systems may be limited by two
types of channel degradations rank deficiency and spatial fading correlation of
the channel. In this paper, we assess the effects of these degradations on the
diversity performance of multiple-input multiple-output (MIMO) systems, with an
emphasis on orthogonal space-time block codes, in terms of the symbol error
probability, the effective fading figure (EFF), and the capacity at low
signal-to-noise ratio (SNR). In particular, we consider a general family of
MIMO channels known as double-scattering channels, which encompasses a variety
of propagation environments from independent and identically distributed
Rayleigh to degenerate keyhole or pinhole cases by embracing both
rank-deficient and spatial correlation effects. It is shown that a MIMO system
with $n_T$ transmit and $n_R$ receive antennas achieves the diversity of order
$\frac{\n_T n_S n_R}{\max(n_T,n_S,n_R)}$ in a double-scattering channel with
$n_S$ effective scatterers. We also quantify the combined effect of the spatial
correlation and the lack of scattering richness on the EFF and the low-SNR
capacity in terms of the correlation figures of transmit, receive, and
scatterer correlation matrices. We further show the monotonicity properties of
these performance measures with respect to the strength of spatial correlation,
characterized by the eigenvalue majorization relations of the correlation
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511029</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511029</id><created>2005-11-06</created><authors><author><keyname>Perera</keyname><forenames>Rasika R</forenames></author><author><keyname>Pollock</keyname><forenames>Tony S</forenames></author><author><keyname>Abhayapala</keyname><forenames>Thushara D</forenames></author></authors><title>Non-coherent Rayleigh fading MIMO channels: Capacity Supremum</title><categories>cs.IT math.IT</categories><comments>08 pages, 5 figures, IEEE Transactions on Information Theory</comments><abstract>  This paper investigates the limits of information transfer over a fast
Rayleigh fading MIMO channel, where neither the transmitter nor the receiver
has the knowledge of the channel state information (CSI) except the fading
statistics. We develop a scalar channel model due to absence of the phase
information in non-coherent Rayleigh fading and derive a capacity supremum with
the number of receive antennas at any signal to noise ratio (SNR) using
Lagrange optimisation. Also, we conceptualise the discrete nature of the
optimal input distribution by posing the optimisation on the channel mutual
information for $N$ discrete inputs. Furthermore, we derive an expression for
the asymptotic capacity when the input power is large, and compare with the
existing capacity results when the receiver is equipped with a large number of
antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511030</id><created>2005-11-07</created><updated>2006-03-13</updated><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Rafiey</keyname><forenames>A.</forenames></author><author><keyname>Szeider</keyname><forenames>S.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>The Linear Arrangement Problem Parameterized Above Guaranteed Value</title><categories>cs.DS cs.CC</categories><acm-class>F.2.2</acm-class><abstract>  A linear arrangement (LA) is an assignment of distinct integers to the
vertices of a graph. The cost of an LA is the sum of lengths of the edges of
the graph, where the length of an edge is defined as the absolute value of the
difference of the integers assigned to its ends. For many application one hopes
to find an LA with small cost. However, it is a classical NP-complete problem
to decide whether a given graph $G$ admits an LA of cost bounded by a given
integer. Since every edge of $G$ contributes at least one to the cost of any
LA, the problem becomes trivially fixed-parameter tractable (FPT) if
parameterized by the upper bound of the cost. Fernau asked whether the problem
remains FPT if parameterized by the upper bound of the cost minus the number of
edges of the given graph; thus whether the problem is FPT ``parameterized above
guaranteed value.'' We answer this question positively by deriving an algorithm
which decides in time $O(m+n+5.88^k)$ whether a given graph with $m$ edges and
$n$ vertices admits an LA of cost at most $m+k$ (the algorithm computes such an
LA if it exists). Our algorithm is based on a procedure which generates a
problem kernel of linear size in linear time for a connected graph $G$. We also
prove that more general parameterized LA problems stated by Serna and Thilikos
are not FPT, unless P=NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511031</id><created>2005-11-07</created><updated>2007-01-11</updated><authors><author><keyname>Prashant</keyname></author></authors><title>Internet Protocol Black Holes: A E-Security Threat</title><categories>cs.NI</categories><abstract>  The paper is taken out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511032</id><created>2005-11-08</created><authors><author><keyname>Yee</keyname><forenames>Yang Li Hector</forenames><affiliation>Cornell University</affiliation></author></authors><title>Spatiotemporal sensistivity and visual attention for efficient rendering
  of dynamic environments</title><categories>cs.GR cs.CV</categories><journal-ref>ACM Transactions on Graphics, 20(1), January 2001</journal-ref><abstract>  We present a method to accelerate global illumination computation in dynamic
environments by taking advantage of limitations of the human visual system. A
model of visual attention is used to locate regions of interest in a scene and
to modulate spatiotemporal sensitivity. The method is applied in the form of a
spatiotemporal error tolerance map. Perceptual acceleration combined with good
sampling protocols provide a global illumination solution feasible for use in
animation. Results indicate an order of magnitude improvement in computational
speed. The method is adaptable and can also be used in image-based rendering,
geometry level of detail selection, realistic image synthesis, video telephony
and video compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511033</id><created>2005-11-08</created><authors><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Fast (Multi-)Evaluation of Linearly Recurrent Sequences: Improvements
  and Applications</title><categories>cs.SC</categories><abstract>  For a linearly recurrent vector sequence P[n+1] = A(n) * P[n], consider the
problem of calculating either the n-th term P[n] or L&lt;=n arbitrary terms
P[n_1],...,P[n_L], both for the case of constant coefficients A(n)=A and for a
matrix A(n) with entries polynomial in n. We improve and extend known
algorithms for this problem and present new applications for it. Specifically
it turns out that for instance * any family (p_n) of classical orthogonal
polynomials admits evaluation at given x within O(n^{1/2} log n) operations
INDEPENDENT of the family (p_n) under consideration. * For any L indices
n_1,...,n_L &lt;= n, the values p_{n_i}(x) can be calculated simultaneously using
O(n^{1/2} log n + L log(n/L)) arithmetic operations; again this running time
bound holds uniformly. * Every hypergeometric (or, more generally, holonomic)
function admits approximate evaluation up to absolute error e&gt;0 within
O((log(1/e)^{1/2} loglog(1/e)) -- as opposed to O(log(1/e)) -- arithmetic
steps. * Given m and a polynomial p of degree d over a field of characteristic
zero, the coefficient of p^m to term X^n can be computed within O(d^2
M(n^{1/2})) steps where M(n) denotes the cost of multiplying two degree-n
polynomials. * The same time bound holds for the joint calculation of any
L&lt;=n^{1/2} desired coefficients of p^m to terms X^{n_i}, n_1,...,n_L &lt;= n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511034</id><created>2005-11-08</created><authors><author><keyname>Bulygin</keyname><forenames>Stanislav</forenames></author></authors><title>Generalized Hermitian Codes over GF(2^r)</title><categories>cs.DM</categories><abstract>  In this paper we studied generalization of Hermitian function field proposed
by A.Garcia and H.Stichtenoth. We calculated a Weierstrass semigroup of the
point at infinity for the case q=2, r&gt;=3. It turned out that unlike Hermitian
case, we have already three generators for the semigroup. We then applied this
result to codes, constructed on generalized Hermitian function fields. Further,
we applied results of C.Kirfel and R.Pellikaan to estimating a Feng-Rao
designed distance for GH-codes, which improved on Goppa designed distance.
Next, we studied the question of codes dual to GH-codes. We identified that the
duals are also GH-codes and gave an explicit formula. We concluded with some
computational results. In particular, a new record-giving [32,16,&gt;=12]-code
over GF(8) was presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511035</identifier>
 <datestamp>2008-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511035</id><created>2005-11-08</created><updated>2006-02-14</updated><authors><author><keyname>Serrano</keyname><forenames>M. Angeles</forenames></author><author><keyname>Maguitman</keyname><forenames>Ana</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>Decoding the structure of the WWW: facts versus sampling biases</title><categories>cs.NI cond-mat.dis-nn physics.soc-ph</categories><comments>10 pages 19 figures. Values in Table 2 and Figure 1 corrected. Figure
  7 updated. Minor changes in the text</comments><acm-class>H.4.m; G.3</acm-class><journal-ref>ACM Transactions on the Web (TWEB) 1, 10 (2007)</journal-ref><abstract>  The understanding of the immense and intricate topological structure of the
World Wide Web (WWW) is a major scientific and technological challenge. This
has been tackled recently by characterizing the properties of its
representative graphs in which vertices and directed edges are identified with
web-pages and hyperlinks, respectively. Data gathered in large scale crawls
have been analyzed by several groups resulting in a general picture of the WWW
that encompasses many of the complex properties typical of rapidly evolving
networks. In this paper, we report a detailed statistical analysis of the
topological properties of four different WWW graphs obtained with different
crawlers. We find that, despite the very large size of the samples, the
statistical measures characterizing these graphs differ quantitatively, and in
some cases qualitatively, depending on the domain analyzed and the crawl used
for gathering the data. This spurs the issue of the presence of sampling biases
and structural differences of Web crawls that might induce properties not
representative of the actual global underlying graph. In order to provide a
more accurate characterization of the Web graph and identify observables which
are clearly discriminating with respect to the sampling process, we study the
behavior of degree-degree correlation functions and the statistics of
reciprocal connections. The latter appears to enclose the relevant correlations
of the WWW graph and carry most of the topological information of theWeb. The
analysis of this quantity is also of major interest in relation to the
navigability and searchability of the Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511036</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511036</id><created>2005-11-08</created><authors><author><keyname>Chen</keyname><forenames>Mei</forenames></author><author><keyname>Li</keyname><forenames>Teng</forenames></author><author><keyname>Collins</keyname><forenames>Oliver M.</forenames></author></authors><title>A Capacity Achieving and Low Complexity Multilevel Coding Scheme for ISI
  Channels</title><categories>cs.IT math.IT</categories><comments>10 pages, 7 figures, 43rd Anual Allerton Conference on Communication,
  Control and Computing</comments><abstract>  We propose a computationally efficient multilevel coding scheme to achieve
the capacity of an ISI channel using layers of binary inputs. The transmitter
employs multilevel coding with linear mapping. The receiver uses multistage
decoding where each stage performs a separate linear minimum mean square error
(LMMSE) equalization and decoding. The optimality of the scheme is due to the
fact that the LMMSE equalizer is information lossless in an ISI channel when
signal to noise ratio is sufficiently low. The computational complexity is low
and scales linearly with the length of the channel impulse response and the
number of layers. The decoder at each layer sees an equivalent AWGN channel,
which makes coding straightforward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511037</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511037</id><created>2005-11-08</created><authors><author><keyname>Chen</keyname><forenames>Mei</forenames></author><author><keyname>Collins</keyname><forenames>Oliver M.</forenames></author></authors><title>Trellis Pruning for Peak-to-Average Power Ratio Reduction</title><categories>cs.IT math.IT</categories><comments>5 pages, 10 figures, 2005 IEEE International Symposium on Information
  Theory</comments><abstract>  This paper introduces a new trellis pruning method which uses nonlinear
convolutional coding for peak-to-average power ratio (PAPR) reduction of
filtered QPSK and 16-QAM modulations. The Nyquist filter is viewed as a
convolutional encoder that controls the analog waveforms of the filter output
directly. Pruning some edges of the encoder trellis can effectively reduce the
PAPR. The only tradeoff is a slightly lower channel capacity and increased
complexity. The paper presents simulation results of the pruning action and the
resulting PAPR, and also discusses the decoding algorithm and the capacity of
the filtered and pruned QPSK and 16-QAM modulations on the AWGN channel.
Simulation results show that the pruning method reduces the PAPR significantly
without much damage to capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511038</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511038</id><created>2005-11-09</created><authors><author><keyname>Hitzler</keyname><forenames>Pascal</forenames></author><author><keyname>Schwarz</keyname><forenames>Sibylle</forenames></author></authors><title>Towards a unified theory of logic programming semantics: Level mapping
  characterizations of selector generated models</title><categories>cs.AI cs.LO</categories><comments>17 pages</comments><abstract>  Currently, the variety of expressive extensions and different semantics
created for logic programs with negation is diverse and heterogeneous, and
there is a lack of comprehensive comparative studies which map out the
multitude of perspectives in a uniform way. Most recently, however, new
methodologies have been proposed which allow one to derive uniform
characterizations of different declarative semantics for logic programs with
negation. In this paper, we study the relationship between two of these
approaches, namely the level mapping characterizations due to [Hitzler and
Wendt 2005], and the selector generated models due to [Schwarz 2004]. We will
show that the latter can be captured by means of the former, thereby supporting
the claim that level mappings provide a very flexible framework which is
applicable to very diversely defined semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511039</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511039</id><created>2005-11-09</created><authors><author><keyname>Measson</keyname><forenames>Cyril</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Richardson</keyname><forenames>Tom</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>The Generalized Area Theorem and Some of its Consequences</title><categories>cs.IT math.IT</categories><comments>27 pages, 46 ps figures</comments><abstract>  There is a fundamental relationship between belief propagation and maximum a
posteriori decoding. The case of transmission over the binary erasure channel
was investigated in detail in a companion paper. This paper investigates the
extension to general memoryless channels (paying special attention to the
binary case). An area theorem for transmission over general memoryless channels
is introduced and some of its many consequences are discussed. We show that
this area theorem gives rise to an upper-bound on the maximum a posteriori
threshold for sparse graph codes. In situations where this bound is tight, the
extrinsic soft bit estimates delivered by the belief propagation decoder
coincide with the correct a posteriori probabilities above the maximum a
posteriori threshold. More generally, it is conjectured that the fundamental
relationship between the maximum a posteriori and the belief propagation
decoder which was observed for transmission over the binary erasure channel
carries over to the general case. We finally demonstrate that in order for the
design rate of an ensemble to approach the capacity under belief propagation
decoding the component codes have to be perfectly matched, a statement which is
well known for the special case of transmission over the binary erasure
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511040</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511040</id><created>2005-11-09</created><authors><author><keyname>Bennatan</keyname><forenames>Amir</forenames></author><author><keyname>Burshtein</keyname><forenames>David</forenames></author></authors><title>Design and Analysis of Nonbinary LDPC Codes for Arbitrary
  Discrete-Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>To appear, IEEE Transactions on Information Theory, (submitted
  October 2004, revised and accepted for publication, November 2005). The
  material in this paper was presented in part at the 41st Allerton Conference
  on Communications, Control and Computing, October 2003 and at the 2005 IEEE
  International Symposium on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. IT-52, no. 2, pp.
  549-583, 2006</journal-ref><doi>10.1109/TIT.2005.862080</doi><abstract>  We present an analysis, under iterative decoding, of coset LDPC codes over
GF(q), designed for use over arbitrary discrete-memoryless channels
(particularly nonbinary and asymmetric channels). We use a random-coset
analysis to produce an effect that is similar to output-symmetry with binary
channels. We show that the random selection of the nonzero elements of the
GF(q) parity-check matrix induces a permutation-invariance property on the
densities of the decoder messages, which simplifies their analysis and
approximation. We generalize several properties, including symmetry and
stability from the analysis of binary LDPC codes. We show that under a Gaussian
approximation, the entire q-1 dimensional distribution of the vector messages
is described by a single scalar parameter (like the distributions of binary
LDPC messages). We apply this property to develop EXIT charts for our codes. We
use appropriately designed signal constellations to obtain substantial shaping
gains. Simulation results indicate that our codes outperform multilevel codes
at short block lengths. We also present simulation results for the AWGN
channel, including results within 0.56 dB of the unconstrained Shannon limit
(i.e. not restricted to any signal constellation) at a spectral efficiency of 6
bits/s/Hz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511041</id><created>2005-11-10</created><authors><author><keyname>Yamasaki</keyname><forenames>Susumu</forenames></author></authors><title>Logic Programming with Default, Weak and Strict Negations</title><categories>cs.LO</categories><comments>14 pages, to appear in Theory and Practice of Logic Programming
  (TPLP)</comments><acm-class>F.3.2; F.4.1; I.2.3</acm-class><abstract>  This paper treats logic programming with three kinds of negation: default,
weak and strict negations. A 3-valued logic model theory is discussed for logic
programs with three kinds of negation. The procedure is constructed for
negations so that a soundness of the procedure is guaranteed in terms of
3-valued logic model theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511042</id><created>2005-11-10</created><authors><author><keyname>Bader</keyname><forenames>Sebastian</forenames></author><author><keyname>Hitzler</keyname><forenames>Pascal</forenames></author></authors><title>Dimensions of Neural-symbolic Integration - A Structured Survey</title><categories>cs.AI cs.LO cs.NE</categories><comments>28 pages</comments><abstract>  Research on integrated neural-symbolic systems has made significant progress
in the recent past. In particular the understanding of ways to deal with
symbolic knowledge within connectionist systems (also called artificial neural
networks) has reached a critical mass which enables the community to strive for
applicable implementations and use cases. Recent work has covered a great
variety of logics used in artificial intelligence and provides a multitude of
techniques for dealing with them within the context of artificial neural
networks. We present a comprehensive survey of the field of neural-symbolic
integration, including a new classification of system according to their
architectures and abilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511043</id><created>2005-11-11</created><updated>2006-02-03</updated><authors><author><keyname>Bolzoni</keyname><forenames>Damiano</forenames></author><author><keyname>Zambon</keyname><forenames>Emmanuele</forenames></author><author><keyname>Etalle</keyname><forenames>Sandro</forenames></author><author><keyname>Hartel</keyname><forenames>Pieter</forenames></author></authors><title>Poseidon: a 2-tier Anomaly-based Intrusion Detection System</title><categories>cs.CR</categories><report-no>TR-CTIT-05-53</report-no><abstract>  We present Poseidon, a new anomaly based intrusion detection system. Poseidon
is payload-based, and presents a two-tier architecture: the first stage
consists of a Self-Organizing Map, while the second one is a modified PAYL
system. Our benchmarks on the 1999 DARPA data set show a higher detection rate
and lower number of false positives than PAYL and PHAD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511044</id><created>2005-11-12</created><authors><author><keyname>Gruska</keyname><forenames>J.</forenames></author><author><keyname>La Torre</keyname><forenames>S.</forenames></author><author><keyname>Napoli</keyname><forenames>M.</forenames></author><author><keyname>Parente</keyname><forenames>M.</forenames></author></authors><title>Various Solutions to the Firing Squad Synchronization Problems</title><categories>cs.DS cs.CC</categories><abstract>  We present different classes of solutions to the Firing Squad Synchronization
Problem on networks of different shapes. The nodes are finite state processors
that work at unison discrete steps. The networks considered are the line, the
ring and the square. For all of these models we have considered one and two-way
communication modes and also constrained the quantity of information that
adjacent processors can exchange each step. We are given a particular time
expressed as a function of the number of nodes of the network, $f(n)$ and
present synchronization algorithms in time $n^2$, $n \log n$, $n\sqrt n$,
$2^n$. The solutions are presented as {\em signals} that are used as building
blocks to compose new solutions for all times expressed by polynomials with
nonnegative coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511045</id><created>2005-11-12</created><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Martini</keyname><forenames>Simone</forenames></author></authors><title>An Invariant Cost Model for the Lambda Calculus</title><categories>cs.LO cs.CC</categories><comments>19 pages</comments><acm-class>F.4.1</acm-class><abstract>  We define a new cost model for the call-by-value lambda-calculus satisfying
the invariance thesis. That is, under the proposed cost model, Turing machines
and the call-by-value lambda-calculus can simulate each other within a
polynomial time overhead. The model only relies on combinatorial properties of
usual beta-reduction, without any reference to a specific machine or evaluator.
In particular, the cost of a single beta reduction is proportional to the
difference between the size of the redex and the size of the reduct. In this
way, the total cost of normalizing a lambda term will take into account the
size of all intermediate results (as well as the number of steps to normal
form).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511046</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511046</id><created>2005-11-14</created><authors><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Liu</keyname><forenames>Qingchong</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author></authors><title>Generalized Kasami Sequences: The Large Set</title><categories>cs.IT cs.CR math.IT</categories><comments>30 pages</comments><abstract>  In this paper new binary sequence families $\mathcal{F}^k$ of period $2^n-1$
are constructed for even $n$ and any $k$ with ${\rm gcd}(k,n)=2$ if $n/2$ is
odd or ${\rm gcd}(k,n)=1$ if $n/2$ is even. The distribution of their
correlation values is completely determined. These families have maximum
correlation $2^{n/2+1}+1$ and family size $2^{3n/2}+2^{n/2}$ for odd $n/2$ or
$2^{3n/2}+2^{n/2}-1$ for even $n/2$. The construction of the large set of
Kasami sequences which is exactly the $\mathcal{F}^{k}$ with $k=n/2+1$ is
generalized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511047</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511047</id><created>2005-11-12</created><authors><author><keyname>Ye</keyname><forenames>Chunxuan</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author></authors><title>The Secret Key-Private Key Capacity Region for Three Terminals</title><categories>cs.IT math.IT</categories><comments>Appeared in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4 -- 9, 2005</comments><abstract>  We consider a model for secrecy generation, with three terminals, by means of
public interterminal communication, and examine the problem of characterizing
all the rates at which all three terminals can generate a ``secret key,'' and
-- simultaneously -- two designated terminals can generate a ``private key''
which is effectively concealed from the remaining terminal; both keys are also
concealed from an eavesdropper that observes the public communication. Inner
and outer bounds for the ``secret key--private key capacity region'' are
derived. Under a certain special condition, these bounds coincide to yield the
(exact) secret key--private key capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511048</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511048</id><created>2005-11-12</created><authors><author><keyname>Sarshar</keyname><forenames>Nima</forenames></author><author><keyname>Wu</keyname><forenames>Xiaolin</forenames></author></authors><title>Joint Network-Source Coding: An Achievable Region with Diversity Routing</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Informatoin Theory Workshop 2006</comments><abstract>  We are interested in how to best communicate a (usually real valued) source
to a number of destinations (sinks) over a network with capacity constraints in
a collective fidelity metric over all the sinks, a problem which we call joint
network-source coding. Unlike the lossless network coding problem, lossy
reconstruction of the source at the sinks is permitted. We make a first attempt
to characterize the set of all distortions achievable by a set of sinks in a
given network. While the entire region of all achievable distortions remains
largely an open problem, we find a large, non-trivial subset of it using ideas
in multiple description coding. The achievable region is derived over all
balanced multiple-description codes and over all network flows, while the
network nodes are allowed to forward and duplicate data packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511049</id><created>2005-11-12</created><updated>2006-10-30</updated><authors><author><keyname>Gutoski</keyname><forenames>Gus</forenames></author></authors><title>Entropy, Convex Optimization, and Competitive Quantum Interactions</title><categories>cs.CC cs.GT quant-ph</categories><comments>withdrawn</comments><abstract>  This paper has been withdrawn by the author due to errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511050</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511050</id><created>2005-11-12</created><authors><author><keyname>Ye</keyname><forenames>Chunxuan</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author></authors><title>Secret Key and Private Key Constructions for Simple Multiterminal Source
  Models</title><categories>cs.IT cs.CR math.IT</categories><comments>Appeared in the proceedings of the 2005 IEEE International Symposium
  on Information Theory, Adelaide, Australia, September 4 -- 9, 2005</comments><abstract>  This work is motivated by recent results of Csiszar and Narayan (IEEE Trans.
on Inform. Theory, Dec. 2004), which highlight innate connections between
secrecy generation by multiple terminals and multiterminal Slepian-Wolf
near-lossless data compression (sans secrecy restrictions). We propose a new
approach for constructing secret and private keys based on the long-known
Slepian-Wolf code for sources connected by a virtual additive noise channel,
due to Wyner (IEEE Trans. on Inform. Theory, Jan. 1974). Explicit procedures
for such constructions, and their substantiation, are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511051</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511051</id><created>2005-11-12</created><authors><author><keyname>Ye</keyname><forenames>Chunxuan</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author></authors><title>The Private Key Capacity Region for Three Terminals</title><categories>cs.IT cs.CR math.IT</categories><comments>Appeared in the proceedings of the 2004 IEEE International Symposium
  on Information Theory, Chicago, Illinois, June 27 -- July 2, 2004</comments><abstract>  We consider a model with three terminals and examine the problem of
characterizing the largest rates at which two pairs of terminals can
simultaneously generate private keys, each of which is effectively concealed
from the remaining terminal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511052</id><created>2005-11-14</created><authors><author><keyname>Giraldi</keyname><forenames>Gilson A.</forenames></author><author><keyname>Oliveira</keyname><forenames>Antonio A. F.</forenames></author><author><keyname>Carvalho</keyname><forenames>Leonardo</forenames></author></authors><title>Mining Cellular Automata DataBases throug PCA Models</title><categories>cs.DM cs.DB</categories><comments>13 pages, 4 figures, 5 tables</comments><acm-class>F.1.1</acm-class><abstract>  Cellular Automata are discrete dynamical systems that evolve following simple
and local rules. Despite of its local simplicity, knowledge discovery in CA is
a NP problem. This is the main motivation for using data mining techniques for
CA study. The Principal Component Analysis (PCA) is a useful tool for data
mining because it provides a compact and optimal description of data sets. Such
feature have been explored to compute the best subspace which maximizes the
projection of the I/O patterns of CA onto the principal axis. The stability of
the principal components against the input patterns is the main result of this
approach. In this paper we perform such analysis but in the presence of noise
which randomly reverses the CA output values with probability $p$. As expected,
the number of principal components increases when the pattern size is
increased. However, it seems to remain stable when the pattern size is
unchanged but the noise intensity gets larger. We describe our experiments and
point out further works using KL transform theory and parameter sensitivity
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511053</id><created>2005-11-14</created><authors><author><keyname>Smith</keyname><forenames>Leland</forenames></author><author><keyname>Thirunavukkarasu</keyname><forenames>Muthukumar</forenames></author><author><keyname>Varadarajan</keyname><forenames>Srinidhi</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Naren</forenames></author></authors><title>A Model Based Approach to Reachability Routing</title><categories>cs.NI</categories><comments>In submission to IEEE Journal on Selected Areas of Communication</comments><acm-class>C.2.2; I.2.11</acm-class><abstract>  Current directions in network routing research have not kept pace with the
latest developments in network architectures, such as peer-to-peer networks,
sensor networks, ad-hoc wireless networks, and overlay networks. A common
characteristic among all of these new technologies is the presence of highly
dynamic network topologies. Currently deployed single-path routing protocols
cannot adequately cope with this dynamism, and existing multi-path algorithms
make trade-offs which lead to less than optimal performance on these networks.
This drives the need for routing protocols designed with the unique
characteristics of these networks in mind.
  In this paper we propose the notion of reachability routing as a solution to
the challenges posed by routing on such dynamic networks. In particular, our
formulation of reachability routing provides cost-sensitive multi-path
forwarding along with loop avoidance within the confines of the Internet
Protocol (IP) architecture. This is achieved through the application of
reinforcement learning within a probabilistic routing framework. Following an
explanation of our design decisions and a description of the algorithm, we
provide an evaluation of the performance of the algorithm on a variety of
network topologies. The results show consistently superior performance compared
to other reinforcement learning based routing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511054</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511054</id><created>2005-11-14</created><authors><author><keyname>Peacock</keyname><forenames>Matthew J. M.</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author><author><keyname>Honig</keyname><forenames>Michael L.</forenames></author></authors><title>Eigenvalue Distributions of Sums and Products of Large Random Matrices
  via Incremental Matrix Expansions</title><categories>cs.IT math.IT</categories><comments>Submitted to Trans IT</comments><abstract>  This paper uses an incremental matrix expansion approach to derive asymptotic
eigenvalue distributions (a.e.d.'s) of sums and products of large random
matrices. We show that the result can be derived directly as a consequence of
two common assumptions, and matches the results obtained from using R- and
S-transforms in free probability theory. We also give a direct derivation of
the a.e.d. of the sum of certain random matrices which are not free. This is
used to determine the asymptotic signal-to-interference-ratio of a multiuser
CDMA system with a minimum mean-square error linear receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511055</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511055</id><created>2005-11-15</created><authors><author><keyname>Antoniou</keyname><forenames>Grigoris</forenames></author><author><keyname>Billington</keyname><forenames>David</forenames></author><author><keyname>Governatori</keyname><forenames>Guido</forenames></author><author><keyname>Maher</keyname><forenames>Michael J.</forenames></author></authors><title>Embedding Defeasible Logic into Logic Programming</title><categories>cs.LO</categories><comments>To appear in Theory and Practice of Logic Programming</comments><acm-class>F.4.1; I.2.3</acm-class><journal-ref>Theory and Practice of Logic Programming, 6, 6 (2006): 703-735</journal-ref><doi>10.1017/S147106840600277</doi><abstract>  Defeasible reasoning is a simple but efficient approach to nonmonotonic
reasoning that has recently attracted considerable interest and that has found
various applications. Defeasible logic and its variants are an important family
of defeasible reasoning methods. So far no relationship has been established
between defeasible logic and mainstream nonmonotonic reasoning approaches.
  In this paper we establish close links to known semantics of logic programs.
In particular, we give a translation of a defeasible theory D into a
meta-program P(D). We show that under a condition of decisiveness, the
defeasible consequences of D correspond exactly to the sceptical conclusions of
P(D) under the stable model semantics. Without decisiveness, the result holds
only in one direction (all defeasible consequences of D are included in all
stable models of P(D)). If we wish a complete embedding for the general case,
we need to use the Kunen semantics of P(D), instead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511056</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511056</id><created>2005-11-15</created><authors><author><keyname>Han</keyname><forenames>Junsheng</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Improved Upper Bounds on Stopping Redundancy</title><categories>cs.IT cs.DM math.IT</categories><comments>13 pages, 3 figures. Submitted to the IEEE Transactions on
  Information Theory</comments><abstract>  Let C be a linear code with length n and minimum distance d. The stopping
redundancy of C is defined as the minimum number of rows in a parity-check
matrix for C such that the smallest stopping sets in the corresponding Tanner
graph have size d. We derive new upper bounds on the stopping redundancy of
linear codes in general, and of maximum distance separable (MDS) codes
specifically, and show how they improve upon previously known results. For MDS
codes, the new bounds are found by upper bounding the stopping redundancy by a
combinatorial quantity closely related to Turan numbers. (The Turan number,
T(v,k,t), is the smallest number of t-subsets of a v-set, such that every
k-subset of the v-set contains at least one of the t-subsets.) We further show
that the stopping redundancy of MDS codes is T(n,d-1,d-2)(1+O(n^{-1})) for
fixed d, and is at most T(n,d-1,d-2)(3+O(n^{-1})) for fixed code dimension
k=n-d+1. For d=3,4, we prove that the stopping redundancy of MDS codes is equal
to T(n,d-1,d-2), for which exact formulas are known. For d=5, we show that the
stopping redundancy of MDS codes is either T(n,4,3) or T(n,4,3)+1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511057</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511057</id><created>2005-11-15</created><authors><author><keyname>Tomic</keyname><forenames>Ratko V.</forenames></author></authors><title>Quantized Indexing: Beyond Arithmetic Coding</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>Submitted to DCC-2006</comments><report-no>TR05-1115</report-no><acm-class>E.4; G.2.1</acm-class><journal-ref>IEEE/DCC 2006, p. 468</journal-ref><abstract>  Quantized Indexing is a fast and space-efficient form of enumerative
(combinatorial) coding, the strongest among asymptotically optimal universal
entropy coding algorithms. The present advance in enumerative coding is similar
to that made by arithmetic coding with respect to its unlimited precision
predecessor, Elias coding. The arithmetic precision, execution time, table
sizes and coding delay are all reduced by a factor O(n) at a redundancy below
2*log(e)/2^g bits/symbol (for n input symbols and g-bit QI precision). Due to
its tighter enumeration, QI output redundancy is below that of arithmetic
coding (which can be derived as a lower accuracy approximation of QI). The
relative compression gain vanishes in large n and in high entropy limits and
increases for shorter outputs and for less predictable data. QI is
significantly faster than the fastest arithmetic coders, from factor 6 in high
entropy limit to over 100 in low entropy limit (`typically' 10-20 times
faster). These speedups are result of using only 3 adds, 1 shift and 2 array
lookups (all in 32 bit precision) per less probable symbol and no coding
operations for the most probable symbol . Further, the exact enumeration
algorithm is sharpened and its lattice walks formulation is generalized. A new
numeric type with a broader applicability, sliding window integer, is
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511058</id><created>2005-11-15</created><updated>2006-01-24</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>On-line regression competitive with reproducing kernel Hilbert spaces</title><categories>cs.LG</categories><comments>37 pages, 1 figure</comments><abstract>  We consider the problem of on-line prediction of real-valued labels, assumed
bounded in absolute value by a known constant, of new objects from known
labeled objects. The prediction algorithm's performance is measured by the
squared deviation of the predictions from the actual labels. No stochastic
assumptions are made about the way the labels and objects are generated.
Instead, we are given a benchmark class of prediction rules some of which are
hoped to produce good predictions. We show that for a wide range of
infinite-dimensional benchmark classes one can construct a prediction algorithm
whose cumulative loss over the first N examples does not exceed the cumulative
loss of any prediction rule in the class plus O(sqrt(N)); the main differences
from the known results are that we do not impose any upper bound on the norm of
the considered prediction rules and that we achieve an optimal leading term in
the excess loss of our algorithm. If the benchmark class is &quot;universal&quot; (dense
in the class of continuous functions on each compact set), this provides an
on-line non-stochastic analogue of universally consistent prediction in
non-parametric statistics. We use two proof techniques: one is based on the
Aggregating Algorithm and the other on the recently developed method of
defensive forecasting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511059</identifier>
 <datestamp>2008-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511059</id><created>2005-11-15</created><updated>2006-05-30</updated><authors><author><keyname>Liu</keyname><forenames>Ke</forenames></author><author><keyname>Abu-Ghazaleh</keyname><forenames>Nael</forenames></author></authors><title>Virtual Coordinate Backtracking for Void Traversal in Geographic Routing</title><categories>cs.NI</categories><journal-ref>AdHocNow 2006</journal-ref><abstract>  Geographical routing protocols have several desirable features for use in ad
hoc and sensor networks but are susceptible to voids and localization errors.
Virtual coordinate systems are an alternative solution to geographically based
routing protocols that works by overlaying a coordinate system on the sensors
relative to well chosen reference points. VC is resilient to localization
errors; however, we show that it is vulnerable to different forms of the void
problem and have no viable complementary approach to overcome them.
Specifically, we show that there are instances when packets reach nodes with no
viable next hop nodes in the forwarding set. In addition, it is possible for
nodes with the same coordinates to arise at different points in the network in
the presence of voids. This paper identifies and analyzes these problems. It
also compares several existing routing protocols based on Virtual Coordinate
systems. Finally, it presents a new routing algorithm that uses backtracking to
overcome voids to achieve high connectivity in the greedy phase, higher overall
path quality and more resilience to localization errors. We show these
properties using extensive simulation analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511060</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511060</id><created>2005-11-16</created><authors><author><keyname>Ryu</keyname><forenames>Jonghoon</forenames></author><author><keyname>Takeshita</keyname><forenames>Oscar Y.</forenames></author></authors><title>On Quadratic Inverses for Quadratic Permutation Polynomials over Integer
  Rings</title><categories>cs.IT math.IT</categories><comments>Submitted as a Correspondence to the IEEE Transactions on Information
  Theory Submitted : April 1, 2005 Revised : Nov. 15, 2005</comments><abstract>  An interleaver is a critical component for the channel coding performance of
turbo codes. Algebraic constructions are of particular interest because they
admit analytical designs and simple, practical hardware implementation. Sun and
Takeshita have recently shown that the class of quadratic permutation
polynomials over integer rings provides excellent performance for turbo codes.
In this correspondence, a necessary and sufficient condition is proven for the
existence of a quadratic inverse polynomial for a quadratic permutation
polynomial over an integer ring. Further, a simple construction is given for
the quadratic inverse. All but one of the quadratic interleavers proposed
earlier by Sun and Takeshita are found to admit a quadratic inverse, although
none were explicitly designed to do so. An explanation is argued for the
observation that restriction to a quadratic inverse polynomial does not narrow
the pool of good quadratic interleavers for turbo codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511061</id><created>2005-11-16</created><authors><author><keyname>Hammer</keyname><forenames>Moritz</forenames><affiliation>IFI-LMU</affiliation></author><author><keyname>Knapp</keyname><forenames>Alexander</forenames><affiliation>IFI-LMU</affiliation></author><author><keyname>Merz</keyname><forenames>Stephan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Truly On-The-Fly LTL Model Checking</title><categories>cs.LO</categories><proxy>ccsd inria-00000753</proxy><journal-ref>Dans Tools and Algorithms for the Construction and Analysis of
  Systems (TACAS 2005)</journal-ref><abstract>  We propose a novel algorithm for automata-based LTL model checking that
interleaves the construction of the generalized B\&quot;{u}chi automaton for the
negation of the formula and the emptiness check. Our algorithm first converts
the LTL formula into a linear weak alternating automaton; configurations of the
alternating automaton correspond to the locations of a generalized B\&quot;{u}chi
automaton, and a variant of Tarjan's algorithm is used to decide the existence
of an accepting run of the product of the transition system and the automaton.
Because we avoid an explicit construction of the B\&quot;{u}chi automaton, our
approach can yield significant improvements in runtime and memory, for large
LTL formulas. The algorithm has been implemented within the SPIN model checker,
and we present experimental results for some benchmark examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511062</id><created>2005-11-16</created><authors><author><keyname>Bumiller</keyname><forenames>Gerd</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lu</keyname><forenames>Liping</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Song</keyname><forenames>Yeqiong</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Analytic performance comparison of routing protocols in master-slave PLC
  networks</title><categories>cs.NI</categories><proxy>ccsd inria-00000756</proxy><abstract>  In the wide area master-slave PLC (powerline communication) system, the
source node cannot reach the destination node without packet relay. Due to the
time-variable attenuation in the powerline, the communication distance cannot
be defined. Two kind of dynamic repeater algorithms are developed, dynamic
source routing and flooding based routing. In this paper, we use analytic
approach to compare the performance of those two routing protocols. We give
formulas to calculate the average duration of a polling cycle for each
protocols. Then we present simulation results to bolster the results of our
analysis. We use three metrics, which are bandwidth consumed for routing
signaling, normalized routing load and average duration of a polling cycle to
evaluate those routing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511063</id><created>2005-11-16</created><authors><author><keyname>Finelli</keyname><forenames>Michele</forenames></author></authors><title>Pathwords: a user-friendly schema for common passwords management</title><categories>cs.CR</categories><abstract>  Many computer-based authentication schemata are based on pass- words. Logging
on a computer, reading email, accessing content on a web server are all
examples of applications where the identification of the user is usually
accomplished matching the data provided by the user with data known by the
application.
  Such a widespread approach relies on some assumptions, whose satisfaction is
of foremost importance to guarantee the robustness of the solution. Some of
these assumptions, like having a &quot;secure&quot; chan- nel to transmit data, or having
sound algorithms to check the correct- ness of the data, are not addressed by
this paper. We will focus on two simple issues: the problem of using adequate
passwords and the problem of managing passwords.
  The proposed solution, the pathword, is a method that guarantees:
  1 that the passwords generated with the help of a pathword are adequate (i.e.
that they are not easy to guess),
  2 that managing pathwords is more user friendly than managing passwords and
that pathwords are less amenable to problems typical of passwords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511064</id><created>2005-11-16</created><authors><author><keyname>Evako</keyname><forenames>Alexander V.</forenames></author></authors><title>The consistency principle for a digitization procedure. An algorithm for
  building normal digital spaces of continuous n-dimensional objects</title><categories>cs.CV cs.DM</categories><comments>13 pages, 11 figures</comments><acm-class>I.3.5; I.5.1; G.2.2</acm-class><abstract>  This paper considers conditions, which allow to preserve important
topological and geometric properties in the process of digitization. For this
purpose, we introduce a triplet {C,M,D} consisting of a continuous object C, an
intermediate model M, which is a collection of subregions whose union is C, a
digital model D, which is the intersection graph of M, and apply the
consistency principle and criteria of similarity to M in order to make its
mathematical structure consistent with the natural structure of D.
Specifically, this paper introduces a locally centered lump collection of
subregions and shows that for any locally centered lump cover of an
n-dimensional continuous manifold, the digital model of the manifold is a
digital normal n-dimensional space. In addition, we give examples of locally
centered lump tilings of two-manifolds. We propose an algorithm for
constructing normal digital models of continuous objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511065</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511065</id><created>2005-11-17</created><authors><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Grant</keyname><forenames>Alex J.</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Performance Analysis of MIMO-MRC in Double-Correlated Rayleigh
  Environments</title><categories>cs.IT math.IT</categories><comments>25 pages. Submitted to the IEEE Transactions on Communications</comments><abstract>  We consider multiple-input multiple-output (MIMO) transmit beamforming
systems with maximum ratio combining (MRC) receivers. The operating environment
is Rayleigh-fading with both transmit and receive spatial correlation. We
present exact expressions for the probability density function (p.d.f.) of the
output signal-to-noise ratio (SNR), as well as the system outage probability.
The results are based on explicit closed-form expressions which we derive for
the p.d.f. and c.d.f. of the maximum eigenvalue of double-correlated complex
Wishart matrices. For systems with two antennas at either the transmitter or
the receiver, we also derive exact closed-form expressions for the symbol error
rate (SER). The new expressions are used to prove that MIMO-MRC achieves the
maximum available spatial diversity order, and to demonstrate the effect of
spatial correlation. The analysis is validated through comparison with
Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511066</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511066</id><created>2005-11-17</created><updated>2007-09-13</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Urbanska</keyname><forenames>Anna</forenames><affiliation>LJK</affiliation></author></authors><title>An introspective algorithm for the integer determinant</title><categories>cs.SC</categories><comments>Published in Transgressive Computing 2006, Grenade : Espagne (2006)</comments><proxy>ccsd ccsd-00014044</proxy><abstract>  We present an algorithm computing the determinant of an integer matrix A. The
algorithm is introspective in the sense that it uses several distinct
algorithms that run in a concurrent manner. During the course of the algorithm
partial results coming from distinct methods can be combined. Then, depending
on the current running time of each method, the algorithm can emphasize a
particular variant. With the use of very fast modular routines for linear
algebra, our implementation is an order of magnitude faster than other existing
implementations. Moreover, we prove that the expected complexity of our
algorithm is only O(n^3 log^{2.5}(n ||A||)) bit operations in the dense case
and O(Omega n^{1.5} log^2(n ||A||) + n^{2.5}log^3(n||A||)) in the sparse case,
where ||A|| is the largest entry in absolute value of the matrix and Omega is
the cost of matrix-vector multiplication in the case of a sparse matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511067</id><created>2005-11-18</created><authors><author><keyname>He</keyname><forenames>Dongqing</forenames></author><author><keyname>Ma</keyname><forenames>Peisun</forenames></author></authors><title>Effects of Initial Stance of Quadruped Trotting on Walking Stability</title><categories>cs.RO</categories><abstract>  It is very important for quadruped walking machine to keep its stability in
high speed walking. It has been indicated that moment around the supporting
diagonal line of quadruped in trotting gait largely influences walking
stability. In this paper, moment around the supporting diagonal line of
quadruped in trotting gait is modeled and its effects on body attitude are
analyzed. The degree of influence varies with different initial stances of
quadruped and we get the optimal initial stance of quadruped in trotting gait
with maximal walking stability. Simulation results are presented. Keywords:
quadruped, trotting, attitude, walking stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511068</id><created>2005-11-18</created><authors><author><keyname>Heinrich</keyname><forenames>S.</forenames></author><author><keyname>Durr</keyname><forenames>H.</forenames></author><author><keyname>Hanel</keyname><forenames>T.</forenames></author><author><keyname>Lassig</keyname><forenames>J.</forenames></author></authors><title>An Agent-based Manufacturing Management System for Production and
  Logistics within Cross-Company Regional and National Production Networks</title><categories>cs.RO</categories><abstract>  The goal is the development of a simultaneous, dynamic, technological as well
as logistical real-time planning and an organizational control of the
production by the production units themselves, working in the production
network under the use of Multi-Agent-Technology. The design of the
multi-agent-based manufacturing management system, the models of the single
agents, algorithms for the agent-based, decentralized dispatching of orders,
strategies and data management concepts as well as their integration into the
SCM, basing on the solution described, will be explained in the following.
  Keywords: production engineering and management, dynamic manufacturing
planning and control, multi-agentsystems (MAS), supply-chain-management (SCM),
e-manufacturing
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511069</id><created>2005-11-18</created><authors><author><keyname>Hedjar</keyname><forenames>R.</forenames></author><author><keyname>Boucher</keyname><forenames>P.</forenames></author></authors><title>Nonlinear Receding-Horizon Control of Rigid Link Robot Manipulators</title><categories>cs.RO</categories><abstract>  The approximate nonlinear receding-horizon control law is used to treat the
trajectory tracking control problem of rigid link robot manipulators. The
derived nonlinear predictive law uses a quadratic performance index of the
predicted tracking error and the predicted control effort. A key feature of
this control law is that, for their implementation, there is no need to perform
an online optimization, and asymptotic tracking of smooth reference
trajectories is guaranteed. It is shown that this controller achieves the
positions tracking objectives via link position measurements. The stability
convergence of the output tracking error to the origin is proved. To enhance
the robustness of the closed loop system with respect to payload uncertainties
and viscous friction, an integral action is introduced in the loop. A nonlinear
observer is used to estimate velocity. Simulation results for a two-link rigid
robot are performed to validate the performance of the proposed controller.
  Keywords: receding-horizon control, nonlinear observer, robot manipulators,
integral action, robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511070</identifier>
 <datestamp>2008-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511070</id><created>2005-11-18</created><updated>2008-06-13</updated><authors><author><keyname>Mitra</keyname><forenames>Arindam</forenames></author></authors><title>A particle can carry more than one bit of information</title><categories>cs.IT math.IT</categories><comments>1301 words</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is believed that a particle cannot carry more than one bit of information.
It is pointed out that particle or single-particle quantum state can carry more
than one bit of information. It implies that minimum energy cost of
transmitting a bit will be less than the accepted limit KTlog2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511071</id><created>2005-11-18</created><updated>2005-11-28</updated><authors><author><keyname>Capasso</keyname><forenames>Francesco</forenames></author></authors><title>A polynomial-time heuristic for Circuit-SAT</title><categories>cs.CC cs.DS</categories><comments>20 pages, 8 figures</comments><abstract>  In this paper is presented an heuristic that, in polynomial time and space in
the input dimension, determines if a circuit describes a tautology or a
contradiction. If the circuit is neither a tautology nor a contradiction, then
the heuristic finds an assignment to the circuit inputs such that the circuit
is satisfied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511072</identifier>
 <datestamp>2007-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511072</id><created>2005-11-18</created><updated>2007-10-08</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Rudra</keyname><forenames>Atri</forenames></author></authors><title>Explicit Codes Achieving List Decoding Capacity: Error-correction with
  Optimal Redundancy</title><categories>cs.IT math.IT</categories><comments>28 pages, 6 figures</comments><acm-class>H.1.1</acm-class><abstract>  We present error-correcting codes that achieve the information-theoretically
best possible trade-off between the rate and error-correction radius.
Specifically, for every $0 &lt; R &lt; 1$ and $\eps&gt; 0$, we present an explicit
construction of error-correcting codes of rate $R$ that can be list decoded in
polynomial time up to a fraction $(1-R-\eps)$ of {\em worst-case} errors. At
least theoretically, this meets one of the central challenges in algorithmic
coding theory.
  Our codes are simple to describe: they are {\em folded Reed-Solomon codes},
which are in fact {\em exactly} Reed-Solomon (RS) codes, but viewed as a code
over a larger alphabet by careful bundling of codeword symbols. Given the
ubiquity of RS codes, this is an appealing feature of our result, and in fact
our methods directly yield better decoding algorithms for RS codes when errors
occur in {\em phased bursts}.
  The alphabet size of these folded RS codes is polynomial in the block length.
We are able to reduce this to a constant (depending on $\eps$) using ideas
concerning ``list recovery'' and expander-based codes from
\cite{GI-focs01,GI-ieeejl}. Concatenating the folded RS codes with suitable
inner codes also gives us polynomial time constructible binary codes that can
be efficiently list decoded up to the Zyablov bound, i.e., up to twice the
radius achieved by the standard GMD decoding of concatenated codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511073</id><created>2005-11-19</created><authors><author><keyname>Mjolsness</keyname><forenames>Eric</forenames></author></authors><title>Stochastic Process Semantics for Dynamical Grammar Syntax: An Overview</title><categories>cs.AI cs.LO nlin.AO</categories><comments>Accepted for: Ninth International Symposium on Artificial
  Intelligence and Mathematics, January 2006</comments><report-no>UCI ICS TR# 05-14</report-no><acm-class>D.3.1</acm-class><abstract>  We define a class of probabilistic models in terms of an operator algebra of
stochastic processes, and a representation for this class in terms of
stochastic parameterized grammars. A syntactic specification of a grammar is
mapped to semantics given in terms of a ring of operators, so that grammatical
composition corresponds to operator addition or multiplication. The operators
are generators for the time-evolution of stochastic processes. Within this
modeling framework one can express data clustering models, logic programs,
ordinary and stochastic differential equations, graph grammars, and stochastic
chemical reaction kinetics. This mathematical formulation connects these
apparently distant fields to one another and to mathematical methods from
quantum field theory and operator algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511074</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511074</id><created>2005-11-21</created><updated>2006-08-11</updated><authors><author><keyname>Doty</keyname><forenames>David</forenames></author></authors><title>Every Sequence is Decompressible from a Random One</title><categories>cs.IT cs.CC math.IT</categories><comments>revised conclusion to remove possibly incorrect statements about
  reversibility of decompression; restated as open question</comments><acm-class>F.1.1; H.1.1</acm-class><abstract>  Kucera and Gacs independently showed that every infinite sequence is Turing
reducible to a Martin-Lof random sequence. This result is extended by showing
that every infinite sequence S is Turing reducible to a Martin-Lof random
sequence R such that the asymptotic number of bits of R needed to compute n
bits of S, divided by n, is precisely the constructive dimension of S. It is
shown that this is the optimal ratio of query bits to computed bits achievable
with Turing reductions. As an application of this result, a new
characterization of constructive dimension is given in terms of Turing
reduction compression ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511075</id><created>2005-11-20</created><authors><author><keyname>Terribilini</keyname><forenames>Michael</forenames></author><author><keyname>Lee</keyname><forenames>Jae-Hyung</forenames></author><author><keyname>Yan</keyname><forenames>Changhui</forenames></author><author><keyname>Jernigan</keyname><forenames>Robert L.</forenames></author><author><keyname>Carpenter</keyname><forenames>Susan</forenames></author><author><keyname>Honavar</keyname><forenames>Vasant</forenames></author><author><keyname>Dobbs</keyname><forenames>Drena</forenames></author></authors><title>Identifying Interaction Sites in &quot;Recalcitrant&quot; Proteins: Predicted
  Protein and Rna Binding Sites in Rev Proteins of Hiv-1 and Eiav Agree with
  Experimental Data</title><categories>cs.LG cs.AI</categories><comments>Pacific Symposium on Biocomputing, Hawaii, In press, Accepted, 2006</comments><acm-class>J.3</acm-class><abstract>  Protein-protein and protein nucleic acid interactions are vitally important
for a wide range of biological processes, including regulation of gene
expression, protein synthesis, and replication and assembly of many viruses. We
have developed machine learning approaches for predicting which amino acids of
a protein participate in its interactions with other proteins and/or nucleic
acids, using only the protein sequence as input. In this paper, we describe an
application of classifiers trained on datasets of well-characterized
protein-protein and protein-RNA complexes for which experimental structures are
available. We apply these classifiers to the problem of predicting protein and
RNA binding sites in the sequence of a clinically important protein for which
the structure is not known: the regulatory protein Rev, essential for the
replication of HIV-1 and other lentiviruses. We compare our predictions with
published biochemical, genetic and partial structural information for HIV-1 and
EIAV Rev and with our own published experimental mapping of RNA binding sites
in EIAV Rev. The predicted and experimentally determined binding sites are in
very good agreement. The ability to predict reliably the residues of a protein
that directly contribute to specific binding events - without the requirement
for structural information regarding either the protein or complexes in which
it participates - can potentially generate new disease intervention strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511076</id><created>2005-11-21</created><authors><author><keyname>Potard</keyname><forenames>Blaise</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Laprie</keyname><forenames>Yves</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Using phonetic constraints in acoustic-to-articulatory inversion</title><categories>cs.CL</categories><proxy>ccsd ccsd-00014057</proxy><journal-ref>Proceedings of Interspeech, 9th European Conference on Speech
  Communication and Technology (2005) 3217-3220</journal-ref><abstract>  The goal of this work is to recover articulatory information from the speech
signal by acoustic-to-articulatory inversion. One of the main difficulties with
inversion is that the problem is underdetermined and inversion methods
generally offer no guarantee on the phonetical realism of the inverse
solutions. A way to adress this issue is to use additional phonetic
constraints. Knowledge of the phonetic caracteristics of French vowels enable
the derivation of reasonable articulatory domains in the space of Maeda
parameters: given the formants frequencies (F1,F2,F3) of a speech sample, and
thus the vowel identity, an &quot;ideal&quot; articulatory domain can be derived. The
space of formants frequencies is partitioned into vowels, using either
speaker-specific data or generic information on formants. Then, to each
articulatory vector can be associated a phonetic score varying with the
distance to the &quot;ideal domain&quot; associated with the corresponding vowel.
Inversion experiments were conducted on isolated vowels and vowel-to-vowel
transitions. Articulatory parameters were compared with those obtained without
using these constraints and those measured from X-ray data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511077</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511077</id><created>2005-11-21</created><authors><author><keyname>McCown</keyname><forenames>Frank</forenames></author><author><keyname>Chan</keyname><forenames>Sheffan</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>The Availability and Persistence of Web References in D-Lib Magazine</title><categories>cs.DL</categories><comments>11 pages, 7 figures, 3 tables</comments><acm-class>H.3.m</acm-class><journal-ref>5th International Web Archiving Workshop (IWAW05), Vienna,
  Austria, 2005</journal-ref><abstract>  We explore the availability and persistence of URLs cited in articles
published in D-Lib Magazine. We extracted 4387 unique URLs referenced in 453
articles published from July 1995 to August 2004. The availability was checked
three times a week for 25 weeks from September 2004 to February 2005. We found
that approximately 28% of those URLs failed to resolve initially, and 30%
failed to resolve at the last check. A majority of the unresolved URLs were due
to 404 (page not found) and 500 (internal server error) errors. The content
pointed to by the URLs was relatively stable; only 16% of the content
registered more than a 1 KB change during the testing period. We explore
possible factors which may cause a URL to fail by examining its age, path
depth, top-level domain and file extension. Based on the data collected, we
found the half-life of a URL referenced in a D-Lib Magazine article is
approximately 10 years. We also found that URLs were more likely to be
unavailable if they pointed to resources in the .net, .edu or country-specific
top-level domain, used non-standard ports (i.e., not port 80), or pointed to
resources with uncommon or deprecated extensions (e.g., .shtml, .ps, .txt).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511078</id><created>2005-11-21</created><authors><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author><author><keyname>Murty</keyname><forenames>M. Narasimha</forenames></author><author><keyname>Bhatnagar</keyname><forenames>Shalabh</forenames></author></authors><title>Uniqueness of Nonextensive entropy under Renyi's Recipe</title><categories>cs.IT math.IT</categories><abstract>  By replacing linear averaging in Shannon entropy with Kolmogorov-Nagumo
average (KN-averages) or quasilinear mean and further imposing the additivity
constraint, R\'{e}nyi proposed the first formal generalization of Shannon
entropy. Using this recipe of R\'{e}nyi, one can prepare only two information
measures: Shannon and R\'{e}nyi entropy. Indeed, using this formalism R\'{e}nyi
characterized these additive entropies in terms of axioms of quasilinear mean.
As additivity is a characteristic property of Shannon entropy,
pseudo-additivity of the form $x \oplus_{q} y = x + y + (1-q)x y$ is a
characteristic property of nonextensive (or Tsallis) entropy. One can apply
R\'{e}nyi's recipe in the nonextensive case by replacing the linear averaging
in Tsallis entropy with KN-averages and thereby imposing the constraint of
pseudo-additivity. In this paper we show that nonextensive entropy is unique
under the R\'{e}nyi's recipe, and there by give a characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511079</id><created>2005-11-22</created><authors><author><keyname>Maj</keyname><forenames>Jean-Baptiste</forenames><affiliation>LORIA</affiliation></author><author><keyname>Bonneau</keyname><forenames>Anne</forenames><affiliation>LORIA</affiliation></author><author><keyname>Fohr</keyname><forenames>Dominique</forenames><affiliation>LORIA</affiliation></author><author><keyname>Laprie</keyname><forenames>Yves</forenames><affiliation>LORIA</affiliation></author></authors><title>An elitist approach for extracting automatically well-realized speech
  sounds with high confidence</title><categories>cs.CL</categories><proxy>ccsd ccsd-00014016</proxy><abstract>  This paper presents an &quot;elitist approach&quot; for extracting automatically
well-realized speech sounds with high confidence. The elitist approach uses a
speech recognition system based on Hidden Markov Models (HMM). The HMM are
trained on speech sounds which are systematically well-detected in an iterative
procedure. The results show that, by using the HMM models defined in the
training phase, the speech recognizer detects reliably specific speech sounds
with a small rate of errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511080</id><created>2005-11-22</created><authors><author><keyname>Stauffer</keyname><forenames>Alexandre O.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>A dissemination strategy for immunizing scale-free networks</title><categories>cs.NI</categories><acm-class>C.2.2; F.2.2</acm-class><journal-ref>Physical Review E 74 (2006), 056105</journal-ref><doi>10.1103/PhysRevE.74.056105</doi><abstract>  We consider the problem of distributing a vaccine for immunizing a scale-free
network against a given virus or worm. We introduce a new method, based on
vaccine dissemination, that seems to reflect more accurately what is expected
to occur in real-world networks. Also, since the dissemination is performed
using only local information, the method can be easily employed in practice.
Using a random-graph framework, we analyze our method both mathematically and
by means of simulations. We demonstrate its efficacy regarding the trade-off
between the expected number of nodes that receive the vaccine and the network's
resulting vulnerability to develop an epidemic as the virus or worm attempts to
infect one of its nodes. For some scenarios, the new method is seen to render
the network practically invulnerable to attacks while requiring only a small
fraction of the nodes to receive the vaccine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511081</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511081</id><created>2005-11-22</created><updated>2005-11-28</updated><authors><author><keyname>Borade</keyname><forenames>Shashi</forenames></author><author><keyname>Zheng</keyname><forenames>Lizhong</forenames></author></authors><title>Writing on Fading Paper and Causal Transmitter CSI</title><categories>cs.IT math.IT</categories><abstract>  A wideband fading channel is considered with causal channel state information
(CSI) at the transmitter and no receiver CSI. A simple orthogonal code with
energy detection rule at the receiver (similar to [6]) is shown to achieve the
capacity of this channel in the limit of large bandwidth. This code transmits
energy only when the channel gain is large enough. In this limit, this capacity
without any receiver CSI is the same as the capacity with full receiver CSI--a
phenomenon also true for dirty paper coding. For Rayleigh fading, this capacity
(per unit time) is proportional to the logarithm of the bandwidth. Our coding
scheme is motivated from the Gel'fand-Pinsker [2,3] coding and dirty paper
coding [4]. Nonetheless, for our case, only causal CSI is required at the
transmitter in contrast with dirty-paper coding and Gel'fand-Pinsker coding,
where non-causal CSI is required.
  Then we consider a general discrete channel with i.i.d. states. Each input
has an associated cost and a zero cost input &quot;0&quot; exists. The channel state is
assumed be to be known at the transmitter in a causal manner. Capacity per unit
cost is found for this channel and a simple orthogonal code is shown to achieve
this capacity. Later, a novel orthogonal coding scheme is proposed for the case
of causal transmitter CSI and a condition for equivalence of capacity per unit
cost for causal and non-causal transmitter CSI is derived. Finally, some
connections are made to the case of non-causal transmitter CSI in [8].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511082</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511082</id><created>2005-11-23</created><authors><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author><author><keyname>Della Vedova</keyname><forenames>Gianluca</forenames></author><author><keyname>Dondi</keyname><forenames>Riccardo</forenames></author></authors><title>Approximating Clustering of Fingerprint Vectors with Missing Values</title><categories>cs.DS</categories><comments>13 pages, 4 figures</comments><doi>10.1007/s00453-008-9265-0</doi><abstract>  The problem of clustering fingerprint vectors is an interesting problem in
Computational Biology that has been proposed in (Figureroa et al. 2004). In
this paper we show some improvements in closing the gaps between the known
lower bounds and upper bounds on the approximability of some variants of the
biological problem. Namely we are able to prove that the problem is APX-hard
even when each fingerprint contains only two unknown position. Moreover we have
studied some variants of the orginal problem, and we give two 2-approximation
algorithm for the IECMV and OECMV problems when the number of unknown entries
for each vector is at most a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511083</id><created>2005-11-23</created><authors><author><keyname>Powell</keyname><forenames>Olivier</forenames></author><author><keyname>Jarry</keyname><forenames>Aubin</forenames></author><author><keyname>Leone</keyname><forenames>Pierre</forenames></author><author><keyname>Rolim</keyname><forenames>Jose</forenames></author></authors><title>Gradient Based Routing in Wireless Sensor Networks: a Mixed Strategy</title><categories>cs.DC</categories><comments>4 pages, 2 figures</comments><acm-class>C.2.1</acm-class><abstract>  We show how recent theoretical advances for data-propagation in Wireless
Sensor Networks (WSNs) can be combined to improve gradient-based routing (GBR)
in Wireless Sensor Networks. We propose a mixed-strategy of direct transmission
and multi-hop propagation of data which improves the lifespan of WSNs by
reaching better energy-load-balancing amongst sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511084</identifier>
 <datestamp>2012-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511084</id><created>2005-11-23</created><updated>2006-05-10</updated><authors><author><keyname>Mendel</keyname><forenames>Manor</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>Ramsey partitions and proximity data structures</title><categories>cs.DS cs.CG math.FA math.MG</categories><comments>21 pages. Two explanatory figures were added, a few typos were fixed</comments><journal-ref>J. European Math. Soc. 9(2): 253-275, 2007</journal-ref><doi>10.4171/JEMS/79</doi><abstract>  This paper addresses two problems lying at the intersection of geometric
analysis and theoretical computer science: The non-linear isomorphic Dvoretzky
theorem and the design of good approximate distance oracles for large
distortion. We introduce the notion of Ramsey partitions of a finite metric
space, and show that the existence of good Ramsey partitions implies a solution
to the metric Ramsey problem for large distortion (a.k.a. the non-linear
version of the isomorphic Dvoretzky theorem, as introduced by Bourgain, Figiel,
and Milman). We then proceed to construct optimal Ramsey partitions, and use
them to show that for every e\in (0,1), any n-point metric space has a subset
of size n^{1-e} which embeds into Hilbert space with distortion O(1/e). This
result is best possible and improves part of the metric Ramsey theorem of
Bartal, Linial, Mendel and Naor, in addition to considerably simplifying its
proof. We use our new Ramsey partitions to design the best known approximate
distance oracles when the distortion is large, closing a gap left open by
Thorup and Zwick. Namely, we show that for any $n$ point metric space X, and
k&gt;1, there exists an O(k)-approximate distance oracle whose storage requirement
is O(n^{1+1/k}), and whose query time is a universal constant. We also discuss
applications of Ramsey partitions to various other geometric data structure
problems, such as the design of efficient data structures for approximate
ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511085</id><created>2005-11-25</created><updated>2005-11-26</updated><authors><author><keyname>Cohen</keyname><forenames>R. A.</forenames></author></authors><title>Proving that P is not equal to NP and that P is not equal to the
  intersection of NP and co-NP</title><categories>cs.CC</categories><comments>9 pages ; 3 figures</comments><abstract>  The open question, P=NP?, was presented by Cook (1971). In this paper, a
proof that P is not equal to NP is presented. In addition, it is shown that P
is not equal to the intersection of NP and co-NP. Finally, the exact inclusion
relationships between the classes P, NP and co-NP are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511086</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511086</id><created>2005-11-24</created><authors><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Energy-Efficient Resource Allocation in Time Division Multiple-Access
  over Fading Channels</title><categories>cs.IT math.IT</categories><comments>45 pages, 9 figures, submitted to IEEE Transactions on Information
  Theory</comments><abstract>  We investigate energy-efficiency issues and resource allocation policies for
time division multi-access (TDMA) over fading channels in the power-limited
regime. Supposing that the channels are frequency-flat block-fading and
transmitters have full or quantized channel state information (CSI), we first
minimize power under a weighted sum-rate constraint and show that the optimal
rate and time allocation policies can be obtained by water-filling over
realizations of convex envelopes of the minima for cost-reward functions. We
then address a related minimization under individual rate constraints and
derive the optimal allocation policies via greedy water-filling. Using
water-filling across frequencies and fading states, we also extend our results
to frequency-selective channels. Our approaches not only provide fundamental
power limits when each user can support an infinite number of
capacity-achieving codebooks, but also yield guidelines for practical designs
where users can only support a finite number of adaptive modulation and coding
(AMC) modes with prescribed symbol error probabilities, and also for systems
where only discrete-time allocations are allowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511087</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511087</id><created>2005-11-25</created><authors><author><keyname>Zaffalon</keyname><forenames>Marco</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Robust Inference of Trees</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>26 pages, 7 figures</comments><report-no>IDSIA-11-03</report-no><journal-ref>Annals of Mathematics and Artificial Intelligence, 45 (2005)
  215-239</journal-ref><doi>10.1007/s10472-005-9007-9</doi><abstract>  This paper is concerned with the reliable inference of optimal
tree-approximations to the dependency structure of an unknown distribution
generating data. The traditional approach to the problem measures the
dependency strength between random variables by the index called mutual
information. In this paper reliability is achieved by Walley's imprecise
Dirichlet model, which generalizes Bayesian learning with Dirichlet priors.
Adopting the imprecise Dirichlet model results in posterior interval
expectation for mutual information, and in a set of plausible trees consistent
with the data. Reliable inference about the actual tree is achieved by focusing
on the substructure common to all the plausible trees. We develop an exact
algorithm that infers the substructure in time O(m^4), m being the number of
random variables. The new algorithm is applied to a set of data sampled from a
known distribution. The method is shown to reliably infer edges of the actual
tree even when the data are very scarce, unlike the traditional approach.
Finally, we provide lower and upper credibility limits for mutual information
under the imprecise Dirichlet model. These enable the previous developments to
be extended to a full inferential method for trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511088</id><created>2005-11-25</created><authors><author><keyname>Pearlmutter</keyname><forenames>Barak A.</forenames></author></authors><title>Bounds on Query Convergence</title><categories>cs.LG</categories><comments>6 pages, 2 figures</comments><acm-class>G.1.6</acm-class><abstract>  The problem of finding an optimum using noisy evaluations of a smooth cost
function arises in many contexts, including economics, business, medicine,
experiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -
x*)^2 ] &gt;= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,
&gt;...) generated by an unbiased feedback process observing noisy evaluations of
an unknown quadratic function maximised at x*. The bound is tight, as the proof
leads to a simple algorithm which meets it. We further establish a bound on the
total regret, E[ sum_{i=1..t} (x_i - x*)^2 ] &gt;= O(sqrt(t)) These bounds may
impose practical limitations on an agent's performance, as O(eps^-4) queries
are made before the queries converge to x* with eps accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511089</id><created>2005-11-25</created><authors><author><keyname>Vielhaber</keyname><forenames>Michael</forenames></author></authors><title>Continued Fraction Expansion as Isometry: The Law of the Iterated
  Logarithm for Linear, Jump, and 2--Adic Complexity</title><categories>cs.IT math.IT</categories><comments>32 pages Submitted (in revised form: 24 pages) to IEEE Transactions
  on Information Theory</comments><abstract>  In the cryptanalysis of stream ciphers and pseudorandom sequences, the
notions of linear, jump, and 2-adic complexity arise naturally to measure the
(non)randomness of a given string. We define an isometry K on F_q^\infty that
is the precise equivalent to Euclid's algorithm over the reals to calculate the
continued fraction expansion of a formal power series. The continued fraction
expansion allows to deduce the linear and jump complexity profiles of the input
sequence. Since K is an isometry, the resulting F_q^\infty-sequence is i.i.d.
for i.i.d. input. Hence the linear and jump complexity profiles may be modelled
via Bernoulli experiments (for F_2: coin tossing), and we can apply the very
precise bounds as collected by Revesz, among others the Law of the Iterated
Logarithm.
  The second topic is the 2-adic span and complexity, as defined by Goresky and
Klapper. We derive again an isometry, this time on the dyadic integers Z_2
which induces an isometry A on F_2}^\infty. The corresponding jump complexity
behaves on average exactly like coin tossing.
  Index terms:
 Formal power series, isometry, linear complexity, jump complexity, 2-adic
complexity, 2-adic span, law of the iterated logarithm, Levy classes, stream
ciphers, pseudorandom sequences
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511090</id><created>2005-11-27</created><updated>2006-01-14</updated><authors><author><keyname>Hofstedt</keyname><forenames>Petra</forenames></author><author><keyname>Pepper</keyname><forenames>Peter</forenames></author></authors><title>Integration of Declarative and Constraint Programming</title><categories>cs.PL cs.AI</categories><comments>30 pages, 9 figures, To appear in Theory and Practice of Logic
  Programming (TPLP)</comments><acm-class>D.3.2</acm-class><abstract>  Combining a set of existing constraint solvers into an integrated system of
cooperating solvers is a useful and economic principle to solve hybrid
constraint problems. In this paper we show that this approach can also be used
to integrate different language paradigms into a unified framework.
Furthermore, we study the syntactic, semantic and operational impacts of this
idea for the amalgamation of declarative and constraint programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511091</id><created>2005-11-28</created><authors><author><keyname>Kavka</keyname><forenames>Carlos</forenames><affiliation>INRIA Futurs, UNSL-DI</affiliation></author><author><keyname>Roggero</keyname><forenames>Patricia</forenames><affiliation>UNSL-DI</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Evolution of Voronoi based Fuzzy Recurrent Controllers</title><categories>cs.AI</categories><proxy>ccsd inria-00000539</proxy><journal-ref>Dans GECCO 2005</journal-ref><abstract>  A fuzzy controller is usually designed by formulating the knowledge of a
human expert into a set of linguistic variables and fuzzy rules. Among the most
successful methods to automate the fuzzy controllers development process are
evolutionary algorithms. In this work, we propose the Recurrent Fuzzy Voronoi
(RFV) model, a representation for recurrent fuzzy systems. It is an extension
of the FV model proposed by Kavka and Schoenauer that extends the application
domain to include temporal problems. The FV model is a representation for fuzzy
controllers based on Voronoi diagrams that can represent fuzzy systems with
synergistic rules, fulfilling the $\epsilon$-completeness property and
providing a simple way to introduce a priory knowledge. In the proposed
representation, the temporal relations are embedded by including internal units
that provide feedback by connecting outputs to inputs. These internal units act
as memory elements. In the RFV model, the semantic of the internal units can be
specified together with the a priori rules. The geometric interpretation of the
rules allows the use of geometric variational operators during the evolution.
The representation and the algorithms are validated in two problems in the area
of system identification and evolutionary robotics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511092</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511092</id><created>2005-11-28</created><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author></authors><title>The SL synchronous language, revisited</title><categories>cs.PL</categories><proxy>ccsd ccsd-00014540</proxy><journal-ref>Journal of Logic and Algebraic Programming 70 (15/02/2007) 121-150</journal-ref><abstract>  We revisit the SL synchronous programming model introduced by Boussinot and
De Simone (IEEE, Trans. on Soft. Eng., 1996). We discuss an alternative design
of the model including thread spawning and recursive definitions and we explore
some basic properties of the revised model: determinism, reactivity, CPS
translation to a tail recursive form, computational expressivity, and a
compositional notion of program equivalence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511093</id><created>2005-11-28</created><authors><author><keyname>Semet</keyname><forenames>Yann</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Gelly</keyname><forenames>Sylvain</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Artificial Agents and Speculative Bubbles</title><categories>cs.GT cs.AI</categories><proxy>ccsd inria-00000859</proxy><abstract>  Pertaining to Agent-based Computational Economics (ACE), this work presents
two models for the rise and downfall of speculative bubbles through an exchange
price fixing based on double auction mechanisms. The first model is based on a
finite time horizon context, where the expected dividends decrease along time.
The second model follows the {\em greater fool} hypothesis; the agent behaviour
depends on the comparison of the estimated risk with the greater fool's.
Simulations shed some light on the influent parameters and the necessary
conditions for the apparition of speculative bubbles in an asset market within
the considered framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511094</id><created>2005-11-28</created><authors><author><keyname>Souvatzis</keyname><forenames>Ignatios</forenames></author></authors><title>A Machine-Independent port of the MPD language run time system to NetBSD</title><categories>cs.DC cs.PL</categories><comments>6 pages</comments><acm-class>D.1.3; D.3.4</acm-class><journal-ref>Christian Tschudin et al. (Eds.): Proceedings of the Fourth
  European BSD Conference, 2005 Basel, Switzerland</journal-ref><abstract>  SR (synchronizing resources) is a PASCAL - style language enhanced with
constructs for concurrent programming developed at the University of Arizona in
the late 1980s. MPD (presented in Gregory Andrews' book about Foundations of
Multithreaded, Parallel, and Distributed Programming) is its successor,
providing the same language primitives with a different, more C-style, syntax.
  The run-time system (in theory, identical, but not designed for sharing) of
those languages provides the illusion of a multiprocessor machine on a single
Unix-like system or a (local area) network of Unix-like machines.
  Chair V of the Computer Science Department of the University of Bonn is
operating a laboratory for a practical course in parallel programming
consisting of computing nodes running NetBSD/arm, normally used via PVM, MPI
etc.
 We are considering to offer SR and MPD for this, too. As the original language
distributions were only targeted at a few commercial Unix systems, some porting
effort is needed. However, some of the porting effort of our earlier SR port
should be reusable.
  The integrated POSIX threads support of NetBSD-2.0 and later allows us to use
library primitives provided for NetBSD's phtread system to implement the
primitives needed by the SR run-time system, thus implementing 13 target CPUs
at once and automatically making use of SMP on VAX, Alpha, PowerPC, Sparc,
32-bit Intel and 64 bit AMD CPUs.
  We'll present some methods used for the impementation and compare some
performance values to the traditional implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511095</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511095</id><created>2005-11-28</created><updated>2006-10-29</updated><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Carbon Copying Onto Dirty Paper</title><categories>cs.IT math.IT</categories><comments>To appear, IT. Trans. on Information Theory. Modified to incorporate
  reviewer's comments. Also includes some additional results for the Gaussian
  case</comments><abstract>  A generalization of the problem of writing on dirty paper is considered in
which one transmitter sends a common message to multiple receivers. Each
receiver experiences on its link an additive interference (in addition to the
additive noise), which is known noncausally to the transmitter but not to any
of the receivers. Applications range from wireless multi-antenna multicasting
to robust dirty paper coding.
  We develop results for memoryless channels in Gaussian and binary special
cases. In most cases, we observe that the availability of side information at
the transmitter increases capacity relative to systems without such side
information, and that the lack of side information at the receivers decreases
capacity relative to systems with such side information.
  For the noiseless binary case, we establish the capacity when there are two
receivers. When there are many receivers, we show that the transmitter side
information provides a vanishingly small benefit. When the interference is
large and independent across the users, we show that time sharing is optimal.
  For the Gaussian case we present a coding scheme and establish its optimality
in the high signal-to-interference-plus-noise limit when there are two
receivers. When the interference is large and independent across users we show
that time-sharing is again optimal. Connections to the problem of robust dirty
paper coding are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511096</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511096</id><created>2005-11-28</created><authors><author><keyname>Kang</keyname><forenames>W.</forenames></author><author><keyname>Ulukus</keyname><forenames>S.</forenames></author></authors><title>A Single-letter Upper Bound for the Sum Rate of Multiple Access Channels
  with Correlated Sources</title><categories>cs.IT math.IT</categories><comments>5 pages, pdf file, Proc. 39th Asilomar Conf. on Signals, Systems and
  Computers</comments><acm-class>H.1.1</acm-class><abstract>  The capacity region of the multiple access channel with arbitrarily
correlated sources remains an open problem. Cover, El Gamal and Salehi gave an
achievable region in the form of single-letter entropy and mutual information
expressions, without a single-letter converse. Cover, El Gamal and Salehi also
gave a converse in terms of some n-letter mutual informations, which are
incomputable. In this paper, we derive an upper bound for the sum rate of this
channel in a single-letter expression by using spectrum analysis. The
incomputability of the sum rate of Cover, El Gamal and Salehi scheme comes from
the difficulty of characterizing the possible joint distributions for the
n-letter channel inputs. Here we introduce a new data processing inequality,
which leads to a single-letter necessary condition for these possible joint
distributions. We develop a single-letter upper bound for the sum rate by using
this single-letter necessary condition on the possible joint distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511097</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511097</id><created>2005-11-28</created><updated>2006-01-16</updated><authors><author><keyname>Hardin</keyname><forenames>Christopher</forenames></author></authors><title>Modularizing the Elimination of r=0 in Kleene Algebra</title><categories>cs.LO</categories><acm-class>F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 3 (December
  21, 2005) lmcs:1128</journal-ref><doi>10.2168/LMCS-1(3:4)2005</doi><abstract>  Given a universal Horn formula of Kleene algebra with hypotheses of the form
r = 0, it is already known that we can efficiently construct an equation which
is valid if and only if the Horn formula is valid. This is an example of
&lt;i&gt;elimination of hypotheses&lt;/i&gt;, which is useful because the equational theory
of Kleene algebra is decidable while the universal Horn theory is not. We show
that hypotheses of the form r = 0 can still be eliminated in the presence of
other hypotheses. This lets us extend any technique for eliminating hypotheses
to include hypotheses of the form r = 0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511098</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511098</id><created>2005-11-29</created><authors><author><keyname>Yee</keyname><forenames>Kenton K.</forenames></author></authors><title>Information and Stock Prices: A Simple Introduction</title><categories>cs.CY cs.IT math.IT nlin.AO physics.soc-ph</categories><comments>http://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=240309
  contains background references</comments><report-no>http://www.columbia.edu/~kky2001/</report-no><acm-class>H.2; H.3; H.4; K.5</acm-class><abstract>  This article summarizes recent research in financial economics about why
information, such as earnings announcements, moves stock prices. The article
does not presume any prior exposure to finance beyond what you might read in
newspapers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511099</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511099</id><created>2005-11-29</created><authors><author><keyname>Li</keyname><forenames>Na</forenames></author><author><keyname>Qi</keyname><forenames>Wen-feng</forenames></author></authors><title>Symmetric Boolean Function with Maximum Algebraic Immunity on Odd Number
  of Variables</title><categories>cs.CR</categories><abstract>  To resist algebraic attack, a Boolean function should possess good algebraic
immunity (AI). Several papers constructed symmetric functions with the maximum
algebraic immunity $\lceil \frac{n}{2}\rceil $. In this correspondence we prove
that for each odd $n$, there is exactly one trivial balanced $n$-variable
symmetric Boolean function achieving the algebraic immunity $\lceil
\frac{n}{2}\rceil $. And we also obtain a necessary condition for the algebraic
normal form of a symmetric Boolean function with maximum algebraic immunity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511100</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511100</id><created>2005-11-29</created><authors><author><keyname>Rathi</keyname><forenames>Vishwambhar</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>Density Evolution, Thresholds and the Stability Condition for Non-binary
  LDPC Codes</title><categories>cs.IT math.IT</categories><comments>To appear in IEE Proc. Communications, December, 2005</comments><abstract>  We derive the density evolution equations for non-binary low-density
parity-check (LDPC) ensembles when transmission takes place over the binary
erasure channel. We introduce ensembles defined with respect to the general
linear group over the binary field. For these ensembles the density evolution
equations can be written compactly. The density evolution for the general
linear group helps us in understanding the density evolution for codes defined
with respect to finite fields. We compute thresholds for different alphabet
sizes for various LDPC ensembles. Surprisingly, the threshold is not a
monotonic function of the alphabet size. We state the stability condition for
non-binary LDPC ensembles over any binary memoryless symmetric channel. We also
give upper bounds on the MAP thresholds for various non-binary ensembles based
on EXIT curves and the area theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511101</identifier>
 <datestamp>2007-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511101</id><created>2005-11-29</created><updated>2006-12-04</updated><authors><author><keyname>Zhou</keyname><forenames>Shi</forenames></author><author><keyname>Zhang</keyname><forenames>Guo-Qiang</forenames></author><author><keyname>Zhang</keyname><forenames>Guo-Qing</forenames></author></authors><title>Chinese Internet AS-level Topology</title><categories>cs.NI</categories><comments>This paper is a preprint of a paper submitted to IEE Proceedings on
  Communications and is subject to Institution of Engineering and Technology
  Copyright. If accepted, the copy of record will be available at IET Digital
  Library</comments><acm-class>C.2.1</acm-class><journal-ref>IET Communications, vol.1, no.2, pp.209-214, 2007</journal-ref><doi>10.1049/iet-com:20060518</doi><abstract>  We present the first complete measurement of the Chinese Internet topology at
the autonomous systems (AS) level based on traceroute data probed from servers
of major ISPs in mainland China. We show that both the Chinese Internet AS
graph and the global Internet AS graph can be accurately reproduced by the
Positive-Feedback Preference (PFP) model with the same parameters. This result
suggests that the Chinese Internet preserves well the topological
characteristics of the global Internet. This is the first demonstration of the
Internet's topological fractality, or self-similarity, performed at the level
of topology evolution modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511102</id><created>2005-11-29</created><authors><author><keyname>Leguay</keyname><forenames>Jeremie</forenames></author><author><keyname>Friedman</keyname><forenames>Timur</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author></authors><title>Evaluating Mobility Pattern Space Routing for DTNs</title><categories>cs.NI</categories><comments>IEEE INFOCOM 2006 preprint</comments><abstract>  Because a delay tolerant network (DTN) can often be partitioned, the problem
of routing is very challenging. However, routing benefits considerably if one
can take advantage of knowledge concerning node mobility. This paper addresses
this problem with a generic algorithm based on the use of a high-dimensional
Euclidean space, that we call MobySpace, constructed upon nodes' mobility
patterns. We provide here an analysis and the large scale evaluation of this
routing scheme in the context of ambient networking by replaying real mobility
traces. The specific MobySpace evaluated is based on the frequency of visit of
nodes for each possible location. We show that the MobySpace can achieve good
performance compared to that of the other algorithms we implemented, especially
when we perform routing on the nodes that have a high connection time. We
determine that the degree of homogeneity of mobility patterns of nodes has a
high impact on routing. And finally, we study the ability of nodes to learn
their own mobility patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511103</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511103</id><created>2005-11-29</created><authors><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author></authors><title>An Infeasibility Result for the Multiterminal Source-Coding Problem</title><categories>cs.IT math.IT</categories><comments>42 pages; submitted to IEEE Trans. Inf. Theory</comments><acm-class>H.1.1; E.4</acm-class><abstract>  We prove a new outer bound on the rate-distortion region for the
multiterminal source-coding problem. This bound subsumes the best outer bound
in the literature and improves upon it strictly in some cases. The improved
bound enables us to obtain a new, conclusive result for the binary erasure
version of the &quot;CEO problem.&quot; The bound recovers many of the converse results
that have been established for special cases of the problem, including the
recent one for the Gaussian version of the CEO problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511104</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511104</id><created>2005-11-29</created><authors><author><keyname>Kakavand</keyname><forenames>Hossein</forenames></author></authors><title>Channel Model and Upper Bound on the Information Capacity of the Fiber
  Optical Communication Channel Based on the Effects of XPM Induced
  Nonlinearity</title><categories>cs.IT math.IT</categories><comments>10 pages, 43rd Annual Allerton Conference on Communication, Control
  and Computing, Monticello, IL, USA, Sept. 28-30, 2005</comments><abstract>  An upper bound to the information capacity of a wavelength-division multi-
plexed optical fiber communication system is derived in a model incorporating
the nonlinear propagation effects of cross-phase modulation (XPM). This work is
based on the paper by Mitra et al., finding lower bounds to the channel
capacity, in which physical models for propagation are used to calculate
statistical properties of the conditional probability distribution relating
input and output in a single WDM channel. In this paper we present a tractable
channel model incorporating the effects of cross phase modulation. Using this
model we find an upper bound to the information capacity of the fiber optical
communication channel at high SNR. The results provide physical insight into
the manner in which nonlinearities degrade the information capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511105</id><created>2005-11-30</created><authors><author><keyname>Boczko</keyname><forenames>Erik M.</forenames></author><author><keyname>Young</keyname><forenames>Todd R.</forenames></author></authors><title>The Signed Distance Function: A New Tool for Binary Classification</title><categories>cs.LG cs.CG</categories><comments>13 pages, 5 figures</comments><abstract>  From a geometric perspective most nonlinear binary classification algorithms,
including state of the art versions of Support Vector Machine (SVM) and Radial
Basis Function Network (RBFN) classifiers, and are based on the idea of
reconstructing indicator functions. We propose instead to use reconstruction of
the signed distance function (SDF) as a basis for binary classification. We
discuss properties of the signed distance function that can be exploited in
classification algorithms. We develop simple versions of such classifiers and
test them on several linear and nonlinear problems. On linear tests accuracy of
the new algorithm exceeds that of standard SVM methods, with an average of 50%
fewer misclassifications. Performance of the new methods also matches or
exceeds that of standard methods on several nonlinear problems including
classification of benchmark diagnostic micro-array data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511106</id><created>2005-11-30</created><authors><author><keyname>Chelcea</keyname><forenames>Sergiu Theodor</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Da Silva</keyname><forenames>Alzennyr</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Lechevallier</keyname><forenames>Yves</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Tanasa</keyname><forenames>Doru</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Trousse</keyname><forenames>Brigitte</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>Benefits of InterSite Pre-Processing and Clustering Methods in
  E-Commerce Domain</title><categories>cs.DB</categories><proxy>ccsd inria-00000880</proxy><journal-ref>Dans Proceedings of the ECML/PKDD2005 Discovery Challenge, A
  Collaborative Effort in Knowledge Discovery from Databases</journal-ref><abstract>  This paper presents our preprocessing and clustering analysis on the
clickstream dataset proposed for the ECMLPKDD 2005 Discovery Challenge. The
main contributions of this article are double. First, after presenting the
clickstream dataset, we show how we build a rich data warehouse based an
advanced preprocesing. We take into account the intersite aspects in the given
ecommerce domain, which offers an interesting data structuration. A preliminary
statistical analysis based on time period clickstreams is given, emphasing the
importance of intersite user visits in such a context. Secondly, we describe
our crossed-clustering method which is applied on data generated from our data
warehouse. Our preliminary results are interesting and promising illustrating
the benefits of our WUM methods, even if more investigations are needed on the
same dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511107</id><created>2005-11-30</created><authors><author><keyname>Esteve</keyname><forenames>J. G.</forenames></author><author><keyname>Falceto</keyname><forenames>F.</forenames></author></authors><title>Phase transition in the assignment problem for random matrices</title><categories>cs.CC cond-mat.stat-mech</categories><comments>7 pages, 5 figures; accepted for publication in Europhys. Lett.
  http://www.edpsciences.org/journal/index.cfm?edpsname=epl</comments><doi>10.1209/epl/i2005-10296-6</doi><abstract>  We report an analytic and numerical study of a phase transition in a P
problem (the assignment problem) that separates two phases whose
representatives are the simple matching problem (an easy P problem) and the
traveling salesman problem (a NP-complete problem). Like other phase
transitions found in combinatoric problems (K-satisfiability, number
partitioning) this can help to understand the nature of the difficulties in
solving NP problems an to find more accurate algorithms for them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0511108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0511108</id><created>2005-11-30</created><authors><author><keyname>Benabdallah</keyname><forenames>A.</forenames></author><author><keyname>Radons</keyname><forenames>G.</forenames></author></authors><title>Parameter Estimation of Hidden Diffusion Processes: Particle Filter vs.
  Modified Baum-Welch Algorithm</title><categories>cs.DS cs.LG</categories><comments>15 pages, 3 figures, 2 tables</comments><acm-class>F.2.1; J.2</acm-class><abstract>  We propose a new method for the estimation of parameters of hidden diffusion
processes. Based on parametrization of the transition matrix, the Baum-Welch
algorithm is improved. The algorithm is compared to the particle filter in
application to the noisy periodic systems. It is shown that the modified
Baum-Welch algorithm is capable of estimating the system parameters with better
accuracy than particle filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512001</id><created>2005-11-30</created><authors><author><keyname>Carroll</keyname><forenames>Jeremy</forenames><affiliation>HP Laboratories, Bristol, UK</affiliation></author><author><keyname>Ruskey</keyname><forenames>Frank</forenames><affiliation>University of Victoria, Canada</affiliation></author><author><keyname>Weston</keyname><forenames>Mark</forenames><affiliation>University of Victoria, Canada</affiliation></author></authors><title>Which n-Venn diagrams can be drawn with convex k-gons?</title><categories>cs.CG</categories><comments>10 pages, 3 figures. To be published in Proceedings of the Second
  International Workshop on Euler Diagrams (Euler 2005), Electronic Notes in
  Theoretical Computer Science</comments><acm-class>I.3.5</acm-class><abstract>  We establish a new lower bound for the number of sides required for the
component curves of simple Venn diagrams made from polygons. Specifically, for
any n-Venn diagram of convex k-gons, we prove that k &gt;= (2^n - 2 - n) / (n
(n-2)). In the process we prove that Venn diagrams of seven curves, simple or
not, cannot be formed from triangles. We then give an example achieving the new
lower bound of a (simple, symmetric) Venn diagram of seven quadrilaterals.
Previously Grunbaum had constructed a 7-Venn diagram of non-convex 5-gons
[``Venn Diagrams II'', Geombinatorics 2:25-31, 1992].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512002</id><created>2005-11-30</created><authors><author><keyname>Ramos</keyname><forenames>Vitorino</forenames></author><author><keyname>Fernandes</keyname><forenames>Carlos</forenames></author><author><keyname>Rosa</keyname><forenames>Agostinho C.</forenames></author></authors><title>On Self-Regulated Swarms, Societal Memory, Speed and Dynamics</title><categories>cs.NE cs.AI</categories><comments>11 pages, 8 figures,
  http://alfa.ist.utl.pt/~cvrm/staff/vramos/refs_2005.html, KEYWORDS: Dynamic
  Optimization, Dynamic Optimal Control problems, Swarm Intelligence,
  Self-Organization, Societal Implicit Memory. Submitted to ALIFE-X, Int. Conf.
  on the Simulation and Synthesis of Living Systems, Bloomington, Indiana, USA,
  June 3-7, 2006</comments><acm-class>I.2.11; G.1.6; I.2.9</acm-class><abstract>  We propose a Self-Regulated Swarm (SRS) algorithm which hybridizes the
advantageous characteristics of Swarm Intelligence as the emergence of a
societal environmental memory or cognitive map via collective pheromone laying
in the landscape (properly balancing the exploration/exploitation nature of our
dynamic search strategy), with a simple Evolutionary mechanism that trough a
direct reproduction procedure linked to local environmental features is able to
self-regulate the above exploratory swarm population, speeding it up globally.
In order to test his adaptive response and robustness, we have recurred to
different dynamic multimodal complex functions as well as to Dynamic
Optimization Control problems, measuring reaction speeds and performance. Final
comparisons were made with standard Genetic Algorithms (GAs), Bacterial
Foraging strategies (BFOA), as well as with recent Co-Evolutionary approaches.
SRS's were able to demonstrate quick adaptive responses, while outperforming
the results obtained by the other approaches. Additionally, some successful
behaviors were found. One of the most interesting illustrate that the present
SRS collective swarm of bio-inspired ant-like agents is able to track about 65%
of moving peaks traveling up to ten times faster than the velocity of a single
individual composing that precise swarm tracking system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512003</id><created>2005-11-30</created><authors><author><keyname>Ramos</keyname><forenames>Vitorino</forenames></author><author><keyname>Fernandes</keyname><forenames>Carlos</forenames></author><author><keyname>Rosa</keyname><forenames>Agostinho C.</forenames></author></authors><title>Societal Implicit Memory and his Speed on Tracking Extrema over Dynamic
  Environments using Self-Regulatory Swarms</title><categories>cs.MA cs.AI</categories><comments>20 pages, 25 figures, http://alfa.ist.utl.pt/~cvrm/staff/vramos .
  Draft submitted to Journal of Systems Architecture, Farooq M. and Menezes R.
  (Eds.), Special issue on Nature Inspired Applied Systems, Elsevier, 2006</comments><acm-class>I.2.11; G.1.6; I.2.9</acm-class><abstract>  In order to overcome difficult dynamic optimization and environment extrema
tracking problems, We propose a Self-Regulated Swarm (SRS) algorithm which
hybridizes the advantageous characteristics of Swarm Intelligence as the
emergence of a societal environmental memory or cognitive map via collective
pheromone laying in the landscape (properly balancing the
exploration/exploitation nature of our dynamic search strategy), with a simple
Evolutionary mechanism that trough a direct reproduction procedure linked to
local environmental features is able to self-regulate the above exploratory
swarm population, speeding it up globally. In order to test his adaptive
response and robustness, we have recurred to different dynamic multimodal
complex functions as well as to Dynamic Optimization Control problems,
measuring reaction speeds and performance. Final comparisons were made with
standard Genetic Algorithms (GAs), Bacterial Foraging strategies (BFOA), as
well as with recent Co-Evolutionary approaches. SRS's were able to demonstrate
quick adaptive responses, while outperforming the results obtained by the other
approaches. Additionally, some successful behaviors were found. One of the most
interesting illustrate that the present SRS collective swarm of bio-inspired
ant-like agents is able to track about 65% of moving peaks traveling up to ten
times faster than the velocity of a single individual composing that precise
swarm tracking system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512004</id><created>2005-11-30</created><authors><author><keyname>Fernandes</keyname><forenames>Carlos</forenames></author><author><keyname>Ramos</keyname><forenames>Vitorino</forenames></author><author><keyname>Rosa</keyname><forenames>Agostinho C.</forenames></author></authors><title>Self-Regulated Artificial Ant Colonies on Digital Image Habitats</title><categories>cs.MA cs.AI</categories><comments>8 pages, 17 figures, full pictures in
  http://alfa.ist.utl.pt/~cvrm/staff/vramos/Vramos-WCLC05b.pdf</comments><acm-class>I.2.11; I.2.9; I.3.3; I.4; I.4.10; I.4.6; I.4.9; I.5.4</acm-class><journal-ref>in International Journal of Lateral Computing, IJLC, vol. 2 (1),
  pp. 1-8, ISSN 0973-208X, Dec. 2005</journal-ref><abstract>  Artificial life models, swarm intelligent and evolutionary computation
algorithms are usually built on fixed size populations. Some studies indicate
however that varying the population size can increase the adaptability of these
systems and their capability to react to changing environments. In this paper
we present an extended model of an artificial ant colony system designed to
evolve on digital image habitats. We will show that the present swarm can adapt
the size of the population according to the type of image on which it is
evolving and reacting faster to changing images, thus converging more rapidly
to the new desired regions, regulating the number of his image foraging agents.
Finally, we will show evidences that the model can be associated with the
Mathematical Morphology Watershed algorithm to improve the segmentation of
digital grey-scale images. KEYWORDS: Swarm Intelligence, Perception and Image
Processing, Pattern Recognition, Mathematical Morphology, Social Cognitive
Maps, Social Foraging, Self-Organization, Distributed Search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512005</id><created>2005-11-30</created><authors><author><keyname>Ramos</keyname><forenames>Vitorino</forenames></author><author><keyname>Fernandes</keyname><forenames>Carlos</forenames></author><author><keyname>Rosa</keyname><forenames>Agostinho C.</forenames></author></authors><title>On Ants, Bacteria and Dynamic Environments</title><categories>cs.DC</categories><comments>8 pages, 6 figures, full paper with pictures in
  http://alfa.ist.utl.pt/~cvrm/staff/vramos/ref_63.html, keywords: Swarm
  Intelligence and Perception, Social Cognitive Maps, Social Foraging,
  Self-Organization, Distributed Search and Optimization in Dynamic
  Environments. In NCA-05, Natural Computing and Applications Workshop, IEEE
  Computer Press, Timisoara, Romania, Sep. 25-29, 2005</comments><abstract>  Wasps, bees, ants and termites all make effective use of their environment
and resources by displaying collective swarm intelligence. Termite colonies -
for instance - build nests with a complexity far beyond the comprehension of
the individual termite, while ant colonies dynamically allocate labor to
various vital tasks such as foraging or defense without any central
decision-making ability. Recent research suggests that microbial life can be
even richer: highly social, intricately networked, and teeming with
interactions, as found in bacteria. What strikes from these observations is
that both ant colonies and bacteria have similar natural mechanisms based on
Stigmergy and Self-Organization in order to emerge coherent and sophisticated
patterns of global behaviour. Keeping in mind the above characteristics we will
present a simple model to tackle the collective adaptation of a social swarm
based on real ant colony behaviors (SSA algorithm) for tracking extrema in
dynamic environments and highly multimodal complex functions described in the
well-know De Jong test suite. Then, for the purpose of comparison, a recent
model of artificial bacterial foraging (BFOA algorithm) based on similar
stigmergic features is described and analyzed. Final results indicate that the
SSA collective intelligence is able to cope and quickly adapt to unforeseen
situations even when over the same cooperative foraging period, the community
is requested to deal with two different and contradictory purposes, while
outperforming BFOA in adaptive speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512006</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512006</id><created>2005-12-01</created><authors><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>Capacity-Achieving Ensembles of Accumulate-Repeat-Accumulate Codes for
  the Erasure Channel with Bounded Complexity</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory, December 1st, 2005.
  Includes 50 pages and 13 figures</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 53 (6), pp.
  2088-2115, June 2007</journal-ref><doi>10.1109/TIT.2007.896873</doi><abstract>  The paper introduces ensembles of accumulate-repeat-accumulate (ARA) codes
which asymptotically achieve capacity on the binary erasure channel (BEC) with
{\em bounded complexity}, per information bit, of encoding and decoding. It
also introduces symmetry properties which play a central role in the
construction of capacity-achieving ensembles for the BEC with bounded
complexity. The results here improve on the tradeoff between performance and
complexity provided by previous constructions of capacity-achieving ensembles
of codes defined on graphs. The superiority of ARA codes with moderate to large
block length is exemplified by computer simulations which compare their
performance with those of previously reported capacity-achieving ensembles of
LDPC and IRA codes. The ARA codes also have the advantage of being systematic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512007</id><created>2005-12-01</created><authors><author><keyname>Mitra</keyname><forenames>Arindam</forenames></author></authors><title>Entangled messages</title><categories>cs.CR cs.IR</categories><comments>PDF, 2 Pages</comments><abstract>  It is sometimes necessary to send copies of the same email to different
parties, but it is impossible to ensure that if one party reads the message the
other parties will bound to read it. We propose an entanglement based scheme
where if one party reads the message the other party will bound to read it
simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512008</id><created>2005-12-01</created><updated>2005-12-02</updated><authors><author><keyname>Friedman</keyname><forenames>Joel</forenames></author></authors><title>Cohomology in Grothendieck Topologies and Lower Bounds in Boolean
  Complexity</title><categories>cs.CC math.AG</categories><comments>70 pages, abstract corrected and modified</comments><abstract>  This paper is motivated by questions such as P vs. NP and other questions in
Boolean complexity theory. We describe an approach to attacking such questions
with cohomology, and we show that using Grothendieck topologies and other ideas
from the Grothendieck school gives new hope for such an attack.
  We focus on circuit depth complexity, and consider only finite topological
spaces or Grothendieck topologies based on finite categories; as such, we do
not use algebraic geometry or manifolds.
  Given two sheaves on a Grothendieck topology, their &quot;cohomological
complexity&quot; is the sum of the dimensions of their Ext groups. We seek to model
the depth complexity of Boolean functions by the cohomological complexity of
sheaves on a Grothendieck topology. We propose that the logical AND of two
Boolean functions will have its corresponding cohomological complexity bounded
in terms of those of the two functions using ``virtual zero extensions.'' We
propose that the logical negation of a function will have its corresponding
cohomological complexity equal to that of the original function using duality
theory. We explain these approaches and show that they are stable under
pullbacks and base change. It is the subject of ongoing work to achieve AND and
negation bounds simultaneously in a way that yields an interesting depth lower
bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512009</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512009</id><created>2005-12-02</created><updated>2008-10-07</updated><authors><author><keyname>Spitters</keyname><forenames>Bas</forenames></author></authors><title>Almost periodic functions, constructively</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 3 (December
  20, 2005) lmcs:712</journal-ref><doi>10.2168/LMCS-1(3:3)2005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The almost periodic functions form a natural example of a non-separable
normed space. As such, it has been a challenge for constructive mathematicians
to find a natural treatment of them. Here we present a simple proof of Bohr's
fundamental theorem for almost periodic functions which we then generalize to
almost periodic functions on general topological groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512010</id><created>2005-12-02</created><authors><author><keyname>Gratus</keyname><forenames>Jonathan</forenames></author><author><keyname>Porter</keyname><forenames>Timothy</forenames></author></authors><title>A geometry of information, I: Nerves, posets and differential forms</title><categories>cs.AI cs.GR</categories><comments>28 pages. A version of this paper appears also on the Dagstuhl
  seminar portal http://drops.dagstuhl.de/portals/04351/</comments><abstract>  The main theme of this workshop (Dagstuhl seminar 04351) is `Spatial
Representation: Continuous vs. Discrete'. Spatial representation has two
contrasting but interacting aspects (i) representation of spaces' and (ii)
representation by spaces. In this paper, we will examine two aspects that are
common to both interpretations of the theme, namely nerve constructions and
refinement. Representations change, data changes, spaces change. We will
examine the possibility of a `differential geometry' of spatial representations
of both types, and in the sequel give an algebra of differential forms that has
the potential to handle the dynamical aspect of such a geometry. We will
discuss briefly a conjectured class of spaces, generalising the Cantor set
which would seem ideal as a test-bed for the set of tools we are developing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512011</id><created>2005-12-02</created><updated>2006-07-13</updated><authors><author><keyname>Zhou</keyname><forenames>Shi</forenames></author></authors><title>Understanding the internet topology evolution dynamics</title><categories>cs.NI</categories><comments>15 figures</comments><acm-class>C.2.1</acm-class><journal-ref>Physical Review E, vol. 70, no. 016124, July 2006.</journal-ref><doi>10.1103/PhysRevE.74.016124</doi><abstract>  The internet structure is extremely complex. The Positive-Feedback Preference
(PFP) model is a recently introduced internet topology generator. The model
uses two generic algorithms to replicate the evolution dynamics observed on the
internet historic data. The phenomenological model was originally designed to
match only two topology properties of the internet, i.e. the rich-club
connectivity and the exact form of degree distribution. Whereas numerical
evaluation has shown that the PFP model accurately reproduces a large set of
other nontrivial characteristics as well. This paper aims to investigate why
and how this generative model captures so many diverse properties of the
internet. Based on comprehensive simulation results, the paper presents a
detailed analysis on the exact origin of each of the topology properties
produced by the model. This work reveals how network evolution mechanisms
control the obtained topology properties and it also provides insights on
correlations between various structural characteristics of complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512012</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512012</id><created>2005-12-02</created><updated>2006-03-10</updated><authors><author><keyname>Dongol</keyname><forenames>Brijesh</forenames></author><author><keyname>Goldson</keyname><forenames>Doug</forenames></author></authors><title>Extending the theory of Owicki and Gries with a logic of progress</title><categories>cs.LO</categories><acm-class>D.2.4; D.3.1; F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 1 (March 10,
  2006) lmcs:767</journal-ref><doi>10.2168/LMCS-2(1:6)2006</doi><abstract>  This paper describes a logic of progress for concurrent programs. The logic
is based on that of UNITY, molded to fit a sequential programming model.
Integration of the two is achieved by using auxiliary variables in a systematic
way that incorporates program counters into the program text. The rules for
progress in UNITY are then modified to suit this new system. This modification
is however subtle enough to allow the theory of Owicki and Gries to be used
without change.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512013</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512013</id><created>2005-12-03</created><authors><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>The Water-Filling Game in Fading Multiple Access Channels</title><categories>cs.IT math.IT</categories><comments>26 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  We adopt a game theoretic approach for the design and analysis of distributed
resource allocation algorithms in fading multiple access channels. The users
are assumed to be selfish, rational, and limited by average power constraints.
We show that the sum-rate optimal point on the boundary of the multipleaccess
channel capacity region is the unique Nash Equilibrium of the corresponding
water-filling game. This result sheds a new light on the opportunistic
communication principle and argues for the fairness of the sum-rate optimal
point, at least from a game theoretic perspective. The base-station is then
introduced as a player interested in maximizing a weighted sum of the
individual rates. We propose a Stackelberg formulation in which the
base-station is the designated game leader. In this set-up, the base-station
announces first its strategy defined as the decoding order of the different
users, in the successive cancellation receiver, as a function of the channel
state. In the second stage, the users compete conditioned on this particular
decoding strategy. We show that this formulation allows for achieving all the
corner points of the capacity region, in addition to the sum-rate optimal
point. On the negative side, we prove the non-existence of a base-station
strategy in this formulation that achieves the rest of the boundary points. To
overcome this limitation, we present a repeated game approach which achieves
the capacity region of the fading multiple access channel. Finally, we extend
our study to vector channels highlighting interesting differences between this
scenario and the scalar channel case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512014</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512014</id><created>2005-12-03</created><authors><author><keyname>Meshkati</keyname><forenames>Farhad</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Schwartz</keyname><forenames>Stuart C.</forenames></author></authors><title>A Game-Theoretic Approach to Energy-Efficient Power Control in
  Multi-Carrier CDMA Systems</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Journal on Selected Areas in Communications
  (JSAC) special issue on advances in multi-carrier CDMA</comments><abstract>  A game-theoretic model for studying power control in multi-carrier CDMA
systems is proposed. Power control is modeled as a non-cooperative game in
which each user decides how much power to transmit over each carrier to
maximize its own utility. The utility function considered here measures the
number of reliable bits transmitted over all the carriers per Joule of energy
consumed and is particularly suitable for networks where energy efficiency is
important. The multi-dimensional nature of users' strategies and the
non-quasiconcavity of the utility function make the multi-carrier problem much
more challenging than the single-carrier or throughput-based-utility case. It
is shown that, for all linear receivers including the matched filter, the
decorrelator, and the minimum-mean-square-error (MMSE) detector, a user's
utility is maximized when the user transmits only on its &quot;best&quot; carrier. This
is the carrier that requires the least amount of power to achieve a particular
target signal-to-interference-plus-noise ratio (SINR) at the output of the
receiver. The existence and uniqueness of Nash equilibrium for the proposed
power control game are studied. In particular, conditions are given that must
be satisfied by the channel gains for a Nash equilibrium to exist, and the
distribution of the users among the carriers at equilibrium is also
characterized. In addition, an iterative and distributed algorithm for reaching
the equilibrium (when it exists) is presented. It is shown that the proposed
approach results in significant improvements in the total utility achieved at
equilibrium compared to a single-carrier system and also to a multi-carrier
system in which each user maximizes its utility over each carrier
independently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512015</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512015</id><created>2005-12-03</created><updated>2007-05-17</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Joint fixed-rate universal lossy coding and identification of
  continuous-alphabet memoryless sources</title><categories>cs.IT cs.LG math.IT</categories><comments>28 pages, 2 eps figures; revised version submitted to IEEE Trans.
  Inform. Theory</comments><abstract>  The problem of joint universal source coding and identification is considered
in the setting of fixed-rate lossy coding of continuous-alphabet memoryless
sources. For a wide class of bounded distortion measures, it is shown that any
compactly parametrized family of $\R^d$-valued i.i.d. sources with absolutely
continuous distributions satisfying appropriate smoothness and
Vapnik--Chervonenkis learnability conditions, admits a joint scheme for
universal lossy block coding and parameter estimation, such that when the block
length $n$ tends to infinity, the overhead per-letter rate and the distortion
redundancies converge to zero as $O(n^{-1}\log n)$ and $O(\sqrt{n^{-1}\log
n})$, respectively. Moreover, the active source can be determined at the
decoder up to a ball of radius $O(\sqrt{n^{-1} \log n})$ in variational
distance, asymptotically almost surely. The system has finite memory length
equal to the block length, and can be thought of as blockwise application of a
time-invariant nonlinear filter with initial conditions determined from the
previous block. Comparisons are presented with several existing schemes for
universal vector quantization, which do not include parameter estimation
explicitly, and an extension to unbounded distortion measures is outlined.
Finally, finite mixture classes and exponential families are given as explicit
examples of parametric sources admitting joint universal compression and
modeling schemes of the kind studied here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512016</id><created>2005-12-03</created><updated>2006-03-11</updated><authors><author><keyname>Cs&#x171;r&#xf6;s</keyname><forenames>Mikl&#xf3;s</forenames></author></authors><title>A linear-time algorithm for finding the longest segment which scores
  above a given threshold</title><categories>cs.DS cs.CE</categories><acm-class>F.2.2; G.2; J.3</acm-class><abstract>  This paper describes a linear-time algorithm that finds the longest stretch
in a sequence of real numbers (``scores'') in which the sum exceeds an input
parameter. The algorithm also solves the problem of finding the longest
interval in which the average of the scores is above a fixed threshold. The
problem originates from molecular sequence analysis: for instance, the
algorithm can be employed to identify long GC-rich regions in DNA sequences.
The algorithm can also be used to trim low-quality ends of shotgun sequences in
a preprocessing step of whole-genome assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512017</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512017</id><created>2005-12-05</created><updated>2005-12-06</updated><authors><author><keyname>Tavildar</keyname><forenames>Saurabha</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Approximately Universal Codes over Slow Fading Channels</title><categories>cs.IT math.IT</categories><comments>Revised version. Accepted for IEEE Transactions on Information Theory</comments><abstract>  Performance of reliable communication over a coherent slow fading channel at
high SNR is succinctly captured as a fundamental tradeoff between diversity and
multiplexing gains. We study the problem of designing codes that optimally
tradeoff the diversity and multiplexing gains. Our main contribution is a
precise characterization of codes that are universally tradeoff-optimal, i.e.,
they optimally tradeoff the diversity and multiplexing gains for every
statistical characterization of the fading channel. We denote this
characterization as one of approximate universality where the approximation is
in the connection between error probability and outage capacity with diversity
and multiplexing gains, respectively. The characterization of approximate
universality is then used to construct new coding schemes as well as to show
optimality of several schemes proposed in the space-time coding literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512018</id><created>2005-12-05</created><updated>2006-03-21</updated><authors><author><keyname>Mouraud</keyname><forenames>Anthony</forenames><affiliation>GRIMAAG, ISC</affiliation></author><author><keyname>Puzenat</keyname><forenames>Didier</forenames><affiliation>GRIMAAG</affiliation></author><author><keyname>Paugam-Moisy</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>ISC</affiliation></author></authors><title>DAMNED: A Distributed and Multithreaded Neural Event-Driven simulation
  framework</title><categories>cs.NE cs.LG</categories><comments>6 pages</comments><proxy>ccsd ccsd-00015137</proxy><abstract>  In a Spiking Neural Networks (SNN), spike emissions are sparsely and
irregularly distributed both in time and in the network architecture. Since a
current feature of SNNs is a low average activity, efficient implementations of
SNNs are usually based on an Event-Driven Simulation (EDS). On the other hand,
simulations of large scale neural networks can take advantage of distributing
the neurons on a set of processors (either workstation cluster or parallel
computer). This article presents DAMNED, a large scale SNN simulation framework
able to gather the benefits of EDS and parallel computing. Two levels of
parallelism are combined: Distributed mapping of the neural topology, at the
network level, and local multithreaded allocation of resources for simultaneous
processing of events, at the neuron level. Based on the causality of events, a
distributed solution is proposed for solving the complex problem of scheduling
without synchronization barrier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512019</id><created>2005-12-05</created><authors><author><keyname>Gutowski</keyname><forenames>Marek W.</forenames></author></authors><title>Amazing geometry of genetic space or are genetic algorithms convergent?</title><categories>cs.NE cs.DM cs.SE</categories><comments>7 pages, presented on VII KAEiOG (VII Domestic Conference on
  Evolutionary Algorithms and Global Optimization), May 24-26, 2004, Kazimierz
  Dolny, Poland</comments><acm-class>F.2.2; G.1.6; G.4; I.1.2</acm-class><abstract>  There is no proof yet of convergence of Genetic Algorithms. We do not supply
it too. Instead, we present some thoughts and arguments to convince the Reader,
that Genetic Algorithms are essentially bound for success. For this purpose, we
consider only the crossover operators, single- or multiple-point, together with
selection procedure. We also give a proof that the soft selection is superior
to other selection schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512020</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512020</id><created>2005-12-05</created><authors><author><keyname>Sarshar</keyname><forenames>Nima</forenames></author><author><keyname>Wu</keyname><forenames>Xiaolin</forenames></author></authors><title>A Practical Approach to Joint Network-Source Coding</title><categories>cs.IT math.IT</categories><comments>submitted to Data Compression Conference, 2006</comments><abstract>  We are interested in how to best communicate a real valued source to a number
of destinations (sinks) over a network with capacity constraints in a
collective fidelity metric over all the sinks, a problem which we call joint
network-source coding. It is demonstrated that multiple description codes along
with proper diversity routing provide a powerful solution to joint
network-source coding. A systematic optimization approach is proposed. It
consists of optimizing the network routing given a multiple description code
and designing optimal multiple description code for the corresponding optimized
routes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512021</id><created>2005-12-05</created><authors><author><keyname>Hamid</keyname><forenames>Brahim</forenames><affiliation>LaBRI University of Bordeaux-1 France</affiliation></author><author><keyname>Herman</keyname><forenames>Ted</forenames><affiliation>University of Iowa</affiliation></author><author><keyname>Mjelde</keyname><forenames>Morten</forenames><affiliation>University in Bergen Norway</affiliation></author></authors><title>The Poster Session of SSS 2005</title><categories>cs.DC cs.DS</categories><comments>3 pages, related to Springer LNCS 3764, Proceedings of Symposium on
  Self-Stabilizing Systems</comments><report-no>TR-05-13</report-no><acm-class>D.4.5</acm-class><abstract>  This technical report documents the poster session of SSS 2005, the Symposium
on Self-Stabilizing Systems published by Springer as LNCS volume 3764. The
poster session included five presentations. Two of these presentations are
summarized in brief abstracts contained in this technical report.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512022</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512022</id><created>2005-12-05</created><authors><author><keyname>Mello</keyname><forenames>Louis</forenames></author></authors><title>Fat Tailed Distributions in Catastrophe Prediction</title><categories>cs.OH</categories><abstract>  This paper discusses the use of fat-tailed distributions in catastrophe
prediction as opposed to the more common use of the Normal Distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512023</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512023</id><created>2005-12-05</created><authors><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Sethuraman</keyname><forenames>B. A.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Perfect Space-Time Codes with Minimum and Non-Minimum Delay for Any
  Number of Antennas</title><categories>cs.IT math.IT</categories><abstract>  Perfect space-time codes were first introduced by Oggier et. al. to be the
space-time codes that have full rate, full diversity-gain, non-vanishing
determinant for increasing spectral efficiency, uniform average transmitted
energy per antenna and good shaping of the constellation. These defining
conditions jointly correspond to optimality with respect to the Zheng-Tse D-MG
tradeoff, independent of channel statistics, as well as to near optimality in
maximizing mutual information. All the above traits endow the code with error
performance that is currently unmatched. Yet perfect space-time codes have been
constructed only for 2,3,4 and 6 transmit antennas. We construct minimum and
non-minimum delay perfect codes for all channel dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512024</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512024</id><created>2005-12-05</created><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Nogin</keyname><forenames>Dmitry</forenames></author></authors><title>A bound on Grassmannian codes</title><categories>cs.IT math.IT math.MG</categories><comments>5 pages, submitted</comments><journal-ref>Problems of Information Transmission, 2006, vol. 42, no. 2, pp.
  77---89</journal-ref><doi>10.1134/S0032946006020025</doi><abstract>  We give a new asymptotic upper bound on the size of a code in the
Grassmannian space. The bound is better than the upper bounds known previously
in the entire range of distances except very large values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512025</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512025</id><created>2005-12-05</created><updated>2006-03-13</updated><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Nogin</keyname><forenames>Dmitry</forenames></author></authors><title>Spectral approach to linear programming bounds on codes</title><categories>cs.IT math.CO math.IT</categories><comments>11 pages, submitted</comments><abstract>  We give new proofs of asymptotic upper bounds of coding theory obtained
within the frame of Delsarte's linear programming method. The proofs rely on
the analysis of eigenvectors of some finite-dimensional operators related to
orthogonal polynomials. The examples of the method considered in the paper
include binary codes, binary constant-weight codes, spherical codes, and codes
in the projective spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512026</id><created>2005-12-07</created><authors><author><keyname>Josopait</keyname><forenames>I.</forenames></author></authors><title>Checking C++ Programs for Dimensional Consistency</title><categories>cs.PL</categories><comments>submitted to &quot;Computing in Science and Engineering&quot;</comments><acm-class>D.1.2; I.2.2</acm-class><abstract>  I will present my implementation 'n-units' of physical units into C++
programs. It allows the compiler to check for dimensional consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512027</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512027</id><created>2005-12-07</created><updated>2005-12-22</updated><authors><author><keyname>Chen</keyname><forenames>Jing</forenames></author></authors><title>The Physical Foundation of Human Mind and a New Theory of Investment</title><categories>cs.IT math.IT</categories><abstract>  This paper consists of two parts. In the first part, we develop a new
information theory, in which it is not a coincidence that information and
physical entropy share the same mathematical formula. It is an adaptation of
mind to help search for resources. We then show that psychological patterns
either reflect the constraints of physical laws or are evolutionary adaptations
to efficiently process information and to increase the chance of survival in
the environment of our evolutionary past. In the second part, we demonstrate
that the new information theory provides the foundation to understand market
behavior. One fundamental result from the information theory is that
information is costly. In general, information with higher value is more
costly. Another fundamental result from the information theory is that the
amount of information one can receive is the amount of information generated
minus equivocation. The level of equivocation, which is the measure of
information asymmetry, is determined by the correlation between the source of
information and the receiver of information. In general, how much information
one can receive depends on the background knowledge of the receiver. The
difference in cost different investors are willing to pay for information and
the difference in background knowledge about a particular information causes
the heterogeneity in information processing by the investment public, which is
the main reason of the price and volume patterns observed in the market. Many
assumptions in some of the recent models on behavioral finance can be derived
naturally from this theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512028</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512028</id><created>2005-12-07</created><authors><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Approximately universal optimality over several dynamic and non-dynamic
  cooperative diversity schemes for wireless networks</title><categories>cs.IT math.IT</categories><abstract>  In this work we explicitly provide the first ever optimal, with respect to
the Zheng-Tse diversity multiplexing gain (D-MG) tradeoff, cooperative
diversity schemes for wireless relay networks. The schemes are based on
variants of perfect space-time codes and are optimal for any number of users
and all statistically symmetric (and in some cases, asymmetric) fading
distributions.
  We deduce that, with respect to the D-MG tradeoff, channel knowledge at the
intermediate relays and infinite delay are unnecessary. We also show that the
non-dynamic selection decode and forward strategy, the non-dynamic amplify and
forward, the non-dynamic receive and forward, the dynamic amplify and forward
and the dynamic receive and forward cooperative diversity strategies allow for
exactly the same D-MG optimal performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512029</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512029</id><created>2005-12-07</created><authors><author><keyname>Maneva</keyname><forenames>Elitza N.</forenames></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames></author></authors><title>New model for rigorous analysis of LT-codes</title><categories>cs.IT math.IT</categories><abstract>  We present a new model for LT codes which simplifies the analysis of the
error probability of decoding by belief propagation. For any given degree
distribution, we provide the first rigorous expression for the limiting error
probability as the length of the code goes to infinity via recent results in
random hypergraphs [Darling-Norris 2005]. For a code of finite length, we
provide an algorithm for computing the probability of error of the decoder.
This algorithm improves the one of [Karp-Luby-Shokrollahi 2004] by a linear
factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512030</id><created>2005-12-08</created><authors><author><keyname>Somaraju</keyname><forenames>Ram</forenames></author><author><keyname>Hanlen</keyname><forenames>Leif W.</forenames></author></authors><title>Uncertainty Principles for Signal Concentrations</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, Australian Communications Theory Workshop 2006</comments><abstract>  Uncertainty principles for concentration of signals into truncated subspaces
are considered. The ``classic'' uncertainty principle is explored as a special
case of a more general operator framework. The time-bandwidth concentration
problem is shown as a similar special case. A spatial concentration of radio
signals example is provided, and it is shown that an uncertainty principle
exists for concentration of single-frequency signals for regions in space. We
show that the uncertainty is related to the volumes of the spatial regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512031</id><created>2005-12-08</created><updated>2006-08-24</updated><authors><author><keyname>Lasota</keyname><forenames>Slawomir</forenames></author><author><keyname>Walukiewicz</keyname><forenames>Igor</forenames></author></authors><title>Alternating Timed Automata</title><categories>cs.LO</categories><comments>the full version of the Fossacs'05 conference preliminary paper
  revised according ot the referee's comments</comments><abstract>  A notion of alternating timed automata is proposed. It is shown that such
automata with only one clock have decidable emptiness problem over finite
words. This gives a new class of timed languages which is closed under boolean
operations and which has an effective presentation. We prove that the
complexity of the emptiness problem for alternating timed automata with one
clock is non-primitive recursive. The proof gives also the same lower bound for
the universality problem for nondeterministic timed automata with one clock. We
investigate extension of the model with epsilon-transitions and prove that
emptiness is undecidable. Over infinite words, we show undecidability of the
universality problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512032</id><created>2005-12-08</created><authors><author><keyname>Bengochea</keyname><forenames>Sebasti&#xe1;n</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Talamona</keyname><forenames>Angel</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Parent</keyname><forenames>Michel</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A Software Framework for Vehicle-Infrastructure Cooperative Applications</title><categories>cs.IR</categories><proxy>ccsd inria-00000907</proxy><abstract>  A growing category of vehicle-infrastructure cooperative (VIC) applications
requires telematics software components distributed between an
infrastructure-based management center and a number of vehicles. This article
presents an approach based on a software framework, focusing on a Telematic
Management System (TMS), a component suite aimed to run inside an
infrastructure-based operations center, in some cases interacting with legacy
systems like Advanced Traffic Management Systems or Vehicle Relationship
Management. The TMS framework provides support for modular, flexible,
prototyping and implementation of VIC applications. This work has received the
support of the European Commission in the context of the projects REACT and
CyberCars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512033</id><created>2005-12-08</created><authors><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Wu</keyname><forenames>Fang</forenames></author></authors><title>Bootstrapping the Long Tail in Peer to Peer Systems</title><categories>cs.NI cs.CY physics.soc-ph</categories><abstract>  We describe an efficient incentive mechanism for P2P systems that generates a
wide diversity of content offerings while responding adaptively to customer
demand. Files are served and paid for through a parimutuel market similar to
that commonly used for betting in horse races. An analysis of the performance
of such a system shows that there exists an equilibrium with a long tail in the
distribution of content offerings, which guarantees the real time provision of
any content regardless of its popularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512034</id><created>2005-12-08</created><authors><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Wu</keyname><forenames>Fang</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>Ensuring Trust in One Time Exchanges: Solving the QoS Problem</title><categories>cs.GT physics.soc-ph</categories><abstract>  We describe a pricing structure for the provision of IT services that ensures
trust without requiring repeated interactions between service providers and
users. It does so by offering a pricing structure that elicits truthful
reporting of quality of service (QoS) by providers while making them
profitable. This mechanism also induces truth-telling on the part of users
reserving the service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512035</id><created>2005-12-09</created><authors><author><keyname>Tarasov</keyname><forenames>Sergey P.</forenames></author><author><keyname>Vyalyi</keyname><forenames>Mikhail N.</forenames></author></authors><title>Semidefinite programming and arithmetic circuit evaluation</title><categories>cs.CC</categories><comments>Submitted to Special issue of DAM in memory of L.Khachiyan</comments><acm-class>F.1.3</acm-class><abstract>  A rational number can be naturally presented by an arithmetic computation
(AC): a sequence of elementary arithmetic operations starting from a fixed
constant, say 1. The asymptotic complexity issues of such a representation are
studied e.g. in the framework of the algebraic complexity theory over arbitrary
field.
  Here we study a related problem of the complexity of performing arithmetic
operations and computing elementary predicates, e.g. ``='' or ``&gt;'', on
rational numbers given by AC.
  In the first place, we prove that AC can be efficiently simulated by the
exact semidefinite programming (SDP).
  Secondly, we give a BPP-algorithm for the equality predicate.
  Thirdly, we put ``&gt;''-predicate into the complexity class PSPACE.
  We conjecture that ``&gt;''-predicate is hard to compute. This conjecture, if
true, would clarify the complexity status of the exact SDP - a well known open
problem in the field of mathematical programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512036</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512036</id><created>2005-12-09</created><updated>2006-04-03</updated><authors><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author></authors><title>A System of Interaction and Structure II: The Need for Deep Inference</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 2 (April 3,
  2006) lmcs:1075</journal-ref><doi>10.2168/LMCS-2(2:4)2006</doi><abstract>  This paper studies properties of the logic BV, which is an extension of
multiplicative linear logic (MLL) with a self-dual non-commutative operator. BV
is presented in the calculus of structures, a proof theoretic formalism that
supports deep inference, in which inference rules can be applied anywhere
inside logical expressions. The use of deep inference results in a simple
logical system for MLL extended with the self-dual non-commutative operator,
which has been to date not known to be expressible in sequent calculus. In this
paper, deep inference is shown to be crucial for the logic BV, that is, any
restriction on the ``depth'' of the inference rules of BV would result in a
strictly less expressive logical system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512037</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512037</id><created>2005-12-09</created><updated>2005-12-13</updated><authors><author><keyname>Anastasiadis</keyname><forenames>Aristoklis D.</forenames></author><author><keyname>Magoulas</keyname><forenames>George D.</forenames></author></authors><title>Evolving Stochastic Learning Algorithm Based on Tsallis Entropic Index</title><categories>cs.NE cs.AI</categories><comments>12 pages, 11 figures, journal</comments><doi>10.1140/epjb/e2006-00137-6</doi><abstract>  In this paper, inspired from our previous algorithm, which was based on the
theory of Tsallis statistical mechanics, we develop a new evolving stochastic
learning algorithm for neural networks. The new algorithm combines
deterministic and stochastic search steps by employing a different adaptive
stepsize for each network weight, and applies a form of noise that is
characterized by the nonextensive entropic index q, regulated by a weight decay
term. The behavior of the learning algorithm can be made more stochastic or
deterministic depending on the trade off between the temperature T and the q
values. This is achieved by introducing a formula that defines a
time--dependent relationship between these two important learning parameters.
Our experimental study verifies that there are indeed improvements in the
convergence speed of this new evolving stochastic learning algorithm, which
makes learning faster than using the original Hybrid Learning Scheme (HLS). In
addition, experiments are conducted to explore the influence of the entropic
index q and temperature T on the convergence speed and stability of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512038</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512038</id><created>2005-12-12</created><authors><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author><author><keyname>Simon</keyname><forenames>Steven H.</forenames></author><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author></authors><title>Capacity of Differential versus Non-Differential Unitary Space-Time
  Modulation for MIMO channels</title><categories>cs.IT cond-mat.stat-mech math-ph math.IT math.MP</categories><comments>submitted to IEEE Trans. Information Theory Jan. 2004; current
  version addresses referees' minor comments; 13 pages</comments><abstract>  Differential Unitary Space-Time Modulation (DUSTM) and its earlier
nondifferential counterpart, USTM, permit high-throughput MIMO communication
entirely without the possession of channel state information (CSI) by either
the transmitter or the receiver. For an isotropically random unitary input we
obtain the exact closed-form expression for the probability density of the
DUSTM received signal, which permits the straightforward Monte Carlo evaluation
of its mutual information. We compare the performance of DUSTM and USTM through
both numerical computations of mutual information and through the analysis of
low- and high-SNR asymptotic expressions. In our comparisons the symbol
durations of the equivalent unitary space-time signals are both equal to T, as
are the number of receive antennas N. For DUSTM the number of transmit antennas
is constrained by the scheme to be M = T/2, while USTM has no such constraint.
If DUSTM and USTM utilize the same number of transmit antennas at high SNR's
the normalized mutual information of the differential and the nondifferential
schemes expressed in bits/sec/Hz are asymptotically equal, with the
differential scheme performing somewhat better, while at low SNR's the
normalized mutual information of DUSTM is asymptotically twice the normalized
mutual information of USTM. If, instead, USTM utilizes the optimum number of
transmit antennas then USTM can outperform DUSTM at sufficiently low SNR's.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512039</id><created>2005-12-09</created><authors><author><keyname>Zhou</keyname><forenames>Jianqin</forenames></author><author><keyname>Xu</keyname><forenames>Xirong</forenames></author></authors><title>An algorithm for the k-error linear complexity of a sequence with period
  2pn over GF(q)</title><categories>cs.CR</categories><comments>6 pages</comments><abstract>  The union cost is used, so that an efficient algorithm for computing the
k-error linear complexity of a sequence with period 2pn over GF(q) is
presented, where p and q are odd primes, and q is a primitive root of modulo
p2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512040</id><created>2005-12-09</created><authors><author><keyname>Zhou</keyname><forenames>Jianqin</forenames></author></authors><title>A fast algorithm for determining the linear complexity of periodic
  sequences</title><categories>cs.CR</categories><comments>7 pages</comments><abstract>  A fast algorithm is presented for determining the linear complexity and the
minimal polynomial of periodic sequences over GF(q) with period q n p m, where
p is a prime, q is a prime and a primitive root modulo p2. The algorithm
presented here generalizes both the algorithm in [4] where the period of a
sequence over GF(q) is p m and the algorithm in [5] where the period of a
binary sequence is 2 n p m . When m=0, the algorithm simplifies the generalized
Games-Chan algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512041</id><created>2005-12-09</created><authors><author><keyname>Zhou</keyname><forenames>Jianqin</forenames></author></authors><title>Generalized partially bent functions</title><categories>cs.CR</categories><comments>7 pages</comments><abstract>  Based on the definition of generalized partially bent functions, using the
theory of linear transformation, the relationship among generalized partially
bent functions over ring Z N, generalized bent functions over ring Z N and
affine functions is discussed. When N is a prime number, it is proved that a
generalized partially bent function can be decomposed as the addition of a
generalized bent function and an affine function. The result obtained here
generalizes the main works concerning partially bent functions by Claud Carlet
in [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512042</id><created>2005-12-09</created><authors><author><keyname>Gu</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Mayordomo</keyname><forenames>Elvira</forenames></author></authors><title>Points on Computable Curves</title><categories>cs.CC cs.CG</categories><comments>10 pages, 12 pages appendix</comments><abstract>  The ``analyst's traveling salesman theorem'' of geometric measure theory
characterizes those subsets of Euclidean space that are contained in curves of
finite length. This result, proven for the plane by Jones (1990) and extended
to higher-dimensional Euclidean spaces by Okikiolu (1991), says that a bounded
set $K$ is contained in some curve of finite length if and only if a certain
``square beta sum'', involving the ``width of $K$'' in each element of an
infinite system of overlapping ``tiles'' of descending size, is finite.
  In this paper we characterize those {\it points} of Euclidean space that lie
on {\it computable} curves of finite length by formulating and proving a
computable extension of the analyst's traveling salesman theorem. Our extension
says that a point in Euclidean space lies on some computable curve of finite
length if and only if it is ``permitted'' by some computable ``Jones
constriction''. A Jones constriction here is an explicit assignment of a
rational cylinder to each of the above-mentioned tiles in such a way that, when
the radius of the cylinder corresponding to a tile is used in place of the
``width of $K$'' in each tile, the square beta sum is finite. A point is
permitted by a Jones constriction if it is contained in the cylinder assigned
to each tile containing the point. The main part of our proof is the
construction of a computable curve of finite length traversing all the points
permitted by a given Jones constriction. Our construction uses the main ideas
of Jones's ``farthest insertion'' construction, but our algorithm for computing
the curve must work exclusively with the Jones constriction itself, because it
has no direct access to the (typically uncomputable) points permitted by the
Jones constriction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512043</id><created>2005-12-10</created><authors><author><keyname>Wagner</keyname><forenames>Dirk</forenames></author><author><keyname>Noga</keyname><forenames>John</forenames></author></authors><title>Random Walks with Anti-Correlated Steps</title><categories>cs.DM cs.PF</categories><comments>5 pages, 1 chart, 2 tables</comments><abstract>  We conjecture the expected value of random walks with anti-correlated steps
to be exactly 1. We support this conjecture with 2 plausibility arguments and
experimental data. The experimental analysis includes the computation of the
expected values of random walks for steps up to 22. The result shows the
expected value asymptotically converging to 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512044</identifier>
 <datestamp>2014-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512044</id><created>2005-12-10</created><authors><author><keyname>Stinehour</keyname><forenames>Joshua</forenames></author><author><keyname>Radziszowski</keyname><forenames>Stanis&#x142;aw</forenames></author><author><keyname>Tse</keyname><forenames>Kung-Kuen</forenames></author></authors><title>Computation of the Ramsey Number $R(W_5,K_5)$</title><categories>cs.DM</categories><comments>5 pages</comments><journal-ref>Bulletin of the Institute of Combinatorics and Its Applications,
  47 (2006) 53-57</journal-ref><abstract>  We determine the value of the Ramsey number $R(W_5,K_5)$ to be 27, where $W_5
= K_1 + C_4$ is the 4-spoked wheel of order 5. This solves one of the four
remaining open cases in the tables given in 1989 by George R. T. Hendry, which
included the Ramsey numbers $R(G,H)$ for all pairs of graphs $G$ and $H$ having
five vertices, except seven entries. In addition, we show that there exists a
unique up to isomorphism critical Ramsey graph for $W_5$ versus $K_5$. Our
results are based on computer algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512045</id><created>2005-12-11</created><updated>2007-05-08</updated><authors><author><keyname>Vu</keyname><forenames>Xuan-Ha</forenames></author><author><keyname>Silaghi</keyname><forenames>Marius-Calin</forenames></author><author><keyname>Sam-Haroud</keyname><forenames>Djamila</forenames></author><author><keyname>Faltings</keyname><forenames>Boi</forenames></author></authors><title>Branch-and-Prune Search Strategies for Numerical Constraint Solving</title><categories>cs.AI</categories><comments>43 pages, 11 figures</comments><report-no>LIA-REPORT-2006-007</report-no><acm-class>F.4.1; I.2.8</acm-class><abstract>  When solving numerical constraints such as nonlinear equations and
inequalities, solvers often exploit pruning techniques, which remove redundant
value combinations from the domains of variables, at pruning steps. To find the
complete solution set, most of these solvers alternate the pruning steps with
branching steps, which split each problem into subproblems. This forms the
so-called branch-and-prune framework, well known among the approaches for
solving numerical constraints. The basic branch-and-prune search strategy that
uses domain bisections in place of the branching steps is called the bisection
search. In general, the bisection search works well in case (i) the solutions
are isolated, but it can be improved further in case (ii) there are continuums
of solutions (this often occurs when inequalities are involved). In this paper,
we propose a new branch-and-prune search strategy along with several variants,
which not only allow yielding better branching decisions in the latter case,
but also work as well as the bisection search does in the former case. These
new search algorithms enable us to employ various pruning techniques in the
construction of inner and outer approximations of the solution set. Our
experiments show that these algorithms speed up the solving process often by
one order of magnitude or more when solving problems with continuums of
solutions, while keeping the same performance as the bisection search when the
solutions are isolated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512046</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512046</id><created>2005-12-11</created><updated>2008-01-11</updated><authors><author><keyname>Mertzios</keyname><forenames>George B.</forenames></author></authors><title>A polynomial algorithm for the k-cluster problem on interval graphs</title><categories>cs.DS</categories><comments>12 pages, 5 figures</comments><abstract>  This paper deals with the problem of finding, for a given graph and a given
natural number k, a subgraph of k nodes with a maximum number of edges. This
problem is known as the k-cluster problem and it is NP-hard on general graphs
as well as on chordal graphs. In this paper, it is shown that the k-cluster
problem is solvable in polynomial time on interval graphs. In particular, we
present two polynomial time algorithms for the class of proper interval graphs
and the class of general interval graphs, respectively. Both algorithms are
based on a matrix representation for interval graphs. In contrast to
representations used in most of the previous work, this matrix representation
does not make use of the maximal cliques in the investigated graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512047</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512047</id><created>2005-12-12</created><updated>2005-12-15</updated><authors><author><keyname>Salmeron</keyname><forenames>Jose L.</forenames></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>Processing Uncertainty and Indeterminacy in Information Systems success
  mapping</title><categories>cs.AI</categories><comments>13 pages, 2 figures</comments><acm-class>I.2.11</acm-class><abstract>  IS success is a complex concept, and its evaluation is complicated,
unstructured and not readily quantifiable. Numerous scientific publications
address the issue of success in the IS field as well as in other fields. But,
little efforts have been done for processing indeterminacy and uncertainty in
success research. This paper shows a formal method for mapping success using
Neutrosophic Success Map. This is an emerging tool for processing indeterminacy
and uncertainty in success research. EIS success have been analyzed using this
tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512048</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512048</id><created>2005-12-12</created><authors><author><keyname>Lamahewa</keyname><forenames>Tharaka A.</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author><author><keyname>Abhayapala</keyname><forenames>Thushara D.</forenames></author><author><keyname>Nguyen</keyname><forenames>Van K.</forenames></author></authors><title>Spatial Precoder Design for Space-Time Coded MIMO Systems: Based on
  Fixed Parameters of MIMO Channels</title><categories>cs.IT math.IT</categories><comments>15 Figures, 1-Table. Submitted to Personal Wireless Communications
  Springer 08/12/2005</comments><abstract>  In this paper, we introduce the novel use of linear spatial precoding based
on fixed and known parameters of multiple-input multiple-output (MIMO) channels
to improve the performance of space-time coded MIMO systems. We derive linear
spatial precoding schemes for both coherent (channel is known at the receiver)
and non-coherent (channel is un-known at the receiver) space-time coded MIMO
systems. Antenna spacing and antenna placement (geometry) are considered as
fixed parameters of MIMO channels, which are readily known at the transmitter.
These precoding schemes exploit the antenna placement information at both ends
of the MIMO channel to ameliorate the effect of non-ideal antenna placement on
the performance of space-time coded systems. In these schemes, the precoder is
fixed for given transmit and receive antenna configurations and transmitter
does not require any feedback of channel state information (partial or full)
from the receiver. Closed form solutions for both precoding schemes are
presented for systems with up to three receiver antennas. A generalized method
is proposed for more than three receiver antennas. We use the coherent
space-time block codes (STBC) and differential space-time block codes to
analyze the performance of proposed precoding schemes. Simulation results show
that at low SNRs, both precoders give significant performance improvement over
a non-precoded system for small antenna aperture sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512049</id><created>2005-12-12</created><authors><author><keyname>Stuckman</keyname><forenames>Jeff</forenames></author><author><keyname>Zhang</keyname><forenames>Guo-Qiang</forenames></author></authors><title>Mastermind is NP-Complete</title><categories>cs.CC cs.DM</categories><abstract>  In this paper we show that the Mastermind Satisfiability Problem (MSP) is
NP-complete. The Mastermind is a popular game which can be turned into a
logical puzzle called Mastermind Satisfiability Problem in a similar spirit to
the Minesweeper puzzle. By proving that MSP is NP-complete, we reveal its
intrinsic computational property that makes it challenging and interesting.
This serves as an addition to our knowledge about a host of other puzzles, such
as Minesweeper, Mah-Jongg, and the 15-puzzle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512050</id><created>2005-12-13</created><authors><author><keyname>Az&#xe9;</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LRI</affiliation></author><author><keyname>Roche</keyname><forenames>Mathieu</forenames><affiliation>LRI</affiliation></author><author><keyname>Kodratoff</keyname><forenames>Yves</forenames><affiliation>LRI</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LRI</affiliation></author></authors><title>Preference Learning in Terminology Extraction: A ROC-based approach</title><categories>cs.LG</categories><proxy>ccsd ccsd-00015665</proxy><journal-ref>Proceeedings of Applied Stochastic Models and Data Analysis (2005)
  209-219</journal-ref><abstract>  A key data preparation step in Text Mining, Term Extraction selects the
terms, or collocation of words, attached to specific concepts. In this paper,
the task of extracting relevant collocations is achieved through a supervised
learning algorithm, exploiting a few collocations manually labelled as
relevant/irrelevant. The candidate terms are described along 13 standard
statistical criteria measures. From these examples, an evolutionary learning
algorithm termed Roger, based on the optimization of the Area under the ROC
curve criterion, extracts an order on the candidate terms. The robustness of
the approach is demonstrated on two real-world domain applications, considering
different domains (biology and human resources) and different languages
(English and French).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512051</id><created>2005-12-13</created><authors><author><keyname>Richomme</keyname><forenames>Gw&#xe9;na&#xeb;l</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Wlazinski</keyname><forenames>Francis</forenames><affiliation>LaRIA</affiliation></author></authors><title>Existence of finite test-sets for k-power-freeness of uniform morphisms</title><categories>cs.DM</categories><proxy>ccsd ccsd-00015775</proxy><abstract>  A challenging problem is to find an algorithm to decide whether a morphism is
k-power-free. We provide such an algorithm when k &gt;= 3 for uniform morphisms
showing that in such a case, contrarily to the general case, there exist finite
test-sets for k-power-freeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512052</id><created>2005-12-14</created><authors><author><keyname>Mandoiu</keyname><forenames>Ion I.</forenames></author><author><keyname>Prajescu</keyname><forenames>Claudia</forenames></author></authors><title>High-Throughput SNP Genotyping by SBE/SBH</title><categories>cs.DS q-bio.GN</categories><comments>19 pages</comments><acm-class>F.2.2; G.1.6</acm-class><abstract>  Despite much progress over the past decade, current Single Nucleotide
Polymorphism (SNP) genotyping technologies still offer an insufficient degree
of multiplexing when required to handle user-selected sets of SNPs. In this
paper we propose a new genotyping assay architecture combining multiplexed
solution-phase single-base extension (SBE) reactions with sequencing by
hybridization (SBH) using universal DNA arrays such as all $k$-mer arrays. In
addition to PCR amplification of genomic DNA, SNP genotyping using SBE/SBH
assays involves the following steps: (1) Synthesizing primers complementing the
genomic sequence immediately preceding SNPs of interest; (2) Hybridizing these
primers with the genomic DNA; (3) Extending each primer by a single base using
polymerase enzyme and dideoxynucleotides labeled with 4 different fluorescent
dyes; and finally (4) Hybridizing extended primers to a universal DNA array and
determining the identity of the bases that extend each primer by hybridization
pattern analysis. Our contributions include a study of multiplexing algorithms
for SBE/SBH genotyping assays and preliminary experimental results showing the
achievable tradeoffs between the number of array probes and primer length on
one hand and the number of SNPs that can be assayed simultaneously on the
other. Simulation results on datasets both randomly generated and extracted
from the NCBI dbSNP database suggest that the SBE/SBH architecture provides a
flexible and cost-effective alternative to genotyping assays currently used in
the industry, enabling genotyping of up to hundreds of thousands of
user-specified SNPs per assay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512053</id><created>2005-12-13</created><authors><author><keyname>Hitchcock</keyname><forenames>John M.</forenames></author></authors><title>Online Learning and Resource-Bounded Dimension: Winnow Yields New Lower
  Bounds for Hard Sets</title><categories>cs.CC cs.LG</categories><abstract>  We establish a relationship between the online mistake-bound model of
learning and resource-bounded dimension. This connection is combined with the
Winnow algorithm to obtain new results about the density of hard sets under
adaptive reductions. This improves previous work of Fu (1995) and Lutz and Zhao
(2000), and solves one of Lutz and Mayordomo's &quot;Twelve Problems in
Resource-Bounded Measure&quot; (1999).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512054</id><created>2005-12-13</created><authors><author><keyname>Berman</keyname><forenames>Gennady P.</forenames><affiliation>Los Alamos National Laboratory, T-13</affiliation></author><author><keyname>Gorshkov</keyname><forenames>Vyacheslav N.</forenames><affiliation>Los Alamos National Laboratory, Center for Nonlinear Studies</affiliation></author><author><keyname>Wang</keyname><forenames>Xidi</forenames><affiliation>Citigroup, Sao Paulo, Brasil</affiliation></author></authors><title>Irreducible Frequent Patterns in Transactional Databases</title><categories>cs.DS cs.DB</categories><comments>30 pages, 18 figures</comments><abstract>  Irreducible frequent patters (IFPs) are introduced for transactional
databases. An IFP is such a frequent pattern (FP),(x1,x2,...xn), the
probability of which, P(x1,x2,...xn), cannot be represented as a product of the
probabilities of two (or more) other FPs of the smaller lengths. We have
developed an algorithm for searching IFPs in transactional databases. We argue
that IFPs represent useful tools for characterizing the transactional databases
and may have important applications to bio-systems including the immune systems
and for improving vaccination strategies. The effectiveness of the IFPs
approach has been illustrated in application to a classification problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512055</id><created>2005-12-14</created><authors><author><keyname>Shen</keyname><forenames>Yi-Dong</forenames></author><author><keyname>De Schreye</keyname><forenames>Danny</forenames></author></authors><title>Termination Analysis of General Logic Programs for Moded Queries: A
  Dynamic Approach</title><categories>cs.LO cs.PL</categories><comments>24 Pages</comments><acm-class>D.1.6</acm-class><abstract>  The termination problem of a logic program can be addressed in either a
static or a dynamic way. A static approach performs termination analysis at
compile time, while a dynamic approach characterizes and tests termination of a
logic program by applying a loop checking technique. In this paper, we present
a novel dynamic approach to termination analysis for general logic programs
with moded queries. We address several interesting questions, including how to
formulate an SLDNF-derivation for a moded query, how to characterize an
infinite SLDNF-derivation with a moded query, and how to apply a loop checking
mechanism to cut infinite SLDNF-derivations for the purpose of termination
analysis. The proposed approach is very powerful and useful. It can be used (1)
to test if a logic program terminates for a given concrete or moded query, (2)
to test if a logic program terminates for all concrete or moded queries, and
(3) to find all (most general) concrete/moded queries that are most likely
terminating (or non-terminating).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512056</id><created>2005-12-14</created><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames><affiliation>University of Parma</affiliation></author><author><keyname>Pescetti</keyname><forenames>Andrea</forenames><affiliation>University of Parma</affiliation></author><author><keyname>Zaccagnini</keyname><forenames>Alessandro</forenames><affiliation>University of Parma</affiliation></author><author><keyname>Zaffanella</keyname><forenames>Enea</forenames><affiliation>University of Parma</affiliation></author></authors><title>PURRS: Towards Computer Algebra Support for Fully Automatic Worst-Case
  Complexity Analysis</title><categories>cs.MS cs.CC</categories><comments>6 pages</comments><abstract>  Fully automatic worst-case complexity analysis has a number of applications
in computer-assisted program manipulation. A classical and powerful approach to
complexity analysis consists in formally deriving, from the program syntax, a
set of constraints expressing bounds on the resources required by the program,
which are then solved, possibly applying safe approximations. In several
interesting cases, these constraints take the form of recurrence relations.
While techniques for solving recurrences are known and implemented in several
computer algebra systems, these do not completely fulfill the needs of fully
automatic complexity analysis: they only deal with a somewhat restricted class
of recurrence relations, or sometimes require user intervention, or they are
restricted to the computation of exact solutions that are often so complex to
be unmanageable, and thus useless in practice. In this paper we briefly
describe PURRS, a system and software library aimed at providing all the
computer algebra services needed by applications performing or exploiting the
results of worst-case complexity analyses. The capabilities of the system are
illustrated by means of examples derived from the analysis of programs written
in a domain-specific functional programming language for real-time embedded
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512057</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512057</id><created>2005-12-14</created><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Zilio</keyname><forenames>Silvano Dal</forenames><affiliation>LIF</affiliation></author></authors><title>Resource Control for Synchronous Cooperative Threads</title><categories>cs.PL</categories><proxy>ccsd ccsd-00015836</proxy><journal-ref>Journal of Theoretical Computer Science (TCS) 358 (15/08/2006)
  229-254</journal-ref><abstract>  We develop new methods to statically bound the resources needed for the
execution of systems of concurrent, interactive threads. Our study is concerned
with a \emph{synchronous} model of interaction based on cooperative threads
whose execution proceeds in synchronous rounds called instants. Our
contribution is a system of compositional static analyses to guarantee that
each instant terminates and to bound the size of the values computed by the
system as a function of the size of its parameters at the beginning of the
instant. Our method generalises an approach designed for first-order functional
languages that relies on a combination of standard termination techniques for
term rewriting systems and an analysis of the size of the computed values based
on the notion of quasi-interpretation. We show that these two methods can be
combined to obtain an explicit polynomial bound on the resources needed for the
execution of the system during an instant. As a second contribution, we
introduce a virtual machine and a related bytecode thus producing a precise
description of the resources needed for the execution of a system. In this
context, we present a suitable control flow analysis that allows to formulte
the static analyses for resource control at byte code level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512058</identifier>
 <datestamp>2007-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512058</id><created>2005-12-14</created><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Boudol</keyname><forenames>Gerard</forenames></author><author><keyname>Castellani</keyname><forenames>Ilaria</forenames></author><author><keyname>Boussinot</keyname><forenames>Frederic</forenames></author></authors><title>Reactive concurrent programming revisited</title><categories>cs.PL</categories><proxy>ccsd ccsd-00015838</proxy><journal-ref>Workshop on Process Algebra (29/09/2006) 49-60</journal-ref><abstract>  In this note we revisit the so-called reactive programming style, which
evolves from the synchronous programming model of the Esterel language by
weakening the assumption that the absence of an event can be detected
instantaneously. We review some research directions that have been explored
since the emergence of the reactive model ten years ago. We shall also outline
some questions that remain to be investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512059</id><created>2005-12-14</created><updated>2006-01-25</updated><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Competing with wild prediction rules</title><categories>cs.LG</categories><comments>28 pages, 3 figures</comments><acm-class>I.2.6</acm-class><abstract>  We consider the problem of on-line prediction competitive with a benchmark
class of continuous but highly irregular prediction rules. It is known that if
the benchmark class is a reproducing kernel Hilbert space, there exists a
prediction algorithm whose average loss over the first N examples does not
exceed the average loss of any prediction rule in the class plus a &quot;regret
term&quot; of O(N^(-1/2)). The elements of some natural benchmark classes, however,
are so irregular that these classes are not Hilbert spaces. In this paper we
develop Banach-space methods to construct a prediction algorithm with a regret
term of O(N^(-1/p)), where p is in [2,infty) and p-2 reflects the degree to
which the benchmark class fails to be a Hilbert space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512060</id><created>2005-12-14</created><authors><author><keyname>Buragohain</keyname><forenames>Chiranjeeb</forenames></author><author><keyname>Agrawal</keyname><forenames>Divyakant</forenames></author><author><keyname>Suri</keyname><forenames>Subhash</forenames></author></authors><title>Distributed Navigation Algorithms for Sensor Networks</title><categories>cs.NI cs.DC cs.DS</categories><comments>To Appear in INFOCOM 2006</comments><abstract>  We propose efficient distributed algorithms to aid navigation of a user
through a geographic area covered by sensors. The sensors sense the level of
danger at their locations and we use this information to find a safe path for
the user through the sensor field. Traditional distributed navigation
algorithms rely upon flooding the whole network with packets to find an optimal
safe path. To reduce the communication expense, we introduce the concept of a
skeleton graph which is a sparse subset of the true sensor network
communication graph. Using skeleton graphs we show that it is possible to find
approximate safe paths with much lower communication cost. We give tight
theoretical guarantees on the quality of our approximation and by simulation,
show the effectiveness of our algorithms in realistic sensor network
situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512061</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512061</id><created>2005-12-15</created><updated>2007-12-07</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Goertz</keyname><forenames>Inge Li</forenames></author></authors><title>Matching Subsequences in Trees</title><categories>cs.DS</categories><comments>Minor correction of typos, etc</comments><abstract>  Given two rooted, labeled trees $P$ and $T$ the tree path subsequence problem
is to determine which paths in $P$ are subsequences of which paths in $T$. Here
a path begins at the root and ends at a leaf. In this paper we propose this
problem as a useful query primitive for XML data, and provide new algorithms
improving the previously best known time and space bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512062</id><created>2005-12-15</created><authors><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author><author><keyname>Gagliolo</keyname><forenames>Matteo</forenames></author><author><keyname>Wierstra</keyname><forenames>Daan</forenames></author><author><keyname>Gomez</keyname><forenames>Faustino</forenames></author></authors><title>Evolino for recurrent support vector machines</title><categories>cs.NE</categories><comments>10 pages, 2 figures</comments><report-no>IDSIA-19-05 version 2.0</report-no><acm-class>F.1.1; I.2.6</acm-class><abstract>  Traditional Support Vector Machines (SVMs) need pre-wired finite time windows
to predict and classify time series. They do not have an internal state
necessary to deal with sequences involving arbitrary long-term dependencies.
Here we introduce a new class of recurrent, truly sequential SVM-like devices
with internal adaptive states, trained by a novel method called EVOlution of
systems with KErnel-based outputs (Evoke), an instance of the recent Evolino
class of methods. Evoke evolves recurrent neural networks to detect and
represent temporal dependencies while using quadratic programming/support
vector regression to produce precise outputs. Evoke is the first SVM-based
mechanism learning to classify a context-sensitive language. It also
outperforms recent state-of-the-art gradient-based recurrent neural networks
(RNNs) on various time series prediction tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512063</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512063</id><created>2005-12-15</created><authors><author><keyname>Eriksson</keyname><forenames>Jan</forenames></author><author><keyname>Koivunen</keyname><forenames>Visa</forenames></author></authors><title>Complex Random Vectors and ICA Models: Identifiability, Uniqueness and
  Separability</title><categories>cs.IT cs.CE cs.IR cs.LG math.IT</categories><comments>To appear in IEEE TR-IT March 2006</comments><journal-ref>Information Theory, IEEE Transactions on , vol.52, no.3pp. 1017-
  1029, March 2006</journal-ref><doi>10.1109/TIT.2005.864440</doi><abstract>  In this paper the conditions for identifiability, separability and uniqueness
of linear complex valued independent component analysis (ICA) models are
established. These results extend the well-known conditions for solving
real-valued ICA problems to complex-valued models. Relevant properties of
complex random vectors are described in order to extend the Darmois-Skitovich
theorem for complex-valued models. This theorem is used to construct a proof of
a theorem for each of the above ICA model concepts. Both circular and
noncircular complex random vectors are covered. Examples clarifying the above
concepts are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512064</id><created>2005-12-15</created><authors><author><keyname>Kutz</keyname><forenames>Martin</forenames></author></authors><title>Computing shortest non-trivial cycles on orientable surfaces of bounded
  genus in almost linear time</title><categories>cs.CG</categories><comments>13 pages, 7 figures</comments><abstract>  We present an algorithm that computes a shortest non-contractible and a
shortest non-separating cycle on an orientable combinatorial surface of bounded
genus in O(n \log n) time, where n denotes the complexity of the surface. This
solves a central open problem in computational topology, improving upon the
current-best O(n^{3/2})-time algorithm by Cabello and Mohar (ESA 2005). Our
algorithm uses universal-cover constructions to find short cycles and makes
extensive use of existing tools from the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512065</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512065</id><created>2005-12-15</created><authors><author><keyname>Veldhuizen</keyname><forenames>Todd L.</forenames></author></authors><title>Tradeoffs in Metaprogramming</title><categories>cs.PL</categories><comments>2006 ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based
  Program Manipulation (PEPM 2006)</comments><acm-class>D.3.1</acm-class><abstract>  The design of metaprogramming languages requires appreciation of the
tradeoffs that exist between important language characteristics such as safety
properties, expressive power, and succinctness. Unfortunately, such tradeoffs
are little understood, a situation we try to correct by embarking on a study of
metaprogramming language tradeoffs using tools from computability theory.
Safety properties of metaprograms are in general undecidable; for example, the
property that a metaprogram always halts and produces a type-correct instance
is $\Pi^0_2$-complete. Although such safety properties are undecidable, they
may sometimes be captured by a restricted language, a notion we adapt from
complexity theory. We give some sufficient conditions and negative results on
when languages capturing properties can exist: there can be no languages
capturing total correctness for metaprograms, and no `functional' safety
properties above $\Sigma^0_3$ can be captured. We prove that translating a
metaprogram from a general-purpose to a restricted metaprogramming language
capturing a property is tantamount to proving that property for the
metaprogram. Surprisingly, when one shifts perspective from programming to
metaprogramming, the corresponding safety questions do not become substantially
harder -- there is no `jump' of Turing degree for typical safety properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512066</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512066</id><created>2005-12-15</created><authors><author><keyname>Rathi</keyname><forenames>Vishwambhar</forenames></author></authors><title>On the Asymptotic Weight and Stopping Set Distribution of Regular LDPC
  Ensembles</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans on Information Theory (revised version).
  Minor comments from reviewers addressed</comments><abstract>  We estimate the variance of weight and stopping set distribution of regular
LDPC ensembles. Using this estimate and the second moment method we obtain
bounds on the probability that a randomly chosen code from regular LDPC
ensemble has its weight distribution and stopping set distribution close to
respective ensemble averages. We are able to show that a large fraction of
total number of codes have their weight and stopping set distribution close to
the average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512067</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512067</id><created>2005-12-15</created><authors><author><keyname>Codish</keyname><forenames>Michael</forenames></author><author><keyname>Lagoon</keyname><forenames>Vitaly</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author></authors><title>Solving Partial Order Constraints for LPO Termination</title><categories>cs.PL cs.LO cs.SC</categories><comments>15 pages, 2 figures, 2 tables</comments><acm-class>F.3.1; F.4.1</acm-class><journal-ref>Journal of Satisfiability, Boolean Modeling and Computation,
  5:193-215: 2008</journal-ref><abstract>  This paper introduces a new kind of propositional encoding for reasoning
about partial orders. The symbols in an unspecified partial order are viewed as
variables which take integer values and are interpreted as indices in the
order. For a partial order statement on n symbols each index is represented in
log2 n propositional variables and partial order constraints between symbols
are modeled on the bit representations. We illustrate the application of our
approach to determine LPO termination for term rewrite systems. Experimental
results are unequivocal, indicating orders of magnitude speedups in comparison
with current implementations for LPO termination. The proposed encoding is
general and relevant to other applications which involve propositional
reasoning about partial orders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512068</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512068</id><created>2005-12-16</created><authors><author><keyname>Swaney</keyname><forenames>Daniel S.</forenames></author><author><keyname>McCown</keyname><forenames>Frank</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Dynamic Web File Format Transformations with Grace</title><categories>cs.DL</categories><comments>12 pages, 9 figures</comments><journal-ref>5th International Web Archiving Workshop and Digital Preservation
  (IWAW'05). September 22-23, 2005</journal-ref><abstract>  Web accessible content stored in obscure, unpopular or obsolete formats
represents a significant problem for digital preservation. The file formats
that encode web content represent the implicit and explicit choices of web site
maintainers at a particular point in time. Older file formats that have fallen
out of favor are obviously a problem, but so are new file formats that have not
yet been fully supported by browsers. Often browsers use plug-in software for
displaying old and new formats, but plug-ins can be difficult to find, install
and replicate across all environments that one may use. We introduce Grace, an
http proxy server that transparently converts browser-incompatible and obsolete
web content into web content that a browser is able to display without the use
of plug-ins. Grace is configurable on a per user basis and can be expanded to
provide an array of conversion services. We illustrate how the Grace prototype
transforms several image formats (XBM, PNG with various alpha channels, and
JPEG 2000) so they are viewable in Internet Explorer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512069</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512069</id><created>2005-12-16</created><authors><author><keyname>McCown</keyname><forenames>Frank</forenames></author><author><keyname>Smith</keyname><forenames>Joan A.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>Reconstructing Websites for the Lazy Webmaster</title><categories>cs.IR cs.CY</categories><comments>13 pages, 11 figures, 4 tables</comments><acm-class>H.3.5</acm-class><abstract>  Backup or preservation of websites is often not considered until after a
catastrophic event has occurred. In the face of complete website loss, &quot;lazy&quot;
webmasters or concerned third parties may be able to recover some of their
website from the Internet Archive. Other pages may also be salvaged from
commercial search engine caches. We introduce the concept of &quot;lazy
preservation&quot;- digital preservation performed as a result of the normal
operations of the Web infrastructure (search engines and caches). We present
Warrick, a tool to automate the process of website reconstruction from the
Internet Archive, Google, MSN and Yahoo. Using Warrick, we have reconstructed
24 websites of varying sizes and composition to demonstrate the feasibility and
limitations of website reconstruction from the public Web infrastructure. To
measure Warrick's window of opportunity, we have profiled the time required for
new Web resources to enter and leave search engine caches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512070</id><created>2005-12-16</created><updated>2006-01-05</updated><authors><author><keyname>Nouvel</keyname><forenames>Bertrand</forenames><affiliation>LIP</affiliation></author><author><keyname>Remila</keyname><forenames>Eric</forenames><affiliation>LIP</affiliation></author></authors><title>Incremental and Transitive Discrete Rotations</title><categories>cs.DM cs.GR</categories><proxy>ccsd ccsd-00016037</proxy><abstract>  A discrete rotation algorithm can be apprehended as a parametric application
$f\_\alpha$ from $\ZZ[i]$ to $\ZZ[i]$, whose resulting permutation ``looks
like'' the map induced by an Euclidean rotation. For this kind of algorithm, to
be incremental means to compute successively all the intermediate rotate d
copies of an image for angles in-between 0 and a destination angle. The di
scretized rotation consists in the composition of an Euclidean rotation with a
discretization; the aim of this article is to describe an algorithm whic h
computes incrementally a discretized rotation. The suggested method uses o nly
integer arithmetic and does not compute any sine nor any cosine. More pr
ecisely, its design relies on the analysis of the discretized rotation as a
step function: the precise description of the discontinuities turns to be th e
key ingredient that will make the resulting procedure optimally fast and e
xact. A complete description of the incremental rotation process is provided,
also this result may be useful in the specification of a consistent set of
defin itions for discrete geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512071</id><created>2005-12-16</created><authors><author><keyname>Timmis</keyname><forenames>Jon</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author><author><keyname>Banzhaf</keyname><forenames>Wolfgang</forenames></author><author><keyname>Tyrrell</keyname><forenames>Andy</forenames></author></authors><title>&quot;Going back to our roots&quot;: second generation biocomputing</title><categories>cs.AI cs.NE</categories><comments>Submitted to the International Journal of Unconventional Computing</comments><abstract>  Researchers in the field of biocomputing have, for many years, successfully
&quot;harvested and exploited&quot; the natural world for inspiration in developing
systems that are robust, adaptable and capable of generating novel and even
&quot;creative&quot; solutions to human-defined problems. However, in this position paper
we argue that the time has now come for a reassessment of how we exploit
biology to generate new computational systems. Previous solutions (the &quot;first
generation&quot; of biocomputing techniques), whilst reasonably effective, are crude
analogues of actual biological systems. We believe that a new, inherently
inter-disciplinary approach is needed for the development of the emerging
&quot;second generation&quot; of bio-inspired methods. This new modus operandi will
require much closer interaction between the engineering and life sciences
communities, as well as a bidirectional flow of concepts, applications and
expertise. We support our argument by examining, in this new light, three
existing areas of biocomputing (genetic programming, artificial immune systems
and evolvable hardware), as well as an emerging area (natural genetic
engineering) which may provide useful pointers as to the way forward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512072</id><created>2005-12-18</created><authors><author><keyname>Emiris</keyname><forenames>Ioannis Z.</forenames></author><author><keyname>Tsigaridas</keyname><forenames>Elias P.</forenames></author></authors><title>Computations with one and two real algebraic numbers</title><categories>cs.SC cs.MS</categories><acm-class>I.1.2</acm-class><abstract>  We present algorithmic and complexity results concerning computations with
one and two real algebraic numbers, as well as real solving of univariate
polynomials and bivariate polynomial systems with integer coefficients using
Sturm-Habicht sequences.
  Our main results, in the univariate case, concern the problems of real root
isolation (Th. 19) and simultaneous inequalities (Cor.26) and in the bivariate,
the problems of system real solving (Th.42), sign evaluation (Th. 37) and
simultaneous inequalities (Cor. 43).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512073</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512073</id><created>2005-12-17</created><updated>2015-12-10</updated><authors><author><keyname>Kisil</keyname><forenames>Vladimir V.</forenames></author></authors><title>Schwerdtfeger-Fillmore-Springer-Cnops Construction Implemented in GiNaC</title><categories>cs.MS cs.CG cs.SC</categories><comments>LaTeX, 82 p; 11 PS graphics in two figures, the full source files and
  ISO image of Live DVD are included; v9: library update for the book on
  Moebius transformations; v10: an ISO image of a Live DVD is attached to the
  paper; v11: a bug is fixed; v12: Library is uupdated, the reference to a
  larger project is added</comments><report-no>LEEDS-MATH-PURE-2005-29</report-no><msc-class>51B25, 51N25, 68U05, 11E88, 68W30</msc-class><journal-ref>Adv. Appl. Clifford Algebr. v.17 (2007), no.1, 59-70</journal-ref><doi>10.1007/s00006-006-0017-4</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This paper presents an implementation of the
Schwerdtfeger-Fillmore-Springer-Cnops construction (SFSCc) along with
illustrations of its usage. SFSCc linearises the linear-fraction action of the
Moebius group in R^n. This has clear advantages in several theoretical and
applied fields including engineering. Our implementation is based on the
Clifford algebra capacities of the GiNaC computer algebra system
(http://www.ginac.de/), which were described in cs.MS/0410044.
  The core of this realisation of SFSCc is done for an arbitrary dimension of
R^n with a metric given by an arbitrary bilinear form. We also present a
subclass for two dimensional cycles (i.e. circles, parabolas and hyperbolas),
which add some 2D specific routines including a visualisation to PostScript
files through the MetaPost (http://www.tug.org/metapost.html) or Asymptote
(http://asymptote.sourceforge.net/) packages.
  This software is the backbone of many results published in math.CV/0512416
and we use its applications their for demonstration. The library can be ported
(with various level of required changes) to other CAS with Clifford algebras
capabilities similar to GiNaC.
  There is an ISO image of a Live Debian DVD attached to this paper as an
auxiliary file, a copy is stored on Google Drive as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512074</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512074</id><created>2005-12-18</created><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames></author></authors><title>Analytical Bounds on Maximum-Likelihood Decoded Linear Codes with
  Applications to Turbo-Like Codes: An Overview</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures. Accepted for presentation in Fourth International
  Symposium on Turbo Codes and Related Topics, Munich, Germany, 3--7 April,
  2006</comments><abstract>  Upper and lower bounds on the error probability of linear codes under
maximum-likelihood (ML) decoding are shortly surveyed and applied to ensembles
of codes on graphs. For upper bounds, focus is put on Gallager bounding
techniques and their relation to a variety of other reported bounds. Within the
class of lower bounds, we address de Caen's based bounds and their
improvements, sphere-packing bounds, and information-theoretic bounds on the
bit error probability of codes defined on graphs. A comprehensive overview is
provided in a monograph by the authors which is currently in preparation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512075</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512075</id><created>2005-12-18</created><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author><author><keyname>Wiechman</keyname><forenames>Gil</forenames></author></authors><title>Performance versus Complexity Per Iteration for Low-Density Parity-Check
  Codes: An Information-Theoretic Approach</title><categories>cs.IT math.IT</categories><comments>Accepted for presentation in the Fourth International Symposium on
  Turbo Codes and Related Topics, Munich, Germany, 3--7 April, 2006</comments><abstract>  The paper is focused on the tradeoff between performance and decoding
complexity per iteration for LDPC codes in terms of their gap (in rate) to
capacity. The study of this tradeoff is done via information-theoretic bounds
which also enable to get an indication on the sub-optimality of message-passing
iterative decoding algorithms (as compared to optimal ML decoding). The bounds
are generalized for parallel channels, and are applied to ensembles of
punctured LDPC codes where both intentional and random puncturing are
addressed. This work suggests an improvement in the tightness of some
information-theoretic bounds which were previously derived by Burshtein et al.
and by Sason and Urbanke.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512076</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512076</id><created>2005-12-18</created><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author><author><keyname>Wiechman</keyname><forenames>Gil</forenames></author></authors><title>On Achievable Rates and Complexity of LDPC Codes for Parallel Channels:
  Information-Theoretic Bounds and Applications</title><categories>cs.IT math.IT</categories><comments>5 pages. The paper is submitted to the 2006 IEEE International
  Symposium on Information Theory (ISIT 2006), Seatle, Washington, USA, 9--14
  July, 2006. The full paper version was submitted to the IEEE Trans. on
  Information Theory, August 2005 and is online available at
  http://arxiv.org/abs/cs.IT/0508072</comments><abstract>  The paper presents bounds on the achievable rates and the decoding complexity
of low-density parity-check (LDPC) codes. It is assumed that the communication
of these codes takes place over statistically independent parallel channels
where these channels are memoryless, binary-input and output-symmetric (MBIOS).
The bounds are applied to punctured LDPC codes. A diagram concludes our
discussion by showing interconnections between the theorems in this paper and
some previously reported results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512077</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512077</id><created>2005-12-20</created><updated>2011-12-30</updated><authors><author><keyname>Itkis</keyname><forenames>Gene</forenames></author><author><keyname>Levin</keyname><forenames>Leonid A.</forenames></author></authors><title>Flat Holonomies on Automata Networks</title><categories>cs.DC cs.DM</categories><comments>20 pages, significant revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider asynchronous networks of identical finite (independent of
network's size or topology) automata. Our automata drive any network from any
initial configuration of states, to a coherent one in which it can carry
efficiently any computations implementable on synchronous properly initialized
networks of the same size.
  A useful data structure on such networks is a partial orientation of its
edges. It needs to be flat, i.e. have null holonomy (no excess of up or down
edges in any cycle). It also needs to be centered, i.e. have a unique node with
no down edges.
  There are (interdependent) self-stabilizing asynchronous finite automata
protocols assuring flat centered orientation. Such protocols may vary in
assorted efficiency parameters and it is desirable to have each replaceable
with any alternative, responsible for a simple limited task. We describe an
efficient reduction of any computational task to any such set of protocols
compliant with our interface conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512078</id><created>2005-12-20</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author></authors><title>Graph-Cover Decoding and Finite-Length Analysis of Message-Passing
  Iterative Decoding of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, December 2005</comments><abstract>  The goal of the present paper is the derivation of a framework for the
finite-length analysis of message-passing iterative decoding of low-density
parity-check codes. To this end we introduce the concept of graph-cover
decoding. Whereas in maximum-likelihood decoding all codewords in a code are
competing to be the best explanation of the received vector, under graph-cover
decoding all codewords in all finite covers of a Tanner graph representation of
the code are competing to be the best explanation. We are interested in
graph-cover decoding because it is a theoretical tool that can be used to show
connections between linear programming decoding and message-passing iterative
decoding. Namely, on the one hand it turns out that graph-cover decoding is
essentially equivalent to linear programming decoding. On the other hand,
because iterative, locally operating decoding algorithms like message-passing
iterative decoding cannot distinguish the underlying Tanner graph from any
covering graph, graph-cover decoding can serve as a model to explain the
behavior of message-passing iterative decoding. Understanding the behavior of
graph-cover decoding is tantamount to understanding the so-called fundamental
polytope. Therefore, we give some characterizations of this polytope and
explain its relation to earlier concepts that were introduced to understand the
behavior of message-passing iterative decoding for finite-length codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512079</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512079</id><created>2005-12-20</created><authors><author><keyname>Fossgaard</keyname><forenames>Eirik</forenames></author></authors><title>An invariant bayesian model selection principle for gaussian data in a
  sparse representation</title><categories>cs.IT math.IT</categories><comments>168 pages, PhD-thesis</comments><report-no>82-92461-43-4</report-no><abstract>  We develop a code length principle which is invariant to the choice of
parameterization on the model distributions. An invariant approximation formula
for easy computation of the marginal distribution is provided for gaussian
likelihood models. We provide invariant estimators of the model parameters and
formulate conditions under which these estimators are essentially posteriori
unbiased for gaussian models. An upper bound on the coarseness of
discretization on the model parameters is deduced. We introduce a
discrimination measure between probability distributions and use it to
construct probability distributions on model classes. The total code length is
shown to equal the NML code length of Rissanen to within an additive constant
when choosing Jeffreys prior distribution on the model parameters together with
a particular choice of prior distribution on the model classes. Our model
selection principle is applied to a gaussian estimation problem for data in a
wavelet representation and its performance is tested and compared to
alternative wavelet-based estimation methods in numerical experiments
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512080</id><created>2005-12-20</created><authors><author><keyname>Pivovarov</keyname><forenames>G. B.</forenames></author><author><keyname>Trunov</keyname><forenames>S. E.</forenames></author></authors><title>EqRank: Theme Evolution in Citation Graphs</title><categories>cs.DS cs.DL</categories><comments>8 pages, 7 figs, 2 tables</comments><abstract>  Time evolution of the classification scheme generated by the EqRank algorithm
is studied with hep-th citation graph as an example. Intuitive expectations
about evolution of an adequate classification scheme for a growing set of
objects are formulated. Evolution compliant with these expectations is called
natural. It is demonstrated that EqRank yields a naturally evolving
classification scheme. We conclude that EqRank can be used as a means to detect
new scientific themes, and to track their development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512081</id><created>2005-12-20</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>der Heide</keyname><forenames>Friedhelm Meyer auf</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author></authors><title>De Dictionariis Dynamicis Pauco Spatio Utentibus</title><categories>cs.DS</categories><comments>14 pages. Full version of a paper accepted to LATIN'06</comments><abstract>  We develop dynamic dictionaries on the word RAM that use asymptotically
optimal space, up to constant factors, subject to insertions and deletions, and
subject to supporting perfect-hashing queries and/or membership queries, each
operation in constant time with high probability. When supporting only
membership queries, we attain the optimal space bound of Theta(n lg(u/n)) bits,
where n and u are the sizes of the dictionary and the universe, respectively.
Previous dictionaries either did not achieve this space bound or had time
bounds that were only expected and amortized. When supporting perfect-hashing
queries, the optimal space bound depends on the range {1,2,...,n+t} of
hashcodes allowed as output. We prove that the optimal space bound is Theta(n
lglg(u/n) + n lg(n/(t+1))) bits when supporting only perfect-hashing queries,
and it is Theta(n lg(u/n) + n lg(n/(t+1))) bits when also supporting membership
queries. All upper bounds are new, as is the Omega(n lg(n/(t+1))) lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512082</id><created>2005-12-21</created><authors><author><keyname>Barradas</keyname><forenames>Hector Ruiz</forenames><affiliation>LSR - IMAG</affiliation></author><author><keyname>Bert</keyname><forenames>Didier</forenames><affiliation>LSR - IMAG</affiliation></author></authors><title>A Fixpoint Semantics of Event Systems with and without Fairness
  Assumptions</title><categories>cs.LO</categories><proxy>ccsd ccsd-00016136</proxy><report-no>RR 1081-L LSR 21</report-no><abstract>  We present a fixpoint semantics of event systems. The semantics is presented
in a general framework without concerns of fairness. Soundness and completeness
of rules for deriving &quot;leads-to&quot; properties are proved in this general
framework. The general framework is instantiated to minimal progress and weak
fairness assumptions and similar results are obtained. We show the power of
these results by deriving sufficient conditions for &quot;leads-to&quot; under minimal
progress proving soundness of proof obligations without reasoning over
state-traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512083</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512083</id><created>2005-12-21</created><updated>2005-12-21</updated><authors><author><keyname>Meng</keyname><forenames>Jiangtao</forenames></author></authors><title>New directions in mechanism design</title><categories>cs.GT</categories><abstract>  Mechanism design uses the tools of economics and game theory to design rules
of interaction for economic transactions that will,in principle, yield some de-
sired outcome. In the last few years this field has received much interest of
researchers in computer science, especially with the Internet developing as a
platform for communications and connections among enormous numbers of computers
and humans. Arguably the most positive result in mechanism de- sign is truthful
and there are only one general truthful mechanisms so far : the generalized
Vickrey-Clarke-Groves (VCG) mechanism. But VCG mecha- nism has one shortage:
The implementation of truthfulness is on the cost of decreasing the revenue of
the mechanism. (e.g., Ning Chen and Hong Zhu. [1999]). We introduce three new
characters of mechanism:partly truthful, criti- cal, consistent, and introduce
a new mechanism: X mechanism that satisfy the above three characters. Like VCG
mechanism, X mechanism also generalizes from Vickery Auction and is consistent
with Vickery auction in many ways, but the extended methods used in X mechanism
is different from that in VCG mechanism . This paper will demonstrate that X
mechanism better than VCG mechanism in optimizing utility of mechanism, which
is the original intention of mechanism design. So partly truthful,critical and
consistent are at least as important as truthful in mechanism design, and they
beyond truthful in many situations.As a result, we conclude that partly
truthful,critical and consistent are three new directions in mechanism design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512084</id><created>2005-12-21</created><authors><author><keyname>Sakhanenko</keyname><forenames>Nikita</forenames></author><author><keyname>Makaruk</keyname><forenames>Hanna</forenames></author></authors><title>Understanding physics from interconnected data</title><categories>cs.CV</categories><comments>9 pages, 8 figures</comments><report-no>LA-UR-05-5921</report-no><acm-class>I.4.6; I.4.7; I.5.4</acm-class><abstract>  Metal melting on release after explosion is a physical system far from
quilibrium. A complete physical model of this system does not exist, because
many interrelated effects have to be considered. General methodology needs to
be developed so as to describe and understand physical phenomena involved.
  The high noise of the data, moving blur of images, the high degree of
uncertainty due to the different types of sensors, and the information
entangled and hidden inside the noisy images makes reasoning about the physical
processes very difficult. Major problems include proper information extraction
and the problem of reconstruction, as well as prediction of the missing data.
In this paper, several techniques addressing the first problem are given,
building the basis for tackling the second problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512085</id><created>2005-12-21</created><authors><author><keyname>Holloway</keyname><forenames>Todd</forenames></author><author><keyname>Bozicevic</keyname><forenames>Miran</forenames></author><author><keyname>B&#xf6;rner</keyname><forenames>Katy</forenames></author></authors><title>Analyzing and Visualizing the Semantic Coverage of Wikipedia and Its
  Authors</title><categories>cs.IR</categories><abstract>  This paper presents a novel analysis and visualization of English Wikipedia
data. Our specific interest is the analysis of basic statistics, the
identification of the semantic structure and age of the categories in this free
online encyclopedia, and the content coverage of its highly productive authors.
The paper starts with an introduction of Wikipedia and a review of related
work. We then introduce a suite of measures and approaches to analyze and map
the semantic structure of Wikipedia. The results show that co-occurrences of
categories within individual articles have a power-law distribution, and when
mapped reveal the nicely clustered semantic structure of Wikipedia. The results
also reveal the content coverage of the article's authors, although the roles
these authors play are as varied as the authors themselves. We conclude with a
discussion of major results and planned future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512086</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512086</id><created>2005-12-22</created><updated>2007-10-05</updated><authors><author><keyname>Strassburger</keyname><forenames>Lutz</forenames></author></authors><title>On the Axiomatisation of Boolean Categories with and without Medial</title><categories>cs.LO</categories><comments>66 pages LaTeX, using TAC style, v3: minor changes as requested by
  the referee</comments><abstract>  The term ``Boolean category'' should be used for describing an object that is
to categories what a Boolean algebra is to posets. More specifically, a Boolean
category should provide the abstract algebraic structure underlying the proofs
in Boolean Logic, in the same sense as a Cartesian closed category captures the
proofs in intuitionistic logic and a *-autonomous category captures the proofs
in linear logic. However, recent work has shown that there is no canonical
axiomatisation of a Boolean category. In this work, we will see a series (with
increasing strength) of possible such axiomatisations, all based on the notion
of *-autonomous category. We will particularly focus on the medial map, which
has its origin in an inference rule in KS, a cut-free deductive system for
Boolean logic in the calculus of structures. Finally, we will present a
category of proof nets as a particularly well-behaved example of a Boolean
category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512087</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512087</id><created>2005-12-22</created><updated>2006-05-05</updated><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Fundamental Limits and Scaling Behavior of Cooperative Multicasting in
  Wireless Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>The upper bound in Section (IV) has been modified so that it
  immediately generalizes to the multiple antenna case. The new version does
  not rely on Teletar's conjecture being true. Some additional typos have been
  corrected</comments><abstract>  A framework is developed for analyzing capacity gains from user cooperation
in slow fading wireless networks when the number of nodes (network size) is
large. The framework is illustrated for the case of a simple multipath-rich
Rayleigh fading channel model. Both unicasting (one source and one destination)
and multicasting (one source and several destinations) scenarios are
considered. We introduce a meaningful notion of Shannon capacity for such
systems, evaluate this capacity as a function of signal-to-noise ratio (SNR),
and develop a simple two-phase cooperative network protocol that achieves it.
We observe that the resulting capacity is the same for both unicasting and
multicasting, but show that the network size required to achieve any target
error probability is smaller for unicasting than for multicasting. Finally, we
introduce the notion of a network ``scaling exponent'' to quantify the rate of
decay of error probability with network size as a function of the targeted
fraction of the capacity. This exponent provides additional insights to system
designers by enabling a finer grain comparison of candidate cooperative
transmission protocols in even moderately sized networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512088</identifier>
 <datestamp>2007-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512088</id><created>2005-12-22</created><updated>2007-02-14</updated><authors><author><keyname>Antunes</keyname><forenames>Nelson</forenames></author><author><keyname>Fricker</keyname><forenames>Christine</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author><author><keyname>Tibi</keyname><forenames>Danielle</forenames></author></authors><title>Analysis of loss networks with routing</title><categories>cs.NI math.PR</categories><comments>Published at http://dx.doi.org/10.1214/105051606000000466 in the
  Annals of Applied Probability (http://www.imstat.org/aap/) by the Institute
  of Mathematical Statistics (http://www.imstat.org)</comments><proxy>ccsd inria-00000959</proxy><msc-class>60K35 (Primary) 60K25 (Secondary)</msc-class><journal-ref>Annals of Applied Probability 16, 4 (2006) 2007-2026</journal-ref><abstract>  This paper analyzes stochastic networks consisting of finite capacity nodes
with different classes of requests which move according to some routing policy.
The Markov processes describing these networks do not, in general, have
reversibility properties, so the explicit expression of their invariant
distribution is not known. Kelly's limiting regime is considered: the arrival
rates of calls as well as the capacities of the nodes are proportional to a
factor going to infinity. It is proved that, in limit, the associated rescaled
Markov process converges to a deterministic dynamical system with a unique
equilibrium point characterized by a nonstandard fixed point equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512089</id><created>2005-12-22</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author><author><keyname>Hughes</keyname><forenames>Todd</forenames></author></authors><title>On The Effectiveness of Kolmogorov Complexity Estimation to Discriminate
  Semantic Types</title><categories>cs.NI cs.CR</categories><acm-class>C.2.1</acm-class><journal-ref>SFI Workshop: Resilient and Adaptive Defense of Computing Networks
  2003, Santa Fe Institute, Santa Fe, NM, Nov 5-6, 2003</journal-ref><abstract>  We present progress on the experimental validation of a fundamental and
universally applicable vulnerability analysis framework that is capable of
identifying new types of vulnerabilities before attackers innovate attacks.
This new framework proactively identifies system components that are vulnerable
based upon their Kolmogorov Complexity estimates and it facilitates prediction
of previously unknown vulnerabilities that are likely to be exploited by future
attack methods. A tool that utilizes a growing library of complexity estimators
is presented. This work is an incremental step towards validation of the
concept of complexity-based vulnerability analysis. In particular, results
indicate that data types (semantic types) can be identified by estimates of
their complexity. Thus, a map of complexity can identify suspicious types, such
as executable data embedded within passive data types, without resorting to
predefined headers, signatures, or other limiting a priori information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512090</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512090</id><created>2005-12-23</created><updated>2005-12-29</updated><authors><author><keyname>Lambiotte</keyname><forenames>R.</forenames></author><author><keyname>Ausloos</keyname><forenames>M.</forenames></author></authors><title>Collaborative tagging as a tripartite network</title><categories>cs.DS cs.DL</categories><journal-ref>Lecture Notes in Computer Science, 3993 (2006) 1114 - 1117</journal-ref><doi>10.1007/11758532_152</doi><abstract>  We describe online collaborative communities by tripartite networks, the
nodes being persons, items and tags. We introduce projection methods in order
to uncover the structures of the networks, i.e. communities of users, genre
families...
 To do so, we focus on the correlations between the nodes, depending on their
profiles, and use percolation techniques that consist in removing less
correlated links and observing the shaping of disconnected islands. The
structuring of the network is visualised by using a tree representation. The
notion of diversity in the system is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512091</identifier>
 <datestamp>2015-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512091</id><created>2005-12-22</created><updated>2015-07-15</updated><authors><author><keyname>Aronov</keyname><forenames>Boris</forenames></author><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author></authors><title>Data Structures for Halfplane Proximity Queries and Incremental Voronoi
  Diagrams</title><categories>cs.CG cs.DS</categories><comments>17 pages, 6 figures. Improved grappa trees. Full version of paper
  appearing in LATIN 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider preprocessing a set $S$ of $n$ points in convex position in the
plane into a data structure supporting queries of the following form: given a
point $q$ and a directed line $\ell$ in the plane, report the point of $S$ that
is farthest from (or, alternatively, nearest to) the point $q$ among all points
to the left of line $\ell$. We present two data structures for this problem.
The first data structure uses $O(n^{1+\varepsilon})$ space and preprocessing
time, and answers queries in $O(2^{1/\varepsilon} \log n)$ time, for any $0 &lt;
\varepsilon &lt; 1$. The second data structure uses $O(n \log^3 n)$ space and
polynomial preprocessing time, and answers queries in $O(\log n)$ time. These
are the first solutions to the problem with $O(\log n)$ query time and $o(n^2)$
space.
  The second data structure uses a new representation of nearest- and
farthest-point Voronoi diagrams of points in convex position. This
representation supports the insertion of new points in clockwise order using
only $O(\log n)$ amortized pointer changes, in addition to $O(\log n)$-time
point-location queries, even though every such update may make $\Theta(n)$
combinatorial changes to the Voronoi diagram. This data structure is the first
demonstration that deterministically and incrementally constructed Voronoi
diagrams can be maintained in $o(n)$ amortized pointer changes per operation
while keeping $O(\log n)$-time point-location queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512092</id><created>2005-12-22</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author><author><keyname>Smith</keyname><forenames>Nathan</forenames></author></authors><title>The Limits of Motion Prediction Support for Ad hoc Wireless Network
  Performance</title><categories>cs.NI</categories><comments>Introduces flash routing</comments><acm-class>C.2.1</acm-class><journal-ref>The 2005 International Conference on Wireless Networks (ICWN-05)
  Monte Carlo Resort, Las Vegas, Nevada, USA, June 27-30, 2005</journal-ref><abstract>  A fundamental understanding of gain provided by motion prediction in wireless
ad hoc routing is currently lacking. This paper examines benefits in routing
obtainable via prediction. A theoretical best-case non-predictive routing model
is quantified in terms of both message overhead and update time for
non-predictive routing. This best- case model of existing routing performance
is compared with predictive routing. Several specific instances of predictive
improvements in routing are examined. The primary contribution of this paper is
quantification of predictive gain for wireless ad hoc routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512093</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512093</id><created>2005-12-23</created><authors><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author><author><keyname>Chaturvedi</keyname><forenames>A K</forenames></author><author><keyname>Banerjee</keyname><forenames>Adrish</forenames></author></authors><title>Construction of Turbo Code Interleavers from 3-Regular Hamiltonian
  Graphs</title><categories>cs.IT math.IT</categories><comments>This paper has been accepted for publication in IEEE Communication
  Letters</comments><journal-ref>IEEE Communications Letters, pp. 284-286, Vol. 10, Issue 4, April,
  2006.</journal-ref><doi>10.1109/LCOMM.2006.04013</doi><abstract>  In this letter we present a new construction of interleavers for turbo codes
from 3-regular Hamiltonian graphs. The interleavers can be generated using a
few parameters, which can be selected in such a way that the girth of the
interleaver graph (IG) becomes large, inducing a high summary distance. The
size of the search space for these parameters is derived. The proposed
interleavers themselves work as their de-interleavers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512094</id><created>2005-12-23</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author></authors><title>Low-Energy Sensor Network Time Synchronization as an Emergent Property</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><abstract>  The primary contribution of this work is to examine the energy efficiency of
pulse coupled oscillation for time synchronization in a realistic wireless
network environment and to explore the impact of mobility on convergence rate.
Energy coupled oscillation is susceptible to interference; this approach uses
reception and decoding of short packet bursts to eliminate this problem. The
energy efficiency of a commonly used timestamp broadcast algorithm is compared
and contrasted with pulse-coupled oscillation. The emergent pulse coupled
oscillation technique shows greater energy efficiency as well as robustness
with mobility. A proportion of the sensors may be integrated with GPS receivers
in order to obtain a master clock time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512095</identifier>
 <datestamp>2008-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512095</id><created>2005-12-23</created><authors><author><keyname>Mahadevan</keyname><forenames>Priya</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Fomenkov</keyname><forenames>Marina</forenames></author><author><keyname>Huffaker</keyname><forenames>Bradley</forenames></author><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author><author><keyname>Vahdat</keyname><forenames>Amin</forenames></author></authors><title>The Internet AS-Level Topology: Three Data Sources and One Definitive
  Metric</title><categories>cs.NI physics.soc-ph</categories><comments>This paper is a revised journal version of cs.NI/0508033</comments><acm-class>C.2.5; C.2.1; G.3; G.2.2</acm-class><journal-ref>ACM SIGCOMM Computer Communication Review (CCR), v.36, n.1,
  p.17-26, 2006</journal-ref><doi>10.1145/1111322.1111328</doi><abstract>  We calculate an extensive set of characteristics for Internet AS topologies
extracted from the three data sources most frequently used by the research
community: traceroutes, BGP, and WHOIS. We discover that traceroute and BGP
topologies are similar to one another but differ substantially from the WHOIS
topology. Among the widely considered metrics, we find that the joint degree
distribution appears to fundamentally characterize Internet AS topologies as
well as narrowly define values for other important metrics. We discuss the
interplay between the specifics of the three data collection mechanisms and the
resulting topology views. In particular, we show how the data collection
peculiarities explain differences in the resulting joint degree distributions
of the respective topologies. Finally, we release to the community the input
topology datasets, along with the scripts and output of our calculations. This
supplement should enable researchers to validate their models against real data
and to make more informed selection of topology data sources for their specific
needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512096</id><created>2005-12-24</created><updated>2006-06-21</updated><authors><author><keyname>Laemmel</keyname><forenames>Ralf</forenames></author></authors><title>Book review &quot;The Haskell Road to Logic, Maths and Programming&quot;</title><categories>cs.PL cs.LO</categories><comments>To appear in the JoLLI journal in 2006</comments><acm-class>D.1.1; F.3.1; G.0</acm-class><abstract>  The textbook by Doets and van Eijck puts the Haskell programming language
systematically to work for presenting a major piece of logic and mathematics.
The reader is taken through chapters on basic logic, proof recipes, sets and
lists, relations and functions, recursion and co-recursion, the number systems,
polynomials and power series, ending with Cantor's infinities. The book uses
Haskell for the executable and strongly typed manifestation of various
mathematical notions at the level of declarative programming. The book adopts a
systematic but relaxed mathematical style (definition, example, exercise, ...);
the text is very pleasant to read due to a small amount of anecdotal
information, and due to the fact that definitions are fluently integrated in
the running text. An important goal of the book is to get the reader acquainted
with reasoning about programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512097</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512097</id><created>2005-12-26</created><authors><author><keyname>Liu</keyname><forenames>Jialing</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author></authors><title>Gaussian Channels with Feedback: Optimality, Fundamental Limitations,
  and Connections of Communication, Estimation, and Control</title><categories>cs.IT math.IT</categories><comments>37 pages, 14 figures. The material in this paper was presented in
  part at the 43rd Annual Allerton Conference on Communication, Control, and
  Computing, Monticello, IL, September 2005. This paper was submitted to IEEE
  Transactions on Information Theory in October, 2005</comments><abstract>  Gaussian channels with memory and with noiseless feedback have been widely
studied in the information theory literature. However, a coding scheme to
achieve the feedback capacity is not available. In this paper, a coding scheme
is proposed to achieve the feedback capacity for Gaussian channels. The coding
scheme essentially implements the celebrated Kalman filter algorithm, and is
equivalent to an estimation system over the same channel without feedback. It
reveals that the achievable information rate of the feedback communication
system can be alternatively given by the decay rate of the Cramer-Rao bound of
the associated estimation system. Thus, combined with the control theoretic
characterizations of feedback communication (proposed by Elia), this implies
that the fundamental limitations in feedback communication, estimation, and
control coincide. This leads to a unifying perspective that integrates
information, estimation, and control. We also establish the optimality of the
Kalman filtering in the sense of information transmission, a supplement to the
optimality of Kalman filtering in the sense of information processing proposed
by Mitter and Newton. In addition, the proposed coding scheme generalizes the
Schalkwijk-Kailath codes and reduces the coding complexity and coding delay.
The construction of the coding scheme amounts to solving a finite-dimensional
optimization problem. A simplification to the optimal stationary input
distribution developed by Yang, Kavcic, and Tatikonda is also obtained. The
results are verified in a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512098</id><created>2005-12-26</created><authors><author><keyname>Paukov</keyname><forenames>Dmitry P.</forenames></author></authors><title>Mathematical models of the complex surfaces in simulation and
  visualization systems</title><categories>cs.GR cs.CG</categories><comments>8 pages, 4 figures</comments><abstract>  Modeling, simulation and visualization of three-dimension complex bodies
widely use mathematical model of curves and surfaces. The most important curves
and surfaces for these purposes are curves and surfaces in Hermite and Bezier
forms, splines and NURBS. Article is devoted to survey this way to use
geometrical data in various computer graphics systems and adjacent fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512099</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512099</id><created>2005-12-27</created><authors><author><keyname>Burgin</keyname><forenames>Mark</forenames></author></authors><title>Mathematical Models in Schema Theory</title><categories>cs.AI</categories><acm-class>I.2.4</acm-class><abstract>  In this paper, a mathematical schema theory is developed. This theory has
three roots: brain theory schemas, grid automata, and block-shemas. In Section
2 of this paper, elements of the theory of grid automata necessary for the
mathematical schema theory are presented. In Section 3, elements of brain
theory necessary for the mathematical schema theory are presented. In Section
4, other types of schemas are considered. In Section 5, the mathematical schema
theory is developed. The achieved level of schema representation allows one to
model by mathematical tools virtually any type of schemas considered before,
including schemas in neurophisiology, psychology, computer science, Internet
technology, databases, logic, and mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512100</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512100</id><created>2005-12-28</created><updated>2006-02-11</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>The logic of interactive Turing reduction</title><categories>cs.LO cs.AI math.LO</categories><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Journal of Symbolic Logic 72 (2007), pp. 243-276</journal-ref><doi>10.2178/jsl/1174668394</doi><abstract>  The paper gives a soundness and completeness proof for the implicative
fragment of intuitionistic calculus with respect to the semantics of
computability logic, which understands intuitionistic implication as
interactive algorithmic reduction. This concept -- more precisely, the
associated concept of reducibility -- is a generalization of Turing
reducibility from the traditional, input/output sorts of problems to
computational tasks of arbitrary degrees of interactivity. See
http://www.cis.upenn.edu/~giorgi/cl.html for a comprehensive online source on
computability logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512101</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512101</id><created>2005-12-28</created><updated>2006-05-29</updated><authors><author><keyname>Krishnan</keyname><forenames>K. Murali</forenames></author><author><keyname>Shankar</keyname><forenames>Priti</forenames></author></authors><title>On the Complexity of finding Stopping Distance in Tanner Graphs</title><categories>cs.IT cs.CC math.IT</categories><comments>A decision problem proved NP-complete in the earlier version was not
  equivalent to stopping distance problem for Tanner graphs. Now corrected</comments><journal-ref>IEEE Trans. Info. Theory, 53(6), 2007, pp. 2278-2280.</journal-ref><abstract>  Two decision problems related to the computation of stopping sets in Tanner
graphs are shown to be NP-complete. NP-hardness of the problem of computing the
stopping distance of a Tanner graph follows as a consequence
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512102</identifier>
 <datestamp>2008-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512102</id><created>2005-12-28</created><authors><author><keyname>Buk</keyname><forenames>Solomija</forenames></author><author><keyname>Rovenchak</keyname><forenames>Andrij</forenames></author></authors><title>Statistical Parameters of the Novel &quot;Perekhresni stezhky&quot; (&quot;The
  Cross-Paths&quot;) by Ivan Franko</title><categories>cs.CL</categories><comments>11 pages</comments><journal-ref>Quantitative Linguistics 62: Exact methods in the study of
  language and text: dedicated to Professor Gabriel Altmann on the occasion of
  his 75th birthday / Ed. by P. Grzybek and R. Kohler (Berlin; New York: de
  Gruyter), 39-48 (2007)</journal-ref><abstract>  In the paper, a complex statistical characteristics of a Ukrainian novel is
given for the first time. The distribution of word-forms with respect to their
size is studied. The linguistic laws by Zipf-Mandelbrot and Altmann-Menzerath
are analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512103</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512103</id><created>2005-12-28</created><authors><author><keyname>Mello</keyname><forenames>Louis</forenames></author></authors><title>The Fibonacci Sequence Mod m</title><categories>cs.OH</categories><abstract>  This paper proposes a computational method for obtaining the length of the
cycle that arises from the Fibonacci series taken mod m (some number) and mod p
(some prime number).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512104</id><created>2005-12-28</created><authors><author><keyname>Burger</keyname><forenames>John Robert</forenames></author></authors><title>Reversible CAM Processor Modeled After Quantum Computer Behavior</title><categories>cs.AR quant-ph</categories><acm-class>C.1.2; C.5.4</acm-class><abstract>  Proposed below is a reversible digital computer modeled after the natural
behavior of a quantum system. Using approaches usually reserved for idealized
quantum computers, the Reversible CAM, or State Vector Parallel (RSVP)
processor can easily find keywords in an unstructured database (that is, it can
solve a needle in a haystack problem). The RSVP processor efficiently solves a
SAT (Satisfiability of Boolean Formulae) problem; also it can aid in the
solution of a GP (Global Properties of Truth Table) problem. The power delay
product of the RSVP processor is exponentially lower than that of a standard
CAM programmed to perform similar operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0512105</identifier>
 <datestamp>2011-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0512105</id><created>2005-12-29</created><updated>2011-06-30</updated><authors><author><keyname>Stauffer</keyname><forenames>Alexandre O.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>A study of the edge-switching Markov-chain method for the generation of
  random graphs</title><categories>cs.DM</categories><comments>Minor typos corrected</comments><acm-class>F.2.2; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of generating connected random graphs with no self-loops
or multiple edges and that, in addition, have a given degree sequence. The
generation method we focus on is the edge-switching Markov-chain method, whose
functioning depends on a parameter w related to the method's core operation of
an edge switch. We analyze two existing heuristics for adjusting w during the
generation of a graph and show that they result in a Markov chain whose
stationary distribution is uniform, thus ensuring that generation occurs
uniformly at random. We also introduce a novel w-adjusting heuristic which,
even though it does not always lead to a Markov chain, is still guaranteed to
converge to the uniform distribution under relatively mild conditions. We
report on extensive computer experiments comparing the three heuristics'
performance at generating random graphs whose node degrees are distributed as
power laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601001</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601001</id><created>2006-01-02</created><updated>2007-05-28</updated><authors><author><keyname>Oehlschl&#xe4;gel</keyname><forenames>Jens</forenames></author></authors><title>Truecluster: robust scalable clustering with model selection</title><categories>cs.AI</categories><comments>Article (10 figures). Changes in 2nd version: dropped supplements in
  favor of better integrated presentation, better literature coverage, put into
  proper English. Author's website available via http://www.truecluster.com</comments><acm-class>G.3; I.5.3</acm-class><abstract>  Data-based classification is fundamental to most branches of science. While
recent years have brought enormous progress in various areas of statistical
computing and clustering, some general challenges in clustering remain: model
selection, robustness, and scalability to large datasets. We consider the
important problem of deciding on the optimal number of clusters, given an
arbitrary definition of space and clusteriness. We show how to construct a
cluster information criterion that allows objective model selection. Differing
from other approaches, our truecluster method does not require specific
assumptions about underlying distributions, dissimilarity definitions or
cluster models. Truecluster puts arbitrary clustering algorithms into a generic
unified (sampling-based) statistical framework. It is scalable to big datasets
and provides robust cluster assignments and case-wise diagnostics. Truecluster
will make clustering more objective, allows for automation, and will save time
and costs. Free R software is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601002</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601002</id><created>2006-01-02</created><updated>2008-02-13</updated><authors><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Rote</keyname><forenames>Guenter</forenames></author></authors><title>Minimum-weight triangulation is NP-hard</title><categories>cs.CG cs.CC</categories><comments>45 pages (including a technical appendix of 13 pages), 28 figures.
  This revision contains a few improvements in the exposition</comments><report-no>B 05-23 (revised)</report-no><acm-class>F.2.2; G.2.2</acm-class><journal-ref>Journal of the ACM, 55, no. 2 (May 2008), Article 11, 29 pp.</journal-ref><doi>10.1145/1346330.1346336</doi><abstract>  A triangulation of a planar point set S is a maximal plane straight-line
graph with vertex set S. In the minimum-weight triangulation (MWT) problem, we
are looking for a triangulation of a given point set that minimizes the sum of
the edge lengths. We prove that the decision version of this problem is
NP-hard. We use a reduction from PLANAR-1-IN-3-SAT. The correct working of the
gadgets is established with computer assistance, using dynamic programming on
polygonal faces, as well as the beta-skeleton heuristic to certify that certain
edges belong to the minimum-weight triangulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601003</id><created>2006-01-02</created><authors><author><keyname>Vandeginste</keyname><forenames>Ruben</forenames></author><author><keyname>Demoen</keyname><forenames>Bart</forenames></author></authors><title>Incremental copying garbage collection for WAM-based Prolog systems</title><categories>cs.PL</categories><comments>33 pages, 22 figures, 5 tables. To appear in Theory and Practice of
  Logic Programming (TPLP)</comments><abstract>  The design and implementation of an incremental copying heap garbage
collector for WAM-based Prolog systems is presented. Its heap layout consists
of a number of equal-sized blocks. Other changes to the standard WAM allow
these blocks to be garbage collected independently. The independent collection
of heap blocks forms the basis of an incremental collecting algorithm which
employs copying without marking (contrary to the more frequently used mark&amp;copy
or mark&amp;slide algorithms in the context of Prolog). Compared to standard
semi-space copying collectors, this approach to heap garbage collection lowers
in many cases the memory usage and reduces pause times. The algorithm also
allows for a wide variety of garbage collection policies including generational
ones. The algorithm is implemented and evaluated in the context of hProlog.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601004</id><created>2006-01-03</created><authors><author><keyname>Girard</keyname><forenames>Beno&#xee;t</forenames><affiliation>LIP6, LPPA</affiliation></author><author><keyname>Filliat</keyname><forenames>David</forenames><affiliation>LIP6</affiliation></author><author><keyname>Meyer</keyname><forenames>Jean-Arcady</forenames><affiliation>LIP6</affiliation></author><author><keyname>Berthoz</keyname><forenames>Alain</forenames><affiliation>LPPA</affiliation></author><author><keyname>Guillot</keyname><forenames>Agn&#xe8;s</forenames><affiliation>LIP6</affiliation></author></authors><title>Integration of navigation and action selection functionalities in a
  computational model of cortico-basal ganglia-thalamo-cortical loops</title><categories>cs.AI cs.RO</categories><proxy>ccsd ccsd-00016389</proxy><journal-ref>Adaptive Behavior 13 (2005) 115-130</journal-ref><doi>10.1177/105971230501300204</doi><abstract>  This article describes a biomimetic control architecture affording an animat
both action selection and navigation functionalities. It satisfies the survival
constraint of an artificial metabolism and supports several complementary
navigation strategies. It builds upon an action selection model based on the
basal ganglia of the vertebrate brain, using two interconnected cortico-basal
ganglia-thalamo-cortical loops: a ventral one concerned with appetitive actions
and a dorsal one dedicated to consummatory actions. The performances of the
resulting model are evaluated in simulation. The experiments assess the
prolonged survival permitted by the use of high level navigation strategies and
the complementarity of navigation strategies in dynamic environments. The
correctness of the behavioral choices in situations of antagonistic or
synergetic internal states are also tested. Finally, the modelling choices are
discussed with regard to their biomimetic plausibility, while the experimental
results are estimated in terms of animat adaptivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601005</id><created>2006-01-04</created><authors><author><keyname>Ke</keyname><forenames>J-Y</forenames></author><author><keyname>Yao</keyname><forenames>Y.</forenames></author></authors><title>Analyzing language development from a network approach</title><categories>cs.CL</categories><comments>22 pages, 12 figures</comments><abstract>  In this paper we propose some new measures of language development using
network analyses, which is inspired by the recent surge of interests in network
studies of many real-world systems. Children's and care-takers' speech data
from a longitudinal study are represented as a series of networks, word forms
being taken as nodes and collocation of words as links. Measures on the
properties of the networks, such as size, connectivity, hub and authority
analyses, etc., allow us to make quantitative comparison so as to reveal
different paths of development. For example, the asynchrony of development in
network size and average degree suggests that children cannot be simply
classified as early talkers or late talkers by one or two measures. Children
follow different paths in a multi-dimensional space. They may develop faster in
one dimension but slower in another dimension. The network approach requires
little preprocessing of words and analyses on sentence structures, and the
characteristics of words and their usage emerge from the network and are
independent of any grammatical presumptions. We show that the change of the two
articles &quot;the&quot; and &quot;a&quot; in their roles as important nodes in the network
reflects the progress of children's syntactic development: the two articles
often start in children's networks as hubs and later shift to authorities,
while they are authorities constantly in the adult's networks. The network
analyses provide a new approach to study language development, and at the same
time language development also presents a rich area for network theories to
explore.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601006</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601006</id><created>2006-01-04</created><authors><author><keyname>Zhong</keyname><forenames>Y.</forenames></author><author><keyname>Alajaji</keyname><forenames>F.</forenames></author><author><keyname>Campbell</keyname><forenames>L. L.</forenames></author></authors><title>On the Joint Source-Channel Coding Error Exponent for Discrete
  Memoryless Systems: Computation and Comparison with Separate Coding</title><categories>cs.IT math.IT</categories><comments>Technical Report, December 2005</comments><abstract>  We investigate the computation of Csiszar's bounds for the joint
source-channel coding (JSCC) error exponent, E_J, of a communication system
consisting of a discrete memoryless source and a discrete memoryless channel.
We provide equivalent expressions for these bounds and derive explicit formulas
for the rates where the bounds are attained. These equivalent representations
can be readily computed for arbitrary source-channel pairs via Arimoto's
algorithm. When the channel's distribution satisfies a symmetry property, the
bounds admit closed-form parametric expressions. We then use our results to
provide a systematic comparison between the JSCC error exponent E_J and the
tandem coding error exponent E_T, which applies if the source and channel are
separately coded. It is shown that E_T &lt;= E_J &lt;= 2E_T. We establish conditions
for which E_J &gt; E_T and for which E_J = 2E_T. Numerical examples indicate that
E_J is close to 2E_T for many source-channel pairs. This gain translates into a
power saving larger than 2 dB for a binary source transmitted over additive
white Gaussian noise channels and Rayleigh fading channels with finite output
quantization. Finally, we study the computation of the lossy JSCC error
exponent under the Hamming distortion measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601007</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601007</id><created>2006-01-04</created><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author><author><keyname>Mitter</keyname><forenames>Sanjoy</forenames></author></authors><title>The necessity and sufficiency of anytime capacity for stabilization of a
  linear system over a noisy communication link Part I: scalar systems</title><categories>cs.IT math.IT</categories><comments>27 pages, submitted to Information Theory Transactions</comments><abstract>  We review how Shannon's classical notion of capacity is not enough to
characterize a noisy communication channel if the channel is intended to be
used as part of a feedback loop to stabilize an unstable scalar linear system.
While classical capacity is not enough, another sense of capacity (parametrized
by reliability) called ``anytime capacity'' is shown to be necessary for the
stabilization of an unstable process. The required rate is given by the log of
the unstable system gain and the required reliability comes from the sense of
stability desired. A consequence of this necessity result is a sequential
generalization of the Schalkwijk/Kailath scheme for communication over the AWGN
channel with feedback.
  In cases of sufficiently rich information patterns between the encoder and
decoder, adequate anytime capacity is also shown to be sufficient for there to
exist a stabilizing controller. These sufficiency results are then generalized
to cases with noisy observations, delayed control actions, and without any
explicit feedback between the observer and the controller. Both necessary and
sufficient conditions are extended to continuous time systems as well. We close
with comments discussing a hierarchy of difficulty for communication problems
and how these results establish where stabilization problems sit in that
hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601008</id><created>2006-01-05</created><updated>2006-01-05</updated><authors><author><keyname>Moszkowski</keyname><forenames>Ben</forenames></author></authors><title>A Hierarchical Analysis of Propositional Temporal Logic Based on
  Intervals</title><categories>cs.LO</categories><comments>64 pages, revised and expanded version of published work. An earlier
  version of this appeared in &quot;We Will Show Them: Essays in Honour of Dov
  Gabbay on his 60th Birthday&quot;, Volume 2. S. Artemov, H. Barringer, A. S.
  d'Avila Garcez, L. C. Lamb, and J. Woods (editors.), pages 371-440, College
  Publications (formely KCL Publications), King's College, London, 2005,
  http://www.collegepublications.co.uk</comments><acm-class>F.4.1</acm-class><abstract>  We present a hierarchical framework for analysing propositional linear-time
temporal logic (PTL) to obtain standard results such as a small model property,
decision procedures and axiomatic completeness. Both finite time and infinite
time are considered and one consequent benefit of the framework is the ability
to systematically reduce infinite-time reasoning to finite-time reasoning. The
treatment of PTL with both the operator Until and past time naturally reduces
to that for PTL without either one. Our method utilises a low-level normal form
for PTL called a &quot;transition configuration&quot;. In addition, we employ reasoning
about intervals of time. Besides being hierarchical and interval-based, the
approach differs from other analyses of PTL typically based on sets of formulas
and sequences of such sets. Instead we describe models using time intervals
represented as finite and infinite sequences of states. The analysis relates
larger intervals with smaller ones. Steps involved are expressed in
Propositional Interval Temporal Logic (PITL) which is better suited than PTL
for sequentially combining and decomposing formulas. Consequently, we can
articulate issues in PTL model construction of equal relevance in more
conventional analyses but normally only considered at the metalevel. We also
describe a decision procedure based on Binary Decision Diagrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601009</identifier>
 <datestamp>2008-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601009</id><created>2006-01-05</created><updated>2008-04-14</updated><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>Gaussian Fading is the Worst Fading</title><categories>cs.IT math.IT</categories><comments>Presented at the IEEE International Symposium on Information Theory
  (ISIT) 2006; replaced with version that appears in the proceedings</comments><abstract>  The capacity of peak-power limited, single-antenna, non-coherent, flat-fading
channels with memory is considered. The emphasis is on the capacity pre-log,
i.e., on the limiting ratio of channel capacity to the logarithm of the
signal-to-noise ratio (SNR), as the SNR tends to infinity. It is shown that,
among all stationary and ergodic fading processes of a given spectral
distribution function whose law has no mass point at zero, the Gaussian process
gives rise to the smallest pre-log.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601010</id><created>2006-01-05</created><authors><author><keyname>Zhang</keyname><forenames>Xiaowen</forenames></author><author><keyname>Shu</keyname><forenames>Li</forenames></author><author><keyname>Tang</keyname><forenames>Ke</forenames></author></authors><title>Multi-Map Orbit Hopping Chaotic Stream Cipher</title><categories>cs.CR</categories><comments>9 pages</comments><acm-class>D.4.6; E.3</acm-class><abstract>  In this paper we propose a multi-map orbit hopping chaotic stream cipher that
utilizes the idea of spread spectrum mechanism for secure digital
communications and fundamental chaos characteristics of mixing, unpredictable,
and extremely sensitive to initial conditions. The design, key and subkeys, and
detail implementation of the system are addressed. A variable number of well
studied chaotic maps form a map bank. And the key determines how the system
hops between multiple orbits, and it also determines the number of maps, the
number of orbits for each map, and the number of sample points for each orbits.
A detailed example is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601011</id><created>2006-01-05</created><updated>2006-04-13</updated><authors><author><keyname>Hatami</keyname><forenames>Hamed</forenames></author><author><keyname>Magen</keyname><forenames>Avner</forenames></author><author><keyname>Markakis</keyname><forenames>Vangelis</forenames></author></authors><title>Integrality gaps of semidefinite programs for Vertex Cover and relations
  to $\ell_1$ embeddability of Negative Type metrics</title><categories>cs.DS cs.DM math.MG</categories><comments>A more complete version. Changed order of results. A complete proof
  of (current) Theorem 5</comments><abstract>  We study various SDP formulations for {\sc Vertex Cover} by adding different
constraints to the standard formulation. We show that {\sc Vertex Cover} cannot
be approximated better than $2-o(1)$ even when we add the so called pentagonal
inequality constraints to the standard SDP formulation, en route answering an
open question of Karakostas~\cite{Karakostas}. We further show the surprising
fact that by strengthening the SDP with the (intractable) requirement that the
metric interpretation of the solution is an $\ell_1$ metric, we get an exact
relaxation (integrality gap is 1), and on the other hand if the solution is
arbitrarily close to being $\ell_1$ embeddable, the integrality gap may be as
big as $2-o(1)$. Finally, inspired by the above findings, we use ideas from the
integrality gap construction of Charikar \cite{Char02} to provide a family of
simple examples for negative type metrics that cannot be embedded into $\ell_1$
with distortion better than $8/7-\eps$. To this end we prove a new
isoperimetric inequality for the hypercube.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601012</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601012</id><created>2006-01-05</created><updated>2007-02-18</updated><authors><author><keyname>Madan</keyname><forenames>Ritesh</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Leveque</keyname><forenames>Olivier</forenames></author></authors><title>Product Multicommodity Flow in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Revised version of &quot;Capacity-Delay Scaling in Arbitrary Wireless
  Networks&quot; submitted to the IEEE Transactions on Information Theory. Part of
  this work appeared in the Allerton Conference on Communication, Control, and
  Computing, Monticello, IL, 2005, and the Internation Symposium on Information
  Theory (ISIT), 2006</comments><abstract>  We provide a tight approximate characterization of the $n$-dimensional
product multicommodity flow (PMF) region for a wireless network of $n$ nodes.
Separate characterizations in terms of the spectral properties of appropriate
network graphs are obtained in both an information theoretic sense and for a
combinatorial interference model (e.g., Protocol model). These provide an inner
approximation to the $n^2$ dimensional capacity region. These results answer
the following questions which arise naturally from previous work: (a) What is
the significance of $1/\sqrt{n}$ in the scaling laws for the Protocol
interference model obtained by Gupta and Kumar (2000)? (b) Can we obtain a
tight approximation to the &quot;maximum supportable flow&quot; for node distributions
more general than the geometric random distribution, traffic models other than
randomly chosen source-destination pairs, and under very general assumptions on
the channel fading model?
  We first establish that the random source-destination model is essentially a
one-dimensional approximation to the capacity region, and a special case of
product multi-commodity flow. Building on previous results, for a combinatorial
interference model given by a network and a conflict graph, we relate the
product multicommodity flow to the spectral properties of the underlying graphs
resulting in computational upper and lower bounds. For the more interesting
random fading model with additive white Gaussian noise (AWGN), we show that the
scaling laws for PMF can again be tightly characterized by the spectral
properties of appropriately defined graphs. As an implication, we obtain
computationally efficient upper and lower bounds on the PMF for any wireless
network with a guaranteed approximation factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601013</id><created>2006-01-05</created><authors><author><keyname>Silva</keyname><forenames>Josep</forenames></author><author><keyname>Vidal</keyname><forenames>Germ&#xe1;n</forenames></author></authors><title>Forward slicing of functional logic programs by partial evaluation</title><categories>cs.PL cs.LO</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><acm-class>D.3.4; I.2.2</acm-class><abstract>  Program slicing has been mainly studied in the context of imperative
languages, where it has been applied to a wide variety of software engineering
tasks, like program understanding, maintenance, debugging, testing, code reuse,
etc. This work introduces the first forward slicing technique for declarative
multi-paradigm programs which integrate features from functional and logic
programming. Basically, given a program and a slicing criterion (a function
call in our setting), the computed forward slice contains those parts of the
original program which are reachable from the slicing criterion. Our approach
to program slicing is based on an extension of (online) partial evaluation.
Therefore, it provides a simple way to develop program slicing tools from
existing partial evaluators and helps to clarify the relation between both
methodologies. A slicing tool for the multi-paradigm language Curry, which
demonstrates the usefulness of our approach, has been implemented in Curry
itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601014</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601014</id><created>2006-01-05</created><updated>2013-11-14</updated><authors><author><keyname>Feng</keyname><forenames>Yuan</forenames></author><author><keyname>Duan</keyname><forenames>Runyao</forenames></author><author><keyname>Ji</keyname><forenames>Zhengfeng</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Probabilistic bisimilarities between quantum processes</title><categories>cs.LO quant-ph</categories><comments>Journal version</comments><acm-class>F.1.2</acm-class><journal-ref>Information and Computation 2007, 205:1608-1639</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling and reasoning about concurrent quantum systems is very important
both for distributed quantum computing and for quantum protocol verification.
As a consequence, a general framework describing formally the communication and
concurrency in complex quantum systems is necessary. For this purpose, we
propose a model qCCS which is a natural quantum extension of classical
value-passing CCS with the input and output of quantum states, and unitary
transformations and measurements on quantum systems. The operational semantics
of qCCS is given based on probabilistic labeled transition system. This
semantics has many different features compared with the proposals in literature
in order to describe input and output of quantum systems which are possibly
correlated with other components. Based on this operational semantics, we
introduce the notions of strong probabilistic bisimilarity and weak
probabilistic bisimilarity between quantum processes and discuss some
properties of them, such as congruence under various combinators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601015</identifier>
 <datestamp>2007-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601015</id><created>2006-01-06</created><authors><author><keyname>Antunes</keyname><forenames>Nelson</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Fricker</keyname><forenames>Christine</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author></authors><title>Perturbation Analysis of a Variable M/M/1 Queue: A Probabilistic
  Approach</title><categories>cs.NI</categories><proxy>ccsd inria-00000896</proxy><journal-ref>Advances in Applied Probability 38, 1 (2006) 263-283</journal-ref><abstract>  Motivated by the problem of the coexistence on transmission links of
telecommunication networks of elastic and unresponsive traffic, we study in
this paper the impact on the busy period of an M/M/1 queue of a small
perturbation in the server rate. The perturbation depends upon an independent
stationary process (X(t)) and is quantified by means of a parameter \eps \ll 1.
We specifically compute the two first terms of the power series expansion in
\eps of the mean value of the busy period duration. This allows us to study the
validity of the Reduced Service Rate (RSR) approximation, which consists in
comparing the perturbed M/M/1 queue with the M/M/1 queue where the service rate
is constant and equal to the mean value of the perturbation. For the first term
of the expansion, the two systems are equivalent. For the second term, the
situation is more complex and it is shown that the correlations of the
environment process (X(t)) play a key role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601016</identifier>
 <datestamp>2007-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601016</id><created>2006-01-06</created><authors><author><keyname>Antunes</keyname><forenames>Nelson</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Fricker</keyname><forenames>Christine</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author></authors><title>Integration of streaming services and TCP data transmission in the
  Internet</title><categories>cs.NI</categories><proxy>ccsd inria-00000898</proxy><journal-ref>Performance Evaluation 62, 1-4 (2006) 263-277</journal-ref><doi>10.1016/j.peva.2005.07.006</doi><abstract>  We study in this paper the integration of elastic and streaming traffic on a
same link in an IP network. We are specifically interested in the computation
of the mean bit rate obtained by a data transfer. For this purpose, we consider
that the bit rate offered by streaming traffic is low, of the order of
magnitude of a small parameter \eps \ll 1 and related to an auxiliary
stationary Markovian process (X(t)). Under the assumption that data transfers
are exponentially distributed, arrive according to a Poisson process, and share
the available bandwidth according to the ideal processor sharing discipline, we
derive the mean bit rate of a data transfer as a power series expansion in
\eps. Since the system can be described by means of an M/M/1 queue with a
time-varying server rate, which depends upon the parameter \eps and process
(X(t)), the key issue is to compute an expansion of the area swept under the
occupation process of this queue in a busy period. We obtain closed formulas
for the power series expansion in \eps of the mean bit rate, which allow us to
verify the validity of the so-called reduced service rate at the first order.
The second order term yields more insight into the negative impact of the
variability of streaming flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601017</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601017</id><created>2006-01-06</created><updated>2006-07-07</updated><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author></authors><title>Weighted Norms of Ambiguity Functions and Wigner Distributions</title><categories>cs.IT math.IT quant-ph</categories><comments>5 twocolumn pages,2 figures, accepted for 2006 IEEE International
  Symposium on Information Theory, typos corrected, some additional cites,
  legend in Fig.2 corrected</comments><abstract>  In this article new bounds on weighted p-norms of ambiguity functions and
Wigner functions are derived. Such norms occur frequently in several areas of
physics and engineering. In pulse optimization for Weyl--Heisenberg signaling
in wide-sense stationary uncorrelated scattering channels for example it is a
key step to find the optimal waveforms for a given scattering statistics which
is a problem also well known in radar and sonar waveform optimizations. The
same situation arises in quantum information processing and optical
communication when optimizing pure quantum states for communicating in bosonic
quantum channels, i.e. find optimal channel input states maximizing the pure
state channel fidelity. Due to the non-convex nature of this problem the
optimum and the maximizers itself are in general difficult find, numerically
and analytically. Therefore upper bounds on the achievable performance are
important which will be provided by this contribution. Based on a result due to
E. Lieb, the main theorem states a new upper bound which is independent of the
waveforms and becomes tight only for Gaussian weights and waveforms. A
discussion of this particular important case, which tighten recent results on
Gaussian quantum fidelity and coherent states, will be given. Another bound is
presented for the case where scattering is determined only by some arbitrary
region in phase space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601018</id><created>2006-01-06</created><authors><author><keyname>Palomino</keyname><forenames>Miguel</forenames></author></authors><title>A comparison between two logical formalisms for rewriting</title><categories>cs.LO</categories><comments>31 pages, 2 figures To appear in Theory and Practice of Logic
  Programming</comments><acm-class>D.1.6; F.3.1</acm-class><abstract>  Meseguer's rewriting logic and the rewriting logic CRWL are two well-known
approaches to rewriting as logical deduction that, despite some clear
similarities, were designed with different objectives. Here we study the
relationships between them, both at a syntactic and at a semantic level. Even
though it is not possible to establish an entailment system map between them,
both can be naturally simulated in each other. Semantically, there is no
embedding between the corresponding institutions. Along the way, the notions of
entailment and satisfaction in Meseguer's rewriting logic are generalized. We
also use the syntactic results to prove reflective properties of CRWL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601019</id><created>2006-01-06</created><updated>2006-11-21</updated><authors><author><keyname>Reilles</keyname><forenames>Antoine</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Canonical Abstract Syntax Trees</title><categories>cs.PL</categories><proxy>ccsd inria-00000967</proxy><journal-ref>Dans Workshop on Rewriting Techniques and Applications (2006)</journal-ref><abstract>  This paper presents Gom, a language for describing abstract syntax trees and
generating a Java implementation for those trees. Gom includes features
allowing the user to specify and modify the interface of the data structure.
These features provide in particular the capability to maintain the internal
representation of data in canonical form with respect to a rewrite system. This
explicitly guarantees that the client program only manipulates normal forms for
this rewrite system, a feature which is only implicitly used in many
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601020</id><created>2006-01-06</created><authors><author><keyname>Majuca</keyname><forenames>Ruperto P.</forenames></author><author><keyname>Yurcik</keyname><forenames>William</forenames></author><author><keyname>Kesan</keyname><forenames>Jay P.</forenames></author></authors><title>The Evolution of Cyberinsurance</title><categories>cs.CR cs.CY</categories><comments>16 pages, 6 tables, 2 figures</comments><acm-class>K.6.5</acm-class><abstract>  Cyberinsurance is a powerful tool to align market incentives toward improving
Internet security. We trace the evolution of cyberinsurance from traditional
insurance policies to early cyber-risk insurance policies to current
comprehensive cyberinsurance products. We find that increasing Internet
security risk in combination with the need for compliance with recent corporate
legislation has contributed significantly to the demand for cyberinsurance.
Cyberinsurance policies have become more comprehensive as insurers better
understand the risk landscape and specific business needs. More specifically,
cyberinsurers are addressing what used to be considered insurmountable problems
(e.g., adverse selection/asymmetric information, moral hazard, etc.) that could
lead to a failure of this market solution. Although some implementation issues
remain, we suggest the future development of cyberinsurance will resolve these
issues as evidenced by insurance solutions in other risk domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601021</id><created>2006-01-07</created><authors><author><keyname>Haubold</keyname><forenames>Alexander</forenames></author></authors><title>Lighting Control using Pressure-Sensitive Touchpads</title><categories>cs.HC</categories><acm-class>B.4.2; H.5.2</acm-class><abstract>  We introduce a novel approach to control physical lighting parameters by
means of a pressure-sensitive touchpad. The two-dimensional area of the
touchpad is subdivided into 5 virtual sliders, each controlling the intensity
of a color (red, green, blue, yellow, and white). The physical interaction
methodology is modeled directly after ubiquitous mechanical sliders and dimmers
which tend to be used for intensity/volume control. Our abstraction to a
pressure-sensitive touchpad provides advantages and introduces additional
benefits over such existing devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601022</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601022</id><created>2006-01-08</created><authors><author><keyname>Moser</keyname><forenames>Stefan M.</forenames></author></authors><title>On the Fading Number of Multiple-Input Single-Output Fading Channels
  with Memory</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE International Symposium on Information Theory
  (ISIT) 2006</comments><acm-class>H.1.1</acm-class><abstract>  We derive new upper and lower bounds on the fading number of multiple-input
single-output (MISO) fading channels of general (not necessarily Gaussian)
regular law with spatial and temporal memory. The fading number is the second
term, after the double-logarithmic term, of the high signal-to-noise ratio
(SNR) expansion of channel capacity.
  In case of an isotropically distributed fading vector it is proven that the
upper and lower bound coincide, i.e., the general MISO fading number with
memory is known precisely.
  The upper and lower bounds show that a type of beam-forming is asymptotically
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601023</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601023</id><created>2006-01-09</created><updated>2006-02-10</updated><authors><author><keyname>Shankar</keyname><forenames>Priti</forenames></author><author><keyname>Kumar</keyname><forenames>P. N. A.</forenames></author><author><keyname>Sasidharan</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. S.</forenames></author><author><keyname>Madhu</keyname><forenames>A. S.</forenames></author></authors><title>Efficient Convergent Maximum Likelihood Decoding on Tail-Biting
  Trellises</title><categories>cs.IT math.IT</categories><comments>23 pages, 8 figures, Submitted to IEEE Transactions on Information
  Theory. Figures 7 and 8 replaced</comments><abstract>  An algorithm for exact maximum likelihood(ML) decoding on tail-biting
trellises is presented, which exhibits very good average case behavior. An
approximate variant is proposed, whose simulated performance is observed to be
virtually indistinguishable from the exact one at all values of signal to noise
ratio, and which effectively performs computations equivalent to at most two
rounds on the tail-biting trellis. The approximate algorithm is analyzed, and
the conditions under which its output is different from the ML output are
deduced. The results of simulations on an AWGN channel for the exact and
approximate algorithms on the 16 state tail-biting trellis for the (24,12)
Extended Golay Code, and tail-biting trellises for two rate 1/2 convolutional
codes with memories of 4 and 6 respectively, are reported. An advantage of our
algorithms is that they do not suffer from the effects of limit cycles or the
presence of pseudocodewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601024</id><created>2006-01-09</created><authors><author><keyname>Xu</keyname><forenames>Hong</forenames></author><author><keyname>Qi</keyname><forenames>Wen-Feng</forenames></author></authors><title>Further Results on the Distinctness of Decimations of l-sequences</title><categories>cs.CR</categories><comments>submitted to IEEE-IT</comments><abstract>  Let $\underline{a}$ be an \textit{l}-sequence generated by a
feedback-with-carry shift register with connection integer $q=p^{e}$, where $
p$ is an odd prime and $e\geq 1$. Goresky and Klapper conjectured that when $
p^{e}\notin \{5,9,11,13\}$, all decimations of $\underline{a}$ are cyclically
distinct. When $e=1$ and $p&gt;13$, they showed that the set of distinct
decimations is large and, in some cases, all deciamtions are distinct. In this
article, we further show that when $e\geq 2$ and$ p^{e}\neq 9$, all decimations
of $\underline{a}$ are also cyclically distinct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601025</id><created>2006-01-09</created><authors><author><keyname>Ortega</keyname><forenames>Michael</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Coquillart</keyname><forenames>Sabine</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Prop-Based Haptic Interaction with Co-location and Immersion: an
  Automotive Application</title><categories>cs.HC</categories><proxy>ccsd inria-00000962</proxy><journal-ref>Dans HAVE 2005 - IEEE International Workshop on Haptic Audio
  Visual Environments and their Applications</journal-ref><abstract>  Most research on 3D user interfaces aims at providing only a single sensory
modality. One challenge is to integrate several sensory modalities into a
seamless system while preserving each modality's immersion and performance
factors. This paper concerns manipulation tasks and proposes a visuo-haptic
system integrating immersive visualization, tactile force and tactile feedback
with co-location. An industrial application is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601026</id><created>2006-01-09</created><authors><author><keyname>Harvey</keyname><forenames>Nicholas J. A.</forenames></author></authors><title>Algebraic Structures and Algorithms for Matching and Matroid Problems
  (Preliminary Version)</title><categories>cs.DS cs.DM</categories><abstract>  Basic path-matchings, introduced by Cunningham and Geelen (FOCS 1996), are a
common generalization of matroid intersection and non-bipartite matching. The
main results of this paper are a new algebraic characterization of basic
path-matching problems and an algorithm for constructing basic path-matchings
in O(n^w) time, where n is the number of vertices and w is the exponent for
matrix multiplication. Our algorithms are randomized, and our approach assumes
that the given matroids are linear and can be represented over the same field.
  Our main results have interesting consequences for several special cases of
path-matching problems. For matroid intersection, we obtain an algorithm with
running time O(nr^(w-1))=O(nr^1.38), where the matroids have n elements and
rank r. This improves the long-standing bound of O(nr^1.62) due to Gabow and Xu
(FOCS 1989). Also, we obtain a simple, purely algebraic algorithm for
non-bipartite matching with running time O(n^w). This resolves the central open
problem of Mucha and Sankowski (FOCS 2004).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601027</id><created>2006-01-09</created><authors><author><keyname>Lev&#xe9;</keyname><forenames>Florence</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Richomme</keyname><forenames>Gw&#xe9;na&#xeb;l</forenames><affiliation>LaRIA</affiliation></author></authors><title>Quasiperiodic Sturmian words and morphisms</title><categories>cs.DM</categories><proxy>ccsd ccsd-00016679</proxy><abstract>  We characterize all quasiperiodic Sturmian words: a Sturmian word is not
quasiperiodic if and only if it is a Lyndon word. Moreover, we study links
between Sturmian morphisms and quasiperiodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601028</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601028</id><created>2006-01-09</created><updated>2006-05-22</updated><authors><author><keyname>Bross</keyname><forenames>Shraga</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Tinguely</keyname><forenames>Stephan</forenames></author></authors><title>Superimposed Coded and Uncoded Transmissions of a Gaussian Source over
  the Gaussian Channel</title><categories>cs.IT math.IT</categories><comments>three pages, to appear in Proceedings International Symposium on
  Information Theory 2006</comments><acm-class>E.4</acm-class><abstract>  We propose to send a Gaussian source over an average-power limited additive
white Gaussian noise channel by transmitting a linear combination of the source
sequence and the result of its quantization using a high dimensional Gaussian
vector quantizer. We show that, irrespective of the rate of the vector
quantizer (assumed to be fixed and smaller than the channel's capacity), this
transmission scheme is asymptotically optimal (as the quantizer's dimension
tends to infinity) under the mean squared-error fidelity criterion. This
generalizes the classical result of Goblick about the optimality of scaled
uncoded transmission, which corresponds to choosing the rate of the vector
quantizer as zero, and the classical source-channel separation approach, which
corresponds to choosing the rate of the vector quantizer arbitrarily close to
the capacity of the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601029</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601029</id><created>2006-01-09</created><updated>2006-05-22</updated><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Tinguely</keyname><forenames>Stephan</forenames></author></authors><title>Sending a Bi-Variate Gaussian Source over a Gaussian MAC</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in Proceedings International Symposium on
  Information Theory 2006</comments><acm-class>E.4</acm-class><abstract>  We consider a problem where a memoryless bi-variate Gaussian source is to be
transmitted over an additive white Gaussian multiple-access channel with two
transmitting terminals and one receiving terminal. The first transmitter only
sees the first source component and the second transmitter only sees the second
source component. We are interested in the pair of mean squared-error
distortions at which the receiving terminal can reproduce each of the source
components.
  It is demonstrated that in the symmetric case, below a certain
signal-to-noise ratio (SNR) threshold, which is determined by the source
correlation, uncoded communication is optimal. For SNRs above this threshold we
present outer and inner bounds on the achievable distortions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601030</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601030</id><created>2006-01-09</created><authors><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Journal Status</title><categories>cs.DL cs.CY</categories><comments>16 pages</comments><report-no>LA-UR-05-6466</report-no><acm-class>H.3.7</acm-class><journal-ref>Scientometrics, volume 69, number 3, pp. 669-687, 2006</journal-ref><doi>10.1007/s11192-006-0176-z</doi><abstract>  The status of an actor in a social context is commonly defined in terms of
two factors: the total number of endorsements the actor receives from other
actors and the prestige of the endorsing actors. These two factors indicate the
distinction between popularity and expert appreciation of the actor,
respectively. We refer to the former as popularity and to the latter as
prestige. These notions of popularity and prestige also apply to the domain of
scholarly assessment. The ISI Impact Factor (ISI IF) is defined as the mean
number of citations a journal receives over a 2 year period. By merely counting
the amount of citations and disregarding the prestige of the citing journals,
the ISI IF is a metric of popularity, not of prestige. We demonstrate how a
weighted version of the popular PageRank algorithm can be used to obtain a
metric that reflects prestige. We contrast the rankings of journals according
to their ISI IF and their weighted PageRank, and we provide an analysis that
reveals both significant overlaps and differences. Furthermore, we introduce
the Y-factor which is a simple combination of both the ISI IF and the weighted
PageRank, and find that the resulting journal rankings correspond well to a
general understanding of journal status.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601031</id><created>2006-01-09</created><authors><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Sav&#xe9;ant</keyname><forenames>Pierre</forenames><affiliation>TRT</affiliation></author><author><keyname>Vidal</keyname><forenames>Vincent</forenames><affiliation>CRIL</affiliation></author></authors><title>Divide-and-Evolve: a New Memetic Scheme for Domain-Independent Temporal
  Planning</title><categories>cs.AI</categories><proxy>ccsd inria-00000975</proxy><journal-ref>Dans EvoCOP2006</journal-ref><abstract>  An original approach, termed Divide-and-Evolve is proposed to hybridize
Evolutionary Algorithms (EAs) with Operational Research (OR) methods in the
domain of Temporal Planning Problems (TPPs). Whereas standard Memetic
Algorithms use local search methods to improve the evolutionary solutions, and
thus fail when the local method stops working on the complete problem, the
Divide-and-Evolve approach splits the problem at hand into several, hopefully
easier, sub-problems, and can thus solve globally problems that are intractable
when directly fed into deterministic OR algorithms. But the most prominent
advantage of the Divide-and-Evolve approach is that it immediately opens up an
avenue for multi-objective optimization, even though the OR method that is used
is single-objective. Proof of concept approach on the standard
(single-objective) Zeno transportation benchmark is given, and a small original
multi-objective benchmark is proposed in the same Zeno framework to assess the
multi-objective capabilities of the proposed methodology, a breakthrough in
Temporal Planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601032</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601032</id><created>2006-01-09</created><updated>2006-09-26</updated><authors><author><keyname>Babaian</keyname><forenames>Tamara</forenames></author><author><keyname>Schmolze</keyname><forenames>James G.</forenames></author></authors><title>Efficient Open World Reasoning for Planning</title><categories>cs.AI cs.LO</categories><comments>39 pages, 13 figures. to appear in Logical Methods in Computer
  Science</comments><acm-class>I.2.4; I.2.8; F.4.1; F.2.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 3 (September
  26, 2006) lmcs:851</journal-ref><doi>10.2168/LMCS-2(3:5)2006</doi><abstract>  We consider the problem of reasoning and planning with incomplete knowledge
and deterministic actions. We introduce a knowledge representation scheme
called PSIPLAN that can effectively represent incompleteness of an agent's
knowledge while allowing for sound, complete and tractable entailment in
domains where the set of all objects is either unknown or infinite. We present
a procedure for state update resulting from taking an action in PSIPLAN that is
correct, complete and has only polynomial complexity. State update is performed
without considering the set of all possible worlds corresponding to the
knowledge state. As a result, planning with PSIPLAN is done without direct
manipulation of possible worlds. PSIPLAN representation underlies the PSIPOP
planning algorithm that handles quantified goals with or without exceptions
that no other domain independent planner has been shown to achieve. PSIPLAN has
been implemented in Common Lisp and used in an application on planning in a
collaborative interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601033</id><created>2006-01-09</created><authors><author><keyname>Klein</keyname><forenames>Rolf</forenames></author><author><keyname>Kutz</keyname><forenames>Martin</forenames></author></authors><title>The density of iterated crossing points and a gap result for
  triangulations of finite point sets</title><categories>cs.CG</categories><comments>10 pages + appendix</comments><abstract>  Consider a plane graph G, drawn with straight lines. For every pair a,b of
vertices of G, we compare the shortest-path distance between a and b in G (with
Euclidean edge lengths) to their actual distance in the plane. The worst-case
ratio of these two values, for all pairs of points, is called the dilation of
G. All finite plane graphs of dilation 1 have been classified. They are closely
related to the following iterative procedure. For a given point set P in R^2,
we connect every pair of points in P by a line segment and then add to P all
those points where two such line segments cross. Repeating this process
infinitely often, yields a limit point set P*.
  The main result of this paper is the following gap theorem: For any finite
point set P in the plane for which the above P* is infinite, there exists a
threshold t &gt; 1 such that P is not contained in the vertex set of any finite
plane graph of dilation at most t. We construct a concrete point set Q such
that any planar graph that contains this set amongst its vertices must have a
dilation larger than 1.0000047.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601034</id><created>2006-01-09</created><updated>2006-05-15</updated><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Weissman</keyname><forenames>Vicky</forenames></author></authors><title>Using First-Order Logic to Reason about Policies</title><categories>cs.LO cs.CR</categories><comments>39 pages, earlier version in Proceedings of the Sixteenth IEEE
  Computer Security Foundations Workshop, 2003, pp. 187-201</comments><acm-class>H.2.7; K.4.4</acm-class><abstract>  A policy describes the conditions under which an action is permitted or
forbidden. We show that a fragment of (multi-sorted) first-order logic can be
used to represent and reason about policies. Because we use first-order logic,
policies have a clear syntax and semantics. We show that further restricting
the fragment results in a language that is still quite expressive yet is also
tractable. More precisely, questions about entailment, such as `May Alice
access the file?', can be answered in time that is a low-order polynomial
(indeed, almost linear in some cases), as can questions about the consistency
of policy sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601035</id><created>2006-01-10</created><authors><author><keyname>Colonna</keyname><forenames>Francois</forenames><affiliation>LCT</affiliation></author></authors><title>Deductive Object Programming</title><categories>cs.SE</categories><comments>20 pages</comments><proxy>ccsd ccsd-00016672</proxy><abstract>  We propose some slight additions to O-O languages to implement the necessary
features for using Deductive Object Programming (DOP). This way of programming
based upon the manipulation of the Production Tree of the Objects of Interest,
result in making Persistent these Objects and in sensibly lowering the code
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601036</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601036</id><created>2006-01-10</created><authors><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author><author><keyname>Jungers</keyname><forenames>Raphael</forenames></author><author><keyname>Protasov</keyname><forenames>Vladimir</forenames></author></authors><title>On the complexity of computing the capacity of codes that avoid
  forbidden difference patterns</title><categories>cs.IT math.IT</categories><comments>7 pages. Submitted to IEEE Trans. on Information Theory</comments><abstract>  We consider questions related to the computation of the capacity of codes
that avoid forbidden difference patterns. The maximal number of $n$-bit
sequences whose pairwise differences do not contain some given forbidden
difference patterns increases exponentially with $n$. The exponent is the
capacity of the forbidden patterns, which is given by the logarithm of the
joint spectral radius of a set of matrices constructed from the forbidden
difference patterns. We provide a new family of bounds that allows for the
approximation, in exponential time, of the capacity with arbitrary high degree
of accuracy. We also provide a polynomial time algorithm for the problem of
determining if the capacity of a set is positive, but we prove that the same
problem becomes NP-hard when the sets of forbidden patterns are defined over an
extended set of symbols. Finally, we prove the existence of extremal norms for
the sets of matrices arising in the capacity computation. This result makes it
possible to apply a specific (even though non polynomial) approximation
algorithm. We illustrate this fact by computing exactly the capacity of codes
that were only known approximately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601037</id><created>2006-01-10</created><authors><author><keyname>Delzanno</keyname><forenames>Giorgio</forenames></author></authors><title>Constraint-based verification of abstract models of multitreaded
  programs</title><categories>cs.CL cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming</comments><abstract>  We present a technique for the automated verification of abstract models of
multithreaded programs providing fresh name generation, name mobility, and
unbounded control.
  As high level specification language we adopt here an extension of
communication finite-state machines with local variables ranging over an
infinite name domain, called TDL programs. Communication machines have been
proved very effective for representing communication protocols as well as for
representing abstractions of multithreaded software.
  The verification method that we propose is based on the encoding of TDL
programs into a low level language based on multiset rewriting and constraints
that can be viewed as an extension of Petri Nets. By means of this encoding,
the symbolic verification procedure developed for the low level language in our
previous work can now be applied to TDL programs. Furthermore, the encoding
allows us to isolate a decidable class of verification problems for TDL
programs that still provide fresh name generation, name mobility, and unbounded
control. Our syntactic restrictions are in fact defined on the internal
structure of threads: In order to obtain a complete and terminating method,
threads are only allowed to have at most one local variable (ranging over an
infinite domain of names).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601038</id><created>2006-01-10</created><authors><author><keyname>Delzanno</keyname><forenames>Giorgio</forenames></author></authors><title>Constraint-based automatic verification of abstract models of
  multithreaded programs</title><categories>cs.LO cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming</comments><abstract>  We present a technique for the automated verification of abstract models of
multithreaded programs providing fresh name generation, name mobility, and
unbounded control.
  As high level specification language we adopt here an extension of
communication finite-state machines with local variables ranging over an
infinite name domain, called TDL programs. Communication machines have been
proved very effective for representing communication protocols as well as for
representing abstractions of multithreaded software.
  The verification method that we propose is based on the encoding of TDL
programs into a low level language based on multiset rewriting and constraints
that can be viewed as an extension of Petri Nets. By means of this encoding,
the symbolic verification procedure developed for the low level language in our
previous work can now be applied to TDL programs. Furthermore, the encoding
allows us to isolate a decidable class of verification problems for TDL
programs that still provide fresh name generation, name mobility, and unbounded
control. Our syntactic restrictions are in fact defined on the internal
structure of threads: In order to obtain a complete and terminating method,
threads are only allowed to have at most one local variable (ranging over an
infinite domain of names).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601039</id><created>2006-01-10</created><authors><author><keyname>Alpuente</keyname><forenames>Maria</forenames></author><author><keyname>Escobar</keyname><forenames>Santiago</forenames></author><author><keyname>Lucas</keyname><forenames>Salvador</forenames></author></authors><title>Removing Redundant Arguments Automatically</title><categories>cs.PL</categories><comments>Accepted for publication in Theory and Practice of Logic Programming</comments><acm-class>D.2.4; F.3.1; F.3.3; I.2.2; I.2.5</acm-class><abstract>  The application of automatic transformation processes during the formal
development and optimization of programs can introduce encumbrances in the
generated code that programmers usually (or presumably) do not write. An
example is the introduction of redundant arguments in the functions defined in
the program. Redundancy of a parameter means that replacing it by any
expression does not change the result. In this work, we provide methods for the
analysis and elimination of redundant arguments in term rewriting systems as a
model for the programs that can be written in more sophisticated languages. On
the basis of the uselessness of redundant arguments, we also propose an erasure
procedure which may avoid wasteful computations while still preserving the
semantics (under ascertained conditions). A prototype implementation of these
methods has been undertaken, which demonstrates the practicality of our
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601040</identifier>
 <datestamp>2009-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601040</id><created>2006-01-10</created><authors><author><keyname>Parent</keyname><forenames>Michel</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>New Technologies for Sustainable Urban Transport in Europe</title><categories>cs.RO</categories><proxy>ccsd inria-00000986</proxy><journal-ref>Transportation Research Board 85th Annual Meeting (2006)</journal-ref><abstract>  In the past few years, the European Commission has financed several projects
to examine how new technologies could improve the sustainability of European
cities. These technologies concern new public transportation modes such as
guided buses to form high capacity networks similar to light rail but at a
lower cost and better flexibility, PRT (Personal Rapid Transit) and cybercars
(small urban vehicles with fully automatic driving capabilities to be used in
carsharing mode, mostly as a complement to mass transport). They also concern
private vehicles with technologies which could improve the efficiency of the
vehicles as well as their safety (Intelligent Speed Adaptation, Adaptive Cruise
&gt;.Control, Stop&amp;Go, Lane Keeping,...) and how these new vehicles can complement
mass transport in the form of car-sharing services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601041</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601041</id><created>2006-01-10</created><authors><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>Oblivious channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE International Symposium on Information Theory
  (ISIT) 2006</comments><abstract>  Let C = {x_1,...,x_N} \subset {0,1}^n be an [n,N] binary error correcting
code (not necessarily linear). Let e \in {0,1}^n be an error vector. A codeword
x in C is said to be &quot;disturbed&quot; by the error e if the closest codeword to x +
e is no longer x. Let A_e be the subset of codewords in C that are disturbed by
e. In this work we study the size of A_e in random codes C (i.e. codes in which
each codeword x_i is chosen uniformly and independently at random from
{0,1}^n). Using recent results of Vu [Random Structures and Algorithms 20(3)]
on the concentration of non-Lipschitz functions, we show that |A_e| is strongly
concentrated for a wide range of values of N and ||e||.
  We apply this result in the study of communication channels we refer to as
&quot;oblivious&quot;. Roughly speaking, a channel W(y|x) is said to be oblivious if the
error distribution imposed by the channel is independent of the transmitted
codeword x. For example, the well studied Binary Symmetric Channel is an
oblivious channel.
  In this work, we define oblivious and partially oblivious channels and
present lower bounds on their capacity. The oblivious channels we define have
connections to Arbitrarily Varying Channels with state constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601042</id><created>2006-01-10</created><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames><affiliation>Eds.</affiliation></author><author><keyname>Harrison</keyname><forenames>John</forenames><affiliation>Eds.</affiliation></author><author><keyname>Schuermann</keyname><forenames>Carsten</forenames><affiliation>Eds.</affiliation></author></authors><title>LPAR-05 Workshop: Empirically Successfull Automated Reasoning in
  Higher-Order Logic (ESHOL)</title><categories>cs.AI cs.LO</categories><comments>Workshop Proceedings</comments><abstract>  This workshop brings together practioners and researchers who are involved in
the everyday aspects of logical systems based on higher-order logic. We hope to
create a friendly and highly interactive setting for discussions around the
following four topics. Implementation and development of proof assistants based
on any notion of impredicativity, automated theorem proving tools for
higher-order logic reasoning systems, logical framework technology for the
representation of proofs in higher-order logic, formal digital libraries for
storing, maintaining and querying databases of proofs.
  We envision attendees that are interested in fostering the development and
visibility of reasoning systems for higher-order logics. We are particularly
interested in a discusssion on the development of a higher-order version of the
TPTP and in comparisons of the practical strengths of automated higher-order
reasoning systems. Additionally, the workshop includes system demonstrations.
  ESHOL is the successor of the ESCAR and ESFOR workshops held at CADE 2005 and
IJCAR 2004.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601043</id><created>2006-01-11</created><authors><author><keyname>Cadoli</keyname><forenames>Marco</forenames></author><author><keyname>Mancini</keyname><forenames>Toni</forenames></author></authors><title>Combining Relational Algebra, SQL, Constraint Modelling, and Local
  Search</title><categories>cs.AI cs.LO</categories><comments>30 pages, 5 figures</comments><abstract>  The goal of this paper is to provide a strong integration between constraint
modelling and relational DBMSs. To this end we propose extensions of standard
query languages such as relational algebra and SQL, by adding constraint
modelling capabilities to them. In particular, we propose non-deterministic
extensions of both languages, which are specially suited for combinatorial
problems. Non-determinism is introduced by means of a guessing operator, which
declares a set of relations to have an arbitrary extension. This new operator
results in languages with higher expressive power, able to express all problems
in the complexity class NP. Some syntactical restrictions which make data
complexity polynomial are shown. The effectiveness of both extensions is
demonstrated by means of several examples. The current implementation, written
in Java using local search techniques, is described. To appear in Theory and
Practice of Logic Programming (TPLP)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601044</id><created>2006-01-11</created><authors><author><keyname>Gagn&#xe9;</keyname><forenames>Christian</forenames><affiliation>INRIA Futurs, LVSN, IIS</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Parizeau</keyname><forenames>Marc</forenames><affiliation>LVSN</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>IIS</affiliation></author></authors><title>Genetic Programming, Validation Sets, and Parsimony Pressure</title><categories>cs.LG</categories><proxy>ccsd inria-00000996</proxy><journal-ref>Dans EuroGP 2006</journal-ref><abstract>  Fitness functions based on test cases are very common in Genetic Programming
(GP). This process can be assimilated to a learning task, with the inference of
models from a limited number of samples. This paper is an investigation on two
methods to improve generalization in GP-based learning: 1) the selection of the
best-of-run individuals using a three data sets methodology, and 2) the
application of parsimony pressure in order to reduce the complexity of the
solutions. Results using GP in a binary classification setup show that while
the accuracy on the test sets is preserved, with less variances compared to
baseline results, the mean tree size obtained with the tested methods is
significantly reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601045</id><created>2006-01-11</created><authors><author><keyname>Kurland</keyname><forenames>Oren</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author></authors><title>PageRank without hyperlinks: Structural re-ranking using links induced
  by language models</title><categories>cs.IR cs.CL</categories><acm-class>H.3.3; I.2.7</acm-class><journal-ref>Proceedings of SIGIR 2005, pp. 306--313</journal-ref><abstract>  Inspired by the PageRank and HITS (hubs and authorities) algorithms for Web
search, we propose a structural re-ranking approach to ad hoc information
retrieval: we reorder the documents in an initially retrieved set by exploiting
asymmetric relationships between them. Specifically, we consider generation
links, which indicate that the language model induced from one document assigns
high probability to the text of another; in doing so, we take care to prevent
bias against long documents. We study a number of re-ranking criteria based on
measures of centrality in the graphs formed by generation links, and show that
integrating centrality into standard language-model-based retrieval is quite
effective at improving precision at top ranks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601046</id><created>2006-01-11</created><authors><author><keyname>Kurland</keyname><forenames>Oren</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author><author><keyname>Domshlak</keyname><forenames>Carmel</forenames></author></authors><title>Better than the real thing? Iterative pseudo-query processing using
  cluster-based language models</title><categories>cs.IR cs.CL</categories><acm-class>H.3.3; I.2.7</acm-class><journal-ref>Proceedings of SIGIR 2005, pp. 19--26</journal-ref><abstract>  We present a novel approach to pseudo-feedback-based ad hoc retrieval that
uses language models induced from both documents and clusters. First, we treat
the pseudo-feedback documents produced in response to the original query as a
set of pseudo-queries that themselves can serve as input to the retrieval
process. Observing that the documents returned in response to the
pseudo-queries can then act as pseudo-queries for subsequent rounds, we arrive
at a formulation of pseudo-query-based retrieval as an iterative process.
Experiments show that several concrete instantiations of this idea, when
applied in conjunction with techniques designed to heighten precision, yield
performance results rivaling those of a number of previously-proposed
algorithms, including the standard language-modeling approach. The use of
cluster-based language models is a key contributing factor to our algorithms'
success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601047</id><created>2006-01-12</created><authors><author><keyname>Araujo</keyname><forenames>Lourdes</forenames></author><author><keyname>Merelo</keyname><forenames>Juan J.</forenames></author></authors><title>Automatic Detection of Trends in Dynamical Text: An Evolutionary
  Approach</title><categories>cs.IR cs.NE</categories><comments>22 pages, submitted to Journal of Information Retrieval</comments><abstract>  This paper presents an evolutionary algorithm for modeling the arrival dates
of document streams, which is any time-stamped collection of documents, such as
newscasts, e-mails, IRC conversations, scientific journals archives and weblog
postings. This algorithm assigns frequencies (number of document arrivals per
time unit) to time intervals so that it produces an optimal fit to the data.
The optimization is a trade off between accurately fitting the data and
avoiding too many frequency changes; this way the analysis is able to find fits
which ignore the noise. Classical dynamic programming algorithms are limited by
memory and efficiency requirements, which can be a problem when dealing with
long streams. This suggests to explore alternative search methods which allow
for some degree of uncertainty to achieve tractability. Experiments have shown
that the designed evolutionary algorithm is able to reach the same solution
quality as those classical dynamic programming algorithms in a shorter time. We
have also explored different probabilistic models to optimize the fitting of
the date streams, and applied these algorithms to infer whether a new arrival
increases or decreases {\em interest} in the topic the document stream is
about.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601048</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601048</id><created>2006-01-12</created><authors><author><keyname>Takeshita</keyname><forenames>Oscar Y.</forenames></author></authors><title>Permutation Polynomial Interleavers: An Algebraic-Geometric Perspective</title><categories>cs.IT cs.DM math.IT</categories><comments>25 pages, 11 figures, 6 tables, submitted to IEEE Trans. on Inform.
  Theory</comments><abstract>  An interleaver is a critical component for the channel coding
  performance of turbo codes. Algebraic constructions are
  important because they admit analytical designs and
  simple, practical hardware implementation. The spread factor of an
  interleaver is a common measure for turbo coding
  applications. Maximum-spread interleavers are interleavers whose
  spread factors achieve the upper bound. An infinite sequence of
  quadratic permutation polynomials over integer rings that generate
  maximum-spread interleavers is presented. New properties of
  permutation polynomial interleavers are investigated from an
  algebraic-geometric perspective resulting in a new non-linearity metric
  for interleavers. A new interleaver metric that is a function of both
  the non-linearity metric and the spread factor is proposed.
  It is numerically demonstrated that the spread factor has a
  diminishing importance with the block length. A table of good
  interleavers for a variety of interleaver lengths according to the
  new metric is listed. Extensive computer simulation results with impressive
  frame error rates confirm the efficacy of the new metric. Further,
  when tail-biting constituent codes are used, the resulting turbo
  codes are quasi-cyclic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601049</id><created>2006-01-13</created><authors><author><keyname>Thomas</keyname><forenames>Tony</forenames></author><author><keyname>Lal</keyname><forenames>Arbind Kumar</forenames></author></authors><title>Undeniable Signature Schemes Using Braid Groups</title><categories>cs.CR</categories><abstract>  Artin's braid groups have been recently suggested as a new source for
public-key cryptography. In this paper we propose the first undeniable
signature schemes using the conjugacy problem and the decomposition problem in
the braid groups which are believed to be hard problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601050</id><created>2006-01-13</created><authors><author><keyname>Vinokur</keyname><forenames>Alex</forenames></author></authors><title>Computing Fibonacci numbers on a Turing Machine</title><categories>cs.DM</categories><comments>5 pages, 1 table</comments><acm-class>F.1.1</acm-class><abstract>  A Turing machine that computes Fibonacci numbers is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601051</id><created>2006-01-13</created><updated>2006-02-08</updated><authors><author><keyname>Son</keyname><forenames>Tran Cao</forenames></author><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author></authors><title>A Constructive Semantic Characterization of Aggregates in ASP</title><categories>cs.AI cs.LO cs.PL cs.SC</categories><comments>21 pages</comments><acm-class>D.1.6; D.3.1; D.3.2; D.3.3</acm-class><abstract>  This technical note describes a monotone and continuous fixpoint operator to
compute the answer sets of programs with aggregates. The fixpoint operator
relies on the notion of aggregate solution. Under certain conditions, this
operator behaves identically to the three-valued immediate consequence operator
$\Phi^{aggr}_P$ for aggregate programs, independently proposed Pelov et al.
This operator allows us to closely tie the computational complexity of the
answer set checking and answer sets existence problems to the cost of checking
a solution of the aggregates in the program. Finally, we relate the semantics
described by the operator to other proposals for logic programming with
aggregates.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601052</id><created>2006-01-13</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Artificial and Biological Intelligence</title><categories>cs.AI</categories><comments>16 pages</comments><journal-ref>ACM Ubiquity, vol. 6, number 42, 2005, pp. 1-20</journal-ref><abstract>  This article considers evidence from physical and biological sciences to show
machines are deficient compared to biological systems at incorporating
intelligence. Machines fall short on two counts: firstly, unlike brains,
machines do not self-organize in a recursive manner; secondly, machines are
based on classical logic, whereas Nature's intelligence may depend on quantum
mechanics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601053</id><created>2006-01-14</created><authors><author><keyname>Al-Jumaily</keyname><forenames>Adel</forenames></author><author><keyname>Leung</keyname><forenames>Cindy</forenames></author></authors><title>Wavefront Propagation and Fuzzy Based Autonomous Navigation</title><categories>cs.RO</categories><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No2.
  (2005)</journal-ref><abstract>  Path planning and obstacle avoidance are the two major issues in any
navigation system. Wavefront propagation algorithm, as a good path planner, can
be used to determine an optimal path. Obstacle avoidance can be achieved using
possibility theory. Combining these two functions enable a robot to
autonomously navigate to its destination. This paper presents the approach and
results in implementing an autonomous navigation system for an indoor mobile
robot. The system developed is based on a laser sensor used to retrieve data to
update a two dimensional world model of therobot environment. Waypoints in the
path are incorporated into the obstacle avoidance. Features such as ageing of
objects and smooth motion planning are implemented to enhance efficiency and
also to cater for dynamic environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601054</id><created>2006-01-14</created><authors><author><keyname>Etxebarria</keyname><forenames>Victor</forenames></author><author><keyname>Sanz</keyname><forenames>Arantza</forenames></author><author><keyname>Lizarraga</keyname><forenames>Ibone</forenames></author></authors><title>Control of a Lightweight Flexible Robotic Arm Using Sliding Modes</title><categories>cs.RO</categories><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No2.
  (2005)</journal-ref><abstract>  This paper presents a robust control scheme for flexible link robotic
manipulators, which is based on considering the flexible mechanical structure
as a system with slow (rigid) and fast (flexible) modes that can be controlled
separately. The rigid dynamics is controlled by means of a robust sliding-mode
approach with wellestablished stability properties while an LQR optimal design
is adopted for the flexible dynamics. Experimental results show that this
composite approach achieves good closed loop tracking properties both for the
rigid and the flexible dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601055</id><created>2006-01-14</created><authors><author><keyname>Geramifard</keyname><forenames>Alborz</forenames></author><author><keyname>Nayeri</keyname><forenames>Peyman</forenames></author><author><keyname>Zamani-Nasab</keyname><forenames>Reza</forenames></author><author><keyname>Habibi</keyname><forenames>Jafar</forenames></author></authors><title>A Hybrid Three Layer Architecture for Fire Agent Management in Rescue
  Simulation Environment</title><categories>cs.RO</categories><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No2.
  (2005)</journal-ref><abstract>  This paper presents a new architecture called FAIS for imple- menting
intelligent agents cooperating in a special Multi Agent environ- ment, namely
the RoboCup Rescue Simulation System. This is a layered architecture which is
customized for solving fire extinguishing problem. Structural decision making
algorithms are combined with heuristic ones in this model, so it's a hybrid
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601056</id><created>2006-01-14</created><authors><author><keyname>Huang</keyname><forenames>Panfeng</forenames></author><author><keyname>Xu</keyname><forenames>Yangsheng</forenames></author><author><keyname>Liang</keyname><forenames>Bin</forenames></author></authors><title>Dynamic Balance Control of Multi-arm Free-Floating Space Robots</title><categories>cs.RO</categories><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No2.
  (2005)</journal-ref><abstract>  This paper investigates the problem of the dynamic balance control of
multi-arm free-floating space robot during capturing an active object in close
proximity. The position and orientation of space base will be affected during
the operation of space manipulator because of the dynamics coupling between the
manipulator and space base. This dynamics coupling is unique characteristics of
space robot system. Such a disturbance will produce a serious impact between
the manipulator hand and the object. To ensure reliable and precise operation,
we propose to develop a space robot system consisting of two arms, with one arm
(mission arm) for accomplishing the capture mission, and the other one (balance
arm) compensating for the disturbance of the base. We present the coordinated
control concept for balance of the attitude of the base using the balance arm.
The mission arm can move along the given trajectory to approach and capture the
target with no considering the disturbance from the coupling of the base. We
establish a relationship between the motion of two arm that can realize the
zeros reaction to the base. The simulation studies verified the validity and
efficiency of the proposed control method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601057</id><created>2006-01-14</created><authors><author><keyname>Mailah</keyname><forenames>Musa</forenames></author><author><keyname>Pitowarno</keyname><forenames>Endra</forenames></author><author><keyname>Jamaluddin</keyname><forenames>Hishamuddin</forenames></author></authors><title>Robust Motion Control for Mobile Manipulator Using Resolved Acceleration
  and Proportional-Integral Active Force Control</title><categories>cs.RO</categories><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No2.
  (2005)</journal-ref><abstract>  A resolved acceleration control (RAC) and proportional-integral active force
control (PIAFC) is proposed as an approach for the robust motion control of a
mobile manipulator (MM) comprising a differentially driven wheeled mobile
platform with a two-link planar arm mounted on top of the platform. The study
emphasizes on the integrated kinematic and dynamic control strategy in which
the RAC is used to manipulate the kinematic component while the PIAFC is
implemented to compensate the dynamic effects including the bounded
known/unknown disturbances and uncertainties. The effectivenss and robustness
of the proposed scheme are investigated through a rigorous simulation study and
later complemented with experimental results obtained through a number of
experiments performed on a fully developed working prototype in a laboratory
environment. A number of disturbances in the form of vibratory and impact
forces are deliberately introduced into the system to evaluate the system
performances. The investigation clearly demonstrates the extreme robustness
feature of the proposed control scheme compared to other systems considered in
the study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601058</id><created>2006-01-14</created><authors><author><keyname>Sdahl</keyname><forenames>Michael</forenames></author><author><keyname>Kuhlenkoetter</keyname><forenames>Bernd</forenames></author></authors><title>CAGD - Computer Aided Gripper Design for a Flexible Gripping System</title><categories>cs.RO</categories><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No2.
  (2005)</journal-ref><abstract>  This paper is a summary of the recently accomplished research work on
flexible gripping systems. The goal is to develop a gripper which can be used
for a great amount of geometrically variant workpieces. The economic aspect is
of particular importance during the whole development. The high flexibility of
the gripper is obtained by three parallel used principles. These are human and
computer based analysis of the gripping object as well as mechanical adaptation
of the gripper to the object with the help of servo motors. The focus is on the
gripping of free-form surfaces with suction cup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601059</id><created>2006-01-14</created><authors><author><keyname>Li</keyname><forenames>Shu-qin</forenames></author><author><keyname>Shuai</keyname><forenames>Lan</forenames></author><author><keyname>Cheng</keyname><forenames>Xian-yi</forenames></author><author><keyname>Tang</keyname><forenames>Zhen-min</forenames></author><author><keyname>Yang</keyname><forenames>Jing-yu</forenames></author></authors><title>A Descriptive Model of Robot Team and the Dynamic Evolution of Robot
  Team Cooperation</title><categories>cs.RO</categories><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No2.
  (2005)</journal-ref><abstract>  At present, the research on robot team cooperation is still in qualitative
analysis phase and lacks the description model that can quantitatively describe
the dynamical evolution of team cooperative relationships with constantly
changeable task demand in Multi-robot field. First this paper whole and static
describes organization model HWROM of robot team, then uses Markov course and
Bayesian theorem for reference, dynamical describes the team cooperative
relationships building. Finally from cooperative entity layer, ability layer
and relative layer we research team formation and cooperative mechanism, and
discuss how to optimize relative action sets during the evolution. The dynamic
evolution model of robot team and cooperative relationships between robot teams
proposed and described in this paper can not only generalize the robot team as
a whole, but also depict the dynamic evolving process quantitatively. Users can
also make the prediction of the cooperative relationship and the action of the
robot team encountering new demands based on this model. Journal web page &amp; a
lot of robotic related papers www.ars-journal.com
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601060</id><created>2006-01-14</created><authors><author><keyname>Bogatyreva</keyname><forenames>Olga</forenames></author><author><keyname>Shillerov</keyname><forenames>Alexandr</forenames></author></authors><title>Robot Swarms in an Uncertain World: Controllable Adaptability</title><categories>cs.RO</categories><comments>Journal web page &amp; a lot of robotic related papers
  www.ars-journal.com</comments><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No3.
  (2005)</journal-ref><abstract>  There is a belief that complexity and chaos are essential for adaptability.
But life deals with complexity every moment, without the chaos that engineers
fear so, by invoking goal-directed behaviour. Goals can be programmed. That is
why living organisms give us hope to achieve adaptability in robots. In this
paper a method for the description of a goal-directed, or programmed,
behaviour, interacting with uncertainty of environment, is described. We
suggest reducing the structural (goals, intentions) and stochastic components
(probability to realise the goal) of individual behaviour to random variables
with nominal values to apply probabilistic approach. This allowed us to use a
Normalized Entropy Index to detect the system state by estimating the
contribution of each agent to the group behaviour. The number of possible group
states is 27. We argue that adaptation has a limited number of possible paths
between these 27 states. Paths and states can be programmed so that after
adjustment to any particular case of task and conditions, adaptability will
never involve chaos. We suggest the application of the model to operation of
robots or other devices in remote and/or dangerous places.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601061</id><created>2006-01-14</created><authors><author><keyname>Topalova</keyname><forenames>I.</forenames></author></authors><title>Modular Adaptive System Based on a Multi-Stage Neural Structure for
  Recognition of 2D Objects of Discontinuous Production</title><categories>cs.RO</categories><comments>www.ars-journal.com</comments><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No1.
  (2005)</journal-ref><abstract>  This is a presentation of a new system for invariant recognition of 2D
objects with overlapping classes, that can not be effectively recognized with
the traditional methods. The translation, scale and partial rotation invariant
contour object description is transformed in a DCT spectrum space. The obtained
frequency spectrums are decomposed into frequency bands in order to feed
different BPG neural nets (NNs). The NNs are structured in three stages -
filtering and full rotation invariance; partial recognition; general
classification. The designed multi-stage BPG Neural Structure shows very good
accuracy and flexibility when tested with 2D objects used in the discontinuous
production. The reached speed and the opportunuty for an easy restructuring and
reprogramming of the system makes it suitable for application in different
applied systems for real time work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601062</id><created>2006-01-14</created><authors><author><keyname>Xian-yi</keyname><forenames>Ceng</forenames></author><author><keyname>Shu-qin</keyname><forenames>Li</forenames></author><author><keyname>De-shen</keyname><forenames>Xia</forenames></author></authors><title>Study of Self-Organization Model of Multiple Mobile Robot</title><categories>cs.RO</categories><comments>www.ars-journal.com</comments><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No3.
  (2005)</journal-ref><abstract>  A good organization model of multiple mobile robot should be able to improve
the efficiency of the system, reduce the complication of robot interactions,
and detract the difficulty of computation. From the sociology aspect of
topology, structure and organization, this paper studies the multiple mobile
robot organization formation and running mechanism in the dynamic, complicated
and unknown environment. It presents and describes in detail a Hierarchical-
Web Recursive Organization Model (HWROM) and forming algorithm. It defines the
robot society leader; robotic team leader and individual robot as the same
structure by the united framework and describes the organization model by the
recursive structure. The model uses task-oriented and top-down method to
dynamically build and maintain structures and organization. It uses
market-based techniques to assign task, form teams and allocate resources in
dynamic environment. The model holds several characteristics of
self-organization, dynamic, conciseness, commonness and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601063</id><created>2006-01-14</created><authors><author><keyname>Ata</keyname><forenames>Atef A.</forenames></author><author><keyname>Myo</keyname><forenames>Thi Rein</forenames></author></authors><title>Optimal Point-to-Point Trajectory Tracking of Redundant Manipulators
  using Generalized Pattern Search</title><categories>cs.RO</categories><comments>www.ars-journal.com</comments><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No3.
  (2005)</journal-ref><abstract>  Optimal point-to-point trajectory planning for planar redundant manipulator
is considered in this study. The main objective is to minimize the sum of the
position error of the end-effector at each intermediate point along the
trajectory so that the end-effector can track the prescribed trajectory
accurately. An algorithm combining Genetic Algorithm and Pattern Search as a
Generalized Pattern Search GPS is introduced to design the optimal trajectory.
To verify the proposed algorithm, simulations for a 3-D-O-F planar manipulator
with different end-effector trajectories have been carried out. A comparison
between the Genetic Algorithm and the Generalized Pattern Search shows that The
GPS gives excellent tracking performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601064</id><created>2006-01-14</created><authors><author><keyname>Kia</keyname><forenames>Chua</forenames></author><author><keyname>Arshad</keyname><forenames>Mohd Rizal</forenames></author></authors><title>Robotics Vision-based Heuristic Reasoning for Underwater Target Tracking
  and Navigation</title><categories>cs.RO</categories><comments>www.ars-journal.com</comments><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No3.
  (2005)</journal-ref><abstract>  This paper presents a robotics vision-based heuristic reasoning system for
underwater target tracking and navigation. This system is introduced to improve
the level of automation of underwater Remote Operated Vehicles (ROVs)
operations. A prototype which combines computer vision with an underwater
robotics system is successfully designed and developed to perform target
tracking and intelligent navigation. ...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601065</id><created>2006-01-14</created><authors><author><keyname>Mir-Nasiri</keyname><forenames>Nazim</forenames></author><author><keyname>Hussaini</keyname><forenames>Sulaiman</forenames></author></authors><title>New Intelligent Transmission Concept for Hybrid Mobile Robot Speed
  Control</title><categories>cs.RO</categories><comments>www.ars-journal.com</comments><journal-ref>International Journal of Advanced Robotics Systems, Vol.2No3.
  (2005)</journal-ref><abstract>  This paper presents a new concept of a mobile robot speed control by using
two degree of freedom gear transmission. The developed intelligent speed
controller utilizes a gear box which comprises of epicyclic gear train with two
inputs, one coupled with the engine shaft and another with the shaft of a
variable speed dc motor. The net output speed is a combination of the two input
speeds and is governed by the transmission ratio of the planetary gear train.
This new approach eliminates the use of a torque converter which is otherwise
an indispensable part of all available automatic transmissions, thereby
reducing the power loss that occurs in the box during the fluid coupling. By
gradually varying the speed of the dc motor a stepless transmission has been
achieved. The other advantages of the developed controller are pulling over and
reversing the vehicle, implemented by intelligent mixing of the dc motor and
engine speeds. This approach eliminates traditional braking system in entire
vehicle design. The use of two power sources, IC engine and battery driven DC
motor, utilizes the modern idea of hybrid vehicles. The new mobile robot speed
controller is capable of driving the vehicle even in extreme case of IC engine
failure, for example, due to gas depletion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601066</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601066</id><created>2006-01-14</created><authors><author><keyname>Ganesan</keyname><forenames>Ashwin</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>On the Existence of Universally Decodable Matrices</title><categories>cs.IT cs.DM math.IT</categories><abstract>  Universally decodable matrices (UDMs) can be used for coding purposes when
transmitting over slow fading channels. These matrices are parameterized by
positive integers $L$ and $N$ and a prime power $q$. The main result of this
paper is that the simple condition $L \leq q+1$ is both necessary and
sufficient for $(L,N,q)$-UDMs to exist. The existence proof is constructive and
yields a coding scheme that is equivalent to a class of codes that was proposed
by Rosenbloom and Tsfasman. Our work resolves an open problem posed recently in
the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601067</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601067</id><created>2006-01-14</created><authors><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Brannstrom</keyname><forenames>Fredrik</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author></authors><title>Design of Rate-Compatible Serially Concatenated Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>To appear at the International Symposium on Turbo Codes and Related
  Topics</comments><abstract>  Recently a powerful class of rate-compatible serially concatenated
convolutional codes (SCCCs) have been proposed based on minimizing analytical
upper bounds on the error probability in the error floor region. Here this
class of codes is further investigated by combining analytical upper bounds
with extrinsic information transfer charts analysis. Following this approach,
we construct a family of rate-compatible SCCCs with good performance in both
the error floor and the waterfall regions over a broad range of code rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601068</id><created>2006-01-14</created><authors><author><keyname>Bansal</keyname><forenames>Sorav</forenames></author></authors><title>Checkbochs: Use Hardware to Check Software</title><categories>cs.OS cs.CR</categories><comments>4 pages, 4 figures</comments><abstract>  In this paper, we present a system called Checkbochs, a machine simulator
that checks rules about its guest operating system and applications at the
hardware level. The properties to be checked can be implemented as `plugins' in
the Checkbochs simulator. Some of the properties that were checked using
Checkbochs include null-pointer checks, format-string vulnerabilities,
user/kernel pointer checks, and race-conditions. On implementing these checks,
we were able to uncover previously-unknown bugs in widely used Linux
distributions. We also tested our tools on undergraduate coursework, and found
numerous bugs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601069</id><created>2006-01-15</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author></authors><title>Fast Enumeration of Combinatorial Objects</title><categories>cs.CC cs.DM</categories><journal-ref>published in Discrete Math.and Applications, v.10, n2, 1998</journal-ref><abstract>  The problem of ranking can be described as follows. We have a set of
combinatorial objects $S$, such as, say, the k-subsets of n things, and we can
imagine that they have been arranged in some list, say lexicographically, and
we want to have a fast method for obtaining the rank of a given object in the
list. This problem is widely known in Combinatorial Analysis, Computer Science
and Information Theory. Ranking is closely connected with the hashing problem,
especially with perfect hashing and with generating of random combinatorial
objects. In Information Theory the ranking problem is closely connected with
so-called enumerative encoding, which may be described as follows: there is a
set of words $S$ and an enumerative code has to one-to-one encode every $s \in
S$ by a binary word $code(s)$. The length of the $code(s)$ must be the same for
all $s \in S$. Clearly, $|code (s)|\geq \log |S|$. (Here and below $\log
x=\log_{2}x)$.) The suggested method allows the exponential growth of the speed
of encoding and decoding for all combinatorial problems of enumeration which
are considered, including the enumeration of permutations, compositions and
others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601070</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601070</id><created>2006-01-16</created><authors><author><keyname>Stepanov</keyname><forenames>M. G.</forenames></author><author><keyname>Chertkov</keyname><forenames>M.</forenames></author></authors><title>Instanton analysis of Low-Density-Parity-Check codes in the error-floor
  regime</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>5 pages, 5 figures</comments><report-no>LA-UR-06-0126</report-no><abstract>  In this paper we develop instanton method introduced in [1], [2], [3] to
analyze quantitatively performance of Low-Density-Parity-Check (LDPC) codes
decoded iteratively in the so-called error-floor regime. We discuss statistical
properties of the numerical instanton-amoeba scheme focusing on detailed
analysis and comparison of two regular LDPC codes: Tanner's (155, 64, 20) and
Margulis' (672, 336, 16) codes. In the regime of moderate values of the
signal-to-noise ratio we critically compare results of the instanton-amoeba
evaluations against the standard Monte-Carlo calculations of the
Frame-Error-Rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601071</id><created>2006-01-16</created><authors><author><keyname>Fernandez</keyname><forenames>Antonio J.</forenames></author><author><keyname>Hortala-Gonzalez</keyname><forenames>Teresa</forenames></author><author><keyname>Saenz-Perez</keyname><forenames>Fernando</forenames></author><author><keyname>del Vado-Virseda</keyname><forenames>Rafael</forenames></author></authors><title>Constraint Functional Logic Programming over Finite Domains</title><categories>cs.PL</categories><comments>Accepted for publication in Theory and Practice of Logic programming
  (TPLP); 47 pages</comments><acm-class>D.3.2; D.3.3; F.3.2</acm-class><abstract>  In this paper, we present our proposal to Constraint Functional Logic
Programming over Finite Domains (CFLP(FD)) with a lazy functional logic
programming language which seamlessly embodies finite domain (FD) constraints.
This proposal increases the expressiveness and power of constraint logic
programming over finite domains (CLP(FD)) by combining functional and
relational notation, curried expressions, higher-order functions, patterns,
partial applications, non-determinism, lazy evaluation, logical variables,
types, domain variables, constraint composition, and finite domain constraints.
  We describe the syntax of the language, its type discipline, and its
declarative and operational semantics. We also describe TOY(FD), an
implementation for CFLPFD(FD), and a comparison of our approach with respect to
CLP(FD) from a programming point of view, showing the new features we
introduce. And, finally, we show a performance analysis which demonstrates that
our implementation is competitive with respect to existing CLP(FD) systems and
that clearly outperforms the closer approach to CFLP(FD).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601072</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601072</id><created>2006-01-16</created><authors><author><keyname>Tron&#xe7;on</keyname><forenames>Remko</forenames></author><author><keyname>Janssens</keyname><forenames>Gerda</forenames></author><author><keyname>Demoen</keyname><forenames>Bart</forenames></author><author><keyname>Vandecasteele</keyname><forenames>Henk</forenames></author></authors><title>Fast Frequent Querying with Lazy Control Flow Compilation</title><categories>cs.PL cs.AI cs.SE</categories><abstract>  Control flow compilation is a hybrid between classical WAM compilation and
meta-call, limited to the compilation of non-recursive clause bodies. This
approach is used successfully for the execution of dynamically generated
queries in an inductive logic programming setting (ILP). Control flow
compilation reduces compilation times up to an order of magnitude, without
slowing down execution. A lazy variant of control flow compilation is also
presented. By compiling code by need, it removes the overhead of compiling
unreached code (a frequent phenomenon in practical ILP settings), and thus
reduces the size of the compiled code. Both dynamic compilation approaches have
been implemented and were combined with query packs, an efficient ILP execution
mechanism. It turns out that locality of data and code is important for
performance. The experiments reported in the paper show that lazy control flow
compilation is superior in both artificial and real life settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601073</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601073</id><created>2006-01-16</created><authors><author><keyname>Caama&#xf1;o</keyname><forenames>Antonio J.</forenames></author><author><keyname>Vinagre</keyname><forenames>Juan J.</forenames></author><author><keyname>Wilby</keyname><forenames>Mark</forenames></author><author><keyname>Ramos</keyname><forenames>Javier</forenames></author></authors><title>A Theory of Routing for Large-Scale Wireless Ad-Hoc Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted to the IEEE International Symposium on Information Theory
  (ISIT) 2006</comments><acm-class>C.2.1; F.2.2</acm-class><abstract>  In this work we develop a new theory to analyse the process of routing in
large-scale ad-hoc wireless networks. We use a path integral formulation to
examine the properties of the paths generated by different routing strategies
in these kinds of networks. Using this theoretical framework, we calculate the
statistical distribution of the distances between any source to any destination
in the network, hence we are able to deduce a length parameter that is unique
for each routing strategy. This parameter, defined as the {\it effective
radius}, effectively encodes the routing information required by a node.
Analysing the aforementioned statistical distribution for different routing
strategies, we obtain a threefold result for practical Large-Scale Wireless
Ad-Hoc Networks: 1) We obtain the distribution of the lengths of all the paths
in a network for any given routing strategy, 2) We are able to identify &quot;good&quot;
routing strategies depending on the evolution of its effective radius as the
number of nodes, $N$, increases to infinity, 3) For any routing strategy with
finite effective radius, we demonstrate that, in a large-scale network, is
equivalent to a random routing strategy and that its transport capacity scales
as $\Theta(\sqrt{N})$ bit-meters per second, thus retrieving the scaling law
that Gupta and Kumar (2000) obtained as the limit for single-route large-scale
wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601074</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601074</id><created>2006-01-16</created><updated>2006-05-11</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Joint universal lossy coding and identification of i.i.d. vector sources</title><categories>cs.IT cs.LG math.IT</categories><comments>5 (or 6 with hyperref) pages, 2 eps figures; final version to appear
  in Proc. ISIT 2006; full version of this paper was submitted to IEEE Trans.
  Inform. Theory and can be found at cs.IT/0512015</comments><abstract>  The problem of joint universal source coding and modeling, addressed by
Rissanen in the context of lossless codes, is generalized to fixed-rate lossy
coding of continuous-alphabet memoryless sources. We show that, for bounded
distortion measures, any compactly parametrized family of i.i.d. real vector
sources with absolutely continuous marginals (satisfying appropriate smoothness
and Vapnik--Chervonenkis learnability conditions) admits a joint scheme for
universal lossy block coding and parameter estimation, and give nonasymptotic
estimates of convergence rates for distortion redundancies and variational
distances between the active source and the estimated source. We also present
explicit examples of parametric sources admitting such joint universal
compression and modeling schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601075</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601075</id><created>2006-01-16</created><updated>2006-04-27</updated><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Ganesan</keyname><forenames>Ashwin</forenames></author></authors><title>On Universally Decodable Matrices for Space-Time Coding</title><categories>cs.IT cs.DM math.IT</categories><comments>Journal version of earlier conference proceedings paper. Submitted on
  April 27, 2006</comments><abstract>  The notion of universally decodable matrices (UDMs) was recently introduced
by Tavildar and Viswanath while studying slow fading channels. It turns out
that the problem of constructing UDMs is tightly connected to the problem of
constructing maximum distance separable (MDS) codes. In this paper, we first
study the properties of UDMs in general and then we discuss an explicit
construction of a class of UDMs, a construction which can be seen as an
extension of Reed-Solomon codes. In fact, we show that this extension is, in a
sense to be made more precise later on, unique. Moreover, the structure of this
class of UDMs allows us to answer some open conjectures by Tavildar, Viswanath,
and Doshi in the positive, and it also allows us to formulate an efficient
decoding algorithm for this class of UDMs. It turns out that our construction
yields a coding scheme that is essentially equivalent to a class of codes that
was proposed by Rosenbloom and Tsfasman. Moreover, we point out connections to
so-called repeated-root cyclic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601076</id><created>2006-01-17</created><authors><author><keyname>Ooi</keyname><forenames>K. S.</forenames></author></authors><title>Learning by Test-infecting Symmetric Ciphers</title><categories>cs.CR</categories><abstract>  We describe a novel way in which students can learn the cipher systems
without much supervision. In this work we focus on learning symmetric ciphers
by altering them using the agile development approach. Two agile approaches the
eXtreme Programming (XP) and the closely related Test-Driven Development (TDD)
are mentioned or discussed. To facilitate this development we experiment with
an approach that is based on refactoring, with JUnit serves as the automatic
testing framework. In this work we exemplify our learning approach by
test-infecting the Vernam cipher, an aged but still widely used stream cipher.
One can replace the cipher with another symmetric cipher with the same
behavior. Software testing is briefly described. Just-in-time introduction to
Object-oriented programming (OOP), exemplified by using JavaTM, is advocated.
Refactoring exercises, as argued, are kept strategically simple so that they do
not become intensive class redesign exercises. The use of free or open-source
tools and frameworks is mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601077</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601077</id><created>2006-01-17</created><authors><author><keyname>Mohan</keyname><forenames>B. S. Shajee</forenames></author><author><keyname>Govindan</keyname><forenames>V. K.</forenames></author></authors><title>IDBE - An Intelligent Dictionary Based Encoding Algorithm for Text Data
  Compression for High Speed Data Transmission Over Internet</title><categories>cs.IT math.IT</categories><abstract>  Compression algorithms reduce the redundancy in data representation to
decrease the storage required for that data. Data compression offers an
attractive approach to reducing communication costs by using available
bandwidth effectively. Over the last decade there has been an unprecedented
explosion in the amount of digital data transmitted via the Internet,
representing text, images, video, sound, computer programs, etc. With this
trend expected to continue, it makes sense to pursue research on developing
algorithms that can most effectively use available network bandwidth by
maximally compressing data. This research paper is focused on addressing this
problem of lossless compression of text files. Lossless compression researchers
have developed highly sophisticated approaches, such as Huffman encoding,
arithmetic encoding, the Lempel-Ziv family, Dynamic Markov Compression (DMC),
Prediction by Partial Matching (PPM), and Burrows-Wheeler Transform (BWT) based
algorithms. However, none of these methods has been able to reach the
theoretical best-case compression ratio consistently, which suggests that
better algorithms may be possible. One approach for trying to attain better
compression ratios is to develop new compression algorithms. An alternative
approach, however, is to develop intelligent, reversible transformations that
can be applied to a source text that improve an existing, or backend,
algorithm's ability to compress. The latter strategy has been explored here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601078</id><created>2006-01-17</created><authors><author><keyname>Gaidioz</keyname><forenames>Benjamin</forenames></author><author><keyname>Koblitz</keyname><forenames>Birger</forenames></author><author><keyname>Santos</keyname><forenames>Nuno</forenames></author></authors><title>Exploring high performance distributed file storage using LDPC codes</title><categories>cs.DC</categories><acm-class>D.4.2</acm-class><abstract>  We explore the feasibility of implementing a reliable, high performance,
distributed storage system on a commodity computing cluster. Files are
distributed across storage nodes using erasure coding with small Low-Density
Parity-Check (LDPC) codes which provide high reliability while keeping the
storage and performance overhead small. We present performance measurements
done on a prototype system comprising 50 nodes which are self organised using a
peer-to-peer overlay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601079</id><created>2006-01-17</created><authors><author><keyname>Luo</keyname><forenames>Katherine</forenames></author><author><keyname>Li</keyname><forenames>Yifan</forenames></author><author><keyname>Ermopoulos</keyname><forenames>Charis</forenames></author><author><keyname>Yurcik</keyname><forenames>William</forenames></author><author><keyname>Slagell</keyname><forenames>Adam</forenames></author></authors><title>SCRUB-PA: A Multi-Level Multi-Dimensional Anonymization Tool for Process
  Accounting</title><categories>cs.CR</categories><comments>19 pages, 11 figures, 4 tables</comments><abstract>  In the UNIX/Linux environment the kernel can log every command process
created by every user using process accounting. This data has many potential
uses, including the investigation of security incidents. However, process
accounting data is also sensitive since it contains private user information.
Consequently, security system administrators have been hindered from sharing
these logs. Given that many interesting security applications could use process
accounting data, it would be useful to have a tool that could protect private
user information in the logs. For this reason we introduce SCRUB-PA, a tool
that uses multi-level multi-dimensional anonymization on process accounting log
files in order to provide different levels of privacy protection. It is our
goal that SCRUB-PA will promote the sharing of process accounting logs while
preserving privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601080</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601080</id><created>2006-01-18</created><authors><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author><author><keyname>Murty</keyname><forenames>M Narasimha</forenames></author><author><keyname>Bhatnagar</keyname><forenames>Shalabh</forenames></author></authors><title>On Measure Theoretic definitions of Generalized Information Measures and
  Maximum Entropy Prescriptions</title><categories>cs.IT math.IT</categories><abstract>  Though Shannon entropy of a probability measure $P$, defined as $- \int_{X}
\frac{\ud P}{\ud \mu} \ln \frac{\ud P}{\ud\mu} \ud \mu$ on a measure space $(X,
\mathfrak{M},\mu)$, does not qualify itself as an information measure (it is
not a natural extension of the discrete case), maximum entropy (ME)
prescriptions in the measure-theoretic case are consistent with that of
discrete case. In this paper, we study the measure-theoretic definitions of
generalized information measures and discuss the ME prescriptions. We present
two results in this regard: (i) we prove that, as in the case of classical
relative-entropy, the measure-theoretic definitions of generalized
relative-entropies, R\'{e}nyi and Tsallis, are natural extensions of their
respective discrete cases, (ii) we show that, ME prescriptions of
measure-theoretic Tsallis entropy are consistent with the discrete case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601081</id><created>2006-01-18</created><authors><author><keyname>Brodnik</keyname><forenames>Andrej</forenames></author><author><keyname>Karlsson</keyname><forenames>Johan</forenames></author><author><keyname>Munro</keyname><forenames>J. Ian</forenames></author><author><keyname>Nilsson</keyname><forenames>Andreas</forenames></author></authors><title>An O(1) Solution to the Prefix Sum Problem on a Specialized Memory
  Architecture</title><categories>cs.DS cs.CC cs.IR</categories><comments>12 pages</comments><acm-class>E.1; F.1.1</acm-class><abstract>  In this paper we study the Prefix Sum problem introduced by Fredman.
  We show that it is possible to perform both update and retrieval in O(1) time
simultaneously under a memory model in which individual bits may be shared by
several words.
  We also show that two variants (generalizations) of the problem can be solved
optimally in $\Theta(\lg N)$ time under the comparison based model of
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601082</id><created>2006-01-18</created><authors><author><keyname>Carmi</keyname><forenames>Shai</forenames></author><author><keyname>Cohen</keyname><forenames>Reuven</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Search in Complex Networks : a New Method of Naming</title><categories>cs.NI cond-mat.dis-nn</categories><comments>5 pages, 4 figures</comments><journal-ref>Europhys. Lett., 74 (6), pp. 1102-1108 (2006)</journal-ref><doi>10.1209/epl/i2006-10049-1</doi><abstract>  We suggest a method for routing when the source does not posses full
information about the shortest path to the destination. The method is
particularly useful for scale-free networks, and exploits its unique
characteristics. By assigning new (short) names to nodes (aka labelling) we are
able to reduce significantly the memory requirement at the routers, yet we
succeed in routing with high probability through paths very close in distance
to the shortest ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601083</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601083</id><created>2006-01-18</created><authors><author><keyname>Jiang</keyname><forenames>Jing</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Multilevel Coding for Channels with Non-uniform Inputs and Rateless
  Transmission over the BSC</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT2006</comments><abstract>  We consider coding schemes for channels with non-uniform inputs (NUI), where
standard linear block codes can not be applied directly. We show that
multilevel coding (MLC) with a set of linear codes and a deterministic mapper
can achieve the information rate of the channel with NUI. The mapper, however,
does not have to be one-to-one. As an application of the proposed MLC scheme,
we present a rateless transmission scheme over the binary symmetric channel
(BSC).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601084</id><created>2006-01-18</created><authors><author><keyname>Kao</keyname><forenames>Ming-Yang</forenames></author><author><keyname>Sanghi</keyname><forenames>Manan</forenames></author><author><keyname>Schweller</keyname><forenames>Robert</forenames></author></authors><title>Randomized Fast Design of Short DNA Words</title><categories>cs.DS</categories><journal-ref>Proceedings of the 32nd International Colloquium on Automata,
  Languages and Programming (ICALP 2005), Lisboa, Portugal, July 11-15, 2005,
  pp. 1275-1286</journal-ref><abstract>  We consider the problem of efficiently designing sets (codes) of equal-length
DNA strings (words) that satisfy certain combinatorial constraints. This
problem has numerous motivations including DNA computing and DNA self-assembly.
Previous work has extended results from coding theory to obtain bounds on code
size for new biologically motivated constraints and has applied heuristic local
search and genetic algorithm techniques for code design. This paper proposes a
natural optimization formulation of the DNA code design problem in which the
goal is to design n strings that satisfy a given set of constraints while
minimizing the length of the strings. For multiple sets of constraints, we
provide high-probability algorithms that run in time polynomial in n and any
given constraint parameters, and output strings of length within a constant
factor of the optimal. To the best of our knowledge, this work is the first to
consider this type of optimization problem in the context of DNA code design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601085</id><created>2006-01-18</created><authors><author><keyname>Pucella</keyname><forenames>Riccardo</forenames></author><author><keyname>Weissman</keyname><forenames>Vicky</forenames></author></authors><title>A Formal Foundation for ODRL</title><categories>cs.LO cs.CR</categories><comments>30 pgs, preliminary version presented at WITS-04 (Workshop on Issues
  in the Theory of Security), 2004</comments><acm-class>H.2.7; K.4.4</acm-class><abstract>  ODRL is a popular XML-based language for stating the conditions under which
resources can be accessed legitimately. The language is described in English
and, as a result, agreements written in ODRL are open to interpretation. To
address this problem, we propose a formal semantics for a representative
fragment of the language. We use this semantics to determine precisely when a
permission is implied by a set of ODRL statements and show that answering such
questions is a decidable NP-hard problem. Finally, we define a tractable
fragment of ODRL that is also fairly expressive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601086</id><created>2006-01-19</created><updated>2006-01-23</updated><authors><author><keyname>Cook</keyname><forenames>Stephen</forenames></author></authors><title>Comments on Beckmann's Uniform Reducts</title><categories>cs.CC</categories><acm-class>F.4.1</acm-class><abstract>  Arnold Beckmann defined the uniform reduct of a propositional proof system f
to be the set of those bounded arithmetical formulas whose propositional
translations have polynomial size f-proofs. We prove that the uniform reduct of
f + Extended Frege consists of all true bounded arithmetical formulas iff f +
Extended Frege simulates every proof system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601087</id><created>2006-01-20</created><authors><author><keyname>Victor</keyname><forenames>Kromer</forenames></author></authors><title>Processing of Test Matrices with Guessing Correction</title><categories>cs.LG</categories><comments>10 pages, in Russian</comments><acm-class>I.2.6; K.3.2</acm-class><abstract>  It is suggested to insert into test matrix 1s for correct responses, 0s for
response refusals, and negative corrective elements for incorrect responses.
With the classical test theory approach test scores of examinees and items are
calculated traditionally as sums of matrix elements, organized in rows and
columns. Correlation coefficients are estimated using correction coefficients.
In item response theory approach examinee and item logits are estimated using
maximum likelihood method and probabilities of all matrix elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601088</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601088</id><created>2006-01-20</created><authors><author><keyname>Lu</keyname><forenames>Xiang</forenames></author><author><keyname>Chen</keyname><forenames>Jiajia</forenames></author><author><keyname>He</keyname><forenames>Sailing</forenames></author></authors><title>An Algorithm for Constructing All Families of Codes of Arbitrary
  Requirement in an OCDMA System</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures</comments><abstract>  A novel code construction algorithm is presented to find all the possible
code families for code reconfiguration in an OCDMA system. The algorithm is
developed through searching all the complete subgraphs of a constructed graph.
The proposed algorithm is flexible and practical for constructing optical
orthogonal codes (OOCs) of arbitrary requirement. Simulation results show that
one should choose an appropriate code length in order to obtain sufficient
number of code families for code reconfiguration with reasonable cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601089</id><created>2006-01-20</created><authors><author><keyname>Predd</keyname><forenames>Joel B.</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Distributed Kernel Regression: An Algorithm for Training Collaboratively</title><categories>cs.LG cs.AI cs.DC cs.IT math.IT</categories><comments>To be presented at the 2006 IEEE Information Theory Workshop, Punta
  del Este, Uruguay, March 13-17, 2006</comments><abstract>  This paper addresses the problem of distributed learning under communication
constraints, motivated by distributed signal processing in wireless sensor
networks and data mining with distributed databases. After formalizing a
general model for distributed learning, an algorithm for collaboratively
training regularized kernel least-squares regression estimators is derived.
Noting that the algorithm can be viewed as an application of successive
orthogonal projection algorithms, its convergence properties are investigated
and the statistical behavior of the estimator is discussed in a simplified
theoretical setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601090</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601090</id><created>2006-01-21</created><updated>2006-05-10</updated><authors><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author></authors><title>Improved Nearly-MDS Expander Codes</title><categories>cs.IT math.IT</categories><comments>Part of this work was presented at the 2004 IEEE Int'l Symposium on
  Information Theory (ISIT'2004), Chicago, Illinois (June 2004). This work was
  submitted to IEEE Transactions on Information Theory on January 21, 2005. To
  appear in IEEE Transactions on Information Theory, August 2006. 12 pages</comments><abstract>  A construction of expander codes is presented with the following three
properties:
  (i) the codes lie close to the Singleton bound, (ii) they can be encoded in
time complexity that is linear in their code length, and (iii) they have a
linear-time bounded-distance decoder.
  By using a version of the decoder that corrects also erasures, the codes can
replace MDS outer codes in concatenated constructions, thus resulting in
linear-time encodable and decodable codes that approach the Zyablov bound or
the capacity of memoryless channels. The presented construction improves on an
earlier result by Guruswami and Indyk in that any rate and relative minimum
distance that lies below the Singleton bound is attainable for a significantly
smaller alphabet size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601091</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601091</id><created>2006-01-21</created><updated>2007-06-18</updated><authors><author><keyname>Taherzadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Mobasher</keyname><forenames>Amin</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Communication Over MIMO Broadcast Channels Using Lattice-Basis Reduction</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Info. Theory (Jan. 15, 2006), Revised
  (Jun. 12, 2007)</comments><abstract>  A simple scheme for communication over MIMO broadcast channels is introduced
which adopts the lattice reduction technique to improve the naive channel
inversion method. Lattice basis reduction helps us to reduce the average
transmitted energy by modifying the region which includes the constellation
points. Simulation results show that the proposed scheme performs well, and as
compared to the more complex methods (such as the perturbation method) has a
negligible loss. Moreover, the proposed method is extended to the case of
different rates for different users. The asymptotic behavior of the symbol
error rate of the proposed method and the perturbation technique, and also the
outage probability for the case of fixed-rate users is analyzed. It is shown
that the proposed method, based on LLL lattice reduction, achieves the optimum
asymptotic slope of symbol-error-rate (called the precoding diversity). Also,
the outage probability for the case of fixed sum-rate is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601092</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601092</id><created>2006-01-21</created><updated>2007-06-18</updated><authors><author><keyname>Taherzadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Mobasher</keyname><forenames>Amin</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>LLL Reduction Achieves the Receive Diversity in MIMO Decoding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Info. Theory (Jan. 15, 2006), Revised
  (Mar. 5, 2007)</comments><abstract>  Diversity order is an important measure for the performance of communication
systems over MIMO fading channels. In this paper, we prove that in MIMO
multiple access systems (or MIMO point-to-point systems with V-BLAST
transmission), lattice-reduction-aided decoding achieves the maximum receive
diversity (which is equal to the number of receive antennas). Also, we prove
that the naive lattice decoding (which discards the out-of-region decoded
points) achieves the maximum diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601093</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601093</id><created>2006-01-21</created><authors><author><keyname>Sayee</keyname><forenames>KCV Kalyanarama Sesha</forenames></author><author><keyname>Mukherji</keyname><forenames>Utpal</forenames></author></authors><title>Stability of Scheduled Multi-access Communication over Quasi-static Flat
  Fading Channels with Random Coding and Joint Maximum Likelihood Decoding</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to 2006 International Symposium on Information
  Theory</comments><abstract>  We consider stability of scheduled multiaccess message communication with
random coding and joint maximum-likehood decoding of messages. The framework we
consider here models both the random message arrivals and the subsequent
reliable communication by suitably combining techniques from queueing theory
and information theory. The number of messages that may be scheduled for
simultaneous transmission is limited to a given maximum value, and the channels
from transmitters to receiver are quasi-static, flat, and have independent
fades. Requests for message transmissions are assumed to arrive according to an
i.i.d. arrival process. Then, (i) we derive an outer bound to the region of
message arrival rate vectors achievable by the class of stationary scheduling
policies, (ii) we show for any message arrival rate vector that satisfies the
outerbound, that there exists a stationary state-independent policy that
results in a stable system for the corresponding message arrival process, and
(iii) in the limit of large message lengths, we show that the stability region
of message nat arrival rate vectors has information-theoretic capacity region
interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601094</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601094</id><created>2006-01-22</created><authors><author><keyname>Sayee</keyname><forenames>KCV Kalyanarama Sesha</forenames></author><author><keyname>Mukherji</keyname><forenames>Utpal</forenames></author></authors><title>Stability of Scheduled Message Communication over Degraded Broadcast
  Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, Submitted to 2006 International Symposium on Information
  Theory</comments><abstract>  We consider scheduled message communication over a discrete memoryless
degraded broadcast channel. The framework we consider here models both the
random message arrivals and the subsequent reliable communication by suitably
combining techniques from queueing theory and information theory. The channel
from the transmitter to each of the receivers is quasi-static, flat, and with
independent fades across the receivers. Requests for message transmissions are
assumed to arrive according to an i.i.d. arrival process. Then, (i) we derive
an outer bound to the region of message arrival vectors achievable by the class
of stationary scheduling policies, (ii) we show for any message arrival vector
that satisfies the outerbound, that there exists a stationary
``state-independent'' policy that results in a stable system for the
corresponding message arrival process, and (iii) under two asymptotic regimes,
we show that the stability region of nat arrival rate vectors has
information-theoretic capacity region interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601095</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601095</id><created>2006-01-23</created><authors><author><keyname>El-Khamy</keyname><forenames>Mostafa</forenames></author><author><keyname>Garello</keyname><forenames>Roberto</forenames></author></authors><title>On the Weight Enumerator and the Maximum Likelihood Performance of
  Linear Product Codes</title><categories>cs.IT math.IT</categories><comments>26 pages, 10 figures, submitted to IEEE transactions in December 2005</comments><acm-class>E.4</acm-class><abstract>  Product codes are widely used in data-storage, optical and wireless
applications. Their analytical performance evaluation usually relies on the
truncated union bound, which provides a low error rate approximation based on
the minimum distance term only. In fact, the complete weight enumerator of most
product codes remains unknown. In this paper, concatenated representations are
introduced and applied to compute the complete average enumerators of arbitrary
product codes over a field Fq. The split weight enumerators of some important
constituent codes (Hamming, Reed-Solomon) are studied and used in the analysis.
The average binary weight enumerators of Reed Solomon product codes are also
derived. Numerical results showing the enumerator behavior are presented. By
using the complete enumerators, Poltyrev bounds on the maximum likelihood
performance, holding at both high and low error rates, are finally shown and
compared against truncated union bounds and simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601096</id><created>2006-01-23</created><authors><author><keyname>D'Souza</keyname><forenames>Deepak</forenames><affiliation>PPS</affiliation></author><author><keyname>Tabareau</keyname><forenames>Nicolas</forenames><affiliation>PPS</affiliation></author></authors><title>On timed automata with input-determined guards</title><categories>cs.LO</categories><proxy>ccsd ccsd-00017462</proxy><abstract>  We consider a general notion of timed automata with input-determined guards
and show that they admit a robust logical framework along the lines of [D
'Souza03], in terms of a monadic second order logic characterisation and an
expressively complete timed temporal logic. We then generalize these automata
using the notion of recursive operators introduced by Henzinger, Raskin, and
Schobbens, and show that they admit a similar logical framework. These results
hold in the ``pointwise'' semantics. We finally use this framework to show that
the real-time logic MITL of Alur et al is expressively complete with respect to
an MSO corresponding to an appropriate input-determined operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601097</id><created>2006-01-23</created><updated>2006-01-23</updated><authors><author><keyname>Shajeemohan</keyname><forenames>B. S.</forenames></author><author><keyname>Govindan</keyname><forenames>Dr. V. K.</forenames></author></authors><title>Compression Scheme for Faster and Secure Data Transmission Over Internet</title><categories>cs.PF cs.DC</categories><abstract>  Compression algorithms reduce the redundancy in data representation to
decrease the storage required for that data. Data compression offers an
attractive approach to reducing communication costs by using available
bandwidth effectively. Over the last decade there has been an unprecedented
explosion in the amount of digital data transmitted via the Internet,
representing text, images, video, sound, computer programs, etc. With this
trend expected to continue, it makes sense to pursue research on developing
algorithms that can most effectively use available network bandwidth by
maximally compressing data. It is also important to consider the security
aspects of the data being transmitted while compressing it, as most of the text
data transmitted over the Internet is very much vulnerable to a multitude of
attacks. This paper is focused on addressing this problem of lossless
compression of text files with an added security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601098</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601098</id><created>2006-01-23</created><authors><author><keyname>Meshkati</keyname><forenames>Farhad</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Schwartz</keyname><forenames>Stuart C.</forenames></author><author><keyname>Balan</keyname><forenames>Radu V.</forenames></author></authors><title>Energy Efficiency and Delay Quality-of-Service in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>To be presented at the Inaugural Workshop of the Center for
  Information Theory and Its Applications, University of California - San
  Diego, La Jolla, CA, February 6 - 10, 2006</comments><abstract>  The energy-delay tradeoffs in wireless networks are studied using a
game-theoretic framework. A multi-class multiple-access network is considered
in which users choose their transmit powers, and possibly transmission rates,
in a distributed manner to maximize their own utilities while satisfying their
delay quality-of-service (QoS) requirements. The utility function considered
here measures the number of reliable bits transmitted per Joule of energy
consumed and is particularly useful for energy-constrained networks. The Nash
equilibrium solution for the proposed non-cooperative game is presented and
closed-form expressions for the users' utilities at equilibrium are obtained.
Based on this, the losses in energy efficiency and network capacity due to
presence of delay-sensitive users are quantified. The analysis is extended to
the scenario where the QoS requirements include both the average source rate
and a bound on the average total delay (including queuing delay). It is shown
that the incoming traffic rate and the delay constraint of a user translate
into a &quot;size&quot; for the user, which is an indication of the amount of resources
consumed by the user. Using this framework, the tradeoffs among throughput,
delay, network capacity and energy efficiency are also quantified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601099</id><created>2006-01-23</created><authors><author><keyname>N.</keyname><forenames>Mohammad H. Taghavi</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Adaptive Linear Programming Decoding</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures. Submitted to the IEEE International Symposium on
  Information Theory (ISIT) 2006</comments><abstract>  Detectability of failures of linear programming (LP) decoding and its
potential for improvement by adding new constraints motivate the use of an
adaptive approach in selecting the constraints for the LP problem. In this
paper, we make a first step in studying this method, and show that it can
significantly reduce the complexity of the problem, which was originally
exponential in the maximum check-node degree. We further show that adaptively
adding new constraints, e.g. by combining parity checks, can provide large
gains in the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601100</id><created>2006-01-23</created><authors><author><keyname>Trevisan</keyname><forenames>Luca</forenames></author></authors><title>Pseudorandomness and Combinatorial Constructions</title><categories>cs.CC math.CO</categories><comments>Submitted to the Proceedings of ICM'06, Madrid</comments><abstract>  In combinatorics, the probabilistic method is a very powerful tool to prove
the existence of combinatorial objects with interesting and useful properties.
Explicit constructions of objects with such properties are often very
difficult, or unknown. In computer science, probabilistic algorithms are
sometimes simpler and more efficient than the best known deterministic
algorithms for the same problem.
  Despite this evidence for the power of random choices, the computational
theory of pseudorandomness shows that, under certain complexity-theoretic
assumptions, every probabilistic algorithm has an efficient deterministic
simulation and a large class of applications of the the probabilistic method
can be converted into explicit constructions.
  In this survey paper we describe connections between the conditional
``derandomization'' results of the computational theory of pseudorandomness and
unconditional explicit constructions of certain combinatorial objects such as
error-correcting codes and ``randomness extractors.''
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601101</id><created>2006-01-23</created><authors><author><keyname>Nagarja</keyname><forenames>Shishir</forenames></author></authors><title>The topology of covert conflict</title><categories>cs.NI cs.GT</categories><comments>University of Cambridge Technical Report</comments><report-no>UCAM-CL-TR-637</report-no><abstract>  Often an attacker tries to disconnect a network by destroying nodes or edges,
while the defender counters using various resilience mechanisms. Examples
include a music industry body attempting to close down a peer-to-peer
file-sharing network; medics attempting to halt the spread of an infectious
disease by selective vaccination; and a police agency trying to decapitate a
terrorist organisation. Albert, Jeong and Barabasi famously analysed the static
case, and showed that vertex-order attacks are effective against scale-free
networks. We extend this work to the dynamic case by developing a framework
based on evolutionary game theory to explore the interaction of attack and
defence strategies. We show, first, that naive defences don't work against
vertex-order attack; second, that defences based on simple redundancy don't
work much better, but that defences based on cliques work well; third, that
attacks based on centrality work better against clique defences than
vertex-order attacks do; and fourth, that defences based on complex strategies
such as delegation plus clique resist centrality attacks better than simple
clique defences. Our models thus build a bridge between network analysis and
evolutionary game theory, and provide a framework for analysing defence and
attack in networks where topology matters. They suggest definitions of
efficiency of attack and defence, and may even explain the evolution of
insurgent organisations from networks of cells to a more virtual leadership
that facilitates operations rather than directing them. Finally, we draw some
conclusions and present possible directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601102</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601102</id><created>2006-01-24</created><authors><author><keyname>Caprari</keyname><forenames>Robert S.</forenames></author></authors><title>Geometric symmetry in the quadratic Fisher discriminant operating on
  image pixels</title><categories>cs.IT cs.CV math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory 52(4), April 2006, pp.
  1780-1788</journal-ref><doi>10.1109/TIT.2006.871581</doi><abstract>  This article examines the design of Quadratic Fisher Discriminants (QFDs)
that operate directly on image pixels, when image ensembles are taken to
comprise all rotated and reflected versions of distinct sample images. A
procedure based on group theory is devised to identify and discard QFD
coefficients made redundant by symmetry, for arbitrary sampling lattices. This
procedure introduces the concept of a degeneracy matrix. Tensor representations
are established for the square lattice point group (8-fold symmetry) and
hexagonal lattice point group (12-fold symmetry). The analysis is largely
applicable to the symmetrisation of any quadratic filter, and generalises to
higher order polynomial (Volterra) filters. Experiments on square lattice
sampled synthetic aperture radar (SAR) imagery verify that symmetrisation of
QFDs can improve their generalisation and discrimination ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601103</id><created>2006-01-24</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Tosques</keyname><forenames>Fabio</forenames></author></authors><title>Google Web APIs - an Instrument for Webometric Analyses?</title><categories>cs.IR</categories><comments>2 pages, 2 figures, 10th International Conference of the
  International Society for Scientometrics and Informetrics</comments><abstract>  This paper introduces Google Web APIs (Google APIs) as an instrument and
playground for webometric studies. Several examples of Google APIs
implementations are given. Our examples show that this Google Web Service can
be used successfully for informetric Internet based studies albeit with some
restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601104</identifier>
 <datestamp>2009-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601104</id><created>2006-01-24</created><updated>2008-07-25</updated><authors><author><keyname>Enge</keyname><forenames>Andreas</forenames><affiliation>INRIA Futurs, Lix</affiliation></author></authors><title>The complexity of class polynomial computation via floating point
  approximations</title><categories>cs.NA cs.SC math.NT</categories><proxy>ccsd inria-00001040</proxy><journal-ref>Mathematics of Computation 78, 266 (2009) 1089-1107</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the complexity of computing class polynomials, that are an
important ingredient for CM constructions of elliptic curves, via complex
floating point approximations of their roots. The heart of the algorithm is the
evaluation of modular functions in several arguments. The fastest one of the
presented approaches uses a technique devised by Dupont to evaluate modular
functions by Newton iterations on an expression involving the
arithmetic-geometric mean. It runs in time $O (|D| \log^5 |D| \log \log |D|) =
O (|D|^{1 + \epsilon}) = O (h^{2 + \epsilon})$ for any $\epsilon &gt; 0$, where
$D$ is the CM discriminant and $h$ is the degree of the class polynomial.
Another fast algorithm uses multipoint evaluation techniques known from
symbolic computation; its asymptotic complexity is worse by a factor of $\log
|D|$. Up to logarithmic factors, this running time matches the size of the
constructed polynomials. The estimate also relies on a new result concerning
the complexity of enumerating the class group of an imaginary-quadratic order
and on a rigorously proven upper bound for the height of class polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601105</id><created>2006-01-24</created><updated>2006-01-26</updated><authors><author><keyname>Vassiliadis</keyname><forenames>Vassilios S.</forenames></author></authors><title>The Perceptron Algorithm: Image and Signal Decomposition, Compression,
  and Analysis by Iterative Gaussian Blurring</title><categories>cs.CV</categories><abstract>  A novel algorithm for tunable compression to within the precision of
reproduction targets, or storage, is proposed. The new algorithm is termed the
`Perceptron Algorithm', which utilises simple existing concepts in a novel way,
has multiple immediate commercial application aspects as well as it opens up a
multitude of fronts in computational science and technology. The aims of this
paper are to present the concepts underlying the algorithm, observations by its
application to some example cases, and the identification of a multitude of
potential areas of applications such as: image compression by orders of
magnitude, signal compression including sound as well, image analysis in a
multilayered detailed analysis, pattern recognition and matching and rapid
database searching (e.g. face recognition), motion analysis, biomedical
applications e.g. in MRI and CAT scan image analysis and compression, as well
as hints on the link of these ideas to the way how biological memory might work
leading to new points of view in neural computation. Commercial applications of
immediate interest are the compression of images at the source (e.g.
photographic equipment, scanners, satellite imaging systems), DVD film
compression, pay-per-view downloads acceleration and many others identified in
the present paper at its conclusion and future work section.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601106</id><created>2006-01-24</created><authors><author><keyname>Vassiliadis</keyname><forenames>Vassilios S.</forenames></author></authors><title>The `Face on Mars': a photographic approach for the search of signs of
  past civilizations from a macroscopic point of view, factoring long-term
  erosion in image reconstruction</title><categories>cs.CV</categories><comments>9 pages</comments><abstract>  This short article presents an alternative view of high resolution imaging
from various sources with the aim of the discovery of potential sites of
archaeological importance, or sites that exhibit `anomalies' such that they may
merit closer inspection and analysis. It is conjectured, and to a certain
extent demonstrated here, that it is possible for advanced civilizations to
factor in erosion by natural processes into a large scale design so that main
features be preserved even with the passage of millions of years. Alternatively
viewed, even without such intent embedded in a design left for posterity, it is
possible that a gigantic construction may naturally decay in such a way that
even cataclysmic (massive) events may leave sufficient information intact with
the passage of time, provided one changes the point of view from high
resolution images to enhanced blurred renderings of the sites in question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601107</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601107</id><created>2006-01-25</created><updated>2006-09-29</updated><authors><author><keyname>Bjelakovic</keyname><forenames>Igor</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>Structure of Optimal Input Covariance Matrices for MIMO Systems with
  Covariance Feedback under General Correlated Fading</title><categories>cs.IT math.IT</categories><comments>5 pages, corrected typos</comments><journal-ref>Proc. of the 2006 IEEE International Symposium on Information
  Theory, ISIT 2006 Seattle, pp. 1041-1045</journal-ref><abstract>  We describe the structure of optimal Input covariance matrices for single
user multiple-input/multiple-output (MIMO) communication system with covariance
feedback and for general correlated fading. Our approach is based on the novel
concept of right commutant and recovers previously derived results for the
Kronecker product models. Conditions are derived which allow a significant
simplification of the optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601108</id><created>2006-01-25</created><updated>2006-03-19</updated><authors><author><keyname>Lifchitz</keyname><forenames>Alain</forenames></author><author><keyname>Maire</keyname><forenames>Frederic</forenames></author><author><keyname>Revuz</keyname><forenames>Dominique</forenames></author></authors><title>Fast Lexically Constrained Viterbi Algorithm (FLCVA): Simultaneous
  Optimization of Speed and Memory</title><categories>cs.CV cs.AI cs.DS</categories><comments>5 pages, 2 figures, 4 tables</comments><acm-class>G.2.2; I.5.5; E.2</acm-class><abstract>  Lexical constraints on the input of speech and on-line handwriting systems
improve the performance of such systems. A significant gain in speed can be
achieved by integrating in a digraph structure the different Hidden Markov
Models (HMM) corresponding to the words of the relevant lexicon. This
integration avoids redundant computations by sharing intermediate results
between HMM's corresponding to different words of the lexicon. In this paper,
we introduce a token passing method to perform simultaneously the computation
of the a posteriori probabilities of all the words of the lexicon. The coding
scheme that we introduce for the tokens is optimal in the information theory
sense. The tokens use the minimum possible number of bits. Overall, we optimize
simultaneously the execution speed and the memory requirement of the
recognition systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601109</id><created>2006-01-25</created><updated>2006-11-30</updated><authors><author><keyname>Yorke-Smith</keyname><forenames>Neil</forenames></author><author><keyname>Gervet</keyname><forenames>Carmen</forenames></author></authors><title>Certainty Closure: Reliable Constraint Reasoning with Incomplete or
  Erroneous Data</title><categories>cs.AI</categories><comments>Revised version</comments><acm-class>I.2.3</acm-class><abstract>  Constraint Programming (CP) has proved an effective paradigm to model and
solve difficult combinatorial satisfaction and optimisation problems from
disparate domains. Many such problems arising from the commercial world are
permeated by data uncertainty. Existing CP approaches that accommodate
uncertainty are less suited to uncertainty arising due to incomplete and
erroneous data, because they do not build reliable models and solutions
guaranteed to address the user's genuine problem as she perceives it. Other
fields such as reliable computation offer combinations of models and associated
methods to handle these types of uncertain data, but lack an expressive
framework characterising the resolution methodology independently of the model.
  We present a unifying framework that extends the CP formalism in both model
and solutions, to tackle ill-defined combinatorial problems with incomplete or
erroneous data. The certainty closure framework brings together modelling and
solving methodologies from different fields into the CP paradigm to provide
reliable and efficient approches for uncertain constraint problems. We
demonstrate the applicability of the framework on a case study in network
diagnosis. We define resolution forms that give generic templates, and their
associated operational semantics, to derive practical solution methods for
reliable solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601110</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601110</id><created>2006-01-25</created><updated>2006-01-27</updated><authors><author><keyname>Shafiee</keyname><forenames>Shabnam</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Mutual Information Games in Multi-user Channels with Correlated Jamming</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><acm-class>H.1.1</acm-class><abstract>  We investigate the behavior of two users and one jammer in an AWGN channel
with and without fading when they participate in a non-cooperative zero-sum
game, with the channel's input/output mutual information as the objective
function. We assume that the jammer can eavesdrop the channel and can use the
information obtained to perform correlated jamming. Under various assumptions
on the channel characteristics, and the extent of information available at the
users and the jammer, we show the existence, or otherwise non-existence of a
simultaneously optimal set of strategies for the users and the jammer. In all
the cases where the channel is non-fading, we show that the game has a
solution, and the optimal strategies are Gaussian signalling for the users and
linear jamming for the jammer. In fading channels, we envision each player's
strategy as a power allocation function over the channel states, together with
the signalling strategies at each channel state. We reduce the game solution to
a set of power allocation functions for the players and show that when the
jammer is uncorrelated, the game has a solution, but when the jammer is
correlated, a set of simultaneously optimal power allocation functions for the
users and the jammer does not always exist. In this case, we characterize the
max-min user power allocation strategies and the corresponding jammer power
allocation strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601111</id><created>2006-01-25</created><authors><author><keyname>Zhang</keyname><forenames>Chen</forenames></author><author><keyname>Herman</keyname><forenames>Ted</forenames></author></authors><title>Localization in Wireless Sensor Grids</title><categories>cs.DC</categories><comments>17 pages, 6 figures</comments><report-no>TR01-06</report-no><acm-class>C.2.4; C.3; J.7</acm-class><abstract>  This work reports experiences on using radio ranging to position sensors in a
grid topology. The implementation is simple, efficient, and could be
practically distributed. The paper describes an implementation and experimental
result based on RSSI distance estimation. Novel techniques such as fuzzy
membership functions and table lookup are used to obtain more accurate result
and simplify the computation. An 86% accuracy is achieved in the experiment in
spite of inaccurate RSSI distance estimates with errors up to 60%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601112</id><created>2006-01-26</created><authors><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames></author></authors><title>Complexity of the Guarded Two-Variable Fragment with Counting
  Quantifiers</title><categories>cs.LO cs.CC</categories><comments>20 pages, 3 figures</comments><abstract>  We show that the finite satisfiability problem for the guarded two-variable
fragment with counting quantifiers is in EXPTIME. The method employed also
yields a simple proof of a result recently obtained by Y. Kazakov, that the
satisfiability problem for the guarded two-variable fragment with counting
quantifiers is in EXPTIME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601113</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601113</id><created>2006-01-26</created><updated>2007-07-04</updated><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Stepanov</keyname><forenames>Mikhail G.</forenames></author></authors><title>An Efficient Pseudo-Codeword Search Algorithm for Linear Programming
  Decoding of LDPC Codes</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>5 pages, 6 figures</comments><report-no>LA-UR-06-0124/06-6751</report-no><abstract>  In Linear Programming (LP) decoding of a Low-Density-Parity-Check (LDPC) code
one minimizes a linear functional, with coefficients related to log-likelihood
ratios, over a relaxation of the polytope spanned by the codewords
\cite{03FWK}. In order to quantify LP decoding, and thus to describe
performance of the error-correction scheme at moderate and large
Signal-to-Noise-Ratios (SNR), it is important to study the relaxed polytope to
understand better its vertexes, so-called pseudo-codewords, especially those
which are neighbors of the zero codeword. In this manuscript we propose a
technique to heuristically create a list of these neighbors and their
distances. Our pseudo-codeword-search algorithm starts by randomly choosing the
initial configuration of the noise. The configuration is modified through a
discrete number of steps. Each step consists of two sub-steps. Firstly, one
applies an LP decoder to the noise-configuration deriving a pseudo-codeword.
Secondly, one finds configuration of the noise equidistant from the pseudo
codeword and the zero codeword. The resulting noise configuration is used as an
entry for the next step. The iterations converge rapidly to a pseudo-codeword
neighboring the zero codeword. Repeated many times, this procedure is
characterized by the distribution function (frequency spectrum) of the
pseudo-codeword effective distance. The effective distance of the coding scheme
is approximated by the shortest distance pseudo-codeword in the spectrum. The
efficiency of the procedure is demonstrated on examples of the Tanner
$[155,64,20]$ code and Margulis $p=7$ and $p=11$ codes (672 and 2640 bits long
respectively) operating over an Additive-White-Gaussian-Noise (AWGN) channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601114</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601114</id><created>2006-01-27</created><updated>2009-02-11</updated><authors><author><keyname>Simkus</keyname><forenames>Mantas</forenames></author><author><keyname>Taroza</keyname><forenames>Evaldas</forenames></author><author><keyname>Lubyte</keyname><forenames>Lina</forenames></author><author><keyname>Trivellato</keyname><forenames>Daniel</forenames></author><author><keyname>Norkunaite</keyname><forenames>Zivile</forenames></author></authors><title>Efficient Query Answering over Conceptual Schemas of Relational
  Databases : Technical Report</title><categories>cs.DB cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a query answering system, where at the core of the work there is
an idea of query answering by rewriting. For this purpose we extend the DL
DL-Lite with the ability to support n-ary relations, obtaining the DL DLR-Lite,
which is still polynomial in the size of the data. We devise a flexible way of
mapping the conceptual level to the relational level, which provides the users
an SQL-like query language over the conceptual schema. The rewriting technique
adds value to conventional query answering techniques, allowing to formulate
simpler queries, with the ability to infer additional information that was not
stated explicitly in the user query. The formalization of the conceptual schema
and the developed reasoning technique allow checking for consistency between
the database and the conceptual schema, thus improving the trustiness of the
information system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601115</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601115</id><created>2006-01-27</created><updated>2006-02-24</updated><authors><author><keyname>Fozunbal</keyname><forenames>Majid</forenames></author><author><keyname>Kalker</keyname><forenames>Ton</forenames></author></authors><title>Decision Making with Side Information and Unbounded Loss Functions</title><categories>cs.LG cs.IT math.IT</categories><comments>17 Pages, submitted to IEEE Trans. Inform. Theory</comments><report-no>HPL-2006-17</report-no><abstract>  We consider the problem of decision-making with side information and
unbounded loss functions. Inspired by probably approximately correct learning
model, we use a slightly different model that incorporates the notion of side
information in a more generic form to make it applicable to a broader class of
applications including parameter estimation and system identification. We
address sufficient conditions for consistent decision-making with exponential
convergence behavior. In this regard, besides a certain condition on the growth
function of the class of loss functions, it suffices that the class of loss
functions be dominated by a measurable function whose exponential Orlicz
expectation is uniformly bounded over the probabilistic model. Decay exponent,
decay constant, and sample complexity are discussed. Example applications to
method of moments, maximum likelihood estimation, and system identification are
illustrated, as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601116</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601116</id><created>2006-01-27</created><updated>2006-09-15</updated><authors><author><keyname>Kucherov</keyname><forenames>Gregory</forenames><affiliation>LIFL</affiliation></author><author><keyname>No&#xe9;</keyname><forenames>Laurent</forenames><affiliation>LIFL</affiliation></author><author><keyname>Roytberg</keyname><forenames>Mihkail</forenames><affiliation>LIFL</affiliation></author></authors><title>A unifying framework for seed sensitivity and its application to subset
  seeds</title><categories>cs.DS q-bio.QM</categories><proxy>ccsd ccsd-00018114</proxy><journal-ref>Journal of Bioinformatics and Computational Biology 4 (2006) 2, pp
  553--569</journal-ref><doi>10.1142/S0219720006001977</doi><abstract>  We propose a general approach to compute the seed sensitivity, that can be
applied to different definitions of seeds. It treats separately three
components of the seed sensitivity problem -- a set of target alignments, an
associated probability distribution, and a seed model -- that are specified by
distinct finite automata. The approach is then applied to a new concept of
subset seeds for which we propose an efficient automaton construction.
Experimental results confirm that sensitive subset seeds can be efficiently
designed using our approach, and can then be used in similarity search
producing better results than ordinary spaced seeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601117</id><created>2006-01-27</created><updated>2007-01-18</updated><authors><author><keyname>Kulkarni</keyname><forenames>Dhananjay D.</forenames></author><author><keyname>Verma</keyname><forenames>Shekhar</forenames></author><author><keyname>Prashant</keyname></author></authors><title>Finding Cliques of a Graph using Prime Numbers</title><categories>cs.DS</categories><comments>7 pages, 1 figure</comments><abstract>  This paper proposes a new algorithm for solving maximal cliques for simple
undirected graphs using the theory of prime numbers. A novel approach using
prime numbers is used to find cliques and ends with a discussion of the
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601118</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601118</id><created>2006-01-27</created><authors><author><keyname>Manset</keyname><forenames>David</forenames></author><author><keyname>Verjus</keyname><forenames>Herve</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Oquendo</keyname><forenames>Flavio</forenames></author></authors><title>A Formal Architecture-Centric Model-Driven Approach for the Automatic
  Generation of Grid Applications</title><categories>cs.SE</categories><comments>11 pages, 9 figures. Proc of the 8th International Conference on
  Enterprise Information Systems (ICEIS06) Paphos, Cyprus. May 2006</comments><acm-class>D.2.11</acm-class><abstract>  This paper discusses the concept of model-driven software engineering applied
to the Grid application domain. As an extension to this concept, the approach
described here, attempts to combine both formal architecture-centric and
model-driven paradigms. It is a commonly recognized statement that Grid systems
have seldom been designed using formal techniques although from past experience
such techniques have shown advantages. This paper advocates a formal
engineering approach to Grid system developments in an effort to contribute to
the rigorous development of Grids software architectures. This approach
addresses quality of service and cross-platform developments by applying the
model-driven paradigm to a formal architecture-centric engineering method. This
combination benefits from a formal semantic description power in addition to
model-based transformations. The result of such a novel combined concept
promotes the re-use of design models and facilitates developments in Grid
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601119</id><created>2006-01-28</created><authors><author><keyname>El-Ghalayini</keyname><forenames>Haya</forenames></author><author><keyname>Odeh</keyname><forenames>Mohammed</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author></authors><title>Engineering Conceptual Data Models from Domain Ontologies: A Critical
  Evaluation</title><categories>cs.SE</categories><comments>12 pages, 3 figures, presented at the 4th International Conference on
  Computer Science and Information Technology (CSIT'06). Amman Jordan April
  2006</comments><acm-class>D.2.11</acm-class><abstract>  This paper studies the differences and similarities between domain ontologies
and conceptual data models and the role that ontologies can play in
establishing conceptual data models during the process of information systems
development. A mapping algorithm has been proposed and embedded in a special
purpose Transformation Engine to generate a conceptual data model from a given
domain ontology. Both quantitative and qualitative methods have been adopted to
critically evaluate this new approach. In addition, this paper focuses on
evaluating the quality of the generated conceptual data model elements using
Bunge-Wand-Weber and OntoClean ontologies. The results of this evaluation
indicate that the generated conceptual data model provides a high degree of
accuracy in identifying the substantial domain entities along with their
attributes and relationships being derived from the consensual semantics of
domain knowledge. The results are encouraging and support the potential role
that this approach can take part in process of information system development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601120</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601120</id><created>2006-01-28</created><authors><author><keyname>Binia</keyname><forenames>Jacob</forenames></author></authors><title>On The Minimum Mean-Square Estimation Error of the Normalized Sum of
  Independent Narrowband Waves in the Gaussian Channel</title><categories>cs.IT math.IT</categories><comments>3 pages, Submitted to IEEE Symposium on Information Theory ISIT 2006</comments><abstract>  The minimum mean-square error of the estimation of a signal where observed
from the additive white Gaussian noise (WGN) channel's output, is analyzed. It
is assumed that the channel input's signal is composed of a (normalized) sum of
N narrowband, mutually independent waves. It is shown that if N goes to
infinity, then for any fixed signal energy to noise energy ratio (no mater how
big) both the causal minimum mean-square error CMMSE and the non-causal minimum
mean-square error MMSE converge to the signal energy at a rate which is
proportional to 1/N.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601121</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601121</id><created>2006-01-28</created><updated>2007-05-21</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>A Multi-Relational Network to Support the Scholarly Communication
  Process</title><categories>cs.DL cs.AI cs.IR</categories><comments>keywords: digital libraries and scholarly communication</comments><report-no>LA-UR-06-2416</report-no><journal-ref>International Journal of Public Information Systems, volume 2007,
  issue 1, pp. 13-29</journal-ref><abstract>  The general pupose of the scholarly communication process is to support the
creation and dissemination of ideas within the scientific community. At a finer
granularity, there exists multiple stages which, when confronted by a member of
the community, have different requirements and therefore different solutions.
In order to take a researcher's idea from an initial inspiration to a community
resource, the scholarly communication infrastructure may be required to 1)
provide a scientist initial seed ideas; 2) form a team of well suited
collaborators; 3) located the most appropriate venue to publish the formalized
idea; 4) determine the most appropriate peers to review the manuscript; and 5)
disseminate the end product to the most interested members of the community.
Through the various delinieations of this process, the requirements of each
stage are tied soley to the multi-functional resources of the community: its
researchers, its journals, and its manuscritps. It is within the collection of
these resources and their inherent relationships that the solutions to
scholarly communication are to be found. This paper describes an associative
network composed of multiple scholarly artifacts that can be used as a medium
for supporting the scholarly communication process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601122</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601122</id><created>2006-01-30</created><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author><author><keyname>Rozenberg</keyname><forenames>Grzegorz</forenames></author></authors><title>Reducibility of Gene Patterns in Ciliates using the Breakpoint Graph</title><categories>cs.LO q-bio.GN</categories><comments>30 pages, 13 figures</comments><journal-ref>Theoretical Computer Science, v. 356, 26-45, 2006</journal-ref><doi>10.1016/j.tcs.2006.01.041</doi><abstract>  Gene assembly in ciliates is one of the most involved DNA processings going
on in any organism. This process transforms one nucleus (the micronucleus) into
another functionally different nucleus (the macronucleus). We continue the
development of the theoretical models of gene assembly, and in particular we
demonstrate the use of the concept of the breakpoint graph, known from another
branch of DNA transformation research. More specifically: (1) we characterize
the intermediate gene patterns that can occur during the transformation of a
given micronuclear gene pattern to its macronuclear form; (2) we determine the
number of applications of the loop recombination operation (the most basic of
the three molecular operations that accomplish gene assembly) needed in this
transformation; (3) we generalize previous results (and give elegant
alternatives for some proofs) concerning characterizations of the micronuclear
gene patterns that can be assembled using a specific subset of the three
molecular operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601123</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601123</id><created>2006-01-29</created><authors><author><keyname>Martinian</keyname><forenames>Emin</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Low density codes achieve the rate-distortion bound</title><categories>cs.IT math.IT</categories><comments>To be published in Proceedings of the Data Compression Conference;
  Snowbird, Utah, March 2006; 10 pages total</comments><abstract>  We propose a new construction for low-density source codes with multiple
parameters that can be tuned to optimize the performance of the code. In
addition, we introduce a set of analysis techniques for deriving upper bounds
for the expected distortion of our construction, as well as more general
low-density constructions. We show that (with an optimal encoding algorithm)
our codes achieve the rate-distortion bound for a binary symmetric source and
Hamming distortion. Our methods also provide rigorous upper bounds on the
minimum distortion achievable by previously proposed low-density constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601124</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601124</id><created>2006-01-30</created><authors><author><keyname>Kaya</keyname><forenames>Onur</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Power Control for User Cooperation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications, October
  2005</comments><abstract>  For a fading Gaussian multiple access channel with user cooperation, we
obtain the optimal power allocation policies that maximize the rates achievable
by block Markov superposition coding. The optimal policies result in a coding
scheme that is simpler than the one for a general multiple access channel with
generalized feedback. This simpler coding scheme also leads to the possibility
of formulating an otherwise non-concave optimization problem as a concave one.
Using the channel state information at the transmitters to adapt the powers, we
demonstrate significant gains over the achievable rates for existing
cooperative systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601125</id><created>2006-01-30</created><authors><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author><author><keyname>Krafft</keyname><forenames>Dean</forenames></author><author><keyname>Cornwell</keyname><forenames>Tim</forenames></author><author><keyname>Dushay</keyname><forenames>Naomi</forenames></author><author><keyname>Eckstrom</keyname><forenames>Dean</forenames></author><author><keyname>Saylor</keyname><forenames>John</forenames></author></authors><title>Metadata aggregation and &quot;automated digital libraries&quot;: A retrospective
  on the NSDL experience</title><categories>cs.DL</categories><comments>Submission to JCDL 2006</comments><acm-class>H.3.7</acm-class><abstract>  Over three years ago, the Core Integration team of the National Science
Digital Library (NSDL) implemented a digital library based on metadata
aggregation using Dublin Core and OAI-PMH. The initial expectation was that
such low-barrier technologies would be relatively easy to automate and
administer. While this architectural choice permitted rapid deployment of a
production NSDL, our three years of experience have contradicted our original
expectations of easy automation and low people cost. We have learned that
alleged &quot;low-barrier&quot; standards are often harder to deploy than expected. In
this paper we report on this experience and comment on the general cost, the
functionality, and the ultimate effectiveness of this architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601126</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601126</id><created>2006-01-30</created><authors><author><keyname>Krishnan</keyname><forenames>K. Murali</forenames></author><author><keyname>Shankar</keyname><forenames>Priti</forenames></author></authors><title>Approximate Linear Time ML Decoding on Tail-Biting Trellises in Two
  Rounds</title><categories>cs.IT math.IT</categories><journal-ref>Proc. ISIT 2006, pp.2245-2249</journal-ref><abstract>  A linear time approximate maximum likelihood decoding algorithm on
tail-biting trellises is prsented, that requires exactly two rounds on the
trellis. This is an adaptation of an algorithm proposed earlier with the
advantage that it reduces the time complexity from O(mlogm) to O(m) where m is
the number of nodes in the tail-biting trellis. A necessary condition for the
output of the algorithm to differ from the output of the ideal ML decoder is
reduced and simulation results on an AWGN channel using tail-biting rrellises
for two rate 1/2 convoluational codes with memory 4 and 6 respectively are
reported
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601127</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601127</id><created>2006-01-30</created><authors><author><keyname>Fiat</keyname><forenames>Amos</forenames></author><author><keyname>Mendel</keyname><forenames>Manor</forenames></author></authors><title>Truly Online Paging with Locality of Reference</title><categories>cs.DS</categories><comments>37 pages. Preliminary version appeared in FOCS '97</comments><journal-ref>38th Annual Symposium on Foundations of Computer Science (FOCS
  '97), 1997, pp. 326</journal-ref><doi>10.1109/SFCS.1997.646121</doi><abstract>  The competitive analysis fails to model locality of reference in the online
paging problem. To deal with it, Borodin et. al. introduced the access graph
model, which attempts to capture the locality of reference. However, the access
graph model has a number of troubling aspects. The access graph has to be known
in advance to the paging algorithm and the memory required to represent the
access graph itself may be very large.
  In this paper we present truly online strongly competitive paging algorithms
in the access graph model that do not have any prior information on the access
sequence. We present both deterministic and randomized algorithms. The
algorithms need only O(k log n) bits of memory, where k is the number of page
slots available and n is the size of the virtual address space. I.e.,
asymptotically no more memory than needed to store the virtual address
translation table.
  We also observe that our algorithms adapt themselves to temporal changes in
the locality of reference. We model temporal changes in the locality of
reference by extending the access graph model to the so called extended access
graph model, in which many vertices of the graph can correspond to the same
virtual page. We define a measure for the rate of change in the locality of
reference in G denoted by Delta(G). We then show our algorithms remain strongly
competitive as long as Delta(G) &gt;= (1+ epsilon)k, and no truly online algorithm
can be strongly competitive on a class of extended access graphs that includes
all graphs G with Delta(G) &gt;= k- o(k).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601128</identifier>
 <datestamp>2008-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601128</id><created>2006-01-30</created><updated>2008-05-18</updated><authors><author><keyname>Dehornoy</keyname><forenames>Pierre</forenames><affiliation>DMA</affiliation></author></authors><title>On the 3-distortion of a path</title><categories>cs.CG</categories><proxy>ccsd ccsd-00017449</proxy><journal-ref>European Journal of Combinatorics (2008)
  http://www.elsevier.com/wps/find/journaldescription.cws_home/622824/description#description</journal-ref><doi>10.1016/j.ejc.2006.11.002</doi><abstract>  We prove that, when a path of length n is embedded in R^2, the 3-distortion
is an Omega(n^{1/2}), and that, when embedded in R^d, the 3-distortion is an
O(n^{1/d-1}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601129</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601129</id><created>2006-01-30</created><authors><author><keyname>Ponnath</keyname><forenames>Abhilash</forenames></author></authors><title>Instantaneously Trained Neural Networks</title><categories>cs.NE cs.AI</categories><comments>13 pages</comments><abstract>  This paper presents a review of instantaneously trained neural networks
(ITNNs). These networks trade learning time for size and, in the basic model, a
new hidden node is created for each training sample. Various versions of the
corner-classification family of ITNNs, which have found applications in
artificial intelligence (AI), are described. Implementation issues are also
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601130</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601130</id><created>2006-01-30</created><authors><author><keyname>Dimakis</keyname><forenames>A. G.</forenames></author><author><keyname>Petrovic</keyname><forenames>D.</forenames></author><author><keyname>Ramchandran</keyname><forenames>K.</forenames></author></authors><title>From Dumb Wireless Sensors to Smart Networks using Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>To be presented at the Inaugural Workshop of the Center for
  Information Theory and Its Applications, University of California - San
  Diego, La Jolla, CA, February 6 - 10, 2006</comments><abstract>  The vision of wireless sensor networks is one of a smart collection of tiny,
dumb devices. These motes may be individually cheap, unintelligent, imprecise,
and unreliable. Yet they are able to derive strength from numbers, rendering
the whole to be strong, reliable and robust. Our approach is to adopt a
distributed and randomized mindset and rely on in network processing and
network coding. Our general abstraction is that nodes should act only locally
and independently, and the desired global behavior should arise as a collective
property of the network. We summarize our work and present how these ideas can
be applied for communication and storage in sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601131</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601131</id><created>2006-01-30</created><updated>2006-05-01</updated><authors><author><keyname>Predd</keyname><forenames>Joel B.</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Osherson</keyname><forenames>Daniel N.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Scalable Algorithms for Aggregating Disparate Forecasts of Probability</title><categories>cs.AI cs.DC cs.IT math.IT</categories><comments>To be presented at the Ninth International Conference on Information
  Fusion, Florence, Italy, July 10-13, 2006</comments><abstract>  In this paper, computational aspects of the panel aggregation problem are
addressed. Motivated primarily by applications of risk assessment, an algorithm
is developed for aggregating large corpora of internally incoherent probability
assessments. The algorithm is characterized by a provable performance
guarantee, and is demonstrated to be orders of magnitude faster than existing
tools when tested on several real-world data-sets. In addition, unexpected
connections between research in risk assessment and wireless sensor networks
are exposed, as several key ideas are illustrated to be useful in both fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601132</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601132</id><created>2006-01-31</created><authors><author><keyname>Rastegar</keyname><forenames>R.</forenames></author><author><keyname>Meybodi</keyname><forenames>M. R.</forenames></author></authors><title>A Study on the Global Convergence Time Complexity of Estimation of
  Distribution Algorithms</title><categories>cs.AI cs.NE</categories><abstract>  The Estimation of Distribution Algorithm is a new class of population based
search methods in that a probabilistic model of individuals is estimated based
on the high quality individuals and used to generate the new individuals. In
this paper we compute 1) some upper bounds on the number of iterations required
for global convergence of EDA 2) the exact number of iterations needed for EDA
to converge to global optima.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601133</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601133</id><created>2006-01-31</created><updated>2009-01-14</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Giorgi</keyname><forenames>Pascal</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Pernet</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>Dense Linear Algebra over Finite Fields: the FFLAS and FFPACK packages</title><categories>cs.SC</categories><proxy>ccsd ccsd-00018223</proxy><journal-ref>ACM Transactions on Mathematical Software 35, 3 (2009) article 19</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past two decades, some major efforts have been made to reduce exact
(e.g. integer, rational, polynomial) linear algebra problems to matrix
multiplication in order to provide algorithms with optimal asymptotic
complexity. To provide efficient implementations of such algorithms one need to
be careful with the underlying arithmetic. It is well known that modular
techniques such as the Chinese remainder algorithm or the p-adic lifting allow
very good practical performance, especially when word size arithmetic are used.
Therefore, finite field arithmetic becomes an important core for efficient
exact linear algebra libraries. In this paper, we study high performance
implementations of basic linear algebra routines over word size prime fields:
specially the matrix multiplication; our goal being to provide an exact
alternate to the numerical BLAS library. We show that this is made possible by
a carefull combination of numerical computations and asymptotically faster
algorithms. Our kernel has several symbolic linear algebra applications enabled
by diverse matrix multiplication reductions: symbolic triangularization, system
solving, determinant and matrix inverse implementations are thus studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601134</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601134</id><created>2006-01-31</created><updated>2006-10-18</updated><authors><author><keyname>Avigad</keyname><forenames>Jeremy</forenames></author><author><keyname>Friedman</keyname><forenames>Harvey</forenames></author></authors><title>Combining decision procedures for the reals</title><categories>cs.LO</categories><comments>Will appear in Logical Methods in Computer Science</comments><acm-class>F.4.1; I.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 4 (October
  18, 2006) lmcs:803</journal-ref><doi>10.2168/LMCS-2(4:4)2006</doi><abstract>  &lt;p&gt;We address the general problem of determining the validity of boolean
combinations of equalities and inequalities between real-valued expressions. In
particular, we consider methods of establishing such assertions using only
restricted forms of distributivity. At the same time, we explore ways in which
&quot;local&quot; decision or heuristic procedures for fragments of the theory of the
reals can be amalgamated into global ones. &lt;/p&gt; &lt;p&gt;Let &lt;em&gt;Tadd[Q]&lt;/em&gt; be the
first-order theory of the real numbers in the language of ordered groups, with
negation, a constant &lt;em&gt;1&lt;/em&gt;, and function symbols for multiplication by
rational constants. Let &lt;em&gt;Tmult[Q]&lt;/em&gt; be the analogous theory for the
multiplicative structure, and let &lt;em&gt;T[Q]&lt;/em&gt; be the union of the two. We
show that although &lt;em&gt;T[Q]&lt;/em&gt; is undecidable, the universal fragment of
&lt;em&gt;T[Q]&lt;/em&gt; is decidable. We also show that terms of &lt;em&gt;T[Q]&lt;/em&gt;can
fruitfully be put in a normal form. We prove analogous results for theories in
which &lt;em&gt;Q&lt;/em&gt; is replaced, more generally, by suitable subfields &lt;em&gt;F&lt;/em&gt;
of the reals. Finally, we consider practical methods of establishing
quantifier-free validities that approximate our (impractical) decidability
results.&lt;/p&gt;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0601135</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0601135</id><created>2006-01-31</created><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author><author><keyname>Muskulus</keyname><forenames>Michael</forenames></author></authors><title>Strategies of Loop Recombination in Ciliates</title><categories>cs.LO q-bio.GN</categories><comments>22 pages, 14 figures</comments><report-no>LIACS Technical Report 2006-01</report-no><journal-ref>Discrete Applied Mathematics, v. 156, 1736-1753, 2008</journal-ref><doi>10.1016/j.dam.2007.08.032</doi><abstract>  Gene assembly in ciliates is an extremely involved DNA transformation
process, which transforms a nucleus, the micronucleus, to another functionally
different nucleus, the macronucleus. In this paper we characterize which loop
recombination operations (one of the three types of molecular operations that
accomplish gene assembly) can possibly be applied in the transformation of a
given gene from its micronuclear form to its macronuclear form. We also
characterize in which order these loop recombination operations are applicable.
This is done in the abstract and more general setting of so-called legal
strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602001</id><created>2006-01-31</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Thakur</keyname><forenames>Mayur</forenames></author></authors><title>Query-Monotonic Turing Reductions</title><categories>cs.CC</categories><report-no>URCS-TR-818</report-no><acm-class>F.1.3; F.1.2</acm-class><abstract>  We study reductions that limit the extreme adaptivity of Turing reductions.
In particular, we study reductions that make a rapid, structured progression
through the set to which they are reducing: Each query is strictly longer
(shorter) than the previous one. We call these reductions query-increasing
(query-decreasing) Turing reductions. We also study query-nonincreasing
(query-nondecreasing) Turing reductions. These are Turing reductions in which
the sequence of query lengths is nonincreasing (nondecreasing). We ask whether
these restrictions in fact limit the power of reductions. We prove that
query-increasing and query-decreasing Turing reductions are incomparable with
(that is, are neither strictly stronger than nor strictly weaker than)
truth-table reductions and are strictly weaker than Turing reductions. In
addition, we prove that query-nonincreasing and query-nondecreasing Turing
reductions are strictly stronger than truth-table reductions and strictly
weaker than Turing reductions. Despite the fact that we prove query-increasing
and query-decreasing Turing reductions to in the general case be strictly
weaker than Turing reductions, we identify a broad class of sets A for which
any set that Turing reduces to A will also reduce to A via both
query-increasing and query-decreasing Turing reductions. In particular, this
holds for all tight paddable sets, where a set is said to be tight paddable
exactly if it is paddable via a function whose output length is bounded tightly
both from above and from below in the length of the input. We prove that many
natural NP-complete problems such as satisfiability, clique, and vertex cover
are tight paddable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602002</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602002</id><created>2006-01-31</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>Simulating Network Influence Algorithms Using Particle-Swarms: PageRank
  and PageRank-Priors</title><categories>cs.DS</categories><comments>17 pages, currently in peer-review</comments><abstract>  A particle-swarm is a set of indivisible processing elements that traverse a
network in order to perform a distributed function. This paper will describe a
particular implementation of a particle-swarm that can simulate the behavior of
the popular PageRank algorithm in both its {\it global-rank} and {\it
relative-rank} incarnations. PageRank is compared against the particle-swarm
method on artificially generated scale-free networks of 1,000 nodes constructed
using a common gamma value, $\gamma = 2.5$. The running time of the
particle-swarm algorithm is $O(|P|+|P|t)$ where $|P|$ is the size of the
particle population and $t$ is the number of particle propagation iterations.
The particle-swarm method is shown to be useful due to its ease of extension
and running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602003</id><created>2006-02-02</created><authors><author><keyname>Mandhani</keyname><forenames>Navneet</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Watermarking Using Decimal Sequences</title><categories>cs.CR</categories><comments>8 pages, 9 figures</comments><journal-ref>Cryptologia, vol. 29, pp. 50-58, 2005</journal-ref><abstract>  This paper introduces the use of decimal sequences in a code division
multiple access (CDMA) based watermarking system to hide information for
authentication in black and white images. Matlab version 6.5 was used to
implement the algorithms discussed in this paper. The advantage of using
d-sequences over PN sequences is that one can choose from a variety of prime
numbers which provides a more flexible system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602004</id><created>2006-02-02</created><authors><author><keyname>Gottlob</keyname><forenames>Georg</forenames></author><author><keyname>Koch</keyname><forenames>Christoph</forenames></author><author><keyname>Schulz</keyname><forenames>Klaus U.</forenames></author></authors><title>Conjunctive Queries over Trees</title><categories>cs.DB cs.AI cs.CC cs.LO</categories><comments>36 pages, 12 figures, 2 tables, long version of PODS 2004 papers. To
  appear in Journal of the ACM 53(2), March 2006</comments><acm-class>E.1; F.1.3; F.2.2; H.2.3; H.2.4; I.7.2</acm-class><abstract>  We study the complexity and expressive power of conjunctive queries over
unranked labeled trees represented using a variety of structure relations such
as ``child'', ``descendant'', and ``following'' as well as unary relations for
node labels. We establish a framework for characterizing structures
representing trees for which conjunctive queries can be evaluated efficiently.
Then we completely chart the tractability frontier of the problem and establish
a dichotomy theorem for our axis relations, i.e., we find all subset-maximal
sets of axes for which query evaluation is in polynomial time and show that for
all other cases, query evaluation is NP-complete. All polynomial-time results
are obtained immediately using the proof techniques from our framework.
Finally, we study the expressiveness of conjunctive queries over trees and show
that for each conjunctive query, there is an equivalent acyclic positive query
(i.e., a set of acyclic conjunctive queries), but that in general this query is
not of polynomial size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602005</id><created>2006-02-03</created><authors><author><keyname>Ch&#xe1;ves</keyname><forenames>Francisco</forenames><affiliation>LIP</affiliation></author><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>LIRMM, LP2A</affiliation></author></authors><title>A library of Taylor models for PVS automatic proof checker</title><categories>cs.MS</categories><proxy>ccsd ccsd-00018529</proxy><abstract>  We present in this paper a library to compute with Taylor models, a technique
extending interval arithmetic to reduce decorrelation and to solve differential
equations. Numerical software usually produces only numerical results. Our
library can be used to produce both results and proofs. As seen during the
development of Fermat's last theorem reported by Aczel 1996, providing a proof
is not sufficient. Our library provides a proof that has been thoroughly
scrutinized by a trustworthy and tireless assistant. PVS is an automatic proof
assistant that has been fairly developed and used and that has no internal
connection with interval arithmetic or Taylor models. We built our library so
that PVS validates each result as it is produced. As producing and validating a
proof, is and will certainly remain a bigger task than just producing a
numerical result our library will never be a replacement to imperative
implementations of Taylor models such as Cosy Infinity. Our library should
mainly be used to validate small to medium size results that are involved in
safety or life critical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602006</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602006</id><created>2006-02-03</created><authors><author><keyname>Koch</keyname><forenames>Christoph</forenames></author></authors><title>A Visual Query Language for Complex-Value Databases</title><categories>cs.DB cs.HC</categories><comments>12 pages, 6 figures, 1 table</comments><abstract>  In this paper, a visual language, VCP, for queries on complex-value databases
is proposed. The main strength of the new language is that it is purely visual:
(i) It has no notion of variable, quantification, partiality, join, pattern
matching, regular expression, recursion, or any other construct proper to
logical, functional, or other database query languages and (ii) has a very
natural, strong, and intuitive design metaphor. The main operation is that of
copying and pasting in a schema tree.
  We show that despite its simplicity, VCP precisely captures complex-value
algebra without powerset, or equivalently, monad algebra with union and
difference. Thus, its expressive power is precisely that of the language that
is usually considered to play the role of relational algebra for complex-value
databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602007</identifier>
 <datestamp>2008-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602007</id><created>2006-02-04</created><updated>2008-04-01</updated><authors><author><keyname>Dodis</keyname><forenames>Yevgeniy</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author><author><keyname>Reyzin</keyname><forenames>Leonid</forenames></author><author><keyname>Smith</keyname><forenames>Adam</forenames></author></authors><title>Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other
  Noisy Data</title><categories>cs.CR cs.IT math.IT</categories><comments>47 pp., 3 figures. Prelim. version in Eurocrypt 2004, Springer LNCS
  3027, pp. 523-540. Differences from version 3: minor edits for grammar,
  clarity, and typos</comments><journal-ref>SIAM Journal on Computing, 38(1):97-139, 2008</journal-ref><doi>10.1137/060651380</doi><abstract>  We provide formal definitions and efficient secure techniques for
  - turning noisy information into keys usable for any cryptographic
application, and, in particular,
  - reliably and securely authenticating biometric data.
  Our techniques apply not just to biometric information, but to any keying
material that, unlike traditional cryptographic keys, is (1) not reproducible
precisely and (2) not distributed uniformly. We propose two primitives: a
&quot;fuzzy extractor&quot; reliably extracts nearly uniform randomness R from its input;
the extraction is error-tolerant in the sense that R will be the same even if
the input changes, as long as it remains reasonably close to the original.
Thus, R can be used as a key in a cryptographic application. A &quot;secure sketch&quot;
produces public information about its input w that does not reveal w, and yet
allows exact recovery of w given another value that is close to w. Thus, it can
be used to reliably reproduce error-prone biometric inputs without incurring
the security risk inherent in storing them.
  We define the primitives to be both formally secure and versatile,
generalizing much prior work. In addition, we provide nearly optimal
constructions of both primitives for various measures of ``closeness'' of input
data, such as Hamming distance, edit distance, and set difference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602008</id><created>2006-02-04</created><authors><author><keyname>Marino</keyname><forenames>Julio</forenames></author><author><keyname>Herranz</keyname><forenames>Angel</forenames></author><author><keyname>Moreno-Navarro</keyname><forenames>Juan Jose</forenames></author></authors><title>Demand Analysis with Partial Predicates</title><categories>cs.PL cs.SC</categories><comments>This is the extended version of a paper accepted for publication in a
  forthcoming special issue of Theory and Practice of Logic Programming on
  Multiparadigm and Constraint Programming (Falaschi and Maher, eds.)
  Appendices are missing in the printed version</comments><abstract>  In order to alleviate the inefficiencies caused by the interaction of the
logic and functional sides, integrated languages may take advantage of
\emph{demand} information -- i.e. knowing in advance which computations are
needed and, to which extent, in a particular context. This work studies
\emph{demand analysis} -- which is closely related to \emph{backwards
strictness analysis} -- in a semantic framework of \emph{partial predicates},
which in turn are constructive realizations of ideals in a domain. This will
allow us to give a concise, unified presentation of demand analysis, to relate
it to other analyses based on abstract interpretation or strictness logics,
some hints for the implementation, and, more important, to prove the soundness
of our analysis based on \emph{demand equations}. There are also some
innovative results. One of them is that a set constraint-based analysis has
been derived in a stepwise manner using ideas taken from the area of program
transformation. The other one is the possibility of using program
transformation itself to perform the analysis, specially in those domains of
properties where algorithms based on constraint solving are too weak.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602009</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602009</id><created>2006-02-06</created><updated>2016-02-08</updated><authors><author><keyname>Cs&#xf3;ka</keyname><forenames>Endre</forenames></author></authors><title>Efficient Teamwork</title><categories>cs.OH</categories><comments>47 pages. It contains colored figures but readable in black and white</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In dynamic stochastic environments, dynamic decision making is necessary for
efficiency. In multi-agent projects, this means that all agents should
truthfully reveal their abilities and chance events, and they should make all
their hidden decisions according to the efficient dynamic plan. But agents can
easily cheat, e.g. by exerting lower efforts, reporting optimistic stochastic
predictions, or reporting higher costs for being flexible. In this paper, we
solve this problem by constructing a mechanism that implements efficiency in
quasi-dominant equilibrium, provided that we can select the participating
agents by a tender, and the agents have private values. The mechanism is widely
applicable, and the major application details will be elaborated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602010</id><created>2006-02-04</created><authors><author><keyname>Kao</keyname><forenames>Ming-Yang</forenames></author><author><keyname>Schweller</keyname><forenames>Robert</forenames></author></authors><title>Reducing Tile Complexity for Self-Assembly Through Temperature
  Programming</title><categories>cs.CC</categories><comments>A preliminary version of this paper appeared in Proceedings of the
  17th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2006), Miami,
  Florida, Jan. 2006</comments><abstract>  We consider the tile self-assembly model and how tile complexity can be
eliminated by permitting the temperature of the self-assembly system to be
adjusted throughout the assembly process. To do this, we propose novel
techniques for designing tile sets that permit an arbitrary length $m$ binary
number to be encoded into a sequence of $O(m)$ temperature changes such that
the tile set uniquely assembles a supertile that precisely encodes the
corresponding binary number. As an application, we show how this provides a
general tile set of size O(1) that is capable of uniquely assembling
essentially any $n\times n$ square, where the assembled square is determined by
a temperature sequence of length $O(\log n)$ that encodes a binary description
of $n$. This yields an important decrease in tile complexity from the required
$\Omega(\frac{\log n}{\log\log n})$ for almost all $n$ when the temperature of
the system is fixed. We further show that for almost all $n$, no tile system
can simultaneously achieve both $o(\log n)$ temperature complexity and
$o(\frac{\log n}{\log\log n})$ tile complexity, showing that both versions of
an optimal square building scheme have been discovered. This work suggests that
temperature change can constitute a natural, dynamic method for providing input
to self-assembly systems that is potentially superior to the current technique
of designing large tile sets with specific inputs hardwired into the tileset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602011</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602011</id><created>2006-02-05</created><updated>2006-02-11</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>The intuitionistic fragment of computability logic at the propositional
  level</title><categories>cs.LO cs.AI math.LO</categories><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Annals of Pure and Applied Logic 147 (2007), pp. 187-227</journal-ref><doi>10.1016/j.apal.2007.05.001</doi><abstract>  This paper presents a soundness and completeness proof for propositional
intuitionistic calculus with respect to the semantics of computability logic.
The latter interprets formulas as interactive computational problems,
formalized as games between a machine and its environment. Intuitionistic
implication is understood as algorithmic reduction in the weakest possible --
and hence most natural -- sense, disjunction and conjunction as
deterministic-choice combinations of problems (disjunction = machine's choice,
conjunction = environment's choice), and &quot;absurd&quot; as a computational problem of
universal strength. See http://www.cis.upenn.edu/~giorgi/cl.html for a
comprehensive online source on computability logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602012</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602012</id><created>2006-02-05</created><authors><author><keyname>Anashin</keyname><forenames>Vladimir</forenames></author></authors><title>Wreath Products in Stream Cipher Design</title><categories>cs.CR</categories><comments>18 pages, 2 figures. To be published in Proceedings of the Int'l
  Conference `Mathematics and Secure Information Technologies' (Moscow, 2005).
  The paper is mainly based on the preprint http://arxiv.org/abs/cs.CR/0401030,
  yet contains some new results and no proofs</comments><acm-class>E.3</acm-class><journal-ref>&quot;Applied Algebraic Dynamics&quot;, volume 49 of de Gruyter Expositions
  in Mathematics, 2009, 269-304</journal-ref><abstract>  The paper develops a novel approach to stream cipher design: Both the state
update function and the output function of the corresponding pseudorandom
generators are compositions of arithmetic and bitwise logical operations, which
are standard instructions of modern microprocessors. Moreover, both the state
update function and the output function are being modified dynamically during
the encryption. Also, these compositions could be keyed, so the only
information available to an attacker is that these functions belong to some
exponentially large class.
  The paper shows that under rather loose conditions the output sequence is
uniformly distributed, achieves maximum period length and has high linear
complexity and high $\ell$-error linear complexity. Ciphers of this kind are
flexible: One could choose a suitable combination of instructions to obtain due
performance without affecting the quality of the output sequence. Finally, some
evidence is given that a key recovery problem for (reasonably designed) stream
ciphers of this kind is intractable up to plausible conjectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602013</id><created>2006-02-05</created><authors><author><keyname>Pritchard</keyname><forenames>David</forenames></author></authors><title>An Optimal Distributed Edge-Biconnectivity Algorithm</title><categories>cs.DC</categories><comments>Submitted to PODC 2006. Contains a pstricks figure</comments><abstract>  We describe a synchronous distributed algorithm which identifies the
edge-biconnected components of a connected network. It requires a leader, and
uses messages of size O(log |V|). The main idea is to preorder a BFS spanning
tree, and then to efficiently compute least common ancestors so as to mark
cycle edges. This algorithm takes O(Diam) time and uses O(|E|) messages.
Furthermore, we show that no correct singly-initiated edge-biconnectivity
algorithm can beat either bound on any graph by more than a constant factor. We
also describe a near-optimal local algorithm for edge-biconnectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602014</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602014</id><created>2006-02-05</created><authors><author><keyname>Laufer</keyname><forenames>Amir</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Messer</keyname><forenames>Hagit</forenames></author></authors><title>Game theoretic aspects of distributed spectral coordination with
  application to DSL networks</title><categories>cs.IT math.IT</categories><abstract>  In this paper we use game theoretic techniques to study the value of
cooperation in distributed spectrum management problems. We show that the
celebrated iterative water-filling algorithm is subject to the prisoner's
dilemma and therefore can lead to severe degradation of the achievable rate
region in an interference channel environment. We also provide thorough
analysis of a simple two bands near-far situation where we are able to provide
closed form tight bounds on the rate region of both fixed margin iterative
water filling (FM-IWF) and dynamic frequency division multiplexing (DFDM)
methods. This is the only case where such analytic expressions are known and
all previous studies included only simulated results of the rate region. We
then propose an alternative algorithm that alleviates some of the drawbacks of
the IWF algorithm in near-far scenarios relevant to DSL access networks. We
also provide experimental analysis based on measured DSL channels of both
algorithms as well as the centralized optimum spectrum management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602015</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602015</id><created>2006-02-06</created><authors><author><keyname>Khoshnevis</keyname><forenames>Ahmad</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>On the Asymptotic Performance of Multiple Antenna Channels with Fast
  Channel Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  In this paper, we analyze the asymptotic performance of multiple antenna
channels where the transmitter has either perfect or finite bit channel state
information. Using the diversity-multiplexing tradeoff to characterize the
system performance, we demonstrate that channel feedback can fundamentally
change the system behavior. Even one-bit of information can increase the
diversity order of the system compared to the system with no transmitter
information. In addition, as the amount of channel information at the
transmitter increases, the diversity order for each multiplexing gain increases
and goes to infinity for perfect transmitter information. The major reason for
diversity order gain is a &quot;location-dependent&quot; temporal power control, which
adapts the power control strategy based on the average channel conditions of
the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602016</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602016</id><created>2006-02-06</created><updated>2009-04-14</updated><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Hurand</keyname><forenames>Mathilde</forenames></author></authors><title>Finding total unimodularity in optimization problems solved by linear
  programs</title><categories>cs.DS cs.DC</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A popular approach in combinatorial optimization is to model problems as
integer linear programs. Ideally, the relaxed linear program would have only
integer solutions, which happens for instance when the constraint matrix is
totally unimodular. Still, sometimes it is possible to build an integer
solution with the same cost from the fractional solution. Examples are two
scheduling problems and the single disk prefetching/caching problem. We show
that problems such as the three previously mentioned can be separated into two
subproblems: (1) finding an optimal feasible set of slots, and (2) assigning
the jobs or pages to the slots. It is straigthforward to show that the latter
can be solved greedily. We are able to solve the former with a totally
unimodular linear program, from which we obtain simple combinatorial algorithms
with improved worst case running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602017</id><created>2006-02-06</created><authors><author><keyname>Ortiz</keyname><forenames>J. S. Espinoza</forenames></author><author><keyname>Giraldi</keyname><forenames>Gilson A.</forenames></author><author><keyname>Neto</keyname><forenames>E. A. de Souza</forenames></author><author><keyname>Feij&#xf3;o</keyname><forenames>Raul A.</forenames></author></authors><title>Quasi-Linear Soft Tissue Models Revisited</title><categories>cs.OH</categories><comments>11 pages, 8figures</comments><acm-class>J.1; J.2</acm-class><abstract>  Incompressibility, nonlinear deformation under stress and viscoelasticity are
the fingerprint of soft tissue mechanical behavior. In order to model soft
tissues appropriately, we must pursue to complete these requirements. In this
work we revisited different soft tissue quasi-linear model possibilities in
trying to achieve for this commitment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602018</id><created>2006-02-06</created><authors><author><keyname>Jia</keyname><forenames>Jiyou</forenames></author><author><keyname>Hou</keyname><forenames>Shufen</forenames></author><author><keyname>Chen</keyname><forenames>Weichao</forenames></author></authors><title>Improving the CSIEC Project and Adapting It to the English Teaching and
  Learning in China</title><categories>cs.CY cs.AI cs.CL cs.HC cs.MA</categories><acm-class>K.3.1; I.2.7; I.2.11</acm-class><abstract>  In this paper after short review of the CSIEC project initialized by us in
2003 we present the continuing development and improvement of the CSIEC project
in details, including the design of five new Microsoft agent characters
representing different virtual chatting partners and the limitation of
simulated dialogs in specific practical scenarios like graduate job application
interview, then briefly analyze the actual conditions and features of its
application field: web-based English education in China. Finally we introduce
our efforts to adapt this system to the requirements of English teaching and
learning in China and point out the work next to do.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602019</id><created>2006-02-06</created><authors><author><keyname>Nie</keyname><forenames>Nie</forenames></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames></author></authors><title>Adaptive Channel Allocation Spectrum Etiquette for Cognitive Radio
  Networks</title><categories>cs.GT</categories><comments>ACM MONET (Mobile Networks and Applications), special issue on
  &quot;Reconfigurable Radio Technologies in Support of Ubiquitous Seamless
  Computing&quot;</comments><acm-class>C.2</acm-class><abstract>  In this work, we propose a game theoretic framework to analyze the behavior
of cognitive radios for distributed adaptive channel allocation. We define two
different objective functions for the spectrum sharing games, which capture the
utility of selfish users and cooperative users, respectively. Based on the
utility definition for cooperative users, we show that the channel allocation
problem can be formulated as a potential game, and thus converges to a
deterministic channel allocation Nash equilibrium point. Alternatively, a
no-regret learning implementation is proposed for both scenarios and it is
shown to have similar performance with the potential game when cooperation is
enforced, but with a higher variability across users. The no-regret learning
formulation is particularly useful to accommodate selfish users.
Non-cooperative learning games have the advantage of a very low overhead for
information exchange in the network.
  We show that cooperation based spectrum sharing etiquette improves the
overall network performance at the expense of an increased overhead required
for information exchange.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602020</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602020</id><created>2006-02-07</created><authors><author><keyname>Zheng</keyname><forenames>Yan-Xiu</forenames></author><author><keyname>Su</keyname><forenames>Yu T.</forenames></author></authors><title>Inter-Block Permuted Turbo Codes</title><categories>cs.IT math.IT</categories><comments>44 pages, 17 figures</comments><abstract>  The structure and size of the interleaver used in a turbo code critically
affect the distance spectrum and the covariance property of a component
decoder's information input and soft output. This paper introduces a new class
of interleavers, the inter-block permutation (IBP) interleavers, that can be
build on any existing &quot;good&quot; block-wise interleaver by simply adding an IBP
stage. The IBP interleavers reduce the above-mentioned correlation and increase
the effective interleaving size. The increased effective interleaving size
improves the distance spectrum while the reduced covariance enhances the
iterative decoder's performance. Moreover, the structure of the
IBP(-interleaved) turbo codes (IBPTC) is naturally fit for high rate
applications that necessitate parallel decoding.
  We present some useful bounds and constraints associated with the IBPTC that
can be used as design guidelines. The corresponding codeword weight upper
bounds for weight-2 and weight-4 input sequences are derived. Based on some of
the design guidelines, we propose a simple IBP algorithm and show that the
associated IBPTC yields 0.3 to 1.2 dB performance gain, or equivalently, an
IBPTC renders the same performance with a much reduced interleaving delay. The
EXIT and covariance behaviors provide another numerical proof of the
superiority of the proposed IBPTC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602021</id><created>2006-02-07</created><authors><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>LMS</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LMS</affiliation></author></authors><title>Using Domain Knowledge in Evolutionary System Identification</title><categories>cs.AI math.AP</categories><proxy>ccsd inria-00001094</proxy><abstract>  Two example of Evolutionary System Identification are presented to highlight
the importance of incorporating Domain Knowledge: the discovery of an
analytical indentation law in Structural Mechanics using constrained Genetic
Programming, and the identification of the repartition of underground
velocities in Seismic Prospection. Critical issues for sucessful ESI are
discussed in the light of these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602022</id><created>2006-02-07</created><authors><author><keyname>Ratle</keyname><forenames>Alain</forenames><affiliation>LMS</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LMS</affiliation></author></authors><title>Avoiding the Bloat with Stochastic Grammar-based Genetic Programming</title><categories>cs.AI</categories><proxy>ccsd inria-00001095</proxy><abstract>  The application of Genetic Programming to the discovery of empirical laws is
often impaired by the huge size of the search space, and consequently by the
computer resources needed. In many cases, the extreme demand for memory and CPU
is due to the massive growth of non-coding segments, the introns. The paper
presents a new program evolution framework which combines distribution-based
evolution in the PBIL spirit, with grammar-based genetic programming; the
information is stored as a probability distribution on the gra mmar rules,
rather than in a population. Experiments on a real-world like problem show that
this approach gives a practical solution to the problem of intron growth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602023</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602023</id><created>2006-02-07</created><authors><author><keyname>Kafri</keyname><forenames>Oded</forenames></author></authors><title>Information theory and Thermodynamics</title><categories>cs.IT math.IT</categories><comments>16 pages and 5 figures. The paper was submitted to IEEE Transaction
  on Information theory</comments><acm-class>H.1.1</acm-class><abstract>  A communication theory for a transmitter broadcasting to many receivers is
presented. In this case energetic considerations cannot be neglected as in
Shannon theory. It is shown that, when energy is assigned to the information
bit, information theory complies with classical thermodynamic and is part of
it. To provide a thermodynamic theory of communication it is necessary to
define equilibrium for informatics systems that are not in thermal equilibrium
and to calculate temperature, heat, and entropy with accordance to Clausius
inequality. It is shown that for a binary file the temperature is proportional
to the bit energy and that information is thermodynamic entropy. Equilibrium
exists in random files that cannot be compressed. Thermodynamic bounds on the
computing power of a physical device, and the maximum information that an
antenna can broadcast are calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602024</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602024</id><created>2006-02-07</created><updated>2006-03-08</updated><authors><author><keyname>Conradie</keyname><forenames>Willem</forenames></author><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author><author><keyname>Vakarelov</keyname><forenames>Dimiter</forenames></author></authors><title>Algorithmic correspondence and completeness in modal logic. I. The core
  algorithm SQEMA</title><categories>cs.LO</categories><comments>26 pages, no figures, to appear in the Logical Methods in Computer
  Science</comments><acm-class>F.4.1; I.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 1 (March 7,
  2006) lmcs:1227</journal-ref><doi>10.2168/LMCS-2(1:5)2006</doi><abstract>  Modal formulae express monadic second-order properties on Kripke frames, but
in many important cases these have first-order equivalents. Computing such
equivalents is important for both logical and computational reasons. On the
other hand, canonicity of modal formulae is important, too, because it implies
frame-completeness of logics axiomatized with canonical formulae.
  Computing a first-order equivalent of a modal formula amounts to elimination
of second-order quantifiers. Two algorithms have been developed for
second-order quantifier elimination: SCAN, based on constraint resolution, and
DLS, based on a logical equivalence established by Ackermann.
  In this paper we introduce a new algorithm, SQEMA, for computing first-order
equivalents (using a modal version of Ackermann's lemma) and, moreover, for
proving canonicity of modal formulae. Unlike SCAN and DLS, it works directly on
modal formulae, thus avoiding Skolemization and the subsequent problem of
unskolemization. We present the core algorithm and illustrate it with some
examples. We then prove its correctness and the canonicity of all formulae on
which the algorithm succeeds. We show that it succeeds not only on all
Sahlqvist formulae, but also on the larger class of inductive formulae,
introduced in our earlier papers. Thus, we develop a purely algorithmic
approach to proving canonical completeness in modal logic and, in particular,
establish one of the most general completeness results in modal logic so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602025</id><created>2006-02-07</created><authors><author><keyname>Argentini</keyname><forenames>Gianluca</forenames></author></authors><title>On local symbolic approximation and resolution of ODEs using Implicit
  Function Theorem</title><categories>cs.NA math.CA physics.comp-ph</categories><comments>12 pages, 2 figures; keywords: ordinary differential equations,
  implicit function theorem, local solutions, symbolic solutions, cavitation</comments><acm-class>G.1.7</acm-class><abstract>  In this work the implicit function theorem is used for searching local
symbolic resolution of differential equations. General results of existence for
first order equations are proven and some examples, one relative to cavitation
in a fluid, are developed. These examples seem to show that local approximation
of non linear differential equations can give useful informations about
symbolic form of possible solutions, and in the case a global solution is
known, locally the accuracy of approximation can be good.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602026</id><created>2006-02-07</created><authors><author><keyname>Anjum</keyname><forenames>Ashiq</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Ali</keyname><forenames>Arshad</forenames></author><author><keyname>Willers</keyname><forenames>Ian</forenames></author></authors><title>Bulk Scheduling with DIANA Scheduler</title><categories>cs.DC</categories><comments>4 pages, 5 figures. Accepted by the Computing for High Energy Physics
  Conference. Mumbai, Indai. February 2006</comments><acm-class>H.2.4; J.3</acm-class><abstract>  Results from and progress on the development of a Data Intensive and Network
Aware (DIANA) Scheduling engine, primarily for data intensive sciences such as
physics analysis, are described. Scientific analysis tasks can involve
thousands of computing, data handling, and network resources and the size of
the input and output files and the amount of overall storage space allocated to
a user necessarily can have significant bearing on the scheduling of data
intensive applications. If the input or output files must be retrieved from a
remote location, then the time required transferring the files must also be
taken into consideration when scheduling compute resources for the given
application. The central problem in this study is the coordinated management of
computation and data at multiple locations and not simply data movement.
However, this can be a very costly operation and efficient scheduling can be a
challenge if compute and data resources are mapped without network cost. We
have implemented an adaptive algorithm within the DIANA Scheduler which takes
into account data location and size, network performance and computation
capability to make efficient global scheduling decisions. DIANA is a
performance-aware as well as an economy-guided Meta Scheduler. It iteratively
allocates each job to the site that is likely to produce the best performance
as well as optimizing the global queue for any remaining pending jobs.
Therefore it is equally suitable whether a single job is being submitted or
bulk scheduling is being performed. Results suggest that considerable
performance improvements are to be gained by adopting the DIANA scheduling
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602027</id><created>2006-02-07</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>Explaining Constraint Programming</title><categories>cs.PL cs.AI</categories><comments>15 pages, appeared in &quot;Processes, Terms and Cycles: Steps on the Road
  to Infinity&quot;, (A. Middeldorp, V. van Oostrom, F. van Raamsdonk, R. de Vrijer,
  eds.), LNCS 3838, pp. 55-69. (2005)</comments><acm-class>D.3.2; F.4.1</acm-class><abstract>  We discuss here constraint programming (CP) by using a proof-theoretic
perspective. To this end we identify three levels of abstraction. Each level
sheds light on the essence of CP.
  In particular, the highest level allows us to bring CP closer to the
computation as deduction paradigm. At the middle level we can explain various
constraint propagation algorithms. Finally, at the lowest level we can address
the issue of automatic generation and optimization of the constraint
propagation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602028</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602028</id><created>2006-02-07</created><authors><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Analysis of Belief Propagation for Non-Linear Problems: The Example of
  CDMA (or: How to Prove Tanaka's Formula)</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 eps figures, IEEE Information Theory Workshop, Punta del
  Este, Uruguay, March 13-17, 2006 (invited)</comments><abstract>  We consider the CDMA (code-division multiple-access) multi-user detection
problem for binary signals and additive white gaussian noise. We propose a
spreading sequences scheme based on random sparse signatures, and a detection
algorithm based on belief propagation (BP) with linear time complexity. In the
new scheme, each user conveys its power onto a finite number of chips l, in the
large system limit.
  We analyze the performances of BP detection and prove that they coincide with
the ones of optimal (symbol MAP) detection in the l-&gt;\infty limit. In the same
limit, we prove that the information capacity of the system converges to
Tanaka's formula for random `dense' signatures, thus providing the first
rigorous justification of this formula. Apart from being computationally
convenient, the new scheme allows for optimization in close analogy with
irregular low density parity check code ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602029</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602029</id><created>2006-02-07</created><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Wortman</keyname><forenames>Kevin A.</forenames></author></authors><title>Approximate Weighted Farthest Neighbors and Minimum Dilation Stars</title><categories>cs.CG cs.DS</categories><comments>12 pages, 2 figures</comments><abstract>  We provide an efficient reduction from the problem of querying approximate
multiplicatively weighted farthest neighbors in a metric space to the
unweighted problem. Combining our techniques with core-sets for approximate
unweighted farthest neighbors, we show how to find (1+epsilon)-approximate
farthest neighbors in time O(log n) per query in D-dimensional Euclidean space
for any constants D and epsilon. As an application, we find an O(n log n)
expected time algorithm for choosing the center of a star topology network
connecting a given set of points, so as to approximately minimize the maximum
dilation between any pair of points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602030</id><created>2006-02-08</created><authors><author><keyname>Khan</keyname><forenames>Md. Zafar ALi</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Single-Symbol Maximum Likelihood Decodable Linear STBCs</title><categories>cs.IT math.IT</categories><comments>38 pages, 9 Figures, accepted for publication in IEEE Trans.
  Information Theory, 2006</comments><abstract>  Space-Time block codes (STBC) from Orthogonal Designs (OD) and Co-ordinate
Interleaved Orthogonal Designs (CIOD) have been attracting wider attention due
to their amenability for fast (single-symbol) ML decoding, and full-rate with
full-rank over quasi-static fading channels. However, these codes are instances
of single-symbol decodable codes and it is natural to ask, if there exist codes
other than STBCs form ODs and CIODs that allow single-symbol coding?
  In this paper, the above question is answered in the affirmative by
characterizing all linear STBCs, that allow single-symbol ML decoding (not
necessarily full-diversity) over quasi-static fading channels-calling them
single-symbol decodable designs (SDD). The class SDD includes ODs and CIODs as
proper subclasses. Further, among the SDD, a class of those that offer
full-diversity, called Full-rank SDD (FSDD) are characterized and classified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602031</id><created>2006-02-08</created><authors><author><keyname>Jakuczun</keyname><forenames>Wit</forenames></author></authors><title>Classifying Signals with Local Classifiers</title><categories>cs.AI</categories><acm-class>I.5; G.3; G.1.2</acm-class><abstract>  This paper deals with the problem of classifying signals. The new method for
building so called local classifiers and local features is presented. The
method is a combination of the lifting scheme and the support vector machines.
Its main aim is to produce effective and yet comprehensible classifiers that
would help in understanding processes hidden behind classified signals. To
illustrate the method we present the results obtained on an artificial and a
real dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602032</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602032</id><created>2006-02-08</created><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Nandakumar</keyname><forenames>Satyadev</forenames></author></authors><title>Finite-State Dimension and Real Arithmetic</title><categories>cs.CC cs.IT math.IT</categories><comments>15 pages</comments><abstract>  We use entropy rates and Schur concavity to prove that, for every integer k
&gt;= 2, every nonzero rational number q, and every real number alpha, the base-k
expansions of alpha, q+alpha, and q*alpha all have the same finite-state
dimension and the same finite-state strong dimension. This extends, and gives a
new proof of, Wall's 1949 theorem stating that the sum or product of a nonzero
rational number and a Borel normal number is always Borel normal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602033</id><created>2006-02-08</created><authors><author><keyname>Levin</keyname><forenames>Leonid A.</forenames></author></authors><title>Self-stabilization of Circular Arrays of Automata</title><categories>cs.DC cs.DM</categories><comments>2 pages</comments><journal-ref>Theoretical Computer Science, 235(1):143-144, 2000</journal-ref><abstract>  [Gacs, Kurdiumov, Levin, 78] proposed simple one-dimensional cellular
automata with 2 states. In an infinite array they are self-stabilizing: if all
but a finite minority of automata are in the same state, the minority states
disappear. Implicit in the paper was a stronger result that a sufficiently
small minority of states vanish even in a finite circular array. The following
note makes this strengthening explicit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602034</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602034</id><created>2006-02-08</created><updated>2007-08-13</updated><authors><author><keyname>Guo</keyname><forenames>Yuchun</forenames></author><author><keyname>Chen</keyname><forenames>Changjia</forenames></author><author><keyname>Zhou</keyname><forenames>Shi</forenames></author></authors><title>A topology visualisation tool for large-scale communications networks</title><categories>cs.NI</categories><comments>9 pages, 2 figures. Published</comments><acm-class>C.2.1; C.4</acm-class><journal-ref>ELECTRONICS LETTERS, Vol. 43, No. 10, PP. 597-598, May 2007.</journal-ref><abstract>  A visualisation tool is presented to facilitate the study on large-scale
communications networks. This tool provides a simple and effective way to
summarise the topology of a complex network at a coarse level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602035</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602035</id><created>2006-02-09</created><authors><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author><author><keyname>Heusdens</keyname><forenames>Richard</forenames></author></authors><title>n-Channel Entropy-Constrained Multiple-Description Lattice Vector
  Quantization</title><categories>cs.IT math.IT</categories><comments>17 Pages, two-columns. Accepted for publication in IEEE Trans. on
  Inform. Th</comments><abstract>  In this paper we derive analytical expressions for the central and side
quantizers which, under high-resolutions assumptions, minimize the expected
distortion of a symmetric multiple-description lattice vector quantization
(MD-LVQ) system subject to entropy constraints on the side descriptions for
given packet-loss probabilities.
  We consider a special case of the general n-channel symmetric
multiple-description problem where only a single parameter controls the
redundancy tradeoffs between the central and the side distortions. Previous
work on two-channel MD-LVQ showed that the distortions of the side quantizers
can be expressed through the normalized second moment of a sphere. We show here
that this is also the case for three-channel MD-LVQ. Furthermore, we conjecture
that this is true for the general n-channel MD-LVQ.
  For given source, target rate and packet-loss probabilities we find the
optimal number of descriptions and construct the MD-LVQ system that minimizes
the expected distortion. We verify theoretical expressions by numerical
simulations and show in a practical setup that significant performance
improvements can be achieved over state-of-the-art two-channel MD-LVQ by using
three-channel MD-LVQ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602036</id><created>2006-02-10</created><authors><author><keyname>Ndoundam</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Tchuente</keyname><forenames>Maurice</forenames></author></authors><title>R\'{e}seaux d'Automates de Caianiello Revisit\'{e}</title><categories>cs.NE</categories><comments>39 pages</comments><proxy>ccsd ccsd-00018804</proxy><abstract>  We exhibit a family of neural networks of McCulloch and Pitts of size $2nk+2$
which can be simulated by a neural networks of Caianiello of size $2n+2$ and
memory length $k$. This simulation allows us to find again one of the result of
the following article: [Cycles exponentiels des r\'{e}seaux de Caianiello et
compteurs en arithm\'{e}tique redondante, Technique et Science Informatiques
Vol. 19, pages 985-1008] on the existence of neural networks of Caianiello of
size $2n+2$ and memory length $k$ which describes a cycle of length $k \times
2^{nk}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602037</id><created>2006-02-10</created><authors><author><keyname>Climent</keyname><forenames>J. J.</forenames></author><author><keyname>Gorla</keyname><forenames>E.</forenames></author><author><keyname>Rosenthal</keyname><forenames>J.</forenames></author></authors><title>Cryptanalysis of the CFVZ cryptosystem</title><categories>cs.CR</categories><comments>12 pages</comments><abstract>  The paper analyzes a new public key cryptosystem whose security is based on a
matrix version of the discrete logarithm problem over an elliptic curve. It is
shown that the complexity of solving the underlying problem for the proposed
system is dominated by the complexity of solving a fixed number of discrete
logarithm problems in the group of an elliptic curve. Using an adapted Pollard
rho algorithm it is shown that this problem is essentially as hard as solving
one discrete logarithm problem in the group of an elliptic curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602038</id><created>2006-02-10</created><updated>2006-02-14</updated><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Hell</keyname><forenames>P.</forenames></author><author><keyname>Rafiey</keyname><forenames>A.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>Minimum Cost Homomorphisms to Proper Interval Graphs and Bigraphs</title><categories>cs.DM cs.AI</categories><abstract>  For graphs $G$ and $H$, a mapping $f: V(G)\dom V(H)$ is a homomorphism of $G$
to $H$ if $uv\in E(G)$ implies $f(u)f(v)\in E(H).$ If, moreover, each vertex $u
\in V(G)$ is associated with costs $c_i(u), i \in V(H)$, then the cost of the
homomorphism $f$ is $\sum_{u\in V(G)}c_{f(u)}(u)$. For each fixed graph $H$, we
have the {\em minimum cost homomorphism problem}, written as MinHOM($H)$. The
problem is to decide, for an input graph $G$ with costs $c_i(u),$ $u \in V(G),
i\in V(H)$, whether there exists a homomorphism of $G$ to $H$ and, if one
exists, to find one of minimum cost. Minimum cost homomorphism problems
encompass (or are related to) many well studied optimization problems. We
describe a dichotomy of the minimum cost homomorphism problems for graphs $H$,
with loops allowed. When each connected component of $H$ is either a reflexive
proper interval graph or an irreflexive proper interval bigraph, the problem
MinHOM($H)$ is polynomial time solvable. In all other cases the problem
MinHOM($H)$ is NP-hard. This solves an open problem from an earlier paper.
Along the way, we prove a new characterization of the class of proper interval
bigraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602039</id><created>2006-02-10</created><authors><author><keyname>Arion</keyname><forenames>Andrei</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Bonifati</keyname><forenames>Angela</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Manolescu</keyname><forenames>Ioana</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Pugliese</keyname><forenames>Andrea</forenames></author></authors><title>Path Summaries and Path Partitioning in Modern XML Databases</title><categories>cs.DB</categories><proxy>ccsd inria-00001105</proxy><abstract>  We study the applicability of XML path summaries in the context of
current-day XML databases. We find that summaries provide an excellent basis
for optimizing data access methods, which furthermore mixes very well with
path-partitioned stores. We provide practical algorithms for building and
exploiting summaries, and prove its benefits through extensive experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602040</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602040</id><created>2006-02-10</created><authors><author><keyname>Chouali</keyname><forenames>Samir</forenames><affiliation>LIFC</affiliation></author><author><keyname>Julliand</keyname><forenames>Jacques</forenames><affiliation>LIFC</affiliation></author><author><keyname>Masson</keyname><forenames>Pierre-Alain</forenames><affiliation>LIFC</affiliation></author><author><keyname>Bellegarde</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LIFC</affiliation></author></authors><title>PLTL Partitioned Model Checking for Reactive Systems under Fairness
  Assumptions</title><categories>cs.LO</categories><proxy>ccsd ccsd-00018848</proxy><acm-class>D.2.4</acm-class><journal-ref>ACM Transactions on Embedded Computing Systems 4(2) (2005) 267-301</journal-ref><doi>10.1145/1067915.1067918</doi><abstract>  We are interested in verifying dynamic properties of finite state reactive
systems under fairness assumptions by model checking. The systems we want to
verify are specified through a top-down refinement process. In order to deal
with the state explosion problem, we have proposed in previous works to
partition the reachability graph, and to perform the verification on each part
separately. Moreover, we have defined a class, called Bmod, of dynamic
properties that are verifiable by parts, whatever the partition. We decide if a
property P belongs to Bmod by looking at the form of the Buchi automaton that
accepts the negation of P. However, when a property P belongs to Bmod, the
property f =&gt; P, where f is a fairness assumption, does not necessarily belong
to Bmod. In this paper, we propose to use the refinement process in order to
build the parts on which the verification has to be performed. We then show
that with such a partition, if a property P is verifiable by parts and if f is
the expression of the fairness assumptions on a system, then the property f =&gt;
P is still verifiable by parts. This approach is illustrated by its application
to the chip card protocol T=1 using the B engineering design language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602041</identifier>
 <datestamp>2007-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602041</id><created>2006-02-10</created><updated>2007-06-17</updated><authors><author><keyname>Mihaescu</keyname><forenames>Radu</forenames></author><author><keyname>Levy</keyname><forenames>Dan</forenames></author><author><keyname>Pachter</keyname><forenames>Lior</forenames></author></authors><title>Why neighbor-joining works</title><categories>cs.DS cs.DM</categories><comments>Revision 2</comments><acm-class>F.2.0</acm-class><abstract>  We show that the neighbor-joining algorithm is a robust quartet method for
constructing trees from distances. This leads to a new performance guarantee
that contains Atteson's optimal radius bound as a special case and explains
many cases where neighbor-joining is successful even when Atteson's criterion
is not satisfied. We also provide a proof for Atteson's conjecture on the
optimal edge radius of the neighbor-joining algorithm. The strong performance
guarantees we provide also hold for the quadratic time fast neighbor-joining
algorithm, thus providing a theoretical basis for inferring very large
phylogenies with neighbor-joining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602042</id><created>2006-02-10</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>New security and control protocol for VoIP based on steganography and
  digital watermarking</title><categories>cs.CR cs.MM</categories><comments>8 pages, 4 figures, 1 table</comments><acm-class>C.2.0; K.4.6</acm-class><journal-ref>Annales UMCS, Informatica, AI 4 (2006), ISNN 1732-1360</journal-ref><abstract>  In this paper new security and control protocol for Voice over Internet
Protocol (VoIP) service is presented. It is the alternative for the IETF's
(Internet Engineering Task Force) RTCP (Real-Time Control Protocol) for
real-time application's traffic. Additionally this solution offers
authentication and integrity, it is capable of exchanging and verifying QoS and
security parameters. It is based on digital watermarking and steganography that
is why it does not consume additional bandwidth and the data transmitted is
inseparably bound to the voice content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602043</id><created>2006-02-11</created><updated>2006-02-21</updated><authors><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Deng</keyname><forenames>Xiaotie</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Computing Nash Equilibria: Approximation and Smoothed Complexity</title><categories>cs.CC cs.GT</categories><acm-class>F.1.2; F.1.3; F.2; F.2.3</acm-class><abstract>  We show that the BIMATRIX game does not have a fully polynomial-time
approximation scheme, unless PPAD is in P. In other words, no algorithm with
time polynomial in n and 1/\epsilon can compute an \epsilon-approximate Nash
equilibrium of an n by nbimatrix game, unless PPAD is in P. Instrumental to our
proof, we introduce a new discrete fixed-point problem on a high-dimensional
cube with a constant side-length, such as on an n-dimensional cube with
side-length 7, and show that they are PPAD-complete. Furthermore, we prove,
unless PPAD is in RP, that the smoothed complexity of the Lemke-Howson
algorithm or any algorithm for computing a Nash equilibrium of a bimatrix game
is polynomial in n and 1/\sigma under perturbations with magnitude \sigma. Our
result answers a major open question in the smoothed analysis of algorithms and
the approximation of Nash equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602044</id><created>2006-02-12</created><authors><author><keyname>Arora</keyname><forenames>Siddharth</forenames></author><author><keyname>Acharya</keyname><forenames>Jayadev</forenames></author><author><keyname>Verma</keyname><forenames>Amit</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>Multilevel Thresholding for Image Segmentation through a Fast
  Statistical Recursive Algorithm</title><categories>cs.CV</categories><comments>9 pages, 3 figures</comments><abstract>  A novel algorithm is proposed for segmenting an image into multiple levels
using its mean and variance. Starting from the extreme pixel values at both
ends of the histogram plot, the algorithm is applied recursively on sub-ranges
computed from the previous step, so as to find a threshold level and a new
sub-range for the next step, until no significant improvement in image quality
can be achieved. The method makes use of the fact that a number of
distributions tend towards Dirac delta function, peaking at the mean, in the
limiting condition of vanishing variance. The procedure naturally provides for
variable size segmentation with bigger blocks near the extreme pixel values and
finer divisions around the mean or other chosen value for better visualization.
Experiments on a variety of images show that the new algorithm effectively
segments the image in computationally very less time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602045</id><created>2006-02-12</created><authors><author><keyname>Abbott</keyname><forenames>Russ</forenames></author></authors><title>Emergence Explained</title><categories>cs.MA cs.DC cs.GL</categories><comments>67 pages. Earlier versions presented at Lake ArrowHead conference on
  human complex systems (2005), GECCO 2005 workshop on Biological Applications
  of Genetic and Evolutionary Computation, and Symposium on Understanding
  Complex Systems (2005)</comments><abstract>  Emergence (macro-level effects from micro-level causes) is at the heart of
the conflict between reductionism and functionalism. How can there be
autonomous higher level laws of nature (the functionalist claim) if everything
can be reduced to the fundamental forces of physics (the reductionist
position)? We cut through this debate by applying a computer science lens to
the way we view nature. We conclude (a) that what functionalism calls the
special sciences (sciences other than physics) do indeed study autonomous laws
and furthermore that those laws pertain to real higher level entities but (b)
that interactions among such higher-level entities is epiphenomenal in that
they can always be reduced to primitive physical forces. In other words,
epiphenomena, which we will identify with emergent phenomena, do real
higher-level work. The proposed perspective provides a framework for
understanding many thorny issues including the nature of entities, stigmergy,
the evolution of complexity, phase transitions, supervenience, and downward
entailment. We also discuss some practical considerations pertaining to systems
of systems and the limitations of modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602046</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602046</id><created>2006-02-12</created><authors><author><keyname>Martinian</keyname><forenames>Emin</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Analysis of LDGM and compound codes for lossy compression and binning</title><categories>cs.IT math.IT</categories><comments>5 pages; to appear in Workshop on Information Theory and its
  Applications, February 2006, San Diego</comments><abstract>  Recent work has suggested that low-density generator matrix (LDGM) codes are
likely to be effective for lossy source coding problems. We derive rigorous
upper bounds on the effective rate-distortion function of LDGM codes for the
binary symmetric source, showing that they quickly approach the rate-distortion
function as the degree increases. We also compare and contrast the standard
LDGM construction with a compound LDPC/LDGM construction introduced in our
previous work, which provably saturates the rate-distortion bound with finite
degrees. Moreover, this compound construction can be used to generate nested
codes that are simultaneously good as source and channel codes, and are hence
well-suited to source/channel coding with side information. The sparse and
high-girth graphical structure of our constructions render them well-suited to
message-passing encoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602047</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602047</id><created>2006-02-13</created><updated>2008-01-11</updated><authors><author><keyname>Jonsson</keyname><forenames>Peter</forenames></author><author><keyname>Kuivinen</keyname><forenames>Fredrik</forenames></author><author><keyname>Nordh</keyname><forenames>Gustav</forenames></author></authors><title>Approximability of Integer Programming with Generalised Constraints</title><categories>cs.CC</categories><comments>Due to a flaw in a proof result 1 has changed. For maximal constraint
  languages we now prove a classification result for domains of size less than
  or equal to four. We also give a complete classification result for maximal
  constraint languages under the assumption that a conjecture due to Szczepara
  holds</comments><abstract>  We study a family of problems, called \prob{Maximum Solution}, where the
objective is to maximise a linear goal function over the feasible integer
assignments to a set of variables subject to a set of constraints. When the
domain is Boolean (i.e. restricted to $\{0,1\}$), the maximum solution problem
is identical to the well-studied \prob{Max Ones} problem, and the
approximability is completely understood for all restrictions on the underlying
constraints [Khanna et al., SIAM J. Comput., 30 (2001), pp. 1863-1920]. We
continue this line of research by considering domains containing more than two
elements. We present two main results: a complete classification for the
approximability of all maximal constraint languages over domains of cardinality
at most 4, and a complete classification of the approximability of the problem
when the set of allowed constraints contains all permutation constraints. Under
the assumption that a conjecture due to Szczepara holds, we give a complete
classification for all maximal constraint languages. These classes of languages
are well-studied in universal algebra and computer science; they have, for
instance, been considered in connection with machine learning and constraint
satisfaction. Our results are proved by using algebraic results from clone
theory and the results indicates that this approach is very powerful for
classifying the approximability of certain optimisation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602048</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602048</id><created>2006-02-13</created><authors><author><keyname>Azarian</keyname><forenames>Kambiz</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>On the Optimality of the ARQ-DDF Protocol</title><categories>cs.IT math.IT</categories><comments>26 pages, 2 figures</comments><acm-class>E.4; H.1.1</acm-class><abstract>  The performance of the automatic repeat request-dynamic decode and forward
(ARQ-DDF) cooperation protocol is analyzed in two distinct scenarios. The first
scenario is the multiple access relay (MAR) channel where a single relay is
dedicated to simultaneously help several multiple access users. For this setup,
it is shown that the ARQ-DDF protocol achieves the optimal diversity
multiplexing tradeoff (DMT) of the channel. The second scenario is the
cooperative vector multiple access (CVMA) channel where the users cooperate in
delivering their messages to a destination equipped with multiple receiving
antennas. For this setup, we develop a new variant of the ARQ-DDF protocol
where the users are purposefully instructed not to cooperate in the first round
of transmission. Lower and upper bounds on the achievable DMT are then derived.
These bounds are shown to converge to the optimal tradeoff as the number of
transmission rounds increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602049</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602049</id><created>2006-02-13</created><updated>2006-02-15</updated><authors><author><keyname>Murugan</keyname><forenames>Arul</forenames></author><author><keyname>Azarian</keyname><forenames>Kambiz</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>Cooperative Lattice Coding and Decoding</title><categories>cs.IT math.IT</categories><comments>25 pages, 8 figures</comments><acm-class>E.4; H.1.1</acm-class><abstract>  A novel lattice coding framework is proposed for outage-limited cooperative
channels. This framework provides practical implementations for the optimal
cooperation protocols proposed by Azarian et al. In particular, for the relay
channel we implement a variant of the dynamic decode and forward protocol,
which uses orthogonal constellations to reduce the channel seen by the
destination to a single-input single-output time-selective one, while
inheriting the same diversity-multiplexing tradeoff. This simplification allows
for building the receiver using traditional belief propagation or tree search
architectures. Our framework also generalizes the coding scheme of Yang and
Belfiore in the context of amplify and forward cooperation. For the cooperative
multiple access channel, a tree coding approach, matched to the optimal linear
cooperation protocol of Azarain et al, is developed. For this scenario, the
MMSE-DFE Fano decoder is shown to enjoy an excellent tradeoff between
performance and complexity. Finally, the utility of the proposed schemes is
established via a comprehensive simulation study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602050</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602050</id><created>2006-02-13</created><authors><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Outage Capacity of the Fading Relay Channel in the Low SNR Regime</title><categories>cs.IT math.IT</categories><abstract>  In slow fading scenarios, cooperation between nodes can increase the amount
of diversity for communication. We study the performance limit in such
scenarios by analyzing the outage capacity of slow fading relay channels. Our
focus is on the low SNR and low outage probability regime, where the adverse
impact of fading is greatest but so are the potential gains from cooperation.
We showed that while the standard Amplify-Forward protocol performs very poorly
in this regime, a modified version we called the Bursty Amplify-Forward
protocol is optimal and achieves the outage capacity of the network. Moreover,
this performance can be achieved without a priori channel knowledge at the
receivers. In contrast, the Decode-Forward protocol is strictly sub-optimal in
this regime. Our results directly yield the outage capacity per unit energy of
fading relay channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602051</id><created>2006-02-14</created><authors><author><keyname>Lobo</keyname><forenames>Fernando G.</forenames></author><author><keyname>Lima</keyname><forenames>Claudio F.</forenames></author></authors><title>On the utility of the multimodal problem generator for assessing the
  performance of Evolutionary Algorithms</title><categories>cs.NE</categories><comments>Also UALG-ILAB Report No. 200601</comments><acm-class>I.2.8</acm-class><abstract>  This paper looks in detail at how an evolutionary algorithm attempts to solve
instances from the multimodal problem generator. The paper shows that in order
to consistently reach the global optimum, an evolutionary algorithm requires a
population size that should grow at least linearly with the number of peaks. It
is also shown a close relationship between the supply and decision making
issues that have been identified previously in the context of population sizing
models for additively decomposable problems.
  The most important result of the paper, however, is that solving an instance
of the multimodal problem generator is like solving a peak-in-a-haystack, and
it is argued that evolutionary algorithms are not the best algorithms for such
a task. Finally, and as opposed to what several researchers have been doing, it
is our strong belief that the multimodal problem generator is not adequate for
assessing the performance of evolutionary algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602052</id><created>2006-02-14</created><updated>2006-03-17</updated><authors><author><keyname>Grigoriev</keyname><forenames>Evgeniy</forenames></author></authors><title>The OverRelational Manifesto</title><categories>cs.DB cs.DS</categories><comments>34 pages</comments><acm-class>D.3.3; E.2; F.3.3; F.4.1; H.2.1; H.2.3; H.2.4; H.3.3</acm-class><abstract>  The OverRelational Manifesto (below ORM) proposes a possible approach to
creation of data storage systems of the next generation. ORM starts from the
requirement that information in a relational database is represented by a set
of relation values. Accordingly, it is assumed that the information about any
entity of an enterprise must also be represented as a set of relation values
(the ORM main requirement). A system of types is introduced, which allows one
to fulfill the main requirement. The data are represented in the form of
complex objects, and the state of any object is described as a set of relation
values. Emphasize that the types describing the objects are encapsulated,
inherited, and polymorphic. Then, it is shown that the data represented as a
set of such objects may also be represented as a set of relational values
defined on the set of scalar domains (dual data representation). In the general
case, any class is associated with a set of relation variables (R-variables)
each one containing some data about all objects of this class existing in the
system. One of the key points is the fact that the usage of complex (from the
user's viewpoint) refined names of R-variables and their attributes makes it
possible to preserve the semantics of complex data structures represented in
the form of a set of relation values. The most important part of the data
storage system created on the approach proposed is an object-oriented
translator operating over a relational DBMS. The expressiveness of such a
system is comparable with that of OO programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602053</id><created>2006-02-14</created><authors><author><keyname>Dani</keyname><forenames>Varsha</forenames></author><author><keyname>Hayes</keyname><forenames>Thomas P.</forenames></author></authors><title>How to Beat the Adaptive Multi-Armed Bandit</title><categories>cs.DS cs.LG</categories><abstract>  The multi-armed bandit is a concise model for the problem of iterated
decision-making under uncertainty. In each round, a gambler must pull one of
$K$ arms of a slot machine, without any foreknowledge of their payouts, except
that they are uniformly bounded. A standard objective is to minimize the
gambler's regret, defined as the gambler's total payout minus the largest
payout which would have been achieved by any fixed arm, in hindsight. Note that
the gambler is only told the payout for the arm actually chosen, not for the
unchosen arms.
  Almost all previous work on this problem assumed the payouts to be
non-adaptive, in the sense that the distribution of the payout of arm $j$ in
round $i$ is completely independent of the choices made by the gambler on
rounds $1, \dots, i-1$. In the more general model of adaptive payouts, the
payouts in round $i$ may depend arbitrarily on the history of past choices made
by the algorithm.
  We present a new algorithm for this problem, and prove nearly optimal
guarantees for the regret against both non-adaptive and adaptive adversaries.
After $T$ rounds, our algorithm has regret $O(\sqrt{T})$ with high probability
(the tail probability decays exponentially). This dependence on $T$ is best
possible, and matches that of the full-information version of the problem, in
which the gambler is told the payouts for all $K$ arms after each round.
  Previously, even for non-adaptive payouts, the best high-probability bounds
known were $O(T^{2/3})$, due to Auer, Cesa-Bianchi, Freund and Schapire. The
expected regret of their algorithm is $O(T^{1/2}) for non-adaptive payouts, but
as we show, $\Omega(T^{2/3})$ for adaptive payouts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602054</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602054</id><created>2006-02-14</created><authors><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Kumar</keyname><forenames>K. Raj</forenames></author><author><keyname>Pawar</keyname><forenames>Sameer A.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author><author><keyname>Lu</keyname><forenames>Hsiao-feng</forenames></author></authors><title>Explicit Space-Time Codes Achieving The Diversity-Multiplexing Gain
  Tradeoff</title><categories>cs.IT math.IT</categories><comments>Revised submission to IEEE Transactions on Information Theory</comments><abstract>  A recent result of Zheng and Tse states that over a quasi-static channel,
there exists a fundamental tradeoff, referred to as the diversity-multiplexing
gain (D-MG) tradeoff, between the spatial multiplexing gain and the diversity
gain that can be simultaneously achieved by a space-time (ST) block code. This
tradeoff is precisely known in the case of i.i.d. Rayleigh-fading, for T&gt;=
n_t+n_r-1 where T is the number of time slots over which coding takes place and
n_t,n_r are the number of transmit and receive antennas respectively. For T &lt;
n_t+n_r-1, only upper and lower bounds on the D-MG tradeoff are available.
  In this paper, we present a complete solution to the problem of explicitly
constructing D-MG optimal ST codes, i.e., codes that achieve the D-MG tradeoff
for any number of receive antennas. We do this by showing that for the square
minimum-delay case when T=n_t=n, cyclic-division-algebra (CDA) based ST codes
having the non-vanishing determinant property are D-MG optimal. While
constructions of such codes were previously known for restricted values of n,
we provide here a construction for such codes that is valid for all n.
  For the rectangular, T &gt; n_t case, we present two general techniques for
building D-MG-optimal rectangular ST codes from their square counterparts. A
byproduct of our results establishes that the D-MG tradeoff for all T&gt;= n_t is
the same as that previously known to hold for T &gt;= n_t + n_r -1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602055</id><created>2006-02-15</created><authors><author><keyname>Lobo</keyname><forenames>Fernando G.</forenames></author><author><keyname>Lima</keyname><forenames>Claudio F.</forenames></author></authors><title>Revisiting Evolutionary Algorithms with On-the-Fly Population Size
  Adjustment</title><categories>cs.NE</categories><comments>Also UALG-ILAB Report No. 200602</comments><acm-class>I.2.8</acm-class><abstract>  In an evolutionary algorithm, the population has a very important role as its
size has direct implications regarding solution quality, speed, and
reliability. Theoretical studies have been done in the past to investigate the
role of population sizing in evolutionary algorithms. In addition to those
studies, several self-adjusting population sizing mechanisms have been proposed
in the literature. This paper revisits the latter topic and pays special
attention to the genetic algorithm with adaptive population size (APGA), for
which several researchers have claimed to be very effective at autonomously
(re)sizing the population.
  As opposed to those previous claims, this paper suggests a complete opposite
view. Specifically, it shows that APGA is not capable of adapting the
population size at all. This claim is supported on theoretical grounds and
confirmed by computer simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602056</id><created>2006-02-15</created><authors><author><keyname>Borri</keyname><forenames>Dino</forenames></author><author><keyname>Camarda</keyname><forenames>Domenico</forenames></author></authors><title>Building Scenarios for Environmental Management and Planning: An
  IT-Based Approach</title><categories>cs.MA</categories><acm-class>I.2.11</acm-class><abstract>  Oftentimes, the need to build multidiscipline knowledge bases, oriented to
policy scenarios, entails the involvement of stakeholders in manifold domains,
with a juxtaposition of different languages whose semantics can hardly allow
inter-domain transfers. A useful support for planning is the building up of
durable IT based interactive platforms, where it is possible to modify initial
positions toward a semantic convergence. The present paper shows an area-based
application of these tools, for the integrated distance-management of different
forms of knowledge expressed by selected stakeholders about environmental
planning issues, in order to build alternative development scenarios.
  Keywords: Environmental planning, Scenario building, Multi-source knowledge,
IT-based
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602057</id><created>2006-02-15</created><authors><author><keyname>Agnew</keyname><forenames>Melanie J.</forenames></author><author><keyname>Homan</keyname><forenames>Christopher M.</forenames></author></authors><title>Plane Decompositions as Tools for Approximation</title><categories>cs.DS</categories><abstract>  Tree decompositions were developed by Robertson and Seymour. Since then
algorithms have been developed to solve intractable problems efficiently for
graphs of bounded treewidth. In this paper we extend tree decompositions to
allow cycles to exist in the decomposition graph; we call these new
decompositions plane decompositions because we require that the decomposition
graph be planar. First, we give some background material about tree
decompositions and an overview of algorithms both for decompositions and for
approximations of planar graphs. Then, we give our plane decomposition
definition and an algorithm that uses this decomposition to approximate the
size of the maximum independent set of the underlying graph in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602058</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602058</id><created>2006-02-15</created><updated>2007-02-17</updated><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Incremental Redundancy Cooperative Coding for Wireless Networks:
  Cooperative Diversity, Coding, and Transmission Energy Gain</title><categories>cs.IT math.IT</categories><comments>revised version</comments><abstract>  We study an incremental redundancy (IR) cooperative coding scheme for
wireless networks. To exploit the spatial diversity benefit we propose a
cluster-based collaborating strategy for a quasi-static Rayleigh fading channel
model and based on a network geometric distance profile. Our scheme enhances
the network performance by embedding an IR cooperative coding scheme into an
existing noncooperative route. More precisely, for each hop, we form a
collaborating cluster of M-1 nodes between the (hop) sender and the (hop)
destination. The transmitted message is encoded using a mother code and
partitioned into M blocks corresponding to the each of M slots. In the first
slot, the (hop) sender broadcasts its information by transmitting the first
block, and its helpers attempt to relay this message. In the remaining slots,
the each of left-over M-1 blocks is sent either through a helper which has
successfully decoded the message or directly by the (hop) sender where a
dynamic schedule is based on the ACK-based feedback from the cluster. By
employing powerful good codes (e.g., turbo codes, LDPC codes, and raptor codes)
whose performance is characterized by a threshold behavior, our approach
improves the reliability of a multi-hop routing through not only cooperation
diversity benefit but also a coding advantage. The study of the diversity and
the coding gain of the proposed scheme is based on a new simple threshold bound
on the frame-error rate (FER) of maximum likelihood decoding. A average FER
upper bound and its asymptotic (in large SNR) version are derived as a function
of the average fading channel SNRs and the code threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602059</id><created>2006-02-15</created><authors><author><keyname>Manepalli</keyname><forenames>Suchitra</forenames></author><author><keyname>Manepalli</keyname><forenames>Giridhar</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>D2D: Digital Archive to MPEG-21 DIDL</title><categories>cs.DL</categories><comments>28 pages, 8 figures</comments><abstract>  Digital Archive to MPEG-21 DIDL (D2D) analyzes the contents of the digital
archive and produces an MPEG-21 Digital Item Declaration Language (DIDL)
encapsulating the analysis results. DIDL is an extensible XML-based language
that aggregates resources and the metadata. We provide a brief report on
several analysis techniques applied on the digital archive by the D2D and
provide an evaluation of its run-time performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602060</id><created>2006-02-16</created><authors><author><keyname>Davis</keyname><forenames>Philip M.</forenames></author><author><keyname>Price</keyname><forenames>Jason S.</forenames></author></authors><title>eJournal interface can influence usage statistics: implications for
  libraries, publishers, and Project COUNTER</title><categories>cs.IR cs.DL</categories><comments>22 pages, 5 figures. JASIST (in press, 2006)</comments><journal-ref>JASIST v57 n9 (2006):1243-1248</journal-ref><doi>10.1002/asi.20405</doi><abstract>  The design of a publisher's electronic interface can have a measurable effect
on electronic journal usage statistics. A study of journal usage from six
COUNTER-compliant publishers at thirty-two research institutions in the United
States, the United Kingdom and Sweden indicates that the ratio of PDF to HTML
views is not consistent across publisher interfaces, even after controlling for
differences in publisher content. The number of fulltext downloads may be
artificially inflated when publishers require users to view HTML versions
before accessing PDF versions or when linking mechanisms, such as CrossRef,
direct users to the full text, rather than the abstract, of each article. These
results suggest that usage reports from COUNTER-compliant publishers are not
directly comparable in their current form. One solution may be to modify
publisher numbers with adjustment factors deemed to be representative of the
benefit or disadvantage due to its interface. Standardization of some interface
and linking protocols may obviate these differences and allow for more accurate
cross-publisher comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602061</id><created>2006-02-16</created><authors><author><keyname>Anderson</keyname><forenames>David P.</forenames></author><author><keyname>Fedak</keyname><forenames>Gilles</forenames></author></authors><title>The Computational and Storage Potential of Volunteer Computing</title><categories>cs.DC cs.PF</categories><comments>8 pages. To appear in CCGrid 2006</comments><abstract>  &quot;Volunteer computing&quot; uses Internet-connected computers, volunteered by their
owners, as a source of computing power and storage. This paper studies the
potential capacity of volunteer computing. We analyzed measurements of over
330,000 hosts participating in a volunteer computing project. These
measurements include processing power, memory, disk space, network throughput,
host availability, user-specified limits on resource usage, and host churn. We
show that volunteer computing can support applications that are significantly
more data-intensive, or have larger memory and storage requirements, than those
in current projects.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="98000" completeListSize="102538">1122234|99001</resumptionToken>
</ListRecords>
</OAI-PMH>
